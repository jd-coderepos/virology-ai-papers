Sl. No,Authors,Year of publication,Primary affiliation of primary author,Title,Name of publication,Subdomain,Disease Name,doi,Type of evidence source,Research Aim,Research Problem,AI Objective,AI Methodology,AI Method Details,AI Method Type,Is software publicly released?,Software License,Virology AI task addressed,Type of Underlying Data,Dataset Name,Was Performance Measured,How was Performance measured and what was measured?,Performance metrics,Performance score
1,"Amyar, A.; Modzelewski, R.; Ruan, S.",2020,"Artificial Intelligence and Modelling in Epidemiology Program, Melbourne Sexual Health Centre, Alfred Health, Melbourne, Australia.",Multi-task Deep Learning Based CT Imaging Analysis For COVID-19: Classification and Segmentation,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.04.16.20064709,Research,The aim of this study is to develop a multi-task deep learning model that can jointly classify COVID-19 cases and segment lung lesions from chest CT images,"Existing deep learning models for CT-based COVID-19 detection often rely on separate architectures for classification and segmentation, missing the opportunity to exploit shared features between tasks.","To develop a multi-task deep learning model that can simultaneously classify COVID-19 cases and segment infected lung regions in chest CT images, while improving feature representation and minimizing overfitting through shared learning and an auxiliary image reconstruction task.","The study employs a multi-task learning (MTL) framework with hard parameter sharing to address the limitations of existing COVID-19 detection models. In MTL, multiple related tasks are learned jointly, allowing the model to share representations and improve generalization. The authors designed a unified architecture that learns from three tasks simultaneously: image reconstruction, lesion segmentation, and COVID-19 classification. The rationale behind this setup is that learning a shared feature representation across tasks allows the model to extract more robust and discriminative features, particularly in the presence of limited labeled data. Hard parameter sharing is used, meaning that the encoder’s parameters are shared across all tasks, while each task has its own task-specific output layers (decoders or MLP). This approach not only reduces overfitting by regularizing the shared parameters but also allows auxiliary tasks (like reconstruction) to act as regularizers that stabilize training and enhance the quality of learned representations. The methodology is validated across three experiments: task combination tuning, comparison with U-Net for segmentation, and comparison with a CNN for classification.","The proposed method is a multi-task deep learning model composed of a shared 2D U-Net-based encoder and three task-specific branches: one for image reconstruction, another for infection segmentation, and a third for COVID-19 classification using a multi-layer perceptron (MLP). The encoder extracts deep feature representations from CT images, which are then passed to two decoders (for reconstruction and segmentation) and a classifier head (for binary classification). The reconstruction decoder is trained using mean squared error, the segmentation decoder uses dice loss with sigmoid activation, and the classification head uses binary cross-entropy loss with a sigmoid output. The entire model is optimized jointly using the Adam optimizer with a learning rate of 0.0001 and early stopping after 35 epochs. Input images are resized to 256×256 pixels and intensity-normalized to ensure consistency across datasets. The inclusion of an image reconstruction task, although not a primary objective, serves to improve the encoder’s capacity to generalize across tasks, thereby enhancing both segmentation and classification performance. Experimental results demonstrate the superiority of the multi-task approach over single-task models like standalone U-NET and CNNs.",MT-UNet-COVID: Multi-Task U-Net-Based Model for COVID-19 Detection and Lesion Segmentation,No,No,Automated detection and analysis of COVID-19 infection from chest CT imaging,CT images,Amyar et.al,Yes,"To evaluate the effectiveness of the proposed multi-task learning (MTL) model for COVID-19 detection and lesion segmentation, the authors conducted three controlled experiments. They used the same datasets (COVID-CT, COVID-19 CT Segmentation, Henri Becquerel scans) and consistent train/validation/test splits for all experiments. In Experiment 1, they varied task combinations (reconstruction, segmentation, classification) to tune the architecture and select the best setup. In Experiment 2, they compared their MTL model with standard U-Net architectures for the segmentation task. In Experiment 3, they compared their model against a classification-only CNN for detecting COVID-19 from CT scans. The segmentation task was evaluated using CT images with lesion masks and measured by Dice coefficient. The classification task was evaluated using labeled COVID/non-COVID scans and measured by accuracy, sensitivity, specificity, and AUC (Area Under the ROC Curve). All models were trained with the same optimizer, learning rate, and early stopping criteria to ensure fair comparisons.","{""segmentation"": [""dice""], ""classification"": [""accuracy"", ""sensitivity"", ""specificity"", ""auc""]}","performance_metrics = {
    ""segmentation"": {
        ""task"": ""COVID-19 lesion segmentation"",
        ""evaluation_method"": ""Dice coefficient using annotated lesion masks"",
        ""dice"": 0.7852
    },
    ""classification"": {
        ""task"": ""COVID-19 vs non-COVID classification from CT"",
        ""evaluation_method"": ""Binary classification using test set with ground truth labels"",
        ""accuracy"": 0.86,
        ""sensitivity"": 0.94,
        ""specificity"": 0.79,
        ""auc"": 0.93
    }
}"
2,"Durant, T. J.; Dudgeon, S. N.; Mcpadden, J.; Simpson, A.; Price, N.; Schulz, W. L.; Torres, R.; Olson, E.",2021,"Department of Information System, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah 21589, Saudi Arabia.",Applications of Digital Microscopy and Densely Connected Convolutional Neural Networks for Automated Quantitation of Babesia-Infected Erythrocytes,MedRxiv,General Virology,['Babesia'],10.1101/2021.04.27.21256115,Research,"The aim of this study is to develop and evaluate a machine learning (ML)-based method for the automated measurement of percent parasitemia in digital microscopic images of Giemsa-stained peripheral blood smears, specifically for the diagnosis and monitoring of babesiosis. ","The manual quantification of parasitemia from Giemsa-stained blood smears is time-consuming, error-prone, and reliant on experienced personnel factors that can delay or compromise clinical decisions, especially in severe babesiosis cases. With growing demands on laboratory workflows and limited expert availability, there is a critical need for an accurate, automated method to measure percent parasitemia from digital blood smear images to enhance diagnostic efficiency and reliability.",Parasite quantification,"The study employs a supervised deep learning approach to automate the classification of erythrocytes as parasite-infected or normal in Giemsa-stained peripheral blood smear images. Individual cells were manually labeled and cropped into 70×70×3 images, which were used to train a DenseNet121 convolutional neural network with ImageNet pre-trained weights. The model was trained using binary cross-entropy loss and optimized with the Adam optimizer, incorporating data augmentation and class oversampling to handle data imbalance. After training, the model was applied to segment and classify cells from clinical validation slides, and percent parasitemia was calculated as the ratio of predicted parasite-infected cells to total cells analyzed. Model performance was compared to a reference standard derived from repeated assessments by experienced medical laboratory scientists. To enhance interpretability, the study also used Integrated Gradients to visualize which image regions influenced model predictions.","The authors implemented a DenseNet121 architecture pre-trained on ImageNet, modified with a global average pooling layer, dropout, and a sigmoid-activated dense output layer for binary classification of erythrocytes as parasite-infected or normal. Individual 70×70×3 RGB erythrocyte images were generated from manually labeled blood smear slides and split into training, validation, and test datasets. The model was trained with data augmentation and class oversampling to address imbalance. Optimization was done using the Adam optimizer with binary cross-entropy loss. After training, the best-performing model was applied to clinical validation slides, using contour-based cell segmentation to isolate cells. Percent parasitemia was then computed by dividing the number of predicted parasite cells by the total cells analyzed per image. Integrated Gradients were used to visualize the image regions most influential in model decisions.",ParaNet-121: DenseNet-Based Model for Automated Parasitemia Quantification,No,No,automated quantification of intraerythrocytic parasitemia caused by Babesia species,Microscopic images,Durant et.al,Yes,"Performance was measured at two levels: single-cell classification and slide-level parasitemia quantification. For the classification task, the model was evaluated on a held-out test dataset of labeled erythrocyte images using standard metrics including accuracy, precision, recall, and AUC. The best-performing model was then applied to clinical validation slides, where it classified segmented erythrocytes and computed percent parasitemia as the ratio of predicted parasite-infected cells to total cells. These slide-level results were compared against a clinical reference standard derived from nine expert readings per slide. Agreement was assessed using linear regression (R²), Bland-Altman analysis for bias, categorical agreement across parasitemia bins and around the 10% clinical decision threshold, and coefficient of variation to measure precision.","{""accuracy"", ""precision"", ""recall"", ""auc"", ""false_positives"", ""false_negatives"", ""r2_with_outliers"", ""r2_without_outliers""}","{""accuracy"": 0.99, ""precision"": 0.92, ""recall"": 1.00, ""auc"": ""not reported numerically"", ""false_positives"": 20, ""false_negatives"": 0, ""r2_with_outliers"": 0.244, ""r2_without_outliers"": 0.916}"
3,"Kalia, R. K.; Sharma, A.; Amin, S. B.; Saha, M.; Thittamaranahalli, S. K.",2021,"Department of Biostatistics, Epidemiology, and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.",AI-DRIVEN QUANTIFICATION OF GROUND GLASS OPACITIES IN LUNGS OF COVID-19 PATIENTS USING 3D COMPUTED TOMOGRAPHY IMAGING,MedRxiv,Respiratory Virology,['SARS-CoV-2'],10.1101/2021.07.06.21260109,Research," develop an AI-driven, unsupervised deep learning framework based on PointNet++ and Minkowski tensor analysis to accurately segment, visualize, and quantify ground-glass opacities (GGOs) in 3D CT lung scans of COVID-19 patients, and to use these features for disease severity assessment and abnormality prediction","Ground-glass opacities (GGOs) are a key radiological feature in CT scans of COVID-19 patients, but their manual detection and analysis is time-consuming, subjective, and error-prone, especially given the scale of the pandemic and limited radiological resources. Existing supervised deep learning approaches require large labeled datasets and struggle with variability in GGO appearance, especially in low-contrast CT images. Moreover, most models treat GGOs as simple binary regions without quantifying their 3D morphology. There is a critical need for a robust, unsupervised AI method that can efficiently segment GGOs, analyze their 3D shape and distribution, and predict disease abnormality to support rapid diagnosis and optimize resource allocation.","The objective of this study is to develop an AI-driven framework for the automated segmentation, classification, and morphological analysis of ground-glass opacities (GGOs) in 3D CT scans of COVID-19 patients. The model aims to support radiologists by efficiently identifying GGOs, analyzing their spatial distribution and shapes, and predicting disease abnormality levels. This approach is designed to facilitate rapid diagnosis and triage, especially in overwhelmed healthcare systems with limited expert resources.","The study employs an unsupervised deep learning methodology that combines point cloud-based segmentation with morphological and statistical analysis. CT scans are preprocessed to extract lung regions using thresholding and morphological operations. GGOs are then segmented using K-means clustering and convex hull algorithms to preserve anatomical structure. These segmented lung volumes are converted into point clouds and analyzed using the PointNet++ neural network, which performs 3D segmentation and classification. In parallel, a CNN followed by a Cox proportional hazards model is used to compute abnormality scores for different lung regions. Minkowski tensor analysis is applied to quantify the shapes and anisotropic properties of GGOs for further diagnostic insight.","The authors use the publicly available MosMedData dataset containing 3D CT scans of lungs from 1110 patients. First, lung regions are extracted from CT scans using thresholding and morphological operations. To restore GGO areas missed during masking, a convex hull algorithm is applied to reconstruct the lung boundaries. GGOs are then segmented using K-means clustering. The processed CT volumes are converted into point clouds, where a subset of 2048 points is sampled to capture the 3D structure. These point clouds are fed into a PointNet++ architecture, which performs segmentation and classification of GGOs with high accuracy. For abnormality scoring, the output of a CNN is fed into a Cox proportional hazards model, producing heatmaps that indicate high-risk lung regions. The morphological characteristics of GGOs are further analyzed using Minkowski tensors, quantifying their shape deviation, area, perimeter, and anisotropy indices to support clinical interpretation.",PointNet++-MinkowskiGGO(Unsupervised 3D Segmentation and Morphological Analysis Framework for COVID-19 GGOs),No,No,"automated detection, segmentation, and morphological analysis of ground-glass opacities (GGOs) in lung CT scans of COVID-19 patients",3D CT scans of lungs,MosMedData,Yes,"Performance was measured by evaluating the effectiveness of the PointNet++ model in segmenting ground-glass opacities (GGOs) from 3D CT scans in the MosMedData dataset. The model’s segmentation accuracy was assessed using a labeled subset of CT scans containing annotated GGOs. Key performance indicators included evaluation accuracy, average class accuracy, and intersection over union (IoU). Additionally, abnormality scoring was performed using a CNN followed by a Cox proportional hazards model, producing heatmaps to highlight high-risk lung regions, though this part was evaluated qualitatively. The shape and size of GGOs were quantitatively analyzed using Minkowski tensors, measuring anisotropy and other geometric features. Overall, the focus was on assessing segmentation quality, pattern analysis, and interpretability for clinical relevance.","{""evaluation_accuracy"", ""average_class_accuracy"", ""intersection_over_union""}","{""evaluation_accuracy"": 0.98, ""average_class_accuracy"": 0.95, ""intersection_over_union"": 0.92}"
4,"Vilar, J.; Saiz, L.",2022,"Department of Food Science and Technology, The Ohio State University, Columbus, OH, United States of America.",Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series,MedRxiv,Respiratory Virology,['SARS-CoV-2'],10.1101/2022.09.14.22279935,Research,"The aim of this study is to develop a dynamics-informed deconvolutional neural network (DIDNN) that can infer the timing and amplitude of epidemiological regime changes such as the implementation or lifting of nonpharmaceutical interventions (NPIs) from noisy, time-lagged, and low-resolution death data.","Traditional models rely heavily on known intervention dates or smoothed case data, which obscures precise temporal changes in disease transmission. Unlike fields such as computer vision, epidemiology lacks high-resolution, regularized inference techniques capable of handling such complex deconvolution.","The objective of this study is to design an unsupervised, physics-informed deep learning model that can accurately infer the daily infection incidence and detect regime changes such as lockdowns or other nonpharmaceutical interventions (NPIs) from stochastically delayed COVID-19 death records. The approach aims to identify these transitions at single-day resolution, enabling improved retrospective analysis of transmission dynamics and policy impacts.","The proposed methodology integrates convolutional neural networks (CNNs) with physics-informed neural network (PINN) principles to model the relationship between observed daily death counts and unobserved infection incidence. The model is built on the renewal equation framework of epidemiology, incorporating domain knowledge through a custom loss function that balances data fidelity (Poisson likelihood of observed deaths) with regularization terms that enforce sparsity in transmission rate changes and consistency with the underlying disease dynamics. The method further incorporates model selection techniques (e.g., Akaike Information Criterion) to tune regularization strength, and it operates entirely without using prior knowledge of NPI timing.","The architecture is a reverse convolutional neural network designed to estimate scaled infection incidence from daily death data, using known probabilistic kernels for infection-to-death and generation time. The input to the network includes the death data and epidemiological kernels, while the outputs are the expected daily deaths and inferred incidence. The network is trained using a custom objective function that combines (1) a Poisson log-likelihood weighted for scale invariance, and (2) a regime-change-aware regularization based on changes in the logarithm of the reproduction number. A dynamics-informed term is also introduced to enforce the renewal equation linking current incidence with past infections. This leads to the final combined loss used for unsupervised training. The final model infers regime shifts in the instantaneous reproduction number with remarkable temporal accuracy and robustness across multiple countries.",Dynamics-Informed Deconvolutional Neural Network (DIDNN),No,No,"retrospective inference of daily infection incidence from noisy, lagged COVID-19 death data","Historical COVID-19 data (deaths, cases, etc.)",Vilar et.al,Yes,"Performance was measured by evaluating how accurately the model could infer the timing of regime changes such as the implementation or lifting of nonpharmaceutical interventions (NPIs) sfrom observed COVID-19 death data, without prior knowledge of intervention dates. Specifically, the model’s predicted dates of significant changes in the reproduction number (R?), inferred from reconstructed infection incidence, were compared to the actual dates of known NPIs. The primary evaluation metric was the offset between predicted and actual intervention dates, calculated across multiple European countries. Additional measurements included the model’s fidelity to the observed daily death counts using a Poisson likelihood loss, and the consistency of its predictions over a wide range of death rates and dynamic regimes. This demonstrated the model’s ability to resolve rapid shifts in transmission dynamics with single-day resolution, validating both its temporal precision and epidemiological realism.","{""mean_NPI_offset_days"", ""std_NPI_offset_days"", ""poisson_fluctuation_score"", ""single_day_accuracy_within_±1d""}","{""mean_NPI_offset_days"": 0.22, ""std_NPI_offset_days"": 0.63, ""poisson_fluctuation_score"": 1.25, ""single_day_accuracy_within_±1d"": ""86%""}"
5,"Joung, H.-A.; Ballard, Z. S.; Wu, J.; Tseng, D. K.; Teshome, H.; Zhang, L.; Horn, E. J.; Arnaboldi, P. M.; Dattwyler, R. J.; Garner, O. B.; Carlo, D. D.; Ozcan, A.",2019,"Artificial Intelligence and Modelling in Epidemiology Program, Melbourne Sexual Health Centre, Alfred Health, Melbourne, Australia.",Point-of-care serodiagnostic test for early-stage Lyme disease using a multiplexed paper-based immunoassay and machine learning,MedRxiv,Zoonotic Virology,['Lyme disease'],10.1101/19009423,Research,"To develop a low-cost, rapid, and highly accurate point-of-care (POC) diagnostic test for early-stage Lyme disease (LD), using a paper-based multiplexed vertical flow assay (xVFA) combined with deep learning to improve diagnostic performance compared to standard two-tier serological testing.","Current diagnostic methods for Lyme disease are inadequate during the early stages of infection. There is an urgent need for a rapid, affordable, and accurate POC test that can replace or supplement the current two-tier approach for early detection of Lyme disease.",To use deep learning to develop a diagnostic algorithm that accurately interprets multiplexed antibody responses from a paper-based test to detect early-stage Lyme disease at the point-of-care.,"The approach combines a multiplexed serological assay (xVFA) with a supervised deep learning model. Raw colorimetric outputs from the assay are preprocessed using image analysis and normalization techniques. A feature selection process is applied to identify the most informative antigen channels, followed by the training of a neural network classifier on labeled data (seropositive or seronegative) using binary cross-entropy loss. The model is trained and validated using human serum samples with known diagnoses.","The AI method developed in this study centers around a supervised deep learning neural network designed to classify early-stage Lyme disease based on outputs from a multiplexed paper-based assay (xVFA). The input to the model consists of normalized colorimetric signals (R?) from selected antigen spots for both IgM and IgG antibodies. A feature selection process—Sequential Forward Feature Selection (SFFS)—was applied to identify the most diagnostically informative 9 out of 20 potential antigen/peptide targets. The final neural network comprises three fully connected hidden layers with 128, 64, and 32 nodes, each employing batch normalization, 50% dropout, and ReLU activation functions. The output layer uses a sigmoid activation to produce a binary classification score. Training used a binary cross-entropy loss function with a learning rate of 0.001, batch size of 32, and early stopping criteria based on stagnation of training accuracy. The model was trained and cross-validated on 100 individual test instances derived from 50 human serum samples, aiming to replicate and eventually replace the standard two-tier Lyme disease testing protocol.",Deep Learning-Based Diagnostic Neural Network for xVFA,No,No, early-stage serological diagnosis of Lyme disease,human serum samples,Lyme Disease Biobank,Yes,"The model was evaluated using blind testing on 50 new serum samples, separate from the training data. Metrics such as AUC, sensitivity, specificity, and overall accuracy were used to assess the diagnostic performance of the deep learning-enhanced xVFA system.","{""AUC"", ""sensitivity"", ""specificity"", ""overall_accuracy""}","{""AUC"": 0.963, ""sensitivity"": 0.857, ""specificity"": 0.963, ""overall_accuracy"": 0.917}"
6,"Zhou, M.; Chen, Y.; Wang, D.; Xu, Y.; Yao, W.; Huang, J.; Jin, X.; Pan, Z.; Tan, J.; Wang, L.; Xia, Y.; Zou, L.; Xu, X.; Wei, J.; Guan, M.; Feng, J.; Zhang, H.; Qu, J.",2020,"Department of Pulmonary and Critical Care Medicine, Ruijin hospital, Shanghai Jiao Tong University School o f Medicine , China",Improved deep learning model for differentiating novel coronavirus pneumonia and influenza pneumonia,MedRxiv,Respiratory Virology,"['COVID-19 (SARS-CoV-2)', 'Influenza (IP)']",10.1101/2020.03.24.20043117,Research,"The aim of this study is to develop and validate an integrated deep learning framework using chest CT images to automatically detect novel coronavirus pneumonia (NCP) and distinguish it from influenza pneumonia (IP), enhancing early diagnosis and aiding epidemic control.","Early-stage NCP and IP present overlapping clinical symptoms and similar CT imaging features, making accurate differentiation difficult especially in contexts where nucleic acid tests are limited or delayed. This diagnostic ambiguity can lead to misclassification, misallocation of resources, and increased transmission risk.","To automatically detect and differentiate novel coronavirus pneumonia (NCP) from influenza pneumonia (IP) using chest CT images, enabling faster, more accurate diagnosis—especially when nucleic acid testing is delayed or inconclusive.","The study employed a deep learning pipeline combining object detection and image classification to analyze chest CT scans. The system first detects lung lesions using YOLOv3 and then classifies the lesions as NCP or IP using a modified VGGNet model. To improve generalization across different CT scanners and hospitals, the authors introduced a novel training strategy called the ""Trinary scheme"" that encourages the model to learn device-independent, lesion-specific features.","The AI method developed in this study consists of a two-stage deep learning pipeline designed for automatic detection and differentiation of novel coronavirus pneumonia (NCP) and influenza pneumonia (IP) on chest CT images. First, the system uses YOLOv3 to detect potential lung lesions on CT slices, leveraging its speed and accuracy for object detection. The detected lesion regions are then classified using a modified version of VGGNet, which incorporates transfer learning to adapt to the limited annotated dataset. To address domain shift and device-dependence common challenges in medical imaging the authors introduce a novel ""Trinary scheme"" during training. This approach adds a third class of randomly selected background regions to the classification task, encouraging the network to focus on lesion-specific rather than device-specific features. The classification outputs from individual lesions are aggregated through ensemble averaging to make a patient-level diagnosis. This method was evaluated against specialist radiologists and demonstrated improved generalization and diagnostic performance, particularly on data from previously unseen CT devices and centers.",Trinary Scheme Deep Learning Framework using YOLOv3 for lesion detection and a Modified VGGNet for lesion classification.,No,No,differential diagnosis of novel coronavirus pneumonia (NCP) from influenza pneumonia (IP) using chest CT scans,chest CT images,Zhou et.al,Yes,"Performance in this study was measured by evaluating both lesion-level and patient-level classification accuracy for distinguishing Novel Coronavirus Pneumonia (NCP) from Influenza Pneumonia (IP) using chest CT scans. Lesion detection was carried out using the YOLOv3 architecture, while classification was performed with a modified VGGNet. To assess generalization across different imaging devices, two training schemes were compared: a standard Plain scheme and a novel Trinary scheme designed to learn device-independent features. Lesion-level predictions were aggregated per patient to compute patient-level classification results. Performance was benchmarked against diagnoses confirmed by nucleic acid tests and evaluated using metrics such as AUC, sensitivity, specificity, accuracy, precision, and F1 score. The study also included comparative analysis with human radiologists to validate the model’s clinical applicability.","{""AUC"", ""accuracy"", ""sensitivity"", ""specificity"", ""precision"", ""F1_score"", ""lesion_detection_F1""}","{""AUC"": 0.92, ""accuracy"": 0.91, ""sensitivity"": 1.00, ""specificity"": 0.95, ""precision"": None, ""F1_score"": 0.847, ""lesion_detection_F1"": 0.742}"
7,"Jo, H.; Son, H.; Jung, S. Y.; Hwang, H. J.",2020,"Department of Mathematics, Pohang University of Science and Technology, South Korea",Analysis of COVID-19 spread in South Korea using the SIR model with time-dependent parameters and deep learning,MedRxiv,General Virology,['COVID-19'],10.1101/2020.04.13.20063412,Research,To model the spread of COVID-19 in South Korea more accurately by integrating time-dependent parameters into the SIR epidemiological model using deep neural networks.,"Traditional SIR models with constant parameters struggle to accurately reflect the rapidly changing dynamics of real-world infectious disease outbreaks like COVID-19. Furthermore, constant-parameter models fail to capture effects of interventions and behavioral shifts over time.","To use deep neural networks to simultaneously approximate the variables (S, I, R) and time-varying parameters (?, ?) in the SIR model, enabling real-time computation of the reproduction number RT(t) and improving epidemic forecasting accuracy.","The study frames the COVID-19 modeling task as a forward-inverse problem, where both the solution of the SIR model and its parameters (? and ?) are approximated simultaneously. This is achieved by training deep neural networks (DNNs) to learn both the system dynamics and the underlying time-dependent parameters, allowing for real-time estimation of key epidemic indicators such as the reproduction number RT(t).","The researchers construct five separate deep neural networks Snet, Inet, Rnet, ?net, and ?net each taking time t as input and outputting one of the target variables: the scaled compartment values S(t),I(t),R(t) and the time-varying parameters ?(t) and ?(t). All networks share a consistent architecture with one input node, one output node, four hidden layers, and 256 neurons per layer. They use the hyperbolic tangent (tanh) activation for hidden layers, while the final layer uses Softplus and Sigmoid activations to enforce constraints such as ?,S,I,R>0 and 0<?<1. The networks are trained using loss functions that incorporate relative errors and numerical consistency with the SIR differential equations. The Runge-Kutta 4 (RK4) method is also used to verify that the learned parameters can reproduce the dynamics of the original system.",Deep Neural Networks (DNNs),No,No,Modeling and forecasting the spread dynamics of COVID-19 in South Korea using time-dependent SIR parameters,daily cumulative COVID-19 statistics,Jo et.al,Yes,"The study does not report standard machine learning metrics such as accuracy, F1-score, AUC, RMSE, or MAE. Instead, the evaluation focuses on how well the deep neural networks approximate the time-dependent SIR model parameters and variables. Performance was assessed using relative errors between predicted and observed values for the susceptible, infected, and recovered populations. Additionally, the authors validated the correctness of their learned parameters by running simulations with the Runge-Kutta 4 (RK4) numerical method and comparing the results to actual COVID-19 data. Epidemiological consistency was also checked by analyzing the behavior of the time-dependent reproduction number R_T(t) = \beta(t)/\gamma(t). These evaluation strategies emphasize mathematical and epidemiological validity over conventional ML benchmarking.",,
8,"Deng, Q.",2020,"College of Economics and Management, China-Africa International Business School, Zhejiang Normal University, Jinhua, China",Dynamics and Development of the COVID-19 Epidemics in the US: a Compartmental Model with Deep Learning Enhancement,MedRxiv,Emerging & Re-emerging Viruses,['SARS-CoV-2'],10.1101/2020.05.31.20118414,Research,"To develop a deep learning–enhanced compartmental model that accurately simulates and forecasts the progression of the COVID-19 epidemic in the United States, while minimizing dependence on resource-intensive transmission statistics typically required by traditional epidemic models","Traditional compartmental epidemic models, such as SEIR variants, rely heavily on stochastic parameterization processes that require detailed and costly epidemiological data. This reliance limits their scalability and responsiveness, especially in data-scarce or rapidly evolving outbreak scenarios.","To apply deep neural networks (DNN) and recurrent neural networks with long short-term memory (RNN-LSTM) for estimating key transmission parameters (? and ?R) of a simplified compartmental model (SIRJD), enabling accurate epidemic forecasting without the need for exhaustive epidemiological data collection.","The study follows a multi-step deep learning-based forecasting pipeline. First, it constructs a simplified compartmental epidemic model (SIRJD) using real-world COVID-19 data. Next, deep learning models are trained to predict the key transmission parameters (? and ?R) using historical confirmed and death time series data. Finally, the predicted parameters are recursively fed back into the compartmental model to simulate future epidemic trajectories over 35- and 42-day horizons.","DNNs were used to model complex nonlinear relationships between input features (daily confirmed and death case counts) and target transmission parameters. The architecture likely consisted of multiple fully connected hidden layers with activation functions (e.g., ReLU), trained using backpropagation and mean squared error (MSE) loss. The DNN takes a fixed-size window of past data (time series features) as input and outputs predicted values of ? and ?R. These predictions are then fed into the compartmental model to forecast the epidemic’s trajectory.",Deep Neural Networks (DNN),No,No,Forecasting the epidemic dynamics of COVID-19,"Daily case data (confirmed, active, recovered, hospitalized, deaths)",Deng et.al,Yes,"In this study, performance was measured by evaluating the ability of deep learning models DNN and RNN-LSTM to accurately estimate key transmission parameters (? and ?R) and forecast the trajectory of the COVID-19 epidemic in the United States. Rather than using standard predictive metrics like RMSE or MAE, the authors focused on the consistency, plausibility, and epidemiological relevance of the predictions. Specifically, they assessed whether the predicted basic reproduction number (R?) would drop below 1 signaling containment of the epidemic and whether the models could accurately forecast milestone events such as the peak of active infections and the point when cumulative confirmed cases would surpass 5 million. Performance was judged based on how well the predicted infection curves aligned with known epidemic dynamics and the agreement between the 35-day and 42-day forecasts produced by both DNN and RNN-LSTM models. This approach emphasized interpretability and scenario realism over purely statistical error measures.",,
,,,,,,,,,,,,,,"LSTMs are a type of RNN that incorporate memory cells to capture long-term dependencies in sequential data. In this study, LSTM networks are trained on multivariate time series of confirmed and death cases to learn temporal patterns and trends. LSTMs outperform DNNs in modeling epidemic dynamics due to their ability to maintain and update internal states, which is essential for sequence prediction. Like the DNNs, the LSTMs output future values of ? and ?R, which are recursively applied in the SIRJD model to simulate the development of susceptible, infected, recovered, isolated, and deceased compartments over time.",Recurrent Neural Networks – Long Short-Term Memory (RNN-LSTM),,,,Time series of confirmed and death cases,,,,,
9,"He, X.; Wang, S.; Shi, S.; Chu, X.; Tang, J.; Liu, X.; Yan, C.; Zhang, J.; Ding, G.",2021,"Department of Computer Science, Hong Kong Baptist University, Hong Kong, China",Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.06.08.20125963,Research,"To conduct a systematic, reproducible, and comprehensive benchmarking study of deep learning models for COVID-19 diagnosis using chest CT scans, by building a clean and consistent dataset (Clean-CC-CCII) and evaluating both manually designed and automatically generated models under uniform conditions.","There is a lack of consistent and fair comparison across deep learning methods for COVID-19 detection due to the presence of noise and inconsistency in datasets (like CC-CCII) and the absence of standardized evaluation protocols, making it difficult to assess which models perform best.","To develop and evaluate multiple 2D and 3D CNN architectures, including automated neural architecture search (NAS) for model design, for the purpose of improving classification performance in distinguishing between novel coronavirus pneumonia (NCP), common pneumonia (CP), and normal controls using the newly cleaned CT dataset (Clean-CC-CCII).",The study follows a supervised deep learning methodology using both manual model design and automatic neural architecture search (NAS). The models are trained on a cleaned and standardized CT image dataset for multi-class classification under a uniform pipeline to ensure reproducibility and fair evaluation.,"The 2D CNN models in the study were trained on individual CT slices, treating them as standalone images without considering the 3D spatial continuity between slices. This category includes well-established architectures such as ResNet50, DenseNet121, EfficientNetB3, ResNeXt101, and MobileNetV2. These models are widely used in computer vision tasks due to their efficient design and proven accuracy. ResNet50 introduces residual connections for deeper training, DenseNet121 emphasizes dense connectivity for feature reuse, and EfficientNetB3 applies compound scaling to balance depth, width, and resolution. MobileNetV2 is optimized for mobile and embedded environments, while ResNeXt101 enhances representational power via grouped convolutions. While these models are fast and resource-efficient, they do not leverage the full spatial context available in volumetric CT data, which may limit their diagnostic depth.",2D CNN Models,https://github.com/UCSD-AI4H/COVID-CT,Apache License 2.0,COVID-19 infection diagnosis,CT scans,Clean-CC-CCII,Yes,"In this study, performance was measured to evaluate how effectively different deep learning models could classify chest CT scans into three categories: COVID-19 pneumonia (NCP), common pneumonia (CP), and normal cases. The primary metric used was classification accuracy, which reflects the overall percentage of correctly predicted cases. To assess model efficiency, the authors also measured inference time per scan, indicating how fast each model could process a full CT volume, and model size, which refers to the memory footprint of each trained model in megabytes. Additionally, to evaluate the stability and reliability of each model’s performance, the experiments were repeated multiple times and the standard deviation of the accuracy scores was reported. These evaluations ensured a holistic comparison not just in terms of predictive performance, but also in computational efficiency and robustness across runs."," {""accuracy"" , ""f1_score"" , ""auc""}","{""MNas3DNet41 (NAS-based 3D CNN)"": {""accuracy"": 87.14, ""f1_score"": 87.25, ""auc"": 0.957}, ""ResNet50 (2D CNN)"": {""accuracy"": 86.75, ""f1_score"": 86.85, ""auc"": 0.954}, ""ResNet3D101 (3D CNN)"": {""accuracy"": 85.15, ""f1_score"": 85.30, ""auc"": 0.950}}"
,,,,,,,,,,,,,,"The 3D CNN models operate on full CT volumes, allowing the network to exploit spatial dependencies across adjacent slices. This group includes ResNet3D101, DenseNet3D121, MC3_18, R2Plus1D, and PreActResNet3D. These architectures extend their 2D counterparts into the third dimension, enabling richer volumetric feature extraction. For example, ResNet3D101 and DenseNet3D121 bring deep and densely connected residual learning into the 3D domain. MC3_18 uses mixed convolutions to balance complexity and performance by separating spatial and temporal dimensions. R2Plus1D factorizes 3D convolutions into 2D spatial followed by 1D temporal convolutions to improve convergence and representation. PreActResNet3D applies batch normalization before activation layers for smoother gradient flow. Overall, 3D CNNs tend to outperform 2D CNNs in volumetric medical imaging tasks due to their ability to capture global spatial structures, though at the cost of increased computational demands.",3D CNN Models,,,,,,,,,
,,,,,,,,,,,,,,"To explore automation in model design, the study also incorporates models generated via Neural Architecture Search (NAS): MNas3DNet21 and MNas3DNet41. These 3D CNNs were automatically constructed using a search strategy that optimizes for both accuracy and efficiency. MNas3DNet21 is a lightweight model (~12.4 MB) designed for fast inference and deployment in low-resource environments, while MNas3DNet41 is a deeper variant offering the highest classification performance among all tested models. These NAS-based architectures demonstrate that compact, high-performing deep learning models can be discovered algorithmically, reducing the need for manual architecture engineering. The inclusion of NAS models in the benchmark reflects a growing trend toward automated machine learning (AutoML) approaches in medical imaging, especially when resource constraints and deployment feasibility are critical.",NAS-Generated CNN Models,,,,,,,,,
10,"El-Bana, S.; Al-Kabbany, A.; Sharkas, M.",2020,"National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing",A Multi-Task Pipeline with Specialized Streams forClassification and Segmentation of InfectionManifestations in COVID-19 Scans,MedRxiv,Respiratory Virology,['SARS-CoV-2'],10.1101/2020.06.24.20139238,Research,"To develop and evaluate a multi-task deep learning pipeline for COVID-19 detection, infection classification, and segmentation in chest X-ray and CT scans, offering a digital second opinion to support radiologists in managing the pandemic.","Traditional diagnostic methods like RT-PCR suffer from false negatives, supply shortages, and delayed results, and current deep learning-based imaging approaches often fail to jointly address detection, classification, and segmentation tasks with high accuracy and efficiency.","To develop a high-performance, multi-task deep learning pipeline for COVID-19 detection, manifestation classification, and infection segmentation using models like Inception-v3 and DeepLab-v3+, with transfer learning and multi-stream design.",Deep learning-based approach using convolutional neural networks (CNNs) and multiple streams for segmentation.,Fine-tuned on X-ray and CT scan images; pre-trained on ImageNet. Achieved up to 99.5% test accuracy using multi-modal data.,Inception-v3 (Transfer Learning),No,No,COVID-19 classification (binary and multi-class),Chest CT scans,COVID-19 CT Segmentation Dataset,Yes,"In the first task, a fine-tuned Inception-v3 model was used to classify chest scans into either two classes (COVID-19 vs. Normal) or four classes (COVID-19, Normal, Bacterial Pneumonia, Viral Pneumonia). The performance was evaluated using standard classification metrics. The model achieved 99.4% test accuracy in the binary classification setting and 98.1% in the four-class classification task. Furthermore, incorporating CT scans alongside X-rays (multi-modal learning) led to a slight performance improvement, achieving 99.5% accuracy, which suggests that CT scans contribute valuable spatial features for diagnosis. The results indicate strong generalization and robustness of the model across both tasks and input modalities.","{""binary"":{""accuracy"":,""sensitivity"":,""specificity"":,""precision"":,""f1_score"":,""mcc"":},""four_class"":{""accuracy"":},""multi_modal"":{""accuracy"":,""sensitivity"":,""specificity"":,""precision"":,""f1_score"":,""mcc"":}","{""binary"":{""accuracy"":99.4,""sensitivity"":99.5,""specificity"":99.1,""precision"":99.1,""f1score"":99.3,""mcc"":98.7},""four_class"":{""accuracy"":98.1},""multi_modal"":{""accuracy"":99.5,""sensitivity"":99.8,""specificity"":98.2,""precision"":99.2,""f1_score"":99.5,""mcc"":99.0}"
,,,,,,,,,,,,,,"Predicts probabilities for each manifestation. Uses ELU activation, dropout regularization, and binary cross-entropy loss.",Custom CNN,,,"Multi-label classification of manifestations (GGO, PE, consolidation)",Chest X-rays and CT scans,COVID-19 Image Data Collection,,"The second task aimed to identify specific infection manifestations (Ground Glass Opacity, Pleural Effusion, and Consolidation) in CT scans using a custom multi-label CNN. The classifier was evaluated using accuracy, precision, sensitivity, and F1-score both per class and overall. It achieved an overall accuracy of 87.2%, with F1-scores ranging from 85% to 90% for individual manifestation types. This task fills an important gap in prior work by distinguishing among multiple manifestation types, enhancing the interpretability and clinical value of the predictions, and preparing the input for more targeted segmentation in the next stage.","{""overall"":{""accuracy"":,""precision"":,""sensitivity"":,""f1_score"":},""per_label"":{""pleural_effusion"":{""accuracy"":,""precision"":,""sensitivity"":,""f1_score"":},""ground_glass_opacity"":{""accuracy"":,""precision"":,""sensitivity"":,""f1_score"":},""consolidation"":{""accuracy"":,""precision"":,""sensitivity"":,""f1_score"":}","{""accuracy"":87.2,""precision"":87.3,""sensitivity"":87.6,""f1score"":87.0},""per_label"":{""pleural_effusion"":{""accuracy"":91.31,""precision"":83.0,""sensitivity"":90.0,""f1score"":86.0},""ground_glass_opacity"":{""accuracy"":89.46,""precision"":91.0,""sensitivity"":80.0,""f1_score"":85.0},""consolidation"":{""accuracy"":93.72,""precision"":88.0,""sensitivity"":93.0,""f1_score"":90.0}"
,,,,,,,,,,,,,,Transfer learning from pulmonary nodule segmentation. Employs specialized multi-stream training one stream per manifestation type for better Dice and mIoU performance.,DeepLab-v3+ with Xception-65 backbone,,,Semantic segmentation of infection regions,Chest X-rays,RSNA Pneumonia Detection Challenge Dataset,,"The third task involved pixel-level segmentation of infection regions in CT scans using the DeepLab-v3+ model with an Xception-65 backbone. A novel multi-stream approach was used, where each stream was trained to segment a specific type of manifestation. This yielded superior results compared to single-stream models. The multi-stream setup achieved 91.01% Dice Coefficient and 83.5% mIoU. Additionally, the model showed significant improvements over previous studies: a 41% increase in DSC for Ground Glass Opacity and a 290% increase for Consolidation. It also offered efficiency benefits, with diagnosis time per case reduced to 5.33 seconds, representing a 60% decrease in computational time compared to traditional RT-PCR testing.","{""accuracy"",""precision"",""sensitivity"",""f1score""}","{""overall"":{""dice_coefficient"":86.04,""mean_iou"":75.5,""multi_stream_dice"":91.01,""multi_stream_miou"":83.5},""per_label"":{""ground_glass_opacity"":{""dice_coefficient"":90.2,""mean_iou"":82.15,""dsc_gain_percent"":41},""consolidation"":{""dice_coefficient"":91.5,""mean_iou"":84.46,""dsc_gain_percent"":290},""pleural_effusion"":{""dice_coefficient"":91.34,""mean_iou"":84.06}},""efficiency"":{""diagnosis_time_per_case_seconds"":5.33,""reduction_vs_rt_pcr_percent"":60}}"
11,"Bhouri, M. A.; Costabal, F. S.; Wang, H.; Linka, K.; Peirlinck, M.; Kuhl, E.; Perdikaris, P.",2020,"Department of Mechanical Engineering and Applied Mechanics University of Pennsylvania Philadelphia, PA 19104 bhouri@seas.upenn.edu",COVID-19 dynamics across the US: A deep learning study of human mobility and social behavior,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.09.20.20198432,Research,"The aim of this research is to develop a robust, data-driven computational framework for calibrating epidemiological models of COVID-19 that can provide probabilistic forecasts and quantify the effects of mobility, social behavior, and policy interventions on the spread of the virus across U.S. counties.","The problem of predicting the spread of infectious diseases, particularly COVID-19, using machine learning and epidemiology models","The AI objective is to use deep learning to infer the time-varying reproduction number (?) of COVID-19 from real-world, noisy, and partially observed mobility and infection data, in order to produce uncertainty-aware forecasts of disease spread and support decision-making.","The authors propose a deep learning-based system identification framework to estimate the time-varying disease transmission rate from partially observed and noisy epidemiological data. This involves combining an SEIR epidemiological model with an LSTM-based neural network that models the basic reproduction number ?(t) as a function of mobility and social behavior trends. The model is trained across multiple county-level trajectories using a tensorized multi-step loss function, enabling efficient joint calibration and uncertainty quantification.","The proposed AI method integrates a mobility- and social behavior-informed SEIR epidemiological model with a deep learning approach to estimate the time-varying disease transmission rate. Specifically, the model uses a Long Short-Term Memory (LSTM) neural network to learn the mapping from time-series mobility and social behavior trends to the basic reproduction number beta(t), which governs the spread of the disease. The SEIR model is discretized and combined with a tensorized multi-step loss function that allows training across multiple county-level trajectories simultaneously. To account for uncertainty in the data and model predictions, an ensemble of 100 LSTM networks is trained with different initializations. This approach enables both accurate and uncertainty-aware forecasts of COVID-19 dynamics while also allowing for sensitivity analysis and simulation of intervention strategies, such as lockdowns or changes in mobility patterns.",Ensemble LSTM-based Epidemiological Model Calibration (DeepCOVID19),https://github.com/PredictiveIntelligenceLab/DeepCOVID19,No,COVID-19 disease severity and early triage decisions guidance,Google COVID-19 Community Mobility Reports and Unacast Social Behavior Data,Bhouri et.al,Yes,"The study measured the model's ability to forecast cumulative COVID-19 cases across U.S. counties. After training on 66 days of data, the model's predictions were evaluated over a 15-day forecast period using relative forecasting error as the primary metric. This error was calculated by comparing the predicted cumulative case counts to the actual observed values in each county. The model achieved an average relative error of 4.3% on the training data and 6.6% on the test (forecast) data, indicating strong predictive performance. Standard machine learning metrics like accuracy or AUC were not reported; instead, the evaluation focused on the model's effectiveness in accurately projecting future case trajectories.","{""overall"":{""dice_coefficient"":,""mean_iou"":,""multi_stream_dice"":,""multi_stream_miou"":},""per_label"":{""ground_glass_opacity"":{""dice_coefficient"":,""mean_iou"":,""dsc_gain_percent"":},""consolidation"":{""dice_coefficient"":,""mean_iou"":,""dsc_gain_percent"":},""pleural_effusion"":{""dice_coefficient"":,""mean_iou"":}},""efficiency"":{""diagnosis_time_per_case_seconds"":,""reduction_vs_rt_pcr_percent"":}}",
12,"Rodriguez, A.; Tabassum, A.; Cui, J.; Xie, J.; Ho, J.; Agarwal, P.; Adhikari, B.; Prakash, B. A.",2021,"College of Computing, Georgia Institute of Technology, Atlanta, USA",DeepCOVID: An Operational Deep Learning-driven Framework for Explainable Real-time COVID-19 Forecasting,MedRxiv,Emerging & Re-emerging Viruses,"['SARS-CoV-2', 'COVID-19']",10.1101/2020.09.28.20203109,Research,"To develop and operationalize a purely data-driven deep learning framework capable of providing real-time, short-term forecasts of COVID-19 trajectories (including deaths and hospitalizations) across multiple geographic regions, with a focus on interpretability, robustness to noisy data, and principled uncertainty estimation.",Addressing the challenge of predicting COVID-19 cases using historical data and real-time updates,"To design and deploy a deep learning-based predictive model that can ingest multivariate time series data from diverse sources (e.g., mobility, testing, hospital records), and generate probabilistic short-term forecasts with calibrated uncertainty estimates, which are suitable for public health decision-making and real-time policy interventions.","The methodology is a data-driven deep learning framework for real-time epidemic forecasting that integrates multiple components: a data preprocessing pipeline to manage noisy, sparse, and heterogeneous signals; a feedforward neural network with autoregressive inputs for probabilistic forecasting; and an explainability module using signal ablation and statistical testing to interpret model outputs and identify key predictive features.","DeepCovid uses a feedforward neural network with autoregressive inputs to forecast COVID-19 targets such as weekly deaths and hospitalizations. Instead of relying on mechanistic disease modeling, it learns directly from multivariate time series data (e.g., mobility trends, testing rates, exposure signals) aggregated at national and state levels. The model includes three hidden layers (sizes 10, 5, 2) and uses the ReLU activation function. To quantify uncertainty, DeepCovid employs bootstrapping, generating multiple forecasts per input sample to construct probabilistic intervals. Batch normalization and multiple optimization initializations improve robustness during training. To ensure temporal consistency in predictions, a self-regressive approach is used, where past forecasts inform subsequent ones. Finally, a signal ablation-based explainability module identifies the relative contribution of each input feature, enhancing interpretability for public health decision-makers.",DeepCovid,https://github.com/srijankr/deepcovid,Apache License 2.0,Short-term forecasting of COVID-19 cases,"heterogeneous, multivariate time series data",Rodriguez et.al,Yes,"The performance of the DeepCovid framework was measured by evaluating its ability to forecast short-term COVID-19 trends, specifically weekly incident and cumulative deaths as well as daily hospitalizations, across U.S. states and nationally. The evaluation focused on both the accuracy of point forecasts and the quality of the associated uncertainty estimates. For point predictions, the primary metric used was Mean Absolute Percentage Error (MAPE), which quantifies the average percentage deviation of predicted values from the actual observed values. To assess the reliability of the probabilistic forecasts, the authors used the Interval Score (??) with a confidence level of ? = 0.7, a standard metric in epidemiological forecasting that penalizes both the width of prediction intervals and whether the true values fall within them. These metrics were applied to real-time forecasts submitted weekly between June and September 2020, and DeepCovid’s performance was benchmarked against the official ensemble model from the COVID-19 Forecast Hub. However, exact numerical values for these metrics were not reported in the paper.",,
13,"Arntfield, R.; Vanberlo, B.; Alaifan, T.; Phelps, N.; White, M.; Chaudhary, R.; Ho, J.; Wu, D.",2020,"Division of Critical Care Medicine, Western University, London, Ontario, Canada",Development of a deep learning classifier to accurately distinguish COVID-19 from look-a-like pathology on lung ultrasound,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.10.13.20212258,Research,The aim of this study is to determine whether deep learning techniques can enhance the diagnostic specificity of lung ultrasound (LUS) by distinguishing between visually similar B-line patterns associated with different respiratory pathologies,To develop a reliable method for differentiating non-cardiogenic B-line pathologies using LUS.,"The AI objective of the study is to develop and train a convolutional neural network (CNN), using the Xception architecture with transfer learning, to classify LUS images into one of three pathologies: COVID-19, NCOVID, or HPE. The model aims to identify subvisible patterns within LUS images that are not apparent to human observers, and to quantitatively outperform LUS-trained physicians in diagnostic classification tasks.","The study follows a deep learning-based image classification methodology using lung ultrasound (LUS) frames to train a convolutional neural network (CNN) to classify B-line patterns into three pathologies: COVID-19, non-COVID ARDS (NCOVID), and hydrostatic pulmonary edema (HPE). The methodology includes data curation, preprocessing (grayscale conversion, beam isolation, artifact removal), extensive data augmentation, and transfer learning with multiple CNN architectures. The best-performing model was selected through validation on a test set (test-1), and final performance was assessed on a completely held-out dataset (test-2) to ensure generalizability. Human physician performance was benchmarked using a national survey, and comparison to the model was statistically validated using Monte Carlo simulations.","The AI method used in this study is a convolutional neural network (CNN) based on the Xception architecture, implemented via transfer learning with pretrained ImageNet weights. The model was trained to classify lung ultrasound (LUS) images into three categories: COVID-19, non-COVID ARDS (NCOVID), and hydrostatic pulmonary edema (HPE). Input images were preprocessed by converting grayscale LUS frames to RGB format and removing interface artifacts using a custom beam isolation algorithm. Data augmentation techniques such as zooming, flipping, stretching, and rotating were applied to improve generalization. The model architecture included global average pooling, dropout (rate 0.6), and a final fully connected softmax layer producing a three-class probability distribution. Training was performed using the Adam optimizer with a learning rate of 1e-6 and weighted categorical cross-entropy as the loss function. Early stopping was used to prevent overfitting. Model performance was evaluated on a held-out test set at both frame and encounter levels, and explainability was addressed using Grad-CAM heatmaps to highlight regions (e.g., pleural line) influential in the model’s decision-making.",Xception-based Convolutional Neural Network (CNN),https://github.com/bvanberl/covid-us-ml,MIT License,differential diagnosis of COVID-19,lung ultrasound (LUS) video clips ,Arntfield et.al,Yes,"performance was measured to evaluate how well the deep learning model could classify lung ultrasound (LUS) images into three disease categories: COVID-19, non-COVID ARDS (NCOVID), and hydrostatic pulmonary edema (HPE). The model’s performance was assessed on a held-out test set using the area under the receiver operating characteristic curve (AUC) at both the individual frame level and the aggregated encounter level. Results were compared against the diagnostic performance of 61 LUS-trained physicians through a structured survey. Additionally, a Monte Carlo simulation with one million iterations was conducted to statistically validate that the model's superior performance, especially in distinguishing between COVID-19 and NCOVID cases, was unlikely to be due to chance.","{""AUC""}","{""model_AUCs"": {""COVID"": 1.0, ""NCOVID"": 0.934, ""HPE"": 1.0, ""overall"": 0.978}, ""human_AUCs"": {""COVID"": 0.697, ""NCOVID"": 0.704, ""HPE"": 0.967, ""overall"": 0.789}, ""monte_carlo_human_AUC_avg"": 0.840}"
14,"Nabi, K. N.",2021,"Department of Mathematics, Bangladesh University of Engineering and Technology (BUET), Dhaka, Bangladesh",Forecasting COVID-19 cases: A comparative analysis between Recurrent and Convolutional Neural Networks,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.11.28.20240259,Research,"The aim of this study is to forecast the future transmission dynamics of COVID-19, including potential second waves, in Brazil, Russia, and the United Kingdom.",need for more reliable deep learning approaches that can provide accurate forecasts even with short historical sequences and minimal features.,"evaluate and compare the performance of four deep learning models LSTM, GRU, CNN, and Multivariate CNN for forecasting daily COVID-19 cases and deaths.","The study uses a comparative deep learning-based forecasting methodology to model the transmission of COVID-19 in Brazil, Russia, and the UK. Time series data of daily COVID-19 cases and deaths are preprocessed using moving average smoothing to reduce noise. The cleaned data is then used to train and validate four deep learning architectures LSTM, GRU, CNN, and Multivariate CNN on country-specific datasets. The models are evaluated using standard forecasting metrics to assess their predictive performance. The approach emphasizes robust long-term prediction in scenarios with limited historical data and lack of seasonality.","LSTM is a type of recurrent neural network (RNN) that captures long-term dependencies in sequential data using memory cells and gating mechanisms (forget, input/update, and output gates). In this study, it was used for univariate time series forecasting based on daily COVID-19 case data. However, LSTM underperformed due to the lack of seasonality and limited historical data in the input. It was trained with moving averaged data, using a sliding window to feed sequences into the model.",Long Short-Term Memory (LSTM),No,No,"Forecasting COVID-19 case counts and deaths, specifically for the second wave prediction in Brazil, Russia, and the United Kingdom.",daily confirmed COVID-19 cases and daily death counts,Nabi et.al,Yes,"The study measured the forecasting accuracy of four deep learning models LSTM, GRU, CNN, and Multivariate CNN in predicting daily COVID-19 cases and deaths over a 40-day horizon for Brazil, Russia, and the United Kingdom. Performance was evaluated using normalized root mean squared error (nRMSE) and mean absolute percentage error (MAPE), which assess the deviation between predicted and actual values while accounting for scale and percentage accuracy, respectively. Additionally, mean squared error (MSE) was used as the loss function during model training. These metrics were calculated on both training and validation sets, with lower values indicating better model performance. The CNN model consistently achieved the best results, demonstrating strong predictive ability even with limited historical data and high data volatility.","{""nRMS"", ""MAP""}","{""Brazil"": {""CNN"": {""nRMSEval"": 0.086, ""MAPEval"": 6.94}, ""Multivariate_CNN"": {""nRMSEval"": 0.109, ""MAPEval"": 8.2}, ""LSTM"": {""nRMSEval"": 0.2, ""MAPEval"": 13.33}, ""GRU"": {""nRMSEval"": 0.12, ""MAPEval"": 10.267}}, ""Russia"": {""CNN"": {""nRMSEval"": 0.01, ""MAPEval"": 0.85}, ""Multivariate_CNN"": {""nRMSEval"": 0.01, ""MAPEval"": 0.86}, ""LSTM"": {""nRMSEval"": 0.05, ""MAPEval"": 4.64}, ""GRU"": {""nRMSEval"": 0.014, ""MAPEval"": 1.2}}, ""UK"": {""CNN"": {""nRMSEval"": 0.04809, ""MAPEval"": 3.75}, ""Multivariate_CNN"": {""nRMSEval"": 0.09, ""MAPEval"": 7.8}, ""LSTM"": {""nRMSEval"": 0.06481, ""MAPEval"": 5.25}, ""GRU"": {""nRMSEval"": 0.04, ""MAPEval"": 2.997}}}"
,,,,,,,,,,,,,,"GRU is a simplified variant of LSTM that combines the forget and input gates into a single update gate, reducing computational complexity while retaining the ability to model temporal dependencies. It lacks a separate memory cell, making it faster to train. Like LSTM, GRU was applied to the smoothed univariate COVID-19 case data. It performed better than LSTM in some cases (e.g., UK), but still did not outperform CNN models overall.",Gated Recurrent Unit (GRU),,,,,,,,,
,,,,,,,,,,,,,,"CNN was adapted for univariate time series forecasting in this study. The architecture included four convolutional layers, followed by a flatten layer and two dense (fully connected) layers. It was used to extract local patterns and short-term dependencies from the smoothed case data. CNN performed best overall across countries like Brazil and Russia, due to its strength in feature extraction even with limited or non-seasonal data. It was particularly effective at forecasting the timing and scale of upcoming COVID-19 waves.",Convolutional Neural Network (CNN),,,,,,,,,
,,,,,,,,,,,,,,"This model extends CNN to multivariate time series forecasting by incorporating multiple correlated features specifically, daily confirmed cases and daily deaths. This architecture used the same CNN structure but was trained on two input variables simultaneously to improve prediction accuracy. The Multivariate CNN demonstrated strong performance, closely rivaling the univariate CNN, and was shown for the first time in this study to be effective in COVID-19 forecasting.",Multivariate Convolutional Neural Network (Multivariate CNN),,,,,,,,,
15,"Paul, A.; Bhattacharjee, J. K.; Pal, A.; Chakraborty, S.",2021,"DESY, Notkestraße 85, D-22607 Hamburg, Germany",Emergence of universality in the transmission dynamics of COVID-19,MedRxiv,General Virology,"['COVID-19', 'Influenza', 'RSV', 'SARS-CoV-2']",10.1101/2021.01.29.21250750,Research,"To uncover universal patterns in the transmission dynamics of COVID-19 that transcend geopolitical, demographic, and policy differences by using scaling principles and data collapse, and to leverage these insights for improved forecasting and policy-making through both analytical (model-dependent) and data-driven (model-agnostic) methods.",Developing a model that can accurately predict the spread of infectious diseases,To construct a model-agnostic predictive framework using a deep neural network (DNN) that can learn from phase-1 COVID-19 case data and generalize to future phases. ,"The study uses a model-agnostic, data-driven forecasting approach to capture the universal dynamics in the spread of COVID-19. It trains a deep neural network (DNN) to learn the rescaled progression of infection cases from phase-1 data across multiple regions. This allows the model to generalize the disease progression without incorporating specific epidemiological parameters or region-specific assumptions. The methodology complements a mechanistic model (Blue Sky Model) and enables robust prediction of future case numbers once the peak of infections is reached in a given region.","The AI method employed in this study is a model-agnostic deep learning approach using a deep neural network (DNN) to capture universal transmission patterns in COVID-19 spread. The DNN is designed with three hidden layers, each containing 16 neurons, and uses sigmoid activation functions to model smooth, nonlinear dynamics similar to logistic growth. It is trained on rescaled phase-1 infection data where the time variable and case counts are normalized allowing it to generalize across regions regardless of population size or policy measures. The network is optimized using the Adam optimizer with a learning rate of 0.01 and mean squared error (MSE) as the loss function. To prevent overfitting, early stopping based on validation loss is applied, with a validation split of 20%. Once trained, the DNN can predict future case trajectories based on a single estimated parameter (t?/?) from the current phase of infection, enabling robust, data-driven forecasting without explicit epidemiological modeling. The method was implemented in TensorFlow and demonstrated strong agreement with predictions made by the Blue Sky Model, validating its effectiveness.",Deep Neural Network-based Universality Fit ,https://github.com/talismanbrandi/Universality-COVID-19.,MIT License, forecasting the transmission dynamics of COVID-19,COVID-19 case count data,Paul et.al,Yes,"The study measured the accuracy and reliability of forecasting COVID-19 case trajectories using both the Blue Sky Model (BSM) and a Deep Neural Network (DNN). Performance was assessed by comparing predicted infection curves against actual case data from multiple regions, focusing on how well the models captured the dynamics of Type I and Type II transmission. The primary evaluation involved visual fit, prediction error bands derived from uncertainties in peak timing and scaling parameters, and validation loss (mean squared error) during DNN training. While the study uses MSE during training, it does  not report standard machine learning metrics like precision, recall, F1-score, or R² explicitly.",,
16,"Yuan, Y.; Jahani, E.; Zhao, S.; Ahn, Y.-Y.; Pentland, A. S.",2022,"Krannert School of Management, Purdue University",Mobility network reveals the impact of spatial vaccination heterogeneity on COVID-19,MedRxiv,General Virology,['COVID-19'],10.1101/2021.10.26.21265488,Research,Developing a novel AI-based approach to optimize COVID-19 vaccine distribution by targeting high-risk areas and individuals.,Optimizing COVID-19 vaccine distribution to maximize coverage and minimize waste.,"To apply Bayesian deep learning and mobility-informed epidemic simulations to infer fine-grained (CBG-level) vaccination rates, model disease transmission under multiple spatial scenarios, and optimize a vaccination targeting policy using projected gradient descent on a differentiable surrogate function that accounts for both network structure and population susceptibility.","The study uses a Bayesian deep learning model to infer fine-grained vaccination rates at the Census Block Group (CBG) level from county-level data and applies these estimates in high-resolution epidemic simulations on mobility networks. A differentiable optimization algorithm is then applied to identify the most impactful CBGs to target for increased vaccination, based on network dynamics.","The AI method used in this study integrates Bayesian deep learning, fine-grained epidemic simulation, and constrained optimization to model and improve spatial vaccination strategies. First, a Bayesian neural network is employed to infer high-resolution vaccination rates at the Census Block Group (CBG) level from aggregated county-level data using demographic, geographic, and socioeconomic features. The model uses ReLU-activated layers with Gaussian priors and applies variational dropout and model ensembling to improve inference accuracy, validated against available zip code-level data. These CBG-level vaccination estimates are then used in a mobility-informed SEIR-based epidemic simulation that captures real-world human movement patterns through 2019 SafeGraph mobility data. The model accounts for vaccine efficacy, reinfection, and breakthrough cases. To optimize vaccine allocation, the study formulates a constrained optimization problem that minimizes the expected number of infections by adjusting vaccination rates in a limited number of CBGs. The objective function based on the unvaccinated population and mobility-driven transmission risk is solved using projected gradient descent under constraints that limit the vaccine supply and ensure feasibility. This pipeline enables the identification of spatially critical areas for targeted vaccination, leveraging both homophily and hub effects in the mobility network.",Bayesian Deep Learning-Driven Spatial Vaccination Optimization Framework,https://github.com/yuany94/covid-vaccine,MIT License,Forecasting and mitigation of infectious disease transmission (COVID-19) based on spatial vaccination distribution,"Mobility data, Vaccination data, Census data",Yuan et.al,Yes,"Performance in this study was measured through simulated reductions in COVID-19 case counts under various hypothetical vaccination distributions and campaign strategies, using a fine-grained SEIR-based epidemic model, no standard machine learning metrics (such as accuracy, precision, recall, F1 score, or AUC) were reported in this study. The key metric being evaluated was the number of new infections over a 30-day simulation period, reflecting the effectiveness of different spatial vaccine allocation strategies. Comparisons were made between the real-world (original) vaccination distribution and several counterfactual distributions designed to isolate the effects of homophily and hub centrality. Additionally, the study assessed the performance of the proposed optimized vaccination campaign by comparing its case reduction impact against four baseline strategies (uniform, random, least vaccinated, and most central). The simulations accounted for real-world parameters such as vaccine efficacy, reinfection, and breakthrough infection, and the results were averaged across multiple runs with standard deviation error bars. Thus, the main quantity being measured was the simulated infection burden, and performance was evaluated in terms of relative case count reductions, indicating how well different strategies could suppress disease spread under constrained resources.",,
17,"Cao, L.; Liu, Q.",2022,"School of Mathematical Sciences, Fudan University",COVID-19 Modeling: A Review,MedRxiv,Emerging & Re-emerging Viruses,"['SARS-CoV-2', 'COVID-19']",10.1101/2022.08.22.22279022,Research,COVID-19 modeling research,"Understanding COVID-19 dynamics, resurgence, and mutation",Artificial Intelligence for disease modeling and analysis,Machine learning and statistical models for predicting epidemic trends and disease transmission,"Combines Q-deformed entropy-based feature selection with deep learning feature extraction and LSTM classification. The hybrid pipeline improves interpretability and predictive performance. However, it may face overfitting risks due to small dataset size.",QDE-DF (Hybrid),No,No,"Multi-class classification (COVID-19, pneumonia, healthy) from CT",Medical Images (CT images),"Hospital triage datasets (proprietary, internal), COVID-19 Prognosis datasets (patient outcomes)",Yes,70/30 train-test split. Results averaged over multiple random splits to ensure stability.,{Accuracy},"{ ""accuracy"": 91,  ""Metric Name"": ""Mentioned but not provided""}"
18,"Du, H.; Dong, E.; Badr, H. S.; Petrone, M.; Grubaugh, N.; Gardner, L. M.",2022,"Center for Systems Science and Engineering, Johns Hopkins University, Baltimore, MD 21218, USA",A Deep Learning Approach to Forecast Short-Term COVID-19 Cases and Deaths in the US,MedRxiv,Emerging & Re-emerging Viruses,['SARS-CoV-2'],10.1101/2022.08.23.22279132,Research,"The aim of this study is to develop and evaluate a robust, multi-stage deep learning framework for short-term forecasting (1–4 weeks ahead) of COVID-19 cases and deaths at the US state level",To develop a forecasting model that can accurately predict COVID-19 transmission dynamics and inform public health decision-making, design and implement a multi-stage LSTM-based deep learning model that can iteratively predict weekly COVID-19 epidemiological outcomes by incorporating multiple time-varying and static features.,"The study uses a data-driven, supervised deep learning approach based on a multi-stage forecasting framework. The methodology combines sequence modeling via recurrent neural networks with iterative prediction, enabling multi-week-ahead forecasts of COVID-19 indicators such as incident cases and deaths. The model is trained and evaluated retrospectively using ground truth data, and performance is assessed across time, geography, and outbreak phase.","The AI method proposed in this study is a multi-stage Long Short-Term Memory (LSTM) network designed for short-term COVID-19 forecasting at the state level in the US. The framework consists of two parallel branches: a main model that predicts the target epidemiological variable (weekly incident cases or deaths), and a feature model that forecasts auxiliary input features (such as growth rates and mobility metrics) required for future predictions. The model operates iteratively, where each stage predicts outcomes one week ahead using the most recent observed and previously predicted data, progressively generating forecasts up to four weeks in advance. Both models share a similar architecture with one LSTM layer followed by two fully connected layers, and use a smoothed L1 loss function for training. Input features include a rich combination of time-varying and static data sources epidemiological, behavioral (survey), mobility, climate, demographic, and genomic surveillance preprocessed and aligned at the state-week level. ",Multi-Stage LSTM Forecasting Framework,No,No,emergence and spread of new variants,Epidemiological data,Du et.al,Yes,"The performance of the proposed multi-stage LSTM model was evaluated using three key error metrics: Absolute Error (AE), Percentage Absolute Error (PAE), and Weighted Interval Score (WIS). AE measures the raw difference between predicted and actual values, while PAE normalizes this difference by actual values to assess relative prediction accuracy. WIS, a probabilistic metric, evaluates the quality of the forecast distribution by incorporating uncertainty intervals. The model was assessed retrospectively over a 52-week period across all U.S. states, with evaluations conducted for different forecast horizons (1 to 4 weeks ahead). Performance was analyzed not only over time and geographic space but also as a function of outbreak phase (growth, decline, stability). The LSTM model consistently outperformed the CDC ensemble benchmark, especially during periods of rapid case growth or decline and for longer forecast windows. Additionally, a sensitivity analysis revealed how performance varied based on the input features used, and a case study showed that incorporating SARS-CoV-2 genomic variant data further improved prediction accuracy during the Delta variant wave.",{PAE_mean},"pae_mean = {""1_week"": 22, ""2_weeks"": 32, ""3_weeks"": 44, ""4_weeks"": 57}"
19,"Sharmin, M.; Manivannan, M.; Woo, D.; Sorel, O.; Auclair, J.; Gandhi, M.; Mujawar, I.",2023,"Thermo Fisher Scientific, South San Francisco, CA, United States",Cross-sectional Ct distributions from qPCR tests can provide an early warning signal for the spread of COVID-19 in communities,MedRxiv,Respiratory Virology,"['SARS-CoV-2', 'Respiratory infectious diseases']",10.1101/2023.01.12.23284489,Research, improve COVID-19 forecasting accuracy and enable earlier detection of epidemic waves by integrating PCR cycle threshold (Ct) values into forecasting models.,Improving early identification of surges in respiratory infectious diseases,"enhance a state-of-the-art deep learning forecasting model (?-AR) by integrating Ct-derived features such as viral load trends, incidence estimates, and reproductive number (Rt) to improve short-term forecasts of COVID-19 case incidence.","The study uses a deep learning-enhanced time-series forecasting approach, combining autoregression with recurrent neural networks (RNNs). This hybrid model is trained on multiple time-dependent and time-independent features, and is further enhanced with Ct-derived features from PCR tests to improve epidemic forecasting accuracy.","The forecasting model used in this study is a modified version of the ?-AR model, originally developed by Facebook/Meta. This model combines a recurrent neural network (RNN) to handle time-dependent inputs (like symptom surveys, mobility, weather, and testing volume) with an autoregressive (AR) component that uses confirmed case counts. In this study, the model is enhanced by incorporating Ct-derived features, including measures of central tendency and dispersion from Ct distributions, and epidemic metrics such as incidence and reproduction number (Rt), obtained from a Ct-based epidemiological model. These Ct features are measured weekly and integrated into the input data to provide the model with richer, biologically grounded signals. ","Ct-?-AR an enhanced version of the ?-AR (beta-autoregressive) forecasting model, augmented with features derived from PCR Ct values.",No,No,Forecasting epidemic trends of COVID-19,routine qPCR test results,Sharmin et.al,Yes,"The performance of the enhanced forecasting model, Ct-?-AR, was measured by evaluating its ability to accurately predict COVID-19 case incidence over 7-day and 14-day forecasting horizons. Specifically, the study measured two key error metrics: root mean square error (RMSE) and mean absolute error (MAE), by comparing the predicted case counts to the actual observed incidence. These evaluations were conducted on retrospective data from October 2020 to December 2021. The aim was to assess whether integrating Ct-derived features (such as median and skewness of Ct values, and Rt estimates) improved the forecasting performance of the original ?-AR model. What was being measured was the forecasting accuracy of predicted COVID-19 case trajectories, and whether the model could provide earlier and more reliable signals of upcoming epidemic waves compared to models relying only on case counts. Statistical significance of performance improvements was tested using the Wilcoxon signed-rank test.","{'MAE' , 'RMSE'}","{""AE_7_day"": 273.4, ""AE_14_day"": 679.6, ""RMSE_7_day"": 366.3, ""RMSE_14_day"": 828.8}"
20,"Nan, L.; Xin, W.; Boqian, W.; Renjie, M.; Yunxiang, Z.; Zili, C.; Yuan, J.; Junjie, Y.; Mingda, H.; Wei, C.; Hongguang, R.",2023,"Beijing Institute of Biotechnology, State Key Laboratory of Pathogen and Biosecurity, Beijing, China",Flu-CNN: predicting host tropism of influenza A viruses via character-level convolutional networks,MedRxiv,Zoonotic Virology,['Influenza A virus'],10.1101/2023.08.28.23294703,Research,"develop an efficient and scalable computational method to predict the host tropism of Influenza A viruses (IAVs), with a focus on identifying avian viruses that may infect humans.",Identifying key amino acid substitutions that affect IAV host adaptability and predicting zoonotic risk of viral strains.,"build a deep learning model (Flu-CNN) that can directly learn from viral genome sequences without manual feature extraction, to classify whether a virus strain is adapted to humans or avians.","The study follows a supervised deep learning methodology using character-level sequence encoding of viral genome data to classify host tropism. It trains a neural network on labeled data (avian vs. human hosts) using one-hot encoded amino acid sequences and evaluates it using standard classification metrics (accuracy, precision, recall, F1-score). The approach is designed to learn directly from raw sequence data without manual feature engineering.","The model architecture is based on a character-level Convolutional Neural Network (Char-CNN), adapted specifically for genomic sequence classification. The architecture includes six convolutional layers and three fully connected layers, with ReLU activations and dropout regularization to improve generalization. The model processes one-hot encoded amino acid sequences derived from IAV genomes to classify viral strains into human or avian host categories. The training procedure uses cross-entropy loss, and the best performing model on the validation set is used for final evaluation. Beyond classification, the model is also used for identifying zoonotic strains and pinpointing amino acid mutations that may influence host adaptation.",Flu-CNN,No,No,host tropism prediction,Influenza A virus genome sequences,Nan et.al,Yes,"The performance of the proposed Flu-CNN model was rigorously evaluated using a variety of standard classification metrics, including accuracy, precision, recall, and F1-score. These metrics were calculated based on predictions made on a separate test set consisting of 16,001 viral genomes. The model was assessed on both full-genome data and individual genomic segments, demonstrating consistently high accuracy across all settings. Comparative analyses were also conducted against existing methods such as ML-(d)nts, VIDHOP, FluPhenotype, and phylogenetic approaches, with Flu-CNN outperforming them in most cases, especially on critical subtypes like H5N1, H7N9, and H9N2. In addition to traditional performance metrics, the model’s interpretability and biological relevance were also explored through dimensionality reduction (UMAP) and mutation impact analysis, validating that the model could identify meaningful features related to host adaptation. This comprehensive evaluation confirms the robustness, generalizability, and biological significance of Flu-CNN in predicting IAV host tropism.","{""accuracy"": """", ""precision"": """", ""recall"": """", ""f1_score"": """"}","{""accuracy"": 0.99, ""precision"": 0.99, ""recall"": 0.99, ""f1_score"": 0.99}"
21,"Vabalas, A.; Hartonen, T.; Vartiainen, P.; Jukarainen, S.; Viippola, E.; Rodosthenous, R.; Liu, A.; Hagg, S.; Perola, M.; Ganna, A.",2023,"Institute for Molecular Medicine Finland (FIMM), HiLIFE, University of Helsinki, Helsinki, Finland",Deep learning-based prediction of one-year mortality in the entire Finnish population is an accurate but unfair digital marker of aging,MedRxiv,Respiratory Virology,"['SARS-CoV-2', 'Respiratory infectious diseases']",10.1101/2023.09.18.23295726,Research,"The primary aim of this study is to develop a highly accurate predictive model for short-term (one-year) mortality risk at a nationwide, population-wide scale, leveraging comprehensive multimodal data, to improve healthcare resource allocation, end-of-life care, and explore potential applications as a digital aging marker.",Developing a predictive model for mortality risk based on demographic and health data.,"build and validate a Deep Learning (DL) model specifically a recurrent neural network (RNN) with gated recurrent units (GRU) that integrates extensive longitudinal health and socioeconomic data spanning several decades to achieve accurate prediction of one-year all-cause mortality, significantly surpassing simpler predictive methods based solely on age and sex.","The study applies a deep learning-based methodology that leverages comprehensive, longitudinal, multi-modal data (medical, demographic, socioeconomic) from national registers. Specifically, a recurrent neural network (RNN) architecture is employed, integrating both fixed (time-invariant) and longitudinal (time-varying) features, to predict short-term (one-year) mortality risk across an entire national population.","The methodology involves developing a recurrent neural network (RNN) using gated recurrent units (GRU), capable of effectively modeling complex temporal interactions in large-scale longitudinal data. Inputs to the RNN include longitudinal features such as disease diagnoses, medication records, healthcare interactions, and detailed socioeconomic history, alongside static demographic information. Each individual’s longitudinal health and socioeconomic records were embedded year-by-year, maintaining temporal order. These embeddings, combined with fixed features (e.g., demographics), were used to train the network, which comprised approximately 2.9 million parameters. Hyperparameters were optimized through a Tree-structured Parzen Estimator algorithm. The model’s predictive accuracy was assessed using metrics such as Area Under the Receiver Operating Characteristic Curve (AUC-ROC), Area Under the Precision-Recall Curve (AUPRC), and calibration measures. Additionally, extensive fairness evaluations were conducted to assess model performance across sensitive socio-demographic subgroups.",Recurrent Neural Network (RNN) with Gated Recurrent Units (GRU),https://github.com/dsgelab/RNN,No,predicting COVID-19 mortality,Nationwide longitudinal register data from Finland,FinRegistry,Yes,"The performance of the model was assessed through a variety of evaluation metrics that measured both the accuracy and calibration of one-year mortality predictions. These included metrics to evaluate classification performance, such as the area under the ROC and precision-recall curves, as well as time-to-event metrics like the concordance index and time-dependent AUC. The model’s calibration was also examined using calibration curves and stratified survival analysis through Kaplan-Meier plots. What was being measured was the model's ability to accurately predict the likelihood of all-cause mortality within a one-year horizon, identify high-risk individuals, generalize across different causes of death including novel ones like COVID-19 and maintain fairness across demographic and socioeconomic subgroups. The evaluation also explored how predictive performance varied across subgroups defined by age, sex, income, geographic location, and other protected characteristics.","{'AUC_ROC', 'AUPRC', 'C_index', 'high_risk_group', 'COVID19_AUC', 'fairness_example'}","{""AUC_ROC"": {""RNN_model"": 0.944, ""baseline_model"": 0.897}, ""AUPRC"": {""RNN_model"": 0.223, ""baseline_model"": 0.119}, ""C_index"": {""RNN_model"": 0.942}, ""high_risk_group"": {""RNN_deaths_predicted_percentage"": 69.5, ""population_percentage"": 5.0}, ""COVID19_AUC"": {""RNN_model"": 0.956}, ""fairness_example"": {""low_pension_AUC"": 0.824, ""high_pension_AUC"": 0.874}}"
22,"Song, T.-H.; Clemente, L.; Pan, X.; Jang, J.; Santillana, M.; Lee, K.",2024,"Department of Bioinformatics & Biostatistics, University of Louisville, KY, USA.",Fine-Grained Forecasting of COVID-19 Trends at the County Level in the United States,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2024.01.13.24301248,Research,"The primary aim of this research is to enhance the accuracy of COVID-19 infection forecasting, particularly at fine-grained geographic levels (county, state, and national), to facilitate efficient public health management and timely implementation of COVID-19 prevention and control measures.","The core research problem addressed is the inherent difficulty of accurately forecasting COVID-19 infection trends due to their highly dynamic, transient, and noise-prone nature, compounded by factors such as local heterogeneity, rapid mutations, fluctuating intervention policies, and diverse vaccination rates.","The AI objective of this study is the development and deployment of the Fine-Grained Infection Forecast Network (FIGI-Net), a deep learning model based on stacked bidirectional Long Short-Term Memory (biLSTM) networks. ","The study employs a deep learning-based time-series forecasting methodology that utilizes fine-grained (county-level) infection data and integrates temporal clustering, transfer learning, and bidirectional sequence modeling to enhance the precision of short-term COVID-19 infection forecasts.","The Fine-Grained Infection Forecast Network (FIGI-Net) methodology involves a deep learning pipeline tailored for short-term forecasting of COVID-19 infections at fine-grained (county-level) resolution. Initially, the data are smoothed using a 7-day moving average to reduce noise. Then, temporal clustering is conducted by extracting autocorrelation and cross-correlation features from county-level time-series data, followed by dimensionality reduction through UMAP. Subsequently, a two-stage clustering process employing DBSCAN and spectral clustering identifies similar local infection dynamics, resulting in eight distinct county clusters. The core forecasting model employs a stacked bidirectional Long Short-Term Memory (biLSTM) neural network to effectively capture temporal dependencies and manage abrupt shifts in infection trends. Additionally, a transfer learning approach is adopted wherein a global biLSTM model is first trained on comprehensive national data, and its learned parameters are then fine-tuned on cluster-specific sub-models.",Fine-Grained Infection Forecast Network (FIGI-Net),No,No,forecasting of COVID-19 infection cases,county-level daily COVID-19 infection and death data,Song et.al,Yes,"The study measured the accuracy and effectiveness of short-term forecasts (from 1 day to up to 14 days ahead) of COVID-19 infection numbers at county, state, and national levels. Performance was evaluated using quantitative metrics such as Root Mean Square Error (RMSE), Relative RMSE (RRMSE), Mean Absolute Percentage Error (MAPE), and slope similarity. RMSE and RRMSE quantified the absolute and relative prediction error magnitudes, respectively, while MAPE provided an error measure expressed as a percentage. Additionally, slope similarity assessed the model’s capability to accurately forecast the trend direction of COVID-19 infections, particularly during critical periods of rapid growth or sudden changes. Statistical significance between model performances was further verified using a two-sided Wilcoxon rank sum test.","{'RMSE', 'RRMSE'}","{""county_level"": {""RMSE_reduction"": {""1_day"": 0.87, ""7_day"": 0.50, ""14_day"": 0.42}, ""median_RRMSE"": {""1_day"": 13.97, ""7_day"": 36.11}}, ""state_level"": {""RMSE"": {""7_day"": [1408.25, 1544.87], ""14_day"": [2292.83, 2924.04]}, ""RMSE_reduction"": {""7_day"": 0.5601, ""14_day"": 0.4115}}, ""national_level_RRMSE_reduction"": {""1_day"": 0.8648, ""7_day"": 0.6098, ""14_day"": 0.538}}"
23,"Jarynowski, A.; Semenov, A.; Kaminski, M.; Belik, V.",2021,"System Modeling Group, Institute of Veterinary Epidemiology and Biostatistics, Freie Universität Berlin, Berlin, Germany",Mild Adverse Events of Sputnik V Vaccine Extracted from Russian Language Telegram Posts via BERT Deep Learning Model,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2021.06.14.21258875,Research,"To enhance transparency and understanding of the mild adverse events (AEs) associated with the Sputnik V COVID-19 vaccine by analyzing self-reported symptoms collected from a Russian-language Telegram group, and comparing them with clinical trial data and official post-marketing surveillance databases.",The study aimed to increase transparency regarding the safety and efficacy of Sputnik V by analyzing reports from a Telegram group.,"To apply natural language processing (NLP) techniques, specifically multi-label classification using a fine-tuned BERT model, to extract and classify self-reported adverse events from Telegram messages, enabling automated analysis of user-generated health data.","The study used a supervised natural language processing pipeline for multi-label text classification. The process involved labeling adverse event entities in Telegram messages and training a machine learning model to predict multiple symptoms per message. The methodology combined manual annotation, preprocessing (sentence splitting, entity extraction), and the use of transformer-based deep learning models tailored for the Russian language.","The researchers manually annotated 1,000 Telegram messages using LabelStudio, creating a dataset of over 4,500 labeled adverse event (AE) entities. They then framed the task as a multi-label classification problem, where each message could be associated with multiple AEs. For modeling, they fine-tuned a pre-trained Russian-language BERT model from DeepPavlov with a final layer of 12 sigmoid neurons (one per AE class), using binary cross-entropy as the loss function. They trained the model using stratified 5-fold cross-validation and applied class upsampling to address label imbalance. ",Russian BERT (DeepPavlov) – Multi-label Classification for AE Detection, https://github.com/ai-forever/AEROS,Apache License 2.0,vaccine safety monitoring,self-reported adverse event (AE) messages,Jarynowski et.al,Yes,"Performance was measured by evaluating the model’s ability to accurately detect multiple adverse events (AEs) from Telegram messages using standard multi-label classification metrics, including micro/macro precision, recall, F1-score, and AUC. The BERT model was trained using 5-fold cross-validation with class upsampling and achieved strong results, with an AUC of 0.991, demonstrating high effectiveness in identifying symptom categories from user-reported vaccine reactions.","{""micro_accuracy"" , ""auc""}","{""micro_accuracy"": 0.94, ""auc"": 0.991}"
24,"Wright, L.; Paul, E.; Steptoe, A.; Fancourt, D.",2021,"Institute of Education, University College London","Facilitators and Barriers to Compliance with COVID-19 Guidelines: A Structural Topic Modelling Analysis of Free-Text Data from 17,500 UK Adults",MedRxiv,Emerging & Re-emerging Viruses,['SARS-CoV-2'],10.1101/2021.06.28.21259621,Research,"To identify and understand the key facilitators and barriers influencing citizens’ compliance with COVID-19 guidelines in the UK, using large-scale qualitative data to uncover behavioral insights that can inform public health policy.","Traditional compliance studies rely heavily on structured quantitative data, which limits the discovery of unanticipated factors influencing behavior. ","To apply Structural Topic Modeling (STM) to analyze over 26,000 free-text responses, enabling the extraction of latent themes related to compliance behavior and linking these topics to participant characteristics for deeper behavioral insights.","The study employed an unsupervised machine learning approach to analyze large-scale qualitative data. Specifically, it used a probabilistic topic modeling technique to uncover latent thematic structures in unstructured free-text survey responses. The method allows researchers to model documents as mixtures of topics, where each topic is a distribution over words, enabling scalable qualitative analysis across thousands of responses.","The method used was Structural Topic Modeling (STM), implemented in R using the stm package. STM enhances traditional topic modeling by allowing metadata (such as age, gender, education, personality traits, and confidence in government) to inform the model. This enables the model to not only extract topics but also examine how topic prevalence varies with respondent characteristics. Data preprocessing steps included tokenization, stemming, spell-checking, stop-word removal, and response filtering. The number of topics was selected based on semantic coherence and exclusivity metrics, supported by manual inspection of representative documents.",Structural Topic Modeling (STM),https://osf.io/nf4m9/,No,behavioral compliance with public health guideline,free-text survey responses,Wright et.al,Yes,"Performance was measured by evaluating the coherence and exclusivity of topics generated via Structural Topic Modelling (STM), along with regression analyses linking topics to participant traits. No standard ML metrics like accuracy or F1-score were used, as the focus was on interpretability and thematic relevance, not classification.",,
25,"Wright, L.; Fluharty, M. E.; Steptoe, A.; Fancourt, D.",2022,"Institute of Education, University College London","How did people cope during the COVID-19 pandemic? A Structural Topic Modelling Analysis of Free-Text Data from 11,000 UK Adults",MedRxiv,General Virology,"['SARS-CoV-2', 'Respiratory infectious diseases']",10.1101/2021.08.13.21262002,Research,"To identify and analyze the coping strategies employed by UK adults during the COVID-19 pandemic using large-scale free-text responses, and to explore how these strategies vary across demographic, socioeconomic, personality, and health-related factors, as well as their association with individuals’ lockdown experiences.",The study aimed to investigate the relationship between social media use and mental health outcomes in young adults.,"To apply Structural Topic Modelling (STM) a text mining and unsupervised machine learning method to extract latent themes (coping strategies) from large-scale open-ended text responses, and quantitatively relate these topics to participant metadata such as demographics, personality traits, and lockdown experiences.","The study uses an unsupervised machine learning approach for natural language processing, specifically probabilistic topic modeling through Structural Topic Modelling (STM). Unlike traditional models such as LDA, STM allows integration of structured metadata (e.g., demographics, personality traits) into the modeling process, enabling researchers to analyze how the distribution of discovered topics varies across participant subgroups. This approach is particularly suitable for large-scale text mining in social science and behavioral research, where open-ended responses need to be explored both qualitatively and quantitatively.","The STM model was applied to free-text responses from over 11,000 participants in the UK COVID-19 Social Study. Text was preprocessed by removing stopwords, correcting spelling errors, and applying stemming using the Porter algorithm. The stm R package was used to train topic models across a range of 2 to 30 topics, with 16 topics selected based on semantic coherence, exclusivity, and manual review of exemplar texts. Participant-level covariates such as age, gender, education, health status, and Big-5 personality traits were incorporated into the STM to model topic prevalence. Post-modeling regression analysis was then conducted to assess how different coping strategies were associated with personal characteristics and lockdown experiences.",Structural Topic Modelling (STM) using the stm R package.,https://osf.io/xqu8h/,No,Psychosocial coping during the COVID-19 pandemic,weekly and monthly survey data on the psychological and social experiences of adults during the COVID-19 pandemic,Wright et.al,Yes,"No standard ML performance metrics (e.g., accuracy, F1-score) were measured.  Instead, the evaluation focused on the quality of the topic modeling output. The researchers assessed how well the Structural Topic Model (STM) captured meaningful themes from the text by using semantic coherence (how often top words in a topic appear together), exclusivity (how distinct the top words of each topic are from other topics), and qualitative review of exemplar texts. Additionally, the study measured how well the topics aligned with participant characteristics and lockdown experiences by running regression analyses. Thus, what was being measured was the interpretability, distinctiveness, and relevance of the extracted coping strategy topics and how their usage varied across demographic, psychological, and contextual factors.",,
26,"Perlman-Arrow, S.; Loo, N.; Bobrovitz, N.; Yan, T.; Arora, R. K.",2022,"School of Population and Global Health, McGill University, QC, Canada",A real-world evaluation of the implementation of NLP technology in abstract screening of a systematic review,MedRxiv,General Virology,['COVID-19'],10.1101/2022.02.24.22268947,Research,"To evaluate the real-world effectiveness, feasibility, and user acceptance of an NLP-assisted abstract screening tool in the context of a living systematic review on global SARS-CoV-2 seroprevalence, with the goal of improving screening efficiency without compromising accuracy.",The rapid spread of COVID-19 has created a significant challenge for researchers to analyze and summarize large volumes of scientific literature. This study aims to address this problem by developing an NLP tool that can efficiently extract relevant information from scientific articles.,"To develop and apply a PubMedBERT-based NLP tool that assists abstract screening by providing inclusion recommendations and key information highlights, aiming to reduce screening time while maintaining accuracy.","The study uses a transformer-based natural language processing (NLP) approach, specifically leveraging fine-tuned models for classification and information highlighting to support abstract screening in a living systematic review.","The core of the NLP tool is based on PubMedBERT, a transformer model pre-trained on biomedical literature. It was fine-tuned on 25,000 previously screened abstracts from the SeroTracker review to provide inclusion recommendations for new abstracts. The tool classifies abstracts into inclusion likelihood categories (e.g., “strongly recommended”), and highlights Population, Intervention, and Outcome (PIO) elements using another fine-tuned version of PubMedBERT trained on the EBM-NLP dataset. Additional UI features such as keyword highlighting, vote tracking, and undo functionality were added to improve usability. The tool was tested in both standard dual-reviewer settings and a one-person-one-tool (OPOT) setup, showing improved efficiency without compromising accuracy.",Fine-tuned PubMedBERT for abstract classification and PIO highlighting.,"https://github.com/yolky/Serotracker-NLP-Tool-Analysis, https://github.com/serotracker/Serotracker-NLP-Training-and-Inference",No,Seroprevalence Evidence Screening,Previously screened abstracts from the SeroTracker living systematic review,SeroTracker abstract dataset,Yes,"performance was measured in the study using both efficiency and accuracy metrics. Efficiency was evaluated by measuring the screening time per abstract and the conflict rate between reviewers. Accuracy was assessed using precision, recall, and F1-score to determine how well the tool maintained the quality of article inclusion decisions. The study also examined performance in different reviewer-tool combinations, such as a one-human-one-tool setup, to evaluate the tool’s effectiveness in supporting or partially replacing human reviewers during the screening process.","{""efficiency"": {""screening_time_reduction_percent"", ""conflict_rate_without_tool"", ""conflict_rate_with_tool""}, ""accuracy"": {""precision_without_tool"", ""precision_with_tool"", ""recall_without_tool"", ""recall_with_tool"", ""f1_score_tool_recommendation"", ""precision_tool_recommendation"", ""recall_tool_recommendation""}, ""one_person_one_tool"": {""precision"", ""recall"", ""estimated_time_saving_percent""}}","{""efficiency"": {""screening_time_reduction_percent"": 45.9, ""conflict_rate_without_tool"": 8.32, ""conflict_rate_with_tool"": 3.64}, ""accuracy"": {""precision_without_tool"": 0.88, ""precision_with_tool"": 0.92, ""recall_without_tool"": 0.81, ""recall_with_tool"": 0.90, ""f1_score_tool_recommendation"": 0.905, ""precision_tool_recommendation"": 0.827, ""recall_tool_recommendation"": 1.0}, ""one_person_one_tool"": {""precision"": 0.91, ""recall"": 0.92, ""estimated_time_saving_percent"": 70.7}}"
27,"Weissenbacher, D.; O'connor, K.; Klein, A.; Golder, S.; Flores Amaro, I.; Elyaderani, A.; Scotch, M.; Gonzalez-Hernandez, G.",2023,"Cedars-Sinai Medical Center, Los Angeles, CA, USA",Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2023.07.29.23293370,Research,"To develop a semi-automated NLP pipeline that can identify scientific publications reporting newly sequenced SARS-CoV-2 genomes and extract corresponding patient metadata, in order to enrich public sequence repositories and enable large-scale genomic epidemiology studies.","Public SARS-CoV-2 sequence records often lack critical metadata such as demographics, clinical outcomes, and geographic information, which are essential for genomic epidemiology. Although this information is sometimes available in the associated scientific articles, it is difficult to retrieve using manual methods or simple keyword searches due to its sparse, varied, and context-dependent nature.",To train machine learning models that can automatically identify relevant articles and extract detailed patient metadata from full-text scientific literature to enrich SARS-CoV-2 sequence databases.,"The study uses a multi-stage NLP pipeline that combines rule-based filtering, supervised machine learning (SVM and BERT), and relation extraction, enhanced through active learning. The approach is designed to process full-text scientific articles and extract relevant metadata with minimal human intervention.","The study employs a multi-step NLP approach that begins with a keyword-based filtering module to select candidate articles, followed by a fine-tuned BERT-base-uncased transformer model to classify sentences that mention viral genome sequencing. To address extreme class imbalance, the training set was refined using sentence embeddings from SentenceTransformers to undersample dissimilar negative examples. For metadata extraction, a relation extraction module is being developed that uses active learning to iteratively refine annotations and extract patient-specific information such as age, gender, comorbidities, and clinical outcomes. This setup allows for accurate identification of relevant literature and semi-automated extraction of granular metadata for enriching sequence databases.",Fine-tuned BERT transformer classifier with active learning-based relation extraction.,No,No,linking of SARS-CoV-2 genome sequences to patient-level metadata,COVID-19-related scientific articles,LitCovid full-text collection,Yes,"Performance was measured using standard classification metrics precision, recall, and F1-score focused on the positive class: sentences that mention viral genome sequencing. These metrics were used to evaluate both sentence-level and article-level classification. At the sentence level, the goal was to correctly identify individual sentences reporting SARS-CoV-2 genome sequencing. At the article level, the aim was to determine whether a given article contained at least one such sentence. The study compared a baseline SVM model with a fine-tuned BERT classifier and found that the BERT model outperformed the SVM, achieving a higher F1-score. Additionally, the researchers assessed the recall of the classifier using an external gold standard of PubMed articles linked to SARS-CoV-2 sequence accessions in GenBank, confirming that the classifier could identify relevant articles beyond those found through keyword searches. Thus, the evaluation focused on the system’s ability to accurately retrieve relevant scientific publications and extract sequencing-related content within them.","{'f1-score', 'Precision', 'Recall'}","{""sentence_level"": {""svm"": {""f1_score"": 0.370, ""precision"": 0.329, ""recall"": 0.422}, ""bert"": {""f1_score"": 0.480, ""precision"": 0.492, ""recall"": 0.469}, ""bert_undersampled"": {""f1_score"": 0.453}}, ""article_level"": {""bert"": {""f1_score"": 0.800, ""precision"": 0.667, ""recall"": 1.000}}, ""external_gold_standard_recall"": 0.800}"
28,"Klein, A. Z.; Kunatharaju, S.; Golder, S.; Levine, L. D.; Figueiredo, J. C.; Gonzalez-Hernandez, G.",2023,"Department of Biostatistics, Epidemiology, and Informatics, University of Pennsylvania, Philadelphia, PA, USA",Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data,MedRxiv,Respiratory Virology,['SARS-CoV-2'],10.1101/2023.11.17.23298696,Research,Assess the association between the trimester of COVID-19 infection and preterm birth.,To investigate whether COVID-19 infection during pregnancy affects the risk of preterm birth.,"To automatically identify and extract self-reported pregnancy timelines, COVID-19 infections, birth outcomes, and maternal age from Twitter posts using natural language processing (NLP) and machine learning techniques, enabling trimester-level analysis of COVID-19’s impact on preterm birth risk.","The study employed a multi-stage NLP and machine learning pipeline to mine and process user-generated social media data. First, automated tools were used to detect tweets indicating pregnancy, due dates, and gestational age. Then, a deep learning classifier identified tweets reporting COVID-19 infections, and rule-based regular expressions were applied to detect birth outcomes. Another NLP tool extracted maternal age. Manual validation was used at key steps to ensure precision. This methodology allowed the researchers to build a temporally aligned dataset capturing trimester-specific exposures and outcomes from unstructured tweet streams.","The study employed a multi-component natural language processing (NLP) and machine learning pipeline to extract structured clinical insights from unstructured Twitter data. First, the tool Pregex was used to detect tweets reporting pregnancy status, gestational age, and due dates, enabling the reconstruction of pregnancy timelines. To identify COVID-19 infection during pregnancy, a deep neural network classifier was trained to recognize tweets indicating confirmed infection through positive tests, clinical diagnoses, or hospitalizations. The trimester of infection was then manually verified using temporal language cues. To detect birth outcomes, regular expressions were applied to find tweets reporting preterm or term births, supplemented by manual inspection for ambiguous cases. Additionally, ReportAGE, an NLP pipeline, was used to extract maternal age from self-reported tweets. These AI components were integrated to construct a retrospective cohort dataset of Twitter users, allowing for trimester-specific analysis of COVID-19 exposure and preterm birth outcomes.",Integrated NLP Pipeline for Social Media-Based Pregnancy Timeline Reconstruction and COVID-19 Outcome Detection (Pregex + DNN Classifier + ReportAGE),No,No,evaluating the association between COVID-19 infection during pregnancy (by trimester) and the risk of preterm birth,publicly available Twitter timelines,Klein et.al,Yes,"In this study, performance was primarily evaluated through manual validation. The main focus was on the correct identification of key events from unstructured Twitter data: pregnancy timelines, COVID-19 infections (including timing by trimester), birth outcomes (preterm or term), and maternal age. Each component of the NLP and machine learning pipeline such as the Pregex tool for pregnancy detection, the deep neural network classifier for COVID-19 diagnosis identification, and the ReportAGE tool for age extraction was followed by manual review to ensure precision and filter out false positives. What was being measured was the accuracy and reliability of the automated extraction process in building a valid retrospective cohort. Additionally, the ultimate goal assessing the association between trimester-specific COVID-19 infection and preterm birth was evaluated using odds ratios (OR) with 95% confidence intervals, comparing infection groups with a control group to determine statistical significance of observed outcomes.", does not include any explicit numerical values for performance metrics,
29,"Dandekar, R.; Barbastathis, G.",2020,"Department of Civil and Environmental Engineering, Massachusetts Institute of Technology,Cambridge, MA 02139, USA,",Quantifying the effect of quarantine control in Covid-19 infectious spread using machine learning,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.04.03.20052084,Research,"The aim of this study is to augment traditional epidemiological models (like SIR) with a neural network-based quarantine modeling component to forecast COVID-19 infection trends and evaluate the impact of quarantine measures in multiple countries, including the USA, Italy, South Korea, and Wuhan","Conventional epidemiological models like SIR/SEIR fail to accurately forecast the dynamics of COVID-19 outbreaks because they do not account for dynamic quarantine effects, non-homogeneous mixing, under-reporting, and noisy real-world data.","To develop a hybrid neural network-augmented SIR model that can learn the time-varying quarantine strength function (Q(t)) from COVID-19 case data and improve prediction accuracy for infection counts and reproduction number Rt, in a way that reflects real-time policy impacts.","The study integrates a neural network into the traditional SIR (Susceptible-Infected-Recovered) epidemiological model to dynamically account for the impact of quarantine and social distancing measures on COVID-19 spread. Unlike standard SIR models that assume constant parameters and homogeneous population mixing, this hybrid approach introduces a time-varying quarantine strength function Q(t), which is not derived from epidemiological theory but learned directly from real-world data. The neural network acts as a nonlinear function approximator that learns how quarantine policies evolve over time in a given region and how they influence the effective reproduction number Rt. This methodology allows the model to adapt to region-specific responses to the pandemic, enabling it to better forecast infection trajectories and evaluate the effectiveness of public health interventions.","The neural network used in the model is a fully connected feedforward network with two layers: one hidden layer consisting of 10 ReLU-activated units, and an output layer that predicts the quarantine strength Q(t). The network takes as input the current values of the SIR compartments susceptible S(t), infected I(t), recovered R(t)along with the quarantined population T(t). The model is trained by minimizing the mean squared error between the logarithm of the predicted infection and recovery curves and the actual data, using the ADAM optimizer for 300 to 500 iterations. To avoid overfitting, training is halted when the loss function plateaus and the derivatives of the predicted curves closely match those of the observed data. The model is calibrated separately for each region (Wuhan, Italy, South Korea, USA) using public datasets such as those from the Chinese National Health Commission and the Johns Hopkins University CSSE COVID-19 database. This neural network-augmented SIR system allows for regional customization and interpretable epidemic forecasting.",Neural Network-Augmented SIR Model (NN-SIR),No,No,forecasting and evaluation of COVID-19 transmission dynamics,"case counts of infected and recovered COVID-19 patients across four regions: Wuhan, Italy, South Korea, and the USA",Dandekar et.al,Yes,"The model's performance was evaluated by comparing the predicted infection and recovery curves against actual reported data. The main performance metric used was the mean squared error (MSE) between the log-transformed predicted values and the log-transformed observed case counts. Additionally, visual agreement between model forecasts and real-world epidemic trends (e.g., stagnation of infections, drop in Rt <1) was used as a qualitative validation. For parameter optimization, the ADAM optimizer was used to minimize this loss function during training.", does not include any explicit numerical values for performance metrics,
30,"Batista, A. F. D. M.; Miraglia, J. L.; Donato, T. H. R.; Chiavegatto Filho, A. D. P.",2020,"Department of Epidemiology, School of Public Health, University of Sao Paulo, 715 Av Dr Arnaldo, Sao Paulo, SP, Brazil 01246-904",COVID-19 diagnosis prediction in emergency care patients: a machine learning approach,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.04.04.20052092,Research,"The aim of this study is to develop a machine learning-based approach to predict the likelihood of a positive COVID-19 diagnosis using only routinely collected emergency care admission exam results, particularly to support testing decisions in resource-constrained healthcare settings.","In many developing countries, there is a shortage of reliable COVID-19 diagnostic tests (RT-PCR), leading to delays in diagnosis, inefficient resource allocation, and higher risks of disease transmission.","The AI objective is to train and evaluate multiple machine learning models including support vector machines, random forests, neural networks, logistic regression, and gradient boosting trees to accurately predict the risk of COVID-19 positivity based solely on standard blood test features collected at emergency admission, and to identify the most informative features for classification.",The study followed a supervised machine learning methodology using a 70-30 train-test split and 10-fold cross-validation with Bayesian hyperparameter optimization. Multiple classification algorithms were trained to predict COVID-19 test outcomes using emergency admission lab features. Model performance was evaluated on an unseen test set using standard metrics.,"The model was trained on data from 235 adult emergency room patients, using 15 routinely collected blood test features such as leukocyte, lymphocyte, and eosinophil counts. Prior to training, all numerical features were normalized, and the dataset was split into a 70% training set and a 30% testing set. To optimize model parameters, 10-fold cross-validation was performed using the Hyperopt library with Bayesian optimization. Multiple machine learning algorithms were evaluated, including support vector machines (SVM), random forests, neural networks, gradient boosting trees, and logistic regression. Feature importance was evaluated using the Mean Decrease Accuracy method.",Neural Networks,No,No,COVID-19 diagnosis prediction,routine blood count exams and corresponding RT-PCR COVID-19 test results,Batista et.al,Yes,"Among the five evaluated machine learning models, Support Vector Machines (SVM) demonstrated the strongest predictive performance. On the test set, it achieved excellent discrimination and calibration, with an AUC of 0.85 and a Brier score of 0.16. Sensitivity and specificity were balanced at 0.68 and 0.85, respectively. Positive and negative predictive values across all models exceeded 0.74 and 0.77. Furthermore, when tested with repeated 10-fold cross-validation, SVM yielded an even higher AUC of 0.87, confirming its robustness and generalization capability."," {""AUC_test"", ""Sensitivity_test"", ""Specificity_test"", ""Brier_score_test"", ""PPV_min"", ""NPV_min"", ""AUC_crossval""}","{""AUC_test"": 0.85, ""Sensitivity_test"": 0.68, ""Specificity_test"": 0.85, ""Brier_score_test"": 0.16, ""PPV_min"": 0.74, ""NPV_min"": 0.77, ""AUC_crossval"": 0.87}"
31,"Uhlig, S.; Nichani, K.; Uhlig, C.; Simon, K.",2020,"QuoData GmbH, Fabeckstr. 43, Berlin, Germany","Modeling projections for COVID-19 pandemic by combining epidemiological, statistical, and neural network approaches",MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.04.17.20059535,Research,"To develop an empirical top-down modeling framework that integrates neural network-derived indicators into statistical parametric models for providing robust, region-specific short- and medium-term forecasts of COVID-19 infection dynamics, along with quantifiable uncertainty estimates.","Traditional compartmental epidemiological models (e.g., SIR/SEIR) struggle to produce reliable forecasts during pandemics due to noisy, incomplete, and regionally inconsistent surveillance data.","To use neural networks to automatically identify high-quality early warning indicators (EWIs) from noisy COVID-19 time-series data, which can be used both to assess current outbreak dynamics and as covariates in statistical models to produce accurate and timely outbreak forecasts.","The study employs a hybrid top-down approach that combines neural network-based feature selection with parametric statistical modeling. Neural networks are used to derive early warning indicators (EWIs) from noisy epidemiological time-series data (e.g., daily confirmed cases, deaths). These EWIs are then used as covariates in statistical models to forecast the short- and medium-term trajectory of the epidemic with uncertainty estimation.","The proposed AI method uses artificial neural networks to analyze multivariate time-series data of daily COVID-19 confirmed cases and deaths across multiple regions. The neural networks are trained to identify patterns and derive early warning indicators (EWIs) that reflect the current epidemic dynamics such as acceleration or deceleration in transmission. These EWIs serve dual purposes: first, as real-time metrics to assess the epidemic's progression and the effectiveness of containment measures; second, as explanatory features in downstream statistical models that generate forecasts and quantify uncertainty. The neural networks help in automated feature extraction and selection, while the resulting indicators are fed into parametric forecasting models to improve predictive accuracy, even in the presence of data noise and reporting inconsistencies",Neural Network-based Early Warning Indicator Extraction,No,No,short-term epidemic forecasting and early outbreak detection,COVID-19 time-series data,CSSE COVID-19 time-series data,Yes,"The model’s performance was evaluated by comparing its predictions to actual reported COVID-19 case numbers over short-term horizons of 7 to 10 days, particularly for Germany and the USA. The study highlights the robustness of the empirical top-down modeling approach, especially in handling noisy or inconsistently reported surveillance data. To enhance the interpretability and reliability of forecasts, the model incorporated uncertainty intervals and leveraged early warning indicators (EWIs) to detect and validate critical transitions in epidemic phases. While the effectiveness of the approach was qualitatively demonstrated, the study did not report standard quantitative metrics such as RMSE or MAPE.",,
32,"Kolozsvari, L. R.; Berczes, T.; Hajdu, A.; Gesztelyi, R.; Tiba, A.; Varga, I.; Al-Tammemi, A. B.; Szollosi, G. J.; Harsanyi, S.; Garboczy, S.; Zsuga, J.",2021,"Department of Family and Occupational Medicine, Faculty of Medicine, University of Debrecen, Debrecen, Hungary",Predicting the epidemic curve of the coronavirus (SARS-CoV-2) disease (COVID-19) using artificial intelligence,MedRxiv,Emerging & Re-emerging Viruses,['SARS-CoV-2'],10.1101/2020.04.17.20069666,Research,forecast the epidemic curve of daily new COVID-19 infections using AI-based Recurrent Neural Networks (RNNs) and validate these predictions against real-world data from multiple countries.,"Due to the progressive and uncertain nature of the COVID-19 pandemic, traditional forecasting models often fail to account for multiple waves and human-to-human transmission dynamics.",develop and implement two prediction models using RNNs with Long Short-Term Memory (LSTM) units that could learn from country-level time series data and forecast daily new COVID-19 cases. ,"The study used a supervised learning approach with time-series modeling based on Recurrent Neural Networks (RNNs), specifically using Long Short-Term Memory (LSTM) units. The task was framed as a sequence prediction problem where daily new COVID-19 cases were forecasted using prior time-step data. Two prediction strategies were implemented: one with incremental retraining (transfer learning style), and another using a static pre-trained model.","The study employed a Recurrent Neural Network (RNN) architecture using Long Short-Term Memory (LSTM) units to forecast daily new COVID-19 cases. The model was structured in an encoder-decoder format, where the encoder processed historical daily case counts (normalized per 100,000 inhabitants) from 17 countries to learn temporal dependencies, and the decoder predicted future values based on this learned sequence. A dense (fully connected) layer followed by a regression output layer was used to generate the predicted number of new cases. Two prediction strategies were tested: one (Prediction 1) retrained the model incrementally using new country-specific data at each step (mimicking transfer learning), while the other (Prediction 2) used a static model trained on global trends. The model was trained over 250 epochs with 100 LSTM layers and validated using Root Mean Squared Logarithmic Error (RMSLE) to measure the deviation between predicted and actual epidemic curves.",Recurrent Neural Network with Long Short-Term Memory (RNN-LSTM),No,No,predicting the daily new COVID-19 infection cases over time using historical data, COVID-19 epidemiological data,Kolozsvari et.al,Yes,"The study evaluated the predictive accuracy of AI-based RNN models by comparing the forecasted epidemic curves (daily new COVID-19 cases) against actual observed data across multiple countries. The key metric used for performance evaluation was the Root Mean Squared Logarithmic Error (RMSLE), which measures the ratio between predicted and actual values while reducing the effect of large outliers and penalizing underestimation more than overestimation. This metric was calculated for each day during the prediction period and also aggregated over the full forecast window to assess overall model accuracy. The RMSLE enabled the researchers to quantify how closely the predicted trends aligned with real epidemic curves, thereby validating the utility of the model in forecasting future outbreaks.","{""Root Mean Squared Logarithmic Error (RMSLE)""}","{""Hungary"": {""Prediction_1_RMSLE"": 0.06, ""Prediction_2_RMSLE"": 0.107}, ""UK"": {""Prediction_1_RMSLE"": 0.234, ""Prediction_2_RMSLE"": 0.455}, ""Italy"": {""Prediction_1_RMSLE"": 0.114, ""Prediction_2_RMSLE"": 0.155}, ""Spain"": {""Prediction_1_RMSLE"": 0.266, ""Prediction_2_RMSLE"": 0.181}, ""Germany"": {""Prediction_1_RMSLE"": 0.147, ""Prediction_2_RMSLE"": 0.108}, ""France"": {""Prediction_1_RMSLE"": 0.513, ""Prediction_2_RMSLE"": 0.307}, ""USA"": {""Prediction_1_RMSLE"": 0.216, ""Prediction_2_RMSLE"": 0.528}}"
33,"Paul, S. K.; Jana, S.; Bhaumik, P.",2020,"Tata Consultancy Services Kolkata, India",A multivariate spatiotemporal spread model of COVID-19 using ensemble of ConvLSTM networks,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.04.17.20069898,Research,develop a high-resolution spatiotemporal forecasting model that can predict short-term COVID-19 case distribution across large geographical regions such as the USA and Italy,Predicting the spread of COVID-19 at a regional level,build an ensemble of Convolutional LSTM models capable of learning both spatial and temporal patterns of infection spread using limited but structured spatiotemporal data.,"The study adopts a data-driven deep learning approach for modeling the spatiotemporal dynamics of COVID-19 spread. It frames the problem as a supervised learning task where input sequences of spatial infection maps and related features are used to predict future infection distributions. To prevent overfitting on limited data, the model employs ensemble learning with bootstrapped datasets and weighted predictions based on model confidence.","The core model is an ensemble of Convolutional Long Short-Term Memory (ConvLSTM) networks. Each ConvLSTM network captures spatial and temporal dependencies by processing sequences of 2D geospatial images (gridded frames of infection data). The input images include features like normalized log-transformed daily new infections and population distributions. Each frame is split into overlapping grids and pixels to preserve spatial autocorrelation. A sliding time window is used to generate training samples from these images. Each ConvLSTM network in the ensemble is trained independently using a bootstrapped sample (60% random samples with replacement), and predictions are aggregated using a weighted average based on training data infection density and validation error. During inference, the model recursively predicts future frames by feeding its own output back as input for the next timestep.",Ensemble of Convolutional LSTM (ConvLSTM) Networks,https://github.com/swarna-kpaul/covid19spatiotemporal,No,Spatiotemporal short-term forecasting of COVID-19 infections ,daily COVID-19 outbreak data and population distribution data,Paul et.al,Yes,"The study evaluated the performance of the proposed ensemble of Convolutional LSTM models by measuring the accuracy of short-term COVID-19 spread forecasting across both spatial and temporal dimensions. The primary focus was on assessing how accurately the model could predict new infection counts at a fine-grained pixel level (representing localized geographic regions) and at a broader country level (aggregated case counts). To quantify this, Mean Absolute Percentage Error (MAPE) was computed at both levels, excluding pixels with zero susceptible population to avoid skewed results from divide-by-zero errors. Additionally, Kullback-Leibler (KL) Divergence was used to assess how closely the predicted spatial distribution of infections matched the actual spread, capturing the distributional similarity across regions. These metrics together provided a robust evaluation of the model’s forecasting accuracy and its ability to reflect real-world infection dynamics.","{""pixel_level_MAPE"", ""country_level_MAPE"", ""KL_divergence""}","{""USA"": {""pixel_level_MAPE"": ""44%"", ""country_level_MAPE"": ""5.57%"", ""KL_divergence"": ""Low""}, ""Italy"": {""pixel_level_MAPE"": ""<30%"", ""country_level_MAPE"": ""0.3%"", ""KL_divergence"": ""Low""}}"
34,"Yu, Y.; Liu, Y.-R.; Luo, F.-M.; Tu, W.-W.; Zhan, D.-C.; Yu, G.; Zhou, Z.-H.",2020,"National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing",COVID-19 Asymptomatic Infection Estimation,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.04.19.20068072,Research," develop a realistic, fine-grained simulator that models the complex transmission dynamics of COVID-19, with a specific focus on estimating the number of undetected asymptomatic infections and evaluating the effects of containment policies across different regions",Developing a model that can accurately predict the transmission characteristics of COVID-19 and estimate the number of asymptomatic infections.," design and implement MLSim, a machine learning–based fine-grained simulator that integrates domain knowledge of disease progression with real-world data through derivative-free optimization","The study applies a hybrid modeling approach that combines domain knowledge from epidemiology with data-driven optimization techniques. Specifically, it uses a machine learning–based simulation framework (MLSim) that models the stages of COVID-19 progression and transmission, and then fits the model to real-world outbreak data using derivative-free optimization. The method enables both accurate epidemic forecasting and estimation of asymptomatic cases, while allowing flexible simulation of “what-if” intervention scenarios.","The simulator (MLSim) divides the infected population into three compartments: latent (asymptomatic but infectious), quarantined, and confirmed cases. It simulates daily transitions between these compartments using probabilistic rules reflecting incubation, quarantine, and confirmation processes. To estimate unknown parameters (e.g., infection rate, quarantine rate, initial infected count, contact rates), the authors employ derivative-free optimization (a type of black-box optimization) using the Python package ZOOpt. The goal is to minimize the loss between simulated and actual epidemic curves (new cases, recoveries, and deaths). The model handles non-differentiable dynamics and uses real data to iteratively update parameters until the simulation closely reproduces real outbreak data. It then uses these learned parameters to forecast epidemic trends, estimate the number of asymptomatic/self-healed infections, and assess the impact of different containment policies.",MLSim (Machine Learning–based Simulator),https://github.com/eyounx/MLSim,No,Estimating the number of undetected asymptomatic COVID-19 infections and modeling realistic transmission dynamics of the virus across time and regions.,Daily COVID-19 outbreak data,Yu et.al,Yes,"performance was measured in the study to evaluate how accurately the proposed MLSim model could simulate and forecast the spread of COVID-19. The primary focus was on predicting the number of new confirmed cases over time, and the model was assessed by comparing its simulated outputs to actual reported epidemic data. Forecasting accuracy was quantitatively evaluated using the Root Mean Squared Error (RMSE) metric. The researchers validated MLSim against two baselines: a classical SEIR model and a deep learning-based LSTM model. Models were trained on early outbreak data and tested on later unseen data to assess generalization. In addition to statistical evaluation, the study also assessed the model's ability to replicate the dynamics of undetected asymptomatic cases and the impact of containment measures, highlighting its effectiveness in both numerical accuracy and epidemiological interpretability.","The MLSim model demonstrated the best overall performance among the three approaches evaluated. It achieved the lowest RMSE, meaning its predictions were closest to the real reported COVID-19 case numbers. Unlike the other models, MLSim was capable of providing long-term forecasts, estimating the number of undetected asymptomatic infections, and offering high interpretability due to its integration of domain knowledge and data.",
35,"Ge, Q.; Hu, Z.; Li, S.; Lin, W.; Jin, L.; Xiong, M.",2020,"School of Mathematical Sciences, SCMS, and SCAM, Fudan University, Shanghai 200433, China",A Novel Intervention Recurrent autoencoder for real time forecasting and non-pharmaceutical intervention selection to curb the spread of Covid-19 in the world,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.05.05.20091827,Research,develop an accurate and flexible AI-based framework to forecast the trajectory of COVID-19 transmission worldwide and evaluate the effectiveness of various public health interventions.,Predicting the effectiveness of different public health interventions to stop the spread of COVID-19,"design and implement a Recurrent Intervention Network (RIN), a deep learning architecture based on sequence-to-sequence Recurrent Neural Networks (RNNs), to model COVID-19 transmission dynamics and to evaluate the effects of multiple public health interventions over time. ","The study adopts a causal inference-inspired deep learning methodology using a sequence-to-sequence architecture called the Recurrent Intervention Network (RIN). The approach treats public health interventions as treatments and COVID-19 case counts as outcomes, transforming the intervention evaluation problem into a treatment response forecasting problem. The methodology involves training two components an encoder RNN to model past transmission dynamics and a decoder RNN to predict future case trajectories under various planned interventions. This enables both forecasting and counterfactual evaluation of different intervention strategies across multiple countries.","The AI method used in this study is the Recurrent Intervention Network (RIN), a sequence-to-sequence deep learning framework designed for time series forecasting and counterfactual outcome estimation. It consists of two main components: an encoder RNN (or LSTM) that learns hidden representations from historical COVID-19 data, and a decoder RNN (or LSTM) that uses these learned features along with a planned sequence of public health interventions to predict future case numbers. The encoder is trained on past observed data to capture the transmission dynamics, while the decoder forecasts future case trajectories under various intervention scenarios. The model uses mean squared error (MSE) as the loss function and is trained using the Adam optimizer. Input data includes the number of new COVID-19 cases and a continuous intervention variable ranging from 0 (no intervention) to 1 (maximum intervention), across 186 countries. The data is normalized and organized into mini-batches for training. The decoder performs recursive multi-step forecasting, allowing the model to simulate different intervention strategies and evaluate their impact on the spread of the virus. This approach enables the estimation of both actual and counterfactual outcomes, making it a powerful tool for public health planning and policy evaluation during the pandemic.",Recurrent Intervention Network (RIN),No,No,forecasting the transmission dynamics of COVID-19 and evaluating the impact of public health interventions.,"surveillance records of daily confirmed COVID-19 cases, new cases, and deaths",Johns Hopkins COVID-19 dataset,Yes,"researchers conducted one-step-ahead and multi-step-ahead forecasting, where the model used past data to predict future case numbers. These predictions were then compared to actual observed case counts. The primary evaluation criteria were forecasting accuracy and error reduction, especially in comparison to traditional epidemiological models, which tend to have poor parameter identifiability and often rely on fixed assumptions.","Across multiple countries, the RIN model demonstrated high consistency and precision, showing small prediction errors, particularly in short-term forecasting.",
36,"Azarafza, M.; Azarafza, M.; Tanha, J.",2020,"Department of Computer Engineering, Faculty of Electrical & Computer Engineering, University of Tabriz, Tabriz, Iran",COVID-19 Infection Forecasting based on Deep Learning in Iran,MedRxiv,General Virology,['COVID-19'],10.1101/2020.05.16.20104182,Research,develop an accurate and reliable time series forecasting model for COVID-19 infection trends in Iran at both the provincial and national levels.,The research problem addressed in the paper is the prediction and modeling of COVID-19 infection development in Iran using time series data.,The AI objective of this study is to implement and evaluate a long short-term memory (LSTM) based deep learning model for forecasting the number of confirmed COVID-19 cases over time in Iran. ,"The study follows a deep learning-based time series forecasting methodology to predict the number of COVID-19 infections. The approach involves training and testing a neural network model specifically an LSTM to capture temporal dependencies in infection data at provincial and national levels. The model's performance is validated through comparison with traditional forecasting methods using multiple statistical error metrics. The data is split into training and test sets, and the infection trend is evaluated using real versus predicted case counts over time.","The study employs a Long Short-Term Memory (LSTM) neural network as the primary deep learning method for time series forecasting of COVID-19 infection trends in Iran. The LSTM model is implemented using TensorFlow and trained with the Adam optimizer to effectively capture long-term dependencies in sequential data. For the provincial-level analysis, the model was trained on 22 days of data and tested on the subsequent 12 days, while for the national-level prediction, it was trained on 67 days and tested on 19 days, covering the period from February 19 to May 13, 2020.",Long Short-Term Memory (LSTM) neural network,No,No,forecasting the temporal and spatial spread of COVID-19 infections in Iran,daily confirmed COVID-19 case counts in Iran,Azarafza et.al,Yes,"To evaluate the LSTM model’s performance, it was compared against several traditional and statistical forecasting methods, including Recurrent Neural Networks (RNN), Seasonal ARIMA (SARIMA), Holt-Winters Exponential Smoothing (HWES), and Moving Averages. The accuracy and robustness of the models were assessed using standard error metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), and Mean Absolute Percentage Error (MAPE). ","Results showed that the LSTM consistently outperformed the baseline models, producing forecasts that were closer to actual reported infections, with lower error rates across all tested provinces and at the national level.",
37,"Heili-Frades, S.; Minguez, P.; Mahillo-Fernandez, I.; Prieto-Rumeau, T.; Herrero Gonzalez, A.; De La Fuente, L.; Rodriguez Nieto, M. J.; Peces-Barba Romero, G.; Peces-Barba, M.; Carballosa De Miguel, M. D. P.; Fernandez Ormaechea, I.; Naya Prieto, A.; Ezzine De Blas, F.; Jimenez Hiscock, L.; Perez Calvo, C.; Santos, A.; Munoz Alameda, L. E.; Romero Bueno, F.; Hernandez-Mora, M. G.; Cabello Ubeda, A.; Alvarez Alvarez, B.; Petkova, E.; Carrasco, N.; Martin Rios, D.; Gonzalez Mangado, N.; Sanchez Pernaute, O.",2020,"Intermediate Respiratory Care Unit, IIS-Fundación Jiménez Díaz Quirón Salud, Madrid, CIBER de enfermedades respiratorias (CIBERES), REVA Network.",COVID-19 Outcomes in 4712 consecutively confirmed SARS-CoV2 cases in the city of Madrid.,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.05.22.20109850,Research,"The aim of this study is to identify clinical factors influencing survival outcomes in COVID-19 patients using a large patient dataset from four public hospitals in Madrid, with a particular emphasis on evaluating the effectiveness of different treatments.","There is limited real-world information available about the clinical features and treatment outcomes of hospitalized COVID-19 patients, and no treatments had conclusively demonstrated efficacy at the time of the study.",The AI objective of this study is to develop predictive models that can identify key factors associated with mortality and disease severity in hospitalized COVID-19 patients using machine learning techniques.,"The study employed a supervised machine learning approach combining neural networks (NN) and principal component analysis (PCA) to predict COVID-19 patient outcomes. These models were used to classify patient severity and mortality based on a variety of clinical and laboratory inputs. Additional statistical methods, including logistic regression and Fisher/Wilcoxon tests, were used to identify significant variables and cut-off thresholds for outcome prediction.","A neural network was implemented using the caret package in R, specifically the ""nnet"" method. The model was trained through repeated random under-sampling of the majority class (less severe patients) and applied 10-fold cross-validation on each balanced sample. A total of 100 NN models were trained and evaluated to ensure stable performance. Each model computed sensitivity, specificity, accuracy, and AUC using the “twoClassSummary” function. Additionally, PCA was used to reduce dimensionality and visualize separation between outcome groups. For binary variables, Fisher’s exact test was used, while non-binary variables (like biomarkers) were analyzed using the Wilcoxon rank-sum test. Logistic regression with ROC analysis was also used to identify optimal cut-off points for vital signs predictive of mortality.",Neural Network (NN) + Principal Component Analysis (PCA) + Multivariate Logistic Regression,https://github.com/pminguez/MachineLearning4UnbalancedData/blob/master/nn4covid19.R,GNU General Public License v3.0,prognostic prediction of COVID-19 disease severity and mortality,electronic clinical records (eCR),Heili-Frades et.al,Yes,"Performance in this study was measured to evaluate the predictive ability of machine learning models particularly a neural network in classifying patient outcomes related to COVID-19 severity and mortality. The outcomes being measured included death, ICU admission, and survival status. The performance was assessed using standard classification metrics: accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). These were calculated by running 100 neural network models, each trained and tested on balanced, re-sampled datasets using 10-fold cross-validation. For each outcome classification task such as deceased vs. alive, or deceased vs. ICU admitted average values of these metrics were reported to ensure robustness and generalizability.","{""AUC"", ""accuracy"", ""sensitivity"", ""specificity""}","{""NN_comorbidities"": {""AUC"": 0.74, ""accuracy"": 0.70, ""sensitivity"": 0.40, ""specificity"": 0.81}, ""NN_vital_signs"": {""AUC"": 0.87, ""accuracy"": 0.80, ""sensitivity"": 0.70, ""specificity"": 0.69}, ""NN_vital_signs_deceased_vs_ICU"": {""AUC"": 0.91}, ""NN_treatments_all_ages"": {""AUC"": 0.65}, ""NN_treatments_age_31_50"": {""AUC"": 0.81}, ""NN_treatments_age_51_70"": {""AUC"": 0.67}, ""NN_treatments_age_71_100"": {""AUC"": 0.59}, ""NN_treatments_critically_ill"": {""AUC"": 0.90, ""accuracy"": 0.84, ""sensitivity"": 0.67, ""specificity"": 0.73}, ""NN_biomarkers"": {""AUC"": 0.73, ""accuracy"": 0.69, ""sensitivity"": 0.62, ""specificity"": 0.66}}"
38,"Gemmar, P.",2020,Trier University of Applied Sciences,An interpretable mortality prediction model for COVID-19 patients - alternative approach,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.06.14.20130732,Research,introduces a Fuzzy logic based prediction system for COVID-19 risk assessment with improved performance compared with other approaches,COVID-19 risk assessment,"The objective from an AI perspective is to evaluate and improve upon existing COVID-19 mortality prediction models by introducing a Sugeno-type Fuzzy Inference System (FIS) trained with selected biomarkers, leveraging ANFIS (Adaptive Neuro-Fuzzy Inference System) for automatic rule generation, and integrating biomarker trends to enhance prediction accuracy and interpretability.","The study follows a hybrid machine learning methodology combining neural network-based feature analysis with fuzzy logic-based classification. Initially, a Kohonen Self-Organizing Map (SOM) is used for unsupervised feature selection and visualization of biomarker patterns. Then, a Sugeno-type Fuzzy Inference System (FIS) is automatically trained using MATLAB's ANFIS (Adaptive Neuro-Fuzzy Inference System) on selected biomarkers to predict patient mortality risk. The model is further extended by incorporating the temporal trend of biomarkers to enhance predictive performance.","The study employed a deep learning-based Sugeno-type Fuzzy Inference System (FIS), trained using the Adaptive Neuro-Fuzzy Inference System (ANFIS) in MATLAB, for COVID-19 mortality risk prediction. This model combined fuzzy logic with neural learning, allowing it to generate interpretable, non-binary risk scores based on key biomarkers such as LDH, lymphocytes, and hs-CRP. The FIS was constructed with three fuzzy terms per input feature, resulting in 27 fuzzy rules, and was trained on 351 patient samples. To enhance performance, additional biomarkers (albumin and INR) and the temporal trends of biomarkers were integrated into extended versions of the model. The approach also utilized Self-Organizing Maps (SOM) to visualize feature importance and guide feature selection. ",ugeno-type Fuzzy Inference System (FIS) generated and trained using ANFIS (Adaptive Neuro-Fuzzy Inference System),No,No,COVID-19 patient mortality risk prediction based on biomarkers.,clinical biomarker measurements and patient outcome labels (alive or deceased),Gemmar et.al,Yes,"performance was measured in this study using multiple classification models, including a fuzzy inference system (FIS), decision tree, and support vector machine (SVM), all applied to predict COVID-19 mortality risk based on patient biomarkers. The key metric used for evaluating prediction quality was the Area Under the ROC Curve (AUC). The Fuzzy classifier (FIS), trained using ANFIS in MATLAB, outperformed other methods, achieving an AUC of up to 98.59 on training data and 95.12 on external test data. Additionally, accuracy, precision, recall, and total classification errors (E) were reported to assess prediction consistency. The inclusion of biomarker trends over time further improved the model, although this couldn't be thoroughly tested due to limited temporal data.","{""AUC_train"", ""AUC_test"", ""Accuracy"":, ""Precision"", ""Recall"", ""Classification_Error_E""}"," {""AUC_train"": 98.59, ""AUC_test"": 95.12, ""Accuracy"": 0.96, ""Precision"": 0.95, ""Recall"": 0.95, ""Classification_Error_E"": 3}"
39,"Tuli, S.; Tuli, S.; Verma, R.; Tuli, R.",2020,"Department of Computer Science and Engineering, Indian Institute of Technology Delhi, India",Modelling for prediction of the spread and severity of COVID-19 and its association with socioeconomic factors and virus types,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.06.18.20134874,Research,"The aim of the study is to develop and evaluate an improved forecasting model, Weibull-LSTM (W-LSTM), to accurately predict the trajectory of COVID-19 infections and deaths across multiple countries, and to analyze how socio-economic, demographic, and viral strain factors influence the spread and severity of the pandemic.","The problem addressed is the limited accuracy, adaptability, and generalizability of existing COVID-19 prediction models, such as classical epidemiological models (e.g., SIR, SEIR) and traditional statistical time-series models (e.g., ARIMA), which struggle with non-stationary, noisy, and dynamically changing pandemic data.",The AI objective is to develop a hybrid deep learning model (W-LSTM) that combines Weibull statistical curve fitting with Long Short-Term Memory (LSTM) networks to model temporal patterns in COVID-19 data.,"The study uses a hybrid modeling approach that integrates statistical curve fitting with deep learning. It first fits daily COVID-19 case and death counts using a Generalized Weibull Distribution, then applies a Long Short-Term Memory (LSTM) network to learn the temporal evolution of the Weibull curve’s parameters over time. This allows the model to dynamically adapt as new data arrives.","The W-LSTM model combines statistical curve fitting with deep learning for COVID-19 forecasting. It first applies a Robust Weibull curve fitting method to model daily new infections and deaths using a Generalized Weibull Distribution, accounting for noisy and incomplete data. Then, it uses a Long Short-Term Memory (LSTM) network to learn the temporal evolution of the Weibull parameters (`k, ?, ?, ?`) across a sequence of curve fits. This hybrid approach allows the model to capture both the statistical shape of the epidemic and its time-dependent dynamics. By training on sequences of past parameter fits, the LSTM predicts the best-fitting Weibull parameters for future trends, leading to more robust and adaptive forecasting. The final model, W-LSTM, outperforms traditional LSTM and ARIMA models in terms of prediction accuracy.",Weibull-Long Short-Term Memory (W-LSTM),https://github.com/shreshthtuli/covid-19-prediction ,"BSD 2-Clause ""Simplified"" License",forecasting the trajectory of COVID-19 infections and deaths,daily confirmed cases and death counts,Our World in Data COVID-19 Dataset (https://ourworldindata.org/coronavirus),Yes," The model's forecasting accuracy was evaluated using three standard metrics: Mean Squared Error (MSE), R-squared (R²), and Mean Absolute Percentage Error (MAPE). These were used to compare the W-LSTM model’s predictions against actual infection and death counts over a 10-day period beyond training. The model achieved high accuracy in 82% of 50 tested countries, outperforming ARIMA and traditional LSTM models. Additionally, W-LSTM’s predictive consistency was validated for both infection and mortality curves across 30 well-fitted countries.","W-LSTM offered superior forecasting performance compared to baseline models like ARIMA and traditional LSTM, particularly in predicting COVID-19 infection and death trajectories.",
40,"Tian, Y.; Luthra, I.; Zhang, X.",2020,"33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada",Forecasting COVID-19 cases using Machine Learning models,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.07.02.20145474,Research,Predicting the number of confirmed cases of COVID-19 using machine learning models,The problem of predicting the spread of COVID-19 and identifying the most effective machine learning models for this task,"To develop and evaluate data-driven AI models that can forecast daily confirmed COVID-19 cases over a 5-day horizon across different countries, using limited and noisy time-series data.","The study employs a comparative modeling approach using three machine learning techniques LSTM, Hierarchical Bayes, and HMM to forecast COVID-19 confirmed cases across six countries. The models are trained and validated on normalized daily case counts, with performance evaluated over a 5-day prediction window using RMSE (root mean square error). Each model handles temporal dynamics differently: LSTM captures sequential patterns, Hierarchical Bayes accounts for inter-country dependencies, and HMM models latent infection states.","Implemented in PyTorch, this recurrent neural network learns long-term dependencies in time-series case data. The model uses change in daily case counts rather than absolute numbers to avoid autocorrelation bias. Gaussian noise is added for data augmentation. A linear layer with ReLU activation prevents negative predictions.",Long Short-Term Memory (LSTM),https://github.com/nZhangx/CPSC540_Covid,No,Forecasting confirmed COVID-19 cases,Daily confirmed COVID-19 cases,Tian et.al,Yes,"performance was measured in the study using the Root Mean Square Error (RMSE) as the primary evaluation metric. The authors evaluated how well each model could predict the number of confirmed COVID-19 cases over a 5-day forecast window (April 9–14, 2020). They compared three different models Hidden Markov Model (HMM), Hierarchical Bayes, and Long Short-Term Memory (LSTM) on data from six countries (South Korea, Italy, United States, Taiwan, Japan, and Germany). Each model was trained on data from January 22 to April 8, 2020, and tested on the subsequent five days. RMSE values were calculated for each country, enabling a direct comparison of model accuracy."," The results showed that the LSTM model achieved the lowest average RMSE across most countries, indicating superior predictive performance, while the Hierarchical Bayes model provided more realistic long-term trend predictions.",
41,"Ge, Q.; Hu, Z.; Zhang, K.; Li, S.; Lin, W.; Jin, L.; Xiong, M.",2020,"School of Mathematical Sciences, Fudan University",Outbreak of Covid-19 worldwide is on the decline-----Recurrent Neural Reinforcement Learning and Health Interventions to Curb the Spread of Covid-19 in the world,MedRxiv,Emerging & Re-emerging Viruses,"['SARS-CoV-2', 'COVID-19']",10.1101/2020.07.08.20149146,Research,To develop a reinforcement learning-based forecasting framework (RNRL) that accurately predicts the trajectory of COVID-19 under different public health intervention strategies and aids in optimizing those interventions globally.,Predicting the spread of COVID-19 and identifying effective interventions,To apply and integrate Reinforcement Learning (RL) with Recurrent Neural Networks (RNN) forming the Recurrent Neural Reinforcement Learning (RNRL) framework for real-time forecasting of COVID-19 case trajectories and evaluating the counterfactual effects of multiple public health interventions under dynamically changing global conditions.,The study employs a Recurrent Neural Reinforcement Learning (RNRL) framework combining Reinforcement Learning (RL) with Recurrent Neural Networks (RNN) to forecast COVID-19 cases and evaluate intervention policies in a dynamic setting.,"The RNRL approach models the pandemic's progression as a partially observed Markov Decision Process (MDP), where the system dynamics are learned using an RNN-based encoder. The encoder captures the temporal evolution of COVID-19 case numbers, interventions, and contextual covariates. The decoder component then performs counterfactual forecasting—predicting future outcomes based on hypothetical intervention sequences. The method uses off-policy evaluation to assess the effects of intervention strategies not previously executed, enabling decision-makers to simulate alternative public health responses. This two-part structure allows RNRL to both identify the underlying system and simulate optimal or alternative control policies.",Recurrent Neural Reinforcement Learning (RNRL),https://github.com/lin-lab/COVID19-Rt,GNU GENERAL PUBLIC LICENSE v3.0, forecasting the spread and dynamics of COVID-19 cases ,surveillance data of lab-confirmed COVID-19 cases worldwide,Ge et.al,Yes," The researchers evaluated how accurately their Recurrent Neural Reinforcement Learning (RNRL) model could predict both the cumulative and new confirmed COVID-19 cases globally and in individual countries. Forecast accuracy was assessed using one-step ahead prediction error and 7-day ahead forecasting error, with a focus on absolute prediction error. These errors were calculated by comparing the model’s predicted case counts with the actual reported data over specific time windows, including a validation set spanning July 24–30, 2020. The low errors reported indicate the model’s strong short-term forecasting performance for COVID-19 trends.","The study did not use metrics like MAPE or R², but focused on absolute error between predicted and actual cumulative case counts.","{'AUC-ROC': 0.93, 'Accuracy': 0.95, 'F1-score': 0.92}"
42,"Li, Y.; Jia, W.; Wang, J.; Guo, J.; Liu, Q.; Li, X.; Xie, G.; Wang, F.",2020,"Ping An Healthcare Technology, Beijing, China",ALeRT-COVID: Attentive Lockdown-awaRe Transfer Learning for Predicting COVID-19 Pandemics in Different Countries,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.07.09.20149831,Research,"The aim of the study is to develop an accurate and adaptable model to forecast the spread of COVID-19 across different countries, especially during transitions in lockdown policies","Traditional epidemiological and statistical models struggle to predict epidemic trends in countries with limited case data, particularly during early stages. These models often rely on fixed assumptions and fail to incorporate dynamic policy changes such as lockdowns, making them inadequate for real-time decision-making under evolving circumstances.","Develop ALeRT-COVID, an attention-based RNN model with transfer learning, to accurately predict COVID-19 trends in countries with limited data. It incorporates lockdown measures and learns the varying impact of past case numbers to improve forecasting accuracy.","The study uses a transfer learning strategy combined with deep learning to forecast COVID-19 case trends across countries. It builds a source model from countries with rich epidemic data and adapts it to countries with limited data by fine-tuning parts of the network. The approach integrates time-series modeling, attention mechanisms, and policy-aware predictors like lockdown status.","The proposed model, ALeRT-COVID, is based on a Long Short-Term Memory (LSTM) network. It processes 7 days of cumulative confirmed cases per million (CCPM) and binary lockdown indicators to predict future CCPM values. The model includes an attention mechanism that assigns weights to past days' inputs, emphasizing their varying contributions. The lockdown effect is modeled using a multi-layer perceptron (MLP), and its weights are constrained to reflect that lockdowns should not positively contribute to case growth. Transfer learning is used to fine-tune the model for target countries using limited local data.",ALeRT-COVID (Attention-based LSTM with transfer learning for COVID-19 prediction),https://github.com/VickyYin/ALeRT-COVID,MIT license,Forecasting the epidemic progression of COVID-19 cases across countries," cumulative confirmed COVID-19 cases per million (CCPM), national lockdown timelines, and population statistics across 83 countries",Li et.al,Yes,"The study evaluated how accurately the ALeRT-COVID model could predict the number of confirmed COVID-19 cases per million people (CCPM) over a 7-day forecast period. The primary metric used for evaluation was Mean Absolute Percentage Error (MAPE). The model’s performance was compared against baseline models, showing that ALeRT-COVID achieved the lowest mean MAPE, indicating superior predictive accuracy.","{'MAPE:""}","{""Linear Regression (MAPE)"": 0.118, ""Model A (LSTM, no transfer, MAPE)"": 0.100, ""Model B (LSTM + transfer, MAPE)"": 0.077, ""Model C (LSTM + transfer + lockdown, MAPE)"": 0.060, ""ALeRT-COVID (LSTM + transfer + lockdown + attention, MAPE)"": 0.050}"
43,"Agarwal, D. K.; De, S.; Shukla, O.; Checker, A.; Mittal, A.; Borah, A.; Gupta, D.",2020,Georgia Institute Of Technology,Alternative Approaches for Modelling COVID-19:High-Accuracy Low-Data Predictions,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.07.22.20159731,Research,Predicting COVID-19 infections and detection rates,The aim of this study is to develop and evaluate machine learning and curve-fitting approaches for accurately predicting the spread of COVID-19 using fewer assumptions and widely available public data,"The AI objective is to implement and fine-tune deep learning models, specifically LSTM-based neural networks, and compare them with curve-fitting techniques (e.g., logistic, Gompertz, and Richards curves) to forecast COVID-19 case trends.","The study employs a hybrid methodology combining statistical curve-fitting techniques and deep learning-based sequence modeling. First, various sigmoid-based functions (e.g., Richards and Gompertz curves) are fitted to reported COVID-19 case and death data across multiple regions. Second, Long Short-Term Memory (LSTM) neural networks are trained using normalized time-series data and demographic features to forecast future case numbers. These models are evaluated using metrics such as R² (coefficient of determination) to assess their predictive accuracy.","The AI method in this study combines deep learning with statistical modeling to forecast COVID-19 case progression. Specifically, a Long Short-Term Memory (LSTM) network is trained on normalized, time-aligned case count data from nine countries and multiple US and Indian states. The model uses a 24-day input window and outputs a 24-day forecast, incorporating 24 demographic and health-related variables (like age distribution and healthcare infrastructure) for improved accuracy. The LSTM architecture includes layers of 200 LSTM units followed by dense layers with ReLU activation, optimized using random search for hyperparameter tuning. Additionally, the study applies curve-fitting techniques using logistic models (such as Richards and Gompertz curves) to model case growth and estimate actual infections from reported deaths.",Long Short-Term Memory (LSTM),https://github.com/debayanLab/covidPredictions.,No,forecasting the number of COVID-19 infections and estimating the true infection rate,official COVID-19 case and death data,Agarwal et.al,Yes,"The researchers evaluated their models by predicting the number of reported COVID-19 cases and comparing these predictions with actual reported values. They used R-squared (R²) values as the main evaluation metric to assess the accuracy of both curve-fitting and deep learning models. The deep learning models, specifically those based on LSTM architecture, were tested on state-level and global datasets to validate their predictive performance. The curve-fitting models also demonstrated strong alignment with actual case data across multiple regions. Overall, the study measured the accuracy of the models in forecasting future reported COVID-19 cases based on historical data.","{""R^2:""}","{""LSTM (state-level R² for 24-day forecast)"": 0.991, ""LSTM (global R² for 14-day forecast)"": 0.995, ""Curve-fitting model (average R² across regions)"": 0.999}"
44,"Gola, A.; Arya, R. K.; Animesh, A.; Dugh, R.",2020,"Department of Electrical and Electronics Engineering National Institute of Technology, Delhi New Delhi, India",Review of Forecasting Models for Coronavirus (COVID-19) Pandemic in India during Country-wise Lockdowns,MedRxiv,General Virology,['COVID-19'],10.1101/2020.08.03.20167254,review,"The aim of this study is to systematically review, compare, and evaluate the forecasting models used to predict the spread of COVID-19 in India during the national lockdown period","lack of a comparative evaluation of these models, leading to uncertainty about which models can be trusted for future policy-making and resource planning in pandemic situations.","The AI objective of the study is to evaluate the performance of machine learning and statistical forecasting techniques such as Linear Regression, Multilayer Perceptron, Recurrent Neural Networks, SEIR, SIR, and LSTM used to predict COVID-19 case counts in India.","The study systematically reviewed and compared various forecasting models used during India's COVID-19 lockdowns by contrasting their predicted infection counts with actual confirmed cases. Among these, deep learning techniques like Multilayer Perceptrons (MLPs) and Long Short-Term Memory (LSTM) networks were evaluated for their prediction performance, using error metrics such as Mean Absolute Percentage Error (MAPE).","Multilayer Perceptron (MLP): Used as a feed-forward neural network with one or more hidden layers to model non-linear relationships in COVID-19 case data. It demonstrated better performance than basic regression but was still outperformed by some other models. Long Short-Term Memory (LSTM): A specialized form of Recurrent Neural Network (RNN) capable of learning long-term dependencies in sequential data. It was used to model time-series data of infection rates, capturing temporal patterns and showing good predictive accuracy with a MAPE of 63.357 in one case.","Multilayer Perceptron (MLP), Long Short-Term Memory (LSTM)",No,No,predicting the number of confirmed COVID-19 cases,official daily confirmed COVID-19 case count in India,Gola et. al,Yes,"The performance of the forecasting models in the study was measured using the Mean Absolute Percentage Error (MAPE). This metric evaluates how close the predicted number of COVID-19 cases was to the actual number reported during the national lockdown in India. The study compared the predicted and real case counts for each model over the same time intervals. MAPE was chosen for its scale-independence, making it suitable for comparing forecasts with different magnitudes. By calculating the average percentage error between predicted and true values, the study was able to quantify how accurate or inaccurate each model was. A lower MAPE indicates a more accurate forecast. The analysis focused on models using a range of techniques, with special attention to deep learning models like MLP and LSTM, as well as traditional ones like linear regression, SEIR, and SIR models.","{""MAPE:""}","{""Multilayer Perceptron (MLP)"": 80.057, ""Long Short-Term Memory (LSTM)"": 63.357}"
45,"Natarajan, A.; Su, H.-W.; Heneghan, C.",2020,"Fitbit Research, 199 Fremont St, Floor 14, San Francisco,",Assessment of physiological signs associated with COVID-19 measured using wearable devices,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.08.14.20175265,Research,"evaluate whether consumer wearable devices, specifically Fitbit, can be leveraged to predict illness onset and disease severity (including the need for hospitalization) in COVID-19 patients. ","Diagnosing the disease early remains a challenge, especially in asymptomatic or mildly symptomatic individuals.","The AI objective is to build machine learning models that can detect COVID-19 illness and predict hospitalization risk using self-reported symptoms and wearable-derived physiological data like heart rate, respiration rate, and heart rate variability.","The study adopted a two-pronged AI methodology combining classical machine learning and deep learning. Logistic regression was used to predict hospitalization needs based on symptoms and demographic data, providing interpretable and fast predictions. In parallel, a convolutional neural network (CNN) was trained to detect COVID-19-related illness using physiological metrics collected over multiple days from wearable devices. This hybrid approach allowed for both symptom-based and physiology-based assessment.","To predict hospitalization based on symptoms, the researchers trained a logistic regression model using features like age, sex, BMI, and the symptoms people reported. The goal was to estimate how likely someone was to require hospital care. For detecting illness based on physiological data, they used five days' worth of health metrics such as respiration rate, heart rate, heart rate variability (RMSSD), and entropy. These values were normalized and arranged into small matrices, which were then resized to look like grayscale images. These image-like inputs were fed into a convolutional neural network (CNN), which also considered extra information like age, BMI, and sleep efficiency. This setup helped the model predict whether someone was likely to be sick on a given day.",Convolutional Neural Network (CNN),Yes,No,early detection and severity prediction of COVID-19 infection,Wearable device data,Natarajan et.al,Yes,"The study utilized data collected from Fitbit users in the USA and Canada, including physiological metrics (respiration rate, heart rate, RMSSD, and entropy) and self-reported survey responses such as symptoms, age, sex, and BMI. Two machine learning models were developed: a logistic regression model to predict the need for hospitalization based on symptoms, and a convolutional neural network to detect illness onset based on physiological signs collected over five days. Performance was evaluated using metrics such as Area Under the ROC Curve (AUC), sensitivity, and specificity. The logistic regression model for hospitalization prediction achieved moderate accuracy, while the CNN model showed promising potential in identifying illness days before symptom onset. These models demonstrate the viability of wearable sensor data and self-reported health inputs for early illness detection and severity assessment.","{""Area Under the ROC Curve (AUC)"", ""sensitivity"", ""specificity""}","{""Hospitalization_Prediction_LogisticRegression"": {""AUC"": 0.77, ""AUC_SD"": 0.05}, ""Illness_Onset_Detection_CNN_CV"": {""AUC"": 0.77, ""AUC_SD"": 0.027, ""Sensitivity_at_95_Specificity"": 0.44}, ""Illness_Onset_Detection_CNN_Test"": {""AUC"": 0.80, ""Sensitivity_at_95_Specificity"": 0.47}, ""Early_Illness_Detection_Rates_95_Specificity"": {""Day_D-1"": 0.21, ""Day_D0"": 0.25, ""Day_D+1"": 0.40, ""Peak_Day"": ""D+4"", ""Peak_Detection"": 0.52}, ""Early_Illness_Detection_Rates_90_Specificity"": {""Day_D-1"": 0.29, ""Day_D0"": 0.32, ""Day_D+1"": 0.52, ""Peak_Day"": ""D+5"", ""Peak_Detection"": 0.59}, ""Symptom_Based_Detection_Severity_Insights"": {""Fever_Detection_Rate_D+6"": 0.63, ""Severe_Case_Detection_Rate_D+4"": 0.65}}"
46,"Bhattacharyya, A.; Chakraborty, T.; Rai, S. N.",2021,"Department of Bioinformatics & Biostatistics, University of Louisville, KY, USA.",Stochastic forecasting of COVID-19 daily new cases across countries with a novel hybrid time series model,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.10.01.20205021,Research,"To develop a simple, computationally efficient, and interpretable hybrid forecasting model (TARNN) that can generate accurate short-term out-of-sample forecasts for daily confirmed COVID-19 cases across five highly affected countries (USA, Brazil, India, UK, Canada), with improved accuracy over existing single and hybrid time-series models.","Traditional statistical and machine learning models struggle to accurately forecast COVID-19 case trajectories due to the pandemic's highly nonlinear, non-stationary, and non-Gaussian nature, compounded by limited and noisy data, reporting inconsistencies, and concept drift. ","To design and implement a hybrid AI model Theta-ARNN (TARNN) that combines the linear modeling strength of the Theta method with the nonlinear pattern recognition ability of Autoregressive Neural Networks (ARNN), in order to capture both the linear and nonlinear structures of COVID-19 time-series data and deliver superior forecasting performance.","The study follows a hybrid residual learning approach, where linear and nonlinear components of time-series COVID-19 data are modeled in two stages. First, a traditional time-series forecasting model (Theta method) is used to capture linear trends. The residual errors from this model are then modeled using a neural network (ARNN) to learn the nonlinear patterns. The final forecast is obtained by summing the outputs of both models.","The TARNN model is a two-phase hybrid forecasting framework combining the Theta method and Autoregressive Neural Networks (ARNN). In the first phase, the Theta model captures the linear structure in the COVID-19 daily case time-series. The residuals (i.e., prediction errors) from the Theta model are then passed to an ARNN model, which is specifically designed to learn from lagged nonlinear dependencies in time-series data. ARNN(p, k) uses ‘p’ past lag values as inputs and ‘k’ neurons in a single hidden layer to fit the nonlinear component. Finally, the outputs of both models (linear + nonlinear) are added to produce the final prediction. This residual modeling strategy enables the TARNN to robustly handle the nonlinearity and nonstationarity inherent in COVID-19 data, while also achieving strong empirical performance across multiple datasets.",TARNN (Theta-Autoregressive Neural Network),https://github.com/arinjita9/COVID-19-Forecasting-by-TARNN-,MIT License,Short-term forecasting of COVID-19 confirmed cases,Daily time-series of COVID-19 confirmed case counts,Bhattacharyya et.al,Yes,"The performance of the proposed TARNN model was evaluated by measuring the forecasting accuracy of daily COVID-19 confirmed cases across five countries: the USA, Brazil, India, the UK, and Canada. To assess accuracy, the study used three well-known error metrics: root mean squared error (RMSE), mean absolute error (MAE), and mean absolute scaled error (MASE). These metrics were computed on a 60-day out-of-sample test set for each country. RMSE captures the square root of the average squared differences between predicted and actual values, emphasizing larger errors. MAE calculates the average absolute difference, providing a straightforward measure of prediction error. MASE compares the model's error against a naive seasonal benchmark, offering a scale-independent assessment. The lower the value for these metrics, the better the model's predictive performance. These evaluations demonstrate the TARNN model’s ability to effectively forecast short-term epidemic trends, capturing both linear and nonlinear components of the pandemic data.","{""MASE"",""RMSE"",""MAE""}","{""USA"":{""MASE"":3.27,""RMSE"":78320.37,""MAE"":66939.65},""UK"":{""MASE"":5.07,""RMSE"":16559.04,""MAE"":14770.08},""India"":{""MASE"":1.60,""RMSE"":7854.66,""MAE"":5487.11},""Canada"":{""MASE"":1.53,""RMSE"":2323.95,""MAE"":758.82},""Brazil"":{""MASE"":1.05,""RMSE"":20423.69,""MAE"":16701.18}}"
47,"Paul, S. K.; Jana, S.; Bhaumik, P.",2020,"Tata Consultancy Services, Gitanjali Park, Newtow, Kolkata, India",On nonlinear incidence rate of Covid-19,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.10.19.20215665,Research,"To develop a dynamic, spatially-resolved forecasting model for COVID-19 transmission that incorporates variable transmission and recovery rates across geographic regions using spatiotemporal external features, in order to better predict local and national-level infection trends and simulate intervention outcomes.","Classical SIR models assume constant transmission and recovery rates and fail to reflect the spatial heterogeneity and temporal variability of real-world COVID-19 transmission dynamics, leading to inaccurate predictions and limited actionable insights for policy interventions.","To design and implement a Convolutional LSTM model that learns the spatiotemporal dynamics of COVID-19 transmission rates from multiple external features (such as population density, median age, temperature, etc.) and forecasts local and cumulative infection cases with high accuracy.","The study uses a data-driven spatiotemporal modeling approach to forecast COVID-19 transmission. The authors integrate a discrete SIR model with a deep learning module to dynamically estimate the time-varying transmission rate ?(t). The model treats disease spread as a spatiotemporal problem, dividing a geographic area into grids and pixels, and constructs a supervised learning problem where input features (e.g., population density, temperature) are used to predict future transmission rates through deep learning.","The core of the modeling pipeline is a Convolutional LSTM (ConvLSTM) network trained on a multichannel spatiotemporal dataset derived from U.S. county-level COVID-19 data and external influencing features like population density, age distribution, gender ratio, and environmental variables. The model input consists of tensors representing sequences of frames, where each frame contains pixel-wise feature matrices over time. Eight features are used as input channels. The output of the ConvLSTM is a predicted transmission rate ?(t) for each pixel, which is then used to compute the new infection cases using a modified SIR framework. The trained model is also used for long-term forecasting under normal and hypothetical intervention (""what-if"") scenarios by modifying recovery rates.",Convolutional Long Short-Term Memory Network (ConvLSTM) integrated into a discrete variable-parameter SIR model,No,No,Forecasting the transmission dynamics of COVID-19 infections across space and time,COVID-19 daily infection data ,Paul et.al,Yes,"The performance of the ConvLSTM-based spatiotemporal model for COVID-19 transmission forecasting was assessed using multiple evaluation metrics. The model was tested with and without the inclusion of weather-related features. Using the mean absolute percentage error (MAPE), the model with weather features achieved 7.95% at the pixel level, 8.39% at the grid level, and 0.19% at the country level. Without weather features, the MAPE values were slightly worse: 10.10% (pixel), 10.36% (grid), and 0.25% (country). Additionally, the training and validation mean absolute errors (MAE) were lower when weather features were included (0.0140 and 0.0043 respectively). The KL divergence at the pixel level was also marginally better with weather features, indicating improved distributional alignment. The model with weather features predicted 1,331,175 total cases, closer to the actual count of 1,330,525, compared to 1,328,605 predicted without weather data. These results highlight the benefit of including environmental features in improving spatiotemporal forecasting accuracy.","{""Training_MAE"": """", ""Validation_MAE"": """", ""Pixel_KL_Divergence"": """", ""Pixel_MAPE (%)"": """", ""Grid_MAPE (%)"": """", ""Country_MAPE (%)"": """", ""Predicted_Total_Cases"": """", ""Actual_Total_Cases"": """"}","{""Training_MAE"": 0.0140, ""Validation_MAE"": 0.0043, ""Pixel_KL_Divergence"": 8.306e-09, ""Pixel_MAPE (%)"": 7.95, ""Grid_MAPE (%)"": 8.39, ""Country_MAPE (%)"": 0.19, ""Predicted_Total_Cases"": 1331175, ""Actual_Total_Cases"": 1330525}"
48,"Ardabili, S.; Mosavi, A.; Band, S. S.; Varkonyi-Koczy, A. R.",2020,"Department of Biosystem Engineering, University of Mohaghegh Ardabili, Ardabil, Iran.",Coronavirus Disease (COVID-19) Global Prediction Using Hybrid Artificial Intelligence Method of ANN Trained with Grey Wolf Optimizer,MedRxiv,Emerging & Re-emerging Viruses,['COVID-19'],10.1101/2020.10.22.20217604,Research,"To develop a robust hybrid machine learning model that can accurately predict the global COVID-19 outbreak using time-series data, assisting health authorities and policymakers with proactive decision-making.","Traditional mathematical models for pandemic prediction (e.g., SIR, SEIR) face issues like complexity, long computational time, and lower reliability when dealing with highly nonlinear and evolving real-world data such as COVID-19 case numbers.","To implement and optimize a hybrid AI-based model, specifically an Artificial Neural Network integrated with the Grey Wolf Optimizer (ANN-GWO), for accurately forecasting the spread of COVID-19 using historical global case data.",The study uses a hybrid machine learning approach that combines Artificial Neural Networks (ANNs) with the Grey Wolf Optimizer (GWO). The GWO is employed to optimize the weights and biases of the ANN to enhance prediction accuracy. The model is trained and validated using time-series data of global COVID-19 cases.,"The proposed AI method in this study is a hybrid model combining an Artificial Neural Network (ANN) with the Grey Wolf Optimizer (GWO), referred to as ANN-GWO. The ANN architecture used consists of four layers arranged as 7-10-4-1, representing the number of neurons in each layer. GWO, a nature-inspired optimization algorithm, was employed to optimize the weights and biases of the ANN to improve prediction accuracy. The model was trained on time-series data of global COVID-19 cases collected from January 22 to September 15, 2020, with 70% of the data used for training and 30% for testing. An additional validation phase was conducted using data from September 16 to October 15, 2020.",ANN-GWO (Artificial Neural Network – Grey Wolf Optimizer),No,No,Forecasting the global outbreak of COVID-19 cases using time-series prediction,Time series data,Time-series COVID-19 case data from Worldometer,Yes,"The performance of the ANN-GWO model was measured by evaluating its ability to predict the global COVID-19 outbreak using historical time-series data. Specifically, the model's predictions for total confirmed COVID-19 cases were compared against actual observed data during training, testing, and validation phases. Two key metrics were used: the Mean Absolute Percentage Error (MAPE), which quantifies the average percentage difference between predicted and actual values, and the correlation coefficient (r), which assesses the strength of the linear relationship between them. Lower MAPE values and higher r values indicate better predictive performance. This approach allowed the researchers to assess the accuracy and reliability of the ANN-GWO model across different phases of the outbreak timeline.","{""MAPE:"", ""r:""}","{""training"": {""MAPE"": 6.23, ""r"": 0.999}, ""testing"": {""MAPE"": 13.15, ""r"": 0.994}, ""validating"": {""MAPE"": 11.4, ""r"": 0.994}}"
49,"Abhijit Dandekar, R.; Wang, E.; Barbastathis, G.; Rackauckas, C.",2021,"Department of Computational Science and Engineering, Massachusetts Institute of Technology, Cambridge",Implications of delayed reopening in controlling the COVID-19 surge in Southern and West-Central USA,MedRxiv,Respiratory Virology,['SARS-CoV-2'],10.1101/2020.12.01.20242172,Research,To develop a quantitative and interpretable epidemiological model that can evaluate the impact of early reopening policies on the surge in COVID-19 cases in Southern and West-Central US states during June–July 2020.,"Despite observed correlations between early reopening and rising COVID-19 infections, there is a lack of robust, data-driven methodologies that can quantify the causal impact of reopening policies on infection dynamics across different US states. ","To design and implement a hybrid epidemiological AI model (QSIR) that augments the classical SIR framework with a neural network to learn and represent the quarantine strength function Q(t) from time-series data, enabling accurate simulation of infection trends under various reopening scenarios.","The study uses a hybrid modeling approach that combines classical epidemiological modeling with neural networks. Specifically, it augments the traditional SIR (Susceptible–Infected–Recovered) model with a neural network to estimate a time-varying quarantine strength function Q(t), enabling simulation and counterfactual analysis ","The AI method used in this study involves augmenting the classical SIR (Susceptible Infected Recovered) epidemiological model with a neural network to dynamically learn a time-varying quarantine strength function, denoted as $Q(t)$. This enhanced model, called the QSIR model, enables the simulation of how changing quarantine measures affect the spread of COVID-19. The neural network is trained to capture real-time policy effects such as lockdowns or reopenings by modeling their impact on infection rates. The model parameters, including contact and recovery rates, are optimized using the ADAM optimizer. Additionally, the researchers implement a stochastic version of the model based on the Chemical Langevin Equation to account for random fluctuations and quantify uncertainty. This allows for more robust predictions and the ability to simulate counterfactual scenarios, such as estimating the number of infections that could have been prevented with stricter lockdowns. The model was trained and validated on state-level COVID-19 data from the Johns Hopkins University repository.",QSIR model — a Quarantine-strength-augmented SIR model with a neural network representing quarantine strength ,https://github.com/RajDandekar/Reopening,No,Quantifying the impact of early reopening on the spread of COVID-19 ,COVID-19 infected and recovered case counts,Johns Hopkins COVID-19 dataset,Yes,"The performance of the proposed QSIR model was evaluated based on its ability to accurately predict the number of infected and recovered COVID-19 cases over time. To quantify prediction accuracy, the study used the Mean Absolute Percentage Error (MAPE), a standard metric that calculates the average absolute difference between predicted and actual values as a percentage. This metric was applied to the time series of both infected and recovered cases across multiple U.S. states. A lower MAPE value indicates better model performance, and the model’s outputs were found to closely align with actual data, demonstrating its reliability. Additionally, the study assessed how well the model could estimate reductions in case counts under hypothetical ""no-reopening"" scenarios by simulating altered quarantine strength functions. These comparisons allowed the researchers to determine how many infections could have been prevented, further validating the practical utility of the model.","{""MAPE"":""}","{'Arizona': 5.4, 'Florida': 18.7, 'Louisiana': 12.0, 'Nevada': 3.14, 'Oklahoma': 7.9, 'South Carolina': 11.7, 'Tennessee': 6.9, 'Texas': 10.4, 'Utah': 3.79}"
50,"Tabrizchi, H.; Mosavi, A.; Szabo-Gali, A.; Nadai, L.",2020,"Department of Computer Science, Shahid Bahonar University of Kerman Kerman, Iran",Rapid COVID-19 Diagnosis Using Deep Learning of the Computerized Tomography Scans,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.12.20.20248582,Research,To explore and compare the effectiveness of various machine learning (ML) and deep learning (DL) models using chest X-ray and CT scan images in order to identify the most accurate method for diagnosing COVID-19 cases with minimal false positives and false negatives.,Developing image-based ML methods for diagnosing COVID-19 and comparing their performance,"To develop and implement a set of AI-based image classification models specifically SVM (with RBF kernel), Naive Bayes, MLP, CNN, AdaBoost, and GBDT for binary classification of medical images (COVID-19 vs. normal), and to evaluate their predictive performance using standardized metrics such as accuracy, precision, recall, F1-score, and MCC.",The study follows a supervised learning methodology where chest X-ray and CT scan image data from COVID-19 positive and negative patients are preprocessed and split into training and testing sets (75%-25%). Multiple ML and DL models are trained to classify the images into COVID-positive or COVID-negative classes. Their performance is then evaluated using metrics derived from the confusion matrix.,"The MLP model implemented for COVID-19 detection was based on a deep feedforward neural network architecture. It included five fully connected (dense) layers arranged in a descending order of neuron count: 350, 250, 150, 50, and finally 2 neurons in the output layer. The ReLU activation function was applied to all hidden layers to introduce non-linearity, while the final output layer used softmax activation to produce class probabilities for binary classification. The MLP processed the flattened image input vectors directly, without any spatial feature extraction, relying instead on dense layer transformations to identify relevant patterns. While more straightforward than CNN, the MLP still performed robustly but did not surpass the CNN in overall accuracy. Its effectiveness highlighted the utility of basic deep learning architectures for medical image classification tasks, especially when computational simplicity is needed.",Multilayer Perceptron (MLP),No,No,COVID-19 diagnosis using medical imaging,chest X-ray images,Tabrizchi et.al,Yes,"The study measured the performance of deep learning models based on their ability to classify chest X-ray images into COVID-19 positive and normal cases. The evaluation focused on key classification metrics: accuracy, precision, recall (sensitivity), F1-score, and Matthews Correlation Coefficient (MCC). The dataset, comprising 980 images, was split into 75% training and 25% testing sets. Both Convolutional Neural Network (CNN) and Multilayer Perceptron (MLP) models were trained using Python libraries such as Scikit-learn and Keras, and evaluated using confusion matrix-derived statistics. The experiments were conducted on a standard Intel Core i5 CPU with 16 GB RAM. These metrics provided a comprehensive assessment of each model’s ability to detect COVID-19 from medical images.","{""""accuracy""}"," ""CNN"": {""accuracy"": 0.97 },""MLP"": { ""accuracy"":  Accuracy for MLP was not explicitly reported  }"
,,,,,,,,,,,,,,"The CNN model designed in this study was tailored for processing chest X-ray images to detect COVID-19. It consisted of four convolutional layers, each using a relatively large kernel size of 7×7 to extract spatial features from the images. These were followed by either average or max pooling layers with a kernel size of 3×3 to downsample the feature maps and reduce dimensionality. The architecture incorporated at least 64 filters in each convolutional layer to capture detailed patterns. After the convolution and pooling layers, two fully connected layers with 512 neurons each were added, along with dropout layers to mitigate overfitting. The model was trained using a softmax output layer to predict the probability of COVID-19-positive or negative cases. ",Convolutional Neural Network (CNN),No,No,,,,,,,
51,"Gahan, P.; Pattnaik, M.; Nayak, A.; Roul, M. K.",2021,"Dept. of Business Administration, Sambalpur University",Prediction of COVID-19 Pandemic of Top Ten Countries in the World Establishing a Hybrid AARNN LTM Model,MedRxiv,Respiratory Virology,['SARS-CoV-2'],10.1101/2020.12.31.20249105,Research,"To generate accurate long-term forecasts of COVID-19 confirmed and death cases for the top ten most affected countries and the world, in order to support effective public health planning, resource allocation, and policy-making during the global pandemic.",Develop a novel hybrid model with AARNN to predict COVID-19 outbreaks more powerfully,"To develop and validate a hybrid forecasting model (AARNN) that integrates ARIMA and ARNN techniques to capture both linear and nonlinear components of COVID-19 time series data, enabling precise 50-day-ahead out-of-sample predictions.","The methodology involves a hybrid modeling approach combining statistical and machine learning methods. First, the ARIMA model is applied to capture the linear structure of the time series data. The residuals from this model, which represent the unexplained nonlinear components, are then modeled using an AutoRegressive Neural Network (ARNN). The final forecast is obtained by combining the linear (ARIMA) and nonlinear (ARNN) predictions. This hybrid approach is designed to overcome the limitations of using ARIMA or ARNN alone and to improve forecast accuracy for complex, nonstationary pandemic data.","The AI method used in this study is a hybrid time series forecasting approach that combines ARIMA and ARNN models to accurately predict COVID-19 confirmed and death cases. First, the ARIMA model captures the linear components of the time series data by identifying trends and seasonality through differencing and analyzing ACF/PACF plots. Once the linear model is fitted, its residuals representing the unexplained, nonlinear part are used as input for an AutoRegressive Neural Network (ARNN). The ARNN is a feed-forward neural network with a single hidden layer that models the nonlinear patterns in the residuals based on lagged values of the series. The final forecast is obtained by summing the outputs of the ARIMA and ARNN models, effectively capturing both linear and nonlinear behaviors in the COVID-19 time series data. This hybrid model is designed to provide more robust and accurate long-term predictions compared to using either model individually.",Hybrid AARNN model — a combination of ARIMA (AutoRegressive Integrated Moving Average) and ARNN (AutoRegressive Neural Network).,No,No,Forecasting COVID-19 confirmed and death cases,"daily time series of confirmed COVID-19 cases and death cases for ten countries (USA, India, Brazil, Russia, France, Spain, UK, Italy, Argentina, Colombia)",Our World in Data – COVID-19 dataset,Yes,"performance was measured in this study to evaluate how accurately the proposed hybrid AARNN model could forecast daily COVID-19 confirmed and death cases across 11 regions (10 countries and the world). The assessment focused on the predictive accuracy of 50-day-ahead forecasts using two standard error metrics: Root Mean Square Error (RMSE) and Mean Absolute Error (MAE). These metrics were calculated for each of the 22 datasets 11 for confirmed cases and 11 for death cases. The results showed that the AARNN model outperformed traditional, advanced, and other hybrid models in 9 out of 11 confirmed case datasets and 7 out of 11 death case datasets, demonstrating its robustness in capturing both linear and nonlinear patterns in pandemic data."," {""RMSE"", ""MAE""}","{""USA"": {""confirmed"": {""RMSE"": 721.57, ""MAE"": 468.63}, ""deaths"": {""RMSE"": 12.25, ""MAE"": 7.90}}, ""India"": {""confirmed"": {""RMSE"": 1278.67, ""MAE"": 755.68}, ""deaths"": {""RMSE"": 16.86, ""MAE"": 10.55}}, ""Brazil"": {""confirmed"": {""RMSE"": 4013.95, ""MAE"": 2745.80}, ""deaths"": {""RMSE"": 141.36, ""MAE"": 82.78}}, ""Russia"": {""confirmed"": {""RMSE"": 1320.47, ""MAE"": 834.99}, ""deaths"": {""RMSE"": 56.55, ""MAE"": 33.95}}, ""France"": {""confirmed"": {""RMSE"": 1887.57, ""MAE"": 1159.07}, ""deaths"": {""RMSE"": 71.84, ""MAE"": 44.66}}, ""Spain"": {""confirmed"": {""RMSE"": 1735.57, ""MAE"": 1027.83}, ""deaths"": {""RMSE"": 81.63, ""MAE"": 48.15}}, ""UK"": {""confirmed"": {""RMSE"": 1828.64, ""MAE"": 1154.49}, ""deaths"": {""RMSE"": 61.11, ""MAE"": 36.12}}, ""Italy"": {""confirmed"": {""RMSE"": 1320.01, ""MAE"": 826.59}, ""deaths"": {""RMSE"": 72.89, ""MAE"": 43.66}}, ""Argentina"": {""confirmed"": {""RMSE"": 3325.15, ""MAE"": 2507.11}, ""deaths"": {""RMSE"": 99.86, ""MAE"": 70.96}}, ""Colombia"": {""confirmed"": {""RMSE"": 3211.36, ""MAE"": 2344.42}, ""deaths"": {""RMSE"": 121.72, ""MAE"": 93.78}}, ""World"": {""confirmed"": {""RMSE"": 14386.09, ""MAE"": 10508.76}, ""deaths"": {""RMSE"": 738.56, ""MAE"": 563.44}}}"
52,"Li, Y.; Pei, X.; Guo, Y.",2021,Beijing University of Posts and Telecommunications,A 3D CNN Classification Model for Accurate Diagnosis of Coronavirus Disease 2019 using Computed Tomography Images,MedRxiv,Respiratory Virology,"['COVID-19', 'Respiratory diseases']",10.1101/2021.01.21.21249999,Research,The aim of this research is to develop and evaluate a deep learning-based diagnostic model using 3D convolutional neural networks (specifically 3D ResNet-18) that can automatically distinguish COVID-19 from common pneumonia and normal controls using chest CT scans. ,"The rapid global spread of COVID-19 has placed immense pressure on healthcare systems, and the standard diagnostic method RT-PCR has limitations such as long turnaround times and high false-negative rates.","To build an accurate, automated diagnostic model based on deep learning that can detect COVID-19 from chest CT images and distinguish it from other pneumonia types and normal cases, with the goal of assisting radiologists in high-pressure clinical environments.","The study uses a supervised deep learning approach for multi-class classification of CT scans into COVID-19, common pneumonia (CP), and normal controls. The process involves preprocessing CT images into volumes of various depths to extract spatial information between slices, followed by inputting these volumes into different 3D convolutional neural networks. The dataset is split into training, validation, and test sets, ensuring that test patients are not seen during training. Cross-entropy loss is used for optimization with the Adam optimizer, and evaluation is conducted using metrics like accuracy, recall, precision, F1-score, and AUROC. Extensive experiments are conducted to evaluate the effect of slice depth, batch size, and different model architectures on classification performance.","The proposed system is built on 3D ResNet architectures, primarily 3D ResNet-18, and compares performance with deeper versions like ResNet-34 and ResNet-50, as well as (2+1)D convolutional variants. The 3D ResNet uses residual blocks composed of batch-normalized 3D convolution layers with ReLU activations and skip connections to capture both local and global spatial features. CT images are preprocessed into volumetric tensors by stacking slices at varying depths (e.g., 4, 8, 16, etc.), which are then used as input to the network. Models are trained with batch sizes ranging from 8 to 64, with performance found to peak at depth 4 and batch size 32. The model outputs probabilities for three classes (COVID-19, CP, normal) using a softmax layer, and final classification is based on the highest probability.",3D ResNet-18,No,No,Diagnosis and classification of COVID-19 from chest CT images,chest CT images,China Consortium of Chest CT Image Investigation (CC-CCII),Yes,"The proposed deep learning models were evaluated on their ability to classify chest CT images into three categories: COVID-19, common pneumonia (CP), and normal controls. The evaluation emphasized both overall classification performance and the specific effectiveness in detecting COVID-19 cases. Standard classification metrics were used to assess the model’s performance, including accuracy, precision, recall (sensitivity), F1-score, and the area under the receiver operating characteristic curve (AUROC). These metrics helped measure the model's correctness, its ability to identify true COVID-19 cases, and the balance between precision and recall. The best-performing model, 3D ResNet-18, demonstrated outstanding results in all metrics, indicating strong potential for assisting clinical diagnosis during the pandemic.","{""accuracy"", ""recall"", ""precision"", ""f1_score"", ""auroc""}}","{""accuracy"": 99.76, ""recall"": 99.96, ""precision"": 99.35, ""f1_score"": 99.65, ""auroc"": 0.9986}"
53,"Alruily, M.; Ezz, M.; Mostafa, A. M.; Yanes, N.; Abbas, M.; El-Manzalawy, Y.",2021,"College of Computer and Information Sciences, Jouf University, Sakaka 72314, Saudi Arabia",Improved Prediction of COVID-19 Transmission and Mortality Using Google Search Trends for Symptoms in the United States,MedRxiv,Respiratory Virology,"['SARS-CoV-2', 'COVID-19']",10.1101/2021.03.14.21253554,Research,To improve short-term forecasting of COVID-19 cases and deaths in the US by developing stacked LSTM models that combine historical data with Google search trends for COVID-19-related symptoms.,"Existing COVID-19 forecasting models often rely solely on historical data and fail to incorporate real-time, behavior-driven indicators like symptom-related search trends, limiting their predictive accuracy and responsiveness.",To enhance 7-day and 14-day-ahead forecasting of COVID-19 confirmed cases and deaths by using stacked LSTM models trained on historical epidemiological data combined with Google search trends for COVID-19-related symptoms.,"The study uses supervised learning for time-series forecasting by training stacked LSTM (SLSTM) models on both historical COVID-19 case/death counts and auxiliary symptom search trend data. The data is split into training, validation, and testing sets, and multiple feature combinations (historical only, symptoms only, combined) are evaluated. Models are selected based on validation set performance and tested using Mean Absolute Percentage Error (MAPE). Window sizes and symptom combinations are tuned for optimal predictive performance.","The proposed model is a stacked LSTM (SLSTM) architecture with two LSTM layers (128 and 64 units), a dense layer (64 units), and a final output neuron. Activation functions used include tanh, linear, and softplus. The models use a recurrent dropout of 0.5 and are trained with the Mean Squared Logarithmic Error (MSLE) loss function and early stopping. Forecasts are made for 7- and 14-day-ahead predictions of both cases and deaths, with input features ranging from historical data alone to combinations with one to three symptom time series.",Stacked Long Short-Term Memory (SLSTM) neural network,No,No,Short-term forecasting of COVID-19 transmission and mortality,COVID-19 historical data,Johns Hopkins University (JHU) CSSE COVID-19 Data Repository,Yes,"The study measured the forecasting performance of deep learning models on four key tasks: predicting 7-day and 14-day-ahead COVID-19 confirmed cases and deaths in the United States. The models were evaluated using the Mean Absolute Percentage Error (MAPE), a standard metric for assessing prediction accuracy in time series forecasting. Predictions were made at the state level, and performance was reported on both validation and test sets. Two types of models were compared: a base model trained only on historical COVID-19 data, and a proposed stacked LSTM model that also incorporated Google search trends for COVID-19-related symptoms. The MAPE values revealed that including symptom trends significantly improved forecasting accuracy, especially for confirmed case predictions.","{""MAPE:""}","{""cases_7_day"": {""base_model_mape"": 6.6, ""proposed_model_mape"": 3.2}, ""cases_14_day"": {""base_model_mape"": 8.8, ""proposed_model_mape"": 5.6}, ""deaths_7_day"": {""base_model_mape"": 4.8, ""proposed_model_mape"": 4.7}, ""deaths_14_day"": {""base_model_mape"": 11.4, ""proposed_model_mape"": 7.8}}"
,,,,,,,,,,,,,,,,,,,Google COVID-19 Search Trends Symptoms data,Google COVID-19 Search Trends Symptoms Dataset,Yes,,,
54,"Choudhary, A.",2021,Basis Independent Silicon Valley,Using Machine Learning along with Data Science algorithms to pre-process and forecast COVID-19 Cases and Deaths,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2021.03.15.21253571,Research,how deep learning (especially RNNs with proper activation functions like tanh) can more accurately forecast COVID-19 trends than traditional statistical methods.,focus on comparing the performance of different machine learning models for predicting COVID-19 cases.,"To leverage artificial intelligence techniques specifically Auto-Regressive models and Recurrent Neural Networks (RNNs) to accurately forecast future COVID-19 cases and deaths across U.S. states, and to evaluate how different activation functions (sigmoid vs. tanh) and model architectures impact predictive performance.","The study employs a two-pronged AI methodology to forecast COVID-19 cases and deaths: one based on traditional Auto-Regressive (AR) models and the other on Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) layers. The methodology begins with preprocessing a large COVID-19 dataset from Kaggle by cleaning null values, removing irrelevant columns, and aggregating data at the state level. For the AR model, the time-series data is transformed to a stationary form using rolling statistics and weighted moving averages to emphasize recent trends. In parallel, the RNN models are trained on non-stationary, sequential data using an 80/20 train-test split. The models’ performance is evaluated using Root Mean Square Error (RMSE), allowing a comparative analysis of how well each model generalizes to unseen data.","The Auto-Regressive model uses past observations to predict future values, requiring the data to be stationary. This is achieved by applying rolling means and weighted moving averages, which assign greater importance to recent data points. The AR model’s predictions are sensitive to data shape and alignment, making temporal shifting critical during model preparation. On the other hand, the Recurrent Neural Network (RNN) approach incorporates LSTM layers that are well-suited for capturing temporal dependencies in time-series data. A stacked LSTM architecture is used, featuring two LSTM layers and one dense output layer. Two activation functions sigmoid and tanh are tested, with tanh showing better predictive accuracy. The model is trained using a cross-entropy loss function, and performance is validated using RMSE for both COVID-19 case and death forecasts, demonstrating the superior ability of LSTMs to model complex, sequential patterns in epidemiological data.",Recurrent Neural Network (RNN) with Long Short-Term Memory (LSTM) layers,No,No,Epidemiological forecasting of COVID-19 case and death counts,state-level daily COVID-19 case and death counts in the United States,Choudhary et.al,Yes,"The performance of the forecasting models was evaluated based on their ability to predict future COVID-19 cases and deaths at the state level, with a focus on California. Two key metrics were used to assess accuracy: Root Mean Square Error (RMSE) and a prediction score (likely R² or similar). RMSE was chosen to quantify the average magnitude of prediction errors, providing insight into how far off the model’s predictions were from actual reported values. Both the Auto-Regressive (AR) model and the Recurrent Neural Network (RNN) with LSTM layers were evaluated using this metric. The RNN model, which utilized tanh and sigmoid activation functions, achieved lower RMSE values compared to the AR model, indicating better performance. The prediction score further confirmed this, with the RNN outperforming the AR model in forecasting both cases and deaths.","{""RMSE_cases"", ""RMSE_deaths"", ""prediction_score""}","{""AR_model"": {""RMSE_cases"": 7629.379, ""RMSE_deaths"": 999.1466, ""prediction_score"": 0.765}, ""RNN_model"": {""RMSE_cases"": 5491.7842, ""RMSE_deaths"": 612.3913, ""prediction_score"": 0.883}}"
55,"Djeddou, M.; Hameed, I. A.; Hellal, A.; Nejatian, A.",2021,"Research Laboratory in Subterranean and Surface Hydraulics (LARHYSS), Faculty of Sciences and Technology, Mohamed Khider University of Biskra, Algeria. PO box 145 RP, 07000 Biskra, Algeria",Predictive modeling of COVID-19 New Confirmed Cases in Algeria using Artificial Neural Network,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2021.03.29.21254532,Research,"To assess the predictive capabilities of four different artificial neural network (ANN) models GRNN, RBFNN, ELM, and MLPNN for forecasting daily new confirmed COVID-19 cases (CNCC) in Algeria, and to determine which model offers the highest accuracy for supporting public health decision-making.",Traditional statistical models often struggle with the non-linear and noisy nature of epidemic data.,"To design, implement, and compare the performance of multiple ANN-based architectures for univariate time series forecasting of COVID-19 cases, using historical CNCC data and standard evaluation metrics (RMSE, MAE, NSE, R) in order to identify the most suitable neural model for epidemic prediction tasks.","The study applied a comparative modeling approach using four distinct artificial neural network (ANN) architectures for time series forecasting. The models were trained and tested on COVID-19 New Confirmed Cases (CNCC) data from Algeria. The dataset was split into training and testing subsets. Each neural network model was trained using MATLAB, and their performance was evaluated using RMSE, MAE, Pearson correlation coefficient (R), and Nash–Sutcliffe efficiency (NSE). The models were then compared through numerical evaluation and graphical tools like Taylor diagrams to assess their predictive accuracy and generalization capabilities.","The MLPNN is a feedforward artificial neural network composed of an input layer, one or more hidden layers, and an output layer. In this study, a single hidden layer was used, and the number of neurons and activation functions were optimized to model the nonlinear relationship between inputs and CNCC. The model was trained using backpropagation in MATLAB, and its performance was validated with RMSE, MAE, R, and NSE. MLPNN achieved the highest accuracy among the models, showing strong generalization in both training and testing.",Multi-Layer Perceptron Neural Network (MLPNN),Yes,No,predicting the number of new confirmed COVID-19 cases (CNCC) in Algeria,daily COVID-19 new confirmed cases in Algeria, Djeddou et.al,Yes,"The study measured the predictive accuracy of four different deep learning models MLPNN, GRNN, RBFNN, and ELM for forecasting COVID-19 New Confirmed Cases (CNCC) in Algeria. The evaluation focused on how closely each model’s predicted values matched the actual observed case numbers. To assess this, four standard statistical metrics were used: Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Pearson Correlation Coefficient (R), and Nash–Sutcliffe Efficiency (NSE). These metrics were calculated during both the training and testing phases. Lower RMSE and MAE values indicated smaller prediction errors, while higher R and NSE values reflected better correlation and model efficiency. This comprehensive evaluation allowed the researchers to compare models effectively and determine that the MLPNN model achieved the highest predictive performance overall.","{""RMSE"", ""MAE"", ""R"", ""NSE""}","{""RMSE"": 28.9663,  ""MAE"": 18.9621,  ""R"": 0.9939, ""NSE"": 0.9878}"
,,,,,,,,,,,,,,"RBFNN is a three-layer network consisting of an input layer, a hidden layer with radial basis activation functions (typically Gaussian), and a linear output layer. The model approximates the target by combining radial basis functions centered on the training data. Hidden neurons and their centers were determined based on Euclidean distances. Although simpler in architecture, RBFNN showed good performance, especially in generalization, but was outperformed by MLPNN in overall accuracy.",Radial Basis Function Neural Network (RBFNN),Yes,No,predicting the number of new confirmed COVID-19 cases (CNCC) in Algeria,daily COVID-19 new confirmed cases in Algeria, Djeddou et.al,Yes,"The study measured the predictive accuracy of four different deep learning models MLPNN, GRNN, RBFNN, and ELM for forecasting COVID-19 New Confirmed Cases (CNCC) in Algeria. The evaluation focused on how closely each model’s predicted values matched the actual observed case numbers. To assess this, four standard statistical metrics were used: Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Pearson Correlation Coefficient (R), and Nash–Sutcliffe Efficiency (NSE). These metrics were calculated during both the training and testing phases. Lower RMSE and MAE values indicated smaller prediction errors, while higher R and NSE values reflected better correlation and model efficiency. This comprehensive evaluation allowed the researchers to compare models effectively and determine that the MLPNN model achieved the highest predictive performance overall.","{""RMSE"", ""MAE"", ""R"", ""NSE""}","{""RMSE"": 75.8441,  ""MAE"": 55.8124,  ""R"": 0.9572, ""NSE"": 0.9163}"
,,,,,,,,,,,,,,"GRNN is a type of radial basis network that avoids iterative training. It estimates continuous functions directly from data using kernel regression. The architecture includes an input layer, a pattern layer, a summation layer, and an output layer. GRNN requires a smoothing parameter (?) to control the influence range of training instances. It is fast to train but may struggle with larger datasets. GRNN achieved acceptable performance but was less accurate during the testing phase compared to MLPNN and RBFNN.",Generalized Regression Neural Network (GRNN),Yes,No,predicting the number of new confirmed COVID-19 cases (CNCC) in Algeria,daily COVID-19 new confirmed cases in Algeria, Djeddou et.al,Yes,"The study measured the predictive accuracy of four different deep learning models MLPNN, GRNN, RBFNN, and ELM for forecasting COVID-19 New Confirmed Cases (CNCC) in Algeria. The evaluation focused on how closely each model’s predicted values matched the actual observed case numbers. To assess this, four standard statistical metrics were used: Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Pearson Correlation Coefficient (R), and Nash–Sutcliffe Efficiency (NSE). These metrics were calculated during both the training and testing phases. Lower RMSE and MAE values indicated smaller prediction errors, while higher R and NSE values reflected better correlation and model efficiency. This comprehensive evaluation allowed the researchers to compare models effectively and determine that the MLPNN model achieved the highest predictive performance overall.","{""RMSE"", ""MAE"", ""R"", ""NSE""}","{""RMSE"": 122.7504, ""MAE"": 100.2906, ""R"": 0.8836, ""NSE"": 0.7807}"
,,,,,,,,,,,,,,"ELM is a single-layer feedforward neural network where the input weights and biases are randomly assigned and not updated during training. The output weights are computed analytically using the Moore–Penrose pseudo-inverse. This allows for very fast training, but model accuracy can vary depending on the initial random weights. In this study, ELM achieved the fastest training time but performed less accurately, particularly in the testing phase.",Extreme Learning Machine (ELM),Yes,No,predicting the number of new confirmed COVID-19 cases (CNCC) in Algeria,daily COVID-19 new confirmed cases in Algeria, Djeddou et.al,Yes,"The study measured the predictive accuracy of four different deep learning models MLPNN, GRNN, RBFNN, and ELM for forecasting COVID-19 New Confirmed Cases (CNCC) in Algeria. The evaluation focused on how closely each model’s predicted values matched the actual observed case numbers. To assess this, four standard statistical metrics were used: Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Pearson Correlation Coefficient (R), and Nash–Sutcliffe Efficiency (NSE). These metrics were calculated during both the training and testing phases. Lower RMSE and MAE values indicated smaller prediction errors, while higher R and NSE values reflected better correlation and model efficiency. This comprehensive evaluation allowed the researchers to compare models effectively and determine that the MLPNN model achieved the highest predictive performance overall.","{""RMSE"", ""MAE"", ""R"", ""NSE""}","{""RMSE"": 172.6720, ""MAE"": 150.6918, ""R"": 0.7524, ""NSE"": 0.5661}"
56,"Demir, I.; Kirisci, M.",2021,"Yildiz Technical University, Science Faculty, Department of Statistics, Esenler, Istanbul, TURKEY,",Forecasting COVID-19 disease cases using the SARIMA-NNAR hybrid model,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2021.04.26.21256108,Research,Forecast the number of deaths due to COVID-19 in Turkey using time series models,"Existing models often struggle with forecasting accuracy, especially when non-linear or seasonal patterns are present. ","develop a deep learning-based time series forecasting model that accurately predicts daily COVID-19 death counts in Turkey, thereby enabling timely public health interventions and policy decisions specifically SARIMA, NNAR, and a hybrid SARIMA-NNAR model.","The study employed a comparative time series forecasting framework integrating statistical and deep learning approaches, with a focus on a hybrid model combining Seasonal AutoRegressive Integrated Moving Average (SARIMA) and Neural Network AutoRegressive (NNAR) methods. In this two-stage pipeline, the SARIMA model was first used to capture the linear components such as trend and seasonality of the COVID-19 death time series in Turkey. The residuals from this SARIMA model, which were presumed to contain nonlinear dynamics, were then modeled using an NNAR network, a type of feedforward neural network adapted for time series forecasting. The NNAR model utilized lagged values as inputs and included hidden neurons to learn complex nonlinear relationships. The final forecast was generated by summing the SARIMA predictions with the NNAR-modeled residuals. The models were trained and validated using a data split approach and evaluated on standard forecasting metrics including RMSE, MAE, and MAPE. Residual diagnostics, including autocorrelation checks, were conducted to validate model assumptions and ensure robustness.","The deep learning method used is the Neural Network Autoregressive (NNAR) model, which is a feedforward neural network adapted for time series data. In this model, lagged values of the target variable (daily COVID-19 deaths) were used as inputs. Several NNAR configurations were tested by varying the number of input lags (p), seasonal components (P), and hidden neurons (k). The best-performing NNAR model was selected based on minimum RMSE, MAE, and MAPE values across both training and validation sets. The final chosen model was NNAR(10,1,7)?, which means 10 input lags, 1 seasonal lag, and 7 neurons in the hidden layer, with a weekly seasonal frequency.","NNAR (10,1,7)? – Neural Network Autoregressive model with weekly seasonality",No,No,time series forecasting of COVID-19 mortality,Daily confirmed COVID-19 cases and deaths in Turkey,Demir et.al,Yes,"The study evaluated the forecasting performance of three models SARIMA, NNAR, and a SARIMA-NNAR hybrid by measuring their ability to predict daily COVID-19 death counts. Each model was trained on historical death data from Turkey and assessed using three standard metrics: Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). These metrics quantify how closely the model predictions align with the actual observed values, with lower values indicating better accuracy. Among the models, the NNAR (Neural Network Autoregressive) model demonstrated the best overall performance on both the training and validation sets, making it the most suitable choice for forecasting COVID-19 mortality trends in this study.","{""RMSE"", ""MAE"", ""MAPE""}","NNAR model had the lowest values of RMSE, MAE, and MAPE across both training and validation sets."
,,,,,,,,,,,,,,"hybrid time series forecasting model that combines the strengths of a Seasonal AutoRegressive Integrated Moving Average (SARIMA) model and a Neural Network AutoRegressive (NNAR) model. First, the SARIMA model is applied to the COVID-19 death time series data to capture linear patterns such as trend and seasonality. The residuals representing unexplained nonlinear components are then modeled using an NNAR network, which is a type of feedforward neural network specifically adapted for time series forecasting. The NNAR model uses lagged values of the residuals as inputs and includes seasonal lags and hidden neurons to model nonlinear dependencies. The final forecast is obtained by summing the SARIMA predictions with the NNAR predictions on the residuals. This ensemble allows the model to effectively handle both the linear structure and complex nonlinear dynamics in the data, resulting in improved forecasting performance.","SARIMA-NNAR (2,1,2)(2,0,1)? + (3,1,2)?",No,No,,,,,,,
57,"Khennou, F.; Akhloufi, M. A.",2021,"Perception, Robotics, and Intelligent Machines Research Group (PRIME), Department of Computer Science, Université de Moncton, Moncton, NB, Canada",Forecasting COVID-19 Spreading in Canada using Deep Learning,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2021.05.01.21256447,Research,The aim of the study is to develop and evaluate an ensemble deep learning model combining LSTM and GRU architectures for forecasting the number of new COVID-19 cases in Canada using both univariate and multivariate time series data. ,"existing COVID-19 forecasting models often rely on univariate time series and fail to incorporate exogenous features, which limits their accuracy and generalizability.",To build an ensemble deep learning model that accurately forecasts future COVID-19 case numbers in Canadian provinces by leveraging both time-series data and exogenous features such as weather conditions and daily testing figures.,"The study employed a two-stage forecasting methodology combining both statistical and deep learning approaches to predict future COVID-19 case counts. Initially, univariate time series models were developed using only temporal case data. This was followed by multivariate time series modeling that incorporated exogenous variables such as weather data (temperature, humidity, precipitation) and daily COVID-19 testing counts. Multiple models including AR, ARIMA, SARIMAX, LSTM, GRU, and their ensemble were implemented and evaluated. The deep learning models were fine-tuned and validated across Canadian provinces to assess generalizability and regional adaptability. Model performance was compared using standard error metrics like MAE, RMSE, and MAPE.","The deep learning approach involved training both LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) networks with a single hidden layer of 100 neurons and an output dense layer for regression. Adam optimizer was used for training, and data batches were created using time series generators. Early stopping and best-weight restoration were applied to avoid overfitting. For multivariate modeling, input features were standardized and filtered based on correlation analysis. The final predictions were generated using an ensemble method that averaged the outputs of LSTM and GRU models to improve accuracy and stability across varying provincial datasets. This ensemble model showed superior performance, especially in provinces with large data volumes like Quebec, Ontario, and Alberta.",Ensemble Deep Learning (LSTM + GRU) for time series forecasting.,No,No,forecasting the spread of COVID-19,"COVID-19 case data, Weather data, number of daily and total COVID-19 tests",Khennou et.al,Yes,"The study evaluated the performance of time series forecasting models for predicting daily new COVID-19 cases across Canadian provinces. Forecast accuracy was assessed using three standard error-based metrics: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). These metrics were calculated by comparing the predicted number of daily cases to the actual reported cases over a test period. The performance was reported per province, with ensemble deep learning models (LSTM + GRU) showing superior accuracy, especially in provinces like Quebec, Ontario, and Alberta. The metrics reflect the precision of the predictions and the consistency of the model's generalization across time.","{""MAE"", ""RMSE"", ""MAPE""}","{""Quebec"": {""MAE"": None, ""RMSE"": 401.11, ""MAPE"": 0.30}, ""Ontario"": {""MAE"": None, ""RMSE"": 1055.87, ""MAPE"": 0.92}, ""Alberta"": {""MAE"": None, ""RMSE"": 588.86, ""MAPE"": 1.47}}"
58,"Jarde, A.; Jeffries, D.; Mackenzie, G. A.",2021,"Department of Statistics and Bioinformatics, Medical Research Council Unit The Gambia at the London School of Hygiene & Tropical Medicine; Fajara; The Gambia",DEVELOPMENT AND VALIDATION OF A MODEL FOR THE PREDICTION OF MORTALITY IN CHILDREN UNDER FIVE YEARS WITH CLINICAL PNEUMONIA IN RURAL GAMBIA,MedRxiv,Respiratory Virology,['pneumonia '],10.1101/2021.08.04.21260737,Research,"Develop and validate a machine learning-based predictive model to estimate mortality risk in children aged 2–59 months hospitalized with clinical pneumonia in a low-resource setting (rural Gambia), using clinically available and reliable features.","Existing clinical prediction tools for pneumonia mortality mostly based on logistic regression models have limited accuracy and generalizability, making them insufficient for real-world clinical use in resource-constrained environments.","To apply and evaluate multiple machine learning algorithms including Random Forest, SVM, ANN, and Regularized Logistic Regression to generate and optimize a supervised classification model that predicts in-hospital mortality based on routine clinical features, while addressing class imbalance and ensuring generalizability.","The study implemented an exhaustive machine learning model generation approach by applying four different supervised learning algorithms Random Forest (RF), Support Vector Machine (SVM), Artificial Neural Network (ANN), and Regularized Logistic Regression (RLR) to every possible combination of two or more of 16 selected clinical features (65,519 combinations in total). Each model was trained using 10-fold cross-validation with hyperparameter tuning, with further filtering based on AUC performance, feature reliability, and clinical interpretability. The final model was validated on a held-out test set using metrics like AUC, sensitivity, and specificity.","The researchers created a comprehensive model development pipeline using population-based surveillance data from over 11,000 pediatric pneumonia cases in rural Gambia. They applied four machine learning algorithms Random Forest, Support Vector Machine, Artificial Neural Network, and Regularized Logistic Regression to every possible feature subset combination, resulting in over 260,000 candidate models. The training process included repeated 10-fold cross-validation with adaptive resampling for hyperparameter optimization. To address class imbalance (only ~2% mortality rate), techniques such as class weighting, SMOTE (Synthetic Minority Over-sampling Technique), and threshold-invariant metrics (AUC) were used. Models were shortlisted based on performance (AUC ? 0.85), limited number of features (?6), and the reliability of those features. The final selected model, a Random Forest with five features (age, heart rate, MUAC, oxygen saturation, and lethargy), achieved an AUC of 0.88 on the test set with sensitivity and specificity of 0.78 and 0.77, respectively. The model is available as a downloadable Shiny App for practical use and validation.",Artificial Neural Network (feedforward neural net),https://github.com/MRCG-djeffries/mortality-prediction ,GNU General Public License v3.0,Predicting mortality risk in children with viral (and mixed etiology) pneumonia using clinical data,"16 routinely collected clinical variables (e.g., age, heart rate, oxygen saturation, MUAC, respiratory signs)lectronic health records",Jarde et.al,Yes,"The model’s performance was evaluated as a binary classification task predicting in-hospital mortality (death vs survival) in children aged 2–59 months with clinical pneumonia. The final selected model was a Random Forest trained on a temporally split training set and validated on a held-out test set. Performance was assessed using standard classification metrics, including Area Under the Receiver Operating Characteristic Curve (AUC) to evaluate the model's ability to discriminate between survivors and non-survivors, and sensitivity and specificity to assess how accurately the model classified deaths and survivals at a chosen probability threshold (0.44). Additionally, calibration plots and density plots were used to evaluate how well the predicted probabilities aligned with observed outcomes. A learning curve was also generated to verify model generalization and rule out overfitting. These metrics demonstrated strong performance and robustness of the model on unseen data.","{""AUC"", ""Sensitivity"", ""Specificity"", ""Best_Threshold""}","{""AUC"": 0.88, ""Sensitivity"": 0.78, ""Specificity"": 0.77, ""Best_Threshold"": 0.44}"
59,"Carrillo-Larco, R. M.; Hernandez Santa Cruz, J. F.",2021,"Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, London, UK","Street images classification according to COVID-19 risk in Lima, Peru: A convolutional neural networks analysis",MedRxiv,General Virology,['COVID-19'],10.1101/2021.09.06.21263188,Research,Developing a deep learning model for predicting COVID-19 risk based on street view images, lack of tools and research applying computer vision and deep learning to the epidemiological surveillance of COVID-19 using unstructured data like street-level imagery.,"To classify street-level images of bus stops in Lima, Peru, into moderate or extreme COVID-19 risk categories using a convolutional neural network (CNN), and to explore which visual features influence classification decisions, thereby supporting population-level epidemiological surveillance.","The study uses a transfer learning approach with pre-trained convolutional neural networks. Five state-of-the-art CNN architectures were tested (NASNetLarge, InceptionResNetV2, Xception, ResNet152V2, and ResNet101V2), and the best-performing model (NASNetLarge) was selected, fine-tuned, and further evaluated. The model was trained on street images labeled with COVID-19 risk levels (moderate or extreme), and evaluated using standard classification metrics. GradCam was used for visual interpretability to identify which image regions contributed most to the classification.","The study used a transfer learning approach with deep convolutional neural networks to classify street images of bus stops in Lima into moderate or extreme COVID-19 risk categories. A dataset of 8,940 images was compiled using the Google Street View API, with five images per bus stop taken from different angles. These images were labeled based on official COVID-19 risk classifications and split into training (60%), validation (20%), and test (20%) sets. Five pre-trained CNN architectures (NASNetLarge, InceptionResNetV2, Xception, ResNet152V2, ResNet101V2) were evaluated, and NASNetLarge was selected for its superior performance. The model's final classification layer was replaced with a 2-neuron softmax layer to enable binary classification. The training used stochastic gradient descent (SGD) with learning rate decay and early stopping. Hyperparameters were fine-tuned, including adjustments to the optimizer decay and learning rate schedule, which improved recall and overall accuracy. Model performance was evaluated using accuracy, recall, and F1-score metrics, and GradCam visualizations were employed to interpret the regions of the image that contributed most to classification decisions, such as green spaces or proximity to buildings and people.",Transfer learning with NASNetLarge CNN architecture for binary classification of street images using softmax output.,https://drive.google.com/file/d/1HXLsenn7yvxri7n2xE80WMtxQzj5fgBX/view?usp=sharing,No,Environmental risk mapping of virus transmission using computer vision,Street view images,Carrillo et.al,Yes,"The model's performance was evaluated on a binary classification task aimed at predicting whether a bus stop was at moderate or extreme COVID-19 risk. Performance assessment was conducted on a held-out test set using standard classification metrics, including overall accuracy as well as precision, recall, and F1-score for each class label (""moderate"" and ""extreme""). These metrics provided a comprehensive view of the model’s ability to correctly classify each risk category. Additionally, GradCam was employed to enhance interpretability by highlighting the regions in the street images that most influenced the model’s decisions, offering insights into the environmental features associated with different levels of COVID-19 risk.","{""Training_Accuracy"", ""Training_Loss"", ""Moderate_Precision"", ""Moderate_Recall"", ""Moderate_F1"", ""Extreme_Precision"", ""Extreme_Recall"", ""Extreme_F1""}","{""Training_Accuracy"": 0.75, ""Training_Loss"": 0.50, ""Moderate_Precision"": 0.80, ""Moderate_Recall"": 0.83, ""Moderate_F1"": 0.82, ""Extreme_Precision"": 0.65, ""Extreme_Recall"": 0.51, ""Extreme_F1"": 0.63}"
60,"Hue, J.; Valinciute, Z.; Thavaraj, S.; Veschini, L.",2022,"Faculty of Dentistry, Oral and Craniofacial Sciences, King’s College London, United Kingdom",High content image analysis in routine diagnostic histopathology predicts outcomes in HPV-associated oropharyngeal squamous cell carcinomas,MedRxiv,Oncogenic virology,Human Papillomavirus-associated Oropharyngeal Squamous Cell Carcinoma (HPV+OpSCC),10.1101/2022.06.24.22276368,Research,"develop an open-source, automated image analysis workflow to extract quantitative features from routine haematoxylin and eosin (H&E) stained histopathological slides of HPV-associated oropharyngeal squamous cell carcinoma (HPV+OpSCC) patients, and to use these features to train a neural network model for predicting patient prognosis (favourable or unfavourable outcomes).","Existing prognostic biomarkers are costly, require specialized lab tests, and are not readily accessible in standard pathology workflows. Moreover, these biomarkers may fail to capture the complex, multifactorial nature of disease progression.","To develop a neural network model that predicts patient prognosis (favourable or unfavourable outcomes) in HPV+OpSCC cases using quantitative features extracted from routine H&E-stained histology slides, without the need for additional biomarker testing.","The study implements a high content image analysis (HCA) pipeline using open-source tools to segment and classify individual cells from H&E slides. Quantitative features (e.g., immune cell counts, nuclear morphology, spatial relationships, heterogeneity) are extracted per patient and used as input for training a neural network. The model is validated using 10-fold cross-validation and a held-out test set.","The study employed a high content analysis workflow combining open-source tools for processing routine H&E-stained histology images. Preprocessing was done using ImageJ, followed by pixel classification in QuPath using an ML-based pixel classifier. Nuclear segmentation was enhanced using the Stardist plugin, and object-level segmentation and classification of cells (tumour cells, TILs, plasma cells) were performed using CellProfiler and CellProfiler Analyst. A total of 31 statistically significant features related to nuclear morphology, spatial distribution, immune infiltration, and intratumour heterogeneity were extracted. These features were used to train a neural network model with four hidden layers (16, 8, 8, 4 nodes), which was validated on a hold-out test set and via 10-fold cross-validation. Performance was assessed using accuracy, sensitivity, specificity, and the Kappa statistic.",Supervised Feedforward Neural Network using engineered histopathological features.,https://github.com/jonashue1/HPV-OpSCC-Machine-Learning,No,Prognostic stratification of virus-induced cancer patients,Histopathological image data ,Hue et.al,Yes,"The performance of the neural network model was assessed using a standard machine learning evaluation strategy involving both a hold-out test set and 10-fold cross-validation. From the full dataset of 567 histopathology images, 80% were used for training and 20% were held out as a test set. The model’s ability to predict patient outcomes (favourable vs. unfavourable prognosis) was evaluated using several metrics: accuracy, sensitivity, specificity, and the Kappa statistic, which measures agreement beyond chance. On the test set, the model achieved strong performance across all evaluation metrics. The Kappa score indicated moderate-to-good agreement. To further validate robustness, 10-fold cross-validation was performed, yielding consistent results across folds for accuracy, sensitivity, specificity, and Kappa. These results demonstrate the model’s effectiveness in distinguishing between outcome groups using features extracted from routine H\&E-stained slides.","{""Test_Accuracy"", ""Test_Sensitivity"", ""Test_Specificity"", ""Test_Kappa"", ""CV_Accuracy"", ""CV_Sensitivity"", ""CV_Specificity"", ""CV_Kappa""}","{""Test_Accuracy"": 0.7876, ""Test_Sensitivity"": 0.7213, ""Test_Specificity"": 0.8654, ""Test_Kappa"": 0.579, ""CV_Accuracy"": 0.7772, ""CV_Sensitivity"": 0.7717, ""CV_Specificity"": 0.7812, ""CV_Kappa"": 0.552}"
61,"Yellapu, G. D.; Rudraraju, G.; Sripada, N. R.; Mamidgi, B.; Jalukuru, C.; Firmal, P.; Yechuri, V.; Varanasi, S.; Sudhakar, P. V.; Bhimarasetty, D. M.; Kanisetti, S.; Joshi, N.; Mohapatra, P.; Pamarthi, K.",2023,"Andhra Medical College, Visakhapatnam, India",Development and Clinical Validation of Swaasa AI Platform for screening and prioritization of Pulmonary TB,MedRxiv,Respiratory Virology,['Tuberculosis (TB)'],10.1101/2022.09.19.22280114,Research,"The primary aim of this research is to develop, validate, and test the Swaasa AI platform, a software-based medical device (SaMD), to effectively screen and prioritize patients at risk for Pulmonary Tuberculosis (PTB) by analyzing cough sounds combined with symptomatic information.","Current diagnostic methods (e.g., sputum staining, chest X-ray, CB-NAAT) are expensive, require specialized laboratory facilities, and highly trained personnel, making them inaccessible for widespread screening, especially in remote or low-income areas", detect and prioritize patients likely to have Pulmonary Tuberculosis (PTB) by analyzing the acoustic signature of cough sounds combined with symptomatic (tabular) data provided by the subjects.,"The AI methodology employed in this study involves a multimodal deep learning framework integrating two neural network models: a Convolutional Neural Network (CNN) and a Feedforward Artificial Neural Network (FFANN). The CNN component processes Mel spectrograms derived from cough sound recordings to extract acoustic features representative of Pulmonary Tuberculosis (PTB). Concurrently, the FFANN analyzes structured, tabular data comprising primary audio-derived features (such as MFCCs, spectral centroid, roll-off, bandwidth, chroma, and zero-crossing rates) and secondary symptomatic features (including age, gender, cough type, duration, and reported symptoms). Finally, outputs from these two neural network models are combined through an additional fully connected layer, termed ""combined logic,"" providing a unified diagnostic decision about the likely presence of PTB.","The AI method incorporates a hybrid deep learning approach, using transfer learning with ResNet-34 pre-trained on ImageNet to analyze cough sound Mel spectrograms, identifying distinct acoustic signatures associated with PTB. The tabular data is processed through an FFANN architecture comprising two hidden layers (with 400 and 300 neurons, respectively), each followed by batch normalization layers to enhance stability and generalization. Feature selection was conducted through correlation analysis and recursive feature elimination, reducing the initial feature set from 209 to 170 critical attributes, which include audio spectral features, MFCCs, temporal domain features, and clinical characteristics. Model performance was rigorously validated using a 10-fold cross-validation strategy, achieving high predictive accuracy with sensitivity and specificity meeting the World Health Organization (WHO) criteria for community-based screening tests.",Multimodal Deep Learning (Hybrid),Yes(proprietary ),Class B Medical Device License,screening and detection of Pulmonary Tuberculosis (PTB) ,Sound waves( cough sound recordings),Yellapu et.al,Yes,"In this initial training phase, the AI model was evaluated using 10-fold cross-validation on cough recordings collected from 195 PTB-positive and 152 PTB-negative subjects, totaling 597 records. The primary performance metric was the Area Under the Receiver Operating Characteristic (ROC) Curve (AUC), reflecting the model's discriminative capability","{""AUC""}","{AUC"": 0.98}"
,,,,,,,,,,,,,,,,,,,,,,"The clinical validation involved a new cohort of 220 presumptive PTB cases. The model’s predictions were directly compared against established clinical diagnostics (CB-NAAT and chest X-ray). Performance metrics included accuracy, sensitivity, and specificity. ","{""Accuracy"", ""Sensitivity"", ""Specificity"", ""AUC""}","{""Accuracy"": 0.8682, ""Sensitivity"": 0.9036, ""Specificity"": 0.8467, ""AUC"": 0.94}"
,,,,,,,,,,,,,,,,,,,,,,"For external validation in a real-world setting, the model was tested at a peripheral healthcare facility with 65 presumptive PTB cases. The model's positive predictions were verified with laboratory confirmation. Performance was evaluated using positive predictive value (PPV), along with overall accuracy. ","{""PPV"", ""AUC""}","{""PPV"": 0.75, ""AUC"": 0.90}"
62,"Turner, S. D.; Hulme-Lowe, C.; Nagraj, V. P.",2022,"Signature Science, LLC",Forecasting Influenza-Like Illness (ILI) during the COVID-19 Pandemic,MedRxiv,Respiratory Virology,['Influenza'],10.1101/2022.10.27.22281617,Research,"To evaluate the performance of various time series forecasting models, including autoregressive neural networks (AR-NN) and statistical models like ARIMA and ETS, for forecasting influenza-like illness (ILI) during the COVID-19 pandemic, and to explore the effectiveness of ensemble forecasting in disrupted epidemiological contexts.","The COVID-19 pandemic disrupted historical ILI patterns, making it unclear whether models developed pre-pandemic remain reliable for ILI forecasting","The COVID-19 pandemic disrupted historical ILI patterns, making it unclear whether models developed pre-pandemic remain reliable for ILI forecasting"," The study applies supervised machine learning using an autoregressive neural network (AR-NN), where past ILI values are used as input features to predict future ILI values. The model is trained using historical ILI data from the CDC FluView, and its predictions are evaluated over one to four-week forecast horizons using short and long training datasets.","The model takes lagged values of ILI as input features and passes them through a neural network with a single hidden layer, allowing it to capture nonlinear temporal patterns. The number of lagged inputs is automatically selected by minimizing the corrected Akaike Information Criterion (AICc). The model is trained weekly using rolling forecast windows, and predictions are generated for one to four-week ahead horizons. Two training data configurations were used: a long dataset (from 2010 onward) and a short dataset (from 2020 onward) to assess the impact of pre- and post-COVID patterns on model performance. Evaluation was conducted using the relative Weighted Interval Score (rWIS) and standardized ranking, comparing the AR-NN's forecasts against statistical baselines and ensemble models.",autoregressive neural network (AR-NN),https://github.com/signaturescience/fiphde,GNU General Public License v3.0,Forecasting influenza-like illness (ILI) during the COVID-19 pandemic,Weekly influenza-like illness (ILI) percentages reported by healthcare providers,CDC FluView / ILINet Data,Yes,"For the autoregressive neural network (AR-NN), performance was gauged by its relative Weighted Interval Score (rWIS) measuring forecast accuracy relative to a naïve baseline and by its standardized rank (0 = worst to 1 = best) across every combination of location, forecast date, and 1-4-week horizon. Each week, the AR-NN was retrained on either the “short” (since Jan 2020) or “long” (since Oct 2010) ILI series, then used to produce 1-4-week-ahead probabilistic forecasts. The rWIS was computed via the evalcast package in R, and for each forecasted observation the AR-NN’s score was compared to other models to assign a standardized rank.","{""rWIS_variability"", ""standardized_rank_above_0.9_proportion""}","{""rWIS_variability"": ""high"", ""standardized_rank_above_0.9_proportion"": 0.25}"
63,"P, P.; Rudraraju, G.; Sripada, N. R.; Mamidgi, B.; Gottipulla, C.; Jalukuru, C.; Palreddy, S.; Bhoge, N. K. R.; Firmal, P.; Yechuri, V.; Sudhakar, P. V.; B, D. M.; S, S.; K, K. L. P.; Joshi, N.",2022,"Andhra Medical College, Visakhapatnam, India",Screening COVID-19 by Swaasa AI Platform using cough sounds: A cross-sectional study,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2022.11.02.22281821,Research,"Development of a cost-effective, instantaneous testing platform for COVID-19 using cough sounds","Current COVID-19 screening methods are costly, slow, and not scalable, and existing AI tools using cough data lack clinical validation and reliable datasets for real-world use.","To develop an AI model that can analyze cough sounds and symptom data to accurately detect the likely presence of COVID-19, enabling rapid, remote, and scalable screening.","The study uses a multimodal machine learning approach, combining deep learning (CNN) on spectrograms and a tabular model trained on time- and frequency-domain features. The final prediction is made by merging the outputs of both models.","The Swaasa AI platform uses a multimodal architecture that combines two models: a Convolutional Neural Network (CNN) and a tabular model. Cough sounds are first converted into Mel-frequency cepstral coefficient (MFCC) spectrograms, which are used as input to a pretrained CNN (ResNet34 via transfer learning). In parallel, time and frequency domain features such as zero-crossing rate, energy, spectral centroid, chroma, and tonnetz are extracted and used to train a tabular model. After individual training, the final layers of both models are merged into a shared fully connected layer referred to as combined logic which produces a single output predicting whether COVID-19 is likely, unlikely, or inconclusive. Feature selection techniques like correlation analysis and recursive feature elimination were applied to reduce redundancy and improve performance.",Swaasa AI Platform(Multimodal Deep Learning (Hybrid)),No,No,COVID-19 screening and early detection using cough sounds,"cough sound recordings, demographic details, and symptom information",Padmalatha et.al,Yes,"In the validation phase, the study measured the diagnostic accuracy, sensitivity, specificity, and AUC of the Swaasa AI platform in detecting COVID-19 compared to RT-PCR test results. The goal was to evaluate how reliably the AI could identify COVID-positive and negative individuals using a single cough sample. each subject provided one cough recording, which was analyzed by the AI model. The model’s prediction (yes/no/inconclusive) was compared to the result from RT-PCR, the clinical gold standard. Metrics such as accuracy, sensitivity, specificity, and AUC were calculated using a confusion matrix and Clopper-Pearson method for confidence intervals.","{""accuracy"", ""sensitivity"", ""specificity"", ""area_under_curve""}","{""accuracy"": 75.54, ""sensitivity"": 95.45, ""specificity"": 73.46, ""area_under_curve"": ""> 0.85""}"
,,,,,,,,,,,,,,,,,,,,,,"In the pilot phase, the main metric assessed was the positive predictive value (PPV), which reflects how effectively the tool can prioritize individuals for confirmatory testing in a real-world healthcare setting. This phase focused on the tool’s practical performance in screening presumptive cases before formal diagnosis. the AI model was deployed in a live primary care setting where it screened 183 presumptive COVID-19 patients. The number of true positives identified among those predicted positive was used to compute the positive predictive value, assessing the model's usefulness as a pre-screening tool.","{""positive_predictive_value""}","{""positive_predictive_value"": 70.73}"
64,"Hu, Z.; Ge, Q.; Li, S.; Jin, L.; Xiong, M.",2020,"State Key Laboratory of Genetic Engineering and Innovation Center of Genetics and Development, School of Life Sciences, Fudan University, Shanghai, China",Evaluating the effect of public health intervention on the global-wide spread trajectory of Covid-19,MedRxiv,Respiratory Virology,['COVID-19'],10.1101/2020.03.11.20033639,Research,To develop a model-based approach for predicting the trajectory of COVID-19 epidemics under various intervention scenarios.,The rapid spread of COVID-19 poses significant challenges to public health systems worldwide. This study aims to address this problem by developing a predictive model that can forecast the epidemic's trajectory and inform policy decisions.,design a modified auto-encoder (MAE) model that can accurately predict future COVID-19 case trends using real-world surveillance data and simulate various public health intervention strategies. ,"The study follows a supervised learning approach using time-series data, where a Modified Auto-Encoder (MAE) is trained to forecast future COVID-19 cases. The methodology includes transfer learning to leverage information from data-rich regions (like China) and applies the model to other countries with less available data. The approach also introduces an intervention variable to simulate and quantify the effect of different public health measures.","The Modified Auto-Encoder (MAE) is a neural network architecture adapted for time-series prediction. It takes as input the historical COVID-19 case data and an intervention variable representing the intensity of public health measures (e.g., 0 for no intervention, 1 for full intervention, and values in between for partial measures). The MAE is trained to minimize forecasting errors over one-step to five-step prediction intervals. The model's performance was validated using real data from WHO reports, showing forecasting errors of less than 5%. It enables scenario analysis for different intervention strategies and quantifies their effects on the pandemic’s progression.",Modified Auto-Encoder (MAE),https://github.com/wenrurumon/stnn/blob/master/project/,No,Epidemic forecasting and intervention modeling for COVID-19,"Historical epidemiological data, World Health Organization (WHO) COVID-19 situation reports",Hu et.al,Yes,The performance of the Modified Auto-Encoder (MAE) was evaluated using forecasting error over a range of future time steps (from one-step to five-step forecasts). This was done by comparing predicted values of cumulative confirmed COVID-19 cases against actual reported values.,"{""forecasting_accuracy""}","{""forecast_steps"": [""1-step"", ""2-step"", ""3-step"", ""4-step"", ""5-step""], ""evaluated_scope"": ""102 countries"", ""max_forecasting_error_percent"": 5.0}"
