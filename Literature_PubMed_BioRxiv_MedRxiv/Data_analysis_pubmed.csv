Sl.No,Authors,Year of publication,Primary affiliation of primary author,Title of article,Name of Publication/Journal,Subdomain,Disease Name,Type of Evidence Source,Research Aim,Research Problem,AI Objective,AI Methodology,AI Method Details,AI Method Type,Is software publicly released?,Software License,Virology AI task addressed,Type of Underlying Data,Dataset Name,Was Performance Measured,How was Performance measured and What was measured?,Performance Metrics,Performance score,
1,"Ong SQ, Ahmad H, Nair G, Isawasan P, Majid AHA.",2021,"UOW Malaysia KDU Penang University College, 32, Jalan Anson, 10400, George Town, Pulau Pinang, Malaysia. songguan26@gmail.com.",Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time,Sci Rep,arboviral virology,['Dengue fever'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","The primary aim of the research is to develop a highly accessible deep learning (DL) model for classifying Aedes aegypti and Aedes albopictus mosquitoes, which are significant vectors of diseases like dengue fever. The study also aims to implement this model on hardware for real-time mosquito classification and evaluate its performance against human expert performance, with a focus on identifying mosquitoes that have age-related morphological changes, especially the loss of key features on the thorax.","Accurate classification is crucial for controlling the spread of diseases like dengue, as different mosquito species require different control strategies. Existing methods are time-consuming and not suitable for real-time field applications, highlighting the need for an automated, efficient model for mosquito identification in practical settings.","The objective of the AI in this study is to develop an automated deep learning model that can accurately classify Aedes aegypti and Aedes albopictus mosquitoes, even in cases where key morphological features are missing, in real-time, and deploy it on hardware for field use.","The methodology involves using deep convolutional neural networks (DCNNs) with transfer learning on a dataset of mosquito images, focusing on fine-tuning hyperparameters like the learning rate and number of epochs for optimal accuracy. The model is implemented through a web-based tool (Teachable Machine 2.0) for easy deployment on hardware (Aedes Detector) for real-time mosquito classification.","The study uses MobileNet, a lightweight deep convolutional neural network (DCNN), with transfer learning to classify Aedes aegypti and Aedes albopictus mosquitoes. The model leverages a pre-trained MobileNet model for feature extraction, fine-tuned on a custom dataset of 4,120 mosquito images. Key hyperparameters like learning rate (LR) and epochs are optimized for the best accuracy. The model is then deployed in real-time on hardware (Aedes Detector) using the p5.js platform for efficient, field-ready mosquito classification.",MobileNet Deep Convolutional Neural Network (DCNN) with Transfer Learning,https://www.kaggle.com/pradeepisawasan/aedes-mosquitos ,CC BY-NC-SA 4.0,"classification of mosquito species, specifically Aedes aegypti and Aedes albopictus, which are vectors of diseases like dengue fever", Mosquito Images,Ong et.al,Yes,"The performance of the mosquito classification model was assessed by focusing on the lateral view of the mosquitoes' thorax and head, which are key features for distinguishing between species. A hyperparameter analysis, adjusting factors like learning rate and epochs, was conducted to optimize the model’s accuracy. The findings were consistent with previous studies, confirming the importance of these parameters for achieving high performance in classification tasks.",{'Accuracy'},{'Accuracy': 0.98},
2,"Agarwal M, Agarwal S, Saba L, Chabert GL, Gupta S, Carriero A, Pasche A, Danna P, Mehmedovic A, Faa G, Shrivastava S, Jain K, Jain H, Jujaray T, Singh IM, Turk M, Chadha PS, Johri AM, Khanna NN, Mavrogeni S, Laird JR, Sobel DW, Miner M, Balestrieri A, Sfikakis PP, Tsoulfas G, Misra DP, Agarwal V, Kitas GD, Teji JS, Al-Maini M, Dhanjil SK, Nicolaides A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Yadav RR, Nagy F, Kincses ZT, Ruzsa Z, Naidu S, Viskovic K, Kalra MK, Suri JS.",2022,"Department of Computer Science Engineering, Bennett University, India.",Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0,Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Multicenter Study","The aim of the study is to develop and evaluate  COVLIAS 2.0, an AI system utilizing pruned deep learning models optimized with evolutionary algorithms to achieve high accuracy while drastically reducing storage requirements and processing time, making it suitable for real-time clinical applications.",improving the efficiency of deep learning models for COVID-19 lung segmentation and lesion localization in CT scans while maintaining their accuracy.,"The objective of the AI in this study is to optimize deep learning models used for COVID-19 lung segmentation and lesion localization in CT scans by reducing the number of parameters without compromising their accuracy, storage efficiency, and processing speed. The goal is to develop a pruned AI model that can perform real-time analysis with minimal computational resources, making it feasible for use in clinical settings where rapid and accurate diagnosis is essential.","This study uses pruned deep learning models to improve COVID-19 lung segmentation and lesion localization in CT scans. Two base models, Fully Convolutional Networks (FCN) and SegNet, are initially trained. Then, evolutionary algorithms like Differential Evolution (DE), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Whale Optimization (WO) are applied to prune redundant parameters, reducing model size while maintaining performance. The pruned models are evaluated on CroMed and NovMed datasets and compared with MedSeg. For lesion localization, the segmented lung regions are passed through DenseNet-121, a convolutional neural network (CNN), which classifies the regions based on the presence of lesions. To further highlight lesion areas, the Grad-CAM technique is used, producing heatmaps that emphasize the regions most affected by COVID-19. The pruned, optimized models capable of performing both lung segmentation and lesion detection are then deployed for real-time clinical application, providing a high-speed, storage-efficient solution for COVID-19 diagnosis. ","In FCN-DE, the Differential Evolution (DE) algorithm optimizes the structure of the Fully Convolutional Network (FCN) by evolving a population of candidate solutions (models) over several generations. The DE algorithm uses mutation, crossover, and selection to modify the model’s weights and structure. During the pruning phase, neurons and layers that contribute minimally to the network's performance are eliminated, reducing the model’s size and enhancing its speed. The fitness of each candidate is evaluated based on accuracy and model compression, and the best solution is selected for further evolution.",FCN-DE ['Fully Connected Network with differential evolution (DE)'],No,No,COVID-19 lung segmentation and lesion localization in CT (computed tomography) scans of COVD-19 patients,chest CT scans ,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.93, 'Jaccard Index': 0.88, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity:0.93', 'Jaccard Index:0.87', 'Correlation Coefficient:0.99'}",
,,,,,,,,,,,,,"FCN-GA uses the Genetic Algorithm to prune a Fully Convolutional Network by selecting the best-performing models from a population of candidate solutions. The algorithm optimizes the network by evolving its structure, reducing unnecessary components and ensuring high performance, leading to an efficient and compact model for lung segmentation",FCN-GA (Fully Convolutional Network with Genetic Algorithm),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.93, 'Jaccard Index': 0.87, 'Correlation Coefficient': 0.94}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.88, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,"In FCN-PSO, Particle Swarm Optimization (PSO) is used to prune the Fully Convolutional Network by treating each particle in the swarm as a potential solution (model configuration). Each particle represents a specific arrangement of the network's neurons and layers, and through iterative movements in the search space, PSO adjusts the model's structure. The particles are attracted toward the best solutions, pruning unnecessary neurons and layers to improve both model efficiency and speed while maintaining accuracy. The optimization objective is to maximize segmentation performance while minimizing model size.",FCN-PSO (Fully Convolutional Network with Particle Swarm Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.92, 'Jaccard Index': 0.86, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.91, 'Jaccard Index': 0.84, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,"In FCN-WO, Whale Optimization (WO) algorithm is used to prune the Fully Convolutional Network by simulating the behavior of humpback whales hunting prey. The WO algorithm adjusts the architecture of the FCN by iteratively exploring and exploiting possible network configurations. It uses a spiral search pattern to remove redundant layers and neurons, with the best solution being selected based on accuracy and compression. The algorithm ensures that while pruning, the network maintains high segmentation performance and is optimized for speed and storage efficiency.",FCN-WO (Fully Convolutional Network with Whale Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"In SegNet-DE, the Differential Evolution algorithm is used to optimize the SegNet architecture. The DE algorithm evolves the SegNet model by generating a population of solutions and applying mutation, crossover, and selection to refine the network. Each candidate model undergoes pruning by removing unnecessary neurons and layers, with the fitness of each model evaluated based on segmentation accuracy and storage efficiency. The DE algorithm helps reduce the network's size while ensuring that the performance is not compromised.",SegNet-DE (SegNet with Differential Evolution),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}"," {'Dice Similarity': 0.96, 'Jaccard Index': 0.92, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"In SegNet-GA, the Genetic Algorithm (GA) prunes the SegNet architecture by evolving a population of models over several generations. The GA uses genetic operations such as selection, crossover, and mutation to modify the structure of the SegNet network. By iteratively removing unnecessary neurons and layers, the GA optimizes the model's size and performance. The fitness of each model is determined by its segmentation accuracy and the reduced size, with the most efficient solution being selected for further evaluation.",SegNet-GA (SegNet with Genetic Algorithm),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.96, 'Jaccard Index': 0.93, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,"In SegNet-PSO, Particle Swarm Optimization (PSO) is employed to prune the SegNet model by optimizing its architecture. PSO treats each particle as a potential solution, adjusting the network’s layers and neurons through iterative movements based on the fitness of the solutions. The swarm collectively searches for the optimal model configuration, pruning unnecessary components to reduce the model size while retaining segmentation accuracy. The process continues until an efficient and high-performing model is found.",SegNet-PSO (SegNet with Particle Swarm Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.96, 'Jaccard Index': 0.94, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.95, 'Jaccard Index': 0.91, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"In SegNet-WO, Whale Optimization (WO) is applied to prune the SegNet architecture. WO simulates the foraging behavior of humpback whales to explore different configurations of the SegNet model. By removing unnecessary neurons and layers, the algorithm optimizes the SegNet network’s size and performance. The optimization process ensures that the SegNet model is both storage-efficient and fast while preserving its accuracy in segmentation tasks.",SegNet-WO (SegNet with Whale Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.96, 'Jaccard Index': 0.94, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.95, 'Jaccard Index': 0.91, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"Lesion detection in this study is performed using DenseNet-121 and Grad-CAM. DenseNet-121 is a deep convolutional neural network that classifies segmented lung regions into ""COVID-19"" or ""Control."" After lung segmentation, the segmented regions are passed through DenseNet-121, which identifies the presence of lesions. Grad-CAM is then applied to generate heatmaps that highlight the regions in the CT scan most responsible for the model’s decision, emphasizing areas with lesions. This combination helps accurately localize and visualize COVID-19-related lesions in the lungs, aiding in clinical diagnosis.",Lesion Detection using DenseNet-121 and Grad-CAM,,,,,CroMed data set,Yes,"the performance metrics in the traditional sense (such as Dice and Jaccard) are not provided, and it is likely that the focus was more on the qualitative evaluation of the generated heatmaps rather than quantitative performance metrics.","The qualitative performance of lesion detection was assessed using Grad-CAM generated heatmaps with the DenseNet-121 model. These heatmaps visually highlighted COVID-19 lesions, such as ground-glass opacities, by overlaying them on the segmented lung regions in CT scans. This approach helped identify the affected areas, aiding clinical decision-making and improving the interpretability of the AI model's predictions.","The qualitative performance of lesion detection was assessed using Grad-CAM generated heatmaps with the DenseNet-121 model. These heatmaps visually highlighted COVID-19 lesions, such as ground-glass opacities, by overlaying them on the segmented lung regions in CT scans. This approach helped identify the affected areas, aiding clinical decision-making and improving the interpretability of the AI model's predictions.",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"the performance metrics in the traditional sense (such as Dice and Jaccard) are not provided, and it is likely that the focus was more on the qualitative evaluation of the generated heatmaps rather than quantitative performance metrics.","The qualitative performance of lesion detection was assessed using Grad-CAM generated heatmaps with the DenseNet-121 model. These heatmaps visually highlighted COVID-19 lesions, such as ground-glass opacities, by overlaying them on the segmented lung regions in CT scans. This approach helped identify the affected areas, aiding clinical decision-making and improving the interpretability of the AI model's predictions.","The qualitative performance of lesion detection was assessed using Grad-CAM generated heatmaps with the DenseNet-121 model. These heatmaps visually highlighted COVID-19 lesions, such as ground-glass opacities, by overlaying them on the segmented lung regions in CT scans. This approach helped identify the affected areas, aiding clinical decision-making and improving the interpretability of the AI model's predictions.",
3,"Gidde PS, Prasad SS, Singh AP, Bhatheja N, Prakash S, Singh P, Saboo A, Takhar R, Gupta S, Saurav S, M V R, Singh A, Sardana V, Mahajan H, Kalyanpur A, Mandal AS, Mahajan V, Agrawal A, Agrawal A, Venugopal VK, Singh S, Dash D.",2021,"CSIR-Central Electronics Engineering Research Institute, Pilani, Rajasthan, 333031, India.",Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays,Sci Rep,Respiratory Virology,['COVID-Pneumonia'],"Journal Article, Research Support, Non-U.S. Gov't, Validation Study","The primary aim of this research is to develop CovBaseAI, an explainable tool for diagnosing COVID-Pneumonia from Chest X-rays (CxR) using an ensemble of deep learning (DL) models and an expert decision system (EDS).","This research seeks to address the challenge of diagnosing COVID-19 pneumonia from Chest X-rays using AI models trained on pre-COVID datasets, with a focus on ensuring explainability and generalizability across varied clinical environments.To develop an AI tool capable of accurately diagnosing COVID-19 pneumonia from Chest X-rays, even when trained on pre-COVID datasets.","To develop AI system for the detection of COVID-19 pneumonia from Chest X-rays. The system uses an ensemble of three deep learning models (lung segmentation, opacity detection, and pathology detection) along with an expert decision system to accurately classify COVID-19 likelihood. The system's objective is to achieve high performance, particularly in real-time screening and triaging scenarios, minimizing false negatives and false positives.","The AI methodology in this study involves the development of CovBaseAI, an explainable tool for diagnosing COVID-19 pneumonia from Chest X-rays. It combines three deep learning modules: a lung segmentation module using modified U-Net, a lung opacity detection module based on Faster R-CNN, and a pathology detection module using DenseNet-201. These modules independently analyze the CxR images, with outputs fed into an Expert Decision System (EDS) to classify the likelihood of COVID-19 pneumonia. The model was validated on two independent datasets and evaluated using various metrics, including sensitivity, specificity, accuracy, and AUC. The combination of deep learning and expert rules ensures both performance and explainability.","The AI method employed in this study consists of three main deep learning modules combined with a rule-based expert decision system. First, for lung segmentation, a modified U-Net architecture is used, where the encoder part is replaced with a VGG16 network pre-trained on ImageNet to speed up convergence and prevent overfitting. The U-Net model processes the chest X-ray images to produce binary lung masks. Second, for lung opacity detection, a Faster R-CNN architecture is applied. Faster R-CNN is a two-stage object detection method where the first stage generates region proposals, and the second stage classifies these proposals. It uses a VGG16 network as the backbone for feature extraction and is trained to detect opacity regions within the lung images. Third, for pathology detection, a DenseNet-201 model is utilized. DenseNet-201 is a convolutional neural network with dense connections between layers, which allows for better feature reuse and more accurate classification. The pathology detection module outputs probabilities for each pathology, including signs of pneumonia, which is integrated into the expert decision system. Finally, the rule-based expert decision system (EDS) classifies the X-ray image into three categories: COVID-likely, indeterminate, or COVID-unlikely, based on the outputs from the deep learning models. The EDS is fully explainable and modifiable, using rules derived from radiologists’ consensus to aid in accurate and interpretable diagnosis.",[' CovBaseAI - ensemble model combining deep learning techniques'],No,No,COVID-19 pneumonia detection,Chest X-Ray,IITAC1.4K,Yes,"The model's performance was assessed by comparing its predictions against radiologist annotations for COVID likelihood using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}","{""Sensitivity"": 0.90, ""Specificity"": 0.86, ""PPV"": 0.41, ""NPV"": 0.98, ""F1 Score"": 0.57, ""Accuracy"": 0.87, ""MCC"": 0.56, ""AUC"": 0.88}",
,,,,,,,,,,,,,,,,,,,PD1K,Yes,"Prediction output of the CovBaseAI model was compared against pneumonia consolidation label annotated by radiologists instead of their RT-PCR status using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}"," {""Sensitivity"": 0.84, ""Specificity"": 0.81, ""PPV"": 0.83, ""NPV"": 0.81, ""F1 Score"": 0.84, ""Accuracy"": 0.82, ""MCC"": 0.65, ""AUC"": 0.89}",
,,,,,,,,,,,,,,,,,,,CID1K,Yes,The model's predictions were compared against RT-PCR results to assess its diagnostic accuracy in distinguishing COVID-19 infection from other conditions.,"{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}"," {""Sensitivity"": 0.66, ""Specificity"": 0.57, ""PPV"": 0.59, ""NPV"": 0.64, ""F1 Score"": 0.62, ""Accuracy"": 0.61, ""MCC"": 0.23, ""AUC"": 0.63}",
,,,,,,,,,,,,,,,,,,,CPD600,Yes,"The model’s ability to identify COVID pneumonia was evaluated by comparing its outputs against the combined RT-PCR and radiologist diagnoses using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}","{""Sensitivity"": 0.83, ""Specificity"": 0.77, ""PPV"": 0.79, ""NPV"": 0.81, ""F1 Score"": 0.81, ""Accuracy"": 0.80, ""MCC"": 0.60, ""AUC"": 0.83}",
,,,,,,,,,,,,,,,,,,,COVIDx1K,Yes,"The model's generalization performance across different geographical regions and datasets was evaluated. The COVIDx1K dataset provided an independent validation set to assess how CovBaseAI would perform on data that it had never seen before, thus testing its robustness and adaptability to new environments using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}","{""Sensitivity"": 0.78, ""Specificity"": 0.97, ""PPV"": 0.79, ""NPV"": 0.97, ""F1 Score"": 0.78, ""Accuracy"": 0.95, ""MCC"": 0.76, ""AUC"": 0.89}",
4,"Soe NN, Yu Z, Latt PM, Lee D, Samra RS, Ge Z, Rahman R, Sun J, Ong JJ, Fairley CK, Zhang L.",2024,"Artificial Intelligence and Modelling in Epidemiology Program, Melbourne Sexual Health Centre, Alfred Health, Melbourne, Australia.",Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study,J Med Internet Res,Emerging & Re-emerging Viruses,['Monkeypox'],"Journal Article, Validation Study",Develop and evaluate an artificial intelligence (AI) based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic,"Given the overlap in appearance between mpox and other sexually transmitted infections (STIs) or skin conditions, there is a need for an automated, AI-driven solution that can reliably differentiate mpox lesions from other skin pathologies.","The objective of the AI in this study is to develop an automated deep learning model for accurately differentiating mpox lesions from other common skin lesions (STIs and non-STIs) based on lesion images. This system should help in early diagnosis, optimize clinic workflows, and assist healthcare professionals in triaging suspected mpox cases in a sexual health clinic setting.","The methodology employed in this study to develop an AI-based tool for differentiating mpox lesions from other skin lesions in a sexual health clinic involved multiple stages. Initially, a dataset of 2200 images, comprising both mpox and non-mpox lesions, was collected from the Melbourne Sexual Health Centre (MSHC) and web resources. These images were carefully labeled by two experienced sexual health physicians to ensure accurate diagnosis. The dataset was then partitioned into training, testing, and external validation subsets. A transfer learning approach was applied using six different pre-trained deep learning architectures, including MobileNet-V2, ShuffleNet-V2, DenseNet-121, ResNet-18, ResNet-34, and Swin-Transformer. To address class imbalance, data augmentation techniques were applied to the training and validation dataset, increasing the number of mpox images. A 5-fold cross-validation was implemented to improve the robustness and generalizability of the models. The overall AI methodology combined the strengths of deep learning models with preprocessing techniques to accurately classify mpox lesions, demonstrating significant improvements in diagnostic accuracy for sexual health clinic settings.","The study used Deep Learning (DL) techniques for classifying mpox and non-mpox lesions from skin images, focusing on the application of Transfer Learning. In this method, pre-trained deep neural networks (DNNs) were fine-tuned on the mpox dataset. The six models selected for the study included MobileNet-V2, ShuffleNet-V2, DenseNet-121, ResNet-18, ResNet-34, and Swin-Transformer. These models were chosen due to their varying parameter sizes, allowing for comparison across different architectures in terms of performance. During training, the models were optimized using the Adam optimizer and trained with a cross-entropy loss function. A batch size of 72 was used, with a dropout rate of 0.2, and training was carried out for 150 epochs. The training utilized a 5-fold cross-validation strategy to ensure robust evaluation and to reduce overfitting by validating the models on different subsets of the training data.  This helps to reduce the model's bias and ensures it generalizes well to unseen data.Additionally, during Transfer Learning, the weights of the backbone layers of the pre-trained models were frozen. Freezing the weights means that the weights in the initial layers, which capture general features like edges and textures, were not updated during training. Instead, only the final classification layers (which are specific to the mpox vs. non-mpox task) were fine-tuned. This approach helps to retain the general knowledge acquired during pre-training and focuses learning on the task-specific layers.",['Deep learning - Convolutional Neural Networks architectures'],https://github.com/pytorch/vision/tree/main/torchvision/models,BSD 3-Clause License,differentiation of mpox lesions from other common skin lesions using AI-based image recognition,Clinical Images,Monkeypox dataset,Yes,"The trained models were evaluated using various performance metrics, including AUC (Area Under the Curve), accuracy, precision, recall, and F1-score. These metrics helped assess how well the model could distinguish mpox lesions from other lesions. The model’s generalizability was tested by evaluating its performance on an external validation dataset (mpox images sourced from Kaggle). This dataset had not been seen during training and provided insights into how well the model could adapt to new, unseen data.","{'AUC', 'accuracy', ' precision', 'recall', 'F1-score'}","{""ResNet-18"": {""AUC"": 0.990, ""Accuracy"": 0.947, ""Precision"": 0.934, ""Recall"": 0.953, ""F1-score"": 0.943}, 
               ""DenseNet-121"": {""AUC"": 0.982, ""Accuracy"": 0.926, ""Precision"": 0.906, ""Recall"": 0.939, ""F1-score"": 0.922}, 
               ""MobileNet-V2"": {""AUC"": 0.985, ""Accuracy"": 0.937, ""Precision"": 0.911, ""Recall"": 0.959, ""F1-score"": 0.934}, 
               ""ShuffleNet-V2"": {""AUC"": 0.963, ""Accuracy"": 0.923, ""Precision"": 0.925, ""Recall"": 0.910, ""F1-score"": 0.917}, 
               ""ResNet-34"": {""AUC"": 0.974, ""Accuracy"": 0.908, ""Precision"": 0.887, ""Recall"": 0.920, ""F1-score"": 0.903}, 
               ""Swin-Transformer"": {""AUC"": 0.979, ""Accuracy"": 0.912, ""Precision"": 0.944, ""Recall"": 0.862, ""F1-score"": 0.901}}",
5,"Saleem F, Al-Ghamdi ASA, Alassafi MO, AlGhamdi SA.",2022,"Department of Information System, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah 21589, Saudi Arabia.","Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review",Int J Environ Res Public Health,Respiratory Virology,"[""SARS-CoV-2""]","Journal Article, Review, Systematic Review, Research Support, Non-U.S. Gov't","This research provides a systematic literature review and analysis of ML, DL, and mathematical models for different purposes such as predicting future cases, analyzing previous infected cases, estimating basic reproduction numbers and virus doubling time.","This research seeks to address the gaps in understanding the comparative performance, generalizability, and limitations of existing ML and DL techniques used in COVID-19 forecasting, detection, and epidemiological analysis.",To systematically review the application of Machine Learning (ML) and Deep Learning (DL) techniques to analyze COVID-19 data and predict its impact. ,"The AI methodology followed in this study is a Systematic Literature Review (SLR) approach. The methodology involves identifying, analyzing, and synthesizing existing research studies that used ML and DL techniques to tackle various aspects of COVID-19. These techniques include predictive models for infection rates, the automatic detection of COVID-19 cases from medical images, and the application of mathematical models for understanding epidemic dynamics. The process follows PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to ensure a comprehensive and systematic collection of relevant papers. The review examines multiple AI techniques, including support vector machines (SVM) for classification, convolutional neural networks (CNN) for medical image analysis, and long short-term memory (LSTM) networks for time-series forecasting. The studies also assess various mathematical models, such as SIR (Susceptible, Infected, Recovered), SEIR, and ARIMA, that help estimate important epidemiological parameters.","In the review paper, Deep Learning (DL) methods are extensively used for automating COVID-19 detection, classification, and forecasting. Convolutional Neural Networks (CNNs) are the most widely applied DL models for medical image classification, especially in detecting COVID-19 from chest X-rays (CXR) and CT scans. CNNs, including models like ResNet-101 and Xception, excel in automatically extracting relevant features from medical images, achieving high accuracy levels, often exceeding 99%, when used with transfer learning. Additionally, Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), are employed for time-series forecasting to predict the spread of COVID-19 cases, often combined with models like ARIMA for improved long-term predictions. ",['Deep Learning'],No,No,"summary of ML and DL techniques for prediction, detection, and treatment of COVID-19 "," research papers related to the epidemiology of COVID-19,  machine learning (ML), deep learning (DL) approaches, and mathematical models for forecasting, detection, and analysis of COVID-19 cases.",Saleem et.al,No,The review paper provided an overview of how the performance of these models was evaluated across different studies.,,,
6,"Klein AZ, Magge A, O'Connor KMS, Cai H, Weissenbacher D, Gonzalez-Hernandez G.",2020,"Department of Biostatistics, Epidemiology, and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.",A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter,medRxiv,Respiratory Virology,['COVID-19'],"Preprint, Journal Article","Develop and evaluate a social media mining framework using natural language processing (NLP) and machine learning to automatically detect personal reports related to COVID-19 on Twitter, and analyze their chronological and geographical distribution in the United States","There is a lack of real-time, individual-level surveillance data, which hampers early detection and response. Although social media platforms like Twitter are widely used and contain user-generated content related to COVID-19, previous efforts had not utilized this data to track personal-level reports of exposure or symptoms in real time.","To design and evaluate a natural language processing and machine learning framework, specifically using a fine-tuned BERT classifier, to automatically detect and classify tweets that report probable or possible exposure to COVID-19, and to use these classifications for real-time spatio-temporal surveillance of the outbreak.
","1. Over 7 million English tweets were collected from the Twitter Streaming API (Jan–Mar 2020) using COVID-19-related keywords. After filtering, 10,000 tweets were manually annotated into three classes:
Probable: User or household member is diagnosed, tested, symptomatic, or directly exposed.
Possible: User or household member shows less-common symptoms or has high-risk exposure (e.g., travel).
Other: General COVID-19 discussion with no personal exposure.
2. A pre-trained BERT model was fine-tuned on the annotated tweets (80/20 train-test split). Preprocessing included lowercasing text, replacing usernames and URLs. The model was trained using the Adam optimizer with learning rate warm-up and decay. It was then deployed on 430,000+ unlabeled tweets to classify them as “probable,” “possible,” or “other.”
3.The classified tweets were analyzed by date and location to detect early trends in potential COVID-19 spread, even before official case reports were available in some regions.","1. A pre-trained BERT model was used with:
12 Transformer blocks
768 hidden units per layer
12 self-attention heads
Tweets were tokenized to a maximum length of 100 tokens, and the output was passed through a dropout layer (rate = 0.1) and a dense layer with softmax activation for classification.
2. Optimizer: Adam with learning rate warm-up and decay
Max Learning Rate: 1e-4 (first 10% of steps), then linearly decayed to 0
Batch Size: 64
Epochs: 3
Preprocessing: Lowercased text, replaced usernames (@user) and URLs with placeholder
3. The trained model was applied to 430,574 unlabeled tweets to classify them as “probable,” “possible,” or “other.”
Performance was evaluated on a 2,000-tweet test set using precision, recall, and F1-score as metrics.",Fine-tuned BERT-based deep neural network classifier,https://huggingface.co/google-bert/bert-base-uncased,Apache License 2.0,Using social media to detect and monitor the early spread of a viral outbreak (COVID-19) through individual-level exposure reports.,Text data from Twitter, Klein et.al,Yes,"Performance was evaluated using standard classification metrics on a held-out test set of 2,000 manually annotated tweets. The model's predictions were compared to human-annotated ground truth labels. Accuracy of classifying tweets into probable, possible, or other categories of COVID-19 exposure by using precision, recall and f1-score.","{pecision, F1-score,recall}","{""probable"": {""precision"": 0.69, ""recall"": 0.61, ""f1_score"": 0.64}, ""possible"": {""precision"": 0.54, ""recall"": 0.52, ""f1_score"": 0.53}, ""probable_and_possible_combined"": {""precision"": 0.70, ""recall"": 0.67, ""f1_score"": 0.68}}",
7,"Ai Y, He F, Lancaster E, Lee J.",2022,"Department of Food Science and Technology, The Ohio State University, Columbus, OH, United States of America.",Application of machine learning for multi-community COVID-19 outbreak predictions with wastewater surveillance,PLoS One,Respiratory Virology,['SARS-CoV-2'],"Review, Journal Article, Research Support, Non-U.S. Gov't",Develop predictive models that estimate COVID-19 case trends using wastewater-based epidemiology (WBE) data.,"Current wastewater-based COVID-19 prediction models lack robustness and generalizability due to limited feature use, temporal inattention, and high variability across diverse sewersheds.","To develop and evaluate machine learning and deep learning models, non-time series models as well as time-series models like LSTM and Prophet, for accurate short-term prediction of COVID-19 case trends across multiple diverse sewersheds using wastewater surveillance data.","The study applied both non-time-series (Linear Regression, Gradient Boosting Decision Tree, Deep Neural Network) and time-series models (Facebook Prophet, LSTM) to predict short-term COVID-19 case trends using wastewater surveillance data from nine diverse sewersheds. A range of domain-specific features such as viral loads, biochemical wastewater parameters, geographical data, and socioeconomic indicators were extracted and processed through feature engineering. Models were trained using a 70/30 train-test split with cross-validation.","A multivariate Long Short-Term Memory (LSTM) model was used for predicting short-term COVID-19 case counts from wastewater data across 9 diverse communities. The model took 16 past time steps (8 weeks) as input and used nearly 30 features, including viral loads, biochemical wastewater parameters, geographic data, and socioeconomic indicators for prediction. The architecture included two stacked LSTM layers (64 and 32 units), followed by dense layers to combine outputs from all sewersheds. Regularization (dropout 0.05, L1/L2 value = 0.025) was adopted to LSTM layers and the Adam optimizer was employed to adapt the learning rate. Built using TensorFlow, the model achieved the best performance in terms of predictive accuracy, generalizing well across communities and capturing temporal and spatial trends.",['LSTM'],https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM,Apache 2.0,Short-term prediction of COVID-19 case trends at the community level( specific local populations) using waste water samples,"Wastewater data (chemical, physical, biological parameters)","Wastewater surveillance dataset from 9 sewersheds in central Ohio, USA, collected from September 2020 to June 2021",Yes,"The performance of the LSTM model was evaluated using a combination of methods and metrics. The dataset was split into 70% for training and 30% for testing, and a sliding window of 16 time steps (about 8 weeks) was used to capture temporal dependencies in the data. The model was trained jointly across nine different sewersheds to enhance generalization. Evaluation was conducted using key performance metrics: the coefficient of determination (R²) was used to measure model fit, with value of 0.81 for testing, indicating strong predictive performance. Additionally, root mean square error (RMSE) quantified the prediction error, while Pearson’s correlation coefficient was used to assess the strength of correlation between predicted and observed COVID-19 case trends. But the exact numbers aren't explicitly listed for RMSE and Pearson's correlation in the text for all sewersheds. LSTM outperformed other models, achieving higher predictive accuracy with a test R² of 0.81 and improved RMSE, especially when a 5-day lag was applied to the input data.",{ 'Coefficient of Determination (R-squared) },{ 'Coefficient of Determination (R-squared) : 0.81},
,,,,,,,,,,,,,"The DNN model is a non-time-series, feed-forward neural network that predicts next-day COVID-19 cases using SARS-CoV-2 viral loads and domain-specific features from wastewater, sewershed geography, and community socioeconomics. Data preprocessing included normalization and encoding. While the model captures complex relationships in the data, it lacks the ability to model temporal trends, making it less effective than LSTM for time-dependent prediction tasks.",[ 'Deep neural Network'],No,No,,"Wastewater data (chemical, physical, biological parameters)","Wastewater surveillance dataset from 9 sewersheds in central Ohio, USA, collected from September 2020 to June 2021",Yes,"The performance of the deep neural network (DNN) model was evaluated using Root Mean Square Error (RMSE) on the test set. Compared to the baseline univariate linear regression model (using only SARS-CoV-2 viral load), the DNN model showed improved prediction accuracy when additional wastewater, geographical, and socioeconomic features were included. However, exact RMSE or R² values for the DNN model were not explicitly provided in the paper, and it was outperformed by time-series models like LSTM and Prophet in terms of predictive performance.",Not specified,Not specified,
8,"Zhou X, Song S, Zhang Y, Hou Z.",2023,"School of Public Health, Fudan University, Shanghai, China.",Deep Learning Analysis of COVID-19 Vaccine Hesitancy and Confidence Expressed on Twitter in 6 High-Income Countries: Longitudinal Observational Study,J Med Internet Res,Respiratory Virology,['SARS-CoV-2'],"Observational Study, Journal Article, Research Support, Non-U.S. Gov't","Track the temporal and spatial distribution of COVID-19 vaccine hesitancy and confidence expressed on Twitter during the entire pandemic period, specifically in six major English-speaking high-income countries (United States, United Kingdom, Australia, New Zealand, Canada, and Ireland).","Despite the availability of effective COVID-19 vaccines, rising vaccine hesitancy and declining public confidence remain significant barriers to pandemic control, highlighting the need for scalable, real-time approaches such as deep learning-based social media monitoring to track and understand evolving public sentiment across regions and time.","To automatically detect and monitor COVID-19 vaccine hesitancy and confidence expressed in tweets using deep learning models, enabling real-time, large-scale, and geographically resolved analysis of public attitudes across six English-speaking countries during the pandemic.","The study collected 5.2 million English-language tweets related to COVID-19 vaccination (Jan 2020–June 2022) from six English-speaking countries using TweetScraper. A separate classification model (model type not specified) was used to filter out non-human tweets, achieving a precision of 0.89 and F1-score of 0.86. Then a domain-specific deep learning model, COVID-Twitter-BERT (CT-BERT), pretrained on 160 million COVID-related tweets, was fine-tuned using 8,073 manually annotated tweets labeled based on the WHO vaccine hesitancy framework. The model was trained to classify tweets into four categories.","COVID-Twitter-BERT (CT-BERT), a transformer-based deep learning model pretrained on 160 million COVID-related tweets, was further fine-tuned using a manually annotated dataset of 8,073 tweets specifically labeled according to the World Health Organization’s vaccine hesitancy framework. Each tweet was independently annotated by two annotators, with disagreements resolved by a third annotator to ensure labeling accuracy. The dataset was divided into training (80%), validation (10%), and test (10%) sets for model fine-tuning and evaluation. This fine-tuning enabled classification into four key categories: intent to accept or reject vaccination, and belief in vaccine effectiveness or unsafety. The fine-tuned CT-BERT model achieved strong performance across categories (F1-scores ranging from 0.73 to 0.86) and was applied to over 5.2 million English-language tweets collected between January 2020 and June 2022. Tweets were geolocated to six English-speaking countries (United States, United Kingdom, Canada, Australia, New Zealand, and Ireland) and, where possible, to U.S. states. The classified tweets were then used to analyze spatiotemporal trends in vaccine sentiment and explore associations with sociodemographic factors through bivariate and multivariable regression analysis at the U.S. state level.",['Deep Learning - Fine-tuned COVID-Twitter-BERT (CT-BERT)'],https://github.com/digitalepidemiologylab/covid-twitter-bert,MIT License.,Monitoring public sentiment and behavioral hesitancy toward COVID-19 vaccination across countries during the COVID-19 pandemic.,"weet text, timestamps, geolocation (country/state), user profile location","COVID-19 Vaccine-Related English Tweets Dataset (Jan 1, 2020 – June 30, 2022)",Yes,"The dataset was split into training (80%), validation (10%), and test (10%) sets. Model performance was measured on the held-out test set using standard classification metrics precision and F1-score for four sentiment categories: intent to accept vaccination, intent to reject vaccination, belief in vaccine effectiveness, and belief that vaccines are unsafe. The model achieved strong performance across categories, with precision ranging from 0.78 to 0.88 and F1-scores ranging from 0.73 to 0.86.","{'Precision', 'F1-score'}","{""category"": ""Intent to accept COVID-19 vaccination"", ""precision"": 0.88, ""F1-score"": 0.86},
    {""category"": ""Intent to reject COVID-19 vaccination"", ""precision"": 0.78, ""F1-score"": 0.75},
    {""category"": ""Belief that COVID-19 vaccines are effective"", ""precision"": 0.81, ""F1-score"": 0.73},
    {""category"": ""Belief that COVID-19 vaccines are unsafe"", ""precision"": 0.86, ""F1-score"": 0.75}",
9,"Rafique Q, Rehman A, Afghan MS, Ahmad HM, Zafar I, Fayyaz K, Ain Q, Rayan RA, Al-Aidarous KM, Rashid S, Mushtaq G, Sharma R.",2023,"Department of Internal Medicine, Sahiwal Medical College, Sahiwal, 57040, Pakistan. Electronic address: qandeelsawalyar@gmail.com.","Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations",Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Review, Research Support, Non-U.S. Gov't","To review and synthesize the current landscape of deep learning (DL)-based diagnostic and therapeutic approaches for COVID-19 and its variants, with a focus on exploring the integration of DL in various diagnostic modalities and the identification of synergistic drug combinations. ","consolidating existing DL-driven methods, examining their roles across diagnostics and therapeutics, and identifying critical research gaps and future directions.","The objective is to identify key DL approaches used in medical imaging, molecular testing, and synergistic drug prediction, and to evaluate their potential, limitations, and readiness for real-world implementation.","The study conducted an extensive literature survey using biomedical databases such as PubMed, Embase, Cochrane, CNKI, CBM, and Wanfang, employing targeted keywords like COVID-19, SARS-CoV-2 variants, deep learning, and synergistic medicine. The analytical framework is structured around three primary domains: the use of deep learning (DL) in diagnostic imaging (including CT scans, chest X-rays, and radiographs), DL in molecular assays and biosensor-based detection, and DL in predicting synergistic drug combinations. A diverse set of AI models is reviewed, including CNNs, DNNs, GANs, RNNs, LSTMs, and ELMs, alongside advanced frameworks like ComboNet for drug synergy prediction. These models are applied across various domains such as COVID-19 variant identification, complication prediction (e.g., cardiovascular involvement), treatment recommendation, and drug repurposing. The paper performs a thematic synthesis by categorizing AI techniques based on their application areas, data types, and model architectures. It also discusses current challenges, including issues of interpretability, generalizability, and limited data availability. ","Used for image-based diagnosis through CT scans, chest X-rays (CXR), and radiographs to detect COVID-19 and its variants. Capable of identifying pneumonia-like patterns, ground-glass opacities, and infection localization.",[CNN'],No,No,Detection and classification of COVID-19 and its variants from radiographic images.,CT and Chest X-ray (CXR) images, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,"Generalized deep architectures applied to multimodal tasks including clinical prediction, feature extraction, and multi-layered diagnostic analysis.",DNN,,,Risk prediction and identification of biomarkers associated with severe COVID-19 symptoms.,Clinical Data, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,"Employed for synthetic image generation and enhancement of limited radiological datasets, aiding in robust training for variant detection and modeling virus spread.",GAN,,,"Data augmentation, image enhancement for better COVID-19 training and visualization.",CXR and CT image data, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,"Utilized for time-series forecasting, especially for predicting COVID-19 transmission and complications (e.g., cardiovascular issues). RNN variants like GRU, CW-RNN, and LSTM improve accuracy in epidemic modeling.",RNN & LSTM,,,Time series data consisting daily case counts,"COVID-19 transmission forecasting, complications prediction", Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,Used in a medication recommendation system for predicting treatment responses in COVID-19 patients with cardiovascular risk. ELM is faster and requires fewer neurons compared to traditional backpropagation networks.,ELM,,,Predicting risk of cardiovascular complications and recommending treatments,Structured EHR data, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,A deep learning architecture that integrates drug molecular structure and target interaction to predict synergistic drug combinations. It uses graph convolutional networks (GCNs) for molecule embedding and a linear model to infer synergy scores.,ComboNet,,,Predicting synergistic combinations of drugs effective against COVID-19.,Molecular graphs, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
10,"Chen J, See KC.",2020,"Yong Loo Lin School of Medicine, National University of Singapore, Singapore, Singapore.",Artificial Intelligence for COVID-19: Rapid Review,J Med Internet Res,Respiratory Virology,['SARS-CoV-2'],"Journal Article, Review","To conduct a rapid review of the applications of artificial intelligence (AI) in the context of the COVID-19 pandemic, specifically identifying how AI has been used across healthcare domains, evaluating its benefits and limitations, and highlighting opportunities for further development.","Addressing the gap between the potential of AI in managing COVID-19 and the practical challenges in its implementation, including data limitations, validation issues, usability barriers, and ethical and legal concerns.","To explore and review how AI has been applied to various aspects of the COVID-19 response, including diagnosis, public health, clinical decision-making, and therapeutic discovery.","The study employed a rapid systematic review methodology to evaluate the application of artificial intelligence (AI) in the context of the COVID-19 pandemic. The authors conducted an extensive literature search using PubMed and EMBASE databases for English-language studies published between December 1, 2019, and March 31, 2020, using keywords related to COVID-19 and SARS-CoV-2. Additional articles were identified through reference list checks. Only primary studies that presented new data on AI applications were included, while commentaries and secondary reviews were excluded. The included studies were analyzed using thematic analysis, which grouped AI applications into four main domains: diagnosis, public health, clinical decision-making, and therapeutics. To assess the quality and transparency of reporting, the authors used a modified version of the TRIPOD (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis) statement, and evaluated risk of bias using the PROBAST (Prediction model Risk Of Bias ASsessment Tool). The review revealed significant variability in methodological rigor among studies, with poor internal and external validation being common issues. The authors synthesized their findings through narrative discussion and tabular summaries, identifying major strengths and limitations in the current use of AI for COVID-19. Overall, the methodology provided a structured, critical overview of how AI has been deployed in pandemic response, highlighting areas for improvement and future development.","COVNet is a 3D deep convolutional neural network (CNN) framework developed specifically for automatic COVID-19 diagnosis using chest CT scans. It combines both 2D slice-level features and 3D volumetric information from CT scan series to classify patients into COVID-19 positive, community-acquired pneumonia (CAP), or no infection. The network architecture likely includes multiple convolutional layers followed by pooling and fully connected layers. COVNet outputs a probability score for COVID-19 presence. Once trained, it can rapidly analyze each CT scan in under 5 seconds, aiding in high-throughput triage.",COVNet,No,No,Diagnosis of COVID-19 from chest CT scans,chest CT scans ,Chen et.al,Yes,Model's ability to correctly classify COVID-19 cases (true positive rate) and exclude non-COVID cases (true negative rate) was evaluated using sensitivity and specificity metrics.,"{""Sensitivity"", ""Specificity""}","{""Sensitivity: 90%"", ""Specificity: 96%""}",
,,,,,,,,,,,,,"A recurrent neural network (RNN)-based model was developed to simulate the epidemiological trend of COVID-19, trained using prior SARS outbreak data and updated with intervention strategies such as lockdowns. This model accurately predicted case peaks and mirrored real-time trends in Hubei, China, thereby supporting early intervention planning. Another application involved using an artificial neural network (ANN) to predict clinical outcomes (death or recovery) based on demographic data in South Korea. These DL models were valuable in epidemiological modeling and risk stratification, contributing to data-driven policymaking during the pandemic.",Recurrent Neural Network,No,No,COVID-19 outbreak prediction,,,No,,,,
,,,,,,,,,,,,,"The MT-DTI model, based on transformer-based natural language processing, predicted binding affinities between SARS-CoV-2 proteins and approved drugs, identifying atazanavir as a strong inhibitor. Another DL method, Deep Docking, rapidly screened 1.3 billion compounds from the ZINC15 database to identify top potential binders for the main protease (Mpro) of SARS-CoV-2. Additionally, deep learning was integrated with molecular docking to evaluate traditional Chinese medicine compounds, suggesting several herbal candidates for further testing. These DL applications dramatically accelerated in silico drug discovery by prioritizing molecules for laboratory validation and clinical testing.",Transformer based model,Yes,No,COVID-19 therapeutics and drug discovery,target proteins.,Chen et.al,Yes,The model's predictive performance was assessed using metrics such as Mean Squared Error (MSE) and Concordance Index (CI).? Specific numerical details are not provided,,,
,,,,,,,,,,,,,"A DL-based predictive model integrated various clinical parameters (e.g., comorbidities, vital signs, lab results) to assess disease severity and guide early triage decisions. The model outperformed traditional statistical approaches like logistic regression in identifying high-risk individuals, enabling more efficient allocation of ICU beds and medical resources. Another DL-augmented imaging system used chest radiographs to track pulmonary progression, helping clinicians predict which hospitalized patients might deteriorate, thus supporting dynamic care planning.",Deep Learning,No,No,COVID-19 disease severity and early triage decisions guidance,,,No,,,,
,,,,,,,,,,,,,"The system likely uses a CNN-based architecture trained on labeled CT datasets. It excels in identifying characteristic CT abnormalities associated with COVID-19 (e.g., bilateral ground-glass opacities and consolidations), and was able to flag infection even in cases with false-negative RT-PCR results. It is optimized for clinical deployment in real-time scenarios and integrates automated reporting.",InferRead CT Pneumonia,Yes,Proprietary commercial software.,Assisting in the detection of COVID-19 pneumonia,Not disclosed,Chen et.al,Yes,"The paper reported improved diagnostic accuracy, especially in cases where RT-PCR yielded false negatives. However, specific performance metrics (e.g., sensitivity, specificity, AUC) were not provided in the summary of the study. The results were discussed qualitatively (i.e., clinical benefit demonstrated), but quantitative benchmarks or validation datasets were not explicitly mentioned.",,,
,,,,,,,,,,,,,"Deep Docking uses a deep neural network (DNN) regression model trained on a small set of docking scores to predict binding affinities across billions of molecules. This enables prioritization of compounds for detailed docking simulations. The model integrates cheminformatics features and molecular descriptors for training and screening, significantly reducing computational cost while maintaining docking accuracy.",Deep Docking,Yes,Open-source,Virtual screening to identify potential antiviral compounds targeting SARS-CoV-2.,drug-like molecules,ZINC15 database.,Yes,"Performance was assessed by the platform's ability to enrich potential hit compounds and reduce computational resources compared to traditional docking methods. The accuracy of predicted docking scores and the identification of experimentally validated inhibitors were key metrics. The Deep Docking platform achieved up to a 100-fold acceleration in structure-based virtual screening. In a specific application, it enabled the screening of billion-sized chemical libraries without extraordinary computational resources, resulting in significant enrichment of virtual hits without substantial loss of potential drug candidates.",,,
11,"Huang S, Yang J, Fong S, Zhao Q.",2021,"Cancer Centre, Institute of Translational Medicine, Faculty of Health Sciences, University of Macau 999078, Macau SAR, China.",Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives,Int J Biol Sci,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Review","The aim of this review is to systematically analyze and summarize how machine learning and deep learning techniques have been applied to COVID-19 diagnosis, focusing on their performance, use cases, and integration into clinical workflows.","The rapid spread of COVID-19 overwhelmed healthcare systems, exposing the limitations of traditional diagnostic methods such as RT-PCR, which suffer from delays and high false-negative rates. There is an urgent need for scalable, fast, and accurate diagnostic tools. Although many AI-based models have been developed, their performance, clinical applicability, and limitations remain unclear and scattered across studies."," the review focuses on evaluating and comparing the performance of AI systems reported in the literature, highlighting their diagnostic potential, limitations, and clinical relevance. The paper aims to inform future research by identifying successful strategies and pinpointing challenges such as false-negative diagnoses, limited generalizability, and the need for integration with clinical context and multimodal data.","The AI methodology involves a structured synthesis of machine learning (ML) and deep learning (DL) techniques applied to COVID-19 diagnosis. The authors collected studies through systematic searches across PubMed, Scopus, Google Scholar, and preprint servers (bioRxiv, medRxiv, arXiv), focusing on clinical and radiological data. These included electronic medical records, laboratory indicators, and imaging data such as CT scans, chest X-rays, and lung ultrasounds. The reviewed models employed diverse ML algorithms (e.g., random forest, SVM, gradient boosting) and DL architectures (e.g., ResNet, VGG, Inception, MobileNet, GANs), often utilizing transfer learning or hybrid systems. Data sources were drawn from national databases (e.g., KNHIS), hospital systems, and open repositories like Kaggle and Radiopaedia. The models addressed tasks such as binary and multi-class classification of COVID-19, pneumonia, and normal cases, with some adopting multitask learning for classification, segmentation, and reconstruction. Evaluation was performed using test-train splits or cross-validation, with metrics including accuracy, sensitivity, specificity, AUC, F1-score, and Brier score. Despite high reported performance, limitations such as overfitting, small sample sizes, and limited generalizability were acknowledged, especially for asymptomatic or early-stage detection. Overall, the methodology demonstrates how AI can integrate heterogeneous medical data to support effective and scalable COVID-19 diagnostic solutions.","ResNet50 is a 50-layer deep residual network used to classify multi-view CT images into COVID-19 or other pneumonia. The model was fine-tuned using transfer learning and trained to recognize COVID-specific lung abnormalities. While effective, it showed lower specificity, likely due to overlap in radiological features between COVID-19 and other pneumonias.",ResNet50,https://pytorch.org/vision/main/models.html,No,COVID-19 diagnosis from CT images,Medical Images (CT images),Huang et.al,Yes,Binary classification using a held-out test set. Evaluation was performed using cross-validation and final results reported on an unseen test set.,"{Accuracy,, Sensitivity, Specificity, AUC}","{Accuracy: 76%, Sensitivity: 81.1%, Specificity: 61.5%, AUC: 81.9}",
,,,,,,,,,,,,,"A deeper ResNet architecture (101 layers) used as part of a CNN comparison study. It was fine-tuned on CT images and outperformed other networks in the same evaluation setting. However, such deep architectures may be computationally expensive and require significant GPU memory for training.",ResNet101,https://pytorch.org/vision/main/models.html,No,Binary classification of CT images for COVID-19 detection,Medical Images (CT images),Huang et.al,Yes,"10-fold cross-validation was used, and final results were derived from an aggregated performance across folds.","{ Accuracy, Sensitivity, Specificity, AUC}","{ Accuracy: 99.51%, Sensitivity: 100%, Specificity: 99.02%, AUC: 99.4]",
,,,,,,,,,,,,,Pre-trained CNN models AlexNet and Inception-V4 were applied to CT data. Transfer learning enabled fast convergence and adaptation to the COVID-specific visual patterns. These older architectures may underperform compared to modern CNN variants in complex medical imaging tasks.,AlexNet and Inception-V4,https://pytorch.org/vision/main/models.html,,Binary classification of CT images for COVID-19 detection,Medical Images (CT images),Huang et.al,Yes,"Standard train/test split, performance reported on the test set. Stratified sampling may have been used.","{ Accuracy, Sensitivity, Specificity}","{ Accuracy: 94.74%, Sensitivity: 87.37%, Specificity: 87.45}",
,,,,,,,,,,,,,"Combines Q-deformed entropy-based feature selection with deep learning feature extraction and LSTM classification. The hybrid pipeline improves interpretability and predictive performance. However, it may face overfitting risks due to small dataset size.",QDE-DF (Hybrid),No,No,"Multi-class classification (COVID-19, pneumonia, healthy) from CT",Medical Images (CT images),Huang et.al,Yes,70/30 train-test split. Results averaged over multiple random splits to ensure stability.,{Accuracy},{Accuracy: 99.68%},
,,,,,,,,,,,,,"Multitask learning setup including segmentation, classification, and reconstruction. Combines encoder-decoder CNN with MLP for final classification. Multitask models can be harder to optimize due to conflicting objectives and require large training datasets to generalize well.",Multitask Encoder-Decoder + MLP,No,No,COVID-19 lesion segmentation and diagnosis from CT scans,Medical Images (CT images),Huang et.al,Yes,"Task-specific evaluation for classification (ROC analysis), segmentation (IoU/Dice), and reconstruction (reconstruction loss). Results averaged over 5-fold cross-validation.","{Accuracy, Sensitivity, Specificity,  AUC}","{Accuracy: 86%, Sensitivity: 94%, Specificity: 79%, AUC: 93}",
,,,,,,,,,,,,," Transfer learning with pre-trained CNNs on chest X-rays. Fine-tuning was performed on a 3-class problem: COVID-19, pneumonia, and normal. These models benefit from pretrained weights but may be limited by the size and imbalance of medical datasets."," VGG19, MobileNetV2, Inception, etc.",https://pytorch.org/vision/main/models.html,MIT/Apache (for base models),Diagnosis of COVID-19 and pneumonia from X-rays,X-ray images,Huang et.al,Yes,Cross-validation and held-out test set performance evaluation. Models compared head-to-head.,"{Accuracy, Sensitivity, Specificity}","{Accuracy: 96.78%, Sensitivity: 98.66%, Specificity: 96.46}",
,,,,,,,,,,,,,"GAN used for synthetic data generation; CNNs trained on the augmented dataset for 4-class classification. GAN-based augmentation improves performance with small datasets, but may introduce artifacts or unrealistic samples.","GAN + AlexNet, GoogLeNet, ResNet18",https://pytorch.org/vision/main/models.html,Not specified,"Classification of COVID-19, bacterial pneumonia, viral pneumonia, and normal from X-rays",X-ray images,Huang et.al,Yes, Stratified hold-out test set with model comparison across CNNs. Evaluated using multiple random seeds,"{ Accuracy, Precision}","{ Accuracy: 85.2% (GoogLeNet), Precision: 80.6% (AlexNet)}",
,,,,,,,,,,,,,"Custom CNN based on the YOLO object detection model repurposed for classification of COVID-19 from X-ray images. Heatmap generation helps in visualization. However, YOLO-based classifiers may suffer from sensitivity to hyperparameters and require more tuning.",DarkNet (YOLO-based CNN),Not specified,Not specified,COVID-19 diagnosis (binary and multiclass) using X-rays,X-ray images,Huang et.al,Yes,Split into binary and 3-class classification tasks. Models evaluated with stratified random sampling. Heatmaps used for interpretability.,"{Accuracy, Sensitivity, Specificity, F1-Score}","{Accuracy: 98.08%, Sensitivity: 95.13%, Specificity: 95.3%, F1-Score: 96.51}",
,,,,,,,,,,,,,"Feature maps from multiple CNNs are concatenated to improve representation. The combined vector is used for final classification into three classes. While ensemble features boost accuracy, the model becomes more complex and computationally demanding.",Concatenated CNN,Not specified,Not specified,"Classification of COVID-19, pneumonia, and normal from X-rays",X-ray images,Huang et.al,Yes,Model evaluated on large-scale 3-class classification using stratified hold-out validation. Generalization tested on a separate validation split.,"{Accuracy, Sensitivity, Specificity}","{Accuracy: 99.5%, Sensitivity: 80.53%, Specificity: 99.56}",
12,"Mohanty S, Harun Ai Rashid M, Mridul M, Mohanty C, Swayamsiddha S.",2020,"School of Applied Science, KIIT University, Bhubaneswar, Odisha, India.",Application of Artificial Intelligence in COVID-19 drug repurposing,Diabetes Metab Syndr,Respiratory Virology,['COVID-19'],"Journal Article, Review","To explore and establish how artificial intelligence (AI), particularly deep learning and network medicine techniques, can be systematically applied to accelerate drug repurposing or repositioning for emerging diseases such as COVID-19","The traditional drug discovery pipeline is time-consuming, costly, and has a low success rate, making it unsuitable for urgent public health crises such as the COVID-19 pandemic. While drug repurposing offers a faster alternative by reusing existing drugs, the absence of systematic and scalable methods to screen and evaluate large datasets of candidate drugs hinders timely therapeutic development.","To accelerate and enhance drug repurposing efforts for emerging diseases like COVID-19 by leveraging deep learning and network medicine approaches that integrate biological, clinical, and pharmacological data.","The AI methodology employed in this study involves the integration of diverse biomedical datasets, including repurposed drug databases and open-access chemical repositories, to serve as inputs for AI models. Initially, data on drug properties, clinical trial outcomes, molecular structures, and pharmacological profiles are collected and preprocessed. Machine learning algorithms, including supervised and unsupervised learning techniques, are then applied to identify patterns and predict drug efficacy. In parallel, deep learning models such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and deep belief networks (DBNs) are utilized to analyze complex and high-dimensional data, such as molecular sequences and drug-target interactions. These models facilitate virtual screening by rapidly evaluating and ranking existing drugs based on their predicted effectiveness against COVID-19. The AI-generated predictions are subsequently validated through available experimental or clinical data, and refined in an iterative manner. This methodology enables accelerated, data-driven identification of potential therapeutic candidates, reducing reliance on time-consuming conventional drug discovery methods.","The study utilizes a combination of machine learning and deep learning techniques to facilitate drug repurposing for COVID-19. Machine learning methods, including supervised learning for classification and regression, are applied to predict drug efficacy based on known input-output relationships. Unsupervised learning techniques such as clustering are used to identify patterns among drugs with similar biological activity or molecular characteristics. In addition, deep learning models particularly convolutional neural networks (CNNs), recurrent neural networks (RNNs), and deep belief networks (DBNs) are employed to process complex, high-dimensional biomedical data. These models analyze drug structures, molecular sequences, and pharmacological profiles to identify candidate drugs with potential antiviral activity. By leveraging these AI techniques, the study aims to accelerate virtual screening and prioritize existing drugs that could be repurposed for treating SARS-CoV-2 infections.",Machine Learning and Deep Learning-based Drug Repurposing Models,No,No,Identification of antiviral drugs effective against SARS-CoV-2 ,Biomedical and Pharmacological Structured Data,Mohanty et.al,No,Not specified,Not specified,Not specified,
13,"Abd-Alrazaq A, Alajlani M, Alhuwail D, Schneider J, Al-Kuwari S, Shah Z, Hamdi M, Househ M.",2020,"Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar.",Artificial Intelligence in the Fight Against COVID-19: Scoping Review,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Scoping Review","To explore and systematically review how existing artificial intelligence (AI) technologies have been applied during the COVID-19 pandemic across various public health domains such as diagnosis, treatment development, epidemiological forecasting, patient outcome prediction, and infodemiology by summarizing the AI techniques, data types, and datasets reported in the literature, without proposing or developing new AI methods.","While artificial intelligence (AI) holds great promise for supporting public health efforts during pandemics by enabling predictive insights from large health datasets, its application in the context of COVID-19 has been fragmented and inconsistently documented. Existing literature largely focuses on narrow use cases or lacks systematic assessment of the AI models, techniques, and datasets involved. As a result, there is a lack of comprehensive understanding of how AI has been leveraged across the full spectrum of COVID-19 public health challenges, limiting its potential utility in current and future pandemics."," to understand the scope, purpose, and technical characteristics of AI applications during the pandemic, with a focus on how AI supports public health efforts.","The study conducted a scoping review based on the PRISMA-ScR guidelines to systematically collect and analyze literature on AI applications in the context of COVID-19. Searches were performed across major databases (e.g., MEDLINE, EMBASE, IEEE Xplore, Google Scholar) using terms related to both AI (e.g., machine learning, deep learning) and COVID-19. A total of 82 eligible studies were included after screening titles, abstracts, and full texts. Data were extracted on the purpose of AI use (e.g., diagnosis, drug discovery), type of AI method (e.g., CNN, SVM, RNN), AI branch (machine learning, deep learning, NLP), and dataset characteristics (source, type, size, validation method). A narrative synthesis was used to categorize AI applications, algorithms, platforms (desktop vs. mobile), and dataset details. The methodology ensured independent review by two authors and high interrater reliability through Cohen's kappa scoring.","The study analyzed a wide variety of AI methods used across different COVID-19 tasks. The most commonly used deep learning technique was the Convolutional Neural Network (CNN), primarily applied for diagnostic tasks using radiology images (CT and X-ray). Other deep learning models included Recurrent Neural Networks (RNNs), Autoencoders, Multilayer Perceptrons, and Deep Neural Networks, especially for time-series prediction and sequence analysis. In the realm of traditional machine learning, models such as Support Vector Machines (SVM), Random Forests, Decision Trees, Logistic Regression, Naive Bayes, K-Nearest Neighbors, and Gradient Boosting (AdaBoost) were used for clinical classification tasks like mortality risk prediction and severity assessment. Natural Language Processing (NLP) techniques (e.g., Skip-gram models, Bag-of-Words, and Porter stemming) were employed in fewer studies, mainly for infodemiology—such as raising awareness and synthesizing information from news or public sources. These models were developed and validated using data from various domains including medical imaging, laboratory test results, genomic sequences, clinical symptoms, demographic information, and epidemiological statistics. The models were trained on datasets sourced from public repositories (e.g., NCBI, GitHub, Kaggle), hospitals, government sources, and published literature.","Deep Learning (DL), and Natural Language Processing (NLP) Techniques",No,No,"Diagnosis, Drug and Vaccine Discovery, Host and Reservoir Prediction","Radiology images, biological data, clinical and laboratory data,",Abd-Alrazaq et.al,No,Not specified,Not specified,Not specified,
14,Younis MC.,2021,"University of Mosul, College of Computer Sciences and Mathematics, Computer Sciences Department, Mosul, Iraq. Electronic address: mohammed.c.y@uomosul.edu.iq.",Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction,Comput Med Imaging Graph,Respiratory Virology,"[""COVID-19""]","Journal Article, Review","To develop and evaluate deep learning models, particularly convolutional neural networks (CNNs) and long short-term memory (LSTM) networks, for the automated classification of COVID-19, SARS/MERS, and healthy cases using lung X-ray images, and to forecast the number of COVID-19 cases over a 10-day period in Italy using time series analysis.","The rapid spread of COVID-19 has overwhelmed global healthcare systems, and the limited availability of diagnostic kits has created an urgent need for automated tools that can assist in early detection and classification of infected individuals. Differentiating between COVID-19 and other types of coronavirus infections (e.g., SARS, MERS) is particularly challenging due to overlapping radiographic features, and existing testing methods like RT-PCR are slow and have high false-negative rates. Therefore, there is a pressing need to develop AI-driven diagnostic and forecasting tools using medical imaging and epidemiological data to improve disease management and resource allocation.","To apply deep learning techniques, specifically convolutional neural networks (CNNs) for image classification and long short-term memory (LSTM) networks for time series forecasting, to automate the detection of COVID-19, SARS/MERS, and healthy cases using lung X-ray images and to predict future COVID-19 case trends in Italy, thereby supporting early diagnosis and proactive public health planning.","The study employs a dual deep learning-based AI methodology combining image classification and time series forecasting. For classification, various convolutional neural network (CNN) architectures including VGG (with one to four blocks), LeNet-5, AlexNet, and ResNet-50 were trained on a custom X-ray image dataset comprising COVID-19, SARS/MERS, and healthy lung images. These models were evaluated using precision, recall, F1-score, and accuracy to identify the best-performing architecture for distinguishing among the three classes. In parallel, a long short-term memory (LSTM) model was used to perform time series forecasting of daily COVID-19 cases in Italy, based on official WHO data from January to May 2020. The LSTM model predicted future trends with high accuracy, aiding in the anticipation of case surges and potential policy decisions. This integrated methodology showcases how AI can assist both in diagnostic automation and epidemic prediction.","Convolutional Neural Networks (CNNs) were applied to classify lung X-ray images into three classes: COVID-19, SARS/MERS, and healthy (normal) cases. The architectures tested include several variations: one-block to four-block VGG models (VGG1–VGG4), LeNet-5, AlexNet, and ResNet-50. The dataset comprised 145 labeled X-ray images (45 COVID-19, 49 SARS/MERS, and 51 normal), resized to 200×200×3 pixels. The data was split into 80% for training and 20% for testing. The input images were fed into CNN models with standardized shapes and evaluated using standard classification metrics precision, recall, F1-score, and weighted average accuracy. Among the tested models, VGG1 achieved the highest classification performance with a weighted accuracy of 91%, followed closely by VGG2, LeNet-5, and VGG3, each in the 87–88% range. The confusion matrix for VGG1 showed perfect classification (100%) for the SARS/MERS class, while COVID-19 and Normal classes had slightly lower precision due to some misclassifications. For instance, some COVID-19 cases were misclassified as normal, likely due to overlapping radiological patterns. Conversely, VGG2 and LeNet-5 perfectly classified normal cases but struggled more with the SARS/MERS class. The confusion matrix of ResNet-50 revealed strong classification performance for the normal class but confusion between COVID-19 and SARS/MERS, indicating the model’s difficulty in differentiating similar pneumonia-related features. Learning and loss curves were also analyzed to understand model behavior during training. For example, VGG1’s accuracy curve improved until epoch 35, after which overfitting was suspected due to validation accuracy drop, while AlexNet showed a steadily decreasing loss curve after epoch 15, indicating effective regularization through dropout layers. These diagnostics provide insights into when models begin to overfit or underfit and help guide model optimization strategies.",Convolutional Neural Networks (CNNs),Yes(can be implemented using Tensorflow and Keras,Apache License 2.0/MIT license,Differential diagnosis of COVID-19 vs. SARS/MERS vs. Normal using lung X-ray images., lung X-ray images,Younis et. al,Yes,"The study evaluated the performance of CNN models for classifying chest X-ray images into three categories COVID-19, SARS/MERS, and normal using precision, recall, F1-score, and overall weighted accuracy. The one-block VGG model (VGG1) achieved the best results with a 91% weighted accuracy, showing 100% precision and recall for the SARS/MERS class and strong performance for the other two classes. VGG2, LeNet-5, and VGG3 followed with weighted accuracies of 88%, 88%, and 87%, respectively. While models like AlexNet and ResNet-50 classified normal cases well (100% precision and recall), they underperformed in differentiating COVID-19 from SARS/MERS","{ ""accuracy"", ""precision"", ""recall""}","{""VGG1"":{""weighted_accuracy"":0.91,""COVID-19"":{""precision"":0.83,""recall"":1.0,""f1_score"":0.91},""Normal"":{""precision"":0.83,""recall"":0.83,""f1_score"":0.83},""SARS-MERS"":{""precision"":1.0,""recall"":0.86,""f1_score"":0.92}},""VGG2"":{""weighted_accuracy"":0.88,""COVID-19"":{""precision"":0.9,""recall"":0.9,""f1_score"":0.9},""Normal"":{""precision"":0.75,""recall"":1.0,""f1_score"":0.86},""SARS-MERS"":{""precision"":0.92,""recall"":0.79,""f1_score"":0.85}},""LeNet-5"":{""weighted_accuracy"":0.88,""COVID-19"":{""precision"":1.0,""recall"":0.7,""f1_score"":0.82},""Normal"":{""precision"":0.86,""recall"":1.0,""f1_score"":0.92},""SARS-MERS"":{""precision"":0.81,""recall"":0.93,""f1_score"":0.87}},""VGG3"":{""weighted_accuracy"":0.87,""COVID-19"":{""precision"":0.8,""recall"":0.8,""f1_score"":0.8},""Normal"":{""precision"":1.0,""recall"":1.0,""f1_score"":1.0},""SARS-MERS"":{""precision"":0.87,""recall"":0.87,""f1_score"":0.87}},""VGG4"":{""weighted_accuracy"":0.84,""COVID-19"":{""precision"":0.67,""recall"":1.0,""f1_score"":0.8},""Normal"":{""precision"":0.75,""recall"":1.0,""f1_score"":0.86},""SARS-MERS"":{""precision"":1.0,""recall"":0.5,""f1_score"":0.67}},""AlexNet"":{""weighted_accuracy"":0.78,""COVID-19"":{""precision"":0.75,""recall"":0.6,""f1_score"":0.67},""Normal"":{""precision"":1.0,""recall"":0.83,""f1_score"":0.91},""SARS-MERS"":{""precision"":0.71,""recall"":0.86,""f1_score"":0.77}},""ResNet-50"":{""weighted_accuracy"":0.77,""COVID-19"":{""precision"":0.71,""recall"":0.5,""f1_score"":0.59},""Normal"":{""precision"":1.0,""recall"":1.0,""f1_score"":1.0},""SARS-MERS"":{""precision"":0.71,""recall"":0.86,""f1_score"":0.77}}}",
,,,,,,,,,,,,,"Long Short-Term Memory (LSTM) neural network was employed to forecast COVID-19 case trends in Italy. The time series dataset was collected from the World Health Organization (WHO), covering the period from January 22 to May 20, 2020. It included daily confirmed, recovered, and death counts, along with associated metadata (e.g., date, latitude, longitude). The structured dataset was stored in CSV format and cleaned for use in sequential input modeling. The LSTM model was implemented using the Keras deep learning framework, and trained on this multivariate time series to predict daily confirmed COVID-19 cases over a 10-day forecasting horizon. LSTM’s architecture, designed to retain long-term dependencies in temporal data, made it well-suited for learning from case count trajectories and seasonal fluctuations. Each input sequence consisted of lagged values (i.e., previous days’ confirmed cases), and the model was optimized through standard backpropagation using the Adam optimizer. The forecasting results showed a prediction accuracy of 99%, although the precise evaluation metric (e.g., MAE or RMSE) was not explicitly stated. Performance was visually validated through comparison plots between actual and predicted values, which revealed minimal deviation (1500–1900 cases/day) over the forecast period. The forecasted case growth showed an upward trajectory, signaling a potential outbreak surge if no policy interventions were made.",Long Short-Term Memory (LSTM),Yes(can be implemented using Tensorflow),Apache License 2.0,Epidemiological forecasting of confirmed COVID-19 cases over a 10-day window in Italy,Time-series tabular data,Younis et. al,Yes,"the study applied an LSTM model trained on WHO time series data. The model achieved a prediction accuracy of approximately 99%, with predicted case counts closely following actual values over a 10-day window, deviating by just 1500–1900 cases daily."," {""accuracy""}","{""accuracy"":0.99,""daily_prediction_error_range"":""1500–1900 cases"",""actual_vs_predicted_example"":{""2020-05-10"":{""actual"":219070,""predicted"":220051.4,""difference"":981.4}}}",
15,"Comito C, Pizzuti C.",2022,"National Research Council of Italy (CNR), Institute for High Performance Computing and Networking (ICAR), Rende, Italy. Electronic address: carmela.comito@icar.cnr.it.",Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review,Artif Intell Med,Respiratory Virology,['COVID-19'],"Journal Article, Review","The aim of this study is to deliver a comprehensive and focused review of artificial intelligence (AI) applications specifically those based on machine learning (ML) and deep learning (DL) used for forecasting and diagnosing COVID-19. The review seeks to evaluate the effectiveness of these techniques, offer accessible explanations of AI methods for non-experts, and analyze each included study in detail with respect to the method employed, dataset characteristics, validation procedures, target applications, and achieved outcomes. ","While AI has shown great promise in supporting efforts such as outbreak prediction, diagnosis, and surveillance, existing literature reviews often take a broad and generalized approach, lacking in-depth focus on forecasting and predictive tracking. This lack of targeted analysis presents a gap for researchers and decision-makers seeking AI-driven solutions specifically tailored to predicting the progression and spread of COVID-19.","The objective of applying Artificial Intelligence (AI) in this review is to enhance the forecasting, tracking, diagnosis, and monitoring of COVID-19 through advanced data-driven models. AI is intended to support public health efforts by improving the accuracy and timeliness of outbreak predictions, identifying high-risk patients, aiding in early diagnosis using clinical, demographic, and epidemiological data, and simulating the effects of preventive measures such as lockdowns or vaccination. Ultimately, the use of AI aims to complement traditional healthcare responses with scalable and adaptive technologies capable of responding to pandemic conditions in real time.","The study employs a structured and systematic review methodology to examine the application of artificial intelligence (AI) techniques specifically machine learning (ML) and deep learning (DL) for forecasting, diagnosing, and monitoring COVID-19. Literature was collected from major scientific databases such as PubMed, IEEE Xplore, Scopus, and arXiv, covering publications from February 2020 to March 2021. A total of 146 relevant papers were selected based on predefined inclusion and exclusion criteria, of which 38 were analyzed in detail. The review highlights a broad range of ML techniques including ARIMA, SVM, Random Forest, Logistic Regression, and ensemble models, as well as DL approaches such as LSTM, Bi-LSTM, CNN, and hybrid models like CNN-LSTM and ConvLSTM. These models were applied to diverse data types including time-series case data, lab results, CT scans, clinical notes, and mobility patterns. Evaluation metrics such as accuracy, AUC, MAE, RMSE, and MAPE were commonly used to assess performance. LSTM-based models emerged as the most frequently used and consistently high-performing techniques for case forecasting. The methodology also involved grouping studies by algorithm type and prediction task to assess model effectiveness across varying datasets and problem domains.","DeepCOVIDNet is a deep learning architecture composed of two modules: an embedding module and a Deep Factorization Machine (DeepFM) module. The model processes heterogeneous features such as census data, mobility data (intra-county and inter-county), social distancing metrics, and prior infection growth. The embedding module generates uniform-dimensional embeddings for each group of features (classified as constant, time-dependent, and cross-county time-dependent), which are then passed to the DeepFM module to learn high-order interactions between features and predict probability distributions for case growth. The model predicts the risk category (4-class output) for COVID-19 case increases.",DeepCOVIDNet,https://github.com/urban-resilience-lab/deepcovidnet,No,COVID-19 case growth classification,"Heterogeneous data (mobility, census, social distancing, infection counts) from April 5 to June 28, 2020``",Comito et.al,Yes,The performance was measured using  4-class classification of case rise (negligible to high) which was evaluated using multiclass classification accuracy on a 17-day test set,{'Accuracy'},{'Accuracy':  63.7%},
,,,,,,,,,,,,,"Combines a traditional infection rate model with LSTM for forecasting and pretrained NLP models to integrate news-derived features (public health measures, media sentiment) that adjust infection rate estimations.",Hybrid LSTM + NLP + Virus Spread Model,No,No,COVID-19 case forecasting with intervention-awareness,Time series (epidemiological) + textual data (news),Comito et.al,Yes,"Regression forecasting of new case trajectories was done and Compared with traditional epidemic models (e.g., ISI model)",Outperformed baseline epidemic models (exact metrics like RMSE or MAE not specified),,
,,,,,,,,,,,,,A deep ensemble of convolutional and bidirectional LSTM models trained on WHO COVID-19 time series data. Forecasts confirmed and death cases for India.,Deep-LSTM Ensemble,No,No,Forecasting confirmed and death cases,Daily case counts,Comito et.al,Yes,The model was evaluated on its forecasting accuracy for a 30-day prediction horizon using both classification-style accuracy and regression-based error metrics like MAPE.,"{""Accuracy"", ""MAPE""}","{""Accuracy_Confirmed"": 97.59, ""Accuracy_Deaths"": 98.88, ""MAPE_Confirmed"": 2.40, ""MAPE_Deaths"": 1.11}",
,,,,,,,,,,,,,"WCRVFL is a hybrid deep learning architecture that applies 1-D discrete wavelet transforms to denoise COVID-19 case signals before passing them through an RVFL neural network (a shallow MLP variant). It enables multi-country, long-term (60-day) forecasts of COVID-19 case spread.",Wavelet-Coupled Random Vector Functional Link Network (WCRVFL),No,No,Long-range daily case forecasting,Denoised time-series via wavelet transform,Comito et.al,Yes,"The model's predictive accuracy was assessed using a suite of regression and signal-based error metrics, enabling robust assessment of forecast sharpness and structure preservation.","{""Qualitative_Metrics"": ""Improved forecasting accuracy across multiple signal and regression metrics (e.g., R², RMSE, MAE, PSNR), exact values not disclosed""}",,
,,,,,,,,,,,,,Hi-COVIDNet is a hierarchical neural network that uses continent-level and country-level encoders to model inter-regional COVID-19 transmission risks based on geographic hierarchy and human travel patterns. The model identifies which foreign countries most likely contribute to the local infection growth.,Hi-COVIDNet,No,No,Cross-border COVID-19 transmission forecasting,Geospatial + temporal foreign infection vectors,Comito et.al,Yes,he model was qualitatively evaluated using real-world outcomes in South Korea to validate its effectiveness for predicting foreign-source transmission; no specific numerical metrics were disclosed.,"{""Qualitative_Metric"": ""Validated through real-world case study in South Korea showing accurate country-level transmission predictions""}",,
16,"Rasheed J, Jamil A, Hameed AA, Al-Turjman F, Rasheed A.",2021,"Department of Computer Engineering, Istanbul Aydin University, Istanbul, 34295, Turkey. jawadrasheed@aydin.edu.tr.",COVID-19 in the Age of Artificial Intelligence: A Comprehensive Review,Interdiscip Sci,Respiratory Virology,['SARS-CoV-2'],"Journal Article, Review","This study aims to systematically review how AI, especially ML and DL, has been applied to diagnose, predict, and manage COVID-19. It covers applications like radiographic image analysis, clinical data classification, outbreak forecasting, and drug discovery, providing insights for healthcare and AI researchers.","Traditional diagnostic tools for COVID-19 are slow, resource-intensive, and insufficient in crisis settings. AI solutions exist but face challenges like limited data, poor generalizability, and lack of integration with real-world variables highlighting the need for more robust, scalable AI models in pandemic response.","To leverage artificial intelligence particularly machine learning (ML) and deep learning (DL) to enhance the early diagnosis, monitoring, prediction, and management of COVID-19 cases by analyzing diverse data sources such as medical images, clinical reports, respiratory signals, and time series data.","The study follows a structured AI methodology involving data collection from multiple sources such as radiographic images (CXR, CT), clinical blood reports, respiratory signals, and COVID-19 case time series. These inputs undergo preprocessing techniques including image segmentation (e.g., 3D U-Net, VB-Net), noise filtering, and feature extraction (e.g., GLCM, PCA). Depending on the task diagnosis, forecasting, or risk assessment the pipeline employs deep learning models like CNNs (e.g., ResNet, VGG, EfficientNet) for image analysis, LSTM variants for time series forecasting, and GRU-based models for respiratory pattern classification. Clinical and textual data are analyzed using ML models such as SVM, Random Forest, and logistic regression. Advanced tasks like drug discovery leverage GANs, graph neural networks, and transformer-based architectures. Models are trained using standard validation strategies (e.g., cross-validation, test/train splits) and evaluated with metrics such as accuracy, precision, recall, F1-score, AUC, RMSE, and MAPE. This methodology supports rapid and effective AI deployment for COVID-19 diagnosis, outbreak prediction, and therapeutic development.","Transfer learning using MobileNetV2 (pretrained on ImageNet) was applied for classifying chest X-ray images into COVID-19, viral/bacterial pneumonia, and healthy. The model was evaluated on two datasets:
Dataset 1 (Sethy et al. [55]):
381 CXR images (balanced: 127 each for COVID-19, pneumonia, and normal)
Features extracted using MobileNetV2
Classifier: SVM
3-class classification task
Reported: Accuracy, F1-score, Sensitivity
Dataset 2 (Apostolopoulos & Mpesiana [67]):
1442 CXR images
COVID-19: 224, pneumonia: 714, healthy: 504
Used for both 2-class and 3-class classification
Pure CNN-based end-to-end training using MobileNetV2",MobileNetV2,No,No,COVID-19 diagnosis using chest X-ray.,"Medical Images (CXR, CT)",Rasheed et.al,Yes,"The model was trained using both binary (COVID-19 vs. Non-COVID) and multiclass (COVID-19, pneumonia, healthy) setups. It was evaluated using standard classification metrics accuracy, sensitivity, specificity on two different datasets. An internal train-test split (likely 80:20) was used. No external validation or k-fold CV reported.","{""accuracy"", ""sensitivity"", ""specificity""}
","{""dataset1_2class_accuracy"": 97.04, ""dataset1_2class_sensitivity"": 99.10, ""dataset1_2class_specificity"": 97.09, ""dataset1_3class_accuracy"": 92.85, ""dataset2_3class_accuracy"": 94.72, ""dataset2_2class_sensitivity"": 98.66, ""dataset2_2class_specificity"": 96.46, ""dataset2_2class_accuracy"": 96.78}",
,,,,,,,,,,,,,"A transfer learning pipeline using a fine-tuned VGG16 CNN architecture was developed in two stages. Stage 1: classification of images into healthy vs. diseased. Stage 2: discrimination between pulmonary disease and COVID-19. The model was trained on 6523 chest X-ray images. Fine-tuning details (e.g., frozen layers, learning rate) were not specified.",VGG16 (fine-tuned DTL),No,No,COVID-19 diagnosis from chest X-rays.,Chest X-ray images.,Rasheed et.al,Yes,"Two-stage model: first, detects whether a person has any pulmonary disease; second, distinguishes COVID-19 from other pulmonary diseases. Performance metrics (accuracy, sensitivity, specificity, F1-score) were reported for each stage. No mention of cross-validation. The model was evaluated on 6523 labeled CXR images.","{""sensitivity"", ""specificity"", ""accuracy"", ""f1_score""}","{""sensitivity"": 87, ""specificity"": 94, ""accuracy"": 98, ""f1_score"": 89}",
,,,,,,,,,,,,," A 3D convolutional neural network was designed, incorporating ResNet as the backbone for spatial feature extraction from volumetric CT images. The model classified images into COVID-19, IAVP (influenza-associated viral pneumonia), and normal categories. The number of ResNet layers and architectural hyperparameters were not mentioned.",3D CNN with ResNet,No,No,COVID-19 detection using CT images.,CT images.,Rasheed et.al,Yes,"CT scans were categorized into three classes: COVID-19, Influenza-A Viral Pneumonia (IAVP), and healthy. Model performance was measured using classification accuracy only. No breakdown by class or use of precision/recall/F1. Evaluation conducted on a labeled test set; details on training/test split size or validation strategy are missing.","{""accuracy""}","{""accuracy"": 86.7}",
,,,,,,,,,,,,,A pre-trained DenseNet201 was used with transfer learning to classify CT scans into COVID-19 and non-COVID categories. No architectural modifications or custom layers were applied. The model was trained using a binary classification objective. Data augmentation and optimizer settings were not reported.,DenseNet201 with DTL,No,No,COVID-19 diagnosis from CT images.,CT images.,Rasheed et.al,Yes,"Applied for binary classification (COVID-19 vs. others). Evaluated using five metrics: accuracy, precision, sensitivity, specificity, F1-score. No cross-validation was reported. A balanced labeled dataset of over 2000 CT images was used with a likely internal train-test split.","{""precision"", ""sensitivity"",  ""specificity"", ""accuracy"", ""f1_score""}","{""precision"": 96.29, ""sensitivity"": 96.29, ""specificity"": 96.21, ""accuracy"": 96.25, ""f1_score"": 96.29}",
,,,,,,,,,,,,,"A Bidirectional Gated Recurrent Unit (GRU) model was combined with an attention mechanism to classify respiratory wave patterns. The model was trained on real-world depth video data (breathing patterns) and supplemented with simulated data using a respiratory simulation model (RSM). Compared against GRU, LSTM, and Bi-AT-LSTM baselines.",BI-AT-GRU,No,No,COVID-19 diagnosis via respiratory wave data.,Respiratory signal / breathing pattern.,Rasheed et.al,Yes,"Used for binary classification of respiratory patterns (e.g., COVID vs. normal). Evaluated on real-world data captured from depth video and augmented using RSM (respiratory simulation model). Metrics used: precision, recall, accuracy, F1-score. Model compared against baselines like LSTM, GRU, and BI-AT-LSTM to establish relative performance. No mention of validation strategy.","{""precision"", ""recall"", ""accuracy"", ""f1_score""}","{""precision"": 94.4, ""recall"": 95.1, ""accuracy"": 94.5, ""f1_score"": 94.8}",
,,,,,,,,,,,,,"First, a 3D U-Net architecture was used to segment lung lobes from CT scans. Then, a modified Inception network predicted CO-RADS scores indicating severity of COVID-19 infection. The model used CT scans but details on the training procedure, loss function, or feature representation were not described.",2-stage 3D U-Net + Inception,No,No,COVID-19 severity assessment.,CT images,Rasheed et.al,Yes,"First, lung lobes were segmented using 3D U-Net; then severity was classified using CO-RADS scoring with a modified Inception model. CO-RADS is a categorical system for estimating COVID-19 suspicion. No numerical evaluation metrics (e.g., accuracy or Dice score) for the second stage were provided. Segmentation performance was not quantified either.",CO-RADS scoring; evaluation details not quantitatively stated.,,
,,,,,,,,,,,,,"VB-Net is a voxel-based 3D CNN used to segment COVID-19 lesions in CT scans. It performs fine-grained volumetric segmentation and calculates infected area. The model was trained for both classification and quantification tasks. Lesion volume estimates were validated using Pearson correlation with radiologist reports. Details on architecture (e.g., kernel size, depth) were not included.",VB-Net (3D CNN),No,No,COVID-19 lesion detection and severity quantification.,CT images,Rasheed et.al,Yes,Used voxel-level segmentation to detect infected regions in CT images. Evaluation was done using Dice Similarity Coefficient (for segmentation overlap) and Pearson correlation coefficient (to assess correlation between predicted and actual lesion volumes). No external validation or test set detail was provided.,"{""pearson_r""}","{""pearson_r"": 96.7}",
,,,,,,,,,,,,,"A fully connected feedforward neural network comprising 6 dense layers was trained on structured clinical data (lab values, demographic attributes) to predict patient mortality risk. No activation functions, dropout, or architecture-specific choices were provided.",Dense Neural Network (6 dense layers),No,No,Mortality prediction,Clinical/blood test data,Rasheed et.al,Yes,"Model input was structured clinical data with features like lab tests and patient demographics. Evaluation was done using classification accuracy. No breakdown of sensitivity/specificity. Details on class balance, train-test split ratio, or external validation were not given.",Accuracy measured; metrics not detailed.,,
,,,,,,,,,,,,,An LSTM model was used to model time-series CT scans over multiple hospital visits. A Multi-Layer Perceptron (MLP) transformed 75-dimensional structured clinical data into a 40-dimensional feature space. A logistic regression model combined the outputs from the LSTM and MLP for final severity prediction. Five-fold cross-validation was used.,Multivariate LSTM + MLP,No,No,Severity and disease progression prediction,CT images + clinical data.,Rasheed et.al,Yes,CT sequences across different hospital visits were input into an LSTM; static clinical data was encoded with MLP. The model output predicted whether a patient’s condition would worsen. Evaluation was done using 5-fold cross-validation on 133 patients; reported metrics included AUC and overall accuracy.,"{""AUC"" ""accuracy""}","{""AUC"": 95.4, ""accuracy"": 89.1}",
,,,,,,,,,,,,," A ConvLSTM network was used to capture spatiotemporal dependencies in COVID-19 case data for the USA and Italy. Input features included infection rates and geographical clustering over time. The model forecasted new cases for the next 5 days. The architecture depth, loss function, and optimizer were not disclosed.",Convolutional LSTM,No,No,COVID-19 outbreak prediction,Time series and geospatial case data,Rasheed et.al,Yes,Designed to forecast COVID-19 case trends in the US and Italy. Used spatial clustering of cases as input and predicted 5-day future case counts. Forecast accuracy was assessed using Mean Absolute Percentage Error (MAPE). No validation on unseen regions or long-term forecasting stability was reported.,"{""MAPE""}","{""MAPE_USA"": 5.57, ""MAPE_Italy"": 0.3}",
17,"Zhu Q, Ye H, Sun L, Li Z, Wang R, Shi F, Shen D, Zhang D.",2021,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China.",GACDN: generative adversarial feature completion and diagnosis network for COVID-19,BMC Med Imaging,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Review",The primary aim of this study is to develop an advanced deep learning framework Generative Adversarial Feature Completion and Diagnosis Network (GACDN) that can automatically generate location-specific handcrafted features from easily obtainable radiomic features and use them to improve diagnostic accuracy in distinguishing COVID-19 from community-acquired pneumonia (CAP) using chest CT images,"While many machine learning methods rely on handcrafted features derived through manual or semi-automated image segmentation, this process is labor-intensive, time-consuming, and requires significant expertise and computational resources making it impractical in high-demand or low-resource settings. Furthermore, diagnostic models often assume the availability of complete multi-view data, which is not always feasible in real-world clinical scenarios. As a result, there is a critical need for diagnostic methods that can function effectively despite missing handcrafted features and can operate with minimal human intervention.","To enhance the accuracy and efficiency of COVID-19 diagnosis from chest CT images by automatically generating missing location-specific handcrafted features using a generative adversarial network (GAN), and integrating these with radiomic features in a unified diagnostic model thus overcoming the limitations posed by incomplete data and the need for manual segmentation.","The study introduces a deep learning-based framework called GACDN (Generative Adversarial Feature Completion and Diagnosis Network) to address the challenge of incomplete handcrafted features in the diagnosis of COVID-19 from chest CT images. The methodology is designed to synthesize location-specific handcrafted features from readily available radiomic features, thereby bypassing the need for time-consuming manual segmentation. These generated features are combined with radiomic features and fed into a classification network trained to differentiate COVID-19 from community-acquired pneumonia (CAP). The model is trained end-to-end using a composite loss function that includes adversarial loss (to ensure feature realism), mean squared error loss (for accurate feature reconstruction), and classification consistency loss (to ensure diagnostic relevance). The method is validated on a dataset comprising 2,522 CT scans, including 1,495 COVID-19 and 1,027 CAP cases, and demonstrates improved diagnostic accuracy compared to existing methods, especially in resource-constrained or data-incomplete settings.","The GACDN framework comprises three core components: a Generator, Discriminator, and a Disease-Consistent Classifier. The generator takes as input the radiomic features 93 features derived from raw CT images using standard image descriptors like GLCM, GLRLM, and histogram-based metrics and learns to generate 96 location-specific handcrafted features typically extracted via expert-driven image segmentation. The discriminator is trained to distinguish between real and generated handcrafted features using binary cross-entropy loss, driving the generator to improve output quality. To ensure clinical utility, the classifier takes both radiomic and generated features as input to predict the disease label (COVID-19 or CAP), optimizing a diagnosis-specific loss function to ensure the generated features contribute meaningfully to classification. The method is trained and evaluated on a large annotated CT dataset collected from several hospitals and imaging devices, making it robust across scanner variability. With joint optimization of adversarial, reconstruction, and diagnostic losses, GACDN achieves high diagnostic accuracy while eliminating the need for manual segmentation making it particularly useful in low-resource clinical environments.",Generative Adversarial Feature Completion and Diagnosis Network (GACDN),No,No, distinguishing COVID-19 infections from community-acquired pneumonia (CAP) using chest CT imaging,Medical Images (CT scans),Zhu et.al,Yes,"The study evaluated the effectiveness of the proposed GACDN model in improving the diagnostic accuracy of COVID-19 vs. community-acquired pneumonia (CAP) from chest CT images, particularly in the presence of incomplete handcrafted feature data. The evaluation was carried out through a series of experiments using a dataset of 2,522 CT images (1,495 COVID-19 and 1,027 CAP cases). The performance of GACDN was assessed under three main setups: (1) comparison of baseline classifiers using radiomic features alone vs. radiomic plus GACDN-generated handcrafted features, (2) comparison against traditional and deep learning-based feature extraction methods, and (3) comparison with state-of-the-art incomplete multi-view learning methods. Standard classification algorithms including logistic regression, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks (NN) were used for performance benchmarking. The models were trained and tested using 10-fold cross-validation, and evaluated using metrics such as accuracy (ACC), sensitivity (SEN), specificity (SPE), and area under the curve (AUC). The results demonstrated that GACDN significantly improved diagnostic performance across all classifiers and outperformed competing methods in both feature extraction and incomplete data recovery scenarios.","{'accuracy', 'sensitivity', 'specificity', 'AUC'}","    ""Radiomic Only"": {
        ""LR"": {""ACC"": 87.74, ""SEN"": 90.34, ""SPE"": 83.90, ""AUC"": 87.12},
        ""SVM"": {""ACC"": 86.59, ""SEN"": 89.30, ""SPE"": 82.72, ""AUC"": 86.01},
        ""KNN"": {""ACC"": 85.76, ""SEN"": 90.04, ""SPE"": 79.72, ""AUC"": 84.88},
        ""NN"": {""ACC"": 87.19, ""SEN"": 84.23, ""SPE"": 91.60, ""AUC"": 87.91},
    },
    ""Radiomic + GACDN"": {
        ""LR"": {""ACC"": 90.83, ""SEN"": 92.41, ""SPE"": 88.52, ""AUC"": 90.46},
        ""SVM"": {""ACC"": 89.13, ""SEN"": 90.24, ""SPE"": 87.62, ""AUC"": 88.93},
        ""KNN"": {""ACC"": 89.61, ""SEN"": 91.97, ""SPE"": 86.19, ""AUC"": 89.08},
        ""NN"": {""ACC"": 90.23, ""SEN"": 90.44, ""SPE"": 90.98, ""AUC"": 91.12}
    }",
,,,,,,,,,,,,,,,,,,,,,,,"feature_selection_comparison = {
    ""LRR"": {""ACC"": 88.02, ""SEN"": 89.02, ""SPE"": 86.79, ""AUC"": 87.90},
    ""LatLRR"": {""ACC"": 90.43, ""SEN"": 90.92, ""SPE"": 88.30, ""AUC"": 90.11},
    ""LPP"": {""ACC"": 89.12, ""SEN"": 90.97, ""SPE"": 86.83, ""AUC"": 89.08},
    ""SAE"": {""ACC"": 90.20, ""SEN"": 91.22, ""SPE"": 88.79, ""AUC"": 90.01},
    ""AFS-DF"": {""ACC"": 90.67, ""SEN"": 90.49, ""SPE"": 90.41, ""AUC"": 90.91},
    ""GACDN"": {""ACC"": 91.31, ""SEN"": 91.62, ""SPE"": 91.01, ""AUC"": 91.32}
}",
,,,,,,,,,,,,,,,,,,,,,,,"incomplete_multiview_comparison = {
    ""PVC"": {""ACC"": 73.16, ""SEN"": 87.89, ""SPE"": 51.44, ""AUC"": 69.67},
    ""UEAF"": {""ACC"": 88.61, ""SEN"": 88.71, ""SPE"": 88.55, ""AUC"": 88.63},
    ""IMC-GRMF"": {""ACC"": 85.85, ""SEN"": 88.59, ""SPE"": 81.96, ""AUC"": 85.27},
    ""GAIN"": {""ACC"": 88.36, ""SEN"": 87.87, ""SPE"": 83.84, ""AUC"": 86.55},
    ""AGC-IMC"": {""ACC"": 88.69, ""SEN"": 89.62, ""SPE"": 87.34, ""AUC"": 88.48},
    ""GACDN"": {""ACC"": 91.31, ""SEN"": 91.62, ""SPE"": 91.01, ""AUC"": 91.32}
}",
18,"Chang Z, Zhan Z, Zhao Z, You Z, Liu Y, Yan Z, Fu Y, Liang W, Zhao L.",2021,"College of Mechanical and Electrical Engineering, Guangdong University of Science and Technology, Dongguan, China.",Application of artificial intelligence in COVID-19 medical area: a systematic review,J Thorac Dis,Respiratory Virology,['COVID-19'],"Journal Article, Review","The aim of this study is to systematically review and analyze the diverse applications of artificial intelligence (AI) across six medical domains epidemiology, diagnosis, disease progression, treatment, psychological health impact, and data security during the COVID-19 pandemic."," Traditional methods of diagnosis, treatment, and outbreak control were often too slow, labor-intensive, or fragmented to effectively manage the fast-spreading virus. Moreover, the pandemic generated vast amounts of heterogeneous medical and behavioral data, which overwhelmed conventional analysis systems. There was a pressing need for scalable, intelligent technologies that could extract meaningful insights from multimodal data, enable early diagnosis and prognosis, support drug and vaccine development, and ensure data privacy and security.","The study seeks to understand how AI models have improved accuracy in outbreak prediction, automated diagnosis from medical images and laboratory data, guided treatment strategies including drug repurposing and vaccine design, and supported mental health assessments and data protection. ","This study employs a systematic literature review approach, adhering to the PRISMA checklist, to identify and analyze AI applications in COVID-19-related medical domains. Researchers searched PubMed, arXiv, medRxiv, and Google Scholar up to February 2020 using a structured query combining keywords related to AI (e.g., “artificial intelligence,” “machine learning,” “deep learning”) and COVID-19. An initial pool of over 144,000 articles was narrowed down to 82 relevant studies through deduplication, title screening, and abstract review. These studies were then categorized into six thematic areas epidemiology, diagnosis, progression, treatment, psychological impact, and data security. For each area, the authors extracted details on AI models used (e.g., CNN, RNN, LSTM, SVM, XGBoost), input modalities (e.g., CT/X-ray images, blood data, demographic data), and evaluation metrics (e.g., accuracy, AUC, RMSE). Comparative analysis highlighted the role of AI in automating medical workflows, reducing human intervention, and improving prediction and diagnostic performance during the pandemic.","LSTM was employed in multiple studies to predict the COVID-19 pandemic trends. Yang et al. used it with SEIR for dynamic forecasting using migration and epidemiological data. Chimmula et al. applied LSTM to Canadian case data to predict short and long-term trends, while Kolozsvari et al. used RNN with LSTM for cross-country epidemic prediction.",LSTM,No,No,COVID-19 spread prediction and severity evaluation,"COVID-19 Image Dataset and Genomic Dataset,  Johns Hopkins University COVID-19 data, WHO & Johns Hopkins global datasets (cases, deaths)",Chang et.al,Yes,LSTM captured pandemic dynamics accurately. Chimmula et al. reported RMSE and accuracy for both short- and long-term forecasts. Kolozsvari et al. used RMSLE to validate model accuracy across different countries.,"{'Accuracy', 'RMSE'}","{ ""Chimmula_short_term"": {""RMSE"": 34.83, ""Accuracy"": 93.4},  ""Chimmula_long_term"": {""RMSE"": 45.70, ""Accuracy"": 92.67},  ""Kolozsvari_RMSLE_Hungary"": 0.06,  ""Kolozsvari_RMSLE_UK"": 0.234,  ""Kolozsvari_RMSLE_Italy"": 0.114}",
,,,,,,,,,,,,,"CNN models were used in both epidemiological modeling and diagnosis. Fong et al. implemented a PNN+cf model to enhance prediction with limited data. Hu et al. used CNN with MAE for epidemic forecasting. In diagnosis, CNNs (ResNet variants) were widely applied for chest CT/X-ray classification to identify COVID-19.",CNN (Convolutional Neural Networks),No,No,"Spread prediction, Diagnosis from CT/X-ray imaging","China’s official case counts, CT images, Chest X-rays",Chang et.al,Yes,CNN-based methods demonstrated excellent diagnostic performance. Wang et al.’s 3D U-Net++ model achieved high AUC on CT data. Narin et al.’s ResNet50 outperformed others in X-ray classification with accuracies >96%.,"{""MAE"", ""Sensitivity"", 'Specificity"",""AUC"", ""Accuracy""}
","{
  ""Hu_CNN_MAE"": {""Error_rate"": 0.0073},
  ""Fong_PNN_cf"": {""Low_data_optimized"": True},
  ""Wang_CNN_CT"": {""Sensitivity"": 0.974, ""Specificity"": 0.922, ""AUC"": 0.991},
  ""Narin_ResNet50"": {""Accuracy"": 0.98}
}",
,,,,,,,,,,,,,"Wang et al. used U-Net++ as part of a three-step COVID-19 screening process in CT images: segmenting lung areas, locating lesions, and isolating infected regions. It assisted in reducing physician workload by 30–40%.",U-Net++,No,No,Diagnosis (CT-based lesion segmentation),CT images,Chang et.al,Yes,"This method provided high diagnostic sensitivity and specificity, streamlining radiological workflows and improving interpretability.","{""Sensitivity"", ""Specificity"", ""AUC""}","{""Sensitivity"": 0.974, ""Specificity"": 0.922, ""AUC"": 0.991}",
,,,,,,,,,,,,,"Xu et al. used ResNet-18 for 3-class classification of CT images (COVID-19, influenza A, healthy). Narin et al. applied ResNet variants to X-ray classification, achieving top performance with ResNet50. Zhang et al. introduced a ResNet-based CAAD model for anomaly detection in X-rays.","ResNet (ResNet-18, ResNet-50, etc.)",No,No,COVID-19 diagnosis from CT and X-ray images.,"CT images, X-ray images",Chang et.al,Yes,ResNet-based models were robust across modalities and classification types. Accuracy and AUC scores were consistently high across studies.,"{""Accuracy"", ""Sensitivity"", ""Specificity"", ""AUC""} ","{
  ""Xu_ResNet18_CT"": {""Accuracy"": 0.867},
  ""Narin_ResNet50_Xray"": {""Accuracy"": 0.98},
  ""Zhang_CAAD_Xray"": {""Sensitivity"": 0.96, ""Specificity"": 0.707, ""AUC"": 0.952}
}",
,,,,,,,,,,,,,"Hu et al. employed a modified stacked auto-encoder (MAE) to model the COVID-19 transmission in China. It used demographic data from January 11 to February 27, 2020, clustering 34 Chinese provinces/cities into nine groups based on similar transmission characteristics.",Modified Auto-Encoder (MAE),No,No,COVID-19 spread prediction and severity evaluatio,"Demographic data from all of China, Jan–Feb 2020 (confirmed case counts)",Chang et.al,Yes,"The MAE model achieved a low error rate of 0.73%, indicating strong predictive accuracy across multiple provincial trajectories.","{""MAE""}
","{ ""Hu_MAE_spread"": {""Error_rate"": 0.0073}}",
,,,,,,,,,,,,,"Wang et al. developed a GRU-based model with bidirectional and attentional mechanisms (BI-AT-GRU) to classify six types of respiratory patterns critical for diagnosing COVID-19, including Eupnea and Central Apnea.",BI-AT-GRU (Bidirectional Attention Gated Recurrent Unit),No,No,Symptom-based diagnosis via respiratory pattern classification,Clinical respiratory audio patterns,Chang et.al,Yes,"BI-AT-GRU achieved high classification performance for respiratory patterns, helpful in non-invasive COVID-19 detection scenarios.","{""Accuracy"", ""Precision"", ""Recall"", ""F1""}","{  ""Wang_BIGRU_respiratory"": {""Accuracy"": 0.945, ""Precision"": 0.944, ""Recall"": 0.951, ""F1"": 0.948}}",
,,,,,,,,,,,,,"Kukar et al. developed a CRISP-DM pipeline using DNNs to classify COVID-19 based on routine blood tests. The model utilized five blood markers (e.g., MCHC, albumin, INR) and was trained on thousands of cases.",Deep Neural Network (DNN – CRISP-based),No,No,Laboratory-based diagnosis via blood parameters.,COVID-19 patients and historical non-COVID cases with blood test data,Chang et.al,Yes,"DNN yielded high specificity (97.9%) and strong AUC (0.97), indicating robustness in early symptomatic detection using standard lab tests.","{""Sensitivity"", ""Specificity"", ""AUC""}","{""Sensitivity"": 0.819, ""Specificity"": 0.979, ""AUC"": 0.97}",
,,,,,,,,,,,,,"Beck et al. utilized MT-DTI, a deep learning framework incorporating natural language processing (NLP) using BERT, to predict drug-target interactions for repurposing existing drugs against SARS-CoV-2.",MT-DTI (Molecule Transformer – Drug Target Interaction model),No,No,Drug repurposing for COVID-19.,drug-target pairs and protein sequences,Chang et.al,Yes,MT-DTI predicted interaction strengths (Kd values) for thousands of drugs; Atazanavir showed the strongest affinity (Kd = 94.94 nM).,"{""kd_values""}","{
  ""MTDTI_Atazanavir"": {""Kd_nM"": 94.94},
  ""MTDTI_Ritonavir"": {""Kd_nM"": 204.05},
  ""MTDTI_Dolutegravir"": {""Kd_nM"": 336.91}
}",
,,,,,,,,,,,,,Zeng et al. created a knowledge graph-based deep learning model combining drug-disease-gene literature to identify repurposable drugs. It was evaluated against ongoing COVID-19 clinical trial data.,KG-DML (Knowledge Graph-based Deep Machine Learning),No,No,Drug repurposing,,Literature-derived biomedical relations,Yes,"KG-DML achieved an AUC of 0.85 in identifying validated repurposable drugs (e.g., dexamethasone, niclosamide).","{""AUC""}","{""AUC"": 0.85}",
19,Tayarani N MH.,2021,"Biocomputation Group, School of Computer Science, University of Hertfordshire, Hatfield, AL10 9AB, United Kingdom.",Applications of artificial intelligence in battling against covid-19: A literature review,Chaos Solitons Fractals,Respiratory Virology,['COVID-19'],"Journal Article, Review",The aim of this paper is to conduct a comprehensive survey of the applications of Artificial Intelligence (AI) in combating the COVID-19 pandemic.,"The COVID-19 pandemic has presented unprecedented global challenges, including the rapid spread of infection, limited medical resources, delayed diagnostics, and a significant socio-economic impact. Traditional approaches in healthcare and public health have struggled to address these challenges effectively due to their limitations in speed, scalability, and adaptability. In this context, there is a pressing need to explore how AI techniques ranging from machine learning to deep neural networks can provide innovative solutions for real-time diagnosis, patient risk assessment, disease progression monitoring, epidemiological modeling, and policy planning. ","To develop and apply AI methodologies including machine learning, deep learning (e.g., CNN, LSTM, GAN), natural language processing, and evolutionary algorithms for automating, enhancing, and accelerating critical tasks in COVID-19 management such as patient diagnosis, risk stratification, outcome prediction, image classification, epidemic trend forecasting, contact tracing, and misinformation detection, using heterogeneous data sources (clinical, textual, imaging, epidemiological).","The study reviews a wide range of AI methodologies applied across clinical and epidemiological domains in the context of COVID-19. In the clinical setting, machine learning (ML) algorithms such as support vector machines (SVM), random forests, logistic regression, and artificial neural networks (ANN) were used to diagnose COVID-19 from blood tests, clinical symptoms, and vital signs, as well as to predict disease severity, mortality, and treatment prioritization. Deep learning (DL) techniques, especially convolutional neural networks (CNNs), were extensively used for chest X-ray and CT image classification, with some studies employing advanced models like EfficientNet, DenseNet, U-Net, and ensemble architectures. Transfer learning was frequently applied due to limited data availability, often leveraging pretrained models (e.g., ResNet, Inception, VGG) to improve performance on COVID-19 datasets. Recurrent neural networks (RNNs), including LSTM and GRU architectures, were applied to time series data for epidemic forecasting and patient outcome prediction. In epidemiological modeling, hybrid approaches combining statistical forecasting (e.g., ARIMA, Holt’s method) with neural networks and optimization algorithms (e.g., genetic algorithms, swarm intelligence) were employed to model virus transmission dynamics and public health interventions. Natural language processing (NLP) methods were also used to extract information from clinical reports and social media, aiding in misinformation detection and psychological impact analysis. The integration of multimodal data (text, imaging, lab results, sensor data) and the adoption of federated learning, weak supervision, and semi-supervised learning frameworks further highlight the methodological diversity in AI-driven COVID-19 research.
","AI methods for COVID-19 diagnosis involved CNNs and transfer learning architectures such as ResNet, VGG16, EfficientNet, Inception, and DenseNet, primarily for classifying CT and X-ray images of lungs. Traditional ML models—including SVM, Random Forest, XGBoost, and Logistic Regression—were applied to clinical and symptom-based data such as blood biomarkers, respiratory signals, and questionnaire responses. Ensemble learning approaches combined multiple models to enhance diagnostic accuracy. GANs and data augmentation techniques were used to address the scarcity of labeled medical images. Mobile-based diagnostic apps leveraged cloud-hosted AI to analyze cough patterns and symptom inputs. NLP models were also employed to interpret clinical text and triage questionnaires for probable infection identification.","CNNs, SVM, Random Forest, XGBoost, ANN, Logistic Regression, GANs, Transfer Learning, Ensemble Learning",No,No,Diagnosis (Clinical + Imaging + Symptom-Based),"Chest X-ray images, CT scans, blood tests (CBC, biomarkers), respiratory pattern recordings, symptoms, questionnaire data.","COVIDx Dataset (Chest X-ray), COVID-CT Dataset (CT Scans), CORD-19 (for clinical reports, NLP) ,Custom hospital datasets (symptom and lab data)",Yes,"Model accuracy for diagnosis (COVID-19 positive/negative classification) was measured using Sensitivity, (Recall), Specificity, AUC (Area under ROC curve), F1-Score","{Sensitivity, (Recall), Specificity, AUC (Area under ROC curve), F1-Score}","{
  ""Accuracy"": 0.95,
  ""Sensitivity"": 0.92,
  ""Specificity"": 0.97,
  ""AUC"": 0.96,
  ""F1-Score"": 0.94
}",
,,,,,,,,,,,,,"AI tools such as SVMs, ANNs, and deep neural networks were used to predict disease progression and support triage decisions, helping identify patients who might need intensive care (e.g., oxygen therapy or ventilator support). Multi-criteria decision analysis algorithms were implemented to rank patients using laboratory test results and health history for plasma therapy or ICU access. These tools allowed for real-time prioritization of medical resources based on a comprehensive risk profile derived from multimodal patient data.","SVM, ANN, Multi-criteria Decision Analysis, Deep Neural Networks",No,No, Treatment Guidance and Risk Stratification,"Laboratory blood tests, patient demographics, symptom severity scores, clinical notes.","Hospital triage datasets (proprietary, internal), COVID-19 Prognosis datasets (patient outcomes)",Yes,"Predicting patient recovery likelihood, oxygen need, or ventilator prioritization. Was Evaluated with Accuracy, Precision, Recall.","{Accuracy, Precision, Recall}","{
  ""Accuracy"": 0.87,
  ""Precision"": 0.85,
  ""Recall"": 0.88
}",
,,,,,,,,,,,,,"For patient monitoring, AI models like Random Forest, XGBoost, DNNs, Logistic Regression, and Gradient Boosting analyzed clinical and laboratory time-series data to forecast ICU transfer, ventilation needs, or death. Graph Neural Networks (GNNs) captured spatial and relational data—such as inter-patient similarity or hospital movement—to predict infection spread. Speech and audio classifiers were also introduced to analyze fatigue, anxiety, and emotional distress from voice recordings. Ensemble-based learning systems were often deployed to strengthen early warning systems for triaging high-risk patients.","Random Forest, XGBoost, DNN, Logistic Regression, Gradient Boosting, Ensemble Learning, Graph Neural Networks (GNN), Speech-based ML models",No,No,"Patient Monitoring (Severity, Mortality, Recovery Prediction)","Vital signs, lab time series (platelet counts, CRP, lymphocyte counts), demographics, survival status","COVID-19 Clinical Data from South Korea, New York, Brazil datasets.",Yes,"Risk scoring, predicting ICU transfer, death risk, or ventilation need was measured using AUC, F1-Score, Sensitivity, Specificity.","{AUC, F1-Score, Sensitivity, Specificity}","{
  ""AUC"": 0.91,
  ""F1-Score"": 0.89,
  ""Sensitivity"": 0.88,
  ""Specificity"": 0.90
}",
,,,,,,,,,,,,,"Deep learning models, including CNNs, 3D CNNs, U-Nets, and Capsule Networks, were used to detect and localize COVID-19 from imaging data. EfficientNet provided a lightweight yet accurate alternative for mobile and real-time applications. YOLO and DeepSORT frameworks were applied to real-time video feeds for monitoring mask usage and social distancing compliance. GANs helped generate synthetic images to enrich training datasets. Hybrid models, such as LSTM-CNN combinations, were used for processing temporal imaging data, and semi-supervised learning addressed annotation scarcity. Ensemble CNN architectures further boosted detection accuracy by fusing outputs from networks like DenseNet and SqueezeNet.","CNNs, 3D CNNs, U-Net, EfficientNet, Autoencoders, Capsule Networks, YOLO, GANs, LSTM-CNN hybrids",No,No,CT and X-ray Image Processing,"CT scan slices, chest X-ray","COVID-CT Dataset, COVIDx CXR Dataset, Clean-CC-CCII Dataset (CT scans)",Yes,"Image classification accuracy (COVID-19 vs normal vs pneumonia). Was measured using Metrics: Accuracy, AUC, Precision, Recall, F1-Score.","{ Accuracy, AUC, Precision, Recall, F1-Score}","{
  ""Accuracy"": 0.94,
  ""AUC"": 0.95,
  ""Precision"": 0.93,
  ""Recall"": 0.92,
  ""F1-Score"": 0.92
}",
,,,,,,,,,,,,,"LSTM and GRU neural networks were widely used to model and predict infection curves, hospitalization rates, and mortality trends. These deep learning models were often hybridized with compartmental models like SIR and SEIR to better capture disease dynamics. CNNs, including 1D CNNs, processed temporal signals such as case curves and online behavior patterns. Self-organizing maps and clustering algorithms identified regional or demographic risk zones. Reinforcement learning frameworks were introduced to simulate and optimize public health policy decisions over time based on real-time input data.","LSTM, GRU, ARIMA, Hybrid Neural Networks, Bayesian Inference, CNNs, Reinforcement Learning, Self-Organizing Maps",No,NO,Epidemiological Modeling and Forecasting,"Time-series of daily COVID-19 cases, recoveries, deaths, mobility trends, interventions (lockdowns, mask mandates).",Johns Hopkins University COVID-19 Dataset,Yes,"Forecasting new infections, death counts, hospitalization needs.
Metrics: RMSE (Root Mean Squared Error), MAE (Mean Absolute Error).","{RMSE (Root Mean Squared Error), MAE (Mean Absolute Error).}","{
  ""RMSE"": 250.0,
  ""MAE"": 180.0
}",
,,,,,,,,,,,,,"In pandemic control, AI models such as CNNs (e.g., YOLO v3) were integrated into video surveillance systems to monitor mask-wearing and social distancing. NLP-based models mined social media and public text data to track misinformation, behavioral trends, and compliance patterns. Federated learning enabled decentralized, privacy-preserving training of hospital-based models. ANN and decision tree algorithms were used in mobile apps and geospatial risk mapping tools to assess local transmission risks and generate individual-level exposure scores.","NLP, CNN (YOLO), Federated Learning, Decision Trees, ANN, SVM",No,No,"Pandemic Control (Contact Tracing, Surveillance, Risk Assessment)","GPS traces, exposure notifications, public surveillance videos, text-based social media posts.",Mobile device datasets (contact tracing apps like SafePaths),Yes,"Contact detection accuracy, social distancing violation detection.
Metrics: Precision, Recall, F1-Score for detection tasks.","{Precision, Recall, F1-Score}","{
  ""Precision"": 0.90,
  ""Recall"": 0.88,
  ""F1-Score"": 0.89
}",
,,,,,,,,,,,,,"To monitor the psychological toll of COVID-19, AI methods including Bayesian Networks and ANNs analyzed data from surveys, social media, and educational platforms to assess emotional distress and satisfaction. NLP-based sentiment analysis and topic modeling techniques detected anxiety, isolation, and depression symptoms in public discourse. These insights were used to tailor interventions, forecast mental health deterioration trajectories, and support digital mental health solutions during the pandemic.","Bayesian Networks, ANN, NLP, Sentiment Analysis",No,No,Psychological Impact and Mental Health Monitoring,"Questionnaire responses, social media text about anxiety, depression, coping mechanisms.",Survey-based datasets (mental health surveys during COVID-19),Yes,"Mental health risk classification, stress detection, satisfaction prediction.
Metrics: Accuracy, F1-Score.","{Accuracy, F1-Score}","{
  ""Accuracy"": 0.85,
  ""F1-Score"": 0.83
}",
20,"Lee CY, Chen YP.",2021,No authors found,New Insights Into Drug Repurposing for COVID-19 Using Deep Learning,IEEE Trans Neural Netw Learn Syst,Emerging & Re-emerging Viruses,['COVID-19'],"Journal Article, Review","The study reviews current DL models used for COVID-19 Drug Repurposing, proposes new architectures that integrate attention mechanisms and pretrained BERT-based encoders, and explores how these advancements can be extended to treat other complex diseases.","Despite the rapid advancement of deep learning in drug repurposing for COVID-19, existing models face significant limitations that reduce their clinical usefulness. Current DL models often operate as opaque “black boxes,” providing little interpretability or insight into how predictions are made. They typically rely on 1-D representations like SMILES strings, which fail to capture critical topological information of drug molecules, and struggle to process complex biological networks involving virus–host–drug interactions. Moreover, these models are not yet capable of reliably predicting effective drug combinations or responding to viral mutations. Discrepancies between DL predictions and clinical outcomes further highlight the need for improved frameworks that integrate domain knowledge, enhance model transparency, and ensure higher predictive reliability in real-world medical applications.","The primary objective of the AI component in this study is to utilize advanced deep learning (DL) models to accurately identify and repurpose existing FDA-approved drugs for the treatment of COVID-19. The goal is to accelerate the drug discovery process by predicting potential drug–target interactions with high precision, identifying multitarget drugs, and discovering effective drug combinations. ","The study employs a range of deep learning methodologies to enhance drug repurposing for COVID-19. Key models include molecule transformer-based drug–target interaction (MT-DTI), BiLSTM-CNN hybrids, and graph-based models like GAT-CNN. These models process SMILES strings and protein sequences to predict drug binding affinities and interactions. Pretrained BERT-based encoders are used to capture semantic and structural information from large-scale drug and protein datasets. An encoder–decoder architecture is proposed, where SMILES and FASTA sequences are encoded and then combined in a decoder implemented using MLPs, transformers, CNNs, or LSTMs to predict repurposed drug candidates. Attention mechanisms and gated skip connections are integrated to enhance interpretability, while transfer learning is used to adapt pretrained models to smaller COVID-19-specific datasets, improving generalizability and reducing training costs.
","MT-DTI is a transformer-based deep learning model designed to predict the binding affinity between drugs and target proteins. It leverages the self-attention mechanism from the BERT architecture to model complex relationships between atoms in molecular sequences. The model is trained on SMILES representations for drugs and amino acid sequences for proteins. MT-DTI incorporates a character-embedded masked language model pretrained on a massive dataset of over 97 million chemical compounds, allowing it to effectively capture long-range dependencies and semantic similarities in molecular data. It outputs binding affinity scores (Kd values) for drug–target pairs and was used to screen FDA-approved drugs against key SARS-CoV-2 proteins such as 3CLpro, RdRp, and helicase.",Molecule Transformer–Drug Target Interaction (MT-DTI),https://github.com/deargen/mt-dti,MIT License.,Identification of antiviral drugs for SARS-CoV-2 targeting viral proteases and replication complexes.,Canonical SMILES for molecules and amino acid sequences for proteins., Drug Target Commons (DTC) and BindingDB databases.,Yes,"Performance was measured using binding affinity (Kd in nM). The model predicted inhibitory potencies for drugs against SARS-CoV-2 3CLpro. For instance, atazanavir (94.94 nM), remdesivir (113.13 nM), and others showed promising binding.","{""binding affinity (Kd in nM)""}","{ ""Atazanavir_Kd_nM"": 94.94,  ""Remdesivir_Kd_nM"": 113.13,  ""Efavirenz_Kd_nM"": 199.17,  ""Ritonavir_Kd_nM"": 204.05,  ""Dolutegravir_Kd_nM"": 336.91}",
,,,,,,,,,,,,,"This model combines the strengths of bidirectional long short-term memory (BiLSTM) networks and convolutional neural networks (CNNs) for drug–target interaction prediction. The SMILES strings of drug molecules are processed using BiLSTM layers to capture sequential chemical dependencies in both forward and backward directions. For protein sequences (FASTA format), a CNN with multiple convolutional and pooling layers is used to extract local features and spatial patterns. The latent representations of the drug and protein are concatenated and passed through fully connected layers to predict the interaction score. This model was trained using the KIBA dataset and validated via docking simulations against SARS-CoV-2 viral proteins.",BiLSTM-CNN Hybrid Model,No,No,Screening and identification of promising FDA-approved drugs against SARS-CoV-2 viral proteins.,1-D SMILES and FASTA protein sequences.,KIBA dataset (kinase inhibitors).,No,Not specified,Not specified,Not specified,
,,,,,,,,,,,,,"CNN-CNN: Two parallel CNN blocks for SMILES and protein sequences.
LSTM-LSTM: Two separate LSTM blocks for drugs and proteins.
CNN-LSTM: A hybrid structure using CNN for proteins and LSTM for drugs.
GAT-CNN: A graph attention network (GAT) is used to learn from molecular graphs (nodes = atoms, edges = bonds), while a CNN processes the protein sequence.
These models were trained using curated datasets from ChEMBL, UniProt, PubChem, and MOSES. Feature extraction is performed using autoencoders TF-LSTM for drugs and a convolutional autoencoder for proteins prior to prediction. These architectures allow flexible encoding and comparison of structural and sequence data for deep feature learning.
","End-to-End Deep Learning Models (CNN, LSTM, CNN-LSTM, GAT-CNN)",No,No,Drug–target binding prediction and drug repurposing for COVID-19.,1-D SMILES and protein sequences; molecular graphs (for GAT-CNN),"Aggregated from MOSES, ChEMBL, UniProt, PubChem, and NCBI",Yes,Implied but specific numerical results not detailed.,these models were used and they successfully identified potential drug candidates.,,
,,,,,,,,,,,,,"This advanced graph-based model enhances the standard Graph Convolutional Network (GCN) by integrating attention mechanisms and gated skip connections. The attention mechanism allows the model to weigh the importance of each node (atom) in the molecular graph based on its chemical context. Gated connections improve the flow of gradients and feature reuse across layers. Together, this configuration enables the model to identify and focus on critical molecular substructures directly associated with binding affinity or other pharmacological properties. This approach significantly reduces prediction error and improves model interpretability, helping identify why certain compounds might be effective against COVID-19 targets.",Attention-Augmented GCN (GCN + Attention + Gate),No,No,Drug feature attribution and repurposing for COVID-19,Molecular graphs with atomic and bond features,Lee et.al,Yes,"MAE was compared between vanilla GCN, GCN+attention, GCN+gates, and GCN+attention+gates. Best result from the latter.","{""MAE:""}","{  ""MAE_GCN"": ""Higher"",  ""MAE_GCN+Attention"": ""Lower"",  ""MAE_GCN+Gate"": ""Lower"",  ""MAE_GCN+Attention+Gate"": ""Lowest""}",
,,,,,,,,,,,,,"This proposed architecture consists of two pretrained BERT-based encoders: one for encoding SMILES strings of drug molecules and another for encoding FASTA protein sequences. These encoders generate high-dimensional feature embeddings, which are then concatenated and passed into a decoder that can be a multilayer perceptron (MLP), Transformer, LSTM, or CNN. The model uses three separate Adam optimizers to independently tune the learning rates of both encoders and the decoder, ensuring optimal balance between leveraging pretrained knowledge and adapting to new COVID-19 data. This architecture enables fine-grained modeling of molecular interactions and supports interpretability by highlighting the contributing substructures. Additionally, it supports multi-target binding prediction, drug combination synergy, and side-effect forecasting, making it suitable for complex tasks in drug repurposing.",BERT-Based Encoder–Decoder Framework for Drug Repurposing,No,No,Predicting repurposed drugs for COVID-19 and modeling drug–protein interaction.,SMILES strings and protein sequences.,Lee et.al,No,No quantitative metrics reported. Proposed framework with qualitative advantages in interpretability and efficiency,,,
21,"Dhiman G, Vinoth Kumar V, Kaur A, Sharma A.",2021,"Department of Computer Science, Government Bikram College of Commerce, Punjabi University, Patiala, 147001, Punjab, India. gdhiman0001@gmail.com.",DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images,Interdiscip Sci,Respiratory Virology,['SARS-CoV-2'],"Comparative Study, Journal Article","The primary aim of the research is to develop an automated detection method for identifying COVID-19 infected patients using chest X-rays. This involves leveraging multi-objective optimization and deep-learning methodologies, particularly convolutional neural networks (CNNs), to enhance the diagnostic process for COVID-19.","Current diagnostic methods, like RT-PCR tests, have limitations including sensitivity issues and delays in results. This necessitates an alternative rapid diagnostic tool to enable timely and accurate identification of infected individuals to help contain the spread. Thus, the need arises to develop a robust, automated system leveraging artificial intelligence, specifically deep learning models applied to X-ray images, to classify and detect COVID-19 infections efficiently and assist in public health responses.","The research employs a methodology that combines deep learning and optimization techniques to automate the detection of COVID-19 using chest X-ray images. Initially, chest X-ray images are collected from open-source repositories and preprocessed to ensure uniformity in size. The study utilizes eleven pre-trained convolutional neural network (CNN) models, such as AlexNet, VGG16, ResNet101, and others, to extract deep features from the images through transfer learning. These features are then classified using the J48 decision tree algorithm, which effectively distinguishes between COVID-19 positive and negative cases. To enhance the performance of the CNN models, the Multi-objective Emperor Penguin Optimizer (MOEPO) is employed, optimizing model parameters by balancing exploration and exploitation during training.",Deep learning-based approach using pre-trained CNN models and J48 classification algorithm.,"The process begins with the collection of chest X-ray images from publicly available databases such as GitHub and Kaggle. Both COVID-19 positive and normal patient images are collected. Images are preprocessed to a standard size (e.g., 280x280 pixels) to ensure consistent input dimensions for the neural networks. A set of eleven pre-trained CNN models is utilized, including architectures such as AlexNet, VGG16, VGG19, GoogleNet, and various ResNet versions (ResNet18, ResNet50, ResNet101), among others like InceptionV3, InceptionResNetV2, DenseNet201, and XceptionNet. These models employ transfer learning to leverage pre-learned weights from larger datasets (e.g., ImageNet), which enhances their ability to extract relevant features from medical images. The deep features extracted from the X-ray images by the CNN models are classified using the J48 decision tree algorithm. J48 is an extension of the ID3 algorithm that supports decision tree pruning, handling of missing values, and derivation of rules. This classification step distinguishes between X-rays of COVID-19 patients and normal patients based on the extracted features. Multi-objective Emperor Penguin Optimizer (MOEPO) is used to optimize the hyperparameters of the CNN models. Inspired by the huddling behavior of emperor penguins, this optimizer focuses on achieving a balance between exploration and exploitation to find the best solutions efficiently. The optimizer calculates distance and temperature profiles to update the positions of virtual ""penguins,"" aiming to discover an optimal configuration of CNN parameters that improves classification performance.",Multi-Objective Optimization with Convolutional Neural Networks (CNN),No,No,COVID-19 Detection using Chest X-Ray Images,Medical Images (Chest X-ray),Dhiman et. al,Yes,"The evaluation was based on its ability to accurately classify chest X-ray images of patients as either COVID-19 positive or negative. The performance was measured using several well-known metrics to assess the effectiveness and reliability of the models. These metrics include accuracy, recall, specificity, precision, and F1-score.",The combination of ResNet101 with the J48 decision tree was found to provide the best performance across these metrics.,,
22,"Liu W, Liu X, Peng M, Chen GQ, Liu PH, Cui XW, Jiang F, Dietrich CF.",2021,"Department of Medical Ultrasound, The Second Hospital of Anhui Medical University, Hefei 230601, Anhui Province, China.",Artificial intelligence for hepatitis evaluation,World J Gastroenterol,Hepatic Virology,"['Hepatitis A', 'Hepatitis B', 'Hepatitis C', 'Hepatitis E']","Journal Article, Review","The aim of the research is to systematically review and summarize the applications of artificial intelligence (AI), encompassing both traditional machine learning and deep learning, in the diagnosis and management of hepatitis. This includes evaluating AI’s potential in predicting the incidence of various types of hepatitis, classifying different stages of hepatitis, screening and diagnosing hepatitis, forecasting its progression, and predicting patient responses to antiviral drugs. Additionally, the research focuses on the application of AI in radiology to assess liver conditions such as fibrosis, hepatocellular carcinoma (HCC), and related complications.","Traditional approaches for diagnosing and managing hepatitis often involve invasive procedures and are limited in predictive accuracy and adaptability. There is a critical need for more accurate, non-invasive, and efficient diagnostic tools to address these limitations.","To enhance the diagnosis, classification, and prediction of various hepatic diseases, including hepatitis, liver fibrosis, and hepatocellular carcinoma (HCC).","The AI methodology in this research leverages a combination of machine learning, deep learning, and radiomics to enhance the diagnosis and management of hepatic diseases, including various forms of hepatitis, liver fibrosis, and hepatocellular carcinoma (HCC). Traditional machine learning approaches, such as autoregressive integrated moving average (ARIMA), support vector machines (SVM), and long-short term memory networks (LSTM), are applied to predict the incidence and progression of hepatitis by mining large datasets from health records and disease control databases. Deep learning techniques, particularly convolutional neural networks (CNNs), are employed to interpret complex medical imaging data such as CT and MRI scans, effectively diagnosing and staging liver diseases as well as differentiating malignant from benign liver conditions. This is further complemented by radiomics, which extracts quantitative features from these images to assist in predicting disease severity and potential complications. Hybrid models, combining various AI techniques, are also used to enhance prediction accuracy. The models are evaluated using metrics like root-mean-square error (RMSE), mean absolute error (MAE), and area under the receiver operating characteristic curve (AUROC), ensuring robust performance in clinical applications. This integrative methodology provides a non-invasive, data-driven approach to advance hepatology, significantly aiding clinicians in diagnosis, treatment planning, and patient care.","ANN was applied to hepatitis A incidence forecasting and treatment response prediction for chronic hepatitis C (CHC). It used standard feed-forward architectures trained on historical clinical or epidemiological datasets, employing supervised learning to minimize prediction errors like RMSE or classification errors. BP-ANN was part of a hybrid model combining Grey system modeling with backpropagation-trained neural networks. Used to enhance time-series prediction of hepatitis B incidence by automatically learning temporal dependencies and trends from national incidence reports.",ANN & BP-ANN,No,No,"Predicting incidence of hepatitis A, Predicting treatment response in chronic hepatitis C (CHC), Forecasting incidence of hepatitis B","Time-series incidence records (hepatitis A), Serological response data to IFN+RIB (hepatitis C)","Liaoning CDC hepatitis A data (1987–2001), Clinical serological dataset for CHC patients (n=300), National Health Commission hepatitis B data (2003–2012)",Yes,"For hepatitis A: Correlation coefficient
For CHC treatment: Diagnostic accuracy.  Regression performance using RMSE, MAE, and correlation coefficient was measured for BP-ANN","{Correlation coefficient', 'Correlation coefficient'} {
    ""Correlation"",
    ""RMSE"",
    ""MAE""
  }","{  ""Hepatitis A"": {""Correlation_ANN"": 0.71},  ""CHC Treatment"": {""ANN_2_Accuracy"": 0.52, ""ANN_6_Accuracy"": 0.70}}  {
  ""BP-ANN"": {
    ""Correlation"": 0.9495,
    ""RMSE"": 4863.0,
    ""MAE"": 39704.0
  }
}",
,,,,,,,,,,,,,A recurrent neural network (RNN) architecture specifically adapted for time-series forecasting of hepatitis B. The network had internal memory units (context units) and was trained with 8 hidden neurons using reported cases from healthcare data. It captured short-term and long-term dependencies better than standard ANN for incidence prediction.,ElmanNN,No,No,Forecasting Hepatatis B incidence,Monthly reported cases of hepatatis B,Local Health Commission data,Yes,Forecasting accuracy was measured using MAE and MSE,"{MSE , MAE}","{'RMSE': 0.89, 'MAE': 0.70}",
,,,,,,,,,,,,,"LSTM was used in two places: (1) to predict monthly hepatitis E incidence from CDC surveillance data, outperforming ARIMA and SVM models, and (2) to classify hepatitis B patients vs non-hepatitis B based on Raman spectroscopy blood sample data, demonstrating superior sensitivity and specificity. The network could model temporal sequences and subtle spectral pattern shifts.",LSTM,No,No,Predicting hepatitis E incidence; (2) Classifying hepatitis B infection from Raman spectroscopy,Monthly case counts; Raman spectra from blood samples,"Local CDC Data (Hepatitis E), Raman Spectroscopy Dataset (Hepatitis B)",Yes," Incidence prediction; infection classification was measured using RMSE, MAE (for Hepatitis E); Accuracy, Sensitivity, Specificity, Precision (for Hepatitis B)","{'RMSE', 'MAE', 'Accuracy', 'Sensitivity', 'Specificity', 'Precision'}"," {'Hepatitis E Prediction': {'RMSE': 0.01, 'MAE': 0.011},
 'Hepatitis B Detection': {'Accuracy': 97.32, 'Sensitivity': 97.87, 'Specificity': 96.77, 'Precision': 96.84}}",
,,,,,,,,,,,,,Multiple variations: (1) CNNs were built on CT texture features to classify alcohol-associated hepatitis clinical severity; (2) CNNs with 3D U-Net structures segmented spleen and liver volumes from CTs to predict cirrhosis stages; (3) CNNs applied on gadoxetic acid-enhanced MRI and ultrasound images to stage hepatic fibrosis and predict outcomes like liver failure after hepatectomy. CNNs were sometimes pretrained (Transfer Learning) or trained from scratch.,CNN (Various Forms):,No,No,(1) Predicting clinical severity of alcohol-associated hepatitis; (2) Liver and spleen segmentation for fibrosis prediction; (3) Staging hepatic fibrosis; (4) Predicting liver failure after hepatectomy,Medical imaging data,Liu et.al,Yes,"Clinical severity classification; fibrosis staging; liver failure prediction was measured using Accuracy, AUC (Area Under Curve)","{AUC, Accuracy}","{'Clinical Severity Prediction (Alcoholic Hepatitis)': {'CNN Accuracy': 70},
 'Fibrosis Staging (MRI)': {'AUC for F4': 0.84, 'AUC for ?F3': 0.84, 'AUC for ?F2': 0.85},
 'Liver Failure Prediction': {'Accuracy': 0.802}}",
,,,,,,,,,,,,,"CNN architecture specifically trained on 2D-SWE (shear wave elastography) images of HBV patients to classify fibrosis stages (F2-F4). Outperformed traditional serological fibrosis scores (APRI, FIB-4) and elastography without deep learning. DLRE automatically learned elastographic patterns associated with fibrosis severity.",Deep Learning Radiomics of Elastography (DLRE),No,No,Liver fibrosis staging in chronic hepatitis B patients,Shear wave elastography images,Lie et.al,Yes,Fibrosis stage classification was measured using AUC,{'AUC'},"{'F4 Classification AUC': 0.97, '?F3 Classification AUC': 0.98, '?F2 Classification AUC': 0.85}",
,,,,,,,,,,,,,"Pretrained Inception-V3 CNN model fine-tuned for staging liver fibrosis using multimodal ultrasound data (grayscale, elastography). This transfer learning approach improved performance when training data was relatively small, avoiding overfitting and ensuring generalizable fibrosis classification.",Transfer Learning (CNN),No,No,Grading liver fibrosis from multimodal ultrasound,Ultrasound images,Liu et.al,Yes,Fibrosis grading was measured using AUC,{Accuracy},"{'AUC for S4': 0.950, 'AUC for ?S3': 0.932, 'AUC for ?S2': 0.930}",
,,,,,,,,,,,,,"CNN architecture combined with Recursive Feature Elimination using Random Forest (RFE-RF) for selecting optimal CT texture features. Applied to predict clinical severity (e.g., AST levels) in alcohol-associated hepatitis patients based on CT images.",Prototype CNN (3D U-Net),No,No,Predicting clinical severity in alcohol-associated hepatitis,Medical Images (CT scans),Liu et.al,Yes," Clinical severity prediction (e.g., AST levels) was measured using accuracy",{'Accuracy'},"{'RFE-RF Accuracy': 82.4, 'CNN Accuracy': 70}",
,,,,,,,,,,,,,  Ultrasound data sources like original radiofrequency signals and contrast-enhanced micro-flow features were combined into multiparametric datasets. CNNs and machine learning algorithms (like Adaboost and SVM) extracted patterns from these complex features for diagnosing significant hepatic fibrosis.,Multimodal Ultrasomics + DL,No,No,Assessing significant hepatic fibrosis,"Ultrasound radiofrequency signals, contrast-enhanced micro-flow features",Liu et.al,Yes,Diagnosis of significant hepatic fibrosis was measured using AUROC,{'AUROC'},{'AUROC': 0.85},
,,,,,,,,,,,,,Blood Raman spectra were fed into LSTM and CNN architectures to discriminate hepatitis B infection with extremely high sensitivity and specificity. The models learned spectral signatures (subtle wavelength shifts) associated with viral infection at the molecular level.,Combined CNN + Raman Spectroscopy  ,No,No,Rapid screening of hepatitis B infection,Raman spectral data from blood samples,Liu et.al,Yes,"Classification of hepatitis B infection vs non-hepatitis B was evaluated using Accuracy, Sensitivity, Specificity, Precision","{Accuracy, Sensitivity, Specificity, Precision}","{'Accuracy': 97.32, 'Sensitivity': 97.87, 'Specificity': 96.77, 'Precision': 96.84}",
23,"Zhu X, Fu B, Yang Y, Ma Y, Hao J, Chen S, Liu S, Li T, Liu S, Guo W, Liao Z.",2019,"College of Intelligence and Computing, Tianjin University, Peiyang Park Campus: No.135 Yaguan Road, Haihe Education Park, Tianjin, 300350, China.",Attention-based recurrent neural network for influenza epidemic prediction,BMC Bioinformatics,Respiratory Virology,['Influenza'],"Evaluation Study, Journal Article"," Develop a deep learning-based model, specifically an Attention-based Multi-Channel LSTM (Att-MCLSTM), that can accurately forecast real-time influenza-like illness rates (ILI%) in Guangzhou, China.","Develop a more robust and region-specific forecasting model that can fully utilize structured surveillance data, capture long-term temporal patterns, and account for the diverse influence of multiple input sources.","The AI objective of this study is to develop an advanced deep learning model capable of accurately forecasting weekly influenza-like illness rates (ILI%) in Guangzhou, China. To achieve this, the researchers aim to design a model that can effectively capture the complex temporal patterns and regional variations inherent in influenza surveillance data. The model must be able to process and integrate multiple types of heterogeneous inputs, including age-stratified case reports, pharmacy sales, and climate data. ","The approach begins with the collection and preprocessing of a comprehensive nine-year influenza surveillance dataset from Guangzhou, which includes both climate-related information and influenza-related data across nine districts. Using a model-based ranking method, 19 of the most relevant features are selected for forecasting. These features are then normalized using Min-Max scaling to ensure consistency in the input range. The dataset is split into training and testing sets, with 80% used for training and 20% for evaluation. To reflect the structure of the data, the model architecture processes two distinct input streams: one dedicated to shared climate variables and the other to region-specific influenza indicators. Each region’s influenza data is processed by its own LSTM unit, while the climate data is handled by a separate LSTM. The outputs from all LSTMs are merged and passed through an attention mechanism, which dynamically weighs the contribution of each regional input. Finally, this combined information is fed into a series of fully connected layers to generate the predicted ILI% for the upcoming week."," It works by separating the data into two parts: flu-related data from 9 different districts and climate data like temperature and humidity. Each district’s flu data goes into its own LSTM (a type of neural network that handles time-series data), while the shared climate data goes into another LSTM. This setup helps the model learn the unique trends for each region without mixing them up. After processing, the model uses an attention mechanism to figure out which regions’ data are most important for making accurate predictions. It gives more weight to the more relevant regions and then combines all the useful information. This combined data is passed through a few final layers to make the prediction. The model is trained on scaled (normalized) data and is evaluated using the Mean Absolute Percentage Error (MAPE). Important settings include using 32 units in each LSTM and the Adam optimizer to adjust the model during training.
",['Attention-based Multi-Channel Long Short-Term Memory Neural Network (Att-MCLSTM) Deep Neural Networks'],No,No,Forecasting Influenza-Like Illness Rate (ILI%),"structured, numerical time-series data",Guangzhou Influenza Surveillance Dataset,Yes,"The performance of the proposed Att-MCLSTM model was evaluated using Mean Absolute Percentage Error (MAPE), which measures the average percentage difference between predicted and actual ILI% values. Two main experiments were conducted. In the first experiment, the researchers tested different lengths of input sequences to determine the optimal number of consecutive weeks needed for accurate forecasting. The results showed that using 10 weeks of data yielded the best performance with a MAPE of 0.086, as shorter inputs lacked temporal context and longer inputs introduced noise.",{'MAPE'},"input_length_mape = {""6_weeks"": 0.107, ""8_weeks"": 0.092, ""10_weeks"": 0.086, ""12_weeks"": 0.106, ""14_weeks"": 0.109}",
,,,,,,,,,,,,,,,,,,,,,"In the second experiment, the model's forecasting ability was compared against three baseline models: multi-channel LSTM without attention (MCLSTM), single LSTM, and traditional RNN. The Att-MCLSTM model achieved the lowest MAPE (0.086), outperforming all other models, thus demonstrating the effectiveness of both its multi-channel structure and attention mechanism in handling regional influenza time-series data.",{'MAPE'}," {""Att-MCLSTM"": 0.086, ""MCLSTM"": 0.105, ""LSTM"": 0.118, ""RNN"": 0.132}",
24,"Zheng F, Li L, Zhang X, Song Y, Huang Z, Chong Y, Chen Z, Zhu H, Wu J, Chen W, Lu Y, Yang Y, Zha Y, Zhao H, Shen J.",2021,"School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510006, China.",Accurately Discriminating COVID-19 from Viral and Bacterial Pneumonia According to CT Images Via Deep Learning,Interdiscip Sci,Respiratory Virology,['SARS-CoV-2'],"Comparative Study, Journal Article","Develop a deep learning-based CT image diagnosis system that can automatically classify patients into four categories : COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls","Develop an automated diagnostic approach capable of accurately classifying multiple, visually similar pneumonia types in CT scans to improve diagnostic precision and reduce clinical workload.","The AI objective of this study is to build a high-performing deep learning model that can automatically classify CT chest images into four categories. The goal is to leverage the strengths of ResNet50 for deep feature extraction and enhance its capability using SE (Squeeze-and-Excitation) blocks, enabling the model to selectively focus on the most informative image regions and channels. The system is designed to support person-level diagnosis by aggregating predictions across CT slices.
","The AI methodology in this study involves a comprehensive pipeline that combines CT image preprocessing, intelligent slice selection, and deep learning-based classification. CT data were collected from 659 individuals across four categories : COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls yielding over 52,000 raw slices, which were filtered down to 5,363 diagnostically relevant slices using a structured selection strategy. Each image underwent preprocessing, including lung region segmentation, morphological cleaning, augmentation through rotation and translation, and resizing to a standard 512×512 resolution. To address class imbalance and enhance model generalization, data augmentation was applied at varying rates across classes. The core model architecture integrates a ResNet50 backbone with Squeeze-and-Excitation (SE) blocks.","ResNet50 serves as the backbone for feature extraction, while SE blocks enhance performance by learning to prioritize the most informative feature channels through adaptive attention. Each SE block compresses spatial features using global average pooling and applies learned weights to highlight key image regions. The model processes individual CT slices resized to 512×512 and then aggregates the prediction scores across all slices to produce a final person-level diagnosis. A fully connected layer with softmax activation is used for quaternary classification. The model is trained using the Adam optimizer with a low learning rate  of 1e?5, using cross-entropy loss for multi-class classification.",['ResNet50 with Squeeze-and-Excitation (SE) Blocks for Quaternary CT Image Classification'],https://github.com/Zhengfudan/COVID-19-Diagnosis-and-Pneumonia-Classification,No,distinguishing COVID-19 from typical viral pneumonia,Medical Images (CT scans),Zheng et. Al,Yes,"The model was evaluated on its ability to classify all four categories (COVID-19, bacterial pneumonia, typical viral pneumonia, healthy) simultaneously. Performance was reported as macro-average across the classes, as well as per-class AUC, precision, recall, and F1-score.","{""Accuracy"", ""AUC"", ""Recall"", ""Precision"", ""F1-score""}","{""AUC"": 0.96, ""Accuracy"": 0.94, ""Recall"": 0.94, ""Precision"": 0.95, ""F1-score"": 0.94}",
,,,,,,,,,,,,,,,,,,,,,"The model's ability to detect COVID-19 in more focused diagnostic scenarios, the authors conducted four binary classification experiments. In each case, the model was trained to distinguish COVID-19 patients from one or more other categories individually. The performance was assessed using AUC, Accuracy, Recall, Precision, and F1-score. These experiments demonstrated that while the model performed nearly perfectly in separating COVID-19 from healthy individuals, its performance decreased when distinguishing COVID-19 from typical viral pneumonia, due to their imaging similarity.
","{""Accuracy"", ""AUC"", ""Recall"", ""Precision"", ""F1-score""}","{""COVID_vs_Healthy"": {""AUC"": 0.99, ""Accuracy"": 0.98, ""Recall"": 1.00, ""Precision"": 0.96, ""F1-score"": 0.98}, ""COVID_vs_Bacterial"": {""AUC"": 0.94, ""Accuracy"": 0.86, ""Recall"": 0.93, ""Precision"": 0.81, ""F1-score"": 0.86}, ""COVID_vs_Viral"": {""AUC"": 0.91, ""Accuracy"": 0.83, ""Recall"": 0.92, ""Precision"": 0.81, ""F1-score"": 0.86}, ""COVID_vs_All"": {""AUC"": 0.92, ""Accuracy"": 0.85, ""Recall"": 0.90, ""Precision"": 0.82, ""F1-score"": 0.86}}",
,,,,,,,,,,,,,,,,,,,,,"The proposed model (ResNet50 + SE) was compared against DenseNet, VGG, and plain ResNet using the same dataset and training setup. Evaluation was based on AUC, Recall, Precision, F1-score, and Accuracy for the quaternary classification task.","{""Accuracy"", ""AUC"", ""Recall"", ""Precision"", ""F1-score""}","{""AUC"": 0.96, ""Accuracy"": 0.94, ""Recall"": 0.94, ""Precision"": 0.95, ""F1-score"": 0.94}",
25,"Ozsahin I, Sekeroglu B, Musa MS, Mustapha MT, Uzun Ozsahin D.",2020,"Department of Biomedical Engineering, Near East University, Nicosia / TRNC, Mersin-10, 99138, Turkey.",Review on Diagnosis of COVID-19 from Chest CT Images Using Artificial Intelligence,Comput Math Methods Med,Respiratory Virology,['COVID-19'],"Journal Article, Review","To review and categorize recent AI-based studies focused on diagnosing COVID-19 using chest CT scans, specifically deep learning techniques, and assess their performance across different classification tasks such as COVID-19 vs. normal, COVID-19 vs. non-COVID-19, COVID-19 vs. non-COVID pneumonia, and severity classification."," Chest CT scans provide higher sensitivity but depend heavily on radiologist interpretation, which can be inconsistent and nonspecific due to visual similarity with other pulmonary diseases. Given the pandemic scale and diagnostic demand, there is a need for faster, more accurate, and scalable diagnostic solutions. This situation has prompted the increasing use of AI especially deep learning to automate and enhance COVID-19 diagnosis from chest CT images.","To apply and evaluate deep learning models particularly convolutional neural networks (CNNs) and their variants for automated detection and classification of COVID-19 from chest CT images. The objective is to improve diagnostic accuracy, sensitivity, and specificity over traditional radiological interpretation by leveraging self-learned image features and pre-trained architectures (e.g., ResNet, DenseNet, UNet++) for segmentation, feature extraction, and classification.
","The study employed supervised deep learning approaches to classify CT chest images into categories such as COVID-19 vs. Normal, COVID-19 vs. Non-COVID-19, and COVID-19 vs. other pneumonia. The methodology involved preprocessing of CT scans, segmentation (in some studies), data augmentation (e.g., rotation, brightness adjustment), feature extraction using pre-trained CNNs, and classification using deep neural networks. Model evaluation was done using both hold-out and k-fold cross-validation strategies.","The reviewed studies primarily used deep convolutional neural networks (CNNs) for COVID-19 detection in CT scans. Pretrained architectures such as DenseNet, ResNet, and ShuffleNet V2 were repurposed using transfer learning for classification tasks, often achieving high accuracy. Segmentation models like UNet++ and V-Net were used to isolate lung regions before classification. In more advanced designs, multi-stage models performed lung segmentation, lesion detection, and severity estimation. Feature learning often bypassed manual engineering, leveraging the hierarchical representations of CNNs. Classification was done via softmax outputs or fully connected layers, while model validation used either hold-out or k-fold cross-validation.","IRRCNN, ShuffleNet V2, ResNet50/18/101, DenseNet121/201, Xception, InceptionV3, InceptionResNetV2, UNet, UNet++, DRE-Net, COVNet, MVPNet, AD3D-MIL.",No,No,COVID-19 diagnosis and severity classification using chest CT imaging ,chest CT scans,Ozsahin et.al,Yes,"The performance of the deep learning models was measured by evaluating their ability to accurately diagnose and classify COVID-19 using chest CT images across various tasks, including COVID-19 vs. normal, COVID-19 vs. non-COVID, other pneumonia, and severity classification. Metrics used to assess model performance included sensitivity (recall), specificity, precision, accuracy, area under the curve (AUC), and F1-score. These metrics quantify how well the models identified true positives, avoided false positives, and maintained overall classification reliability. Evaluation was typically conducted using hold-out validation or k-fold cross-validation on labeled datasets, with some studies comparing model outputs against expert radiologist interpretations to benchmark clinical relevance.","{'Accuracy',  'Precision', 'Sensitivity', 'Specificity', 'Recall', 'AUC'}","{
    'IRRCNN': {'Accuracy': 98.78, 'F1_score': 98.85},
    'ShuffleNet V2': {'Sensitivity': 90.52, 'Specificity': 91.58, 'Accuracy': 91.21, 'AUC': 96.89},
    'ResNet50': {'Sensitivity': 98.2, 'Specificity': 92.2, 'AUC': 99.6},
    'DenseNet121 + Bagging': {'Accuracy': 99.0, 'Precision': 99.0, 'F1_score': 99.0},
    'DenseNet201': {'Accuracy': 96.25},
    'AD3D-MIL': {'Accuracy': 97.9, 'AUC': 99.0, 'F1_score': 97.9},
    'DRE-Net': {'Accuracy': 86, 'Sensitivity': 96, 'AUC': 95},
    'COVNet': {'Sensitivity': 90, 'Specificity': 96, 'AUC': 96},
    'MVPNet (Ni et al.)': {'Accuracy': 94, 'Sensitivity': 100, 'F1_score': 97.0},
    'UNet++ (Chen et al.)': {'Accuracy': 98.85, 'Sensitivity': 94.34, 'Specificity': 99.16},
    'ResNet18 (Ahuja et al.)': {'Accuracy': 99.4, 'Sensitivity': 100.0, 'Specificity': 98.6, 'AUC': 99.65, 'F1_score': 99.5}
}",
26,"Shao Z, Buchanan LB, Zuanazzi D, Khan YN, Khan AR, Prodger JL.",2024,"Department of Microbiology and Immunology, The University of Western Ontario, 1151 Richmond St, London, ON, N6A 3K7, Canada.",Comparison between a deep-learning and a pixel-based approach for the automated quantification of HIV target cells in foreskin tissue,Sci Rep,General Virology,['HIV'],"Comparative Study, Journal Article",The aim of this study is to develop and validate a deep learning-based image analysis workflow using the StarDist model to accurately and efficiently quantify HIV-susceptible immune cells.,"Accurate quantification of HIV target cells in genital tissue is critical for assessing susceptibility to infection during sexual transmission. However, existing pixel-based cell counting techniques struggle in areas of high cell density and autofluorescence common features in genital tissue while manual counting is labor-intensive and prone to human error. There is a lack of automated, unbiased, and robust image analysis tools that can reliably segment and quantify immune cells across complex tissue environments.","Automate the segmentation and quantification of HIV target immune cells (e.g., CD4?, CCR5?, CD3? T cells) in immunofluorescence microscopy images of foreskin tissue. This automation aims to overcome limitations of manual and pixel-based methods by providing a high-throughput, accurate, and reproducible approach that performs reliably even in regions with high cell density and tissue autofluorescence.","Tissue samples were first prepared and stained with multiple biological markers relevant to the study’s objective. High-resolution images were collected, and a subset of them was manually annotated to create training data. These annotated images were used to train a neural network model based on the StarDist architecture, which uses star-convex polygons for object detection and segmentation. The training process included data augmentation techniques to improve model robustness, and model optimization was guided by standard deep learning practices. After training, the model was applied to new microscopy images to automatically detect and count cells of interest. The model’s performance was evaluated by comparing its output to manual counts (considered the gold standard) and to results from a traditional rule-based (pixel-thresholding) method. Additional validation was performed in challenging regions of tissue, such as those with high cell density or autofluorescence, to ensure the model's reliability across diverse imaging conditions.","The study uses a deep learning model based on the StarDist architecture, which detects and segments individual cells using star-convex polygon representations well-suited for the irregular shapes of immune cells. The model was trained on multi-channel immunofluorescence images containing cell markers and nuclei, using 40 manually annotated image tiles as ground truth. A custom workflow was built using Snakemake to train the model with image augmentations (e.g., flipping, intensity variation) for better generalization. Training was carried out for 400 epochs with 100 steps per epoch, using a 2D U-Net backbone. Input images were normalized, and non-maximum suppression (NMS) was applied during prediction to refine detection accuracy. ",['StarDist (2D U-Net-based Deep Learning Model for Cell Segmentation)'],https://zenodo.org/records/8091889,Creative Commons Attribution 4.0 International,Quantifying HIV-susceptible immune cells in genital mucosal tissue (helps in assessing an individual’s vulnerability to HIV transmission and evaluating the effectiveness of HIV prevention strategies),Immunofluorescence microscopy images of foreskin tissue,ProdgerLab-StarDist Training Dataset,Yes,"The performance of the StarDist model was evaluated by comparing its automated cell counts to manual counting, which served as the gold standard. This comparison was done across multiple microscopy images, focusing on identifying key immune cell types, including total cells and various HIV-susceptible subsets like CD3?, CD4?, CCR5?, and triple-positive CD3?CD4?CCR5? cells. The evaluation metrics included sensitivity, precision, false negative rate, and false discovery rate. These metrics were used to assess how well the model could correctly identify cells, avoid missed detections, and minimize incorrect classifications. The results showed strong agreement with manual counts across all measured parameters, demonstrating that the StarDist model is accurate and reliable for immune cell quantification in tissue samples.","{""Sensitivity"", ""Precision"", ""False Negative Rate"", ""False Discovery Rate""}","{
    ""sensitivity"": "">94% (all cell types), >97.5% (for some key subsets)"",
    ""precision"": "">90% for most; 85.2% for rarest subtype"",
    ""false_negative_rate"": ""<5.2% (all types)"",
    ""false_discovery_rate"": ""<10% (except CD4?CCR5? and triple-positive)""
  }",
,,,,,,,,,,,,,,,,,,,,,"To further validate its performance, the StarDist model was compared with a conventional pixel-based cell segmentation method. This comparison assessed the same immune cell types and also tested the models in challenging tissue regions, such as areas with high cell density and high autofluorescence. Evaluation focused on the same set of metrics sensitivity, precision, false negative rate, and false discovery rate. Additional qualitative factors were also observed, such as the tendency for overcounting, undercounting, and errors due to cell merging or splitting. Compared to the pixel-based approach, the StarDist model demonstrated better consistency, fewer errors in difficult regions, and overall superior performance across all metrics used in the analysis.","{""Sensitivity"", ""Precision"", ""False Negative Rate"", ""False Discovery Rate""}","{
    ""sensitivity"": ""60.7%–93.6%"",
    ""precision"": ""69.8%–91.1%"",
    ""false_negative_rate"": ""6.4%–39.3%"",
    ""false_discovery_rate"": ""Up to 30.2%"",
    ""issues_in_special_regions"": ""High merging/splitting in dense tissues; misidentification in autofluorescent regions""
  }",
27,"Helwan A, Ma'aitah MKS, Hamdan H, Ozsahin DU, Tuncyurek O.",2021,"Lebanese American University, School of Engineering, Department of ECE, Byblos, Lebanon.",Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19,Comput Math Methods Med,Respiratory Virology,['COVID-19'],"Comparative Study, Journal Article",To compare the diagnostic performance of pre-trained deep learning models with that of human radiologists in identifying COVID-19 from chest CT images.,"To check if AI-based diagnostic tools, particularly pre-trained deep learning models, outperform human radiologists in detecting COVID-19 from chest CT images and provide a more reliable diagnostic alternative.",Evaluate the effectiveness and generalization ability of deep learning models in diagnosing COVID-19 compared to human radiologists.,"The study adopts a transfer learning-based AI methodology to assess the diagnostic performance of deep learning models in identifying COVID-19 from chest CT images, in comparison to human radiologists. Pre-trained convolutional neural networks ResNet-18, ResNet-50, and DenseNet-201 were selected based on prior success in medical image classification. These models, originally trained on the ImageNet dataset, were fine-tuned for binary classification (COVID-19 vs Non-COVID-19) using a curated dataset of chest CT images. Transfer learning was employed to adapt the models by updating the final layers while retaining earlier feature representations, enabling efficient training on a relatively small dataset. To ensure a fair human-machine comparison, the models and medical experts were tested on the same 250 unseen images. Two radiologists were chosen for this comparison: a senior thoracic radiologist with 10 years of experience in chest imaging (Rad 1), and a junior radiologist with 2 years of experience (Rad 2). Both were given the same time frame and dataset to perform their diagnoses. The methodology includes evaluating both AI models and radiologists using key performance metrics such as accuracy, sensitivity, specificity, precision, and F1-score, and incorporates Grad-CAM visualization to interpret model decision-making.","The AI method used in this study is transfer learning with pre-trained convolutional neural networks (CNNs), specifically ResNet-18, ResNet-50, and DenseNet-201. These models, originally trained on the large-scale ImageNet dataset, were adapted for the binary classification task of detecting COVID-19 from chest CT images. The transfer learning approach involved replacing and fine-tuning the final classification layers while keeping the earlier layers fixed to retain learned visual features. The models were trained using categorical cross-entropy loss and stochastic gradient descent (SGD) with a learning rate of 0.0001 and a batch size of 64, over a maximum of 10 epochs with early stopping based on validation error. Input images were preprocessed by converting from DICOM to PNG format, normalized, and resized to 224 × 224 pixels. Model performance was evaluated using standard metrics such as accuracy, sensitivity, specificity, precision, and F1-score. Additionally, Grad-CAM visualizations were used to highlight the specific image regions the models focused on, providing interpretability for the predictions.",['Transfer Learning with Pre-trained Convolutional Neural Networks (CNNs)'],No,No,COVID-19 Diagnosis from Chest CT Images,Medical Images (CT images),Helwan et.al,Yes,"The performance of both the deep learning models and the radiologists was evaluated using a fixed test set of 250 chest CT images, comprising 100 COVID-19 and 150 Non-COVID-19 cases. Each model and radiologist made predictions on the same set, and their outputs were compared against the ground-truth labels to ensure a fair comparison. A confusion matrix was generated for each evaluator, from which standard diagnostic metrics were calculated: accuracy, sensitivity, specificity, precision, and F1-score. These metrics were used to assess the classification effectiveness of the AI models and the radiologists. ","{""Accuracy"", ""Sensitivity"", ""Specificity"", ""Precision"", ""F1-score""}","{""Radiologist_1"": {""Accuracy"": 76.4, ""Sensitivity"": 79.1, ""Specificity"": 80.3, ""Precision"": 80.4, ""F1-score"": 79.74}, ""Radiologist_2"": {""Accuracy"": 75.9, ""Sensitivity"": 74.1, ""Specificity"": 78.7, ""Precision"": 79.2, ""F1-score"": 76.56}, ""ResNet-18"": {""Accuracy"": 91.3, ""Sensitivity"": 90.1, ""Specificity"": 94.3, ""Precision"": 91.4, ""F1-score"": 90.74}, ""ResNet-50"": {""Accuracy"": 97.2, ""Sensitivity"": 93.1, ""Specificity"": 94.3, ""Precision"": 96.1, ""F1-score"": 94.58}, ""DenseNet-201"": {""Accuracy"": 97.8, ""Sensitivity"": 98.1, ""Specificity"": 97.3, ""Precision"": 98.4, ""F1-score"": 98.25}}",
28,"Zorn KM, Lane TR, Russo DP, Clark AM, Makarov V, Ekins S.",2019,"Collaborations Pharmaceuticals, Inc. , Main Campus Drive, Lab 3510 , Raleigh , North Carolina 27606 , United States.",Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets,Mol Pharm,General Virology,['HIV/AIDS'],"Comparative Study, Journal Article, Research Support, N.I.H., Extramural","To develop, compare, and statistically validate multiple machine learning models trained on curated public HIV datasets (from ChemDB) in order to identify promising drug candidates particularly inhibitors of HIV-1 reverse transcriptase (RT) that could potentially overcome resistance seen with current therapies.","Current reverse transcriptase inhibitors are increasingly becoming ineffective due to the rapid emergence of drug-resistant HIV strains. Although public databases contain thousands of potential antiviral compounds, there is a lack of machine-learning-ready, well-curated datasets and a systematic comparison of ML methods to identify effective alternatives. This limits our ability to efficiently discover new drug candidates capable of overcoming resistance.","To use machine learning models to accurately predict compounds that inhibit HIV-1 reverse transcriptase (RT) and show cell-based antiviral activity, ultimately identifying new candidates that can overcome drug resistance."," The researchers began by curating data from the NIAID ChemDB, filtering for wild-type HIV strains and standardizing assay results. Chemical structures were encoded using extended-connectivity fingerprints (ECFP6), which served as molecular descriptors for model input. Seven machine learning algorithms were implemented, including AdaBoost, Random Forest, Support Vector Classification, k-Nearest Neighbors, Bernoulli Naive Bayes, deep neural networks, and Assay Central (a Bayesian modeling platform). Models were trained and optimized using stratified five-fold cross-validation, and externally validated using 24 diverse test sets. Performance was assessed across multiple metrics such as AUC, F1 score, MCC, and accuracy then normalized into a rank-based scoring system. Statistical significance of performance differences between models was tested using Wilcoxon matched-pairs signed-rank tests and Mann-Whitney U tests to ensure robust comparison.","deep neural networks (DL) were implemented using the Keras library to model compound activity against HIV-1 reverse transcriptase. Each network consisted of three hidden layers, and compound structures were encoded as extended-connectivity fingerprints (ECFP6), generated using RDKit. These fingerprints served as input features for the DL models. Unlike other machine learning methods in the study, hyperparameter tuning was not performed for DL due to computational cost; instead, a previously optimized set of hyperparameters from earlier studies was used. Model performance was evaluated using stratified five-fold cross-validation, which preserved the ratio of active to inactive compounds across folds. The predictive ability of the DL models was assessed using several metrics, including AUC, F1 score, accuracy, precision, recall, Matthews Correlation Coefficient (MCC), and Cohen’s Kappa (CK).
","['Support Vector Classification', 'Deep Neural Networks (DL)']",No,No," identifying small molecules that are active inhibitors of HIV-1 RT, and potentially effective as antiviral drugs against drug-resistant strains of HIV",Structured tabular data (HIV-1 wild-type cell-based and reverse transcriptase DNA polymerase inhibition assays),"NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database",Yes,"The performance of the deep neural network (DNN) model in this study was evaluated using stratified five-fold cross-validation and 24 external test set comparisons. The DNN aimed to classify compounds as active or inactive against HIV-1 RT and cell-based inhibition assays. Performance was measured using standard classification metrics, including AUC, F1 score , accuracy, MCC, and Cohen’s Kappa. Additionally, rank normalized scores (RNS) and ?RNS were used to summarize performance across all metrics. The DNN was among the top-performing models, showing statistically comparable results to Support Vector Classification (SVC), and significantly outperforming several other algorithms, including Naive Bayes and k-Nearest Neighbors.","{""AUC"", ""F1 Score"", ""Accuracy"",  ""MCC"", ""Cohen's Kappa""}","{""AUC"": 0.91, ""F1 Score"": 0.82, ""Accuracy"": 0.85, ""MCC"": 0.65, ""Cohen's Kappa"": 0.61}",
29,"Ni Q, Sun ZY, Qi L, Chen W, Yang Y, Wang L, Zhang X, Yang L, Fang Y, Xing Z, Zhou Z, Yu Y, Lu GM, Zhang LJ.",2020,"Department of Medical Imaging, Jinling Hospital, Medical School of Nanjing University, Nanjing, 210002, Jiangsu, China.",A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images,Eur Radiol,Respiratory Virology,['COVID-19'],"Comparative Study, Journal Article, Multicenter Study","To develop and validate a deep learning-based algorithm that can automatically detect, segment, and localize pneumonia lesions in chest CT images of COVID-19 patients, and to compare its diagnostic performance (sensitivity, specificity, accuracy, F1 score, etc.) with radiological residents, using experienced radiologists reports as a reference standard.","There is a critical need for an accurate and efficient method to detect COVID-19 pneumonia in CT scans due to limitations in current diagnostic tools and human workload, and deep learning could fill this gap but needs to be rigorously validated.","develop a deep learning-based system capable of automatically detecting, segmenting, and localizing pneumonia lesions in chest CT images of COVID-19 patients, while also providing quantitative assessments such as lesion volume, density, and anatomical location.","the researchers designed a multi-step AI pipeline. First, a convolutional MVP-Net was used for abnormality detection by incorporating multi-view CT image features and applying a channel-wise attention mechanism to enhance diagnostic accuracy. Next, a 3D U-Net was employed for voxel-wise lesion segmentation, allowing for precise volume and intensity measurements. Finally, another 3D U-Net, trained with anatomical priors and a smooth margin loss, performed pulmonary lobe segmentation to localize lesions within specific lung regions. The system was trained and validated on over 19,291 CT scans from 14,435 individuals and tested on a separate cohort of 96 confirmed COVID-19 patients to evaluate its performance against radiology residents.","The system integrates two core architectures: MVP-Net, which detects pneumonia lesions by analyzing multi-view CT inputs (e.g., soft tissue and lung windows) and using a channel-wise attention mechanism to fuse features across views; and 3D U-Net, which performs voxel-level segmentation of lesions and anatomical lung lobe segmentation. Lesion detection involves identifying candidate abnormal regions, followed by segmentation of those regions into detailed lesion masks using 3D U-Net. A second 3D U-Net, guided by anatomical priors and trained with smooth margin loss, segments lung lobes to localize lesions by lobe. The model was trained and validated on a large, diverse dataset of 19,291 CT scans from 14,435 patients, including confirmed COVID-19, other pneumonia types, and healthy controls. Only high-quality scans with ?2 mm slice thickness were included, and the model was tested on a fully independent dataset of 96 RT-PCR–confirmed COVID-19 cases from three hospitals to ensure robustness. Although specific hyperparameters were not disclosed, model training was informed by anatomical consistency metrics and clinical knowledge such as lesion distribution patterns. The system performs without human input, processes each scan in approximately 20.3 seconds, and outputs lesion classification, segmentation maps, volumetric measurements, CT intensity values, and spatial localizationsupporting rapid, quantitative, and interpretable diagnostics.",[Deepwise AI-Pneumonia Detection System - two key neural network architectures: MVP-Net (Multi-View Feature Pyramid Network) and 3D U-Net. ],No,No,Automated identification and quantitative evaluation of COVID-19 pneumonia severity using chest CT imaging,CT Images,Ni et.al,Yes,"The performance of the AI system was rigorously evaluated on both a per-patient and per-lung lobe basis using multiple metrics, including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1 score, and processing time per scan. Additionally, Area Under the ROC Curve (AUC) was used to assess performance in AI-assisted diagnosis scenarios. The reference standard for evaluation was established by two senior radiologists with 37 and 18 years of experience, who reached a consensus diagnosis based on clinical, laboratory, and CT imaging data. The AI model’s performance was compared against three radiology residents with 2, 5, and 6 years of experience. Both the standalone AI performance and the combined performance of radiologists aided by AI were assessed. Statistical significance was tested using Chi-square tests with Bonferroni correction and t-tests, and the evaluation was supported by confusion matrices and ROC curve analysis."," {""Accuracy"", ""Sensitivity"", ""Specificity"", ""F1 Score"",  ""PPV"", ""NPV"",  ""Processing_Time_sec"", ""AUC""}","{""Per_Patient"": {""Accuracy"": 0.94, ""Sensitivity"": 1.00, ""Specificity"": 0.25, ""PPV"": 0.94, ""NPV"": 1.00, ""F1_Score"": 0.97, ""Processing_Time_sec"": 20.3, ""AUC"": 0.86}, ""Per_Lung_Lobe"": {""Accuracy"": 0.82, ""Sensitivity"": 0.96, ""Specificity"": 0.63, ""PPV"": 0.78, ""NPV"": 0.93, ""F1_Score"": 0.86, ""AUC"": 0.87}}",
30,"Abade A, Porto LF, Scholze AR, Kuntath D, Barros NDS, Berra TZ, Ramos ACV, ArcÃªncio RA, Alves JD.",2024,"Federal Institute of Education, Science and Technology of Mato Grosso, Department of Computer Science, Campus Barra do GarÃ§as, Barra do GarÃ§as, Mato Grosso, Brazil. andre.abade@ifmt.edu.br.",A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection,Sci Rep,General Virology,"['Tuberculosis', 'HIV']","Journal Article, Comparative Study","The research aims to develop and compare classical statistical models and machine learning models for forecasting the incidence of TB/HIV coinfection, stratified by gender and general population, using time series data from Mato Grosso, Brazil (2012–2023). It also seeks to provide accurate future predictions to assist in public health resource planning and intervention strategies, aligned with global health initiatives like the UN SDGs and WHO goals.","TB/HIV coinfection poses a complex and persistent public health challenge, particularly in high-incidence regions like Mato Grosso, Brazil. Despite global health commitments to eliminate TB by 2030, there is insufficient forecasting and predictive modeling specific to TB/HIV trends, leading to gaps in proactive health policy planning. ","The AI objective is to apply and optimize advanced machine learning and deep learning models including SVR, XGBoost, LSTM, GRU, CNN, CNN-GRU, and CNN-LSTM architectures for accurately capturing complex, nonlinear, and temporal patterns in TB/HIV coinfection time series data. The goal is to assess their forecasting ability compared to traditional statistical models and demonstrate the superior capability of deep learning, particularly Bidirectional LSTM and CNN-LSTM, in predicting future TB/HIV trends.","The study implemented a machine learning and deep learning-based time series forecasting framework. After establishing baseline models with classical statistical methods (exponential smoothing and ARIMA), the methodology advanced to applying machine learning (Support Vector Regression, XGBoost) and deep learning models (LSTM, GRU, CNN, CNN-GRU, CNN-LSTM, Bidirectional LSTM) to capture complex temporal dependencies and non-linear dynamics. Model parameters were optimized using Grid Search, and predictive performance was evaluated using multiple error metrics (MSE, MAE, RMSE, MSLE, sMAPE, MASE). A systematic training-validation split and the Diebold-Mariano test were employed for model comparison.","The study implemented a range of deep learning models to forecast TB/HIV coinfection incidence trends. Long Short-Term Memory (LSTM) networks were used to model long-range temporal dependencies by stacking multiple LSTM layers with dropout regularization, optimized for hidden units between 50 and 150 and trained using the Adam optimizer. Bidirectional LSTM extended this approach by processing data in both forward and backward directions to capture past and future contexts, using relatively smaller hidden layers (16–128 units) and moderate dropout rates. Gated Recurrent Units (GRUs), a simplified variant of LSTM with fewer parameters, were employed to accelerate training while maintaining temporal modeling capability, with hidden units ranging from 16 to 256. Convolutional Neural Networks (CNNs) were also applied to extract local spatial features from the incidence time series, using convolution and max-pooling operations before passing to dense layers. Hybrid models like CNN-LSTM and CNN-GRU were developed, where CNN layers first captured localized patterns and then LSTM or GRU layers modeled sequential dependencies. All deep learning models were systematically tuned through Grid Search for hyperparameter optimization and evaluated using forecasting error metrics to ensure robust predictive performance.","Long Short-Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit (GRU), Convolutional Neural Network (CNN), CNN-LSTM hybrid, and CNN-GRU hybrid architectures. ",No,No,"predicting TB/HIV incidence rates for different population segments (female, male, total population) to support public health planning and intervention strategies.",Confirmed cases of TB/HIV infection,SINAN (Sistema de Informação de Agravos de Notificação – Brazil's Notifiable Diseases Information System),Yes,"The performance evaluation in this study focused on the accuracy of time series forecasts for TB/HIV incidence rates. Performance was measured using standard error and fit metrics, including Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Mean Absolute Scaled Error (MASE), Mean Squared Logarithmic Error (MSLE), and Symmetric Mean Absolute Percentage Error (sMAPE). For classical models, the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) were additionally computed to assess model complexity relative to fit. To statistically compare the predictive accuracy between models, the Diebold-Mariano (DM) test was employed, determining whether differences in forecast errors were significant.","{""MSE"", ""MAE"", ""MSLE"", ""RMSE"", ""MASE"", ""sMAPE""}","performance_results = {
    ""Female_Bidirectional_LSTM"": {
        ""MSE"": 0.009,
        ""MAE"": 0.067,
        ""MSLE"": 0.006,
        ""RMSE"": 0.094,
        ""MASE"": 0.492,
        ""sMAPE"": 26.81
    },
    ""Male_Bidirectional_LSTM"": {
        ""MSE"": 0.003,
        ""MAE"": 0.044,
        ""MSLE"": 0.002,
        ""RMSE"": 0.057,
        ""MASE"": 0.268,
        ""sMAPE"": 16.61
    },
    ""Total_Population_CNN_LSTM"": {
        ""MSE"": 0.006,
        ""MAE"": 0.058,
        ""MSLE"": 0.003,
        ""RMSE"": 0.075,
        ""MASE"": 0.301,
        ""sMAPE"": 19.66
    }
}",
31,"Hussain Z, Sheikh Z, Tahir A, Dashtipour K, Gogate M, Sheikh A, Hussain A.",2022,"Edinburgh Medical School, College of Medicine and Veterinary Medicine, University of Edinburgh, Edinburgh, United Kingdom.",Artificial Intelligence-Enabled Social Media Analysis for Pharmacovigilance of COVID-19 Vaccinations in the United Kingdom: Observational Study,JMIR Public Health Surveill,Respiratory Virology,['COVID-19'],"Journal Article, Observational Study, Research Support, Non-U.S. Gov't",To assess the frequency and nature of AEFI-related mentions on social media in the UK and analyze public sentiments toward COVID-19 vaccines.,"Vaccine hesitancy due to concerns about adverse effects following immunization (AEFIs) remains a significant challenge in the COVID-19 vaccination campaign, especially as new vaccines are introduced and public trust is shaped by emerging information. Traditional pharmacovigilance systems may not capture real-time public concerns, highlighting the need for complementary approaches like social media analysis to monitor AEFI-related discussions and sentiments.","To automatically detect, classify, and analyze public sentiment regarding COVID-19 vaccines and adverse effects following immunization (AEFIs) using artificial intelligence techniques on large-scale social media data (Twitter and Facebook).","The study combined rule-based and deep learning techniques to analyze public discourse on COVID-19 vaccines in the United Kingdom. To identify mentions of adverse effects following immunization (AEFIs), the researchers employed a keyword-based rule-driven approach, using symptom lists informed by official pharmacovigilance systems such as the UK Yellow Card and US VAERS. These AEFI-related keywords were used to filter posts from Facebook and Twitter, enabling frequency analysis and temporal trend monitoring of commonly and rarely reported vaccine side effects. In parallel, sentiment analysis was performed using a hybrid ensemble model that integrated lexicon-based tools (VADER and TextBlob) with a deep learning classifier based on BERT (Bidirectional Encoder Representations from Transformers). The lexicon models were weighted (VADER × 0.45 + TextBlob × 0.55) to prioritize positive sentiment accuracy, while BERT was leveraged for classifying neutral and negative sentiments. A rule-based decision system selected the final sentiment classification by favoring lexicon outputs for positive sentiment and BERT predictions otherwise. This combination enabled accurate tracking of both public sentiment and safety concerns regarding COVID-19 vaccines on social media during the early phase of the UK vaccination campaign.","BERT was used to classify the sentiment polarity (positive, neutral, or negative) of social media posts related to COVID-19 vaccines and adverse effects following immunization (AEFIs). The model was particularly effective at capturing context-dependent meaning in posts and performed better than rule-based models for detecting neutral and negative sentiments. As part of a hybrid ensemble, BERT’s output was conditionally selected whenever the lexicon-based sentiment estimation did not indicate a clear positive sentiment. This integration of BERT ensured more accurate classification of nuanced or complex language found in social media discourse. Although the study does not detail fine-tuning specifics (e.g., learning rate, batch size), it builds on a previously validated use of BERT for public health sentiment analysis in earlier research by the authors.",BERT-based Sentiment Classification Model,No,No,Monitoring and analyzing adverse effects following immunization (AEFIs) for COVID-19 vaccines and assessing public sentiment toward those vaccines,Text data,Hussain et.al,Yes,"two main outcomes were measured: the frequency of adverse effects following immunization (AEFI) mentions on social media and public sentiment toward COVID-19 vaccines. AEFI detection was performed using a rule-based keyword filtering approach, with no machine learning model involved, and evaluated using descriptive statistics such as post counts and temporal trends. Sentiment analysis, on the other hand, was conducted using a hybrid ensemble model combining lexicon-based tools (VADER, TextBlob) and a deep learning model (BERT). While the ensemble model classified posts as positive, neutral, or negative, the study did not report traditional performance metrics like accuracy or F1 score, as the model had been previously validated in earlier work. The sentiment distribution across posts were reported.",{'Insights and trends in sentiment'},"{""Positive Sentiment"": ""58%"", ""Negative Sentiment"": ""22%"", ""Neutral Sentiment"": ""19%""}",
32,"Wang S, Dong D, Li L, Li H, Bai Y, Hu Y, Huang Y, Yu X, Liu S, Qiu X, Lu L, Wang M, Zha Y, Tian J.",2021,No authors found,A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study,IEEE J Biomed Health Inform,Respiratory Virology,['COVID-19'],"Journal Article, Multicenter Study, Research Support, Non-U.S. Gov't",proposed a deep learning and radiomics based hybrid model for accurately identifying poor outcomes(e.g. mortality) in COVID-19 patients with underlying health conditions from initial CT images at admission,"Despite the high morbidity and mortality observed among COVID-19 patients with underlying health conditions, there remains a lack of accurate, non-invasive prognostic tools that can identify individuals at elevated risk of poor outcomes early in their disease course. While chest CT imaging has shown potential for evaluating COVID-19 severity, most existing studies either focus on general patient populations or rely on single-mode analysis approaches, such as deep learning or radiomics alone.","To develop an AI-powered hybrid model that combines deep learning and radiomics features from initial chest CT scans to predict the likelihood of poor outcomes (specifically mortality) in COVID-19 patients with underlying health conditions, and to stratify patients into high- and low-risk groups for clinical decision support.","The study proposed a hybrid AI methodology that integrates deep learning and radiomics to predict poor outcomes in COVID-19 patients with underlying health conditions based on initial chest CT scans. A 3D-ResNet10 deep learning model was trained on automatically segmented lung volumes to capture local, high-level imaging features, producing a probability of mortality. In parallel, a radiomics model extracted first-order statistical features from preprocessed CT volumes using filters like LoG and wavelets, followed by feature selection through recursive feature elimination and classification via logistic regression. The final hybrid model combined the output probabilities of both models using multivariate logistic regression to improve prediction accuracy. This ensemble approach aimed to leverage both localized and global image characteristics for robust risk stratification.","The deep learning component is based on a 10-layer 3D-ResNet10 architecture, specifically adapted for volumetric CT data. This architecture consists of four residual blocks, each containing multiple 3D convolutional layers, followed by batch normalization and ReLU activation to mitigate vanishing gradients. Shortcut (skip) connections were used within residual blocks to facilitate gradient flow and improve feature learning across layers. After the residual layers, a global average pooling layer condensed the spatial dimensions, and a fully connected layer followed by a softmax function produced the final output: the predicted probability of mortality. This architecture was chosen for its balance of depth and parameter efficiency, making it well-suited for the relatively small training dataset. In parallel, the radiomics model extracted 216 first-order statistical features from 3D volumes using PyRadiomics, leveraging original CT data as well as images filtered with Laplacian of Gaussian (LoG) and wavelet transforms. Key features included metrics like interquartile range, entropy, and mean absolute deviation. Feature selection was done using recursive feature elimination (RFE) with 10-fold cross-validation based on the Kappa metric, and a logistic regression classifier was trained on the optimal subset. Finally, the outputs from both the 3D-ResNet10 model and the radiomics model—each producing a mortality probability—were combined using multivariate logistic regression, forming the hybrid model. This integration leveraged complementary local (deep learning) and global (radiomics) image features to improve robustness and prediction accuracy. The model was implemented in PyTorch (v1.3.0), trained using stochastic gradient descent with a learning rate of 2e-6 (fine-tuned to 2e-7), a batch size of 16, and weight decay of 0.01. ",Hybrid Deep Learning–Radiomics Prognostic Model,http://www.radiomics.net.cn/post/136,No,predicting mortality risk (poor outcome) using initial CT scans at admission,Medical Images (CT scans),Wang et.al,Yes,"The performance of the proposed hybrid model, which integrates deep learning and radiomics, was rigorously evaluated using both classification and prognostic metrics across internal and external test sets. For diagnostic classification, the model achieved an AUC of 0.876 on the internal test set and 0.864 on the external test set, outperforming standalone deep learning and radiomics models in sensitivity, specificity, and overall accuracy.","{""AUC"", ""Sensitivity"",  ""Specificity"", ""Accuracy""}","    ""diagnostic"": {
        ""AUC"": {
            ""test_set"": 0.876,
            ""external_test_set"": 0.864
        },
        ""comparison"": ""Outperformed standalone deep learning and radiomics models in sensitivity, specificity, and accuracy""
    },
    ""prognostic"": {
        ""hazard_ratio"": 2.049,
        ""confidence_interval"": [1.462, 2.871],
        ""p_value"": ""< 0.001""
    },
    ""robustness"": {
        ""validation_method"": ""5-fold cross-validation"",
        ""result"": ""Consistent high performance across folds""
    }",
33,"Casalino L, Dommer A, Gaieb Z, Barros EP, Sztain T, Ahn SH, Trifan A, Brace A, Bogetti A, Ma H, Lee H, Turilli M, Khalid S, Chong L, Simmerling C, Hardy DJ, Maia JDC, Phillips JC, Kurth T, Stern A, Huang L, McCalpin J, Tatineni M, Gibbs T, Stone JE, Jha S, Ramanathan A, Amaro RE.",2020,University of California San Diego.,AI-Driven Multiscale Simulations Illuminate Mechanisms of SARS-CoV-2 Spike Dynamics,bioRxiv,Respiratory Virology,"[""SARS-CoV-2""]","Preprint, Journal Article","The aim of the research is to develop a generalizable AI-driven, multiscale molecular dynamics (MD) simulation workflow that leverages heterogeneous high-performance computing (HPC) resources to explore the time-dependent dynamics of the SARS-CoV-2 spike protein and accelerate conformational sampling for biological discovery, including mechanisms of viral infectivity.","Current molecular dynamics (MD) simulations are also constrained by computational resource limitations when simulating extremely large, realistic biological systems. Thus, there is a need for integrated, AI-accelerated multiscale simulations capable of combining disparate biological datasets and overcoming timescale and sampling challenges in understanding spike protein behavior in realistic environments.","The objective of the AI component is to accelerate molecular dynamics (MD) simulations by using deep learning models to identify undersampled or biologically relevant conformational states of the SARS-CoV-2 spike protein, thereby guiding enhanced sampling and improving the efficiency of simulating rare events such as conformational transitions (e.g., spike opening).","The study integrates deep learning into a multiscale molecular dynamics (MD) workflow to guide the sampling of molecular conformations. AI is applied after MD simulations to analyze the massive datasets generated, cluster protein structures based on latent features, identify rare or biologically important conformational states, and suggest new starting points for further simulations. This creates a feedback loop where AI continuously informs and accelerates molecular exploration across different simulation scales.","The researchers developed a 3D PointNet-based Adversarial Autoencoder (3D-AAE) to analyze large molecular dynamics (MD) simulation datasets representing the C? backbone atoms of proteins. The model processes protein structures as 3D point clouds, using a deep convolutional encoder with kernel sizes [5, 3, 3, 1, 1] and filter dimensions [64, 128, 256, 256, 512] to capture both spatial arrangements and sequential information along the protein chain. The latent representations are mapped into a 64-dimensional space using adversarial training with a Wasserstein loss and gradient penalty for stability, combined with a Chamfer distance-based reconstruction loss. The 3D-AAE effectively clusters molecular conformations, detects rare or novel states using local outlier factor (LOF) analysis, and identifies important structural transitions, such as the SARS-CoV-2 spike protein opening. These identified outliers are then fed back as new starting points for additional MD simulations, forming an AI-driven feedback loop that accelerates sampling across complex biological systems.",3D PointNet-based Adversarial Autoencoder (3D-AAE),"Yes. The main software tools used were NAMD (for molecular dynamics) and WESTPA (for weighted ensemble simulations).The AI component (3D-AAE model) was custom-developed, but it builds on open-source libraries like PyTorch and CuPy.","NAMD - custom license(free for non-commercial academic use, but not fully open-source in a GPL sense).
WESTPA is open-source under the MIT License.",atomic-level understanding of the SARS-CoV-2 spike protein dynamics,"Structural Data, Glycomics Data, Lipidomics Data, Simulation Data",Casalino et.al,Yes,"Performance was evaluated for both the Molecular Dynamics (NAMD) simulations and the AI model (3D-AAE) training. For NAMD, the simulation performance was assessed by measuring nanoseconds simulated per day (ns/day), floating-point operation (FLOP) counts, and parallel speedup and scaling efficiency across HPC nodes. Performance data were gathered using CPU and GPU hardware counters to track FLOP operations and application timers to record wall-clock time and simulation throughput. For the AI-driven 3D Adversarial Autoencoder (3D-AAE), training performance was measured by determining peak and sustained FLOP rates (in TFLOPS) during model training. Additionally, training efficiency was evaluated by analyzing the time taken per epoch and per training batch. FLOP counts for the AI model were obtained using NVIDIA Nsight Compute profiling tools, allowing for a detailed assessment of GPU usage and computational efficiency during deep learning model training.","[""Peak TFLOP/s"", ""Sustained TFLOP/s""]","performance_metrics = {
    ""Molecular_Dynamics"": {
        ""Nanoseconds_per_day"": ""Measured via NAMD timers"",
        ""Peak_FLOPs"": ""Mixed precision; based on hardware counters (FP32, FP64)"",
        ""Scaling_Efficiency"": ""Percentage speedup on multiple nodes""
    },
    ""AI_Model_3D_AAE"": {
        ""Peak_TFLOPS"": {""latent_dim_32"": 2.96, ""latent_dim_64"": 3.16, ""latent_dim_128"": 3.13},
        ""Sustained_TFLOPS"": {""latent_dim_32"": 0.97, ""latent_dim_64"": 2.28, ""latent_dim_128"": 0.91},
        ""Validation_Method"": ""t-SNE visualization and local outlier factor (LOF) clustering""
    }
}",
34,"Hwang EJ, Kim KB, Kim JY, Lim JK, Nam JG, Choi H, Kim H, Yoon SH, Goo JM, Park CM.",2021,"Department of Radiology, Seoul National University College of Medicine, Seoul, Korea.",COVID-19 pneumonia on chest X-rays: Performance of a deep learning-based computer-aided detection system,PLoS One,Respiratory Virology,['SARS-CoV-2'],"Evaluation Study, Journal Article, Research Support, Non-U.S. Gov't","Evaluate the performance of a commercialized, clinically-available CAD in identifying COVID-19 and associated pneumonia. The performance of the CAD was compared with physicians interpretation, and investigated whether the CAD can enhance the performance of physicians interpretation and their inter-reader agreement.","Existing CAD systems have not been extensively validated for detecting COVID-19-associated pneumonia, and it remains unclear whether these systems can provide radiologist-level performance and support non-expert clinicians in triaging patients.","To assess the effectiveness of a commercially available deep learning-based CAD system (Lunit INSIGHT CXR 2) in identifying COVID-19 and associated pneumonia on chest X-rays, and to determine whether it can enhance the diagnostic performance and agreement of physicians particularly non-radiologists in clinical settings lacking expert radiologists.","In this study, a commercial deep learning-based CAD system (Lunit INSIGHT CXR 2) was evaluated for its ability to detect COVID-19 pneumonia on chest X-rays. A dataset of 172 CXRs (from RT-PCR confirmed COVID-19 and non-COVID-19 patients) was retrospectively collected. The CAD analyzed these CXRs, generating probability scores and heatmaps for detected abnormalities. Five radiologists and five non-radiologist physicians interpreted the same images, first independently and then with CAD assistance. The model’s performance was compared against reference RT-PCR and CT results using AUC, sensitivity, and specificity. Additionally, the study measured inter-reader agreement and assessed whether CAD improved physician performance, particularly for non-specialists.","The AI method used was the Lunit INSIGHT CXR 2, a commercial CAD system built using deep convolutional neural networks. It was trained on a large dataset of 89,834 chest X-rays, including 6,903 images labeled for pneumonia. The system outputs a probability score (0–100%) indicating the likelihood of abnormalities such as pulmonary infiltrates. If the score exceeds 15%, a heatmap is generated to localize the abnormality. The model was not specifically trained on COVID-19 images but generalized well to detecting COVID-related pneumonia due to overlap with typical pneumonia patterns. The architecture and hyperparameters were not publicly disclosed in this study.",Lunit INSIGHT CXR 2 – a commercial deep learning-based computer-aided detection (CAD) system,Yes,No,identify COVID-19 infection and associated pneumonia using chest X-rays (CXRs) with the assistance of a deep learning-based computer-aided detection (CAD) system,Medical Images (Chest X-rays), Hwang et.al,Yes,"The performance of the deep learning-based CAD system was evaluated by assessing its ability to detect COVID-19 and pneumonia from chest X-rays, using two reference standards: (1) RT-PCR test results for confirming COVID-19 infection and (2) findings of pneumonia on chest CT scans taken within 24 hours. The evaluation involved comparing the CAD’s predictions against those of 5 thoracic radiologists and 5 non-radiologist physicians. Each participant first interpreted X-rays independently and then re-interpreted them with CAD assistance. Performance was measured using standard classification metrics like AUC (Area Under the ROC Curve), sensitivity, and specificity. Additionally, inter-reader agreement was evaluated using Fleiss' kappa to determine how consistently different physicians classified the images. The CAD's ability to improve reader performance and agreement was also assessed in both unassisted and CAD-assisted scenarios.","[""AUC"", ""Sensitivity"", ""Specificity""]"," {""CAD_alone"": {""RT_PCR"": {""AUC"": 0.714, ""sensitivity"": 0.713, ""specificity"": 0.522}, ""CT"": {""AUC"": 0.790, ""sensitivity"": 0.806, ""specificity"": 0.552}}, ""thoracic_radiologist"": {""RT_PCR"": {""AUC"": 0.701, ""sensitivity"": 0.645, ""specificity"": 0.643}, ""CT"": {""AUC"": 0.784, ""sensitivity"": 0.746, ""specificity"": 0.672}}, ""non_radiologist_physician"": {""RT_PCR"": {""AUC"": 0.584, ""sensitivity"": 0.543, ""specificity"": 0.589}, ""CT"": {""AUC"": 0.650, ""sensitivity"": 0.618, ""specificity"": 0.621}, ""CAD_assisted"": {""RT_PCR"": {""AUC"": 0.664, ""sensitivity"": 0.618, ""specificity"": 0.652}, ""CT"": {""AUC"": 0.738, ""sensitivity"": 0.710, ""specificity"": 0.678}}}, ""inter_reader_agreement"": {""five_point_scale"": {""reader_alone"": 0.209, ""CAD_assisted"": 0.322}, ""binary_classification"": {""reader_alone"": 0.510, ""CAD_assisted"": 0.688}}}",
35,"Abdulaal A, Patel A, Charani E, Denny S, Mughal N, Moore L.",2020,"Chelsea and Westminster NHS Foundation Trust, London, United Kingdom.",Prognostic Modeling of COVID-19 Using Artificial Intelligence in the United Kingdom: Model Development and Validation,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Validation Study","The study aims to develop a patient-specific, point-of-admission mortality risk scoring system for COVID-19 using deep learning model.","Despite the presence of known risk factors for severe COVID-19 outcomes (e.g., age, comorbidities), there is no validated, COVID-19-specific prognostic model or scoring system available to predict mortality risk at the time of hospital admission. This gap hampers the ability of clinicians to make early, informed decisions about patient care and resource allocation.","To develop an artificial neural network (ANN) model that can provide patient-specific, point-of-admission mortality risk predictions for COVID-19 patients, enabling early clinical decision-making during hospitalization.","The study developed an artificial neural network (ANN) to predict patient-specific COVID-19 mortality risk at the time of hospital admission. The model was trained on retrospective clinical data extracted from electronic health records (EHRs), including demographic, comorbidity, lifestyle, and symptom information. All data were preprocessed and encoded into standardized numerical formats suitable for model input. The dataset was split into training (80%) and test (20%) sets, and a 10-fold cross-validation strategy was applied during training to prevent overfitting and optimize performance. Model development involved tuning hyperparameters via grid search and evaluating the model using metrics such as accuracy, sensitivity, specificity, AUROC, and predictive values. The final ANN provided a mortality probability score for each patient, enabling early risk stratification. To enhance interpretability, SHAP values were used to identify key features influencing predictions on both global and individual levels.","The study used a feedforward artificial neural network (ANN) for binary classification of mortality risk in hospitalized COVID-19 patients. The input layer consisted of 22 features derived from patient demographics, comorbidities, lifestyle factors, and symptoms. The network architecture included two hidden layers (22 units in the first, 6 units in the second and third), all using ReLU activation, with dropout rates of 20% and 40% respectively to prevent overfitting. The final output layer had one neuron with a sigmoid activation function that produced a probability score between 0 and 1, indicating the likelihood of patient mortality during hospitalization. The network was trained using the Adam optimizer with binary cross-entropy loss, and L2 regularization was applied to all layers except the output. Hyperparameters were selected using grid search, and 10-fold cross-validation was used to ensure generalizability. Feature importance was analyzed using SHAP (Shapley Additive Explanations) to make individual predictions interpretable.",['Artificial Neural Network (ANN)'],"Yes, the software was developed using open-source libraries.",No,"Patient-specific mortality risk prediction for SARS-CoV-2 (COVID-19) positive individuals at the time of hospital admission using clinical features such as symptoms, comorbidities, and demographics.",Electronic Health Records,Abdulaal et.al,Yes,"The model was evaluated on a held-out test set using standard classification metrics. The output was a mortality probability, and predictions were considered positive if this probability exceeded 50%. Performance was evaluated using standard classification metrics including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUROC) to assess how well the model could identify high-risk patients and support early clinical decision-making.","[Accuracy, Sensitivity, Specificity, Positive Predictive Value, Negative Predictive Value, AUROC]","{""accuracy"": ""86.25%"", ""sensitivity"": ""87.50%"", ""specificity"": ""85.94%"", ""positive_predictive_value"": ""60.87%"", ""negative_predictive_value"": ""96.49%"", ""AUROC"": ""90.12%""}",
36,"Kagerbauer SM, Ulm B, Podtschaske AH, Andonov DI, Blobner M, Jungwirth B, Graessner M.",2024,"Department of Anaesthesiology and Intensive Care Medicine, School of Medicine, Technical University of Munich, Munich, Germany. simone.kagerbauer@uni-ulm.de.",Susceptibility of AutoML mortality prediction algorithms to model drift caused by the COVID pandemic,BMC Med Inform Decis Mak,Respiratory Virology,['COVID-19'],"Review, Journal Article",Assess the impact of the COVID pandemic on ML model performance for predicting postoperative mortality using AutoML.,"Machine learning models trained on pre-pandemic data suffered performance drops during COVID-19 due to abrupt data drift, including covariate and concept shift. Despite using AutoML and applying simple training adaptations, models failed to maintain accuracy, revealing the need for ongoing monitoring and adjustment in real-world clinical settings.","To develop and evaluate machine learning models that predict postoperative in-hospital mortality using preoperatively available data, and to determine whether simple pre-training techniques (like weighting, recent-data filtering, and scaling) can make these models robust to sudden data drift, such as the one caused by the COVID-19 pandemic.","The research utilized the H2O AutoML framework within R to train multiple types of machine learning models on a large dataset of over 100,000 surgical cases collected between 2014 and 2019. These models were tested on separate pre-pandemic and in-pandemic datasets to observe performance under data drift. To improve model robustness, the study explored three intuitive pre-training strategies: (1) assigning less weight to older data under the assumption that more recent data better reflects current patient populations; (2) training only on the most recent six months of data to anticipate and adapt to recent trends; and (3) applying z-score scaling (normalization) to ensure consistent data input distributions. These methods were hypothesized to enhance model adaptability and stability during abrupt external changes like the COVID-19 pandemic. Model performance was assessed using standard metrics such as AUROC and AUPR, and statistical analyses were conducted to examine shifts in input feature distributions and performance deterioration over time.","The AutoML system automatically trained and tuned 649 models over 125 hours using preprocessed surgical patient data comprising 2,775 clinical features. The input to the models included variables such as age, laboratory values, ASA scores, and surgical details, while the binary output indicated whether the patient died during the current hospital admission. The output layer of neural models used sigmoid activation to estimate the probability of mortality. The H2O AutoML framework incorporated several model types, including Generalized Linear Models (GLM), Default Random Forest (DRF), Gradient Boosting Machine (GBM), eXtreme Gradient Boosting (XGBoost), deep learning models (fully connected neural networks), and Stacked Ensembles that combined predictions from these base learners. Performance tuning was based on the area under the precision-recall curve (AUPR), and overfitting was controlled using techniques such as dropout, L2 regularization, and k-fold cross-validation. Despite the diversity and complexity of the model architectures and the use of three pre-training strategies (data weighting, recent-data-only training, and z-score scaling), none of these approaches succeeded in mitigating the significant decline in performance observed during the pandemic highlighting the difficulty of building models resilient to abrupt data drift.
",['AutoML (H2O.ai AutoML Framework) '],https://github.com/BernhardUlm/COVIDMortality,Apache License 2.0,how machine learning models for predicting postoperative in-hospital mortality were impacted by sudden data drift caused by the COVID-19 pandemic,"Clinical data (e.g. patient demographics, medical history)",Surgical Patient Dataset (2014–2019) from a German University Hospital,Yes,"The evaluation was conducted using pre-pandemic (Jan–Mar 2020) and in-pandemic (Apr–May 2020) test datasets. Performance was measured using metrics such as AUROC and AUPR, along with statistical tests like paired t-tests and Kolmogorov–Smirnov tests to assess shifts in input data distributions and classification performance. The best-performing model family, Stacked Ensembles, showed high AUROC (0.95 pre-pandemic, 0.91 in-pandemic) but experienced a significant drop in AUPR (from 0.26 to 0.09), highlighting the impact of concept drift and covariate shift during the pandemic.","[AUROC, AUPR]","{""pre_pandemic"": {""AUROC"": 0.92, ""AUPR"": 0.22}, ""in_pandemic"": {""AUROC"": 0.87, ""AUPR"": 0.07}, ""percent_drop"": {""AUROC"": ""-5.50%"", ""AUPR"": ""-69.11%""}, ""best_model_family"": {""name"": ""Stacked Ensemble"", ""pre_pandemic_AUROC"": 0.95, ""in_pandemic_AUROC"": 0.91, ""pre_pandemic_AUPR"": 0.26, ""in_pandemic_AUPR"": 0.09}}",
37,"Gheisari M, Ghaderzadeh M, Li H, Taami T, FernÃ¡ndez-Campusano C, Sadeghsalehi H, Afzaal Abbasi A.",2024,"Institute of Artificial Intelligence, Shaoxing University, Shaoxing, China.",Mobile Apps for COVID-19 Detection and Diagnosis for Future Pandemic Control: Multidimensional Systematic Review,JMIR Mhealth Uhealth,Respiratory Virology,['COVID-19'],"Systematic Review, Journal Article, Review","To systematically review and provide comprehensive information on how mobile applications were used for COVID-19 detection and diagnosis during the pandemic, aiming to support software developers and clinical researchers in designing effective tools for future pandemic prevention and management.
","Existing reviews were either too limited in scope, focused on general app use (such as contact tracing or telehealth), or lacked detailed analysis of diagnostic algorithms and methods, leaving a critical gap in understanding how mobile technology contributed to disease detection and diagnosis.","To analyze and classify the use of artificial intelligence (AI) methods, particularly machine learning (ML) and deep learning (DL) algorithms, applied within mobile apps for the automated detection and diagnosis of COVID-19, identifying the types of input data used (e.g., cough sounds, radiological images, symptoms), evaluating their diagnostic performance, and proposing improvements for future AI-based mobile diagnostic systems.","A systematic review methodology was applied, extracting and analyzing studies where mobile apps utilized AI algorithms (both machine learning and deep learning) for the detection and diagnosis of COVID-19.
Studies were selected from five major databases (PubMed, Scopus, ScienceDirect, IEEE, and Web of Science) using PRISMA guidelines. AI methods used in the apps were categorized by the type of input data (symptoms, cough sounds, radiology images) and by the type of AI approach (traditional ML, DL with CNNs, hybrid ML-DL models). The performance of different AI methods was also compared based on reported accuracy metrics.","Mobile apps used machine learning (ML) and deep learning (DL) techniques to detect or diagnose COVID-19 from different types of input data such as clinical symptoms, cough sounds, and radiological images.
For clinical symptom data and structured features, ML models like support vector machines and decision trees were commonly used, offering accuracies between 83% and 99.5%.
For unstructured data such as cough sounds and chest X-ray or CT images, DL methods, particularly CNNs, were preferred due to their superior ability to extract relevant features automatically.
DL models (like DenseNet121, MobileNetV2, and EfficientNet) achieved high accuracies (91%-99.6%) after being pretrained (transfer learning) and optimized for mobile devices.
Some studies combined ML and DL models to process both structured (e.g., symptom checklists) and unstructured (e.g., audio signals) data, enhancing diagnosis accuracy.
Lightweight CNN architectures were recommended to ensure computational feasibility on mobile devices with limited hardware resources.
Data augmentation, early stopping, and cross-validation were suggested best practices to avoid model overfitting.","Traditional Machine Learning (ML) algorithms (e.g., Support Vector Machines, Decision Trees, Rule-based Reasoning)
Deep Learning (DL) algorithms, especially Convolutional Neural Networks (CNNs)
Hybrid ML-DL pipelines (in some cases)",No,No,detection and diagnosis of COVID-19 through mobile applications,"Clinical symptoms, audio recordings (cough, breath, voice), radiology images (X-ray, CT scans), biosensor readings (blood biomarkers, heart rate, temperature), and social media keywords were used as underlying data.",Gheisari et.al,Yes,"For machine learning models (on structured clinical or sensor data.
Metrics like accuracy, F1-score, sensitivity, specificity were reported.
Example: ML models achieved accuracy between 83% to 99.5% depending on data type and method.
For deep learning models (on images, cough sounds)
Performance was measured using AUC (Area Under Curve), F1-score, precision, recall, and classification accuracy.
Example: CNNs for chest X-ray/CT image classification reported accuracy between 91% to 99.6%.
Confusion matrix-derived metrics (accuracy, sensitivity, specificity) were standard when reporting ML/DL model performance.
Some mobile apps using rule-based diagnosis did not use numerical metrics but simply described diagnostic success qualitatively.
",,,
38,"McCarron ME, Weinberg RL, Izzi JM, Queen SE, Tarwater PM, Misra SL, Russakoff DB, Oakley JD, Mankowski JL.",2021,"Department of Molecular and Comparative Pathobiology, Johns Hopkins University School of Medicine, Baltimore, MD.",Combining In Vivo Corneal Confocal Microscopy With Deep Learning-Based Analysis Reveals Sensory Nerve Fiber Loss in Acute Simian Immunodeficiency Virus Infection,Cornea,Neurovirology,['SIV'],"Comparative Study, Journal Article",To non-invasively detect and measure early sensory nerve fiber loss in macaques during acute SIV infection using in vivo corneal confocal microscopy (IVCM) combined with a custom deep learning-based analysis tool (deepNerve) tailored for macaque eye images.,"A non-invasive and automated solution, such as combining in vivo corneal confocal microscopy (IVCM) with deep learning analysis, could enable longitudinal monitoring of small sensory nerve fiber damage in macaques and be directly translatable to improving early diagnosis and disease management in people living with HIV.",To develop and apply a deep learning-based method for automatically analyzing in vivo corneal confocal microscopy (IVCM) images from macaques to detect and quantify small sensory nerve fiber alterations during acute SIV infection.,"The study employed a deep learning segmentation pipeline trained specifically on macaque IVCM images. The pipeline automatically extracted quantitative nerve fiber features such as corneal nerve fiber length (CNFL), fractal dimension (FD), and tortuosity. These features were then statistically compared across timepoints (pre- and post-SIV infection) and between control groups to detect significant nerve damage.","The study developed a customized deep learning model called deepNerve, designed specifically for analyzing in vivo corneal confocal microscopy (IVCM) images from macaques. This method uses a deep convolutional neural network (CNN) architecture trained to handle the unique anatomical and imaging challenges in macaques, such as smaller eye size and motion artifacts due to anesthesia. The model takes grayscale IVCM images as input and automatically segments subbasal nerve fibers to extract key quantitative features. These include corneal nerve fiber length (CNFL), which measures total nerve length per image area; fractal dimension (FD), which captures the complexity and spatial distribution of the nerve network using a box-counting approach; and tortuosity, which quantifies the curvature of nerve fibers based on the ratio of actual path length to straight-line distance. The method provides rapid, objective, and reproducible measurements, enabling precise tracking of nerve fiber loss over time in SIV-infected animals.",deepNerve – a customized deep convolutional neural network (CNN),No,No,Detecting early peripheral sensory nerve fiber damage during acute Simian Immunodeficiency Virus (SIV) infection — a well-established animal model for studying HIV-associated sensory neuropathy in humans.,Medical Images (In vivo corneal confocal microscopy),McCarron et.al,Yes,"Performance of the deep learning-based tool deepNerve was evaluated by assessing its ability to detect changes in corneal nerve fiber morphology during acute SIV infection in macaques using paired t-tests. The tool successfully identified a significant reduction in corneal nerve fiber length (CNFL), which dropped from 18.37 ± 3.49 mm/mm² pre-infection to 14.23 ± 4.13 mm/mm² post-infection (P = 0.01). Similarly, fractal dimension (FD), a measure of nerve pattern complexity, significantly declined from 1.25 ± 0.04 to 1.20 ± 0.06 (P = 0.008), indicating nerve fiber loss and spatial disorganization. In contrast, nerve tortuosity showed no significant change (P = 0.26), suggesting it may not be sensitive to acute damage. These results demonstrate that deepNerve can objectively detect early sensory nerve loss linked to viral neuropathy.","[CNFL, Fractal Dimension, Tortuosity]","{
  ""CNFL P-Value (SIV pre vs post)"": 0.01,
  ""Fractal Dimension P-Value (SIV pre vs post)"": 0.008,
  ""Tortuosity P-Value (SIV pre vs post)"": 0.26,
  ""Tortuosity P-Value (Species difference: pigtailed vs rhesus)"": 0.005
}",
39,"Ko H, Chung H, Kang WS, Park C, Kim DW, Kim SE, Chung CR, Ko RE, Lee H, Seo JH, Choi TY, Jaimes R, Kim KW, Lee J.",2020,"Biomedical Engineering, Wonkwang University, Iksan, Republic of Korea.",An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Validation Study","To develop and validate an artificial intelligence model (EDRnet), combining deep neural networks and random forest algorithms, for early prediction of in-hospital mortality in COVID-19 patients using routine blood test results taken at the time of hospital admission.","Accurately predicting COVID-19 mortality at hospital admission remains a challenge due to limitations in existing models, which often use few biomarkers or late-stage data. This hinders timely, data-driven clinical decisions. A robust, early-stage AI model using routine blood tests is urgently needed to guide treatment and resource allocation.","To develop an accurate and interpretable artificial intelligence (AI) model that predicts COVID-19 in-hospital mortality using only routine blood biomarkers collected at the time of hospital admission using routinely collected blood biomarkers, age, and gender.","The study followed an ensemble learning approach to build a mortality prediction model using clinical data available at hospital admission. After selecting 28 key blood biomarkers based on ANOVA and data availability, the researchers added age and gender as input features. The data was standardized, and missing values were imputed with mean values from the training set. The dataset was then used to train two independent models deep neural network (DNN) and random forest (RF) each validated through repeated 10-fold stratified cross-validation. The final prediction was generated by combining outputs of the two models using soft voting, thereby leveraging the strengths of both algorithms.","The deep neural network (DNN) used in the ensemble consisted of five layers: one input layer (30 features), three fully connected layers with 30, 16, and 8 nodes respectively, and a softmax output layer. A dropout rate of 0.3 was applied to reduce overfitting. The model was trained using the Adam optimizer with a learning rate of 0.0001 and binary cross-entropy loss. Separately, the random forest (RF) model comprised 100 decision trees with a maximum depth of 4 and a maximum of 5 features considered per split. Both models generated mortality probabilities, which were combined using a weighted average based on validation loss to produce the final ensemble prediction (EDRnet).",EDRnet (Ensemble Deep-learning and Random forest network),deployed as a public web application called BeatCOVID19,No,Predicting in-hospital mortality in COVID-19 patients using routinely collected blood biomarkers at the time of hospital admission.,Blood test data and patient demographics,Ko et.al,Yes,"The performance of the EDRnet model was evaluated using standard classification metrics: sensitivity, specificity, accuracy, and balanced accuracy. The model was assessed through a 10-times repeated 10-fold stratified cross-validation on the training dataset of 361 patients and independently tested on an external dataset of 106 Korean COVID-19 patients from three hospitals. EDRnet achieved superior results compared to individual models (Random Forest and Deep Neural Network) and other external AI models (like XGBoost and AdaBoost). On the test data, EDRnet demonstrated 100% sensitivity, 91% specificity, 92% accuracy, and 96% balanced accuracy, indicating robust performance in early mortality prediction using routine clinical blood data.","[Sensitivity, Specificity, Accuracy, Balanced Accuracy]"," {""Sensitivity"": 100%, ""Specificity"": 91%, ""Accuracy"": 92%, ""Balanced Accuracy"": 96%}",
40,"Xu Q, Gel YR, Ramirez Ramirez LL, Nezafati K, Zhang Q, Tsui KL.",2017,"City University of Hong Kong, Hong Kong SAR, China.",Forecasting influenza in Hong Kong with Google search queries and statistical model fusion,PLoS One,Respiratory Virology,['Influenza'],"Evaluation Study, Journal Article","To evaluate the predictive utility of Google search data, in combination with offline influenza and meteorological data, for forecasting influenza-like illness (ILI) in general outpatient clinics (GOPC) in Hong Kong using statistical, machine learning, and deep learning approaches.","There is a need for an adaptive, data-efficient, and accurate influenza forecasting method that leverages both online search behavior and offline data sources, as traditional linear models relying on structured seasonal patterns are ill-suited for regions like Hong Kong with irregular ILI trends and limited real-time data.","To predict influenza-like illness (ILI) trends in Hong Kong one and two weeks in advance by integrating online (Google search queries) and offline (historical ILI records, meteorological data) sources, using advanced machine learning techniques.","The study implemented a multi-model ensemble forecasting approach that combines traditional statistical techniques with deep learning to predict influenza-like illness (ILI) trends in Hong Kong. Specifically, it utilized four models Generalized Linear Model (GLM), LASSO regression, ARIMA, and a deep learning model based on Feedforward Neural Networks (FNN) each trained on a rolling 104-week window to capture dynamic relationships among Google search trends, meteorological data, and historical ILI rates. To improve robustness and forecasting accuracy, particularly during influenza peaks, the outputs of these models were integrated using Bayesian Model Averaging (BMA), which adaptively weighted each model based on recent performance. This hybrid methodology allows for adaptive, data-efficient, and accurate ILI forecasting in subtropical regions with irregular influenza seasonality.","The study employed a deep learning model using Feedforward Neural Networks (FNN), structured with two hidden layers containing 50 and 100 nodes respectively, and a learning rate of 0.005. The model ingested multiple input features, including Google search query frequencies, meteorological variables, and recent ILI case data, to perform one-week and two-week ahead forecasts. The FNN was trained in a supervised manner and optimized to minimize mean squared error (MSE), leveraging its capability to model complex nonlinear relationships without extensive manual feature engineering. The architecture was implemented using the H2O R package, enabling efficient, nonparametric learning from both online and offline data sources.",Feedforward Neural Network (FNN),No,No,Forecasting influenza-like illness (ILI) cases in general outpatient clinics (GOPC) in Hong Kong 1-week and 2-weeks in advance.,"Google search queries, ILI rates from outpatient clinics, meteorological data.",Xu et.al,Yes,"The performance of the influenza forecasting models was evaluated using both point prediction accuracy and timing of influenza peaks. Four statistical metrics were employed: Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE), and Pearson correlation between predicted and observed values. Additionally, the models were assessed on their ability to predict the correct week of peak influenza activity, quantified using week difference (WD) between observed and forecasted peaks. These evaluations were conducted for both one-week-ahead and two-week-ahead forecasts, over the full time series and specifically during influenza seasons. The Bayesian Model Averaging (BMA) method yielded the best overall performance in terms of RMSE and MAPE, while Deep Learning with Feedforward Neural Networks (DL with FNN) demonstrated the most accurate peak timing predictions.","[RMSE, MAPE, MAE, Correlation, Week Difference (WD)]"," ""one_week_ahead"": {
        ""GLM"":     {""RMSE"": 1.97, ""MAPE"": 25.9, ""MAE"": 1.39, ""Correlation"": 0.65},
        ""ARIMA"":   {""RMSE"": 2.14, ""MAPE"": 28.6, ""MAE"": 1.53, ""Correlation"": 0.47},
        ""LASSO"":   {""RMSE"": 1.84, ""MAPE"": 28.2, ""MAE"": 1.45, ""Correlation"": 0.57},
        ""FNN"":     {""RMSE"": 1.73, ""MAPE"": 25.4, ""MAE"": 1.30, ""Correlation"": 0.63},
        ""BMA"":     {""RMSE"": 1.53, ""MAPE"": 24.5, ""MAE"": 1.23, ""Correlation"": 0.73}
    },
    ""two_week_ahead"": {
        ""GLM"":     {""RMSE"": 2.14, ""MAPE"": 26.1, ""MAE"": 1.47, ""Correlation"": 0.60},
        ""ARIMA"":   {""RMSE"": 2.43, ""MAPE"": 33.3, ""MAE"": 1.81, ""Correlation"": 0.30},
        ""LASSO"":   {""RMSE"": 1.84, ""MAPE"": 27.2, ""MAE"": 1.38, ""Correlation"": 0.59},
        ""FNN"":     {""RMSE"": 1.69, ""MAPE"": 26.0, ""MAE"": 1.35, ""Correlation"": 0.67},
        ""BMA"":     {""RMSE"": 1.68, ""MAPE"": 28.4, ""MAE"": 1.33, ""Correlation"": 0.69}
    },
    ""peak_week_difference"": {
        ""one_week_ahead"": {
            ""GLM"": 2.3, ""ARIMA"": 2.0, ""LASSO"": 1.3, ""FNN"": 0.3, ""BMA"": 0.7
        },
        ""two_week_ahead"": {
            ""GLM"": 1.0, ""ARIMA"": 3.0, ""LASSO"": 2.3, ""FNN"": 1.0, ""BMA"": 1.3
        }
    }",
41,"Suri JS, Puvvula A, Biswas M, Majhail M, Saba L, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Sanches JM, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Kolluri R, Teji J, Maini MA, Agbakoba A, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PR, Naidu S.",2020,"Stroke Monitoring and Diagnostic Division, AtheroPointâ„¢, Roseville, CA, USA. Electronic address: jasjit.suri@atheropoint.com.",COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review,Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Review","The aim of the study is to explore and advocate the use of artificial intelligence (AI), particularly machine learning (ML) and deep learning (DL)-based imaging techniques, for the characterization of tissue damage in COVID-19 patients with comorbidities, to enable effective risk assessment, diagnosis, and patient management.","Traditional medical imaging, although effective in detecting tissue damage, is insufficient for rapid and large-scale diagnosis and risk stratification. Therefore, there is an urgent need for scalable, AI-driven imaging solutions to augment diagnosis and treatment during the pandemic.","The objective of applying AI in this study is to automate the characterization of tissue damage in medical images (e.g., ultrasound, CT, MRI scans) of COVID-19 patients, to rapidly assess disease severity and stratify patient risk levels. This automation aims to overcome the shortage of radiologists, reduce diagnostic delays, and enable scalable, high-throughput evaluation during the pandemic by using machine learning (ML) and deep learning (DL) algorithms for image analysis.","The study proposes a two-level AI-based medical imaging framework for tissue characterization and risk stratification in COVID-19 patients with comorbidities. It uses a pre-test probability (PTP)-based risk categorization system to initially classify patients into risk groups (no-risk, low-risk, low-medium, high-medium, low-high, high-high). Depending on the risk level, appropriate imaging modalities (e.g., ultrasound, CT, MRI, invasive imaging) are selected. Machine learning (ML) and deep learning (DL) models are then applied to extracted image features (in ML) or raw image data (in DL) for characterizing tissue damage and predicting the severity of infection.","The AI approach uses both machine learning and deep learning to automate tissue characterization from COVID-19 patient images. In the ML pipeline, features such as texture, wavelet coefficients, and higher-order spectra are extracted from ultrasound or CT/MRI images and fed into classifiers like Support Vector Machines (SVM) with radial basis function (RBF) kernels or Gaussian Mixture Models (GMM) to predict disease severity. In the DL pipeline, convolutional neural networks (CNNs) are used directly on raw imaging data to perform feature extraction and classification without manual feature engineering. Models like DenseNet, DeepLabv3, ResNet-18, and U-Net++ are adapted for lung, heart, brain, and liver imaging tasks, achieving risk stratification by assessing the extent of tissue damage. Offline-trained DL models are then applied to incoming patient scans (online data) to assist clinical decision-making.",DL and ML based algorithms,No,No,understanding the mechanisms by which SARS-CoV-2 infection contributes to neurological and cardiovascular complications in patients,"Medical Images (X-ray, CT scans)",Suri et.al,No,No new experimental validation was conducted within this paper using a fresh dataset.,,,
42,"Rancati S, Nicora G, Prosperi M, Bellazzi R, Salemi M, Marini S.",2024,"Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy.",Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders,bioRxiv,Emerging & Re-emerging Viruses,['SARS-CoV-2'],"Journal Article, Preprint",To predict future dominant SARS-CoV-2 (sub)lineages (FDLs) early by identifying sequence anomalies in Spike proteins before they become prevalent in the population.,"Existing models can't detect emerging variants before they spread due to reliance on supervised learning and known lineages. There's a need for a generalizable, early-warning system to flag novel, fast-spreading variants for timely public health response.","To develop an unsupervised deep learning system, DeepAutoCoV, that can predict future dominant SARS-CoV-2 lineages (FDLs) early using Spike protein sequences. ","The study uses an unsupervised anomaly detection framework based on deep learning. Spike protein sequences are converted into binary vectors using 3-mer encoding. A deep autoencoder is trained to reconstruct these vectors. During surveillance, sequences that deviate significantly from the learned patterns (high reconstruction error) are flagged as potential FDLs. The model is retrained weekly as new data accumulates, simulating a real-world genomic surveillance pipeline. Filtering using PAM scores refines the flagged outputs.",The model used is a deep autoencoder with a symmetric encoder-decoder architecture comprising dense layers and a central Gaussian noise layer to enhance generalization. It processes input features represented as binary vectors indicating the presence or absence of 3-amino-acid k-mers extracted from SARS-CoV-2 Spike protein sequences. The model is trained for 50 epochs with a batch size of 256 using the Adam optimizer and mean squared error (MSE) as the loss function. Anomalies potential future dominant lineages are detected when the reconstruction error exceeds 1.5 standard deviations from the median MSE. Post-processing involves filtering flagged sequences based on PAM similarity to the original Wuhan reference strain. The system is implemented using Python with TensorFlow and Keras.,DeepAutoCoV – an unsupervised deep learning anomaly detection system,https://github.com/simoRancati/DeepAutoCoV,No,early prediction of future dominant SARS-CoV-2 (sub)lineages (FDLs), Spike protein sequences from SARS-CoV-2 genotypes,"GISAID database with global and country-specific sequences from the USA, UK, France, and Denmark. ",Yes,"The performance of DeepAutoCoV was evaluated through simulated weekly genomic surveillance using Spike protein sequences, with performance measured by lead time (weeks before an FDL reached 10% prevalence), frequency at detection, positive predictive value (PPV), and prioritization rank; DeepAutoCoV consistently outperformed baseline methods across datasets.","[Lead Time, Frequency at Detection, Prioritization, Positive Predictive Value (PPV)]","{""Global"": {""lead_time_weeks"": 17, ""FDL_freq_at_detection"": 0.001, ""PPV"": 0.30, ""prioritization_rank"": 6}, ""USA"": {""lead_time_weeks"": 12, ""FDL_freq_at_detection"": 0.002, ""PPV"": 0.48, ""prioritization_rank"": 3.5}, ""UK"": {""lead_time_weeks"": 6, ""FDL_freq_at_detection"": 0.03, ""PPV"": 0.57, ""prioritization_rank"": 3.5}, ""Denmark"": {""lead_time_weeks"": 5, ""FDL_freq_at_detection"": 0.008, ""PPV"": 0.49, ""prioritization_rank"": 4}, ""France"": {""lead_time_weeks"": 11, ""FDL_freq_at_detection"": 0.015, ""PPV"": 0.47, ""prioritization_rank"": 4}}",
43,"Rezoagli E, Xin Y, Signori D, Sun W, Gerard S, Delucchi KL, Magliocca A, Vitale G, Giacomini M, Mussoni L, Montomoli J, Subert M, Ponti A, Spadaro S, Poli G, Casola F, Herrmann J, Foti G, Calfee CS, Laffey J, Bellani G, Cereda M; CT-COVID19 Multicenter Study Group.",2024,"School of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy. emanuele.rezoagli@unimib.it.",Phenotyping COVID-19 respiratory failure in spontaneously breathing patients with AI on lung CT-scan,Crit Care,Respiratory Virology,['COVID-19'],"Journal Article, Multicenter Study, Observational Study, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't",Integrate lung CT features with clinical and laboratory data to identify COVID-19 subphenotypes.,Need for better stratification and output prediction for COVID-19 respiratory failure patients.,"To automatically analyze lung CT scans using deep learning and integrate the imaging data with clinical and laboratory variables to identify distinct subphenotypes of COVID-19-related respiratory failure.
","In this study, chest CT scans from 559 spontaneously breathing COVID-19 patients were collected within 7 days of hospital admission across multiple Italian hospitals. The CT images were anonymized and processed using a validated convolutional neural network (CNN) developed at the University of Pennsylvania to automatically segment lungs into 15 anatomical regions. For each region, six quantitative features were extracted, resulting in 90 imaging variables per patient. These CT-derived features were combined with clinical and laboratory data (e.g., oxygenation, inflammatory markers, organ function) to form a comprehensive input dataset. This mixed data was used as input to a Latent Class Analysis (LCA) model, a statistical clustering method, to identify distinct subphenotypes of COVID-19-related respiratory failure. The goal was to objectively characterize disease severity patterns and predict clinical outcomes such as mortality.","A pre-trained and validated convolutional neural network (CNN) was used, to automatically segment lung CT scans of COVID-19 patients. The CNN extracted 90 quantitative imaging features by analyzing 15 lung regions for metrics such as density, gas volume, and proportions of ground-glass opacities and consolidations. These AI-derived CT features were then combined with clinical and laboratory data and analyzed using Latent Class Analysis (LCA), an unsupervised statistical method, to identify hidden subgroups (subphenotypes) among patients. This integration of deep learning with statistical modeling enabled the identification of two distinct COVID-19 subphenotypes with different patterns of lung injury, clinical severity, and mortality risk.",Convolutional Neural Network (CNN),No,No,COVID-19 patient subphenotyping and mortality risk prediction,"Medical Images (X-ray, CT scans)",Rezoagli et.al,Yes,"The performance of the AI-based analysis was evaluated by its ability to identify distinct patient subphenotypes and predict 90-day mortality. To assess this, the study used Latent Class Analysis (LCA) to derive two subphenotypes based on a combination of clinical, lab, and CT-derived features. The performance of these models was evaluated using survival analysis via Kaplan–Meier curves and Cox proportional hazard regression, both in univariable and multivariable settings. Model quality was further assessed using Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to determine model fit and robustness.","{Primary Evaluation Task, Evaluation Methods (Kaplan–Meier survival analysis, Univariable and Multivariable Cox regression), Model Fit Criteria (AIC, BIC), Performance Outcome (Hazard Ratios), Significance Level}","{
  ""Primary Evaluation Task"": ""90-day mortality prediction based on subphenotypes"",
  ""Evaluation Methods"": [
    ""Kaplan–Meier survival analysis"",
    ""Univariable Cox regression"",
    ""Multivariable Cox regression (adjusted for sex, comorbidities, life-sustaining decisions)""
  ],
  ""Model Fit Criteria"": {
    ""AIC"": 1797,  # best multivariable model
    ""BIC"": 1813   # best multivariable model with two covariates
  },
  ""Performance Outcome (Hazard Ratios)"": {
    ""Unadjusted HR"": 3.49,  # Subphenotype 1 vs 2
    ""Adjusted HR"": {
      ""Sex, Comorbidities, LSM"": 1.63
    }
  },
  ""Significance Level"": ""p < 0.001""
}",
44,"Jang SB, Lee SH, Lee DE, Park SY, Kim JK, Cho JW, Cho J, Kim KB, Park B, Park J, Lim JK.",2020,"Department of Emergency Medicine, College of Medicine, Yeungnam University, Daegu, Korea.",Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study,PLoS One,Respiratory Virology,['COVID-19 pneumonia'],"Evaluation Study, Journal Article, Multicenter Study, Research Support, Non-U.S. Gov't",Evaluate the efficacy of a DL algorithm in detecting COVID-19 pneumonia on chest radiographs (CR) and compare its performance with radiological reports,To assess whether a deep learning algorithm can accurately detect COVID-19 pneumonia on chest radiographs (CR) and match the diagnostic performance of formal radiology reports.,The objective is to develop an AI-based system that can accurately diagnose pneumonia in COVID-19 patients using chest X-ray images,"Chest radiographs (CRs) of 279 RT-PCR–confirmed adult COVID-19 patients admitted to five emergency departments and one community treatment center in Korea were collected between February 18 and May 1, 2020. The CR images were anonymized and evaluated using a commercial deep learning algorithm Lunit INSIGHT for Chest Radiography (CR) 2 which was previously trained to detect major thoracic conditions such as pneumonia, tuberculosis, pneumothorax, and lung cancer. Each CR image was input into the model, which generated an abnormality score (probability of lesion presence) and a heatmap indicating lesion localization. A score above 15% with correct localization was considered positive. The output classifications were verified by a board-certified radiologist. Ground truth labels were based on either radiologist-reviewed CRs showing ground-glass opacities, consolidations, or infiltration, or on chest CT confirmations when available. ","In this study, the researchers used a commercial deep learning model called Lunit INSIGHT for CR 2, developed to detect major thoracic diseases such as pneumonia from chest radiographs (CR). The model is based on a convolutional neural network (CNN) architecture that processes CR images by extracting features through convolutional layers, combining them via max pooling, and passing them through fully connected layers to generate an abnormality score indicating the likelihood of pneumonia. The input to the model consisted of anonymized DICOM-format CR images from adult COVID-19 patients across six Korean medical centers. The output included both a probability score and a lesion heatmap overlay. An abnormality score above 15% with accurate localization of lesions (e.g., ground-glass opacities or consolidations) was classified as positive for pneumonia. All outputs were reviewed by radiologists for confirmation. ",Convolutional Neural Networks (CNNs)(Lunit INSIGHT for Chest Radiography (CR) 2),Yes(not open-source),No,detection of COVID-19 pneumonia from chest radiographs (CR) in RT-PCR-confirmed COVID-19 patients, Chest radiographs from COVID-19 patients,Daegu COVID-19 Chest Radiograph Dataset.,Yes,"The performance  was evaluated by comparing its output against reference standards derived from radiologist reports and, where available, chest CT scans. The method used for performance evaluation was based on statistical analysis using Receiver Operating Characteristic (ROC) curves, and the Area Under the ROC Curve (AUROC) was calculated with 95% confidence intervals using the DeLong method. In addition to AUROC, standard diagnostic accuracy metrics were computed, including sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics were used to assess the DL model’s ability to accurately detect COVID-19-associated pneumonia in chest radiographs.","[AUROC, Sensitivity, Specificity, PPV, NPV]","performance_metrics = {""AUROC"": 0.921, ""Sensitivity"": 0.956, ""Specificity"": 0.887, ""PPV"": 0.941, ""NPV"": 0.915}",
45,"Grodecki K, Lin A, Razipour A, Cadet S, McElhinney PA, Chan C, Pressman BD, Julien P, Maurovich-Horvat P, Gaibazzi N, Thakur U, Mancini E, Agalbato C, MenÃ¨ R, Parati G, Cernigliaro F, Nerlekar N, Torlasco C, Pontone G, Slomka PJ, Dey D.",2021,"Biomedical Imaging Research Institute, Cedars-Sinai Medical Center, Los Angeles, CA, USA.",Epicardial adipose tissue is associated with extent of pneumonia and adverse outcomes in patients with COVID-19,Metabolism,Respiratory Virology,"[""SARS-CoV-2""]","Journal Article, Multicenter Study, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't","To investigate whether epicardial adipose tissue(EAT), as seen on CT scans, are linked to the severity of pneumonia and risk of serious outcomes in COVID-19 patients","There is a lack of quantitative, deep learning-based analyses assessing how EAT contributes to inflammation and disease progression in COVID-19 patients.",Quantify EAT volume and attenuation using deep learning on chest CT images.,"The study used chest CT scans of 109 confirmed COVID-19 patients from an international registry. Lung abnormalities (like ground-glass opacities and consolidations) were segmented using a semi-automated tool with deep learning support (based on U-Net architecture) to quantify pneumonia burden. A separate deep learning algorithm (QFAT v2.0) was used to segment and measure EAT volume and attenuation. The models processed anonymized CT images to extract quantitative measurements, which were then analyzed for statistical associations with clinical deterioration or death. Multivariable regression analyses were conducted to assess the predictive value of these AI-derived features.","This model was trained using the Lung Tissue Research Consortium dataset and was capable of automatically identifying lung boundaries and dividing them into anatomical lobes. Once the lung regions were segmented, a semi-automated brush-like region-growing tool was used to identify and segment abnormal lung features such as ground-glass opacities and consolidations, consistent with COVID-19 pneumonia. These lesion volumes were summed to compute the total pneumonia volume, and the pneumonia burden was calculated as a percentage of the total lung volume.",U-Net-based deep learning model integrated into FusionQuant Lung v1.0,No,No,COVID-19 pneumonia severity assessment and prediction of adverse clinical outcomes,Medical Images (Chest CT images), Lung Tissue Research Consortium dataset,Yes,"In both cases, performance was not evaluated via typical classification metrics (e.g., accuracy, sensitivity), but rather through predictive power in clinical outcome modeling using regression and odds ratios. To evaluate the model’s effectiveness, researchers assessed how well this burden predicted clinical deterioration or death (including ICU admission, mechanical ventilation, or vasopressor use). This was done using multivariable logistic regression. The model’s output was shown to be a statistically significant predictor of poor outcomes, with an odds ratio (OR) of 2.5, meaning that for each unit increase in pneumonia burden, the odds of clinical deterioration or death increased 2.5 times. A p-value of 0.002 confirmed the association was statistically significant, demonstrating that the DL model provided clinically meaningful and predictive measurements.","{ ""odds_ratio"",   ""p_value""}","{ ""odds_ratio"": 2.5,  ""p_value"": 0.002}",
,,,,,,,,,,,,,"This model automatically detected the boundaries of the heart using CT anatomical landmarks (from the pulmonary artery bifurcation to the posterior descending artery) and traced the pericardium. Within this region, EAT was identified as fat tissue with Hounsfield Unit values between ?190 and ?30. The model computed both the total EAT volume (in milliliters) and the mean attenuation (in Hounsfield Units) as indicators of fat quantity and inflammatory status, respectively. These EAT measurements were then correlated with pneumonia burden and clinical outcomes.",Deep learning model used in QFAT v2.0 software,No,No,,,prospective international COVID-19 chest CT registry,Yes,"In both cases, performance was not evaluated via typical classification metrics (e.g., accuracy, sensitivity), but rather through predictive power in clinical outcome modeling using regression and odds ratios.Logistic regression analyses revealed that both increased EAT volume and higher attenuation were independently predictive of clinical deterioration or death. Specifically, EAT volume (per doubling) and attenuation (per 5 HU increase) significantly correlated with worse outcomes, highlighting the model’s utility in identifying patients at higher risk."," {""EAT_volume_odds_ratio"", ""EAT_volume_p_value"", ""EAT_attenuation_odds_ratio"", ""EAT_attenuation_p_value""}","{""EAT_volume_odds_ratio"": 5.1, ""EAT_volume_p_value"": 0.011, ""EAT_attenuation_odds_ratio"": 3.4, ""EAT_attenuation_p_value"": 0.003}",
46,"Mishra AK, Das SK, Roy P, Bandyopadhyay S.",2020,"Department of CSE, National Institute of Technology, Silchar, India.",Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach,J Healthc Eng,Respiratory Virology,['COVID-19'],"Evaluation Study, Journal Article",Evaluate deep CNN models and proposed decision fusion approach for detecting COVID-19 from chest CT images.,"Current RT-PCR tests for COVID-19 are time-consuming and have limited availability. There is a pressing need for automated, efficient, and reliable diagnostic alternatives such as deep learning approaches applied to chest CT images that can support early detection and reduce the burden on healthcare systems.","To design, implement, and evaluate multiple Deep Convolutional Neural Network (CNN) models and a decision fusion strategy to detect COVID-19 infection from chest CT images with high accuracy, sensitivity, and specificity, thereby providing a rapid, automated diagnostic tool to support clinical screening.","The study used the publicly available COVID-CT dataset, containing 360 positive and 397 negative chest CT images. All images were preprocessed by converting to .png format and resized to 224×224×3 to ensure uniformity across models. The authors implemented five popular deep CNN architectures (VGG16, ResNet50, InceptionV3, DenseNet121, DenseNet201) using Keras with TensorFlow backend in a Google Colab environment. The models were trained using stochastic gradient descent with a learning rate of 0.001 and momentum of 0.9. Each model had three fully connected layers followed by a sigmoid output for binary classification. A decision fusion strategy was proposed, combining the outputs of individual models using majority voting to improve classification performance. All models were evaluated using 10-fold random splits and validated with early stopping to prevent overfitting.","VGG16 is a deep convolutional neural network that uses 13 convolutional layers followed by 3 fully connected layers. In this study, its convolutional layers were retained as in the original ImageNet-trained model, and the fully connected part was customized to three dense layers (4096, 4096, 1000) with ReLU activations and a final sigmoid for binary classification.",VGG16,Open source model through Keras,No,COVID-19 detection from chest CT images (classification: COVID-positive vs COVID-negative).,Medical Images (Chest CT images),COVID-CT dataset (Zhao et al. 2020),Yes,"The models were trained and evaluated using Google Colaboratory GPU resources, implemented in Keras with a TensorFlow backend. The stochastic gradient descent (SGD) optimizer was used with a learning rate of 0.001 and momentum of 0.9. Early stopping was applied based on validation performance to prevent overfitting. All the models are evaluated 10 times with 10 different random splits, where in each split 80% of the data is kept for training purpose (training data) and the rest for testing (testing data). The actual model training is done using 90% of the training data, with 10% of the training data kept as the validation set, which is used to perform early stopping, in order to avoid overfitting. ","[Accuracy, AUROC, F1-Score, Sensitivity, Specificity, Precision, Recall]","{""accuracy"": 0.860, ""auc"": 0.860, ""f1_score"": 0.855, ""precision"": 0.84, ""recall"": 0.86, ""sensitivity"": 0.84, ""specificity"": 0.87}",
,,,,,,,,,,,,,"ResNet50 is a 50-layer deep residual network that uses identity shortcut connections to skip layers and prevent vanishing gradients. The convolutional base was retained as-is; dense layers were customized similar to VGG16. The idea of adding skip connections essentially gets rid of the high training error, which is typically observed in an otherwise deep architecture. ResNet50 is one of the variants of the ResNet architecture that contains 50 layers.",ResNet50,,,,,,Yes,,,"{""accuracy"": 0.862, ""auc"": 0.861, ""f1_score"": 0.857, ""precision"": 0.85, ""recall"": 0.86, ""sensitivity"": 0.83, ""specificity"": 0.88}",
,,,,,,,,,,,,,InceptionV3 uses inception modules that combine multiple convolution kernel sizes to capture diverse spatial features. It is deeper and more complex than VGG but optimized for computational efficiency.,InceptionV3,,,,,,Yes,,,"{""accuracy"": 0.864, ""auc"": 0.865, ""f1_score"": 0.86, ""precision"": 0.85, ""recall"": 0.86, ""sensitivity"": 0.84, ""specificity"": 0.89}",
,,,,,,,,,,,,,"DenseNet121 introduces dense connections where each layer receives inputs from all previous layers, promoting feature reuse and efficiency. Used as-is with modified fully connected layers.",DenseNet121,,,,,,Yes,,,"{""accuracy"": 0.872, ""auc"": 0.875, ""f1_score"": 0.865, ""precision"": 0.86, ""recall"": 0.87, ""sensitivity"": 0.85, ""specificity"": 0.90}",
,,,,,,,,,,,,,A deeper version of DenseNet with more layers and dense connections. Captures fine-grained features with high depth while controlling parameter count.,DenseNet201,,,,,,Yes,,," {""accuracy"": 0.869, ""auc"": 0.870, ""f1_score"": 0.862, ""precision"": 0.85, ""recall"": 0.87, ""sensitivity"": 0.86, ""specificity"": 0.89}",
,,,,,,,,,,,,,"The Decision Fusion model is an ensemble classification approach designed to improve diagnostic accuracy for COVID-19 detection using chest CT images. It integrates the outputs of five pre-trained convolutional neural networks (CNNs): VGG16, ResNet50, InceptionV3, DenseNet121, and DenseNet201. Each of these models was fine-tuned for binary classification (COVID-positive vs COVID-negative) using the same dataset. Specifically, only the fully connected layers were modified while keeping the original convolutional layers intact. The final layers included three dense layers (4096, 4096, 1000) with ReLU activations, followed by a single-node output layer with sigmoid activation to produce binary predictions. During inference, each model independently predicts the class label of a CT image. The final diagnosis is then determined by majority voting—i.e., the label predicted by at least three out of five models is taken as the final output. This strategy was adopted to mitigate overfitting and to reduce errors caused by the biases of individual models. The ensemble thereby leverages the strengths of each architecture while minimizing their weaknesses. This method was also effective in improving specificity, reducing false positives, which is critical in clinical screening contexts.","Decision Fusion (Ensemble of VGG16, ResNet50, InceptionV3, DenseNet121, DenseNet201)",,,,,,Yes,,,"{""accuracy"": 0.8834, ""auc"": 0.8832, ""f1_score"": 0.867, ""precision"": 0.86, ""recall"": 0.88, ""sensitivity"": 0.8813, ""specificity"": 0.9051}",
47,"Watanabe T, McGraw A, Narayan K, Tibebe H, Kuriyama K, Nishimura M, Izumi T, Fujimuro M, Ohno S.",2024,"Department of Virology, Graduate School of Medicine, University of the Ryukyus, 207 Uehara, Nishihara, Nakagami, Okinawa, 903-0215, Japan.",Conserved cysteine residues in Kaposi's sarcoma herpesvirus ORF34 are necessary for viral production and viral pre-initiation complex formation,bioRxiv,Virology and Structural Biology,['KSHV'],"Journal Article, Preprint","The study particularly focuses on understanding how conserved amino acid residues, especially four cysteines, support ORF34's structural integrity and interaction with other vPIC components (e.g., ORF24, ORF66), thereby facilitating viral late gene transcription and progeny virus production.","Although previous studies identified KSHV ORF34 as a hub protein critical for assembling the vPIC, the precise structural features and residue-specific functions of ORF34 in mediating interactions with other vPIC components (like ORF24 and ORF66) remain poorly understood. The lack of detailed knowledge about how specific conserved residues contribute to ORF34's function limits the broader understanding of vPIC assembly and regulation of late gene transcription in beta- and gamma-herpesviruses.","To apply a deep-learning-based structural prediction algorithm (AlphaFold2) to model the three-dimensional structure of KSHV ORF34, identify conserved, structurally important residues across beta- and gamma-herpesviruses, and guide the rational design of alanine-scanning mutants for experimental functional analysis.","deep-learning-based protein structure prediction was employed to model the tertiary structure of KSHV ORF34 and to functionally characterize its conserved residues. The researchers used AlphaFold2, a state-of-the-art deep learning model, to predict the three-dimensional structure of the ORF34 protein from its amino acid sequence. The model output included per-residue confidence scores (pLDDT) and inter-residue distance errors (PAE plots), which provided insights into domain architecture, flexible regions, and highly structured domains within ORF34. Conserved amino acids were mapped onto this predicted structure through sequence alignments across beta- and gamma-herpesviruses. The structural information guided the rational design of alanine-scanning mutants to experimentally validate the functional importance of specific residues, particularly those involved in vPIC assembly and viral replication. Furthermore, AI-assisted ion-binding site prediction was integrated into the analysis to suggest the role of cysteine residues in metal ion coordination, critical for the structural stability of ORF34.","AlphaFold2 (version 2.2.0) was used locally to predict the tertiary structure of KSHV ORF34, utilizing multiple sequence alignment databases including Uniclust30, MGnify, pdb70, PDB/mmCIF, and pdb_seqres. The predicted structure was analyzed for confidence using pLDDT scores and PAE plots, indicating regions of structured domains and disordered linkers. Visualization of the predicted models was conducted with PyMOL, and additional annotations were performed using Python modules such as PSICO and plddt2csv. Surface exposure of residues was evaluated by calculating the relative solvent-accessible surface area (SASA). To explore potential functional sites, the Metal Ion-Binding Site Prediction and Modeling Server (MIB2) was applied to the AlphaFold2 structure, predicting likely metal cation coordination (e.g., Zn²?) at conserved cysteine motifs. These AI-driven insights directly informed experimental design, including alanine-scanning mutagenesis and vPIC functional assays.",ALphaFold2,https://github.com/google-deepmind/alphafold,Apache License 2.0,understanding the molecular mechanisms of KSHV replication, amino acid sequences of ORF34 ,Watanabe et.al,Yes,"Performance evaluation in this study was not based on traditional AI metrics such as accuracy or precision, but was instead assessed experimentally through multiple biological assays. First, the researchers verified whether the critical residues predicted by the AI model were essential for protein-protein interactions by conducting pull-down assays between ORF34 mutants and other vPIC components. Second, they measured viral production recovery by performing quantitative PCR (qPCR) to detect encapsidated KSHV DNA in supernatants from cell models expressing either wildtype or mutant ORF34. Third, they assessed the expression of late viral genes by quantifying K8.1 mRNA levels via RT-qPCR and detecting K8.1 protein through Western blotting. Finally, they evaluated the recruitment of ORF34 mutants to the transcription start site (TSS) of the late gene K8.1 using chromatin immunoprecipitation followed by qPCR (ChIP-qPCR), thereby comprehensively measuring the functional impact of the predicted structural features.",Not specified,Not specified,
48,"Suri JS, Maindarkar MA, Paul S, Ahluwalia P, Bhagawati M, Saba L, Faa G, Saxena S, Singh IM, Chadha PS, Turk M, Johri A, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou AD, Misra DP, Agarwal V, Kitas GD, Kolluri R, Teji JS, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Omerzu T, Naidu S, Nicolaides A, Paraskevas KI, Kalra M, Ruzsa Z, Fouda MM.",2022,"Stroke Monitoring and Diagnostic Division, AtheroPointâ„¢, Roseville, CA 95661, USA.",Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review,Diagnostics (Basel),Respiratory Virology,['COVID-19'],"Journal Article, Review","The primary aim of the study is to design, develop, and validate deep learning (DL) models for early cardiovascular disease (CVD)/stroke risk stratification in Parkinson’s disease (PD) patients who are affected by COVID-19","Traditional ML models struggle to integrate multiple heterogeneous biomarkers effectively, and there has been no well-established AI paradigm tailored for PD patients within the COVID-19 framework. Thus, there is a pressing need for a robust, scientifically validated deep learning system that can dynamically adjust to these complexities and provide precise risk predictions for better clinical decision-making.","The objective of the AI system is to automate the segmentation, feature extraction, and risk prediction processes by using deep learning models. ","The methodology involves using a systematic PRISMA-based literature search to select relevant studies and covariates, followed by the development of a deep learning (DL) model integrating multiple data sources. The DL system consists of two main stages: (i) COVID-19 lesion segmentation and quantification from CT lung images using pretrained convolutional neural networks (e.g., DenseNet201, ResNet50V2, SegNet, UNet) and (ii) CVD/stroke risk stratification using a deep learning model (e.g., LSTM, RNN) trained on covariates including office biomarkers, lab biomarkers, carotid imaging phenotypes, medication usage, PD clinical markers, and quantified COVID-19 lesion data. Feature extraction is automated through DL layers, and model performance is optimized via hyperparameter tuning (learning rate, epochs, batch size, etc.). Validation includes feasibility checks, bias analysis, and performance metrics like accuracy and AUC.","The deep learning methodology involves two stages: (i) COVID-19 lung lesion segmentation using convolutional neural networks trained on CT imaging to quantify lesion severity, and (ii) CVD/stroke risk stratification by integrating CT-derived lesion features with other patient data such as office-based biomarkers (e.g., BMI, blood pressure), laboratory-based biomarkers (e.g., cholesterol levels), carotid ultrasound image phenotypes, medication usage, and PD-specific clinical symptoms. The LSTM model, with its memory gating mechanisms (input, forget, and output gates), is specifically used to model the complex, non-linear relationships across these heterogeneous features over time to predict cardiovascular and stroke outcomes in PD patients exposed to COVID-19 conditions.","Long Short-Term Memory (LSTM) networks and Recurrent Neural Networks (RNN), CNN-based segmentation networks like U-Net and SegNet",No,No,COVID-19 Lung Lesion Segmentation Task,"CT images, clinical records (office and laboratory biomarkers), carotid ultrasound phenotypes, PD patient clinical features, and medication usage.",Suri et.a;,Yes,"TThe COVID-19 lung lesion segmentation task involved training deep learning models such as DenseNet201, ResNet50 V2, MobileNet, VGG-16, SegNet, and Unet on CT lung images to detect COVID-19-induced lesions. Performance was evaluated by comparing the automatically segmented lesions generated by the models against manual annotations made by expert tracers. Accuracy was the primary metric reported for this task, showing high segmentation quality across model.","{ ""Accuracy""}","{
    ""DenseNet201_COVID_CT_segmentation_accuracy"": 97.0,
    ""ResNet50V2_COVID_CT_segmentation_accuracy"": 96.0,
    ""MobileNet_COVID_CT_segmentation_accuracy"": 95.0,
    ""VGG16_COVID_CT_segmentation_accuracy"": 94.0,
    ""SegNet_COVID_CT_segmentation_accuracy"": 95.0,
    ""Unet_COVID_CT_segmentation_accuracy"": 92.0
}",
,,,,,,,,,,,,,,,,,"CVD/Stroke Risk Stratification in PD Patients with COVID-19 Lesions
",,,Yes,"The CVD/stroke risk stratification task assessed the predictive ability of deep learning models, particularly LSTM and RNN, in forecasting cardiovascular or stroke events among Parkinson’s Disease (PD) patients affected by COVID-19. These models were trained on a rich combination of clinical biomarkers, carotid ultrasound imaging features, COVID-19 CT lesion quantifications, and medication usage data. Performance evaluation involved comparing the predicted risk categories against gold standard clinical outcomes. Classification accuracy was the main performance metric, with an LSTM-based model achieving an accuracy of 84.0%. Although AUC was mentioned as an evaluation metric, exact numerical AUC values were not consistently reported. This performance validation demonstrated the deep learning models' effectiveness in risk stratification under complex multi-morbidity conditions.","{ ""Accuracy""}","{""accuracy"": 84.0}",
49,"Abubaker Bagabir S, Ibrahim NK, Abubaker Bagabir H, Hashem Ateeq R.",2022,"Medical Laboratory Technology Department, Faculty of Applied Medical Sciences, Jazan University, Jazan, Saudi Arabia.","Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery",J Infect Public Health,Respiratory Virology,['COVID-19'],"Journal Article, Review","Explore and clarify how Artificial Intelligence (AI) has been applied to support critical aspects of the COVID-19 response, specifically in identifying genomic sequences of the SARS-CoV-2 virus, developing potential therapeutic drugs (including drug repurposing), and designing effective vaccines.","Despite the growing use of AI in genomics, drug discovery, and vaccine development, there has been a lack of comprehensive reviews that summarize its actual contributions to the COVID-19 response. Furthermore, applying AI in these domains faces several challenges, including difficulties in collecting high-quality data, limited interpretability of deep learning models, and the need for robust internal and external validation to ensure generalizability across different populations.","Accelerate and enhance the processes of genomic sequence identification, drug discovery (including drug repurposing), and vaccine development for COVID-19. AI is leveraged to rapidly analyze massive biomedical datasets, identify novel or existing drug candidates, and design effective vaccine candidates with greater precision and speed than traditional methods.","The AI methodology in this study is based on a non-systematic review of literature from databases such as PubMed, Google Scholar, and Medline. It involves summarizing various AI techniques including deep learning (DL), machine learning (ML), artificial neural networks (ANN), reinforcement learning, and topology-based models used across different studies for COVID-19 applications. Specifically, CNNs were used to classify DNA sequences for genomic identification; transformer-based models estimated drug-target interactions; generative neural networks helped design new compounds; and graph-based models explored drug repurposing. AI-based vaccine design approaches included immune-informatics, reverse vaccinology, and epitope mapping using ML on viral proteomes. Performance and clinical value were assessed through reported metrics or experimental validations in vitro/in vivo where available.",A Convolutional Neural Network (CNN) was trained to classify DNA sequences from various coronaviruses and identify representative sequences specific to SARS-CoV-2. The model identified 12 unique 21-bp sequences and selected one to create a primer set for laboratory use.,CNN-based Deep Learning,No,No,Viral genomic sequence classification and specific primer design for SARS-CoV-2 detection.,Genomic sequence data,,Yes,Accuracy comparison between DL output and standard RT-qPCR and CT scans.,"{""Accuracy""}","{""accuracy_dl"": 0.99, ""accuracy_rt_qpcr"": 0.70, ""accuracy_ct_dl_combined"": 0.83}",
,,,,,,,,,,,,,A topology-based deep learning model trained with tens of thousands of experimental data points was used to predict binding free energy (BFE) changes in spike RBD-antibody/ACE2 complexes to assess Omicron’s infectivity and immune evasion.,TopNetmAb – Topology-Based Deep Learning Model,Not mentioned,No,Predicting infectivity and vaccine-escape potential of Omicron variant.,Protein structures and experimental binding data.,,Yes,Not given in numerical metrics; effectiveness validated via prediction of infectivity (10× more infectious than original strain) and escape potential.,,,
,,,,,,,,,,,,,A generative DL model used to design novel chemical structures targeting the 3C-like protease (3CLpro) of SARS-CoV-2. The model focuses on de novo drug design with high novelty and synthetic feasibility.,Generative Deep Learning Pipeline,No,No,Novel drug generation for SARS-CoV-2 main protease inhibition.,Chemical compound structures and protease inhibitor profiles.,,Yes,Not quantified; output was theoretical generation of drug candidates.,,,
,,,,,,,,,,,,,Combines deep Q-learning with fragment-based drug design to iteratively construct molecules targeting the SARS-CoV-2 3CLpro protease.,Advanced Deep Q-learning Network with Fragment-Based Drug Design (ADQN-FBDD),No,No,Novel lead compound generation for COVID-19 therapy.,Fragment-based chemical libraries.,,Yes,Generation of 47 chemically viable lead compounds.,,,
,,,,,,,,,,,,,Zhang et al. utilized a DFCNN to screen chemical compound databases and a tripeptide database to identify potential inhibitors of the SARS-CoV-2 3C-like protease. The model predicts interactions between compounds and the protease to identify promising candidates.,Dense Fully Convolutional Neural Network (DFCNN),No,No,Identifying potential inhibitors for SARS-CoV-2 3CLpro,,,,,,,
50,"Harris M, Qi A, Jeagal L, Torabi N, Menzies D, Korobitsyn A, Pai M, Nathavitharana RR, Ahmad Khan F.",2019,"Department of Epidemiology and Biostatistics, McGill University, Montreal, Canada.",A systematic review of the diagnostic accuracy of artificial intelligence-based computer programs to analyze chest x-rays for pulmonary tuberculosis,PLoS One,Respiratory Virology,Tuberculosis,"Journal Article, Systematic Review","The aim of the study was to systematically review and evaluate the diagnostic accuracy of artificial intelligence (AI)-based computer-aided detection (CAD) software designed to identify radiologic abnormalities suggestive of pulmonary tuberculosis (PTB) on chest X-rays (CXRs). The study also sought to assess methodological quality, identify sources of bias, and provide recommendations to improve future study designs.","Although AI-based CAD programs have shown promise in detecting pulmonary tuberculosis on CXRs, most existing studies focus on software development rather than clinical validation. Furthermore, there are methodological limitations such as training and testing on the same datasets, use of human readers instead of microbiologic confirmation as reference standards, and lack of pre-specified threshold scores that raise concerns about the reliability and generalizability of reported diagnostic accuracies. Therefore, a comprehensive review is needed to critically assess the quality of the evidence, highlight biases, and guide the design of future studies to ensure clinical applicability.","To evaluate the diagnostic accuracy of AI-based computer-aided detection (CAD) software for identifying radiologic abnormalities consistent with pulmonary tuberculosis (PTB) on chest X-rays (CXRs), and to assess study designs, methodological quality, and potential biases in the published literature.","The study undertook a systematic review following PRISMA guidelines to evaluate the diagnostic accuracy of computer-aided detection (CAD) software for pulmonary tuberculosis (PTB) identification on chest X-rays (CXR). Articles were sourced from MEDLINE, EMBASE, PubMed, and Scopus for the period 2005–2019. Studies were classified as either ""Development"" (focused on CAD creation) or ""Clinical"" (focused on CAD evaluation in real-world settings). Risk of bias was assessed using the QUADAS-2 tool. Diagnostic accuracy metrics including area under the receiver operating characteristic curve (AUC), sensitivity, and specificity were extracted. Due to methodological heterogeneity between studies (different software versions, reference standards, datasets), a meta-analysis was not performed. Instead, study-level factors (e.g., use of Deep Learning vs Machine Learning, microbiologic vs radiologic reference standards) were statistically analyzed for association with reported AUC values using non-parametric tests like the Kruskal-Wallis test.","The reviewed CAD systems were developed using either Machine Learning (ML) or Deep Learning (DL) techniques. ML-based systems typically relied on traditional classifiers like support vector machines (SVM) and clustering methods, whereas DL-based systems predominantly used convolutional neural networks (CNNs) with architectures such as AlexNet, GoogLeNet, and custom CNN models. A major software repeatedly evaluated in clinical studies was CAD4TB, a commercially available ML-based CAD program. Development studies often used human reader interpretation as the reference standard, while clinical studies increasingly used microbiological testing (culture or nucleic acid amplification tests, NAAT) to define PTB presence.",CAD4TB (Computer-Aided Detection for Tuberculosis),No,No,detection of pulmonary tuberculosis,Chest X-ray images,"CXR repositories like Montgomery County (MC), Shenzhen Hospital (CH), and Japanese Society of Radiological Technology (JSRT) datasets",Yes," Diagnostic accuracy was evaluated using AUC, sensitivity, specificity, and confusion matrix elements (TP, FP, TN, FN). However, a key issue identified was that many studies did not separate training and testing datasets adequately, potentially inflating reported performance metrics.",,,
51,"Suri JS, Agarwal S, Gupta SK, Puvvula A, Biswas M, Saba L, Bit A, Tandel GS, Agarwal M, Patrick A, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Miguel Sanches J, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Teji J, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PK, Naidu S.",2021,"Stroke Diagnostic and Monitoring Division, AtheroPointâ„¢, Roseville, CA, USA. Electronic address: jasjit.suri@atheropoint.com.",A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence,Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Review","The study aims to explore and evaluate artificial intelligence (AI)-based solutions for the characterization and diagnosis of Acute Respiratory Distress Syndrome (ARDS) in COVID-19 patients, particularly by incorporating comorbidities and age-related factors into AI model design. It introduces a School-of-Thought (SoT)-based classification of AI architectures across imaging modalities (CT, X-ray, ultrasound), and investigates the performance and adaptability of AI frameworks to assess COVID-19 lung severity.
","Despite the rapid development of AI tools for COVID-19 diagnosis, most existing models lack the integration of clinical comorbidity factors, age-specific variations, and ARDS pathophysiology, which are crucial for accurate and personalized risk assessment. Moreover, there is no standardized framework to evaluate or categorize these AI approaches across modalities and clinical needs. This gap hinders the deployment of reliable, explainable, and generalizable AI systems in real-world pulmonary and critical care settings.","TTo develop and evaluate AI-based diagnostic and severity assessment systems for COVID-19-induced Acute Respiratory Distress Syndrome (ARDS) using medical imaging data, while incorporating comorbidity and age as critical factors for personalized risk prediction and clinical decision support.
","A narrative review of AI applications was performed by classifying existing models into seven distinct Schools of Thought (SoT) based on their architectural principles and diagnostic intent. These SoTs include combinations of machine learning (ML), deep learning (DL), and transfer learning (TL) approaches, applied to imaging modalities such as CT, X-ray, and lung ultrasound. The methodology emphasizes multimodal imaging workflows, segmentation-classification pipelines, and severity scoring systems aligned with comorbid conditions.
","Segmentation Models: UNet, DenseNet121-FPN, FC-DenseNet103
Classification Models: ResNet50, VGG16, DenseNet201, InceptionNetV3, AlexNet, SVM, Random Forest, CNN with Attention, Gradient Boosting
Transfer Learning: Pretrained models like VGG16 and Inception used on limited COVID-19 imaging datasets
Hybrid Models: Combination of ML and DL for severity prediction and comorbidity modeling","SoT-1: End-to-end deep learning for segmentation and classification
SoT-3: Automated classification of pneumonia types
SoT-5: Traditional ML with handcrafted features and biomarkers
SoT-7: Explainable AI with Transfer Learning and real-time online/offline systems",No,No,"Diagnosis of COVID-19 pneumonia ,Severity estimation of COVID-19-induced ARDS ,Differential classification between COVID-19, non-COVID pneumonia, and healthy cases ,Impact analysis of comorbidities and age on ARDS progression, Prognosis and risk stratification","CT scans, X-ray images, and lung ultrasound images, Comorbodity metadata(age, hypertension, obesity)","RSNA COVID-19 Dataset, COVID-CT Dataset ,COVID-Xray-5k, Cohen’s COVID-19 X-ray dataset",Yes,"Performance in the reviewed paper was measured individually for each AI model or system, grouped under distinct Schools of Thought (SoTs) based on task type and architecture. Each study evaluated its model independently using various imaging modalities such as chest X-rays, CT scans, and lung ultrasounds. Performance was assessed by comparing model outputs—such as disease classification, segmentation, or severity scoring—against clinically verified ground truths or expert annotations. Key evaluation metrics included accuracy, area under the ROC curve (AUC), sensitivity, specificity, precision, and F1-score. ROC analysis was used to derive AUC, and many studies employed k-fold cross-validation to validate model robustness. Metrics were typically reported per organ and imaging modality rather than in aggregate, ensuring task-specific benchmarking across studies.",,,
52,"Khanna NN, Maindarkar M, Puvvula A, Paul S, Bhagawati M, Ahluwalia P, Ruzsa Z, Sharma A, Munjral S, Kolluri R, Krishnan PR, Singh IM, Laird JR, Fatemi M, Alizad A, Dhanjil SK, Saba L, Balestrieri A, Faa G, Paraskevas KI, Misra DP, Agarwal V, Sharma A, Teji J, Al-Maini M, Nicolaides A, Rathore V, Naidu S, Liblik K, Johri AM, Turk M, Sobel DW, Pareek G, Miner M, Viskovic K, Tsoulfas G, Protogerou AD, Mavrogeni S, Kitas GD, Fouda MM, Kalra MK, Suri JS.",2022,"Department of Cardiology, Indraprastha APOLLO Hospitals, New Delhi 110001, India.","Vascular Implications of COVID-19: Role of Radiological Imaging, Artificial Intelligence, and Tissue Characterization: A Special Report",J Cardiovasc Dev Dis,Respiratory Virology,['COVID-19'],"Journal Article, Review","The primary aim of this study is to investigate the deep-rooted vascular damage caused by COVID-19 across the pulmonary, renal, coronary, and carotid arteries using advanced radiological imaging techniques such as MRI, CT, and ultrasound. "," Current medical imaging approaches alone are insufficient for early and accurate detection of endothelial dysfunction, thrombosis, and inflammation induced by the virus. Furthermore, existing AI models for vascular characterization face challenges such as limited dataset sizes, geographical biases, and lack of clinical validation, hindering their reliability. ","The research seeks to apply Artificial Intelligence-based Tissue Characterization (AIbTC) frameworks, incorporating machine learning, deep learning, and transfer learning models, to automate the detection, characterization, and risk stratification of COVID-19-induced vascular abnormalities.","The AI methodology in this study involves using Artificial Intelligence-based Tissue Characterization (AIbTC) to detect and quantify vascular damage in four key organs (lungs, kidneys, heart, and brain) affected by COVID-19. The AI framework incorporates machine learning (ML), deep learning (DL), and transfer learning (TL) models. Specifically, feature extraction from CT, MRI, and ultrasound images is performed to classify vascular tissue abnormalities. For ML, classical models like support vector machines (SVM), random forests (RF), and decision trees (DT) were used on manually extracted grayscale and texture features. For DL, convolutional neural networks (CNNs) and fully convolutional networks (FCNs) were applied to perform end-to-end feature learning for both segmentation and classification. Transfer learning employed pre-trained models such as VGG16/19, DenseNet121/169, and ResNet50/101 adapted for vascular tissue analysis.","ML models: SVM, Random Forest, Decision Trees.
DL models: CNNs (for classification), FCNs (for segmentation).
TL models: VGG, ResNet, DenseNet, Inception, MobileNet, Xception pre-trained on ImageNet.
Imaging modalities: CT, MRI, Ultrasound.
Prediction targets: Pulmonary, renal, coronary, and carotid artery vascular abnormalities.
Pipeline: Image acquisition ? preprocessing ? AI-based modeling (feature extraction + classification/segmentation) ? performance evaluation.",Artificial Intelligence-based Tissue Characterization (AIbTC),No,No,"Prediction and risk stratification of COVID-19-induced vascular damage (pulmonary, renal, coronary, carotid) through medical imaging.","Medical imaging data(CT scans, MRI scans, ECG data)",Khanna et.al,Yes,"Performance in the study was evaluated using several key metrics, including classification accuracy (to determine the correct prediction of disease versus normal cases), area under the receiver operating characteristic curve (AUC) to assess model discrimination ability, sensitivity (true positive rate), specificity (true negative rate), and segmentation accuracy for tissue characterization tasks. Performance measurement involved comparing the model’s predictions against a gold standard, such as clinical diagnosis or expert annotation. Receiver operating characteristic (ROC) curves were generated to calculate AUC values, and individual reporting of accuracy, sensitivity, and specificity was performed. Metrics were generally analyzed separately for each organ system (pulmonary, renal, coronary, and carotid) and according to the imaging modality used (CT, MRI, ultrasound, or ECG), based on referenced studies.",,,
53,"Ge J, Sun S, Owens J, Galvez V, Gologorskaya O, Lai JC, Pletcher MJ, Lai K.",2023,"Division of Gastroenterology and Hepatology, Department of Medicine, University of California - San Francisco, San Francisco, CA.",Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation,medRxiv,Hepatic Virology,"[\""Hepatitis B\""]","Preprint, Journal Article","To develop LiVersa, a liver disease-specific, PHI-compliant large language model (LLM) by using retrieval-augmented generation (RAG) with AASLD guidelines, improving clinical accuracy and reducing hallucinations in LLM outputs.","General-purpose LLMs are prone to hallucinations and are not PHI-compliant, limiting their clinical use. There is a need for specialized LLMs that integrate authoritative clinical knowledge while maintaining data privacy.","To create a liver disease-specific LLM (LiVersa) that delivers accurate, guideline-based clinical answers by embedding AASLD guidelines, while ensuring PHI compliance and reducing hallucinations.","The methodology involved collecting 30 liver disease-related guidelines and guidance documents from AASLD, excluding summaries and outdated or patient-facing versions. These documents were converted into embeddings using Azure’s text-embedding-ada-002 model and stored in a searchable vector database using Azure Cognitive Search. Upon user input, the system generates an embedding for the query, conducts a semantic similarity search in the database, retrieves relevant guideline excerpts, and passes both the query and retrieved texts to the GPT model to generate a response. This retrieval-augmented framework constrains the LLM outputs to a curated knowledge base, enabling more accurate and specialized responses while minimizing hallucination risks.
","The AI method used is a specialized large language model (LLM) named LiVersa, developed using a Retrieval-Augmented Generation (RAG) approach within UCSF’s Versa platform, a PHI-compliant environment. LiVersa integrates GPT-3.5-Turbo and GPT-4-32k models, enhanced by Microsoft Azure OpenAI’s text-embedding-ada-002 model for embedding text data. The underlying dataset includes 30 American Association for the Study of Liver Diseases (AASLD) clinical practice guidelines and quality documents. These documents were transformed into semantic embeddings and stored in a vector database, which allows real-time retrieval of relevant text chunks during querying. Responses are generated by combining user prompts with retrieved passages, thus improving specificity and reducing hallucinations in clinical applications.","Retrieval-Augmented Generation (RAG) based specialized LLM (""LiVersa"") using Azure OpenAI Services.",No,No,developing an LLM to aid in liver disease management.,AASLD clinical practice guidelines and guidance documents.,Ge et.al,Yes,"The performance of LiVersa was measured by comparing its responses to a previously published set of clinical knowledge assessment questions focused on Hepatitis B (HBV) treatment and Hepatocellular Carcinoma (HCC) surveillance. Evaluation was conducted in two modes: forced yes/no answers and full free-text justifications. The primary measurement was the correctness of LiVersa’s yes/no answers against clinically validated ground truths, while the secondary measurement assessed the accuracy and appropriateness of its detailed explanations. Metrics used included binary correctness for yes/no answers, where LiVersa achieved 100% accuracy, and a qualitative review of explanation quality, where minor inaccuracies were found in 3 out of 10 detailed responses. Performance was also benchmarked against the percentage of medical trainees who had answered these questions correctly in earlier studies.","[Correctness of Answers, Rationale Completeness]","{""Correctness of Answers"": 100% for yes/no questions, ""Rationale Completeness"": 70% fully correct for detailed responses}.",
54,"Hallak JA, Scanzera AC, Azar DT, Chan RVP.",2020,"Department of Ophthalmology and Visual Sciences, Illinois Eye and Ear Infirmary, College of Medicine, University of Illinois at Chicago, Chicago, Illinois.",Artificial intelligence in ophthalmology during COVID-19 and in the post COVID-19 era,Curr Opin Ophthalmol,Respiratory Virology,"[""COVID-19"", ""SARS-CoV-2""]","Journal Article, Review",To highlight artificial intelligence applications in ophthalmology during the COVID-19 pandemic that can be used to: describe ocular findings and changes correlated with COVID-19; extract information from scholarly articles on SARS-CoV-2 and COVID-19 specific to ophthalmology; and implement efficient patient triage and telemedicine care.,"he pandemic has exposed gaps in healthcare delivery infrastructure, particularly the lack of scalable telemedicine solutions, and emphasized the need for AI systems that can prioritize patients, improve remote monitoring, and secure data sharing. Despite these advances, the paper acknowledges that technical, regulatory, and operational challenges still impede the full integration of AI into ophthalmic care.","To assist ophthalmology during the COVID-19 pandemic by enabling noninvasive diagnosis of COVID-19-associated ocular findings, summarizing vast ophthalmology-related COVID-19 literature to guide clinical and research decisions, and supporting efficient patient management through AI-driven triage and telemedicine solutions.","The paper outlines three main AI methodologies applied in ophthalmology during the COVID-19 pandemic: (1) Medical Image Analysis, (2) Natural Language Processing (NLP) for Literature Mining, and (3) Telemedicine and Remote Patient Monitoring Enhancement. For medical image analysis, deep learning models primarily convolutional neural networks (CNNs)—were employed to analyze imaging modalities like chest CT scans and X-rays in COVID-19 patients. Models such as COVNet, joint CNNs with clinical metadata, DarkNet, CAD4COVID-Xray, and EfficientNet architectures were trained to classify COVID-19 infections with high performance (AUC values ranging from 0.81 to 0.98). The concept was adapted for ophthalmology by proposing that similar machine learning models could extract microvascular features from retinal images (such as vessel tortuosity, bifurcation, and microhemorrhages), enabling non-invasive diagnosis of COVID-19 severity through ocular signs. For literature mining, the methodology involved Natural Language Processing (NLP) techniques. Specifically, Latent Dirichlet Allocation (LDA) topic modeling was applied to the CORD-19 dataset and LitCovid database to extract and cluster over 200 ophthalmology-related COVID-19 scholarly articles. Preprocessing steps included text cleaning, tokenization, and calculating similarity scores between documents to automatically classify topics like ocular manifestations, viral transmission routes, treatment strategies, and telemedicine adaptations. In telemedicine AI applications, algorithms were proposed to enhance patient triage by automating the matching between urgent patient needs and available providers, optimizing remote consultation scheduling, and integrating home-monitoring devices. Artificial intelligence-driven decision analytics were envisioned to aid in interpreting electronic health records (EHRs) and imaging data remotely, thus facilitating a scalable, data-secure, and patient-centered telehealth infrastructure. Overall, the methodologies emphasize adapting existing AI models from radiology and informatics for use in ophthalmology, expanding telemedicine capacity, and enabling intelligent data extraction and decision support in clinical workflows.","During the COVID-19 pandemic, artificial intelligence (AI) methodologies were applied in ophthalmology across three primary domains: medical imaging analysis, natural language processing (NLP) for literature mining, and telemedicine enhancement. For medical image analysis, AI models like COVNet (a deep learning model for CT scans), DarkNet CNN (for chest X-rays), and EfficientNet B4 (deep neural network architecture) were adapted from radiology to ophthalmology, proposing that retinal imaging (via OCT, OCT-Angiography, ultra-wide field imaging) could reveal COVID-19-related microvascular changes, hyper-reflective lesions in ganglion cell layers, and cotton wool spots, thus supporting noninvasive diagnosis and severity prediction. Studies cited models achieving high diagnostic performance, such as AUC scores up to 0.96 for lung CT scan diagnosis, suggesting feasibility for ocular image analysis too. For natural language processing (NLP), the researchers mined the CORD-19 and LitCovid datasets, applying Latent Dirichlet Allocation (LDA) topic modeling to classify and summarize over 200 ophthalmology-related COVID-19 articles into themes like patient care, transmission risk, ocular manifestations, and treatments. This extraction aimed to assist clinicians by rapidly synthesizing emerging literature on ocular COVID-19 impacts. In telemedicine applications, AI algorithms were proposed for real-time patient triage, remote monitoring, and data integration from home devices, addressing urgent care prioritization and data security. Teleophthalmology services, already prominent in diabetic retinopathy and retinopathy of prematurity screening, were expanded rapidly under regulatory changes (like Medicare telehealth access expansion), with AI foreseen to further optimize clinician-patient matching, clinical workflow automation, and personalized care provision. Across these domains, AI methods were positioned not only as crisis-response tools but as central enablers of future ophthalmology research, diagnosis, patient management, and healthcare delivery, especially in a post-pandemic environment where telemedicine and digital health solutions are expected to be standard practice.
","Medical Imaging AI (Deep Learning on CT, X-ray, Retinal Imaging)
Natural Language Processing (NLP) for Topic Modeling
AI-enhanced Telemedicine Systems",No,No,Topic modeling of COVID-19 ophthalmology-related articles to extract insights,Full-text scholarly articles and scientific papers,CORD-19 dataset,Yes," the effectiveness was assessed qualitatively by how well the topic modeling captured key areas of interest, such as ocular manifestations, viral transmission through the eye, treatment strategies, and patient care management. The goal was not predictive accuracy but informational relevance and thematic categorization. No validation against a labeled ground truth dataset was done; it was an exploratory summarization task.",,,
,,,,,,,,,,,,,,,,,Filtering and extracting ophthalmology-specific COVID-19 articles,"Curated collection of COVID-19-related publications indexed in PubMed.
",LitCovid,Yes,"No standard performance metrics (like AUC, F1-score, etc.) were used. Instead, the authors judged the quality based on the successful identification and clustering of articles into these meaningful categories. The main aspect being measured was how comprehensive and relevant the classification was for ophthalmology-specific COVID-19 research, again without comparison to a benchmark or ground truth.",,,
55,"Silva RPD, Pollettini JT, Pazin Filho A.",2023,"Faculdade de Medicina de RibeirÃ£o Preto, Universidade de SÃ£o Paulo, RibeirÃ£o Preto, Brasil.",Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection,Cad Saude Publica,Respiratory Virology,['COVID-19'],"Observational Study, Journal Article","The aim of the study is to describe an unsupervised natural language processing (NLP) method using topic modeling to identify patients with suspected COVID-19 infection through the analysis of real-world prior authorization data from a private health care provider in São Paulo, Brazil.","Patients with post-COVID-19 syndrome require early identification for cost-effective enrollment in health promotion programs. Traditional structured methods (such as keyword search or diagnosis codes) perform poorly, especially during pandemics, due to unstructured, incomplete, and heterogeneous health data. Therefore, there is a need for innovative, scalable, and automatic approaches particularly unsupervised NLP methods to identify COVID-19 suspected cases from large and unstructured health records where conventional information like ICD-10 codes is missing or incomplete.","The AI objective is to automatically identify patients suspected of COVID-19 infection from unstructured text fields in a large healthcare prior authorization database, aiming to support early patient selection for health promotion programs without relying on structured data (like diagnosis codes).","The study employed unsupervised machine learning techniques for topic modeling applied to free-text fields of prior authorization records. Specifically, two NLP models BERTopic and Word2Vec were used to group similar authorization requests based on textual patterns. BERTopic created topics automatically through vectorization, dimensionality reduction (UMAP), and clustering (HDBSCAN), while Word2Vec generated word embeddings and used K-Means clustering for grouping. The models were tested both with raw text and after standard preprocessing (e.g., lowercasing, stopword removal). The unsupervised topics were manually evaluated to identify those related to COVID-19, enabling an exploratory classification framework that could feed into future supervised models.","The BERTopic model applied unsupervised topic modeling on the free-text ""clinical indication"" field from healthcare authorizations. Texts were first embedded using the all-MiniLM-L6-v2 sentence transformer model to generate dense vector representations. Then, Uniform Manifold Approximation and Projection (UMAP) was used to reduce dimensionality, followed by Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) to cluster similar authorizations. Each resulting cluster (topic) was characterized using TF-IDF keyword extraction. The model created topics automatically without requiring manual labeling. Two configurations were tested by setting the minimum topic size at 500 and 1,000 records. Some versions used raw text, while others applied text preprocessing (lowercasing, stopword removal, etc.). Cases classified into COVID-19 topics were identified based on automatic topic descriptions. Documents not assigned to any cluster were categorized as outliers.",BERTopic: Unsupervised learning.,Yes(Python library),MIT License.,identification of patients suspected of COVID-19 infection through the analysis of unstructured clinical text data,Text data (Twitter posts),Silva et.al,Yes," Performance of the BERTopic model was measured mainly through manual expert evaluation. The top 100 most expensive prior authorizations identified as suspected COVID-19 cases by the BERTopic +1,000 model were manually reviewed by a medical expert. The method used was human expert labeling compared against the model's automatic topic assignments. The metric used was classification accuracy, where the BERTopic model achieved 70% agreement with manual classification. Additionally, an indirect evaluation was performed by comparing the authorizations detected by BERTopic with those found via a traditional SQL keyword search, analyzing overlaps and differences in identified cases. No standard machine learning metrics like precision, recall, or F1-score were reported for BERTopic.","{ ""Accuracy""}","{ ""Accuracy"":70%}",
,,,,,,,,,,,,,"The Word2Vec model employed a Continuous Bag of Words (CBOW) architecture to learn word embeddings from the ""clinical indication"" text field. Each word was embedded into a 300-dimensional vector space, and an average vector was computed for each authorization text. These averaged text embeddings were then clustered into 20 groups using the K-Means algorithm. Unlike BERTopic, Word2Vec did not generate topic labels automatically instead, manual analysis of the top 100 most costly records per cluster was performed to assign COVID-19 relevance to each cluster. Both raw and preprocessed text versions were tested (preprocessing included lowercasing, stopword removal, normalization of COVID-related terms). The Word2Vec model with preprocessing performed better in identifying suspected COVID-19 cases compared to the raw version.",Word2Vec + K-Means,Yes (Gensim library),LGPL License,,Text data (Twitter posts),Silva et.al,Yes,"Performance of the Word2Vec model was evaluated indirectly. Since Word2Vec clustering required manual topic labeling, performance was compared based on the number of suspected COVID-19 cases identified and the associated expenditure analysis. Specifically, they measured how many COVID-related authorizations were captured compared to the traditional SQL keyword search. There was no formal manual expert reclassification like BERTopic’s 100-case manual check, and no direct accuracy percentage was reported for Word2Vec. Thus, the method used for performance measurement was comparison to traditional methods (SQL search overlap), and expenditure-based proxy evaluation. Again, no machine learning metrics such as precision, recall, F1-score, or accuracy were reported for Word2Vec.",Not specified,Not specified,
56,"Tran BX, Ha GH, Nguyen LH, Vu GT, Hoang MT, Le HT, Latkin CA, Ho CSH, Ho RCM.",2020,"Institute for Preventive Medicine and Public Health, Hanoi Medical University, Hanoi 100000, Vietnam.",Studies of Novel Coronavirus Disease 19 (COVID-19) Pandemic: A Global Analysis of Literature,Int J Environ Res Public Health,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Review","The aim of this study is to explore the current research foci on COVID-19 globally, examine country-level variations in research topics based on income levels and COVID-19 transmission characteristics, and propose a future research agenda to address knowledge gaps.","The rapid and vast growth of COVID-19-related scientific publications across the globe has led to a fragmented understanding of research priorities, with little comprehensive evaluation of how research foci differ between countries of varying income levels and transmission intensities. Existing reviews often focus on narrow topics or small sets of articles, missing a broader global perspective. As a result, there remains a critical need to systematically analyze the COVID-19 literature at scale, to uncover research gaps and better inform future pandemic-related research strategies and international collaborations.","To apply automated text mining and topic modeling techniques to analyze a large volume of COVID-19 publications, uncover latent research themes, and identify global and country-specific variations in research foci to guide future research priorities.","The study employed a text mining and topic modeling approach to process 5,780 COVID-19-related publications collected from Web of Science, Medline, and Scopus. After basic preprocessing (titles, abstracts, keywords extraction), a Latent Dirichlet Allocation (LDA) model was used for unsupervised topic modeling to discover hidden research themes within the textual data. Co-occurrence network analysis of keywords was visualized using VOSviewer. Regression analysis was then performed to statistically associate topic prevalence with countries’ income levels and COVID-19 transmission statuses, adjusting for confounding factors like GDP per capita, number of cases, and deaths.","Latent Dirichlet Allocation (LDA), a probabilistic unsupervised machine learning model, was applied to titles and abstracts to uncover 15 latent research topics based on the distribution of words across documents. Each document was represented as a mixture of topics with probabilistic weights, and each topic was defined by a distribution over terms. The researchers manually inspected and labeled topics by reviewing top keywords and representative documents. Additionally, keyword co-occurrence networks were constructed and visualized using VOSviewer to identify thematic clusters. Regression models were then used to analyze how the prevalence of topics varied with countries’ income groups and COVID-19 transmission characteristics.",Latent Dirichlet Allocation (LDA)-based Topic Modeling,No,No,Uncovering global research patterns in virology and clinical aspects of SARS-CoV-2 through unsupervised text mining,Scientific publications,Tran et.al,No,Manual inspection of sample documents to validate topic labels.,Not specified,Not specified,
57,"Weissenbacher D, O'Connor K, Klein A, Golder S, Flores I, Elyaderani A, Scotch M, Gonzalez-Hernandez G.",2023,"Cedars-Sinai Medical Center, Los Angeles, CA, USA.",Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,medRxiv,Respiratory Virology,['COVID-19'],"Preprint, Journal Article","To develop and validate a semi-automated pipeline that identifies and extracts patient metadata (demographics, clinical characteristics, etc.) from scientific journal articles reporting new SARS-CoV-2 sequences deposited in GenBank or GISAID.","Public databases like GISAID and GenBank lack critical patient metadata linked to SARS-CoV-2 sequences, despite such information often being available in corresponding research articles. Manual extraction from full texts is slow and impractical at scale, while existing keyword-based or basic ML tools fail to accurately retrieve and extract this data, highlighting the need for a more automated and efficient solution.","The AI objective of the study is to develop machine learning and natural language processing models that can automatically identify scientific articles describing newly generated SARS-CoV-2 sequences and extract detailed patient metadata (such as demographics, clinical outcomes, and comorbidities) from full-text content, thus reducing the dependency on manual review and enabling scalable, enriched genomic epidemiology research.","The study designed a semi-automated pipeline composed of multiple machine learning and NLP modules. Initially, a keyword filtering module used handcrafted regular expressions to pre-select articles likely to describe viral sequencing. Next, a classifier module was implemented, where a Support Vector Machine (SVM) and a fine-tuned BERT-base-uncased model were trained to classify sentences mentioning the sequencing of SARS-CoV-2 genomes. To handle the extreme class imbalance, techniques like selective undersampling based on sentence embeddings were explored. Finally, a relation extraction module was proposed to detect and link patient attributes (e.g., age, gender, clinical symptoms) using active learning to iteratively improve extraction quality with minimal human labeling. This pipeline is designed to automate the identification of minor but crucial details buried within large-scale full-text literature.","The pipeline began with a keyword-based filtering step to generate an initial article set from the LitCovid collection. For fine-grained identification, the team implemented a sentence-level classifier, first benchmarking an SVM with n-gram features, then developing a stronger model by fine-tuning a BERT-base-uncased transformer. The BERT classifier achieved an F1 score of 0.48 for sentence classification and 0.80 at the article level. To address the scarcity of positive examples, sentence embeddings were computed using SentenceTransformer models, and distant negative samples were removed to balance training. For extracting patient metadata, the proposed relation extraction module combines concept detection with active learning strategies to prioritize the most informative examples for manual annotation. Future work includes replacing BERT with larger open-source language models (e.g., BLOOM) to enhance scalability and eliminate heavy retraining requirements for adapting to new studies.",Semi-Automated Information Extraction Pipeline,No,No,Extraction of detailed patient metadata (demographic and clinical information) linked to SARS-CoV-2 virus genome sequences deposited in GenBank or GISAID.,Text data (articles in the NCBI Lit-Covid collection),NCBI Lit-Covid collection,Yes,"Performance in the study was evaluated at two levels: sentence-level and article-level classification. At the sentence level, the task was to predict whether a sentence mentioned viral genome sequencing, while at the article level, the goal was to determine whether an article was relevant, meaning it produced and deposited new SARS-CoV-2 sequences. Two models were trained for classification: a Support Vector Machine (SVM) as a baseline and a fine-tuned BERT-base-uncased model as the main classifier. In addition to model performance, inter-rater reliability (IRR) was assessed during manual annotation to measure agreement between human annotators using Cohen’s Kappa. Model performance was evaluated using standard classification metrics Precision, Recall, and F1 Score while manual annotation reliability was assessed through Cohen’s Kappa scores.","{""F1"", ""Precision"", ""Recall""}","{""Sentence_Level_F1"": 0.480, ""Sentence_Level_Precision"": 0.492, ""Sentence_Level_Recall"": 0.469, ""Article_Level_F1"": 0.800, ""Article_Level_Precision"": 0.667, ""Article_Level_Recall"": 1.0, ""Cohens_Kappa_Article_Classification"": 1.0, ""Cohens_Kappa_Evidence_Sentence_Selection"": 0.71}",
58,"Ong SQ, Pauzi MBM, Gan KH.",2022,"Institute for Tropical Biology and Conservation, Universiti Malaysia Sabah, Jalan UMS, Kota Kinabalu, Sabah 88400, Malaysia. Electronic address: songquan.ong@ums.edu.my.",Text mining in mosquito-borne disease: A systematic review,Acta Trop,General Virology,"['Dengue Fever', 'Zika Virus', 'Malaria']","Journal Article, Review, Systematic Review","To review and analyze recent studies that apply text mining techniques in the domain of mosquito-borne diseases, highlighting the data sources (corpora), technologies used, applications (e.g., surveillance, treatment), and existing challenges, in order to guide future work in this underexplored area.","Despite the growing threat of mosquito-borne diseases and advances in text mining, there is no comprehensive review focused specifically on how text mining techniques have been applied in this domain. Existing general-purpose tools are not well-suited due to the specialized biomedical nature of the mosquito-borne disease literature, and challenges such as inconsistent entity recognition, language bias, and limited integration of vector-specific data remain unaddressed.","To examine and categorize how artificial intelligence, particularly text mining and machine learning, has been utilized to extract and analyze information related to mosquito-borne diseases from various text corpora (e.g., Twitter, PubMed, LexisNexis), with a focus on enhancing surveillance, treatment insights, and public awareness.","Article Selection and Filtering
Conducted a bibliometric search across PubMed and Scopus (2016–2021) using Boolean logic to identify 294 research articles related to text mining in mosquito-borne diseases. After relevance filtering and expert validation, 27 articles using actual text mining techniques were selected for in-depth review.
Corpus and Technique Categorization
Reviewed studies based on:
Corpora used (e.g., Twitter, PubMed, LexisNexis)
Text mining techniques (e.g., sentiment analysis, information extraction, topic modeling, keyword extraction)
Applications (e.g., surveillance, treatment, public discourse understanding)
Analysis of Methods and Applications
Identified the dominant techniques (sentiment analysis and information extraction) and mapped them to practical use cases such as disease surveillance, prediction, symptom-drug relationships, and public health monitoring, highlighting trends, limitations, and future research directions.","Text Processing Techniques:
Tokenization, Normalization, Lemmatization, Stemming
Part-of-Speech (POS) tagging
Named Entity Recognition (NER) for extracting disease names, symptoms, treatments
Text Mining Techniques:
Sentiment Analysis: Used mainly on Twitter data to classify opinions as positive, negative, or neutral (often for surveillance and public discourse).
Information Extraction: Extracted structured relations between entities (e.g., disease-symptom, drug-disease) using:
Co-occurrence analysis
Dependency parsing
Literature-based discovery
Topic Modeling: Applied LDA and clustering to discover discussion topics in corpora like news or Twitter.
Keyword Extraction: Identified high-frequency or co-occurring keywords using algorithms like TextRank.",Text Mining with Natural Language Processing (NLP),No,No,"Surveillance, early detection, symptom-drug relation mining, and public discourse analysis","Text data from social media platforms, scientific literature like PubMed, news media",Ong et.al,No,The paper iteself does not evaluate any metrics,Not specified,Not specified,
59,"Pilipiec P, Samsten I, Bota A.",2023,"Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden.",Surveillance of communicable diseases using social media: A systematic review,PLoS One,Respiratory Virology,"[communicable diseases, with a primary emphasis on influenza (studied in 16 out of 23 papers). Other diseases included dengue, measles, Ebola, HIV/AIDS, listeria, and tuberculosis.]","Systematic Review, Journal Article","The aim of the study is to conduct a systematic literature review on the use of textual content from social media for the surveillance and prediction of communicable diseases, with a particular emphasis on the technical application of natural language processing (NLP) methods.","Existing reviews are either outdated, lack technical detail, or focus on broader AI applications rather than on NLP and text mining.","To explore how Artificial Intelligence, specifically Natural Language Processing (NLP) techniques, are applied to analyze user-generated textual data from social media for the monitoring, surveillance, and prediction of communicable diseases. The goal is to evaluate whether AI-based text mining can enhance or supplement traditional public health surveillance systems.","The AI methodology adopted in this systematic review focused on analyzing how natural language processing (NLP) techniques were applied to social media text for the surveillance and prediction of communicable diseases. The review followed the PRISMA guidelines, using a structured, multi-phase screening process. Four major databases ACM Digital Library, IEEE Xplore, PubMed, and Web of Science—were searched in March 2020 using a combination of search terms related to AI, NLP, and public health surveillance. The selection process involved three screening stages: title, abstract, and full-text review. To ensure comprehensiveness, journal articles and conference papers were included if they involved empirical research analyzing user-generated social media text (e.g., tweets) for monitoring communicable diseases. Exclusion criteria ruled out papers focusing on non-communicable diseases, non-social media content (e.g., news articles), or those lacking implementation results (e.g., proposals only). Studies were also excluded if they relied solely on content generated by organizations rather than the general public. From an initial pool of 5,318 records, 23 studies were ultimately included after duplicate removal and eligibility screening. The extracted data included disease type, NLP methods, prediction algorithms, data source, and geographical and language information. A qualitative content analysis was then used to identify themes related to preprocessing, modeling techniques, and surveillance effectiveness.","The core methodology involved using NLP techniques to extract meaningful information from unstructured social media text—primarily from Twitter—for surveillance and prediction of disease trends. Common NLP steps included tokenization, stemming, lemmatization, stop-word removal, n-gram generation, TF-IDF weighting, and sentiment analysis. These processed features were then used in predictive models such as Support Vector Machines (SVM), Naïve Bayes, Decision Trees, Linear Regression, Hidden Markov Models, and Recurrent Neural Networks with LSTM. The studies aimed to classify or predict disease outbreaks, public health sentiment, or case trends based on social media data. Despite methodological differences, all studies reported positive results, confirming the usefulness of AI in communicable disease surveillance.",Natural Language Processing (NLP) and text mining,No,No,surveillance and prediction of communicable disease outbreaks, User-generated social media text (Twitter),Pilipiec et.al,No,no universal evaluation framework was applied across all 23 studies,Not specified,Not specified,
60,"Xue H, Gong X, Stevens H.",2022,"Department of Communication, University of California, Davis, Davis, CA, United States.",COVID-19 Vaccine Fact-Checking Posts on Facebook: Observational Study,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Observational Study","To investigate the impact of COVID-19 vaccine fact-checking posts on public attitude, social media engagement, and emotional-linguistic features.","Widespread COVID-19 vaccine misinformation on social media contributes to vaccine hesitancy, and the effectiveness of fact-checking messages is underexplored.","To analyze attitudes, emotions, and linguistic patterns in fact-checking posts and comments using AI to understand their influence on public opinion.","The AI methodology in this study involved applying commercial natural language processing (NLP) tools to analyze public sentiment and linguistic patterns in social media data related to COVID-19 vaccine fact-checking. The researchers first collected a dataset of 12,553 fact-checking Facebook posts and 122,362 associated comments using Meta’s CrowdTangle and Facepager tools. They then used Google Cloud Natural Language AI to extract sentiment-related features, including entity salience, attitudinal valence (positive/negative sentiment), and emotional magnitude specifically targeting COVID-19 vaccine–related entities. To capture more nuanced emotional and linguistic characteristics, they employed IBM Watson Tone Analyzer, which identified discrete emotions (joy, anger, sadness, fear) and linguistic tones (confidence, tentativeness, analytical thinking) from both posts and comments. These AI tools were used in a black-box fashion, meaning the study did not involve custom model training or tuning. Instead, the focus was on leveraging existing pretrained NLP APIs to extract structured insights for statistical correlation and regression analysis, enabling the researchers to evaluate how public attitudes and emotional responses to vaccine fact-checking evolved over time.","The study employed two commercial AI-based natural language processing tools—Google Cloud Natural Language AI and IBM Watson Tone Analyzer—to extract sentiment, emotional, and linguistic features from a large dataset of Facebook fact-checking posts and their comments related to COVID-19 vaccines. Google Cloud Natural Language AI was used to identify named entities in texts, isolate vaccine-related entities using keyword matching, and quantify three sentiment-related features: entity salience (relevance of vaccine topics), attitudinal valence (degree of positivity/negativity toward the vaccine), and attitudinal magnitude (emotional intensity). IBM Watson Tone Analyzer was then used to capture discrete emotions such as joy, anger, sadness, and fear, as well as linguistic styles like confidence, tentativeness, and analytical thinking. These extracted features were aggregated and analyzed statistically over time and across different sources (e.g., hospitals, news media) to assess public sentiment trends, emotional engagement, and the credibility impact of fact-checking sources. The methods required no custom AI model training but relied on pretrained black-box NLP services to derive interpretable features from unstructured text data.",Google Cloud Natural Language AI and IBM Watson Tone Analyzer (NLP-based Sentiment and Emotion Analysis Tools),Yes(commercial tool),No,COVID-19 vaccine misinformation correction and public sentiment monitoring,"Text data from news articles, social media, and public health reports",Xue et.al,No,"Performance in this study was measured through sentiment and emotion analysis rather than traditional accuracy or predictive modeling metrics. The researchers used Google Cloud Natural Language AI and IBM Watson Tone Analyzer to quantify public responses to COVID-19 vaccine fact-checking posts. Key indicators included attitudinal valence (ranging from -1 to 1), attitudinal magnitude (from 0 to positive infinity), and entity salience (0 to 1), along with discrete emotions (joy, anger, fear, sadness) and linguistic features (confidence, tentativeness, analytical thinking), all ranging from 0 to 1. Statistical methods such as correlation analysis and multiple regression were applied to track how these indicators changed over time and varied across different information sources. Metrics used to quantify these findings included correlation coefficients, t-values, confidence intervals, and P-values.","{""attitudinal_valence_range"": [], ""attitudinal_magnitude_range"": [], ""entity_salience_range"": [], ""discrete_emotion_scores"": {}, ""linguistic_features"": {}, ""statistical_metrics"": {}}","{""attitudinal_valence_range"":[-1,1],""attitudinal_magnitude_range"":[0,""positive infinity""],""entity_salience_range"":[0,1],""discrete_emotion_scores"":{""joy"":[0,1],""anger"":[0,1],""fear"":[0,1],""sadness"":[0,1]},""linguistic_features"":{""confidence"":[0,1],""tentativeness"":[0,1],""analytical_thinking"":[0,1]},""statistical_metrics"":{""correlation_coefficient_r"":""varies per test"",""t_value"":""varies per test"",""confidence_interval"":""reported per result"",""p_value"":""< .001 to > .05 depending on result""}}",
61,"Odlum M, Yoon S.",2015,"School of Nursing, Columbia University Medical Center, New York, NY.",What can we learn about the Ebola outbreak from tweets?,Am J Infect Control,General Virology,"[""Ebola""]","Journal Article, Observational Study","To examine Twitter data during the Ebola outbreak for trends in information spread, early detection, and public attitudes.","Timely epidemic surveillance is difficult in resource-limited settings; there is a need for real-time, publicly sourced early warning systems.","Harness social media data, specifically tweets, to detect early epidemic signals, monitor public perception and knowledge, and identify information dissemination patterns during the Ebola virus disease (EVD) outbreak. ","In this study, tweets related to Ebola were collected over a defined period using keyword-based filtering techniques. Natural language processing (NLP) was then applied for content analysis, beginning with cleaning the tweet text and transforming it into vector representations using N-gram models (unigrams, bigrams, trigrams). To manage the large volume of data, dimensionality reduction was performed using Weka software. The refined data was clustered using the K-means algorithm to identify major thematic concerns such as risk factors, prevention education, disease trends, and expressions of compassion. To capture the dynamics of information dissemination, time series analysis specifically exponential smoothing was employed to model the temporal spread of tweets. Geographic visualization of tweet locations was achieved using Tableau, providing insights into the spatial distribution of public discourse during the Ebola outbreak.","The AI method used in this study integrated natural language processing (NLP) with unsupervised learning and temporal modeling techniques. For the content analysis, tweets were preprocessed by removing symbols, URLs, and stop words, then converted into vector space representations using N-grams (unigram, bigram, trigram) to preserve phrase-level context. Dimensionality reduction was conducted using Weka to streamline high-dimensional data for efficient computation. The core machine learning method applied was K-means clustering, an unsupervised algorithm that grouped tweets into thematic clusters based on content similarity. These clusters revealed dominant topics such as transmission risks, preventive measures, epidemic progression, and compassionate responses. Additionally, exponential smoothing was used in the time series analysis to detect and model the rate of tweet dissemination over time, indicating how rapidly public attention and awareness evolved. Visualization tools such as Tableau were used to map tweet locations, enhancing the interpretability of geographic trends. Importantly, while AI methods like K-means and NLP were central to content classification, the time-based modeling and visualization complemented the AI outputs for comprehensive outbreak surveillance.",Natural Language Processing (NLP) combined with K-means Clustering for topic detection and Time Series Analysis for trend modeling,N,No,"epidemic surveillance of Ebola virus disease (EVD), focusing on early outbreak detection, tracking public attitudes, and identifying knowledge gaps using real-time social media data.",Text Data (tweets),"EVD-related Twitter Corpus (July 24 – August 1, 2014)",Yes,"Performance was not evaluated using traditional AI accuracy metrics such as precision, recall, or F1-score. Instead, performance was assessed through descriptive and statistical analysis of tweet volume, dissemination rates, geographic spread, and thematic content categorization. A total of 42,236 Ebola-related tweets were collected (16,499 unique tweets and 25,737 retweets) over a 9-day period. These tweets were disseminated to approximately 9.36 billion users globally. Temporal trend modeling using exponential smoothing revealed that tweet dissemination increased by approximately 520,441 users per minute (P < 0.0001), indicating a significant surge in information spread during the early outbreak stage. Geographical analysis showed initial concentration in Africa and Europe, which expanded globally after the CDC announcement, including to North America, Asia, and Australia. Content clustering using NLP and K-means revealed four main themes: risk factors (e.g., transmission), prevention education, disease trends, and compassion. These results collectively highlight Twitter’s real-time potential for early epidemic detection and public health surveillance.",Not specified,Not specified,
62,"Li Z, Li Y, Chen Y, Li J, Li S, Li C, Lin Y, Jian W, Shi J, Zhan Y, Cheng J, Zheng J, Zhong N, Ye F.",2021,"State Key Laboratory of Respiratory Disease, National Clinical Research Center for Respiratory Disease, Guangzhou Institute of Respiratory Health, the First Affiliated Hospital of Guangzhou Medical University, Guangzhou, People's Republic of China.","Trends of pulmonary fungal infections from 2013 to 2019: an AI-based real-world observational study in Guangzhou, China",Emerg Microbes Infect,Respiratory Virology,"[""Pulmonary Fungal Infections""]","Journal Article, Observational Study",To investigate changes in epidemiological characteristics and trends of pulmonary fungal infections using AI-based NLP on EHR data.,"Limited knowledge and uncertainty around incidence and characteristics of pulmonary fungal infections (PFIs), especially among youth and rare pathogens.","The objective was to apply artificial intelligence, specifically an automated natural language processing (NLP) system, to extract and standardize clinically relevant information from unstructured electronic health records (EHRs) of patients with pulmonary fungal infections (PFIs). ","The AI methodology involved a multi-phase process designed to extract, clean, standardize, and analyze electronic health record (EHR) data related to pulmonary fungal infections (PFIs). First, an automated NLP system was employed to retrospectively screen patient records from 2013 to 2019, identifying those with confirmed PFIs based on clinical diagnoses. Suspected cases were excluded at this stage. Next, structured clinical data were extracted, including demographics, pathogen types, comorbidities, drug use, and adverse events. A diagnostic standardization pipeline was integrated to ensure consistency in terminology across records, relying on mapping to ICD-10 and SNOMED vocabularies. This enabled uniform categorization of diseases and pathogens. Post-standardization, a trend analysis was conducted using SPSS and R, applying statistical tests (e.g., linear regression on log incidence rates) to evaluate changes in disease incidence and related factors over time.","The study employed a rule-based and dictionary-augmented Natural Language Processing (NLP) method to extract and standardize clinical diagnostic information from unstructured electronic health records (EHRs). The NLP process began with diagnostic parsing, where diagnostic phrases were extracted from multiple sections of patient records such as discharge summaries and outpatient notes. These were then split into individual disease entries using predefined rule sets. Each diagnostic term was matched to standardized medical vocabularies specifically ICD-10 and SNOMED using a curated synonym database. If a direct match wasn’t found, the term was manually normalized and mapped. The NLP pipeline also included a diagnostic validation phase, where outputs were sampled and reviewed to refine rules and update the synonym database iteratively. This structured approach ensured consistent terminology across records, improved data reliability, and facilitated accurate trend analysis in pulmonary fungal infection cases.",Automated Natural Language Processing (NLP) System,No,No,"epidemiological trend analysis of pulmonary fungal infections (PFIs),",Electronic Health Records (EHRs),Li et.al,Yes,"The performance of the AI system in this study was not assessed using traditional AI metrics like accuracy or F1-score. Instead, the system's effectiveness was demonstrated through its successful application in extracting and analyzing clinical data from unstructured electronic health records (EHRs) using natural language processing (NLP). The results showed that out of 40,504 inpatients and 219,414 outpatients screened for respiratory diseases between 2013 and 2019, the AI system identified 1,368 inpatients and 1,313 outpatients with pulmonary fungal infections (PFIs). Through trend analysis, the study revealed a significant increase in PFI incidence over time especially among the 14–30 age group, where hospitalizations rose from 9.5 per 1000 in 2013 to 88.3 per 1000 in 2019. Additionally, the incidence of Talaromyces marneffei, previously considered rare, showed the steepest increase, from 0.17 per 1000 patients in 2013 to 1.97 per 1000 in 2019, reflecting a 16% year-on-year growth (P<0.001). These findings highlight the real-world utility and epidemiological insights enabled by the AI-driven NLP system, despite the absence of explicit predictive model performance metrics.",Not specified,Not specified,
63,"Wang Y, O'Connor K, Flores I, Berdahl CT, Urbanowicz RJ, Stevens R, Bauermeister JA, Gonzalez-Hernandez G.",2024,"Department of Computational Biomedicine, Cedars-Sinai Medical Center, West Hollywood, CA, USA.","Health activism, vaccine, and mpox discourse: BERTopic based mixed-method analyses of tweets from sexual minority men and gender diverse (SMMGD) individuals in the U.S",medRxiv,Emerging & Re-emerging Viruses,"[""Monkeypox""]","Preprint, Journal Article","The aim of the study is to synthesize and analyze online discussions about mpox (monkeypox) among sexual minority men and gender diverse (SMMGD) individuals on Twitter/X. The goal is to understand the thematic concerns, emotional expressions, and activist messaging from this community, which is often underrepresented in mpox-related public health literature, in order to improve inclusive health communication strategies.","Existing mpox research lacks direct representation of sexual minority men and gender diverse (SMMGD) voices, limiting the understanding of their unique experiences and concerns in public health discourse.






","To identify and categorize major themes in mpox-related social media discourse among sexual minority men and gender diverse (SMMGD) individuals using topic modeling techniques, in order to inform inclusive and equitable public health communication strategies.","The study employed a hybrid AI methodology combining natural language processing (NLP), transformer-based text embedding, dimensionality reduction, unsupervised clustering, and topic modeling to analyze mpox-related tweets. Tweets were first collected from a curated cohort of 2,326 self-identified SMMGD users in the U.S. and filtered by mpox-related keywords. NLP preprocessing was applied to normalize the text, including removing URLs and mentions, converting to lowercase, expanding contractions, translating emojis, and harmonizing synonyms (e.g., various spellings of “monkeypox” were mapped to “mpox”). Tokenization, stopword removal, and lemmatization were conducted using the nltk Python library. After preprocessing, semantic embeddings of the tweets were generated and passed through a pipeline involving BERTopic for topic modeling. The pipeline included UMAP for dimensionality reduction, HDBSCAN for clustering, and c-TF-IDF with BM25 for keyword representation. The output topics were further refined and interpreted through human validation and annotated to assess coherence and accuracy. Additionally, correlation analysis was conducted between topic frequencies and state-level social acceptance scores (LGB social climate index) to examine geographic patterns in discourse.","The technical implementation used the all-MiniLM-L6-v2 transformer model to encode each tweet into dense vector representations capturing semantic similarity. These embeddings were reduced in dimensionality using UMAP to enhance cluster separability. The reduced vectors were then clustered using HDBSCAN, an algorithm well-suited for noisy social media data due to its ability to identify dense clusters and label outliers. For topic generation, CountVectorizer converted tweets into bag-of-words format, and BERTopic leveraged c-TF-IDF with BM25 weighting to emphasize important terms while down-weighting frequent but uninformative words. Hyperparameters such as n_neighbors, min_samples, and min_cluster_size were fine-tuned to ensure meaningful topic granularity. Human annotators reviewed top keywords and representative tweets from each topic to assign meaningful labels and conducted inter-annotator agreement testing to validate classification quality. The model ultimately categorized 91.24% of tweets into 11 coherent topics. Topic-level geographic analysis was performed using Carmen 2.0 to assign tweet locations and assess the relationship between topic prevalence and regional LGB social acceptance.",BERTopic (Bidirectional Encoder Representations from Transformers-based Topic Modeling).,No(Can ask authors to get it),No,infodemiology and stigma surveillance for mpox (monkeypox),Social Media Data (Twitter Posts),Mpox-related tweets from self-identified SMMGD (sexual minority men and gender diverse) users on Twitter (October 2020 – September 2022).,Yes,"The performance of the AI method (BERTopic) was evaluated using a human-validated approach rather than traditional automated metrics. Specifically, the researchers measured how well the machine-generated topic labels aligned with human judgment by conducting manual topic validation. Two human annotators independently reviewed a subset of tweets and assigned topic labels based on content, without seeing the model's assigned labels. Their annotations were then compared to both each other’s and the machine’s results. The evaluation focused on percent agreement as a primary metric to assess how accurately BERTopic categorized tweets into meaningful topics. This validation approach accounted for the challenges of multi-class classification tasks and provided a realistic measure of the model's interpretability and thematic coherence.","{""Percent Agreement""}","{ ""human_annotator_agreement"": ""70.77%"", ""machine_vs_human_annotator_1_agreement"": ""60.1%"", ""machine_vs_human_annotator_2_agreement"": ""60%"" }",
64,"Saeidpour A, Bansal S, Rohani P.",2022,"Odum School of Ecology, University of Georgia, Athens, Georgia, United States of America.",Dissecting recurrent waves of pertussis across the boroughs of London,PLoS Comput Biol,Bacteriology,"[""Pertussis ""]","Journal Article, Review, Research Support, N.I.H., Extramural","To investigate the spatial epidemiology and transmission dynamics of pertussis across the boroughs of Greater London (1982–2013), and to identify the demographic, socioeconomic, and geographic factors driving the temporal and spatial diffusion patterns of the disease.","Despite high immunization coverage, pertussis has resurged in the UK to levels not seen since the 1980s, and the underlying causes and spatial diffusion patterns across urban areas like London remain poorly understood.","To quantify and interpret the contribution of demographic, socioeconomic, geographic, and household-level features in determining the spatial and temporal phase differences of pertussis outbreaks across London boroughs using interpretable machine learning.","The study employed a hybrid methodology combining epidemiological signal processing with machine learning. First, the epidemic phase lags measuring how early or late pertussis outbreaks occurred in each London borough were computed using the Hilbert transform applied to temporally filtered incidence time series. These lags served as the target variable for the subsequent AI analysis. Next, the researchers compiled a borough-level dataset consisting of over 20 features derived from UK census data (household composition, socioeconomic indicators, occupation categories, ethnic background, transportation patterns, and geographic attributes). To examine how these features contributed to the timing of pertussis outbreaks, multiple regression models were tested including ordinary least squares (OLS), Lasso, and Ridge regression—to capture linear relationships. However, due to suspected non-linear interactions between variables, a feed-forward neural network (FFNN) was also used for superior modeling power. Model training and evaluation involved careful data splitting and cross-validation. Finally, SHAP (SHapley Additive exPlanations) was used to interpret the machine learning model by quantifying the contribution of each feature to its predictions across boroughs.","The feed-forward neural network (FFNN) implemented in this study was configured using the Keras library with a TensorFlow backend. The model architecture was optimized with up to three hidden layers and 64 nodes per layer using tanh activation functions. Dropout regularization was applied to reduce overfitting, and the model was trained using the Adam optimizer for up to 2000 epochs. For validation, 16 borough samples were reserved as a validation set, and grid search was used to tune hyperparameters. After training, the model’s predictions were interpreted using SHAP values, a model-agnostic method based on cooperative game theory. SHAP explains individual predictions by distributing the output prediction among input features according to their marginal contribution. This allowed researchers to identify key predictors of epidemic phase such as the number of households with children aged 0–4, skilled manual labor populations, latitude, and use of public transport with both local (borough-specific) and global interpretability. The SHAP analysis revealed nuanced associations e.g., boroughs with more young children or higher public transport usage tended to experience earlier outbreaks, while those with higher immigrant populations showed lagging epidemic phases in later years.",Feed-Forward Neural Network (FFNN) with SHapley Additive exPlanations (SHAP) for interpretability.,No,No,Spatial epidemiology and resurgence modeling of pertussis (whooping cough),Demographic data and epidemic phase lag data,Notifications of Infectious Diseases (NOIDs) dataset,Yes,"The performance of the AI model a feed-forward neural network (FFNN) was evaluated using training and test datasets to predict borough-level epidemic phase lags during pertussis outbreaks in London. Model effectiveness was assessed using the coefficient of determination (R²), which measures how closely the predicted values align with actual observations. The FFNN outperformed traditional linear models, including ordinary least squares (OLS), lasso, and ridge regression, showing better generalization and reduced overfitting. Although the exact R² values were not specified, the study confirmed the FFNN's superior performance across all dataset splits. For interpretability, SHapley Additive exPlanations (SHAP) were used to quantify the contribution of each input feature to the model’s output. This approach identified key demographic and socio-economic factors influencing the timing of pertussis epidemics. No classification metrics like accuracy or precision were reported, as the study focused on regression-based temporal-spatial analysis.","{""Coefficient of determination""}","{""Coefficient of determination"":Not specified numerically}",
65,"Hou Y, Zhang Q, Gao F, Mao D, Li J, Gong Z, Luo X, Chen G, Li Y, Yang Z, Sun K, Wang X.",2020,"Center of Integrative Medicine, Beijing Ditan Hospital, Capital Medical University, Beijing, 100015, People's Republic of China.",Artificial neural network-based models used for predicting 28- and 90-day mortality of patients with hepatitis B-associated acute-on-chronic liver failure,BMC Gastroenterol,Hepatic Virology,"[""Hepatitis B""]","Journal Article, Validation Study","To develop and validate artificial neural network (ANN)-based prognostic models for predicting 28-day and 90-day mortality risks in patients with hepatitis B virus-associated acute-on-chronic liver failure (HBV-ACLF), and to compare their predictive performance against existing clinical scoring systems.","To accurately predict 28-day and 90-day mortality in HBV-associated acute-on-chronic liver failure (HBV-ACLF) patients using an artificial neural network (ANN), and to evaluate whether it outperforms existing prognostic scoring models.",To develop an AI-based diagnostic model that can accurately predict HBV-ACLF in patients with chronic hepatitis B,"The study employed a supervised machine learning approach to build prognostic models for predicting 28- and 90-day mortality in patients with HBV-associated acute-on-chronic liver failure (HBV-ACLF). Specifically, an artificial neural network (ANN) was used, trained on retrospective clinical and laboratory data. The model development process involved univariate analysis to identify variables significantly associated with mortality outcomes, which were then included in the training process. The dataset was split into a training cohort (423 patients) and a validation cohort (261 patients) sourced from eight tertiary hospitals in China. The learning process involved adjusting internal weights via backpropagation to minimize prediction error, and the final models were evaluated against established clinical scoring systems using receiver operating characteristic (ROC) curve analysis.","The AI model was implemented as a multilayer perceptron (MLP)-based artificial neural network (ANN), comprising one input layer with eight input features (age, hepatic encephalopathy, serum sodium, prothrombin activity, ?-glutamyltransferase, alkaline phosphatase, hepatitis B e antigen status, and total bilirubin), one hidden layer containing two neurons, and a single output neuron indicating mortality risk. The model was developed using Mathematica 11.1.1 for Windows (64-bit). The ANN was trained via the backpropagation algorithm, where the weights between neurons were iteratively adjusted to reduce the discrepancy between predicted and actual outcomes. The ANN output was a continuous risk score for mortality, which was subsequently assessed for predictive performance using the area under the ROC curve (AUR), with comparisons made against MELD, MELD-Na, CTP, and CLIF-ACLF scoring systems.",['Artificial Neural Network'],No,No,mortality risk prediction in patients with hepatitis B virus (HBV)-associated acute-on-chronic liver failure (HBV-ACLF),"Clinical Data (e.g., patient demographics, lab results, virological markers)",Multi-center HBV-ACLF patient dataset,Yes,"The performance of the artificial neural network (ANN) models for predicting 28- and 90-day mortality in HBV-associated acute-on-chronic liver failure (HBV-ACLF) patients was assessed using Receiver Operating Characteristic (ROC) curve analysis. The Area Under the ROC Curve (AUC) was used as the primary evaluation metric, comparing the ANN model's performance against standard clinical scoring systems such as MELD, MELD-Na, CTP, and CLIF-ACLF. The AUC values reflect the model’s ability to discriminate between survivors and non-survivors. Performance was evaluated separately on the training cohort (n=423) and validation cohort (n=261). Specifically, the ANN model achieved higher AUC values in both training and validation cohorts for 28-day and 90-day mortality predictions. This indicates that the ANN model outperformed traditional models in both sensitivity and specificity of prognostic classification.","{""AUC-ROC""}","AUC scores: 28-day (training: 0.948, validation: 0.748), 90-day (training: 0.913, validation: 0.754)
",
66,"Mayhew MB, Buturovic L, Luethy R, Midic U, Moore AR, Roque JA, Shaller BD, Asuni T, Rawling D, Remmel M, Choi K, Wacker J, Khatri P, Rogers AJ, Sweeney TE.",2020,"Inflammatix, Inc., 863 Mitten Rd, Suite 104, Burlingame, CA, 94010, USA.",A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections,Nat Commun,Respiratory Virology,"[""Bacterial infections, viral infections, ,Noninfectious inflammation""]","Evaluation Study, Journal Article, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't","To develop a generalizable host gene expression-based classifier (IMX-BVN-1) for distinguishing bacterial, viral, and noninfectious acute infections.","Need for a rapid, reliable, and generalizable diagnostic tool that can interpret host immune response to guide appropriate antibiotic use and reduce sepsis-related mortality, overtreatment, and antimicrobial resistance.","Classify infection types (bacterial, viral, noninfected) from host gene expression data using machine learning for clinical application.","The researchers developed the classifier using transcriptomic data from 18 retrospective studies comprising 1,069 patients. They began with a predefined set of 29 host mRNAs previously validated in smaller studies and transformed them into six geometric mean (GM) scores representing biological signatures. To address technical variability from different microarray platforms, they applied the COmbat CO-Normalization Using conTrols (COCONUT) framework to harmonize expression levels. Model development employed hierarchical cross-validation (HiCV) with a leave-one-study-out (LOSO) strategy to reduce bias and improve generalizability. Multiple classifiers were tested logistic regression, SVM, XGBoost, and MLP and multi-layer perceptrons (MLPs) were selected based on best average performance across bacterial-vs-other, viral-vs-other, and noninfected-vs-other AUROCs.","IMX-BVN-1 is a fixed-weight multi-layer perceptron (MLP) model consisting of two hidden layers with four nodes each and linear activations. It was trained using gradient descent over 250 iterations with a small learning rate (1e?5), batch normalization, and L1 regularization (lasso penalty coefficient of 0.1). The input to the model was six geometric mean scores derived from 29 target mRNAs. The classifier outputs three scores bacterial-vs-other, viral-vs-other, and noninfected-vs-other enabling multiclass prediction. The final MLP model was trained entirely on the IMX dataset and validated without retraining on an independent Stanford ICU cohort assayed using NanoString technology, confirming its strong performance and generalizability.","{""IMX-BVN-1 (Inflammatix Bacterial-Viral-Noninfected version 1) (Feed-forward MLP)""}",No,No,"the model distinguishes between viral, bacterial, and noninfectious causes of inflammation using host gene expression data.","Gene expression data, clinical metadata such as age,severity score, treatment details","IMX dataset, which was constructed by combining 18 publicly available transcriptomic studies(NCBI Gene Expression Omnibus (GEO), EMBL-EBI ArrayExpress)",Yes,"Performance on the IMX training dataset (N = 1069) was evaluated using a Leave-One-Study-Out Cross-Validation (LOSO-CV) strategy, which ensured that each individual study was used as a held-out validation fold while the remaining were used for training. This method helped minimize overfitting and accurately simulate external test performance. The classifier’s ability to distinguish between bacterial, viral, and noninfected samples was quantified using AUROC (Area Under the Receiver Operating Characteristic curve) for each one-vs-all classification. To rank models, the authors used the Average Pairwise AUROC (APA) metric, which averages AUROCs across all three tasks. The best-performing model was a multi-layer perceptron (MLP), which achieved AUROCs of 0.92 for both bacterial-vs-other and viral-vs-other tasks, and 0.78 for noninfected-vs-other in LOSO-CV.","{""AUC-ROC""}"," {""AUROC_Bacterial_vs_Other_Validation"": 0.86, ""AUROC_Viral_vs_Other_Validation"": 0.85, ""AUROC_Noninfected_vs_Other_Validation"": 0.82}",
,,,,,,,,,,,,,,,,,,,Stanford ICU biobank,,"The IMX-BVN-1 classifier was externally validated on an independent Stanford ICU cohort (N = 163), using gene expression data collected on a different platform (NanoString nCounter). Performance was assessed using AUROC to evaluate the model’s discriminatory ability between bacterial, viral, and noninfected infections without retraining. Among the 109 patients with unanimous adjudications, the AUROC values were 0.86 for bacterial-vs-other, 0.85 for viral-vs-other, and 0.82 for noninfected-vs-other. A key subgroup analysis was performed on patients enrolled within 36 hours of hospital admission (N = 70), where AUROCs were even higher: 0.92 for bacterial-vs-other, 0.91 for viral-vs-other, and 0.86 for noninfected-vs-other. These consistent values across datasets demonstrated strong generalizability and minimal bias or overfitting.",,"{""AUROC_Bacterial_vs_Other_Validation_36h"": 0.92, ""AUROC_Viral_vs_Other_Validation_36h"": 0.91, ""AUROC_Noninfected_vs_Other_Validation_36h"": 0.86}",
67,"Liu F, Wang J, Liu J, Li Y, Liu D, Tong J, Li Z, Yu D, Fan Y, Bi X, Zhang X, Mo S.",2020,"Taikang Pension & Insurance Co., Ltd., Beijing, China.","Predicting and analyzing the COVID-19 epidemic in China: Based on SEIRD, LSTM and GWR models",PLoS One,Respiratory Virology,"[""COVID-19""]","Comparative Study, Journal Article","To predict and analyze the COVID-19 epidemic trends in China using SEIRD, LSTM, and GWR models.",Developing accurate models to predict COVID-19 epidemic curves and inform public health interventions,"To predict the short-term trend of cumulative confirmed COVID-19 cases in different Chinese regions using data-driven machine learning techniques, particularly a neural network, and compare it with traditional epidemiological and spatial models.","In this study, a hybrid modeling framework was developed to forecast and analyze the spread of COVID-19 across China by integrating three complementary approaches: a modified SEIRD epidemiological model, an LSTM deep learning model, and a Geographically Weighted Regression (GWR) model. The SEIRD model dynamically simulated the epidemic’s progression with time-varying infection parameters and was updated daily to reflect real-time trends. The LSTM model captured temporal patterns and human mobility effects to predict short-term case growth using recurrent neural networks. Meanwhile, the GWR model accounted for spatial heterogeneity, revealing how demographic and healthcare factors influenced regional case counts. Together, these models provided a comprehensive view of the epidemic, enabling accurate short-term forecasting, evaluation of government interventions, and geographically informed decision-making.","The LSTM (Long Short-Term Memory) model used in this study is a deep learning-based recurrent neural network architecture designed to capture temporal dependencies in time series data. The model was trained to predict the next day’s cumulative number of confirmed COVID-19 cases using three key input features: the number of confirmed cases on the previous day, the number of migrants from Wuhan, and a derived feature combining the migration count with the incidence rate in Wuhan to estimate potential imported infections. The network architecture consisted of four layers: an input layer, a hidden LSTM layer with 10 hidden units, a fully connected dense layer, and an output layer. The ReLU activation function was used throughout, and the model was optimized using the Adam optimizer with mean squared error (MSE) as the loss function. Grid search was applied to optimize hyperparameters for each of the selected regions (Zhejiang, Guangdong, Beijing, and Shanghai). The model leveraged the LSTM’s internal memory mechanism to effectively learn patterns from both epidemiological and mobility data, enabling accurate short-term forecasting of the COVID-19 epidemic.",Long Short-Term Memory (LSTM),No,No,Short-term forecasting of the cumulative confirmed COVID-19 cases across different regions in China,"Geographic, demographic, and medical resources data for different cities",Open Wuhan COVID-19 Illness Data,Yes,"The study assessed the predictive performance of three models Modified SEIRD, LSTM neural network, and Geographically Weighted Regression (GWR) by comparing their predicted COVID-19 case counts to actual reported cases across various Chinese regions. The Modified SEIRD model demonstrated high accuracy, with absolute percent errors (APE) below 1% after mid-February and as low as 0.10% by late February. The LSTM model, which incorporated traffic and historical case data, also showed strong predictive capability, with APEs of ?5.1% on February 3rd and ?0.63% on February 14th. The GWR model, which captured spatial heterogeneity, achieved R² values of 99.98% on training data and 97.95% on test data, although it exhibited slightly higher prediction errors in some cities. A statistical comparison using the Wilcoxon signed-rank test revealed no significant performance differences at the 0.05 level, but LSTM and SEIRD generally outperformed GWR, with lower mean absolute percentage errors (MAPE: LSTM = 1.51%, SEIRD = 1.70%, GWR = 3.44%).","{""APE"", ""MAPE"" }"," {""SEIRD_APE_China_LateFeb"": 0.10, ""SEIRD_MAPE"": 1.70, ""LSTM_APE_Feb14_Max"": 0.63, ""LSTM_MAPE"": 1.51, ""GWR_R2_Fit"": 0.9998, ""GWR_R2_Prediction"": 0.9795, ""GWR_MAPE"": 3.44, ""Wilcoxon_p_SEIRD_vs_LSTM"": 0.459, ""Wilcoxon_p_GWR_vs_LSTM"": 0.173, ""Wilcoxon_p_GWR_vs_SEIRD"": 0.187}",
68,"Lin JK, Chien TW, Wang LY, Chou W.",2021,"Department of Ophthalmology, Chi-Mei Medical Center, Yong Kang, Tainan City, Taiwan.",An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission: Development and validation study,Medicine (Baltimore),Respiratory Virology,"[""COVID-19""]","Journal Article, Multicenter Study, Validation Study",Develop an artificial neural network (ANN) model and a publicly available web-based application (PMCP app) that can accurately predict the mortality of COVID-19 patients at the time of hospital admission using routine blood test results and demographic variables.,"During the COVID-19 pandemic, healthcare providers urgently needed reliable tools to identify patients at high risk of mortality at the time of hospital admission. However, most existing models either focused on predictions several days into hospitalization or lacked real-time clinical utility. Furthermore, few models leveraged deep learning techniques such as Artificial Neural Networks (ANN) or Convolutional Neural Networks (CNN) to improve predictive accuracy, and even fewer offered accessible, interactive applications for clinical use. Additionally, the impact of using normalized versus raw laboratory data on prediction performance had not been thoroughly explored. These gaps highlighted the need for a robust, accurate, and user-friendly tool that could aid early triage and decision-making in clinical settings.","To develop and evaluate an artificial intelligence-based predictive model primarily using an Artificial Neural Network (ANN) for accurately estimating the in-hospital mortality risk of COVID-19 patients at the time of hospital admission, based on routine blood biomarkers and demographic data, and to implement this model into a publicly accessible app (PMCP) for real-time clinical decision support.","The study developed and evaluated two deep learning models Artificial Neural Network (ANN) and Convolutional Neural Network (CNN) to predict COVID-19 patient mortality risk at hospital admission. Using patient data from Wuhan, China (n = 361) and three Korean medical centers (n = 106), the researchers used 30 features (28 blood biomarkers and 2 demographic variables), with missing values imputed by mean. Both raw and normalized (z-score) data were tested to assess model sensitivity to scaling. The ANN was uniquely implemented using Microsoft Excel with a multi-layer sigmoid-based architecture and Solver optimization, while CNN served as a comparative model. Model performance was evaluated across scenarios (raw vs. normalized data; training vs. testing sets) using AUC, sensitivity, specificity, accuracy, and balanced accuracy. The ANN with normalized data achieved the highest performance (AUC = 0.96 on training data; balanced accuracy = 0.80 on testing data). Further benchmarking was done using Weka software against traditional machine learning models. Ultimately, the ANN model was deployed in a publicly accessible web app named PMCP, offering mortality risk predictions through interactive visualizations on a dashboard integrated with Google Maps.","The ANN model was developed using Microsoft Excel, featuring a multilayer feed-forward neural network architecture with sigmoid activation functions. The model parameters were optimized through Excel’s Solver add-in by minimizing the total residuals (SUMXMY2 function), which made the approach uniquely accessible and transparent. The model was trained on 361 COVID-19 patient records from Wuhan, using 30 input features (28 blood biomarkers and 2 demographic attributes: age and gender). Both raw and normalized data (z-score normalization) were tested to assess the impact of data scaling. The ANN achieved the highest AUC of 0.96 on the training set (normalized data) and balanced accuracy of 0.80 on the external test set (106 Korean patients). The final trained ANN model was integrated into a publicly available online application called PMCP (Predict the Mortality of COVID-19 Patients). This app visualizes the probability of survival or death through a dashboard with categorical probability curves displayed on Google Maps, offering real-time, user-friendly risk assessment for clinicians and the public.",Artificial Neural Network (ANN),"Yes, the PMCP app",No,Clinical mortality risk prediction at hospital admission for patients infected with COVID-19.,"28 Blood Biomarkers, 28 Blood Biomarkers(age, gender)","Wuhan COVID-19 Patient Dataset – Used as the training dataset, Korean COVID-19 Patient Dataset – Used as the external testing dataset
",Yes,"The study evaluated the performance of two deep learning models Artificial Neural Network (ANN) and Convolutional Neural Network (CNN) for predicting the mortality of COVID-19 patients at hospital admission. Performance was assessed using both training and external testing datasets under two scenarios: one with raw laboratory data and another with normalized data (z-score transformed). The primary evaluation method involved comparing predicted outcomes (death or survival) against actual clinical outcomes using standard classification metrics including sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristic curve (AUC). The ANN model demonstrated superior performance when using normalized data, achieving an AUC of 0.96 on the training dataset and a balanced accuracy of 0.80 on the external testing dataset. In comparison, the CNN model yielded a slightly lower AUC of 0.91 during training and a balanced accuracy of 0.73 on the testing dataset. These results indicate that ANN not only outperformed CNN in terms of discrimination power (AUC) but also exhibited more consistent generalization across datasets. This made ANN the preferred model for integration into the developed PMCP mortality prediction app.","{ ""AUC-ROC""}","{""ANN_AUC_Training_Normalized"": 0.96, ""ANN_Balanced_Accuracy_Testing_Normalized"": 0.80}",
,,,,,,,,,,,,,"The CNN model was implemented as a comparative deep learning method alongside ANN. It was trained and tested using the same datasets 361 training patients from Wuhan and 106 external testing patients from Korea. CNN performance was evaluated under both raw and normalized data conditions. The model structure included typical CNN layers, though specific architecture details (e.g., number of layers, kernel size) were not explicitly described. On the normalized data, CNN achieved an AUC of 0.91 on the training set and lower balanced accuracy (0.73) on the testing set compared to ANN. Unlike ANN, the CNN model was not embedded into the final app and was mainly used to benchmark ANN’s performance against another deep learning approach.
",Convolutional Neural Network (CNN),No,No,,Blood sample data,Lin et.al,Yes,"The performance was measured using the Area Under the Receiver Operating Characteristic Curve (AUC) metric, with a validation dataset from 3 Korean medical institutions.","{ ""AUC-ROC""}","{""CNN_AUC_Training_Normalized"": 0.91, ""CNN_Balanced_Accuracy_Testing_Normalized"": 0.73}",
69,"Akil L, Ahmad HA.",2016,"Department of Biology/Environmental Science, Jackson State University, Jackson, Mississippi, USA.",Salmonella infections modelling in Mississippi using neural network and geographical information system (GIS),BMJ Open,Foodborne Virology," [ ""Salmonella"", ""E. coli""]","Comparative Study, Journal Article, Research Support, N.I.H., Extramural, Research Support, U.S. Gov't, Non-P.H.S.","The aim of this research is to determine the extent of Salmonella and Escherichia coli infections in Mississippi (MS) and to assess the correlation between Salmonella infections and socioeconomic status (e.g., poverty, unemployment, education level) using Geographic Information System (GIS) and neural network models.","The research problem addresses the high rates of Salmonella outbreaks in Mississippi, focusing on understanding the correlation between these outbreaks and socioeconomic status, particularly in low socioeconomic status (LSES) regions, using GIS and neural networks.","Analyze and predict the correlation between Salmonella outbreaks and socioeconomic factors using machine learning models, such as neural networks, and advanced data analysis techniques like GIS, to gain insights that can help mitigate the risk of foodborne illnesses in Mississippi.Predicting the correlation of Salmonella using neural networks","The AI methodology in this study involves using machine learning techniques, particularly neural networks, to analyze and predict the correlation between Salmonella outbreaks and socioeconomic factors. This is complemented by Geographic Information System (GIS) mapping to visualize the geographic distribution of outbreaks and socioeconomic variables. The neural network models are trained on historical data from Mississippi, including variables such as poverty, unemployment, and healthcare access.","GRNN is effective in handling non-linear relationships, providing robust predictions even with small or noisy data. The network is trained on historical data, and once trained, it predicts outbreak rates based on input variables.  The dataset used includes Salmonella and E. coli cases from 2002 to 2012, collected from the CDC and state health departments, along with socioeconomic data from Mississippi’s counties. This AI approach helps identify high-risk areas for foodborne illness outbreaks and aids in designing targeted interventions.","General Regression Neural Network (GRNN)



",No,No,"prediction of the epidemiology of foodborne illnesses, specifically Salmonella and E. coli infections",Structured tabular data (likely related to epidemiological or demographic data),CDC and Mississippi Department of Health public health records,Yes,"In this study, the performance of the General Regression Neural Network (GRNN) model was measured using common regression metrics. The model’s ability to predict Salmonella outbreaks in Mississippi based on socioeconomic factors (such as poverty, unemployment, uninsured rates, and primary care providers' rates) was assessed. These metrics were used to evaluate the effectiveness of the GRNN model in predicting the correlation between Salmonella outbreaks and socioeconomic factors, providing insights into how well the model performed in identifying and predicting the outbreaks.","{R², Correlation coefficient (r), Mean squared error (MSE), Mean absolute error (MAE)}","{""R²"" : 0.4169, ""r "": 0.6457, ""MSE"" : 175.87, ""MAE"": 11.54}",
70,"Saegner T, Austys D.",2022,"Department of Public Health, Institute of Health Sciences, Faculty of Medicine, Vilnius University, M. K. ÄŒiurlionio 21/27, LT-03101 Vilnius, Lithuania.",Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review,Int J Environ Res Public Health,Respiratory Virology,"[""COVID-19""]","Journal Article, Review",To review the literature about the possible use of GT(google trends) for COVID-19 surveillance and prediction of its outbreaks.,"The study seeks to explore whether GT can indeed serve as a useful tool for COVID-19 prediction and surveillance, and if so, what methodologies are most effective.","The goal is to determine whether AI methods can effectively use GT data to predict COVID-19 outbreaks in advance, providing a valuable tool for health authorities and governments in managing public health responses.","The methodology employed in the studies reviewed involves analyzing Google Trends (GT) data for COVID-19 prediction and surveillance. Relevant GT search terms related to COVID-19, such as symptoms, prevention measures, and the virus itself, are collected and preprocessed. The studies then evaluate various forecasting approaches, including time-series models and other statistical methods, to assess how well search interest correlates with COVID-19 trends. These methods aim to identify patterns in the data, with the goal of predicting future outbreaks. The findings suggest that GT data, when combined with statistical modeling, can help forecast COVID-19 trends and support surveillance efforts.","These methods aim to assess the relationship between public interest, as measured by search terms, and actual COVID-19 trends. The AI approaches typically involve time-series analysis, where historical data on GT search queries are examined to identify trends and patterns that may correlate with COVID-19 case numbers. These methods can also integrate external data, such as reported cases or deaths, to enhance the predictive power of the models.","{""Time-Series Forecasting"": ""Autoregressive Integrated Moving Average (ARIMA)"", ""Regression"": ""Random Forest Regression"", ""Ensemble Learning"": ""Gradient Boosting Machines (GBM)"", ""Neural Networks"": ""Long Short-Term Memory (LSTM)"", ""Clustering"": ""K-Means Clustering"", ""Classification"": ""Support Vector Machines (SVM)"", ""Deep Learning"": ""Convolutional Neural Networks (CNN)"", ""Vector Models"": ""Vector Error Correction Model (VECM)"", ""Boosting"": ""Adaboost"", ""Bayesian Models"": ""Bayesian Network""}",No,No,COVID-19 surveillance and outbreak prediction using Google trends data,"temporal, geographic, quantitative, textual, and categorical data ",COVID-19 Google Trends Data,No,it does not provide a specific performance measure in terms of numerical values or metrics for all studies,,,
71,"Wang YW, Shen ZZ, Jiang Y.",2019,"School of Public Health, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, China.",Comparison of autoregressive integrated moving average model and generalised regression neural network model for prediction of haemorrhagic fever with renal syndrome in China: a time-series study,BMJ Open,General Virology,['Haemorrhagic Fever with Renal Syndrome (HFRS)'],"Comparative Study, Journal Article","The aim of the study is to develop and compare the predictive performance of three different models ARIMA, GRNN, and a hybrid ARIMA-GRNN for forecasting the monthly incidence of HFRS in China. The goal is to determine the most accurate model for short-term outbreak prediction and public health decision-making.
","To develop an optimal predictive modeling approach for HFRS, particularly in combining linear and non-linear components for more accurate forecasting.",To improve the forecasting accuracy of monthly HFRS incidence in China by applying and evaluating a generalized regression neural network (GRNN) model and a hybrid ARIMA-GRNN model that captures both linear and non-linear patterns in disease time series data.,"The study used a neural network-based time series forecasting approach by implementing a GRNN model to learn non-linear relationships in HFRS incidence data. It also constructed a hybrid model, where linear trends were first modeled using an ARIMA model, and then the residual or fitted values were used as inputs to train the GRNN for capturing the non-linear structure. A revised GRNN model was also developed using stratified monthly data to assess whether spatial stratified heterogeneity improves prediction.","The Generalized Regression Neural Network (GRNN) model was developed to capture non-linear patterns in the monthly HFRS incidence data from January 2011 to December 2017. The model architecture included input, pattern, summation, and output layers. The last two data points were used for testing, while the rest were used for training. A series of smoothing factors were tested, and the optimal smoothing factor of 0.027 was selected based on the lowest RMSE.",Basic GRNN,No,No,forecasting the monthly incidence of Haemorrhagic Fever with Renal Syndrome (HFRS) in China,Monthly counts of reported HFRS (haemorrhagic fever with renal syndrome) cases in mainland China,Wang et.al,Yes,"The GRNN model was trained using monthly HFRS incidence data from January 2011 to December 2017. To evaluate its performance, the last two samples from this period were held out as a test set, and the remaining data were used for training. After determining the optimal smoothing factor, the model was used to forecast values from January to May 2018. The accuracy of these forecasts was measured by comparing them to the actual reported HFRS incidence values using RMSE, MAE, and MAPE.","{""MAPE"" , ""MAE"",  ""RMSE""}","{""MAPE"": 19.2029, ""MAE"": 177.0356, ""RMSE"": 202.1684}",
,,,,,,,,,,,,,"The hybrid model was constructed by first fitting an ARIMA model to capture linear patterns in the HFRS time series, and then using the ARIMA-fitted values as input to the GRNN to learn the non-linear residual patterns. The actual observed values were used as outputs to train the GRNN. The same training/testing split was applied, and the optimal smoothing factor for the hybrid GRNN was 0.043, selected by minimizing RMSE. This model aimed to combine the strengths of both ARIMA and GRNN.",Hybrid (ARIMA + GRNN),,,,,,,"In the hybrid model, an ARIMA model was first fitted to the monthly HFRS incidence data from January 2011 to December 2017 to model the linear trends. The fitted values from the ARIMA model were then used as input to train a GRNN model, with the actual observed values as outputs, allowing the GRNN to learn the non-linear residual patterns. The ARIMA model was used to generate forecasts for January to May 2018, and these were fed into the trained GRNN to obtain the hybrid model's final predictions. These predictions were evaluated against the true incidence values for those months using RMSE, MAE, and MAPE.","{""MAPE"" , ""MAE"",  ""RMSE""}","{""MAPE"": 17.8335, ""MAE"": 152.3013, ""RMSE"": 196.4682}",
,,,,,,,,,,,,,"To address seasonal effects and spatial stratified heterogeneity (SSH), the time series was partitioned into 12 strata one for each month across years. Separate GRNN models were trained on each monthly stratum using 7 data points (e.g., Jan 2011–Jan 2017). Forecasts for January to May 2018 were generated using the corresponding monthly models. This approach allowed for capturing month-specific patterns, improving predictive performance over the basic GRNN.
",Revised GRNN,,,,,,,"To account for seasonal effects and spatial stratified heterogeneity, the original time series was partitioned into twelve separate monthly subsets (e.g., all Januaries from 2011 to 2017 formed one series, all Februaries another, etc.). Each monthly subset was used to train a dedicated GRNN model on just seven data points. The corresponding GRNN models were then used to forecast HFRS incidence for January through May 2018. These month-specific predictions were evaluated against actual values using the same three error metric RMSE, MAE, and MAPE providing insight into whether stratified modeling improved performance.","{""MAPE"" , ""MAE"",  ""RMSE""}","{""MAPE"": 17.6095, ""MAE"": 163.8000, ""RMSE"": 169.4751}",
72,"Frauenfeld L, Nann D, Sulyok Z, Feng YS, Sulyok M.",2020,"Institute for Pathology and Neuropathology, Eberhard Karls University, University Hospital of TÃ¼bingen , TÃ¼bingen 72076, Germany.",Forecasting tuberculosis using diabetes-related google trends data,Pathog Glob Health,General Virology,['Tuberculosis'],"Evaluation Study, Journal Article","To improve tuberculosis (TB) forecasting by extending traditional time series models with online activity-based data, specifically Google Trends data (GTD) related to diabetes.",To address the gap by evaluating whether integrating diabetes-related search volume into TB forecasting models can improve prediction accuracy and provide a viable early warning tool.,The AI objective of the study is to enhance the forecasting accuracy of tuberculosis (TB) incidence by developing and evaluating a GTD-extended time series model that integrates Google Trends data related to diabetes as an external input. ,"The study applied a neural network-based time series forecasting method to predict weekly tuberculosis (TB) incidence. Specifically, it used autoregressive feed-forward neural networks (NNAR) to model TB case numbers based on historical incidence data. To evaluate the added value of online behavioral signals, the models were also extended with Google Trends data (GTD) related to the search term ""diabetes"" as an external regressor. The performance of both traditional and GTD-extended neural network models was assessed through 5-fold cross-validation and in a data-poor simulation scenario using reduced and partially missing training data.","The study used an autoregressive feed-forward neural network (NNAR) model with a single hidden layer consisting of 4 neurons and 5 lagged inputs to forecast weekly tuberculosis (TB) cases in Germany. The model was trained using historical TB incidence data and extended with Google Trends data (GTD) for the search term ""diabetes"" as an external regressor. The GTD-extended NNAR model aimed to capture the syndemic relationship between TB and diabetes. Model performance was evaluated using 5-fold cross-validation, comparing the traditional and GTD-extended versions using RMSE, MAPE, and other error metrics. The method was implemented in R (forecast package) and further tested in a data-poor setting to assess robustness.",Neural Network (NNAR: Autoregressive Feed-Forward Neural Network),https://github.com/msulyok/Google-Trends-Tuberculosis,Standard open-use academic license via GitHub,"predict future TB case numbers using traditional surveillance data, enhanced with online activity-based data (Google Trends) related to diabetes",Google search data and weekly case numbers of TB in Germany,RKI TB Surveillance Dataset,Yes,"The performance of the deep learning model (NNAR) was evaluated using 5-fold cross-validation. This helped assess the generalizability of the model. To test performance in a challenging environment, the study also simulated a data-poor scenario by using only the first 52 weeks of TB data and randomly removing 10 values. The Diebold-Mariano test was used to statistically compare the prediction errors of traditional and GTD-extended NNAR models under these constraints.","[""validation_RMSE"", ""validation_MAPE"", ""cross_val_RMSE_mean"", ""cross_val_RMSE_std"", ""MAE_mean"", ""MAE_std"", ""MPE_mean"", ""MPE_std"", ""MAPE_mean"", ""MAPE_std"", ""Theils_U_mean"", ""Theils_U_std"", ""autocorr_1st_order_mean"", ""autocorr_1st_order_std"", ""diebold_mariano_p""]","nnar_gtd_metrics = {
    ""validation_RMSE"": 10.94,
    ""validation_MAPE"": 8.02,
    ""cross_val_RMSE_mean"": 19.00,
    ""cross_val_RMSE_std"": 3.27,
    ""MAE_mean"": 14.95,
    ""MAE_std"": 1.91,
    ""MPE_mean"": 3.41,
    ""MPE_std"": 8.43,
    ""MAPE_mean"": 19.44,
    ""MAPE_std"": 13.76,
    ""Theils_U_mean"": 1.49,
    ""Theils_U_std"": 0.66,
    ""autocorr_1st_order_mean"": 0.02,
    ""autocorr_1st_order_std"": 0.18,
    ""diebold_mariano_p"": ""< 0.001""
}",
73,"Zhang R, Song H, Chen Q, Wang Y, Wang S, Li Y.",2022,"Chinese Center for Disease Control and Prevention, Beijing, China.",Comparison of ARIMA and LSTM for prediction of hemorrhagic fever at different time scales in China,PLoS One,General Virology,['Hemorrhagic Fever'],"Comparative Study, Journal Article","The aim of this study is to build and compare two forecasting models (ARIMA and LSTM) for predicting the incidence of hemorrhagic fever in China across three different time scales monthly, weekly, and daily.","While ARIMA is a well-established method in infectious disease forecasting, and LSTM is gaining attention due to its ability to model non-linear relationships, there is a lack of comparative research on how these two models perform across different time scales (monthly, weekly, daily) specifically for hemorrhagic fever.","To determine whether deep learning methods like LSTM offer any advantages over traditional statistical models like ARIMA in terms of accuracy, adaptability, and robustness, especially when dealing with non-linear and high-frequency epidemiological data. ","The study employed a comparative forecasting methodology involving both traditional statistical modeling (ARIMA) and artificial intelligence-based modeling (LSTM) to predict hemorrhagic fever incidence in China across three time scales: monthly, weekly, and daily. For the ARIMA models, the time series data were first tested for stationarity using the Augmented Dickey-Fuller (ADF) test, and appropriate differencing was applied. Model parameters were estimated through autocorrelation (ACF), partial autocorrelation (PACF) plots, and automated selection using the auto.arima() function in R, with final model selection based on residual diagnostics and the Akaike Information Criterion (AIC). In parallel, LSTM neural networks were built by normalizing the data, defining time windows (7, 30, or 60 previous time points), and testing various configurations of hidden neurons, optimizers (SGD, Adam, RMSProp), and training epochs. Both ARIMA and LSTM models were evaluated using direct forecasting and rolling forecasting origin (walk-forward validation) approaches to simulate real-world prediction.","The LSTM modeling process in the study involved several key steps tailored for time series forecasting. First, the hemorrhagic fever incidence data were normalized to a range between 0 and 1 to ensure stable training, as LSTM models are sensitive to input scales. The data were then transformed into supervised learning format using time windows of 7, 30, or 60 previous time steps to predict the next value for daily, weekly, and monthly forecasts respectively. A single-layer LSTM network was constructed with varying numbers of hidden neurons (4, 8, 16, 32, 64, 72, 128, and 256) and trained using different optimizers including SGD, Adam, and RMSProp. The training was performed over 200 to 1000 epochs, with an initial learning rate of 0.005, which was reduced every 125 epochs by a factor of 0.2 to enhance convergence. The optimal LSTM configuration for each time scale was selected based on the lowest root mean square error (RMSE) on the validation set. ",['Neural Network (LSTM)'],No,No,epidemiological forecasting of hemorrhagic fever incidence,Time series data and demographic information,Public Health Science Data Center – daily national incidence data of hemorrhagic fever in China from January 2013 to December 2019,Yes,"The study measured the forecasting performance of the models specifically, how accurately ARIMA and LSTM predicted the future number of hemorrhagic fever cases for the year 2019, using models trained on data from 2013–2018. Performance was measured by comparing predicted case counts to actual values using three metrics: Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). These metrics assessed the accuracy of the forecasts, with lower values indicating better performance. Both direct and rolling forecasting methods were evaluated to simulate real-world prediction scenarios. In the daily rolling forecasting scenario, LSTM significantly outperformed ARIMA","{""MAPE"" , ""MAE"",  ""RMSE""}","lstm_metrics = {
    ""monthly_direct"": {""RMSE"": 354.95, ""MAE"": 284.92, ""MAPE"": 43.17},
    ""monthly_rolling"": {""RMSE"": 247.53, ""MAE"": 224.42, ""MAPE"": 34.20},
    ""weekly_direct"": {""RMSE"": 54.18, ""MAE"": 44.10, ""MAPE"": 33.21},
    ""weekly_rolling"": {""RMSE"": 35.98, ""MAE"": 26.21, ""MAPE"": 17.81},
    ""daily_direct"": {""RMSE"": 13.23, ""MAE"": 10.27, ""MAPE"": 61.20},
    ""daily_rolling"": {""RMSE"": 8.05, ""MAE"": 5.75, ""MAPE"": 35.70}
}",
74,"Tapak L, Hamidi O, Fathian M, Karami M.",2019,"Department of Biostatistics, School of Public Health, Modeling of Noncommunicable Diseases Research Center, Hamadan University of Medical Sciences, Hamadan, Iran.",Comparative evaluation of time series models for predicting influenza outbreaks: application of influenza-like illness data from sentinel sites of healthcare centers in Iran,BMC Res Notes,Respiratory Virology,"[""Influenza""]","Comparative Study, Journal Article","To evaluate and compare the prediction accuracy of Support Vector Machine (SVM), Artificial Neural Network (ANN), and Random Forest (RF) models in forecasting Influenza-Like Illness (ILI) frequencies and detecting outbreaks in Iran. ",Early detection of ILI outbreaks is essential for effective public health intervention. There is limited research comparing ANN with other machine learning models for this purpose in Iran.,To use machine learning models for accurate forecasting of weekly ILI case counts and timely detection of outbreaks to support public health decision-making.,"Time series modeling using SVM, ANN, and RF. Models were trained on 80% of the weekly ILI data (2010–2016) and tested on the remaining 20% (2016–2018). Preprocessing included scaling and feature engineering using previous 52 weeks of data as input. Model performance was evaluated using regression (RMSE, MAE, ICC) and classification metrics (sensitivity, specificity, PPV, NPV, total accuracy).","The artificial neural network (ANN) model used in this study was based on a multilayer perceptron (MLP) architecture designed for time series forecasting of weekly influenza-like illness (ILI) cases. The input consisted of 52 historical weekly observations, and different configurations of hidden layers (1 to 3) were tested to optimize performance. Hyperbolic tangent and identity functions were used as activation functions in the hidden and output layers, respectively. The ANN was trained on 80% of the data and evaluated on the remaining 20%. It showed strong performance in both prediction and classification tasks.",['Machine Learning – Neural Network (ANN/MLP)'],No,No,forecasting weekly influenza-like illness (ILI) frequencies and detecting ILI outbreaks in Iran between 2010 and 2018,Weekly case counts of ILI ,dataset obtained from WHO FluNet web-based tool ,Yes,"The performance of the artificial neural network (ANN) model was evaluated using both regression and classification metrics to assess its ability to forecast weekly influenza-like illness (ILI) frequencies and detect outbreaks. For forecasting, the ANN’s prediction accuracy was assessed using Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Intra-class Correlation Coefficient (ICC). These evaluations were carried out using R statistical software with built-in packages.","[""RMSE"", ""MAE"", ""ICC"", ""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""Total Accuracy""]","{""RMSE"": 26.58, ""MAE"": 13.21, ""ICC"": 0.82, ""Sensitivity"": 86.2, ""Specificity"": 90.4, ""PPV"": 83.3, ""NPV"": 92.2, ""Total Accuracy"": 88.9}",
75,"Mello-RomÃ¡n JD, Mello-RomÃ¡n JC, GÃ³mez-Guerrero S, GarcÃ­a-Torres M.",2019,"Universidad Nacional de ConcepciÃ³n, ConcepciÃ³n 8700, Paraguay.",Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay,Comput Math Methods Med,General Virology,['Dengue virus infection'],"Comparative Study, Journal Article",To compare the performance of artificial neural networks (ANN) and support vector machines (SVM) in predicting dengue diagnosis using patient data,Diagnosing dengue virus infection from clinical data using machine learning algorithms.,To develop and evaluate machine learning models that can accurately assist in the diagnosis of dengue based on clinical and epidemiological data.,"The study used supervised learning techniques (ANN and SVM) on a real-world dataset from Paraguay. Data preprocessing involved handling missing values, followed by model training and evaluation using random dataset partitions and performance metrics.","The artificial neural network (ANN) used in this study is a supervised learning model .Specifically, a multilayer perceptron (MLP) architecture was use d, consisting of an input layer, one or more hidden layers, and an output layer. The model was trained using the backpropagation algorithm to classify dengue cases based on clinical features",['Artificial Neural Network (Multilayer Perceptron - ANN-MLP)'],No,No,early diagnosis of dengue infection,Clinical and demographic data,Mello-Román et.al,Yes,"The performance of the ANN and SVM classifiers was measured on 30 test datasets, using accuracy, sensitivity, and specificity as evaluation criteria.","{'accuracy', 'sensitivity', 'specificity'}","{'accuracy': 96, 'sensitivity': 96, 'specificity': 97}",
76,"Dong Y, Wang K, Zou X, Tan X, Zang Y, Li X, Ren X, Xie D, Jie Z, Chen X, Zeng Y, Shi J.",2022,"Department of Pulmonary and Critical Care Medicine, Shanghai Fifth People's Hospital, Fudan University, 801 Heqing Road, Minhang District, Shanghai, 200240, China; Lingang Laboratory, Shanghai, 200031, China.","Evaluating the ability of the NLHA2 and artificial neural network models to predict COVID-19 severity, and comparing them with the four existing scoring systems",Microb Pathog,Respiratory Virology,"[""COVID-19 Pneumonia ""]","Journal Article, Multicenter Study","To develop and evaluate machine learning models, including a deep learning-based artificial neural network (ANN), to predict ICU admission risk in COVID-19 pneumonia patients and compare their performance with existing clinical scoring systems.","Existing pneumonia severity scoring systems (e.g., PSI, CURB-65, SMARTCOP, MuLBSTA) are limited or inconsistent in predicting COVID-19 severity and ICU admission. There is a need for improved models tailored to COVID-19.",To create more accurate and clinically practical AI models  particularly a logistic regression model (NLHA2) and a deep learning model (ANN) that can identify high-risk COVID-19 patients needing ICU care.,"The study employed a supervised learning framework by splitting clinical data of COVID-19 patients into training and testing sets. Logistic regression and a deep learning-based artificial neural network (ANN) were used to build severity prediction models. The models were trained on selected clinical and laboratory features, and evaluated using metrics like AUC, sensitivity, specificity, Hosmer-Lemeshow test, and Brier score.","The ANN model was implemented as a multi-layer perceptron (MLP) with two hidden layers consisting of 10 and 8 nodes. A total of 42 clinical features were used as input. The model was built using the RSNNS package in R, and variable importance was assessed using Olden’s connection-weighted algorithm.",Artificial Neural Network (deep learning – Multi-layer Perceptron),No,No,"predicting the severity of COVID-19 pneumonia, specifically to identify patients at risk of requiring ICU admission using clinical and laboratory data.",Medical images and structured tabular data,Dong et.al,Yes,"The model was evaluated for its ability to predict ICU admission among COVID-19 pneumonia patients using a binary classification task. The model showed high sensitivity (95.89%) and specificity (88.46%) on the test data. Calibration was assessed using the Hosmer-Lemeshow test (P = 1.000) and the Brier score, which was 0.000 for training and 0.071 for testing, indicating strong model fit and predictive accuracy.","[""AUC"", ""Sensitivity"", ""Specificity"", ""Brier Score"", ""Hosmer-Lemeshow P""]","{""AUC (Training)"": 1.000, ""AUC (Testing)"": 0.907, ""Sensitivity (Testing)"": 95.89, ""Specificity (Testing)"": 88.46, ""Brier Score (Testing)"": 0.071, ""Hosmer-Lemeshow P"": 1.000}",
77,"Zhu H, Chen S, Qin W, Aynur J, Chen Y, Wang X, Chen K, Xie Z, Li L, Liu Y, Chen G, Ou J, Zheng K.",2024,"Fujian Provincial Center for Disease Control and Prevention, Fuzhou, Fujian, 350012, China. hszhu33@126.com.",Study on the impact of meteorological factors on influenza in different periods and prediction based on artificial intelligence RF-Bi-LSTM algorithm: to compare the COVID-19 period with the non-COVID-19 period,BMC Infect Dis,Respiratory Virology,['Influenza'],"Journal Article, Comparative Study",To examine how meteorological factors influence influenza during different periods (before and during COVID-19) and evaluate the predictive performance of an RF-BiLSTM model across those periods.,There is no existing evidence on whether the accuracy or association between meteorological factors and influenza changes across different intervention periods like during COVID-19.,To develop a hybrid deep learning model (RF-BiLSTM) that accurately predicts influenza incidence using meteorological and environmental factors.,A hybrid modeling approach combining Random Forest (RF) for feature selection and Bidirectional Long Short-Term Memory (Bi-LSTM) for time-series prediction. The model uses multi-step rolling forecasting with 7-day input and output windows.,"The study used a hybrid AI method combining Random Forest (RF) and Bidirectional Long Short-Term Memory (Bi-LSTM). RF was applied for feature selection by ranking the importance of meteorological and environmental variables and eliminating redundancy. The selected features were then input into a Bi-LSTM model, which learned temporal patterns in both forward and backward directions. The model used a 7-day input window to predict the average daily influenza cases for the next 7 days through a multi-step rolling forecast approach. Separate models were trained for different time phases (pre-COVID, COVID, and overall), and performance was evaluated using ten statistical metrics.",Random Forest + Bidirectional LSTM (RF-BiLSTM) hybrid model,No,No,"Predicting influenza incidence and analyzing how meteorological and environmental factors influence influenza spread during different phases (pre-COVID, during COVID, overall)","Tabular data (Influenza Case Data, vaccination records, demographic information, environmental data)","Influenza surveillance and meteorological data from Xiamen, China (2010–2022)",Yes,"Performance was measured using ten evaluation metrics to assess the accuracy of influenza predictions. These included root mean square error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), symmetric MAPE (SMAPE), RSR, correlation coefficient (CC), Nash-Sutcliffe efficiency (NSE), Kling-Gupta efficiency (KGE), index of agreement (IA), and Legate and McCabe’s index (LMI). These metrics evaluated both the magnitude and consistency of prediction errors and were applied across different phases to test how accurately the RF-Bi-LSTM model predicted 7-day average daily influenza cases.","[""RMSE"", ""MAE"", ""MAPE"", ""SMAPE"", ""RSR"", ""CC"", ""NSE"", ""KGE"", ""IA"", ""LMI""]","{""RMSE"": 1.05, ""MAE"": 0.59, ""MAPE"": 0.08, ""SMAPE"": 0.12, ""RSR"": 0.12, ""CC"": 0.99, ""NSE"": 0.98, ""KGE"": 0.95, ""IA"": 0.99, ""LMI"": 0.88}",
78,"Madden WG, Jin W, Lopman B, Zufle A, Dalziel B, E Metcalf CJ, Grenfell BT, Lau MSY.",2024,"Department of Biostatistics and Bioinformatics, Rollins School of Public Health, Emory University, Atlanta, Georgia, United States of America.",Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models,PLoS Comput Biol,Respiratory Virology,['Measles'],"Journal Article, Comparative Study","To develop and evaluate deep learning models, particularly spatial-feature neural networks (SFNN) and physics-informed neural networks (PINN), for forecasting endemic measles outbreaks, and to explore how these models can enhance both predictive accuracy and mechanistic understanding of disease dynamics."," There is a need for models that combine high predictive performance with interpretability , fully capture the complex, nonlinear, and spatially structured transmission dynamics of measles, especially in less populous regions or for long-term forecasts.",Feed-forward neural network with spatial and temporal feature engineering.,"To build and assess deep learning models that can accurately forecast measles outbreaks across different cities and time horizons, while also uncovering underlying spatial transmission patterns and supporting mechanistic interpretability.","A high-dimensional feedforward neural network incorporating both spatial and temporal features (SFNN) to forecast endemic measles outbreaks across 1,452 towns in England and Wales from 1944 to 1965. The SFNN consistently outperformed the traditional mechanistic Time-Series Susceptible-Infectious-Recovered (TSIR) model across both short- and long-term forecasting windows, particularly excelling in smaller towns where traditional models struggled. Additionally, explainability analysis using SHapley Additive exPlanations (SHAP) values revealed that the SFNN could uncover the underlying spatial hierarchy in disease spread, where large cities play a central role in driving regional outbreaks.",Spatial-Feature Feedforward Neural Network (SFNN),https://github.com/WyattGMadden/deep_measles_dynamics,No,predicting the spatiotemporal spread of measles across different towns and cities over time,Time series data consisting of biweekly measles incidence counts,England and Wales measles dataset,Yes,"The SFNN model’s performance was evaluated using Root Mean Squared Error (RMSE) of the log-transformed incidence (log(incidence + 1)). RMSE values were standardized within each city to allow fair comparison across locations with varying incidence levels. The model was tested across multiple forecasting windows, ranging from 1 to 52 biweeks ahead. Performance was benchmarked against the traditional TSIR (Time-Series Susceptible-Infected-Recovered) model, with comparative analysis highlighting that SFNN performed significantly better in less populous towns and for longer-term forecasts, whereas performance converged with TSIR in large cities during short-term forecasts.",{'RMSE'},{'RMSE': Outperformed TSIR model in most towns},
,,,,,,,,,,,,,"The researchers also implemented a Physics-Informed Neural Network (PINN), enhanced with latent susceptible dynamics reconstructed from the TSIR model, referred to as TSIR-PINN. This integrative model jointly learned disease dynamics while being constrained by SIR equations, enabling both accurate forecasting and mechanistic inference. Compared to a baseline version (Naive-PINN), the TSIR-PINN showed improved performance in forecasting measles incidence and estimating transmission parameters such as R?, thereby demonstrating the benefit of integrating mechanistic knowledge into neural network training.","Hybrid model (Mechanistic-ML integration), physics-informed neural network (PINN)",,,,,,Yes,"The PINN framework was assessed using Mean Absolute Error (MAE) and correlation between predicted and actual measles incidence, focusing on London for a 52-biweek forecast horizon. Two models were compared: Naive-PINN (no mechanistic augmentation) and TSIR-PINN (augmented with TSIR-reconstructed latent susceptible dynamics).","{""test_MAE"", ""test_correlation"", ""R0_estimate""}","{""test_MAE"": 379.60, ""test_correlation"": 0.88, ""R0_estimate"": 26.8}",
79,"Martin-Moreno JM, Alegre-Martinez A, Martin-Gorgojo V, Alfonso-Sanchez JL, Torres F, Pallares-Carratala V.",2022,"Department of Preventive Medicine and Public Health, Universitat de Valencia, 46010 Valencia, Spain.",Predictive Models for Forecasting Public Health Scenarios: Practical Experiences Applied during the First Wave of the COVID-19 Pandemic,Int J Environ Res Public Health,Respiratory Virology,['COVID-19'],"Journal Article, Systematic Review","To systematically review and categorize the various predictive and explanatory models applied during the first wave of the COVID-19 pandemic (March–June 2020), with the goal of understanding their assumptions, capabilities, and limitations in forecasting disease spread, and to provide insights for improving model applicability in future pandemic scenarios.","Traditional statistical models struggled with capturing the complex temporal dependencies in COVID-19 spread; hence, there was a need for more flexible data-driven approaches.","The paper aims to review and characterize deep learning approaches—alongside other predictive models—that were applied during the first wave of the COVID-19 pandemic (March–June 2020) to forecast epidemic trends. It seeks to evaluate the potential of DL models in anticipating public health needs during emerging infectious disease outbreaks.
","The authors conducted a systematic literature review of studies that implemented various modeling approaches for COVID-19 prediction. This included deep learning models like Long Short-Term Memory (LSTM) networks. The methodology involved collecting and analyzing published works using standard database searches and PRISMA-based selection criteria, focusing on DL models' performance, use cases, and forecast accuracy during the first wave.","LSTM's ability to handle long-range temporal dependencies makes it especially suitable for epidemic forecasting, where future values depend heavily on past case trends. In one highlighted application, an LSTM model used early COVID-19 data in Canada to forecast case trajectories and accurately predicted the end of the first wave by June 2020—though it failed to foresee the pandemic's continuation. ","['Supervised learning, deep learning (LSTM - recurrent neural network)']",No,No,Short-term forecasting of COVID-19 case numbers during the first wave (March–June 2020).,COVID-19 daily case time-series data,Martin-Moreno et.al,Yes,the paper summarized evaluation metrics reported by the original studies. There was no single unified evaluation performed by the authors.,"While exact numeric metrics like RMSE or MAE were not reported, LSTM outperformed traditional models (e.g., ARIMA, NARNN) in predicting short-term COVID-19 trends during the first wave, particularly in Canada",,
80,"Cho Y, Lee HK, Kim J, Yoo KB, Choi J, Lee Y, Choi M.",2024,"College of Nursing, Yonsei University, Seoul, Republic of Korea.",Prediction of hospital-acquired influenza using machine learning algorithms: a comparative study,BMC Infect Dis,Respiratory Virology,Influenza,"Journal Article, Comparative Study, Observational Study, Research Support, Non-U.S. Gov't",The study aims to develop and compare machine learning models to accurately predict the occurrence of hospital-acquired influenza (HAI) using electronic medical record (EMR) data. It seeks to identify key predictive factors and determine the best-performing algorithm for early HAI detection.,"Developing predictive models using electronic medical records can empower clinicians with timely insights enabling earlier detection, targeted interventions, and better prevention of HAI spread within hospital settings.",develop and evaluate machine learning models that can accurately predict hospital-acquired influenza (HAI) using structured patient data from electronic medical records (EMRs). The goal was to support early detection and timely intervention to limit transmission within hospital settings.,"The study trained machine learning models (Logistic Regression, Random Forest, XGBoost, and ANN) to predict hospital-acquired influenza using patient data from electronic medical records. Since HAI cases were very rare, the dataset was imbalanced so SMOTE (Synthetic Minority Oversampling Technique) was used to generate artificial examples of HAI cases and balance the data. To understand which features influenced the predictions, the study used SHAP (SHapley Additive exPlanations), a method that explains how much each feature like room type or lab results contributed to the final prediction. Models were trained on 80% of the data and tested on the remaining 20%.","The Artificial Neural Network (ANN) used in this study was developed to classify patients based on whether they were likely to have hospital-acquired influenza (HAI). It was trained on selected features such as vital signs, lab results, and room information. The ANN architecture included two hidden layers with 50 and 100 neurons, using ReLU (Rectified Linear Unit) as the activation function. The model was optimized using the Adam optimizer with a learning rate of 0.005. The ANN was trained using five-fold grid search cross-validation to fine-tune hyperparameters. It showed strong predictive ability and was evaluated using metrics like AUC, sensitivity, and false negatives.",Artificial Neural Network (ANN),No,No,Early detection and prediction of hospital-acquired influenza (HAI),"EMR i.e, Electronic medical records (e.g., patient demographics, medical history, laboratory results)","Electronic Medical Records (EMR) from Yonsei University Health System, a tertiary teaching hospital in Seoul, South Korea.",Yes,"The performance of the predictive models (including the ANN) was evaluated using a test set (20% of the data) that was not used during training. The study focused on classification metrics relevant to clinical decision-making. Among the four models tested, the ANN showed lower performance compared to Logistic Regression and Random Forest, with the lowest F1 Score and highest false negative count (except for XGB), indicating relatively weaker predictive capability for hospital-acquired influenza in this study.","{""AUC"", ""Sensitivity"", ""Specificity"", ""Accuracy"", ""F1 Score"", ""TP"", ""TN"", ""FP"", ""FN""}","{""AUC"": 75.2, ""Sensitivity"": 0.64, ""Specificity"": 0.70, ""Accuracy"": 70.0, ""F1 Score"": 0.6, ""TP"": 14, ""TN"": 10320, ""FP"": 4430, ""FN"": 8}",
81,"Wu W, Guo J, An S, Guan P, Ren Y, Xia L, Zhou B.",2015,"Department of Epidemiology, School of Public Health, China Medical University, Shenyang, PR China.","Comparison of Two Hybrid Models for Forecasting the Incidence of Hemorrhagic Fever with Renal Syndrome in Jiangsu Province, China",PLoS One,General Virology,['Hantavirus Pulmonary Syndrome (HPS)'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","To develop and evaluate hybrid time-series models combining ARIMA with neural networks (NARNN and GRNN) to improve the accuracy of forecasting Hemorrhagic Fever with Renal Syndrome (HFRS) incidence in Jiangsu Province, China.
",To develop more accurate forecasting models that can handle both linear and nonlinear components to improve epidemic prediction and support disease prevention and control efforts.,"To enhance the forecasting accuracy of HFRS incidence by integrating neural network-based AI methods (NARNN and GRNN) with traditional ARIMA models, capturing both linear and nonlinear time-series components.","The study adopts a hybrid AI methodology by integrating traditional statistical modeling with neural network-based approaches to improve the prediction of HFRS incidence. Specifically, two hybrid models are constructed: ARIMA-NARNN and ARIMA-GRNN. In both cases, the ARIMA model is first used to capture the linear patterns in the time-series data. The residuals from the ARIMA model, which are expected to contain nonlinear components, are then modeled using neural networks. The ARIMA-NARNN hybrid combines ARIMA with a Nonlinear Autoregressive Neural Network, which is a dynamic recurrent model capable of learning temporal dependencies. The ARIMA-GRNN hybrid pairs ARIMA with a Generalized Regression Neural Network, a static network that uses both the ARIMA outputs and time indices as inputs.","After fitting the ARIMA model to the monthly HFRS incidence data, the residuals—representing nonlinear components not captured by ARIMA—were modeled using NARNN. This dynamic neural network, which has memory through feedback loops, was configured with 35 hidden neurons and 6 delays. The network was trained using the Levenberg-Marquardt algorithm in an open-loop architecture, with 90% of the data for training, and 5% each for validation and testing. Once trained, the NARNN adjusted the ARIMA predictions, yielding final outputs that captured both linear and nonlinear patterns. This hybrid model demonstrated superior accuracy in both the modeling and forecasting stages.",ARIMA-NARNN Hybrid Model,No,No,predicting future incidence of a rodent-borne viral disease (HFRS) using time-series forecasting models,univariate time series data representing the monthly incidence rates of HFRS.,"HFRS Incidence Data from Jiangsu Province, China",Yes,"The performance was measured using Mean Squared Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) metrics on the Jiangsu Province HFRS incidence dataset. These metrics were used to evaluate how well each model fit historical data (modeling) and how accurately it predicted future values (forecasting).","{'Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Mean Absolute Percentage Error (MAPE)'}","{""MSE"": 0.00009401, ""MAE"": 0.0074, ""MAPE"": 0.3566}",
,,,,,,,,,,,,,"ARIMA-generated forecasts and corresponding time indices were used as inputs to the GRNN, while the actual HFRS incidence values served as the targets. To optimize performance, the GRNN's spread factor—a key parameter controlling the smoothness of the function approximation—was tuned by trial and error using randomly selected testing samples. The best performance was achieved with a spread of 0.0265. Although this hybrid model outperformed the standalone ARIMA in several metrics, it was slightly less effective than the ARIMA-NARNN model, particularly in forecasting mean absolute percentage error (MAPE).",ARIMA-GRNN Hybrid Model,,,,univariate time series data representing the monthly incidence rates of HFRS.,"HFRS Incidence Data from Jiangsu Province, China",,,"{'Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Mean Absolute Percentage Error (MAPE)'}","{""MSE"": 0.00009746, ""MAE"": 0.0078, ""MAPE"": 0.4899}",
82,"Zheng Y, Zhang L, Zhu X, Guo G.",2020,"College of Medical Engineering and Technology, Xinjiang Medical University, Urumqi, People's Republic of China.","A comparative study of two methods to predict the incidence of hepatitis B in Guangxi, China",PLoS One,General Virology,['Hepatitis B'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","To compare the performance of two predictive models ARIMA and Elman Neural Network (ElmanNN) in forecasting the incidence of hepatitis B (HB) in Guangxi, China, and to assess their feasibility and accuracy for early warning and prevention planning.",To create an accurate predictive tools for early warning of Hepatitis B to plan preventive and resource allocation strategies.,"To apply and evaluate the performance of a deep learning-based model (Elman Neural Network) for predicting hepatitis B incidence, and to compare its accuracy with a traditional statistical model (ARIMA) to support public health decision-making.",The study uses a comparative modeling approach. Historical incidence data (2012–2019) is split into training and test sets. Two models — ARIMA and Elman Neural Network — are trained and tested on the same dataset. Model performance is evaluated using RMSE and MAE for both fitting and prediction phases,"The Elman Neural Network (ElmanNN), a type of recurrent neural network (RNN), was employed for time-series prediction of hepatitis B incidence in Guangxi, China. The ElmanNN is well-suited for dynamic forecasting tasks due to its feedback connections, which enable the model to retain information from previous time steps, thereby capturing temporal patterns more effectively. The input to the model consisted of 12 time-lagged variables representing monthly HB incidence, and the network was trained to perform one-step-ahead predictions. Using a systematic search, the optimal model configuration was determined to have 8 neurons in the hidden layer, with training conducted in MATLAB. Performance was evaluated using root mean square error (RMSE) and mean absolute error (MAE), and the ElmanNN demonstrated superior predictive accuracy compared to the traditional ARIMA model, highlighting its effectiveness in modeling infectious disease trends.",[Elman Neural Network (ElmanNN)],No,No,forecasting the incidence of hepatitis B to support early warning and preventive planning,"univariate time-series data representing the monthly incidence rates of hepatitis B in Guangxi, China, spanning from January 2012 to August 2019","Hepatitis B incidence and population data of Guangxi, China (2012–2019)",Yes,"Performance in the study was measured by evaluating how accurately the models could fit and forecast hepatitis B incidence. The performance was measured using RMSE and MAE metrics on the HB incidence data in Guangxi, China.","{""RMSE"", ""MAE""}","{""RMSE"": 0.89, ""MAE"": 0.70}",
83,"Abdulkareem M, Petersen SE.",2021,"Barts Heart Centre, Barts Health National Health Service (NHS) Trust, London, United Kingdom.","The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype",Front Artif Intell,Respiratory Virology,['COVID-19'],"Journal Article, Review","The aim of the study is to investigate and review the application of artificial intelligence (AI) techniques in the management of the COVID-19 pandemic, specifically focusing on their roles in detection, diagnosis, epidemiological prediction, forecasting, and social control. ","Although AI holds significant promise for improving COVID-19 detection, diagnosis, and management, its practical deployment has been limited by data access issues, lack of external validation, insufficient regulatory awareness, weak collaboration between AI and healthcare experts, and public concerns over privacy and data security.","The objective is to explore how artificial intelligence (AI) techniques can support the detection, diagnosis, epidemiological prediction, forecasting, and social control of COVID-19, highlighting both successful applications and identifying the challenges that need to be overcome for broader clinical deployment.","The study adopts a systematic literature review methodology to investigate how AI techniques have been applied to combat COVID-19, focusing primarily on deep learning (DL) and machine learning (ML) approaches. It reviews the use of convolutional neural networks (CNNs), U-Net and ResNet architectures for diagnosing COVID-19 through chest CT and X-ray imaging, and examines LSTM models, k-means clustering, and ANFIS for outbreak forecasting. It also analyzes non-imaging diagnostics using random forests and GANs for respiratory sound analysis. Special attention is given to data challenges, including limited datasets, imbalance, and the need for external validation, and discusses techniques like data augmentation, transfer learning, and federated learning to address these issues. The methodology stresses interdisciplinary collaboration with clinicians and highlights regulatory, ethical, and public trust concerns crucial for the practical deployment of AI tools. No new model is developed; rather, the study evaluates existing models based on standard performance metrics like AUC, accuracy, sensitivity, specificity, precision, recall, and F1-score.","CNN-based models were used extensively for COVID-19 detection tasks. Standard CNNs extract spatial features from CT and X-ray images. ResNet, a residual learning variant of CNN, improved deeper network training by using shortcut connections. CNN-Inception models used multi-scale feature extraction through inception modules. 3D CNNs operated on full CT volumes instead of 2D slices, capturing 3D structural information. U-Net, a segmentation-focused CNN, was applied for lung and lesion localization before classification.","Convolutional Neural Networks (CNN family, including CNN, ResNet, Inception-CNN, and 3D CNN)",No,No,"COVID-19 detection, diagnosis, and severity assessment from chest CT and X-ray images.",Chest CT scans (both full-volume and slices) and chest X-ray images; segmented lung and infected regions.,"COVID-CT dataset, Cohen's COVID-Xray dataset, internal multicenter datasets from Chinese hospitals (7,917 subjects), Zhejiang Hospitals CT dataset.",Yes,"Image segmentation quality was measured using Dice Similarity Coefficient (DSC). Classification performance measured using ROC curves, confusion matrices, accuracy, precision, recall, and F1 scores.","{'AUC', 'Sensitivity', 'Specificity', 'Dice', 'Accuracy_CT', 'F1_COVID19', 'F1_IAVP', 'F1_Healthy', 'Accuracy_Xray', 'Precision_Xray', 'Recall_Xray'}","{'AUC': 0.9717, 'Sensitivity': 0.9019, 'Specificity': 0.9576, 'Dice': 0.933, 'Accuracy_CT': 0.867, 'F1_COVID19': 0.839, 'F1_IAVP': 0.847, 'F1_Healthy': 0.915, 'Accuracy_Xray': 0.961, 'Precision_Xray': 0.957, 'Recall_Xray': 0.950}",
,,,,,,,,,,,,"Purpose: LSTM was used primarily for time series forecasting of COVID-19 outbreak progression, such as predicting the number of confirmed cases over future days.
Reason for use: LSTMs are a type of Recurrent Neural Network (RNN) specifically designed to model long-range temporal dependencies in sequential data, making them highly effective for epidemic curve predictions where historical case numbers influence future trends.
Application: Some studies used LSTM alone, while others used it alongside CNNs or as part of hybrid models to predict short-term and long-term COVID-19 spread patterns.",LSTM,No,No,COVID-19 outbreak forecasting from epidemiological data,Daily new COVID-19 case numbers (time series data),WHO reported COVID-19 case statistics,Yes,"The LSTM models were applied for short-term and mid-term forecasting of COVID-19 confirmed case numbers, aiming to predict 1-day, 3-days, and 6-days ahead values. Performance evaluation was conducted by comparing the LSTM predictions against actual observed data using standard regression metrics. The primary metrics used were Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), and sometimes R-squared (R²). These metrics provided a comprehensive view of both absolute and relative prediction accuracy. The models demonstrated high accuracy for short-term forecasting, with reported error rates generally below 5% for 1- to 3-day ahead predictions. However, prediction accuracy tended to decrease over longer time horizons due to the inherent volatility of outbreak dynamics. It is important to note that no standardized benchmark dataset was used, which limits direct comparisons across studies.","the metrics were mainly reported qualitatively, not with exact numerical values in all cases.",,,
,,,,,,,,,,,,"Purpose: GANs were proposed for speech and sound analysis — specifically recognizing COVID-19-related audio cues like coughing, sneezing, or breathing irregularities.
Reason for use: GANs can augment limited datasets by generating synthetic audio samples resembling real cough or breathing sounds, helping train better classifiers with small available datasets.
Application: Mainly experimental — they were surveyed as promising methods to boost diagnostic tools using non-invasive sound-based approaches.",GANs (Generative Adversarial Networks),No,No,Cough and respiratory sound analysis for COVID-19 prediction (non-imaging),"Sound recordings (speech, coughs, breathing sounds)",,No,No,No,,,
84,"da Silva Neto SR, Tabosa Oliveira T, Teixeira IV, Aguiar de Oliveira SB, Souza Sampaio V, Lynn T, Endo PT.",2022,"Universidade de Pernambuco, Recife, Brazil.",Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review,PLoS Negl Trop Dis,General Virology,"['arboviral diseases(Dengue, Chikunguniya, Zika)']","Journal Article, Research Support, Non-U.S. Gov't, Systematic Review","The aim of the paper is to systematically review and present the state-of-the-art Machine Learning (ML) and Deep Learning (DL) methods developed for the automatic classification of arboviral diseases (Dengue, Chikungunya, and Zika), in order to support clinical diagnosis especially in low-resource settings where traditional diagnostic approaches are challenging.","The lack of standardization and variability in diagnostic approaches for viral diseases, leading to inaccurate diagnoses and ineffective treatments. The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment.","The AI objective of this study was to systematically review and analyze how Machine Learning (ML) and Deep Learning (DL) techniques have been applied for the automatic classification of arboviral diseases such as Dengue, Chikungunya, and Zika, based on clinical and laboratory data. The goal was to assess the ability of existing AI models to support faster, cheaper, and more accurate diagnosis in resource-limited healthcare settings without developing a new model.","The AI methodology involved conducting a Systematic Literature Review (SLR) using a structured three-phase process: planning, execution, and reporting. Google Scholar was searched with a specific query string to identify initial papers, followed by a backward snowballing technique to find additional studies. Inclusion criteria were defined to select only primary studies that used ML or DL models trained on clinical data for arboviral diagnosis. Data such as model types, datasets, feature selection methods, hyperparameter optimization techniques, and evaluation metrics were extracted from each study. Finally, a qualitative and comparative synthesis of the findings was performed to evaluate the state of AI research in this domain.
","The only Deep Learning method identified was a Convolutional Neural Network (CNN), specifically the DenseNet architecture. DenseNet connects each layer to every other layer within a block, enabling heavy feature reuse and reducing the risk of overfitting even with small datasets. It was trained on clinical and laboratory data to classify Dengue cases. The CNN was compared against traditional models (Decision Tree, Logistic Regression) and showed marginally better Area Under the Curve (AUC) performance (~84%). Feature selection was done beforehand (using odds ratio analysis) to reduce input dimensionality. No ensemble or hybrid DL methods were applied, and no new DL model was developed in this study.",Deep Learning (DL) classification techniques for arboviral disease diagnosis,No,No,The DL model (DenseNet CNN) was used for Dengue virus classification,"clinical and laboratory data such as: Age, Body Temperature, White Blood Cell (WBC) count, Platelet (PLT) count, Hemoglobin (Hb), and gender.",da et.al,Yes,"Performance of the Deep Learning model (DenseNet CNN) was evaluated using a 10-fold cross-validation method. This approach involves dividing the dataset into ten parts, training the model on nine parts, and validating it on the remaining one part, iteratively, to ensure robustness and reduce overfitting. The main metric used to assess performance was the Area Under the Receiver Operating Characteristic Curve (AUC), which measures the model's ability to distinguish between Dengue and non-Dengue cases across different threshold settings. Across experiments using different subsets of attributes (4, 6, 11, and 18 features), the DenseNet CNN achieved a consistent AUC of approximately 84%.",{'AUC'},"{ ""AUC_score"": 0.84}",
85,"Corbacho Abelaira MD, Corbacho Abelaira F, Ruano-Ravina A, FernÃ¡ndez-Villar A.",2021,"Pulmonary Department, Hospital POVISA, Vigo, Spain.",Use of Conventional Chest Imaging and Artificial Intelligence in COVID-19 Infection. A Review of the Literature,Open Respir Arch,Respiratory Virology,"[""COVID-19""]","Journal Article, Review","To review and analyze the contributions of artificial intelligence (AI), particularly deep learning techniques, in the detection, diagnosis, progression monitoring, and severity assessment of COVID-19 using chest radiological imaging methods such as chest X-ray (CXR) and computed tomography (CT), up to May 2020.","RT-PCR, has low sensitivity and limited availability, hindering effective detection and contact tracing. Chest imaging aids diagnosis, but CXR has lower sensitivity and is prone to interpretation errors. Manual analysis is slow and subjective, highlighting the need for faster, scalable, and more objective diagnostic tools.","The objective of AI is to automate and improve chest imaging analysis for COVID-19 by enhancing diagnostic accuracy, reducing interpretation errors, supporting triage, and enabling fast, scalable, and consistent assessment of disease severity and progression.","The study reviews the use of supervised deep learning techniques, mainly Convolutional Neural Networks (CNNs), applied to chest imaging for automating the detection, segmentation, and quantification of COVID-19-related abnormalities.","The reviewed models include architectures such as COVID-Net, ResNet, U-Net++, Dense U-Net, VB-Net, and Bayesian CNNs, performing tasks like image classification, lesion segmentation, progression tracking, and severity prediction, using labeled chest X-ray and CT scan datasets.",deep learning CNN-based models,No,No,"early diagnosis, disease progression monitoring, severity scoring, and clinical outcome prediction for patients affected with COVID-19","Chest X-ray, Chest CT-scans", Corbacho et.al,Yes,The paper does not conduct its own experiments.,The paper does not conduct its own experiments.,The paper does not conduct its own experiments.,
86,"Bressem KK, Adams LC, Erxleben C, Hamm B, Niehues SM, Vahldiek JL.",2020,"CharitÃ© UniversitÃ¤tsmedizin Berlin, Campus Benjamin Franklin, Hindenburgdamm 30, 12203, Berlin, Germany. keno-kyrill.bressem@charite.de.",Comparing different deep learning architectures for classification of chest radiographs,Sci Rep,Respiratory Virology,['COVID-19 pneumonia'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","To systematically compare the performance of sixteen different pre-existing convolutional neural network (CNN) architecture ranging from shallow to deep on the task of classifying chest radiographs, specifically focusing on two datasets: CheXpert and the COVID-19 Image Data Collection.","This study explores whether simpler, shallower CNN architectures can achieve high performance in chest radiograph classification, offering efficient alternatives to deeper, more complex models.","To identify which existing CNN architectures (both shallow and deep) are most effective for classifying chest radiographs, particularly for detecting conditions like cardiomegaly, edema, consolidation, atelectasis, pleural effusion, and COVID-19 pneumonia.Predicting disease progression in patients with COVID-19","The study employed a comparative AI methodology by fine-tuning 16 pre-trained convolutional neural network (CNN) architecture: AlexNet, VGG-13, VGG-16, VGG-19, SqueezeNet-1.0, SqueezeNet-1.1, ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152, DenseNet-121, DenseNet-161, DenseNet-169, DenseNet-201, and Inception v4 originally trained on ImageNet. These models were adapted for medical image classification tasks using two datasets: CheXpert and the COVID-19 Image Data Collection. ","Each model underwent a two-phase fine-tuning process: first, training only the classification head for five epochs, followed by unfreezing and training the entire network for three additional epochs. Input chest radiographs were resized to 320×320 pixels and augmented through flipping, rotation, zooming, and lighting adjustments to enhance generalization. Models were trained using batch sizes of 16 and 32, and evaluated using multi-label classification for CheXpert (five pathology categories) and multi-class classification for COVID-19 (normal, COVID-19 pneumonia, non-COVID pneumonia).",Supervised deep learning using CNN architectures,https://github.com/pytorch/vision/tree/main/torchvision/models,BSD 3-Clause License,Detection and classification of COVID-19 pneumonia from chest radiographs,chest radiograph images (X-rays),CheXpert dataset,Yes,"A separate validation set consisting of 202 images annotated by two radiologists was used for evaluation. Each of the 16 convolutional neural network (CNN) models was trained five times, and predictions across these runs were pooled to ensure stable and reliable results. Evaluation metrics included the Area Under the Receiver Operating Characteristic Curve (AUROC), the Area Under the Precision-Recall Curve (AUPRC), and threshold-based sensitivity and specificity scores.","{""AUROC_range"", ""Top_models"", ""CheXpert_baseline_AUROC"", ""Shallow_models_good_performance"", ""Metrics_used"", ""Observation""}","{""AUROC_range"": ""0.828 - 0.882"", ""Top_models"": [""ResNet-152"", ""DenseNet-161"", ""ResNet-50""], ""CheXpert_baseline_AUROC"": 0.889, ""Shallow_models_good_performance"": [""AlexNet"", ""VGG-16""], ""Metrics_used"": {""AUROC"": {""min"": 0.828, ""max"": 0.882}, ""Sensitivity"": {""range"": ""0.59 - 0.94""}, ""Specificity"": {""range"": ""0.51 - 0.94""}}, ""Observation"": ""Shallow networks performed competitively; deep networks not always necessary""}",
,,,,,,,,,,,,,,,,,,,COVID-19 Image Data ,Yes,"each CNN model was trained five times, and predictions were aggregated for performance evaluation. Metrics used included AUROC (using a one-vs-rest strategy for each class), AUPRC for COVID-19 detection, and class-specific sensitivity and specificity. The models were tested on their ability to generalize with very few COVID-19 cases, making high precision particularly important.","{""AUROC_range"", ""Top_models"", ""CheXpert_baseline_AUROC"", ""Shallow_models_good_performance"", ""Metrics_used"", ""Observation""}","{""AUROC_range"": ""0.983 - 1.000"", ""Top_models"": [""DenseNet-169"", ""DenseNet-201"", ""VGG-16""], ""Sensitivity_Specificity"": {""Sensitivity_range"": ""0.90 - 1.00"", ""Specificity_range"": ""0.91 - 1.00""}, ""Metrics_used"": {""AUROC"": {""min"": 0.983, ""max"": 1.000}, ""Sensitivity"": {""range"": ""0.90 - 1.00""}, ""Specificity"": {""range"": ""0.91 - 1.00""}}, ""Observation"": ""All models performed excellently; even shallow networks achieved state-of-the-art results""}",
87,"Martinez M, Yang K, Constantinescu A, Stiefelhagen R.",2020,"Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, 76131 Karlsruhe, Germany.",Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video,Sensors (Basel),Respiratory Virology,['COVID-19'],"Evaluation Study, Journal Article",To develop a wearable system that helps blind and visually impaired individuals maintain social distancing by detecting nearby people and providing intuitive audio feedback.,"to increase confidence of Blind individuals to maintain safe social distancing with the support of assistive technologies that provide real-time awareness of nearby people using audio feedback, empowering them to navigate public spaces independently and safely during COVID-19.","To detect the presence and proximity of nearby people in real time using visual input, and to alert the user only when individuals are within a critical distance range (50 cm to 1.5 m), thereby supporting physical distancing.","The system uses a real-time AI-driven perception pipeline that combines semantic segmentation with depth sensing. Semantic segmentation is applied to RGB video to identify people in the user’s surroundings, and depth information is used to measure the distance to these individuals. The AI system is designed to provide timely audio feedback when a person enters a defined proximity range, supporting safe navigation.","The AI model used is SwaftNet, a lightweight, real-time semantic segmentation network.
Input: RGB video frames (640×480 resolution) captured by a wearable RGB-D camera.
Output: Pixel-wise semantic labels, particularly the “person” class, for each frame.
These semantic masks are then fused with the corresponding depth maps (from the depth camera) to estimate the real-world distance to detected persons. This fused data guides the audio feedback mechanism, where warnings are generated only if someone is within 50 cm to 150 cm of the user. The sound pitch and volume are dynamically modulated based on proximity and urgency.", SwaftNet deep neural network(Convolutional Neural Network), https://github.com/elnino9ykl/DS-PASS,MIT License.,"Assistive navigation for COVID-19 prevention, enforcing social distancing among visually impaired individuals in indoor and outdoor environments",RGB images,Mapillary Vistas dataset(used for training),Yes,"The SwaftNet model was trained on the Mapillary Vistas dataset using urban street scene images with data augmentation to enhance generalization. Validation was done on its official split, and performance was measured using Intersection over Union (IoU) across object classes, especially focusing on the ""person"" class.","{""Mean IoU"", ""IoU for Person Class""}","{""Mean IoU"": ""59.4%"", ""IoU for Person Class"": ""69.9%""}",
,,,,,,,,,,,,,,,,,,,PASS dataset(used for test)  ,Yes,"The PASS dataset was used solely for real-world evaluation of the trained SwaftNet model under wearable navigation conditions using egocentric RGB-D inputs. Different input resolutions were tested to analyze accuracy-latency trade-offs on both a laptop and Nvidia Xavier. Performance was evaluated using Mean IoU, Person IoU, and inference delay per frame.","{""Mean IoU"", ""IoU for Person Class"", ""Inference Delay (ms/frame)""}","{""Resolution 960x720"": {""Mean IoU"": ""68.3%"", ""Person IoU"": ""81.8%"", ""Delay_Laptop"": ""600.6 ms"", ""Delay_Xavier"": ""108.9 ms""}, ""Resolution 640x480"": {""Mean IoU"": ""66.9%"", ""Person IoU"": ""80.4%"", ""Delay_Laptop"": ""292.1 ms"", ""Delay_Xavier"": ""57.9 ms""}, ""Resolution 480x360"": {""Mean IoU"": ""55.1%"", ""Person IoU"": ""77.7%"", ""Delay_Laptop"": ""184.0 ms"", ""Delay_Xavier"": ""52.6 ms""}, ""Resolution 320x240"": {""Mean IoU"": ""50.8%"", ""Person IoU"": ""63.3%"", ""Delay_Laptop"": ""107.9 ms"", ""Delay_Xavier"": ""46.7 ms""}}",
88,"Magge A, Weissenbacher D, O'Connor K, Scotch M, Gonzalez-Hernandez G.",2022,"Perelman School of Medicine, University of Pennsylvania.",SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning,medRxiv,Respiratory Virology,['COVID-19'],"Preprint, Journal Article",The aim is to create and validate a system that extracts and standardizes symptom/disease mentions from social media posts into medical terminologies.,"The problem is the lack of general, scalable, and accurate tools for extracting and normalizing symptoms from noisy and rare mentions in social media posts, across various contexts.","The AI objective is to build a deep learning-based system to extract and standardize disease and symptom mentions from social media text with high accuracy, generalizability, and scalability.","The AI methodology is a two-phase deep learning approach combining entity extraction and normalization. In the first phase, symptom and disease mentions are extracted from noisy social media posts using a Flair-based NER model. The model architecture consists of a language representation layer (FastText or BERT embeddings) followed by a Bi-GRU network (hidden dimension 256), a fully connected dense layer, and a CRF layer for structured sequence labeling. The training set was built by merging Twitter and DailyStrength datasets (multi-corpus training), improving the generalization of symptom extraction. Tokenization was performed using segtok, labels were encoded in IOB2 format, and model optimization used SGD with a learning rate of 0.1 across 70 epochs, selecting the best model on a development set. In the second phase, extracted symptoms were normalized using a FastText-based classifier. The normalization model was trained on annotated symptom spans and expanded using MedDRA LLTs and expressions from the UMLS ontology, allowing it to generalize beyond seen data. Word n-gram (up to 3) and character n-gram (up to 5) features were used, with training optimized using hierarchical softmax to manage large label spaces efficiently. This combination enabled SEED to achieve state-of-the-art performance in symptom extraction and normalization from social media.","The AI system for symptom extraction uses a Flair-based deep learning model with a bidirectional Gated Recurrent Unit (Bi-GRU) network followed by a Conditional Random Field (CRF) decoding layer. Word embeddings are provided by either FastText embeddings or BERT embeddings, depending on experimental settings. For normalization of extracted symptom mentions, the system uses a FastText classifier, which is a lightweight multinomial logistic regression model incorporating word and character n-gram features. The FastText model enables fast and scalable mapping of detected mentions to clinical terminologies, specifically MedDRA Preferred Terms (PTs) sourced from the UMLS metathesaurus.",Deep Learning-based Named Entity Recognition (NER) and Symptom Normalization System,"Yes(https://healthlanguageprocessing.org/pubs/seed - tool link), code release is in progress",Not specified,To monitor and detect self-reported symptoms of viral infections like COVID-19 from real-time social media data,Social media posts (from Twitter and DailyStrength forums).,Tw-NER-v1,Yes,"The Named Entity Recognition (NER) performance was evaluated on two social media datasets: Tw-NER-v1 (Twitter) and DS-NER (DailyStrength). The model trained with multi-corpus data (Twitter + DailyStrength) achieved state-of-the-art results over previous systems like ADRMine. Specifically, on the Twitter ADR extraction task, it achieved a Precision of 0.87, Recall of 0.73, and an F1-Score of 0.79. On the DailyStrength ADR extraction task, it reached a Precision of 0.89, Recall of 0.84, and an F1-Score of 0.87. For Twitter Indication extraction, it achieved a Precision of 0.59, Recall of 0.46, and an F1-Score of 0.52, while on the DailyStrength Indication extraction, it obtained Precision of 0.89, Recall of 0.71, and F1-Score of 0.79. These results highlight that multi-corpus training greatly improves model generalization for symptom extraction across noisy social media sources.","{""Precision"",""Recall"",""F1-score""}","""NER_Twitter_ADR"": {""P"": 0.87, ""R"": 0.73, ""F1"": 0.79}, ""NER_DailyStrength_ADR"": {""P"": 0.89, ""R"": 0.84, ""F1"": 0.87}, ""NER_Twitter_Indication"": {""P"": 0.59, ""R"": 0.46, ""F1"": 0.52}, ""NER_DailyStrength_Indication"": {""P"": 0.89, ""R"": 0.71, ""F1"": 0.79}",
,,,,,,,,,,,,,,,,,,Social media posts (from Twitter and DailyStrength forums).,DS-NER,Yes,,,,
,,,,,,,,,,,,,,,,,,Social media posts (from Twitter and DailyStrength forums).,Tw-Resolve,Yes,"Normalization performance was evaluated on the Tw-Resolve dataset, focusing on mapping symptom mentions to standardized MedDRA Preferred Terms (PTs). The FastText-based normalization model achieved an F1-Score of 0.49 for the NER-only task (evaluating correct span extraction) and an F1-Score of 0.35 for the end-to-end extraction and normalization task. These results outperformed prior systems submitted to the SMM4H 2019 shared task, demonstrating the benefit of using lightweight, scalable classifiers trained with extended symptom vocabularies sourced from MedDRA and UMLS.","{""f1-score""}","""Normalization_TwResolve_NER_only"": {""F1"": 0.49}, ""Normalization_TwResolve_End_to_End"": {""F1"": 0.35}}",
89,"Li Z, Gurgel H, Dessay N, Hu L, Xu L, Gong P.",2020,"Ministry of Education Key Laboratory for Earth System Modeling, Department of Earth System, Science, Tsinghua University, Beijing 100084, China.",Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation,Int J Environ Res Public Health,General Virology,[Dengue],"Journal Article, Research Support, Non-U.S. Gov't, Review","To provide a comprehensive overview of landscape factors affecting dengue transmission and the satellite Earth observation (EO) data used to identify these factors, by developing an efficient and accurate semi-supervised text classification framework for selecting relevant studies from large bibliographic databases.","Automate the identification of scientific literature on dengue transmission, specifically the landscape factors (like land use, land cover, topography, etc.) that influence mosquito breeding, human-vector interaction, and virus spread using satellite EO data.","To reduce human workload and improve accuracy in literature selection by automating the screening process using text classification algorithms integrated with active learning and deep learning methods.
","A semi-supervised text classification framework was developed which combines Text scoring (based on keyword weighting), Active learning (AL), Bidirectional Long Short-Term Memory (BiLSTM) neural network to replace manual screening steps with AI-driven classification.","A semi-supervised text classification framework was developed to automate the literature review process. It integrates keyword-based text scoring, active learning, and bidirectional long short-term memory (BiLSTM) networks. This framework effectively replaces manual title/abstract and full-text screening with AI-driven classification, reducing human workload while maintaining accuracy.The framework classifies scientific articles as relevant or irrelevant to dengue landscape research by combining keyword-based text scoring, human-guided active learning, and BiLSTM deep learning to analyze titles and abstracts efficiently.",BiLSTM-based active learning,No,No,"identification of scientific literature on dengue transmission, specifically the landscape factors using satellite EO data","Metadata derived from bibliographic databases, text data containing abstracts and full texts",Li et.al,Yes,"The framework's effectiveness was measured by manual validation, tracking relevant articles identified across BiLSTM cycles, verifying precision through random checks of unlabelled records, and analyzing score-rank trends to ensure accurate relevance classification.","{""Total_records_searched"", ""Duplicates_removed"", ""Records_after_deduplication"", ""Records_after_text_scoring"", ""Records_after_BiLSTM_active_learning"", ""Final_included_articles"", ""Manual_screened_titles_abstracts"", ""Unlabelled_checked_for_precision"", ""Relevant_found_in_unlabelled_check"", ""BiLSTM_cycles_until_all_relevant_found"", ""Precision"", ""Relevance_trend_with_score_rank""}","{""Total_records_searched"": 13893, ""Duplicates_removed"": 6197, ""Records_after_deduplication"": 7696, ""Records_after_text_scoring"": 2034, ""Records_after_BiLSTM_active_learning"": 131, ""Final_included_articles"": 101, ""Manual_screened_titles_abstracts"": 1056, ""Unlabelled_checked_for_precision"": 10, ""Relevant_found_in_unlabelled_check"": 0, ""BiLSTM_cycles_until_all_relevant_found"": 4, ""Precision"": ""High"", ""Relevance_trend_with_score_rank"": ""Consistently decreasing""}",
90,"Wang L, Novoa-Laurentiev J, Cook C, Srivatsan S, Hua Y, Yang J, Miloslavsky E, Choi HK, Zhou L, Wallace ZS.",2024,"Division of General Internal Medicine and Primary Care, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, Boston, Massachusetts, USA.",Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records,medRxiv,General Virology,['ANCA-associated vasculitis'],"Journal Article, Preprint","To develop and evaluate a deep learning algorithm that accurately identifies patients with ANCA-associated vasculitis (AAV) using unstructured clinical notes in electronic health records (EHRs), and to compare its performance with traditional rule-based algorithms.","To  develop a scalable solution to address the limitations of current AAV case-identification method which depend heavily on structured data like ICD codes and are often time-consuming, inaccurate, and likely to overlook important patient subgroups such as those who are ANCA-negative.",Classify clinical note sections as indicating AAV or not. Accurately detect AAV cases at the patient level. Outperform rule-based methods in terms of sensitivity and predictive value.,"Extract and segment clinical notes from EHRs into labeled sections using expert annotations and keyword filtering. Train machine learning and deep learning models (including CNN-RNN-attention networks and BioClinicalBERT) on labeled datasets. Validate models on unseen note sections and assess generalizability to random patient samples; compare to rule-based algorithms using metrics like AUROC, AUPRC, PPV, sensitivity, and F1-score.","This model combines CNN, RNN, and attention layers to process clinical note sections:
CNN helps handle word variations like misspellings or plural forms.
RNN captures word order and context, such as negations.
Attention layers allow the model to focus on key phrases that signal AAV.
It uses BioWordVec embeddings trained on biomedical literature and MeSH terms for word representations.
Each note section is processed as a sequence of tokens for binary classification (AAV or not).","Hierarchical deep learning model with CNN, RNN, and attention layers.",No,No,detection and classification of AAV,Clinical notes,Wang et.al,Yes,"The performance of both models was evaluated at two levels: note section-level (for training and testing) and patient-level (for real-world application). Key metrics included AUROC, AUPRC, PPV, sensitivity, and F1 score.","{AUROC, AUPRC, PPV, Sensitivity, F1 Score, patient-level:PPV, Sensitivity}","Section level: AUROC: 0.991, AUPRC: 0.977, PPV: 0.954, Sensitivity: 0.951, F1 Score: 0.946, patient-level:PPV: 0.262, Sensitivity: 0.975",
,,,,,,,,,,,,,"A transformer-based language model pre-trained on clinical data:
Captures complex relationships and context in medical notes using the BERT architecture.
Fine-tuned specifically on AAV-labeled clinical note sections to classify whether they refer to AAV.",BioClinicalBERT,,,,,,,,,,"Best Section-Level — AUROC: 0.981, AUPRC: 0.962, PPV: 0.947, Sensitivity: 0.966, F1 Score: 0.952; Patient-Level: Not evaluated."
91,"Wang Y, Xu C, Zhang S, Yang L, Wang Z, Zhu Y, Yuan J.",2019,"Department of Epidemiology and Health Statistics, School of Public Health, North China University of Science and Technology, Tangshan, Hebei Province, P.R. China.",Development and evaluation of a deep learning approach for modeling seasonality and trends in hand-foot-mouth disease incidence in mainland China,Sci Rep,enterovirus virology,[hand-foot-mouth disease],"Evaluation Study, Journal Article, Research Support, Non-U.S. Gov't","Conceives this work, and collected and analyzed the data.","To develop and evaluate a deep learning model for accurately forecasting hand, foot, and mouth disease (HFMD) incidence in mainland China, and to compare its performance with traditional SARIMA and NAR models.","To develop a model that captures long-term dependencies and complex non-linear patterns in disease incidence data like HFMD, leading to suboptimal forecasts for public health planning.","The study employed a comparative AI methodology by developing and evaluating Long Short-Term Memory (LSTM) model for time-series forecasting of HFMD cases, benchmarking its performance against the traditional SARIMA model and  Nonlinear Autoregressive Neural Network (NAR) using epidemiological data from China.","The optimal architecture consisted of one hidden layer with five hidden neurons and used 11 time steps to capture temporal dependencies in the time series. The model was trained using the sigmoid activation function and optimized with the Adam optimizer over 300 epochs. Training was performed using the Backpropagation Through Time (BPTT) algorithm. The input to the model was monthly HFMD case counts collected over a ten-year period, and the output was multistep-ahead predictions of future case counts, enabling early detection and planning for HFMD outbreaks.",LSTM,No,No,early detection and public health preparedness through accurate time series prediction,Time series data for HFMD,HFMD Notified Case Time Series,Yes,"The study utilized a time series dataset comprising monthly reported cases of Hand, Foot, and Mouth Disease (HFMD) in mainland China, covering the period from June 2008 to June 2018. To validate the models, the dataset was partitioned into different in-sample (training) and out-of-sample (testing) segments. Model performance was assessed through both simulation (in-sample fitting) and forecasting (out-of-sample prediction). The accuracy of the predictions was quantified using three statistical error metrics: Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Square Error (RMSE).","{""MAE"", ""MAPE"", ""RMSE""}","{""MAE"": 19505.80, ""MAPE"": 0.221, ""RMSE"": 25820.17}",
92,"Kim JY, Jung KJ, Yoo SJ, Yoon SH.",2021,"Department of Radiology, Dongsan Hospital, Keimyung University College of Medicine, Daegu, South Korea.",Stratifying the early radiologic trajectory in dyspneic patients with COVID-19 pneumonia,PLoS One,Respiratory Virology,"['Coronavirus disease 2019, pneumonia ']","Journal Article, Multicenter Study","The aim of this study is to monitor how pneumonia changes over time in hospitalized COVID-19 patients who have breathing difficulty (dyspnea), using chest X-rays. By analyzing patterns in pneumonia progression, the study seeks to group patients based on how their lung condition develops, and to compare their age, symptoms, lab results, and health outcome such as ICU admission or deat across these groups. This helps identify which patients are at higher risk for severe illness.",Baseline chest X-rays in COVID-19 patients with dyspnea do not accurately predict who will develop severe illness. There's a need to monitor pneumonia progression over time to better identify high-risk patients early.,automatically quantify the extent of pneumonia on chest radiographs using a deep learning model and to track how pneumonia progresses over time in COVID-19 patients. ,Hospitalized COVID-19 patients with breathing difficulty were selected and their clinical data and chest radiographs were collected.  chest X-rays were uploaded to an AI system (TiSepX COVID-19 by MEDICAL IP) that automatically quantified pneumonia extent as a percentage. A group-based trajectory model (latent class growth modeling) was used to stratify patients based on how pneumonia evolved over time.,"Tool Used: TiSepX COVID-19 (developed by MEDICAL IP)
Model Type: Deep learning model based on a Generative Adversarial Network (GAN)
Training Dataset: 50,000 chest radiographs
Input: Chest radiograph (DICOM format)
Output: Pneumonia extent as percentage (e.g., 13.5% of lung affected)",Deep Learning Quantification tool based on generative adversarial network,DeepCatch X,No,The clinical progression of pneumonia caused by SARS-CoV-2,Chest radiograph images,Kim et.al,Yes,The AI tool’s pneumonia percentage estimation on X-rays was validated by comparing it to the gold standard: CT-based pneumonia quantification.,"{""comparison"", ""average_bias"",  ""correlation_coefficient""}  ","{""comparison"": ""CT-based pneumonia quantification"", ""average_bias"": -6.1, ""limits_of_agreement"": [-29.5, 17.2], ""correlation_coefficient"": 0.748}",
