PMID,Title,Authors,Citation,First Author,Journal/Book,Publication Year,Create Date,PMCID,NIHMS ID,DOI,Abstract,Combined_Text,Is_Relevant,GT_relevant
28693336,Quick Sequential [Sepsis-Related] Organ Failure Assessment (qSOFA) and St. John Sepsis Surveillance Agent to Detect Patients at Risk of Sepsis: An Observational Cohort Study,"Amland RC, Sutariya BB.",Am J Med Qual. 2018 Jan/Feb;33(1):50-57. doi: 10.1177/1062860617692034. Epub 2017 Feb 1.,Amland RC,Am J Med Qual,2018,12-07-2017,PMC5774614,,10.1177/1062860617692034,"The 2016 Sepsis-3 guidelines included the Quick Sequential [Sepsis-related] Organ Failure Assessment (qSOFA) tool to identify patients at risk of sepsis. The objective was to compare the utility of qSOFA to the St. John Sepsis Surveillance Agent among patients with suspected infection. The primary outcomes were in-hospital mortality or admission to the intensive care unit. A multiple center observational cohort study design was used. The study population comprised 17 044 hospitalized patients between January and March 2016. For the primary analysis, receiver operator characteristic curves were constructed for patient outcomes using qSOFA and the St. John Sepsis Surveillance Agent, and the areas under the curve were compared against a baseline risk model. Time-to-event clinical process modeling also was applied. The St. John Sepsis Surveillance Agent, when compared to qSOFA, activated earlier and was more accurate in predicting patient outcomes; in this regard, qSOFA fell far behind on both objectives.","Quick Sequential [Sepsis-Related] Organ Failure Assessment (qSOFA) and St. John Sepsis Surveillance Agent to Detect Patients at Risk of Sepsis: An Observational Cohort Study The 2016 Sepsis-3 guidelines included the Quick Sequential [Sepsis-related] Organ Failure Assessment (qSOFA) tool to identify patients at risk of sepsis. The objective was to compare the utility of qSOFA to the St. John Sepsis Surveillance Agent among patients with suspected infection. The primary outcomes were in-hospital mortality or admission to the intensive care unit. A multiple center observational cohort study design was used. The study population comprised 17 044 hospitalized patients between January and March 2016. For the primary analysis, receiver operator characteristic curves were constructed for patient outcomes using qSOFA and the St. John Sepsis Surveillance Agent, and the areas under the curve were compared against a baseline risk model. Time-to-event clinical process modeling also was applied. The St. John Sepsis Surveillance Agent, when compared to qSOFA, activated earlier and was more accurate in predicting patient outcomes; in this regard, qSOFA fell far behind on both objectives.",0,0
36143468,Artificial Intelligence in Biological Sciences,"Bhardwaj A, Kishore S, Pandey DK.",Life (Basel). 2022 Sep 14;12(9):1430. doi: 10.3390/life12091430.,Bhardwaj A,Life (Basel),2022,23-09-2022,PMC9505413,,10.3390/life12091430,"Artificial intelligence (AI), currently a cutting-edge concept, has the potential to improve the quality of life of human beings. The fields of AI and biological research are becoming more intertwined, and methods for extracting and applying the information stored in live organisms are constantly being refined. As the field of AI matures with more trained algorithms, the potential of its application in epidemiology, the study of host-pathogen interactions and drug designing widens. AI is now being applied in several fields of drug discovery, customized medicine, gene editing, radiography, image processing and medication management. More precise diagnosis and cost-effective treatment will be possible in the near future due to the application of AI-based technologies. In the field of agriculture, farmers have reduced waste, increased output and decreased the amount of time it takes to bring their goods to market due to the application of advanced AI-based approaches. Moreover, with the use of AI through machine learning (ML) and deep-learning-based smart programs, one can modify the metabolic pathways of living systems to obtain the best possible outputs with the minimal inputs. Such efforts can improve the industrial strains of microbial species to maximize the yield in the bio-based industrial setup. This article summarizes the potentials of AI and their application to several fields of biology, such as medicine, agriculture, and bio-based industry.","Artificial Intelligence in Biological Sciences Artificial intelligence (AI), currently a cutting-edge concept, has the potential to improve the quality of life of human beings. The fields of AI and biological research are becoming more intertwined, and methods for extracting and applying the information stored in live organisms are constantly being refined. As the field of AI matures with more trained algorithms, the potential of its application in epidemiology, the study of host-pathogen interactions and drug designing widens. AI is now being applied in several fields of drug discovery, customized medicine, gene editing, radiography, image processing and medication management. More precise diagnosis and cost-effective treatment will be possible in the near future due to the application of AI-based technologies. In the field of agriculture, farmers have reduced waste, increased output and decreased the amount of time it takes to bring their goods to market due to the application of advanced AI-based approaches. Moreover, with the use of AI through machine learning (ML) and deep-learning-based smart programs, one can modify the metabolic pathways of living systems to obtain the best possible outputs with the minimal inputs. Such efforts can improve the industrial strains of microbial species to maximize the yield in the bio-based industrial setup. This article summarizes the potentials of AI and their application to several fields of biology, such as medicine, agriculture, and bio-based industry.",1,0
34056579,"The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype","Abdulkareem M, Petersen SE.",Front Artif Intell. 2021 May 14;4:652669. doi: 10.3389/frai.2021.652669. eCollection 2021.,Abdulkareem M,Front Artif Intell,2021,31-05-2021,PMC8160471,,10.3389/frai.2021.652669,"COVID-19 has created enormous suffering, affecting lives, and causing deaths. The ease with which this type of coronavirus can spread has exposed weaknesses of many healthcare systems around the world. Since its emergence, many governments, research communities, commercial enterprises, and other institutions and stakeholders around the world have been fighting in various ways to curb the spread of the disease. Science and technology have helped in the implementation of policies of many governments that are directed toward mitigating the impacts of the pandemic and in diagnosing and providing care for the disease. Recent technological tools, artificial intelligence (AI) tools in particular, have also been explored to track the spread of the coronavirus, identify patients with high mortality risk and diagnose patients for the disease. In this paper, areas where AI techniques are being used in the detection, diagnosis and epidemiological predictions, forecasting and social control for combating COVID-19 are discussed, highlighting areas of successful applications and underscoring issues that need to be addressed to achieve significant progress in battling COVID-19 and future pandemics. Several AI systems have been developed for diagnosing COVID-19 using medical imaging modalities such as chest CT and X-ray images. These AI systems mainly differ in their choices of the algorithms for image segmentation, classification and disease diagnosis. Other AI-based systems have focused on predicting mortality rate, long-term patient hospitalization and patient outcomes for COVID-19. AI has huge potential in the battle against the COVID-19 pandemic but successful practical deployments of these AI-based tools have so far been limited due to challenges such as limited data accessibility, the need for external evaluation of AI models, the lack of awareness of AI experts of the regulatory landscape governing the deployment of AI tools in healthcare, the need for clinicians and other experts to work with AI experts in a multidisciplinary context and the need to address public concerns over data collection, privacy, and protection. Having a dedicated team with expertise in medical data collection, privacy, access and sharing, using federated learning whereby AI scientists hand over training algorithms to the healthcare institutions to train models locally, and taking full advantage of biomedical data stored in biobanks can alleviate some of problems posed by these challenges. Addressing these challenges will ultimately accelerate the translation of AI research into practical and useful solutions for combating pandemics.","The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype COVID-19 has created enormous suffering, affecting lives, and causing deaths. The ease with which this type of coronavirus can spread has exposed weaknesses of many healthcare systems around the world. Since its emergence, many governments, research communities, commercial enterprises, and other institutions and stakeholders around the world have been fighting in various ways to curb the spread of the disease. Science and technology have helped in the implementation of policies of many governments that are directed toward mitigating the impacts of the pandemic and in diagnosing and providing care for the disease. Recent technological tools, artificial intelligence (AI) tools in particular, have also been explored to track the spread of the coronavirus, identify patients with high mortality risk and diagnose patients for the disease. In this paper, areas where AI techniques are being used in the detection, diagnosis and epidemiological predictions, forecasting and social control for combating COVID-19 are discussed, highlighting areas of successful applications and underscoring issues that need to be addressed to achieve significant progress in battling COVID-19 and future pandemics. Several AI systems have been developed for diagnosing COVID-19 using medical imaging modalities such as chest CT and X-ray images. These AI systems mainly differ in their choices of the algorithms for image segmentation, classification and disease diagnosis. Other AI-based systems have focused on predicting mortality rate, long-term patient hospitalization and patient outcomes for COVID-19. AI has huge potential in the battle against the COVID-19 pandemic but successful practical deployments of these AI-based tools have so far been limited due to challenges such as limited data accessibility, the need for external evaluation of AI models, the lack of awareness of AI experts of the regulatory landscape governing the deployment of AI tools in healthcare, the need for clinicians and other experts to work with AI experts in a multidisciplinary context and the need to address public concerns over data collection, privacy, and protection. Having a dedicated team with expertise in medical data collection, privacy, access and sharing, using federated learning whereby AI scientists hand over training algorithms to the healthcare institutions to train models locally, and taking full advantage of biomedical data stored in biobanks can alleviate some of problems posed by these challenges. Addressing these challenges will ultimately accelerate the translation of AI research into practical and useful solutions for combating pandemics.",1,1
38424562,Prevalence of computer vision syndrome during the COVID-19 pandemic: a systematic review and meta-analysis,"León-Figueroa DA, Barboza JJ, Siddiq A, Sah R, Valladares-Garrido MJ, Adhikari S, Aguirre-Milachay E, Sah S, Rodriguez-Morales AJ.",BMC Public Health. 2024 Feb 29;24(1):640. doi: 10.1186/s12889-024-17636-5.,León-Figueroa DA,BMC Public Health,2024,29-02-2024,PMC10902934,,10.1186/s12889-024-17636-5,"BACKGROUND: Computer vision syndrome has become a significant public health problem, especially in developing countries. Therefore, this study aims to identify the prevalence of computer vision syndrome during the COVID-19 pandemic.
METHODS: A systematic review and meta-analysis of the literature was conducted using the databases PubMed, Scopus, Web of Science, and Embase up to February 22, 2023, using the search terms ""Computer Vision Syndrome"" and ""COVID-19"". Three authors independently performed study selection, quality assessment, and data extraction, and the Joanna Briggs Institute Meta-Analysis of Statistics Assessment and Review Instrument was used to evaluate study quality. Heterogeneity was assessed using the statistical test I2, and the R version 4.2.3 program was used for statistical analysis.
RESULTS: A total of 192 studies were retrieved, of which 18 were included in the final meta-analysis. The total sample included 10,337 participants from 12 countries. The combined prevalence of computer vision syndrome was 74% (95% CI: 66, 81). Subgroup analysis based on country revealed a higher prevalence of computer vision syndrome in Pakistan (99%, 95% CI: 97, 100) and a lower prevalence in Turkey (48%, 95% CI: 44, 52). In addition, subgroup analysis based on study subjects showed a prevalence of 82% (95% CI: 74, 89) for computer vision syndrome in non-students and 70% (95% CI: 60, 80) among students.
CONCLUSION: According to the study, 74% of the participants experienced computer vision syndrome during the COVID-19 pandemic. Given this finding, it is essential to implement preventive and therapeutic measures to reduce the risk of developing computer vision syndrome and improve the quality of life of those affected.
TRIAL REGISTRATION: The protocol for this systematic review and meta-analysis was registered in the international registry of systematic reviews, the International Prospective Register of Systematic Reviews (PROSPERO), with registration number CRD42022345965.","Prevalence of computer vision syndrome during the COVID-19 pandemic: a systematic review and meta-analysis BACKGROUND: Computer vision syndrome has become a significant public health problem, especially in developing countries. Therefore, this study aims to identify the prevalence of computer vision syndrome during the COVID-19 pandemic.
METHODS: A systematic review and meta-analysis of the literature was conducted using the databases PubMed, Scopus, Web of Science, and Embase up to February 22, 2023, using the search terms ""Computer Vision Syndrome"" and ""COVID-19"". Three authors independently performed study selection, quality assessment, and data extraction, and the Joanna Briggs Institute Meta-Analysis of Statistics Assessment and Review Instrument was used to evaluate study quality. Heterogeneity was assessed using the statistical test I2, and the R version 4.2.3 program was used for statistical analysis.
RESULTS: A total of 192 studies were retrieved, of which 18 were included in the final meta-analysis. The total sample included 10,337 participants from 12 countries. The combined prevalence of computer vision syndrome was 74% (95% CI: 66, 81). Subgroup analysis based on country revealed a higher prevalence of computer vision syndrome in Pakistan (99%, 95% CI: 97, 100) and a lower prevalence in Turkey (48%, 95% CI: 44, 52). In addition, subgroup analysis based on study subjects showed a prevalence of 82% (95% CI: 74, 89) for computer vision syndrome in non-students and 70% (95% CI: 60, 80) among students.
CONCLUSION: According to the study, 74% of the participants experienced computer vision syndrome during the COVID-19 pandemic. Given this finding, it is essential to implement preventive and therapeutic measures to reduce the risk of developing computer vision syndrome and improve the quality of life of those affected.
TRIAL REGISTRATION: The protocol for this systematic review and meta-analysis was registered in the international registry of systematic reviews, the International Prospective Register of Systematic Reviews (PROSPERO), with registration number CRD42022345965.",1,0
32413821,A review of modern technologies for tackling COVID-19 pandemic,"Kumar A, Gupta PK, Srivastava A.",Diabetes Metab Syndr. 2020 Jul-Aug;14(4):569-573. doi: 10.1016/j.dsx.2020.05.008. Epub 2020 May 7.,Kumar A,Diabetes Metab Syndr,2020,16-05-2020,PMC7204706,,10.1016/j.dsx.2020.05.008,"OBJECTIVE: Science and technology sector constituting of data science, machine learning and artificial intelligence are contributing towards COVID-19. The aim of the present study is to discuss the various aspects of modern technology used to fight against COVID-19 crisis at different scales, including medical image processing, disease tracking, prediction outcomes, computational biology and medicines.
METHODS: A progressive search of the database related to modern technology towards COVID-19 is made. Further, a brief review is done on the extracted information by assessing the various aspects of modern technologies for tackling COVID-19 pandemic.
RESULTS: We provide a window of thoughts on review of the technology advances used to decrease and smother the substantial impact of the outburst. Though different studies relating to modern technology towards COVID-19 have come up, yet there are still constrained applications and contributions of technology in this fight.
CONCLUSIONS: On-going progress in the modern technology has contributed in improving people's lives and hence there is a solid conviction that validated research plans including artificial intelligence will be of significant advantage in helping people to fight this infection.","A review of modern technologies for tackling COVID-19 pandemic OBJECTIVE: Science and technology sector constituting of data science, machine learning and artificial intelligence are contributing towards COVID-19. The aim of the present study is to discuss the various aspects of modern technology used to fight against COVID-19 crisis at different scales, including medical image processing, disease tracking, prediction outcomes, computational biology and medicines.
METHODS: A progressive search of the database related to modern technology towards COVID-19 is made. Further, a brief review is done on the extracted information by assessing the various aspects of modern technologies for tackling COVID-19 pandemic.
RESULTS: We provide a window of thoughts on review of the technology advances used to decrease and smother the substantial impact of the outburst. Though different studies relating to modern technology towards COVID-19 have come up, yet there are still constrained applications and contributions of technology in this fight.
CONCLUSIONS: On-going progress in the modern technology has contributed in improving people's lives and hence there is a solid conviction that validated research plans including artificial intelligence will be of significant advantage in helping people to fight this infection.",0,1
31830586,EoE disease monitoring: Where we are and where we are going,"Godwin B, Wilkins B, Muir AB.",Ann Allergy Asthma Immunol. 2020 Mar;124(3):240-247. doi: 10.1016/j.anai.2019.12.004. Epub 2019 Dec 9.,Godwin B,Ann Allergy Asthma Immunol,2020,13-12-2019,PMC7059875,NIHMS1548564,10.1016/j.anai.2019.12.004,"OBJECTIVE: To review literature on various methods of monitoring and characterizing eosinophilic esophagitis (EoE) with respect to their validity as well as risk to the patient.
DATA SOURCES: A literature search was performed using PubMed with keyword combinations of EoE and monitoring as well as various techniques used for monitoring, including but not limited to, symptoms, endoscopy, histology, fluoroscopy, FLIP, noninvasive monitoring, and biomarkers.
STUDY SELECTIONS: Case-control studies, observational studies, peer-reviewed reviews and guidelines, and systematic reviews were selected, reviewed, and summarized here.
RESULTS: A wealth of research regarding monitoring of EoE is currently being undertaken and published. Our review highlights those that have been validated and are currently being used, as well as some that show promise for future monitoring and disease characterization.
CONCLUSION: Eosinophilic esophagitis is a chronic condition that at this time requires upper endoscopy as the gold standard of diagnosis and monitoring. There is a great need in the field for less invasive monitoring tools and better ways to characterize disease to allow for personalization of therapies.","EoE disease monitoring: Where we are and where we are going OBJECTIVE: To review literature on various methods of monitoring and characterizing eosinophilic esophagitis (EoE) with respect to their validity as well as risk to the patient.
DATA SOURCES: A literature search was performed using PubMed with keyword combinations of EoE and monitoring as well as various techniques used for monitoring, including but not limited to, symptoms, endoscopy, histology, fluoroscopy, FLIP, noninvasive monitoring, and biomarkers.
STUDY SELECTIONS: Case-control studies, observational studies, peer-reviewed reviews and guidelines, and systematic reviews were selected, reviewed, and summarized here.
RESULTS: A wealth of research regarding monitoring of EoE is currently being undertaken and published. Our review highlights those that have been validated and are currently being used, as well as some that show promise for future monitoring and disease characterization.
CONCLUSION: Eosinophilic esophagitis is a chronic condition that at this time requires upper endoscopy as the gold standard of diagnosis and monitoring. There is a great need in the field for less invasive monitoring tools and better ways to characterize disease to allow for personalization of therapies.",0,0
37091459,Human behavior in the time of COVID-19: Learning from big data,"Lyu H, Imtiaz A, Zhao Y, Luo J.",Front Big Data. 2023 Apr 6;6:1099182. doi: 10.3389/fdata.2023.1099182. eCollection 2023.,Lyu H,Front Big Data,2023,24-04-2023,PMC10118015,,10.3389/fdata.2023.1099182,"Since the World Health Organization (WHO) characterized COVID-19 as a pandemic in March 2020, there have been over 600 million confirmed cases of COVID-19 and more than six million deaths as of October 2022. The relationship between the COVID-19 pandemic and human behavior is complicated. On one hand, human behavior is found to shape the spread of the disease. On the other hand, the pandemic has impacted and even changed human behavior in almost every aspect. To provide a holistic understanding of the complex interplay between human behavior and the COVID-19 pandemic, researchers have been employing big data techniques such as natural language processing, computer vision, audio signal processing, frequent pattern mining, and machine learning. In this study, we present an overview of the existing studies on using big data techniques to study human behavior in the time of the COVID-19 pandemic. In particular, we categorize these studies into three groups-using big data to measure, model, and leverage human behavior, respectively. The related tasks, data, and methods are summarized accordingly. To provide more insights into how to fight the COVID-19 pandemic and future global catastrophes, we further discuss challenges and potential opportunities.","Human behavior in the time of COVID-19: Learning from big data Since the World Health Organization (WHO) characterized COVID-19 as a pandemic in March 2020, there have been over 600 million confirmed cases of COVID-19 and more than six million deaths as of October 2022. The relationship between the COVID-19 pandemic and human behavior is complicated. On one hand, human behavior is found to shape the spread of the disease. On the other hand, the pandemic has impacted and even changed human behavior in almost every aspect. To provide a holistic understanding of the complex interplay between human behavior and the COVID-19 pandemic, researchers have been employing big data techniques such as natural language processing, computer vision, audio signal processing, frequent pattern mining, and machine learning. In this study, we present an overview of the existing studies on using big data techniques to study human behavior in the time of the COVID-19 pandemic. In particular, we categorize these studies into three groups-using big data to measure, model, and leverage human behavior, respectively. The related tasks, data, and methods are summarized accordingly. To provide more insights into how to fight the COVID-19 pandemic and future global catastrophes, we further discuss challenges and potential opportunities.",0,1
37333294,Post-acute immunological and behavioral sequelae in mice after Omicron infection,"Ma T, Suryawanshi RK, Miller SR, Ly KK, Thomas R, Elphick N, Yin K, Luo X, Kaliss N, Chen IP, Montano M, Sreekumar B, Standker L, Münch J, Heath Damron F, Palop JJ, Ott M, Roan NR.",bioRxiv [Preprint]. 2023 Oct 4:2023.06.05.543758. doi: 10.1101/2023.06.05.543758.,Ma T,bioRxiv,2023,19-06-2023,PMC10274741,,10.1101/2023.06.05.543758,"Progress in understanding long COVID and developing effective therapeutics is hampered in part by the lack of suitable animal models. Here we used ACE2-transgenic mice recovered from Omicron (BA.1) infection to test for pulmonary and behavioral post-acute sequelae. Through in-depth phenotyping by CyTOF, we demonstrate that naïve mice experiencing a first Omicron infection exhibit profound immune perturbations in the lung after resolving acute infection. This is not observed if mice were first vaccinated with spike-encoding mRNA. The protective effects of vaccination against post-acute sequelae were associated with a highly polyfunctional SARS-CoV-2-specific T cell response that was recalled upon BA.1 breakthrough infection but not seen with BA.1 infection alone. Without vaccination, the chemokine receptor CXCR4 was uniquely upregulated on multiple pulmonary immune subsets in the BA.1 convalescent mice, a process previously connected to severe COVID-19. Taking advantage of recent developments in machine learning and computer vision, we demonstrate that BA.1 convalescent mice exhibited spontaneous behavioral changes, emotional alterations, and cognitive-related deficits in context habituation. Collectively, our data identify immunological and behavioral post-acute sequelae after Omicron infection and uncover a protective effect of vaccination against post-acute pulmonary immune perturbations.","Post-acute immunological and behavioral sequelae in mice after Omicron infection Progress in understanding long COVID and developing effective therapeutics is hampered in part by the lack of suitable animal models. Here we used ACE2-transgenic mice recovered from Omicron (BA.1) infection to test for pulmonary and behavioral post-acute sequelae. Through in-depth phenotyping by CyTOF, we demonstrate that naïve mice experiencing a first Omicron infection exhibit profound immune perturbations in the lung after resolving acute infection. This is not observed if mice were first vaccinated with spike-encoding mRNA. The protective effects of vaccination against post-acute sequelae were associated with a highly polyfunctional SARS-CoV-2-specific T cell response that was recalled upon BA.1 breakthrough infection but not seen with BA.1 infection alone. Without vaccination, the chemokine receptor CXCR4 was uniquely upregulated on multiple pulmonary immune subsets in the BA.1 convalescent mice, a process previously connected to severe COVID-19. Taking advantage of recent developments in machine learning and computer vision, we demonstrate that BA.1 convalescent mice exhibited spontaneous behavioral changes, emotional alterations, and cognitive-related deficits in context habituation. Collectively, our data identify immunological and behavioral post-acute sequelae after Omicron infection and uncover a protective effect of vaccination against post-acute pulmonary immune perturbations.",0,0
32813110,Telemedicine in ophthalmology in view of the emerging COVID-19 outbreak,"Sommer AC, Blumenthal EZ.",Graefes Arch Clin Exp Ophthalmol. 2020 Nov;258(11):2341-2352. doi: 10.1007/s00417-020-04879-2. Epub 2020 Aug 19.,Sommer AC,Graefes Arch Clin Exp Ophthalmol,2020,20-08-2020,PMC7436071,,10.1007/s00417-020-04879-2,"PURPOSE: Technological advances in recent years have resulted in the development and implementation of various modalities and techniques enabling medical professionals to remotely diagnose and treat numerous medical conditions in diverse medical fields, including ophthalmology. Patients who require prolonged isolation until recovery, such as those who suffer from COVID-19, present multiple therapeutic dilemmas to their caregivers. Therefore, utilizing remote care in the daily workflow would be a valuable tool for the diagnosis and treatment of acute and chronic ocular conditions in this challenging clinical setting. Our aim is to review the latest technological and methodical advances in teleophthalmology and highlight their implementation in screening and managing various ocular conditions. We present them as well as potential diagnostic and treatment applications in view of the recent SARS-CoV-2 virus outbreak.
METHODS: A computerized search from January 2017 up to March 2020 of the online electronic database PubMed was performed, using the following search strings: ""telemedicine,"" ""telehealth,"" and ""ophthalmology."" More generalized complementary contemporary research data regarding the COVID-19 pandemic was also obtained from the PubMed database.
RESULTS: A total of 312 records, including COVID-19-focused studies, were initially identified. After exclusion of non-relevant, non-English, and duplicate studies, a total of 138 records were found eligible. Ninety records were included in the final qualitative analysis.
CONCLUSION: Teleophthalmology is an effective screening and management tool for a range of adult and pediatric acute and chronic ocular conditions. It is mostly utilized in screening of retinal conditions such as retinopathy of prematurity, diabetic retinopathy, and age-related macular degeneration; in diagnosing anterior segment condition; and in managing glaucoma. With improvements in image processing, and better integration of the patient's medical record, teleophthalmology should become a more accepted modality, all the more so in circumstances where social distancing is inflicted upon us.","Telemedicine in ophthalmology in view of the emerging COVID-19 outbreak PURPOSE: Technological advances in recent years have resulted in the development and implementation of various modalities and techniques enabling medical professionals to remotely diagnose and treat numerous medical conditions in diverse medical fields, including ophthalmology. Patients who require prolonged isolation until recovery, such as those who suffer from COVID-19, present multiple therapeutic dilemmas to their caregivers. Therefore, utilizing remote care in the daily workflow would be a valuable tool for the diagnosis and treatment of acute and chronic ocular conditions in this challenging clinical setting. Our aim is to review the latest technological and methodical advances in teleophthalmology and highlight their implementation in screening and managing various ocular conditions. We present them as well as potential diagnostic and treatment applications in view of the recent SARS-CoV-2 virus outbreak.
METHODS: A computerized search from January 2017 up to March 2020 of the online electronic database PubMed was performed, using the following search strings: ""telemedicine,"" ""telehealth,"" and ""ophthalmology."" More generalized complementary contemporary research data regarding the COVID-19 pandemic was also obtained from the PubMed database.
RESULTS: A total of 312 records, including COVID-19-focused studies, were initially identified. After exclusion of non-relevant, non-English, and duplicate studies, a total of 138 records were found eligible. Ninety records were included in the final qualitative analysis.
CONCLUSION: Teleophthalmology is an effective screening and management tool for a range of adult and pediatric acute and chronic ocular conditions. It is mostly utilized in screening of retinal conditions such as retinopathy of prematurity, diabetic retinopathy, and age-related macular degeneration; in diagnosing anterior segment condition; and in managing glaucoma. With improvements in image processing, and better integration of the patient's medical record, teleophthalmology should become a more accepted modality, all the more so in circumstances where social distancing is inflicted upon us.",0,0
33972645,Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time,"Ong SQ, Ahmad H, Nair G, Isawasan P, Majid AHA.",Sci Rep. 2021 May 10;11(1):9908. doi: 10.1038/s41598-021-89365-3.,Ong SQ,Sci Rep,2021,11-05-2021,PMC8110999,,10.1038/s41598-021-89365-3,"Classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) by humans remains challenging. We proposed a highly accessible method to develop a deep learning (DL) model and implement the model for mosquito image classification by using hardware that could regulate the development process. In particular, we constructed a dataset with 4120 images of Aedes mosquitoes that were older than 12 days old and had common morphological features that disappeared, and we illustrated how to set up supervised deep convolutional neural networks (DCNNs) with hyperparameter adjustment. The model application was first conducted by deploying the model externally in real time on three different generations of mosquitoes, and the accuracy was compared with human expert performance. Our results showed that both the learning rate and epochs significantly affected the accuracy, and the best-performing hyperparameters achieved an accuracy of more than 98% at classifying mosquitoes, which showed no significant difference from human-level performance. We demonstrated the feasibility of the method to construct a model with the DCNN when deployed externally on mosquitoes in real time.","Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time Classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) by humans remains challenging. We proposed a highly accessible method to develop a deep learning (DL) model and implement the model for mosquito image classification by using hardware that could regulate the development process. In particular, we constructed a dataset with 4120 images of Aedes mosquitoes that were older than 12 days old and had common morphological features that disappeared, and we illustrated how to set up supervised deep convolutional neural networks (DCNNs) with hyperparameter adjustment. The model application was first conducted by deploying the model externally in real time on three different generations of mosquitoes, and the accuracy was compared with human expert performance. Our results showed that both the learning rate and epochs significantly affected the accuracy, and the best-performing hyperparameters achieved an accuracy of more than 98% at classifying mosquitoes, which showed no significant difference from human-level performance. We demonstrated the feasibility of the method to construct a model with the DCNN when deployed externally on mosquitoes in real time.",1,1
37798709,Clinical utilization of artificial intelligence-based COVID-19 pneumonia quantification using chest computed tomography - a multicenter retrospective cohort study in Japan,"Tanaka H, Maetani T, Chubachi S, Tanabe N, Shiraishi Y, Asakura T, Namkoong H, Shimada T, Azekawa S, Otake S, Nakagawara K, Fukushima T, Watase M, Terai H, Sasaki M, Ueda S, Kato Y, Harada N, Suzuki S, Yoshida S, Tateno H, Yamada Y, Jinzaki M, Hirai T, Okada Y, Koike R, Ishii M, Hasegawa N, Kimura A, Imoto S, Miyano S, Ogawa S, Kanai T, Fukunaga K.",Respir Res. 2023 Oct 5;24(1):241. doi: 10.1186/s12931-023-02530-2.,Tanaka H,Respir Res,2023,05-10-2023,PMC10552312,,10.1186/s12931-023-02530-2,"BACKGROUND: Computed tomography (CT) imaging and artificial intelligence (AI)-based analyses have aided in the diagnosis and prediction of the severity of COVID-19. However, the potential of AI-based CT quantification of pneumonia in assessing patients with COVID-19 has not yet been fully explored. This study aimed to investigate the potential of AI-based CT quantification of COVID-19 pneumonia to predict the critical outcomes and clinical characteristics of patients with residual lung lesions.
METHODS: This retrospective cohort study included 1,200 hospitalized patients with COVID-19 from four hospitals. The incidence of critical outcomes (requiring the support of high-flow oxygen or invasive mechanical ventilation or death) and complications during hospitalization (bacterial infection, renal failure, heart failure, thromboembolism, and liver dysfunction) was compared between the groups of pneumonia with high/low-percentage lung lesions, based on AI-based CT quantification. Additionally, 198 patients underwent CT scans 3 months after admission to analyze prognostic factors for residual lung lesions.
RESULTS: The pneumonia group with a high percentage of lung lesions (N = 400) had a higher incidence of critical outcomes and complications during hospitalization than the low percentage group (N = 800). Multivariable analysis demonstrated that AI-based CT quantification of pneumonia was independently associated with critical outcomes (adjusted odds ratio [aOR] 10.5, 95% confidence interval [CI] 5.59-19.7), as well as with oxygen requirement (aOR 6.35, 95% CI 4.60-8.76), IMV requirement (aOR 7.73, 95% CI 2.52-23.7), and mortality rate (aOR 6.46, 95% CI 1.87-22.3). Among patients with follow-up CT scans (N = 198), the multivariable analysis revealed that the pneumonia group with a high percentage of lung lesions on admission (aOR 4.74, 95% CI 2.36-9.52), older age (aOR 2.53, 95% CI 1.16-5.51), female sex (aOR 2.41, 95% CI 1.13-5.11), and medical history of hypertension (aOR 2.22, 95% CI 1.09-4.50) independently predicted persistent residual lung lesions.
CONCLUSIONS: AI-based CT quantification of pneumonia provides valuable information beyond qualitative evaluation by physicians, enabling the prediction of critical outcomes and residual lung lesions in patients with COVID-19.","Clinical utilization of artificial intelligence-based COVID-19 pneumonia quantification using chest computed tomography - a multicenter retrospective cohort study in Japan BACKGROUND: Computed tomography (CT) imaging and artificial intelligence (AI)-based analyses have aided in the diagnosis and prediction of the severity of COVID-19. However, the potential of AI-based CT quantification of pneumonia in assessing patients with COVID-19 has not yet been fully explored. This study aimed to investigate the potential of AI-based CT quantification of COVID-19 pneumonia to predict the critical outcomes and clinical characteristics of patients with residual lung lesions.
METHODS: This retrospective cohort study included 1,200 hospitalized patients with COVID-19 from four hospitals. The incidence of critical outcomes (requiring the support of high-flow oxygen or invasive mechanical ventilation or death) and complications during hospitalization (bacterial infection, renal failure, heart failure, thromboembolism, and liver dysfunction) was compared between the groups of pneumonia with high/low-percentage lung lesions, based on AI-based CT quantification. Additionally, 198 patients underwent CT scans 3 months after admission to analyze prognostic factors for residual lung lesions.
RESULTS: The pneumonia group with a high percentage of lung lesions (N = 400) had a higher incidence of critical outcomes and complications during hospitalization than the low percentage group (N = 800). Multivariable analysis demonstrated that AI-based CT quantification of pneumonia was independently associated with critical outcomes (adjusted odds ratio [aOR] 10.5, 95% confidence interval [CI] 5.59-19.7), as well as with oxygen requirement (aOR 6.35, 95% CI 4.60-8.76), IMV requirement (aOR 7.73, 95% CI 2.52-23.7), and mortality rate (aOR 6.46, 95% CI 1.87-22.3). Among patients with follow-up CT scans (N = 198), the multivariable analysis revealed that the pneumonia group with a high percentage of lung lesions on admission (aOR 4.74, 95% CI 2.36-9.52), older age (aOR 2.53, 95% CI 1.16-5.51), female sex (aOR 2.41, 95% CI 1.13-5.11), and medical history of hypertension (aOR 2.22, 95% CI 1.09-4.50) independently predicted persistent residual lung lesions.
CONCLUSIONS: AI-based CT quantification of pneumonia provides valuable information beyond qualitative evaluation by physicians, enabling the prediction of critical outcomes and residual lung lesions in patients with COVID-19.",0,1
38620646,Use of Conventional Chest Imaging and Artificial Intelligence in COVID-19 Infection. A Review of the Literature,"Corbacho Abelaira MD, Corbacho Abelaira F, Ruano-Ravina A, Fernández-Villar A.",Open Respir Arch. 2021 Jan 8;3(1):100078. doi: 10.1016/j.opresp.2020.100078. eCollection 2021 Jan-Mar.,Corbacho Abelaira MD,Open Respir Arch,2021,15-04-2024,PMC7834680,,10.1016/j.opresp.2020.100078,"The coronavirus disease caused by SARS-Cov-2 is a pandemic with millions of confirmed cases around the world and a high death toll. Currently, the real-time polymerase chain reaction (RT-PCR) is the standard diagnostic method for determining COVID-19 infection. Various failures in the detection of the disease by means of laboratory samples have raised certain doubts about the characterisation of the infection and the spread of contacts. In clinical practice, chest radiography (RT) and chest computed tomography (CT) are extremely helpful and have been widely used in the detection and diagnosis of COVID-19. RT is the most common and widely available diagnostic imaging technique, however, its reading by less qualified personnel, in many cases with work overload, causes a high number of errors to be committed. Chest CT can be used for triage, diagnosis, assessment of severity, progression, and response to treatment. Currently, artificial intelligence (AI) algorithms have shown promise in image classification, showing that they can reduce diagnostic errors by at least matching the diagnostic performance of radiologists. This review shows how AI applied to thoracic radiology speeds up and improves diagnosis, allowing to optimise the workflow of radiologists. It can provide an objective evaluation and achieve a reduction in subjectivity and variability. AI can also help to optimise the resources and increase the efficiency in the management of COVID-19 infection.","Use of Conventional Chest Imaging and Artificial Intelligence in COVID-19 Infection. A Review of the Literature The coronavirus disease caused by SARS-Cov-2 is a pandemic with millions of confirmed cases around the world and a high death toll. Currently, the real-time polymerase chain reaction (RT-PCR) is the standard diagnostic method for determining COVID-19 infection. Various failures in the detection of the disease by means of laboratory samples have raised certain doubts about the characterisation of the infection and the spread of contacts. In clinical practice, chest radiography (RT) and chest computed tomography (CT) are extremely helpful and have been widely used in the detection and diagnosis of COVID-19. RT is the most common and widely available diagnostic imaging technique, however, its reading by less qualified personnel, in many cases with work overload, causes a high number of errors to be committed. Chest CT can be used for triage, diagnosis, assessment of severity, progression, and response to treatment. Currently, artificial intelligence (AI) algorithms have shown promise in image classification, showing that they can reduce diagnostic errors by at least matching the diagnostic performance of radiologists. This review shows how AI applied to thoracic radiology speeds up and improves diagnosis, allowing to optimise the workflow of radiologists. It can provide an objective evaluation and achieve a reduction in subjectivity and variability. AI can also help to optimise the resources and increase the efficiency in the management of COVID-19 infection.",1,1
28895064,A mouse model of HIV-associated neurocognitive disorders: a brain-behavior approach to discover disease mechanisms and novel treatments,"Tyor WR, Bimonte-Nelson H.",J Neurovirol. 2018 Apr;24(2):180-184. doi: 10.1007/s13365-017-0572-6. Epub 2017 Sep 11.,Tyor WR,J Neurovirol,2018,13-09-2017,PMC5845816,NIHMS905650,10.1007/s13365-017-0572-6,"HIV-associated neurocognitive disorders (HAND) remain highly prevalent despite combined antiretroviral therapy (cART). Although the most common forms of HAND are mild and identified through neuropsychological testing, there is evidence that with aging these mild forms become more prevalent and may advance to the most severe form of HAND, HIV-associated dementia. Therefore, novel therapies must be developed that can be used adjunctively with cART to prevent deterioration or restore normal cognitive function. In order to develop innovative treatments, animal models are used for preclinical testing. Ideally, a HAND animal model should portray similar mild cognitive deficits that are found in humans. A mouse model of HAND is discussed, which demonstrates mild behavioral deficits and has been used to investigate cART and novel treatments for HAND. This model also shows correlations between abnormal mouse behavior due to HIV in the brain and pathological parameters such as gliosis and neuronal abnormalities. A recent advancement utilizes the object recognition test to monitor mouse behavior before and after treatment. It is postulated that this model is well suited for preclinical testing of novel therapies and provides correlations of mild cognitive impairment with pathological markers that can give further insight into the pathophysiology of HAND.","A mouse model of HIV-associated neurocognitive disorders: a brain-behavior approach to discover disease mechanisms and novel treatments HIV-associated neurocognitive disorders (HAND) remain highly prevalent despite combined antiretroviral therapy (cART). Although the most common forms of HAND are mild and identified through neuropsychological testing, there is evidence that with aging these mild forms become more prevalent and may advance to the most severe form of HAND, HIV-associated dementia. Therefore, novel therapies must be developed that can be used adjunctively with cART to prevent deterioration or restore normal cognitive function. In order to develop innovative treatments, animal models are used for preclinical testing. Ideally, a HAND animal model should portray similar mild cognitive deficits that are found in humans. A mouse model of HAND is discussed, which demonstrates mild behavioral deficits and has been used to investigate cART and novel treatments for HAND. This model also shows correlations between abnormal mouse behavior due to HIV in the brain and pathological parameters such as gliosis and neuronal abnormalities. A recent advancement utilizes the object recognition test to monitor mouse behavior before and after treatment. It is postulated that this model is well suited for preclinical testing of novel therapies and provides correlations of mild cognitive impairment with pathological markers that can give further insight into the pathophysiology of HAND.",1,0
27518438,A Systematic Review of the Prevalence and Pattern of Imaging Defined Post-TB Lung Disease,"Meghji J, Simpson H, Squire SB, Mortimer K.",PLoS One. 2016 Aug 12;11(8):e0161176. doi: 10.1371/journal.pone.0161176. eCollection 2016.,Meghji J,PLoS One,2016,13-08-2016,PMC4982669,,10.1371/journal.pone.0161176,"BACKGROUND: Tuberculosis is an important risk factor for chronic respiratory disease in resource poor settings. The persistence of abnormal spirometry and symptoms after treatment are well described, but the structural abnormalities underlying these changes remain poorly defined, limiting our ability to phenotype post-TB lung disease in to meaningful categories for clinical management, prognostication, and ongoing research. The relationship between post-TB lung damage and patient-centred outcomes including functional impairment, respiratory symptoms, and health related quality of life also remains unclear.
METHODS: We performed a systematic literature review to determine the prevalence and pattern of imaging-defined lung pathology in adults after medical treatment for pleural, miliary, or pulmonary TB disease. Data were collected on study characteristics, and the modality, timing, and findings of thoracic imaging. The proportion of studies relating imaging findings to spirometry results and patient morbidity was recorded. Study quality was assessed using a modified Newcastle-Ottowa score. (Prospero Registration number CRD42015027958).
RESULTS: We identified 37 eligible studies. The principle features seen on CXR were cavitation (8.3-83.7%), bronchiectasis (4.3-11.2%), and fibrosis (25.0-70.4%), but prevalence was highly variable. CT imaging identified a wider range of residual abnormalities than CXR, including nodules (25.0-55.8%), consolidation (3.7-19.2%), and emphysema (15.0-45.0%). The prevalence of cavitation was generally lower (7.4-34.6%) and bronchiectasis higher (35.0-86.0%) on CT vs. CXR imaging. A paucity of prospective data, and data from HIV-infected adults and sub-Saharan Africa (sSA) was noted. Few studies related structural damage to physiological impairment, respiratory symptoms, or patient morbidity.
CONCLUSIONS: Post-TB structural lung pathology is common. Prospective data are required to determine the evolution of this lung damage and its associated morbidity over time. Further data are required from HIV-infected groups and those living in sSA.","A Systematic Review of the Prevalence and Pattern of Imaging Defined Post-TB Lung Disease BACKGROUND: Tuberculosis is an important risk factor for chronic respiratory disease in resource poor settings. The persistence of abnormal spirometry and symptoms after treatment are well described, but the structural abnormalities underlying these changes remain poorly defined, limiting our ability to phenotype post-TB lung disease in to meaningful categories for clinical management, prognostication, and ongoing research. The relationship between post-TB lung damage and patient-centred outcomes including functional impairment, respiratory symptoms, and health related quality of life also remains unclear.
METHODS: We performed a systematic literature review to determine the prevalence and pattern of imaging-defined lung pathology in adults after medical treatment for pleural, miliary, or pulmonary TB disease. Data were collected on study characteristics, and the modality, timing, and findings of thoracic imaging. The proportion of studies relating imaging findings to spirometry results and patient morbidity was recorded. Study quality was assessed using a modified Newcastle-Ottowa score. (Prospero Registration number CRD42015027958).
RESULTS: We identified 37 eligible studies. The principle features seen on CXR were cavitation (8.3-83.7%), bronchiectasis (4.3-11.2%), and fibrosis (25.0-70.4%), but prevalence was highly variable. CT imaging identified a wider range of residual abnormalities than CXR, including nodules (25.0-55.8%), consolidation (3.7-19.2%), and emphysema (15.0-45.0%). The prevalence of cavitation was generally lower (7.4-34.6%) and bronchiectasis higher (35.0-86.0%) on CT vs. CXR imaging. A paucity of prospective data, and data from HIV-infected adults and sub-Saharan Africa (sSA) was noted. Few studies related structural damage to physiological impairment, respiratory symptoms, or patient morbidity.
CONCLUSIONS: Post-TB structural lung pathology is common. Prospective data are required to determine the evolution of this lung damage and its associated morbidity over time. Further data are required from HIV-infected groups and those living in sSA.",0,0
32788602,Comparing different deep learning architectures for classification of chest radiographs,"Bressem KK, Adams LC, Erxleben C, Hamm B, Niehues SM, Vahldiek JL.",Sci Rep. 2020 Aug 12;10(1):13590. doi: 10.1038/s41598-020-70479-z.,Bressem KK,Sci Rep,2020,14-08-2020,PMC7423963,,10.1038/s41598-020-70479-z,"Chest radiographs are among the most frequently acquired images in radiology and are often the subject of computer vision research. However, most of the models used to classify chest radiographs are derived from openly available deep neural networks, trained on large image datasets. These datasets differ from chest radiographs in that they are mostly color images and have substantially more labels. Therefore, very deep convolutional neural networks (CNN) designed for ImageNet and often representing more complex relationships, might not be required for the comparably simpler task of classifying medical image data. Sixteen different architectures of CNN were compared regarding the classification performance on two openly available datasets, the CheXpert and COVID-19 Image Data Collection. Areas under the receiver operating characteristics curves (AUROC) between 0.83 and 0.89 could be achieved on the CheXpert dataset. On the COVID-19 Image Data Collection, all models showed an excellent ability to detect COVID-19 and non-COVID pneumonia with AUROC values between 0.983 and 0.998. It could be observed, that more shallow networks may achieve results comparable to their deeper and more complex counterparts with shorter training times, enabling classification performances on medical image data close to the state-of-the-art methods even when using limited hardware.","Comparing different deep learning architectures for classification of chest radiographs Chest radiographs are among the most frequently acquired images in radiology and are often the subject of computer vision research. However, most of the models used to classify chest radiographs are derived from openly available deep neural networks, trained on large image datasets. These datasets differ from chest radiographs in that they are mostly color images and have substantially more labels. Therefore, very deep convolutional neural networks (CNN) designed for ImageNet and often representing more complex relationships, might not be required for the comparably simpler task of classifying medical image data. Sixteen different architectures of CNN were compared regarding the classification performance on two openly available datasets, the CheXpert and COVID-19 Image Data Collection. Areas under the receiver operating characteristics curves (AUROC) between 0.83 and 0.89 could be achieved on the CheXpert dataset. On the COVID-19 Image Data Collection, all models showed an excellent ability to detect COVID-19 and non-COVID pneumonia with AUROC values between 0.983 and 0.998. It could be observed, that more shallow networks may achieve results comparable to their deeper and more complex counterparts with shorter training times, enabling classification performances on medical image data close to the state-of-the-art methods even when using limited hardware.",1,0
34580318,A comparative study on image-based snake identification using machine learning,"Rajabizadeh M, Rezghi M.",Sci Rep. 2021 Sep 27;11(1):19142. doi: 10.1038/s41598-021-96031-1.,Rajabizadeh M,Sci Rep,2021,28-09-2021,PMC8476526,,10.1038/s41598-021-96031-1,"Automated snake image identification is important from different points of view, most importantly, snake bite management. Auto-identification of snake images might help the avoidance of venomous snakes and also providing better treatment for patients. In this study, for the first time, it's been attempted to compare the accuracy of a series of state-of-the-art machine learning methods, ranging from the holistic to neural network algorithms. The study is performed on six snake species in Lar National Park, Tehran Province, Iran. In this research, the holistic methods [k-nearest neighbors (kNN), support vector machine (SVM) and logistic regression (LR)] are used in combination with a dimension reduction approach [principle component analysis (PCA) and linear discriminant analysis (LDA)] as the feature extractor. In holistic methods (kNN, SVM, LR), the classifier in combination with PCA does not yield an accuracy of more than 50%, But the use of LDA to extract the important features significantly improves the performance of the classifier. A combination of LDA and SVM (kernel = 'rbf') is achieved to a test accuracy of 84%. Compared to holistic methods, convolutional neural networks show similar to better performance, and accuracy reaches 93.16% using MobileNetV2. Visualizing intermediate activation layers in VGG model reveals that just in deep activation layers, the color pattern and the shape of the snake contribute to the discrimination of snake species. This study presents MobileNetV2 as a powerful deep convolutional neural network algorithm for snake image classification that could be used even on mobile devices. This finding pave the road for generating mobile applications for snake image identification.","A comparative study on image-based snake identification using machine learning Automated snake image identification is important from different points of view, most importantly, snake bite management. Auto-identification of snake images might help the avoidance of venomous snakes and also providing better treatment for patients. In this study, for the first time, it's been attempted to compare the accuracy of a series of state-of-the-art machine learning methods, ranging from the holistic to neural network algorithms. The study is performed on six snake species in Lar National Park, Tehran Province, Iran. In this research, the holistic methods [k-nearest neighbors (kNN), support vector machine (SVM) and logistic regression (LR)] are used in combination with a dimension reduction approach [principle component analysis (PCA) and linear discriminant analysis (LDA)] as the feature extractor. In holistic methods (kNN, SVM, LR), the classifier in combination with PCA does not yield an accuracy of more than 50%, But the use of LDA to extract the important features significantly improves the performance of the classifier. A combination of LDA and SVM (kernel = 'rbf') is achieved to a test accuracy of 84%. Compared to holistic methods, convolutional neural networks show similar to better performance, and accuracy reaches 93.16% using MobileNetV2. Visualizing intermediate activation layers in VGG model reveals that just in deep activation layers, the color pattern and the shape of the snake contribute to the discrimination of snake species. This study presents MobileNetV2 as a powerful deep convolutional neural network algorithm for snake image classification that could be used even on mobile devices. This finding pave the road for generating mobile applications for snake image identification.",1,0
35751196,Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0,"Agarwal M, Agarwal S, Saba L, Chabert GL, Gupta S, Carriero A, Pasche A, Danna P, Mehmedovic A, Faa G, Shrivastava S, Jain K, Jain H, Jujaray T, Singh IM, Turk M, Chadha PS, Johri AM, Khanna NN, Mavrogeni S, Laird JR, Sobel DW, Miner M, Balestrieri A, Sfikakis PP, Tsoulfas G, Misra DP, Agarwal V, Kitas GD, Teji JS, Al-Maini M, Dhanjil SK, Nicolaides A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Yadav RR, Nagy F, Kincses ZT, Ruzsa Z, Naidu S, Viskovic K, Kalra MK, Suri JS.",Comput Biol Med. 2022 Jul;146:105571. doi: 10.1016/j.compbiomed.2022.105571. Epub 2022 May 21.,Agarwal M,Comput Biol Med,2022,25-06-2022,PMC9123805,,10.1016/j.compbiomed.2022.105571,"BACKGROUND: COVLIAS 1.0: an automated lung segmentation was designed for COVID-19 diagnosis. It has issues related to storage space and speed. This study shows that COVLIAS 2.0 uses pruned AI (PAI) networks for improving both storage and speed, wiliest high performance on lung segmentation and lesion localization.
METHOD: ology: The proposed study uses multicenter ∼9,000 CT slices from two different nations, namely, CroMed from Croatia (80 patients, experimental data), and NovMed from Italy (72 patients, validation data). We hypothesize that by using pruning and evolutionary optimization algorithms, the size of the AI models can be reduced significantly, ensuring optimal performance. Eight different pruning techniques (i) differential evolution (DE), (ii) genetic algorithm (GA), (iii) particle swarm optimization algorithm (PSO), and (iv) whale optimization algorithm (WO) in two deep learning frameworks (i) Fully connected network (FCN) and (ii) SegNet were designed. COVLIAS 2.0 was validated using ""Unseen NovMed"" and benchmarked against MedSeg. Statistical tests for stability and reliability were also conducted.
RESULTS: Pruning algorithms (i) FCN-DE, (ii) FCN-GA, (iii) FCN-PSO, and (iv) FCN-WO showed improvement in storage by 92.4%, 95.3%, 98.7%, and 99.8% respectively when compared against solo FCN, and (v) SegNet-DE, (vi) SegNet-GA, (vii) SegNet-PSO, and (viii) SegNet-WO showed improvement by 97.1%, 97.9%, 98.8%, and 99.2% respectively when compared against solo SegNet. AUC > 0.94 (p < 0.0001) on CroMed and > 0.86 (p < 0.0001) on NovMed data set for all eight EA model. PAI <0.25 s per image. DenseNet-121-based Grad-CAM heatmaps showed validation on glass ground opacity lesions.
CONCLUSIONS: Eight PAI networks that were successfully validated are five times faster, storage efficient, and could be used in clinical settings.","Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0 BACKGROUND: COVLIAS 1.0: an automated lung segmentation was designed for COVID-19 diagnosis. It has issues related to storage space and speed. This study shows that COVLIAS 2.0 uses pruned AI (PAI) networks for improving both storage and speed, wiliest high performance on lung segmentation and lesion localization.
METHOD: ology: The proposed study uses multicenter ∼9,000 CT slices from two different nations, namely, CroMed from Croatia (80 patients, experimental data), and NovMed from Italy (72 patients, validation data). We hypothesize that by using pruning and evolutionary optimization algorithms, the size of the AI models can be reduced significantly, ensuring optimal performance. Eight different pruning techniques (i) differential evolution (DE), (ii) genetic algorithm (GA), (iii) particle swarm optimization algorithm (PSO), and (iv) whale optimization algorithm (WO) in two deep learning frameworks (i) Fully connected network (FCN) and (ii) SegNet were designed. COVLIAS 2.0 was validated using ""Unseen NovMed"" and benchmarked against MedSeg. Statistical tests for stability and reliability were also conducted.
RESULTS: Pruning algorithms (i) FCN-DE, (ii) FCN-GA, (iii) FCN-PSO, and (iv) FCN-WO showed improvement in storage by 92.4%, 95.3%, 98.7%, and 99.8% respectively when compared against solo FCN, and (v) SegNet-DE, (vi) SegNet-GA, (vii) SegNet-PSO, and (viii) SegNet-WO showed improvement by 97.1%, 97.9%, 98.8%, and 99.2% respectively when compared against solo SegNet. AUC > 0.94 (p < 0.0001) on CroMed and > 0.86 (p < 0.0001) on NovMed data set for all eight EA model. PAI <0.25 s per image. DenseNet-121-based Grad-CAM heatmaps showed validation on glass ground opacity lesions.
CONCLUSIONS: Eight PAI networks that were successfully validated are five times faster, storage efficient, and could be used in clinical settings.",1,1
34523805,Peripheral granular lymphocytopenia and dysmorphic leukocytosis as simple prognostic markers in COVID-19,"Horiuchi Y, Hayashi F, Iwasaki Y, Matsuzaki A, Nishibe K, Kaniyu K, Marutani S, Saito K, Matsuoka S, Uchihashi K, Miida T, Ai T, Tabe Y.",Int J Lab Hematol. 2021 Dec;43(6):1309-1318. doi: 10.1111/ijlh.13696. Epub 2021 Sep 15.,Horiuchi Y,Int J Lab Hematol,2021,15-09-2021,PMC8653062,,10.1111/ijlh.13696,"INTRODUCTION: Developing prognostic markers can be useful for clinical decision-making. Peripheral blood (PB) examination is simple and basic that can be performed in any facility. We aimed to investigate whether PB examination can predict prognosis in coronavirus disease (COVID-19).
METHODS: Complete blood count (CBC) and PB cell morphology were examined in 38 healthy controls (HCs) and 40 patients with COVID-19. Patients with COVID-19, including 26 mild and 14 severe cases, were hospitalized in Juntendo University Hospital (Tokyo, Japan) between April 1 and August 6, 2020. PB examinations were performed using Sysmex XN-3000 automated hematology analyzer and Sysmex DI-60 employing the convolutional neural network-based automatic image-recognition system.
RESULTS: Compared with mild cases, severe cases showed a significantly higher incidence of anemia, lymphopenia, and leukocytosis (P < .001). Granular lymphocyte counts were normal or higher in mild cases and persistently decreased in fatal cases. Temporary increase in granular lymphocytes was associated with survival of patients with severe infection. Red cell distribution width was significantly higher in severe cases than in mild cases (P < .001). Neutrophil dysplasia was consistently observed in COVID-19 cases, but not in HCs. Levels of giant neutrophils and toxic granulation/Döhle bodies were increased in severe cases.
CONCLUSION: Basic PB examination can be useful to predict the prognosis of COVID-19, by detecting SARS-CoV-2 infection-induced multi-lineage changes in blood cell counts and morphological anomalies. These changes were dynamically correlated with disease severity and may be associated with disruption of hematopoiesis and the immunological system due to bone marrow stress in severe infection.","Peripheral granular lymphocytopenia and dysmorphic leukocytosis as simple prognostic markers in COVID-19 INTRODUCTION: Developing prognostic markers can be useful for clinical decision-making. Peripheral blood (PB) examination is simple and basic that can be performed in any facility. We aimed to investigate whether PB examination can predict prognosis in coronavirus disease (COVID-19).
METHODS: Complete blood count (CBC) and PB cell morphology were examined in 38 healthy controls (HCs) and 40 patients with COVID-19. Patients with COVID-19, including 26 mild and 14 severe cases, were hospitalized in Juntendo University Hospital (Tokyo, Japan) between April 1 and August 6, 2020. PB examinations were performed using Sysmex XN-3000 automated hematology analyzer and Sysmex DI-60 employing the convolutional neural network-based automatic image-recognition system.
RESULTS: Compared with mild cases, severe cases showed a significantly higher incidence of anemia, lymphopenia, and leukocytosis (P < .001). Granular lymphocyte counts were normal or higher in mild cases and persistently decreased in fatal cases. Temporary increase in granular lymphocytes was associated with survival of patients with severe infection. Red cell distribution width was significantly higher in severe cases than in mild cases (P < .001). Neutrophil dysplasia was consistently observed in COVID-19 cases, but not in HCs. Levels of giant neutrophils and toxic granulation/Döhle bodies were increased in severe cases.
CONCLUSION: Basic PB examination can be useful to predict the prognosis of COVID-19, by detecting SARS-CoV-2 infection-induced multi-lineage changes in blood cell counts and morphological anomalies. These changes were dynamically correlated with disease severity and may be associated with disruption of hematopoiesis and the immunological system due to bone marrow stress in severe infection.",0,0
38099049,"The Role and Impact of Artificial Intelligence in Addressing Sexually Transmitted Infections, Nonvenereal Genital Diseases, Sexual Health, and Wellness","Mehta N, Gupta S, Kularathne Y.",Indian Dermatol Online J. 2023 Oct 27;14(6):793-798. doi: 10.4103/idoj.idoj_426_23. eCollection 2023 Nov-Dec.,Mehta N,Indian Dermatol Online J,2023,15-12-2023,PMC10718125,,10.4103/idoj.idoj_426_23,"The potential of artificial intelligence (AI) in diagnosing and managing sexually transmitted infections (STIs), nonvenereal genital diseases, and overall sexual health is immense. AI shows promise in STI screening and diagnosis through image recognition and patient data analysis, potentially increasing diagnostic accuracy while ensuring inclusivity. AI can fuel the transformation of e-health and direct-to-consumer services, enhancing targeted screening and personalized interventions while improving the user-friendliness of services. There is a significant role for AI in sexual education, particularly its use in interactive, empathetic chatbots. AI's integration into health care as a decision support tool for primary health-care providers can boost real-time diagnostic accuracy. Furthermore, AI's use in big data can enhance real-time epidemiology, predictive analysis, and directed interventions at population levels. However, challenges such as real-world diagnostic accuracy, liability, privacy concerns, and ethical dilemmas persist. Future directions include an emphasis on inclusivity, language accommodation, and swift research-to-practice transitions. Collaboration among policymakers, researchers, and health-care providers is needed to leverage AI's transformative potential in sexual health.","The Role and Impact of Artificial Intelligence in Addressing Sexually Transmitted Infections, Nonvenereal Genital Diseases, Sexual Health, and Wellness The potential of artificial intelligence (AI) in diagnosing and managing sexually transmitted infections (STIs), nonvenereal genital diseases, and overall sexual health is immense. AI shows promise in STI screening and diagnosis through image recognition and patient data analysis, potentially increasing diagnostic accuracy while ensuring inclusivity. AI can fuel the transformation of e-health and direct-to-consumer services, enhancing targeted screening and personalized interventions while improving the user-friendliness of services. There is a significant role for AI in sexual education, particularly its use in interactive, empathetic chatbots. AI's integration into health care as a decision support tool for primary health-care providers can boost real-time diagnostic accuracy. Furthermore, AI's use in big data can enhance real-time epidemiology, predictive analysis, and directed interventions at population levels. However, challenges such as real-world diagnostic accuracy, liability, privacy concerns, and ethical dilemmas persist. Future directions include an emphasis on inclusivity, language accommodation, and swift research-to-practice transitions. Collaboration among policymakers, researchers, and health-care providers is needed to leverage AI's transformative potential in sexual health.",0,1
39297572,Artificial intelligence strengthenes cervical cancer screening - present and future,"Wu T, Lucas E, Zhao F, Basu P, Qiao Y.",Cancer Biol Med. 2024 Sep 19;21(10):864-79. doi: 10.20892/j.issn.2095-3941.2024.0198.,Wu T,Cancer Biol Med,2024,19-09-2024,PMC11523278,,10.20892/j.issn.2095-3941.2024.0198,"Cervical cancer is a severe threat to women's health. The majority of cervical cancer cases occur in developing countries. The WHO has proposed screening 70% of women with high-performance tests between 35 and 45 years of age by 2030 to accelerate the elimination of cervical cancer. Due to an inadequate health infrastructure and organized screening strategy, most low- and middle-income countries are still far from achieving this goal. As part of the efforts to increase performance of cervical cancer screening, it is necessary to investigate the most accurate, efficient, and effective methods and strategies. Artificial intelligence (AI) is rapidly expanding its application in cancer screening and diagnosis and deep learning algorithms have offered human-like interpretation capabilities on various medical images. AI will soon have a more significant role in improving the implementation of cervical cancer screening, management, and follow-up. This review aims to report the state of AI with respect to cervical cancer screening. We discuss the primary AI applications and development of AI technology for image recognition applied to detection of abnormal cytology and cervical neoplastic diseases, as well as the challenges that we anticipate in the future.","Artificial intelligence strengthenes cervical cancer screening - present and future Cervical cancer is a severe threat to women's health. The majority of cervical cancer cases occur in developing countries. The WHO has proposed screening 70% of women with high-performance tests between 35 and 45 years of age by 2030 to accelerate the elimination of cervical cancer. Due to an inadequate health infrastructure and organized screening strategy, most low- and middle-income countries are still far from achieving this goal. As part of the efforts to increase performance of cervical cancer screening, it is necessary to investigate the most accurate, efficient, and effective methods and strategies. Artificial intelligence (AI) is rapidly expanding its application in cancer screening and diagnosis and deep learning algorithms have offered human-like interpretation capabilities on various medical images. AI will soon have a more significant role in improving the implementation of cervical cancer screening, management, and follow-up. This review aims to report the state of AI with respect to cervical cancer screening. We discuss the primary AI applications and development of AI technology for image recognition applied to detection of abnormal cytology and cervical neoplastic diseases, as well as the challenges that we anticipate in the future.",1,0
30409313,Utility of CD8 score by automated quantitative image analysis in head and neck squamous cell carcinoma,"Hartman DJ, Ahmad F, Ferris RL, Rimm DL, Pantanowitz L.",Oral Oncol. 2018 Nov;86:278-287. doi: 10.1016/j.oraloncology.2018.10.005. Epub 2018 Oct 11.,Hartman DJ,Oral Oncol,2018,10-11-2018,PMC6260977,NIHMS1510193,10.1016/j.oraloncology.2018.10.005,"INTRODUCTION: In head and neck squamous cell carcinoma (HNSCC) high numbers of tumor infiltrating CD8 T cells in the tumor microenvironment are associated with better outcome. However, no investigators have employed automated image analysis on whole slide images to permit CD8 scores for use in clinical practice. The aim of this study was to develop and validate an image analysis algorithm to automatically quantify CD8 T cells in patients with oropharyngeal HNSCC.
MATERIALS AND METHODS: Using brightfield image analysis results were cross-validated with fluorescence based quantification (AQUA™). A nuclear image algorithm designed to run on whole slide images was optimized to manual count. The algorithm was locked down and used on a cohort of whole tissue sections from HNSCC patients. Multivariate clinicopathologic parameters and outcomes were statistically correlated with image analysis results.
RESULTS: Linear correlation between manual counts and the customized CD8 algorithm was 0.943. A total of 74 oropharyngeal HNSCC cases were analyzed for CD8 immune cell infiltrate using this image analysis algorithm. A CD8 immune cell density above 136 cells/mm2 was associated with median survival of 18 years compared to 5 years. When multivariate modeling was performed, HPV infection was the only predictor of survival; however, when HPV was excluded only CD8 cell density predicts survival.
CONCLUSIONS: We report the successful technical development and clinical validation of an image algorithm to automate CD8 immune cell density for oropharyngeal HNSCC. Employing brightfield image analysis on entire tumor sections instead of tumor subcompartments permits this strategy to be widely implemented.","Utility of CD8 score by automated quantitative image analysis in head and neck squamous cell carcinoma INTRODUCTION: In head and neck squamous cell carcinoma (HNSCC) high numbers of tumor infiltrating CD8 T cells in the tumor microenvironment are associated with better outcome. However, no investigators have employed automated image analysis on whole slide images to permit CD8 scores for use in clinical practice. The aim of this study was to develop and validate an image analysis algorithm to automatically quantify CD8 T cells in patients with oropharyngeal HNSCC.
MATERIALS AND METHODS: Using brightfield image analysis results were cross-validated with fluorescence based quantification (AQUA™). A nuclear image algorithm designed to run on whole slide images was optimized to manual count. The algorithm was locked down and used on a cohort of whole tissue sections from HNSCC patients. Multivariate clinicopathologic parameters and outcomes were statistically correlated with image analysis results.
RESULTS: Linear correlation between manual counts and the customized CD8 algorithm was 0.943. A total of 74 oropharyngeal HNSCC cases were analyzed for CD8 immune cell infiltrate using this image analysis algorithm. A CD8 immune cell density above 136 cells/mm2 was associated with median survival of 18 years compared to 5 years. When multivariate modeling was performed, HPV infection was the only predictor of survival; however, when HPV was excluded only CD8 cell density predicts survival.
CONCLUSIONS: We report the successful technical development and clinical validation of an image algorithm to automate CD8 immune cell density for oropharyngeal HNSCC. Employing brightfield image analysis on entire tumor sections instead of tumor subcompartments permits this strategy to be widely implemented.",1,0
33480966,Prevalence of SARS-CoV-2 Infection in Children and Their Parents in Southwest Germany,"Tönshoff B, Müller B, Elling R, Renk H, Meissner P, Hengel H, Garbade SF, Kieser M, Jeltsch K, Grulich-Henn J, Euler J, Stich M, Chobanyan-Jürgens K, Zernickel M, Janda A, Wölfle L, Stamminger T, Iftner T, Ganzenmueller T, Schmitt C, Görne T, Laketa V, Olberg S, Plaszczyca A, Cortese M, Bartenschlager R, Pape C, Remme R, Huzly D, Panning M, Weigang S, Giese S, Ciminski K, Ankerhold J, Kochs G, Schwemmle M, Handgretinger R, Niemeyer CM, Engel C, Kern WV, Hoffmann GF, Franz AR, Henneke P, Debatin KM, Kräusslich HG.",JAMA Pediatr. 2021 Jun 1;175(6):586-593. doi: 10.1001/jamapediatrics.2021.0001.,Tönshoff B,JAMA Pediatr,2021,22-01-2021,PMC7823424,,10.1001/jamapediatrics.2021.0001,"IMPORTANCE: School and daycare closures were enforced as measures to confine the novel coronavirus disease 2019 (COVID-19) pandemic, based on the assumption that young children may play a key role in severe acute respiratory coronavirus 2 (SARS-CoV-2) spread. Given the grave consequences of contact restrictions for children, a better understanding of their contribution to the COVID-19 pandemic is of great importance.
OBJECTIVE: To describe the rate of SARS-CoV-2 infections and the seroprevalence of SARS-CoV-2 antibodies in children aged 1 to 10 years, compared with a corresponding parent of each child, in a population-based sample.
DESIGN, SETTING, AND PARTICIPANTS: This large-scale, multicenter, cross-sectional investigation (the COVID-19 BaWü study) enrolled children aged 1 to 10 years and a corresponding parent between April 22 and May 15, 2020, in southwest Germany.
EXPOSURES: Potential exposure to SARS-CoV-2.
MAIN OUTCOMES AND MEASURES: The main outcomes were infection and seroprevalence of SARS-CoV-2. Participants were tested for SARS-CoV-2 RNA from nasopharyngeal swabs by reverse transcription-polymerase chain reaction and SARS-CoV-2 specific IgG antibodies in serum by enzyme-linked immunosorbent assays and immunofluorescence tests. Discordant results were clarified by electrochemiluminescence immunoassays, a second enzyme-linked immunosorbent assay, or an in-house Luminex-based assay.
RESULTS: This study included 4964 participants: 2482 children (median age, 6 [range, 1-10] years; 1265 boys [51.0%]) and 2482 parents (median age, 40 [range, 23-66] years; 615 men [24.8%]). Two participants (0.04%) tested positive for SARS-CoV-2 RNA. The estimated SARS-CoV-2 seroprevalence was low in parents (1.8% [95% CI, 1.2-2.4%]) and 3-fold lower in children (0.6% [95% CI, 0.3-1.0%]). Among 56 families with at least 1 child or parent with seropositivity, the combination of a parent with seropositivity and a corresponding child with seronegativity was 4.3 (95% CI, 1.19-15.52) times higher than the combination of a parent who was seronegative and a corresponding child with seropositivity. We observed virus-neutralizing activity for 66 of 70 IgG-positive serum samples (94.3%).
CONCLUSIONS AND RELEVANCE: In this cross-sectional study, the spread of SARS-CoV-2 infection during a period of lockdown in southwest Germany was particularly low in children aged 1 to 10 years. Accordingly, it is unlikely that children have boosted the pandemic. This SARS-CoV-2 prevalence study, which appears to be the largest focusing on children, is instructive for how ad hoc mass testing provides the basis for rational political decision-making in a pandemic.","Prevalence of SARS-CoV-2 Infection in Children and Their Parents in Southwest Germany IMPORTANCE: School and daycare closures were enforced as measures to confine the novel coronavirus disease 2019 (COVID-19) pandemic, based on the assumption that young children may play a key role in severe acute respiratory coronavirus 2 (SARS-CoV-2) spread. Given the grave consequences of contact restrictions for children, a better understanding of their contribution to the COVID-19 pandemic is of great importance.
OBJECTIVE: To describe the rate of SARS-CoV-2 infections and the seroprevalence of SARS-CoV-2 antibodies in children aged 1 to 10 years, compared with a corresponding parent of each child, in a population-based sample.
DESIGN, SETTING, AND PARTICIPANTS: This large-scale, multicenter, cross-sectional investigation (the COVID-19 BaWü study) enrolled children aged 1 to 10 years and a corresponding parent between April 22 and May 15, 2020, in southwest Germany.
EXPOSURES: Potential exposure to SARS-CoV-2.
MAIN OUTCOMES AND MEASURES: The main outcomes were infection and seroprevalence of SARS-CoV-2. Participants were tested for SARS-CoV-2 RNA from nasopharyngeal swabs by reverse transcription-polymerase chain reaction and SARS-CoV-2 specific IgG antibodies in serum by enzyme-linked immunosorbent assays and immunofluorescence tests. Discordant results were clarified by electrochemiluminescence immunoassays, a second enzyme-linked immunosorbent assay, or an in-house Luminex-based assay.
RESULTS: This study included 4964 participants: 2482 children (median age, 6 [range, 1-10] years; 1265 boys [51.0%]) and 2482 parents (median age, 40 [range, 23-66] years; 615 men [24.8%]). Two participants (0.04%) tested positive for SARS-CoV-2 RNA. The estimated SARS-CoV-2 seroprevalence was low in parents (1.8% [95% CI, 1.2-2.4%]) and 3-fold lower in children (0.6% [95% CI, 0.3-1.0%]). Among 56 families with at least 1 child or parent with seropositivity, the combination of a parent with seropositivity and a corresponding child with seronegativity was 4.3 (95% CI, 1.19-15.52) times higher than the combination of a parent who was seronegative and a corresponding child with seropositivity. We observed virus-neutralizing activity for 66 of 70 IgG-positive serum samples (94.3%).
CONCLUSIONS AND RELEVANCE: In this cross-sectional study, the spread of SARS-CoV-2 infection during a period of lockdown in southwest Germany was particularly low in children aged 1 to 10 years. Accordingly, it is unlikely that children have boosted the pandemic. This SARS-CoV-2 prevalence study, which appears to be the largest focusing on children, is instructive for how ad hoc mass testing provides the basis for rational political decision-making in a pandemic.",0,0
33188678,Outcomes for Out-of-Hospital Cardiac Arrest in the United States During the Coronavirus Disease 2019 Pandemic,"Chan PS, Girotra S, Tang Y, Al-Araji R, Nallamothu BK, McNally B.",JAMA Cardiol. 2021 Mar 1;6(3):296-303. doi: 10.1001/jamacardio.2020.6210.,Chan PS,JAMA Cardiol,2021,14-11-2020,PMC7666759,,10.1001/jamacardio.2020.6210,"IMPORTANCE: Recent reports from communities severely affected by the coronavirus disease 2019 (COVID-19) pandemic found lower rates of sustained return of spontaneous circulation (ROSC) for out-of-hospital cardiac arrest (OHCA). Whether the pandemic has affected OHCA outcomes more broadly is unknown.
OBJECTIVE: To assess the association between the COVID-19 pandemic and OHCA outcomes, including in areas with low and moderate COVID-19 disease burden.
DESIGN, SETTING, AND PARTICIPANTS: This study used a large US registry of OHCAs to compare outcomes during the pandemic period of March 16 through April 30, 2020, with those from March 16 through April 30, 2019. Cases were geocoded to US counties, and the COVID-19 mortality rate in each county was categorized as very low (0-25 per million residents), low (26-100 per million residents), moderate (101-250 per million residents), high (251-500 per million residents), or very high (>500 per million residents). As additional controls, the study compared OHCA outcomes during the prepandemic period (January through February) and peripandemic period (March 1 through 15).
EXPOSURE: The COVID-19 pandemic.
MAIN OUTCOMES AND MEASURES: Sustained ROSC (≥20 minutes), survival to discharge, and OHCA incidence.
RESULTS: A total of 19 303 OHCAs occurred from March 16 through April 30 in both years, with 9863 cases in 2020 (mean [SD] age, 62.6 [19.3] years; 6040 men [61.3%]) and 9440 in 2019 (mean [SD] age, 62.2 [19.2] years; 5922 men [62.7%]). During the pandemic, rates of sustained ROSC were lower than in 2019 (23.0% vs 29.8%; adjusted rate ratio, 0.82 [95% CI, 0.78-0.87]; P < .001). Sustained ROSC rates were lower by between 21% (286 of 1429 [20.0%] in 2020 vs 305 of 1130 [27.0%] in 2019; adjusted RR, 0.79 [95% CI, 0.65-0.97]) and 33% (149 of 863 [17.3%] in 2020 vs 192 of 667 [28.8%] in 2019; adjusted RR, 0.67 [95% CI, 0.56-0.80]) in communities with high or very high COVID-19 mortality, respectively; however, rates of sustained ROSC were also lower by 11% (583 of 2317 [25.2%] in 2020 vs 740 of 2549 [29.0%] in 2019; adjusted RR, 0.89 [95% CI, 0.81-0.98]) to 15% (889 of 3495 [25.4%] in 2020 vs 1109 of 3532 [31.4%] in 2019; adjusted RR, 0.85 [95% CI, 0.78-0.93]) in communities with very low and low COVID-19 mortality. Among emergency medical services agencies with complete data on hospital survival (7085 total patients), survival to discharge was lower during the pandemic compared with 2019 (6.6% vs 9.8%; adjusted RR, 0.83 [95% CI, 0.69-1.00]; P = .048), primarily in communities with moderate to very high COVID-19 mortality (interaction P = .049). Incidence of OHCA was higher than in 2019, but the increase was largely observed in communities with high COVID-19 mortality (adjusted mean difference, 38.6 [95% CI, 37.1-40.1] per million residents) and very high COVID-19 mortality (adjusted mean difference, 28.7 [95% CI, 26.7-30.6] per million residents). In contrast, there was no difference in rates of sustained ROSC or survival to discharge during the prepandemic and peripandemic periods in 2020 vs 2019.
CONCLUSIONS AND RELEVANCE: Early during the pandemic, rates of sustained ROSC for OHCA were lower throughout the US, even in communities with low COVID-19 mortality rates. Overall survival was lower, primarily in communities with moderate or high COVID-19 mortality.","Outcomes for Out-of-Hospital Cardiac Arrest in the United States During the Coronavirus Disease 2019 Pandemic IMPORTANCE: Recent reports from communities severely affected by the coronavirus disease 2019 (COVID-19) pandemic found lower rates of sustained return of spontaneous circulation (ROSC) for out-of-hospital cardiac arrest (OHCA). Whether the pandemic has affected OHCA outcomes more broadly is unknown.
OBJECTIVE: To assess the association between the COVID-19 pandemic and OHCA outcomes, including in areas with low and moderate COVID-19 disease burden.
DESIGN, SETTING, AND PARTICIPANTS: This study used a large US registry of OHCAs to compare outcomes during the pandemic period of March 16 through April 30, 2020, with those from March 16 through April 30, 2019. Cases were geocoded to US counties, and the COVID-19 mortality rate in each county was categorized as very low (0-25 per million residents), low (26-100 per million residents), moderate (101-250 per million residents), high (251-500 per million residents), or very high (>500 per million residents). As additional controls, the study compared OHCA outcomes during the prepandemic period (January through February) and peripandemic period (March 1 through 15).
EXPOSURE: The COVID-19 pandemic.
MAIN OUTCOMES AND MEASURES: Sustained ROSC (≥20 minutes), survival to discharge, and OHCA incidence.
RESULTS: A total of 19 303 OHCAs occurred from March 16 through April 30 in both years, with 9863 cases in 2020 (mean [SD] age, 62.6 [19.3] years; 6040 men [61.3%]) and 9440 in 2019 (mean [SD] age, 62.2 [19.2] years; 5922 men [62.7%]). During the pandemic, rates of sustained ROSC were lower than in 2019 (23.0% vs 29.8%; adjusted rate ratio, 0.82 [95% CI, 0.78-0.87]; P < .001). Sustained ROSC rates were lower by between 21% (286 of 1429 [20.0%] in 2020 vs 305 of 1130 [27.0%] in 2019; adjusted RR, 0.79 [95% CI, 0.65-0.97]) and 33% (149 of 863 [17.3%] in 2020 vs 192 of 667 [28.8%] in 2019; adjusted RR, 0.67 [95% CI, 0.56-0.80]) in communities with high or very high COVID-19 mortality, respectively; however, rates of sustained ROSC were also lower by 11% (583 of 2317 [25.2%] in 2020 vs 740 of 2549 [29.0%] in 2019; adjusted RR, 0.89 [95% CI, 0.81-0.98]) to 15% (889 of 3495 [25.4%] in 2020 vs 1109 of 3532 [31.4%] in 2019; adjusted RR, 0.85 [95% CI, 0.78-0.93]) in communities with very low and low COVID-19 mortality. Among emergency medical services agencies with complete data on hospital survival (7085 total patients), survival to discharge was lower during the pandemic compared with 2019 (6.6% vs 9.8%; adjusted RR, 0.83 [95% CI, 0.69-1.00]; P = .048), primarily in communities with moderate to very high COVID-19 mortality (interaction P = .049). Incidence of OHCA was higher than in 2019, but the increase was largely observed in communities with high COVID-19 mortality (adjusted mean difference, 38.6 [95% CI, 37.1-40.1] per million residents) and very high COVID-19 mortality (adjusted mean difference, 28.7 [95% CI, 26.7-30.6] per million residents). In contrast, there was no difference in rates of sustained ROSC or survival to discharge during the prepandemic and peripandemic periods in 2020 vs 2019.
CONCLUSIONS AND RELEVANCE: Early during the pandemic, rates of sustained ROSC for OHCA were lower throughout the US, even in communities with low COVID-19 mortality rates. Overall survival was lower, primarily in communities with moderate or high COVID-19 mortality.",0,0
29451412,Development and validation of a radiomic signature to predict HPV (p16) status from standard CT imaging: a multicenter study,"Leijenaar RT, Bogowicz M, Jochems A, Hoebers FJ, Wesseling FW, Huang SH, Chan B, Waldron JN, O'Sullivan B, Rietveld D, Leemans CR, Brakenhoff RH, Riesterer O, Tanadini-Lang S, Guckenberger M, Ikenberg K, Lambin P.",Br J Radiol. 2018 Jun;91(1086):20170498. doi: 10.1259/bjr.20170498. Epub 2018 Mar 22.,Leijenaar RT,Br J Radiol,2018,17-02-2018,PMC6223271,,10.1259/bjr.20170498,"OBJECTIVES: Human papillomavirus (HPV) positive oropharyngeal cancer (oropharyngeal squamous cell carcinoma, OPSCC) is biologically and clinically different from HPV negative OPSCC. Here, we evaluate the use of a radiomic approach to identify the HPV status of OPSCC.
METHODS: Four independent cohorts, totaling 778 OPSCC patients with HPV determined by p16 were collected. We randomly assigned 80% of all data for model training (N = 628) and 20% for validation (N = 150). On the pre-treatment CT images, 902 radiomic features were calculated from the gross tumor volume. Multivariable modeling was performed using least absolute shrinkage and selection operator. To assess the impact of CT artifacts in predicting HPV (p16), a model was developed on all training data (M<sub>all</sub>) and on the artifact-free subset of training data (M<sub>no art</sub>). Models were validated on all validation data (V<sub>all</sub>), and the subgroups with (V<sub>art</sub>) and without (V<sub>no art</sub>) artifacts. Kaplan-Meier survival analysis was performed to compare HPV status based on p16 and radiomic model predictions.
RESULTS: The area under the receiver operator curve for M<sub>all</sub> and M<sub>no art</sub> ranged between 0.70 and 0.80 and was not significantly different for all validation data sets. There was a consistent and significant split between survival curves with HPV status determined by p16 [p = 0.007; hazard ratio (HR): 0.46], M<sub>all</sub> (p = 0.036; HR: 0.55) and M<sub>no art</sub> (p = 0.027; HR: 0.49).
CONCLUSION: This study provides proof of concept that molecular information can be derived from standard medical images and shows potential for radiomics as imaging biomarker of HPV status. Advances in knowledge: Radiomics has the potential to identify clinically relevant molecular phenotypes.","Development and validation of a radiomic signature to predict HPV (p16) status from standard CT imaging: a multicenter study OBJECTIVES: Human papillomavirus (HPV) positive oropharyngeal cancer (oropharyngeal squamous cell carcinoma, OPSCC) is biologically and clinically different from HPV negative OPSCC. Here, we evaluate the use of a radiomic approach to identify the HPV status of OPSCC.
METHODS: Four independent cohorts, totaling 778 OPSCC patients with HPV determined by p16 were collected. We randomly assigned 80% of all data for model training (N = 628) and 20% for validation (N = 150). On the pre-treatment CT images, 902 radiomic features were calculated from the gross tumor volume. Multivariable modeling was performed using least absolute shrinkage and selection operator. To assess the impact of CT artifacts in predicting HPV (p16), a model was developed on all training data (M<sub>all</sub>) and on the artifact-free subset of training data (M<sub>no art</sub>). Models were validated on all validation data (V<sub>all</sub>), and the subgroups with (V<sub>art</sub>) and without (V<sub>no art</sub>) artifacts. Kaplan-Meier survival analysis was performed to compare HPV status based on p16 and radiomic model predictions.
RESULTS: The area under the receiver operator curve for M<sub>all</sub> and M<sub>no art</sub> ranged between 0.70 and 0.80 and was not significantly different for all validation data sets. There was a consistent and significant split between survival curves with HPV status determined by p16 [p = 0.007; hazard ratio (HR): 0.46], M<sub>all</sub> (p = 0.036; HR: 0.55) and M<sub>no art</sub> (p = 0.027; HR: 0.49).
CONCLUSION: This study provides proof of concept that molecular information can be derived from standard medical images and shows potential for radiomics as imaging biomarker of HPV status. Advances in knowledge: Radiomics has the potential to identify clinically relevant molecular phenotypes.",0,0
29543803,Development and evaluation of a novel high-throughput image-based fluorescent neutralization test for detection of Zika virus infection,"Koishi AC, Suzukawa AA, Zanluca C, Camacho DE, Comach G, Duarte Dos Santos CN.",PLoS Negl Trop Dis. 2018 Mar 15;12(3):e0006342. doi: 10.1371/journal.pntd.0006342. eCollection 2018 Mar.,Koishi AC,PLoS Negl Trop Dis,2018,16-03-2018,PMC5871014,,10.1371/journal.pntd.0006342,"Zika virus (ZIKV) is an emerging arbovirus belonging to the genus flavivirus that comprises other important public health viruses, such as dengue (DENV) and yellow fever (YFV). In general, ZIKV infection is a self-limiting disease, however cases of Guillain-Barré syndrome and congenital brain abnormalities in newborn infants have been reported. Diagnosing ZIKV infection remains a challenge, as viral RNA detection is only applicable until a few days after the onset of symptoms. After that, serological tests must be applied, and, as expected, high cross-reactivity between ZIKV and other flavivirus serology is observed. Plaque reduction neutralization test (PRNT) is indicated to confirm positive samples for being more specific, however it is laborious intensive and time consuming, representing a major bottleneck for patient diagnosis. To overcome this limitation, we developed a high-throughput image-based fluorescent neutralization test for ZIKV infection by serological detection. Using 226 human specimens, we showed that the new test presented higher throughput than traditional PRNT, maintaining the correlation between results. Furthermore, when tested with dengue virus samples, it showed 50.53% less cross reactivity than MAC-ELISA. This fluorescent neutralization test could be used for clinical diagnosis confirmation of ZIKV infection, as well as for vaccine clinical trials and seroprevalence studies.","Development and evaluation of a novel high-throughput image-based fluorescent neutralization test for detection of Zika virus infection Zika virus (ZIKV) is an emerging arbovirus belonging to the genus flavivirus that comprises other important public health viruses, such as dengue (DENV) and yellow fever (YFV). In general, ZIKV infection is a self-limiting disease, however cases of Guillain-Barré syndrome and congenital brain abnormalities in newborn infants have been reported. Diagnosing ZIKV infection remains a challenge, as viral RNA detection is only applicable until a few days after the onset of symptoms. After that, serological tests must be applied, and, as expected, high cross-reactivity between ZIKV and other flavivirus serology is observed. Plaque reduction neutralization test (PRNT) is indicated to confirm positive samples for being more specific, however it is laborious intensive and time consuming, representing a major bottleneck for patient diagnosis. To overcome this limitation, we developed a high-throughput image-based fluorescent neutralization test for ZIKV infection by serological detection. Using 226 human specimens, we showed that the new test presented higher throughput than traditional PRNT, maintaining the correlation between results. Furthermore, when tested with dengue virus samples, it showed 50.53% less cross reactivity than MAC-ELISA. This fluorescent neutralization test could be used for clinical diagnosis confirmation of ZIKV infection, as well as for vaccine clinical trials and seroprevalence studies.",0,0
36153429,"The impact of the COVID-19 pandemic on the prevalence of computer vision syndrome among medical students in Riyadh, Saudi Arabia","Almousa AN, Aldofyan MZ, Kokandi BA, Alsubki HE, Alqahtani RS, Gikandi P, Alghaihb SG.",Int Ophthalmol. 2023 Apr;43(4):1275-1283. doi: 10.1007/s10792-022-02525-w. Epub 2022 Sep 24.,Almousa AN,Int Ophthalmol,2023,24-09-2022,PMC9510156,,10.1007/s10792-022-02525-w,"PURPOSE: To estimate the prevalence of computer vision syndrome (CVS) among university medical students in Riyadh, Saudi Arabia, after establishing remote learning during COVID-19 pandemic and to compare settings of electronic device usage and patterns of CVS protective measures applied by students before and during this pandemic.
METHODS: This is an observational descriptive cross-sectional study which included 1st to 5th year medical students who were actively enrolled at the governmental colleges of medicine in Riyadh, Saudi Arabia, during the COVID-19 lockdown. The sample size was estimated to be 287 medical students. Participants were asked to volunteer and fill an electronic online questionnaire.
RESULTS: A total of 300 medical students were included in this study. 94.0% reported at least one symptom of CVS, while 67% reported having more than three symptoms. The most frequently reported symptoms were musculoskeletal pain (84.3%), headache (71.1%) and dry eyes (68%). Thirty-eight percent of the students experienced more severe symptoms, while 48% experienced more frequent symptoms during the COVID-19 pandemic. Risk factors for having three or more symptoms were being a female (p < 0.001) and using electronic devices for longer periods (6.8 h ± 2.8) during COVID-19 lockdown (p < 0.001).
CONCLUSION: CVS prevalence during COVID-19 era among medical students is high. This necessitates increasing the awareness of CVS and its preventive measures.","The impact of the COVID-19 pandemic on the prevalence of computer vision syndrome among medical students in Riyadh, Saudi Arabia PURPOSE: To estimate the prevalence of computer vision syndrome (CVS) among university medical students in Riyadh, Saudi Arabia, after establishing remote learning during COVID-19 pandemic and to compare settings of electronic device usage and patterns of CVS protective measures applied by students before and during this pandemic.
METHODS: This is an observational descriptive cross-sectional study which included 1st to 5th year medical students who were actively enrolled at the governmental colleges of medicine in Riyadh, Saudi Arabia, during the COVID-19 lockdown. The sample size was estimated to be 287 medical students. Participants were asked to volunteer and fill an electronic online questionnaire.
RESULTS: A total of 300 medical students were included in this study. 94.0% reported at least one symptom of CVS, while 67% reported having more than three symptoms. The most frequently reported symptoms were musculoskeletal pain (84.3%), headache (71.1%) and dry eyes (68%). Thirty-eight percent of the students experienced more severe symptoms, while 48% experienced more frequent symptoms during the COVID-19 pandemic. Risk factors for having three or more symptoms were being a female (p < 0.001) and using electronic devices for longer periods (6.8 h ± 2.8) during COVID-19 lockdown (p < 0.001).
CONCLUSION: CVS prevalence during COVID-19 era among medical students is high. This necessitates increasing the awareness of CVS and its preventive measures.",0,0
36607623,Deep Convolutional Neural Networks Detect no Morphological Differences Between Culture-Positive and Culture-Negative Infectious Keratitis Images,"Kogachi K, Lalitha P, Prajna NV, Gunasekaran R, Keenan JD, Campbell JP, Song X, Redd TK.",Transl Vis Sci Technol. 2023 Jan 3;12(1):12. doi: 10.1167/tvst.12.1.12.,Kogachi K,Transl Vis Sci Technol,2023,06-01-2023,PMC9836011,,10.1167/tvst.12.1.12,"PURPOSE: To determine whether convolutional neural networks can detect morphological differences between images of microbiologically positive and negative corneal ulcers.
METHODS: A cross-sectional comparison of prospectively collected data consisting of bacterial and fungal cultures and smears from eyes with acute infectious keratitis at Aravind Eye Hospital. Two convolutional neural network architectures (DenseNet and MobileNet) were trained using images obtained from handheld cameras collected from culture-positive and negative images and smear-positive and -negative images. Each architecture was trained on two image sets: (1) one with labels assigned using only culture results and (2) one using culture and smear results. The outcome measure was area under the receiver operating characteristic curve for predicting whether an ulcer would be microbiologically positive or negative.
RESULTS: There were 1970 images from 886 patients were included. None of the models were better than random chance at predicting positive microbiologic results (area under the receiver operating characteristic curve ranged from 0.49 to 0.56; all confidence intervals included 0.5).
CONCLUSIONS: These two state-of-the-art deep convolutional neural network architectures could not reliably predict whether a corneal ulcer would be microbiologically positive or negative based on clinical photographs. This absence of detectable morphological differences informs the future development of computer vision models trained to predict the causative agent in infectious keratitis using corneal photography.
TRANSLATIONAL RELEVANCE: These deep learning models were not able to identify morphological differences between microbiologically positive and negative corneal ulcers. This finding suggests that similar artificial intelligence models trained to identify the causative pathogen using only microbiologically positive cases may have potential to generalize well, including to cases with falsely negative microbiologic testing.","Deep Convolutional Neural Networks Detect no Morphological Differences Between Culture-Positive and Culture-Negative Infectious Keratitis Images PURPOSE: To determine whether convolutional neural networks can detect morphological differences between images of microbiologically positive and negative corneal ulcers.
METHODS: A cross-sectional comparison of prospectively collected data consisting of bacterial and fungal cultures and smears from eyes with acute infectious keratitis at Aravind Eye Hospital. Two convolutional neural network architectures (DenseNet and MobileNet) were trained using images obtained from handheld cameras collected from culture-positive and negative images and smear-positive and -negative images. Each architecture was trained on two image sets: (1) one with labels assigned using only culture results and (2) one using culture and smear results. The outcome measure was area under the receiver operating characteristic curve for predicting whether an ulcer would be microbiologically positive or negative.
RESULTS: There were 1970 images from 886 patients were included. None of the models were better than random chance at predicting positive microbiologic results (area under the receiver operating characteristic curve ranged from 0.49 to 0.56; all confidence intervals included 0.5).
CONCLUSIONS: These two state-of-the-art deep convolutional neural network architectures could not reliably predict whether a corneal ulcer would be microbiologically positive or negative based on clinical photographs. This absence of detectable morphological differences informs the future development of computer vision models trained to predict the causative agent in infectious keratitis using corneal photography.
TRANSLATIONAL RELEVANCE: These deep learning models were not able to identify morphological differences between microbiologically positive and negative corneal ulcers. This finding suggests that similar artificial intelligence models trained to identify the causative pathogen using only microbiologically positive cases may have potential to generalize well, including to cases with falsely negative microbiologic testing.",1,0
30918429,Diffusion-weighted magnetic resonance imaging and micro-RNA in the diagnosis of hepatic fibrosis in chronic hepatitis C virus,"Besheer T, Elalfy H, Abd El-Maksoud M, Abd El-Razek A, Taman S, Zalata K, Elkashef W, Zaghloul H, Elshahawy H, Raafat D, Elemshaty W, Elsayed E, El-Gilany AH, El-Bendary M.",World J Gastroenterol. 2019 Mar 21;25(11):1366-1377. doi: 10.3748/wjg.v25.i11.1366.,Besheer T,World J Gastroenterol,2019,29-03-2019,PMC6429339,,10.3748/wjg.v25.i11.1366,"BACKGROUND: Diffusion-weighted magnetic resonance imaging has shown promise in the detection and quantiﬁcation of hepatic ﬁbrosis. In addition, the liver has numerous endogenous micro-RNAs (miRs) that play important roles in the regulation of biological processes such as cell proliferation and hepatic fibrosis.
AIM: To assess diffusion-weighted magnetic resonance imaging and miRs in diagnosing and staging hepatic fibrosis in patients with chronic hepatitis C.
METHODS: This prospective study included 208 patients and 82 age- and sex-matched controls who underwent diffusion-weighted magnetic resonance imaging of the abdomen, miR profiling, and liver biopsy. Pathological scoring was classified according to the METAVIR scoring system. The apparent diffusion coefficient (ADC) and miR were calculated and correlated with pathological scoring.
RESULTS: The ADC value decreased significantly with the progression of fibrosis, from controls (F0) to patients with early fibrosis (F1 and F2) to those with late fibrosis (F3 and F4) (median 1.92, 1.53, and 1.25 × 10-3 mm2/s, respectively) (P = 0.001). The cut-off ADC value used to differentiate patients from controls was 1.83 × 10-3 mm2/s with an area under the curve (AUC) of 0.992. Combining ADC and miR-200b revealed the highest AUC (0.995) for differentiating patients from controls with an accuracy of 96.9%. The cut-off ADC used to differentiate early fibrosis from late fibrosis was 1.54 × 10-3 mm2/s with an AUC of 0.866. The combination of ADC and miR-200b revealed the best AUC (0.925) for differentiating early fibrosis from late fibrosis with an accuracy of 80.2%. The ADC correlated with miR-200b (r = - 0.61, P = 0.001), miR-21 (r = - 0.62, P = 0.001), and miR-29 (r = 0.52, P = 0.001).
CONCLUSION: Combining ADC and miRs offers an alternative surrogate non-invasive diagnostic tool for diagnosing and staging hepatic fibrosis in patients with chronic hepatitis C.","Diffusion-weighted magnetic resonance imaging and micro-RNA in the diagnosis of hepatic fibrosis in chronic hepatitis C virus BACKGROUND: Diffusion-weighted magnetic resonance imaging has shown promise in the detection and quantiﬁcation of hepatic ﬁbrosis. In addition, the liver has numerous endogenous micro-RNAs (miRs) that play important roles in the regulation of biological processes such as cell proliferation and hepatic fibrosis.
AIM: To assess diffusion-weighted magnetic resonance imaging and miRs in diagnosing and staging hepatic fibrosis in patients with chronic hepatitis C.
METHODS: This prospective study included 208 patients and 82 age- and sex-matched controls who underwent diffusion-weighted magnetic resonance imaging of the abdomen, miR profiling, and liver biopsy. Pathological scoring was classified according to the METAVIR scoring system. The apparent diffusion coefficient (ADC) and miR were calculated and correlated with pathological scoring.
RESULTS: The ADC value decreased significantly with the progression of fibrosis, from controls (F0) to patients with early fibrosis (F1 and F2) to those with late fibrosis (F3 and F4) (median 1.92, 1.53, and 1.25 × 10-3 mm2/s, respectively) (P = 0.001). The cut-off ADC value used to differentiate patients from controls was 1.83 × 10-3 mm2/s with an area under the curve (AUC) of 0.992. Combining ADC and miR-200b revealed the highest AUC (0.995) for differentiating patients from controls with an accuracy of 96.9%. The cut-off ADC used to differentiate early fibrosis from late fibrosis was 1.54 × 10-3 mm2/s with an AUC of 0.866. The combination of ADC and miR-200b revealed the best AUC (0.925) for differentiating early fibrosis from late fibrosis with an accuracy of 80.2%. The ADC correlated with miR-200b (r = - 0.61, P = 0.001), miR-21 (r = - 0.62, P = 0.001), and miR-29 (r = 0.52, P = 0.001).
CONCLUSION: Combining ADC and miRs offers an alternative surrogate non-invasive diagnostic tool for diagnosing and staging hepatic fibrosis in patients with chronic hepatitis C.",0,0
32932585,Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video,"Martinez M, Yang K, Constantinescu A, Stiefelhagen R.",Sensors (Basel). 2020 Sep 12;20(18):5202. doi: 10.3390/s20185202.,Martinez M,Sensors (Basel),2020,16-09-2020,PMC7571123,,10.3390/s20185202,"The current COVID-19 pandemic is having a major impact on our daily lives. Social distancing is one of the measures that has been implemented with the aim of slowing the spread of the disease, but it is difficult for blind people to comply with this. In this paper, we present a system that helps blind people to maintain physical distance to other persons using a combination of RGB and depth cameras. We use a real-time semantic segmentation algorithm on the RGB camera to detect where persons are and use the depth camera to assess the distance to them; then, we provide audio feedback through bone-conducting headphones if a person is closer than 1.5 m. Our system warns the user only if persons are nearby but does not react to non-person objects such as walls, trees or doors; thus, it is not intrusive, and it is possible to use it in combination with other assistive devices. We have tested our prototype system on one blind and four blindfolded persons, and found that the system is precise, easy to use, and amounts to low cognitive load.","Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video The current COVID-19 pandemic is having a major impact on our daily lives. Social distancing is one of the measures that has been implemented with the aim of slowing the spread of the disease, but it is difficult for blind people to comply with this. In this paper, we present a system that helps blind people to maintain physical distance to other persons using a combination of RGB and depth cameras. We use a real-time semantic segmentation algorithm on the RGB camera to detect where persons are and use the depth camera to assess the distance to them; then, we provide audio feedback through bone-conducting headphones if a person is closer than 1.5 m. Our system warns the user only if persons are nearby but does not react to non-person objects such as walls, trees or doors; thus, it is not intrusive, and it is possible to use it in combination with other assistive devices. We have tested our prototype system on one blind and four blindfolded persons, and found that the system is precise, easy to use, and amounts to low cognitive load.",1,0
33976268,Combining radiomic phenotypes of non-small cell lung cancer with liquid biopsy data may improve prediction of response to EGFR inhibitors,"Yousefi B, LaRiviere MJ, Cohen EA, Buckingham TH, Yee SS, Black TA, Chien AL, Noël P, Hwang WT, Katz SI, Aggarwal C, Thompson JC, Carpenter EL, Kontos D.",Sci Rep. 2021 May 11;11(1):9984. doi: 10.1038/s41598-021-88239-y.,Yousefi B,Sci Rep,2021,12-05-2021,PMC8113313,,10.1038/s41598-021-88239-y,"Among non-small cell lung cancer (NSCLC) patients with therapeutically targetable tumor mutations in epidermal growth factor receptor (EGFR), not all patients respond to targeted therapy. Combining circulating-tumor DNA (ctDNA), clinical variables, and radiomic phenotypes may improve prediction of EGFR-targeted therapy outcomes for NSCLC. This single-center retrospective study included 40 EGFR-mutant advanced NSCLC patients treated with EGFR-targeted therapy. ctDNA data included number of mutations and detection of EGFR T790M. Clinical data included age, smoking status, and ECOG performance status. Baseline chest CT scans were analyzed to extract 429 radiomic features from each primary tumor. Unsupervised hierarchical clustering was used to group tumors into phenotypes. Kaplan-Meier (K-M) curves and Cox proportional hazards regression were modeled for progression-free survival (PFS) and overall survival (OS). Likelihood ratio test (LRT) was used to compare fit between models. Among 40 patients (73% women, median age 62 years), consensus clustering identified two radiomic phenotypes. For PFS, the model combining radiomic phenotypes with ctDNA and clinical variables had c-statistic of 0.77 and a better fit (LRT p = 0.01) than the model with clinical and ctDNA variables alone with a c-statistic of 0.73. For OS, adding radiomic phenotypes resulted in c-statistic of 0.83 versus 0.80 when using clinical and ctDNA variables (LRT p = 0.08). Both models showed separation of K-M curves dichotomized by median prognostic score (p < 0.005). Combining radiomic phenotypes, ctDNA, and clinical variables may enhance precision oncology approaches to managing advanced non-small cell lung cancer with EGFR mutations.","Combining radiomic phenotypes of non-small cell lung cancer with liquid biopsy data may improve prediction of response to EGFR inhibitors Among non-small cell lung cancer (NSCLC) patients with therapeutically targetable tumor mutations in epidermal growth factor receptor (EGFR), not all patients respond to targeted therapy. Combining circulating-tumor DNA (ctDNA), clinical variables, and radiomic phenotypes may improve prediction of EGFR-targeted therapy outcomes for NSCLC. This single-center retrospective study included 40 EGFR-mutant advanced NSCLC patients treated with EGFR-targeted therapy. ctDNA data included number of mutations and detection of EGFR T790M. Clinical data included age, smoking status, and ECOG performance status. Baseline chest CT scans were analyzed to extract 429 radiomic features from each primary tumor. Unsupervised hierarchical clustering was used to group tumors into phenotypes. Kaplan-Meier (K-M) curves and Cox proportional hazards regression were modeled for progression-free survival (PFS) and overall survival (OS). Likelihood ratio test (LRT) was used to compare fit between models. Among 40 patients (73% women, median age 62 years), consensus clustering identified two radiomic phenotypes. For PFS, the model combining radiomic phenotypes with ctDNA and clinical variables had c-statistic of 0.77 and a better fit (LRT p = 0.01) than the model with clinical and ctDNA variables alone with a c-statistic of 0.73. For OS, adding radiomic phenotypes resulted in c-statistic of 0.83 versus 0.80 when using clinical and ctDNA variables (LRT p = 0.08). Both models showed separation of K-M curves dichotomized by median prognostic score (p < 0.005). Combining radiomic phenotypes, ctDNA, and clinical variables may enhance precision oncology approaches to managing advanced non-small cell lung cancer with EGFR mutations.",0,0
32717786,Comparison of Multiplexed Immunofluorescence Imaging to Chromogenic Immunohistochemistry of Skin Biomarkers in Response to Monkeypox Virus Infection,"Sood A, Sui Y, McDonough E, Santamaría-Pang A, Al-Kofahi Y, Pang Z, Jahrling PB, Kuhn JH, Ginty F.",Viruses. 2020 Jul 23;12(8):787. doi: 10.3390/v12080787.,Sood A,Viruses,2020,29-07-2020,PMC7472296,,10.3390/v12080787,"Over the last 15 years, advances in immunofluorescence-imaging based cycling methods, antibody conjugation methods, and automated image processing have facilitated the development of a high-resolution, multiplexed tissue immunofluorescence (MxIF) method with single cell-level quantitation termed Cell DIVETM. Originally developed for fixed oncology samples, here it was evaluated in highly fixed (up to 30 days), archived monkeypox virus-induced inflammatory skin lesions from a retrospective study in 11 rhesus monkeys to determine whether MxIF was comparable to manual H-scoring of chromogenic stains. Six protein markers related to immune and cellular response (CD68, CD3, Hsp70, Hsp90, ERK1/2, ERK1/2 pT202_pY204) were manually quantified (H-scores) by a pathologist from chromogenic IHC double stains on serial sections and compared to MxIF automated single cell quantification of the same markers that were multiplexed on a single tissue section. Overall, there was directional consistency between the H-score and the MxIF results for all markers except phosphorylated ERK1/2 (ERK1/2 pT202_pY204), which showed a decrease in the lesion compared to the adjacent non-lesioned skin by MxIF vs an increase via H-score. Improvements to automated segmentation using machine learning and adding additional cell markers for cell viability are future options for improvement. This method could be useful in infectious disease research as it conserves tissue, provides marker colocalization data on thousands of cells, allowing further cell level data mining as well as a reduction in user bias.","Comparison of Multiplexed Immunofluorescence Imaging to Chromogenic Immunohistochemistry of Skin Biomarkers in Response to Monkeypox Virus Infection Over the last 15 years, advances in immunofluorescence-imaging based cycling methods, antibody conjugation methods, and automated image processing have facilitated the development of a high-resolution, multiplexed tissue immunofluorescence (MxIF) method with single cell-level quantitation termed Cell DIVETM. Originally developed for fixed oncology samples, here it was evaluated in highly fixed (up to 30 days), archived monkeypox virus-induced inflammatory skin lesions from a retrospective study in 11 rhesus monkeys to determine whether MxIF was comparable to manual H-scoring of chromogenic stains. Six protein markers related to immune and cellular response (CD68, CD3, Hsp70, Hsp90, ERK1/2, ERK1/2 pT202_pY204) were manually quantified (H-scores) by a pathologist from chromogenic IHC double stains on serial sections and compared to MxIF automated single cell quantification of the same markers that were multiplexed on a single tissue section. Overall, there was directional consistency between the H-score and the MxIF results for all markers except phosphorylated ERK1/2 (ERK1/2 pT202_pY204), which showed a decrease in the lesion compared to the adjacent non-lesioned skin by MxIF vs an increase via H-score. Improvements to automated segmentation using machine learning and adding additional cell markers for cell viability are future options for improvement. This method could be useful in infectious disease research as it conserves tissue, provides marker colocalization data on thousands of cells, allowing further cell level data mining as well as a reduction in user bias.",0,1
34288966,"Coronary artery calcification on low-dose chest CT is an early predictor of severe progression of COVID-19-A multi-center, multi-vendor study","Fervers P, Kottlors J, Große Hokamp N, Bremm J, Maintz D, Tritt S, Safarov O, Persigehl T, Vollmar N, Bansmann PM, Abdullayev N.",PLoS One. 2021 Jul 21;16(7):e0255045. doi: 10.1371/journal.pone.0255045. eCollection 2021.,Fervers P,PLoS One,2021,21-07-2021,PMC8294495,,10.1371/journal.pone.0255045,"PURPOSE: Cardiovascular comorbidity anticipates severe progression of COVID-19 and becomes evident by coronary artery calcification (CAC) on low-dose chest computed tomography (LDCT). The purpose of this study was to predict a patient's obligation of intensive care treatment by evaluating the coronary calcium burden on the initial diagnostic LDCT.
METHODS: Eighty-nine consecutive patients with parallel LDCT and positive RT-PCR for SARS-CoV-2 were included from three centers. The primary endpoint was admission to ICU, tracheal intubation, or death in the 22-day follow-up period. CAC burden was represented by the Agatston score. Multivariate logistic regression was modeled for prediction of the primary endpoint by the independent variables ""Agatston score > 0"", as well as the CT lung involvement score, patient sex, age, clinical predictors of severe COVID-19 progression (history of hypertension, diabetes, prior cardiovascular event, active smoking, or hyperlipidemia), and laboratory parameters (creatinine, C-reactive protein, leucocyte, as well as thrombocyte counts, relative lymphocyte count, d-dimer, and lactate dehydrogenase levels).
RESULTS: After excluding multicollinearity, ""Agatston score >0"" was an independent regressor within multivariate analysis for prediction of the primary endpoint (p<0.01). Further independent regressors were creatinine (p = 0.02) and leucocyte count (p = 0.04). The Agatston score was significantly higher for COVID-19 cases which completed the primary endpoint (64.2 [interquartile range 1.7-409.4] vs. 0 [interquartile range 0-0]).
CONCLUSION: CAC scoring on LDCT might help to predict future obligation of intensive care treatment at the day of patient admission to the hospital.","Coronary artery calcification on low-dose chest CT is an early predictor of severe progression of COVID-19-A multi-center, multi-vendor study PURPOSE: Cardiovascular comorbidity anticipates severe progression of COVID-19 and becomes evident by coronary artery calcification (CAC) on low-dose chest computed tomography (LDCT). The purpose of this study was to predict a patient's obligation of intensive care treatment by evaluating the coronary calcium burden on the initial diagnostic LDCT.
METHODS: Eighty-nine consecutive patients with parallel LDCT and positive RT-PCR for SARS-CoV-2 were included from three centers. The primary endpoint was admission to ICU, tracheal intubation, or death in the 22-day follow-up period. CAC burden was represented by the Agatston score. Multivariate logistic regression was modeled for prediction of the primary endpoint by the independent variables ""Agatston score > 0"", as well as the CT lung involvement score, patient sex, age, clinical predictors of severe COVID-19 progression (history of hypertension, diabetes, prior cardiovascular event, active smoking, or hyperlipidemia), and laboratory parameters (creatinine, C-reactive protein, leucocyte, as well as thrombocyte counts, relative lymphocyte count, d-dimer, and lactate dehydrogenase levels).
RESULTS: After excluding multicollinearity, ""Agatston score >0"" was an independent regressor within multivariate analysis for prediction of the primary endpoint (p<0.01). Further independent regressors were creatinine (p = 0.02) and leucocyte count (p = 0.04). The Agatston score was significantly higher for COVID-19 cases which completed the primary endpoint (64.2 [interquartile range 1.7-409.4] vs. 0 [interquartile range 0-0]).
CONCLUSION: CAC scoring on LDCT might help to predict future obligation of intensive care treatment at the day of patient admission to the hospital.",0,0
37243220,Trajectory of Gastrointestinal Symptoms in Previously Hospitalized COVID-19 Survivors: The Long COVID Experience Multicenter Study,"Fernández-de-Las-Peñas C, Torres-Macho J, Guijarro C, Martín-Guerrero JD, Pellicer-Valero OJ, Plaza-Manzano G.",Viruses. 2023 May 10;15(5):1134. doi: 10.3390/v15051134.,Fernández-de-Las-Peñas C,Viruses,2023,27-05-2023,PMC10221203,,10.3390/v15051134,"This multicenter cohort study used Sankey plots and exponential bar plots to visualize the fluctuating evolution and the trajectory of gastrointestinal symptoms in previously hospitalized COVID-19 survivors during the first 18 months after acute SARS-CoV-2 infection. A total of 1266 previously hospitalized COVID-19 survivors were assessed at four points: hospital admission (T0), at 8.4 months (T1), at 13.2 months (T2), and at 18.3 months (T3) after hospitalization. Participants were asked about their overall gastrointestinal symptoms and particularly diarrhea. Clinical and hospitalization data were collected from hospital medical records. The prevalence of overall gastrointestinal post-COVID symptomatology was 6.3% (n = 80) at T1, 3.99% (n = 50) at T2 and 2.39% (n = 32) at T3. The prevalence of diarrhea decreased from 10.69% (n = 135) at hospital admission (T0), to 2.55% (n = 32) at T1, to 1.04% (n = 14) at T2, and to 0.64% (n = 8) at T3. The Sankey plots revealed that just 20 (1.59%) and 4 (0.32%) patients exhibited overall gastrointestinal post-COVID symptoms or diarrhea, respectively, throughout the whole follow-up period. The recovery fitted exponential curves revealed a decreasing prevalence trend, showing that diarrhea and gastrointestinal symptoms recover during the first two or three years after COVID-19 in previously hospitalized COVID-19 survivors. The regression models did not reveal any symptoms to be associated with the presence of gastrointestinal post-COVID symptomatology or post-COVID diarrhea at hospital admission or at T1. The use of Sankey plots revealed the fluctuating evolution of gastrointestinal post-COVID symptoms during the first two years after infection. In addition, exponential bar plots revealed the decreased prevalence of gastrointestinal post-COVID symptomatology during the first three years after infection.","Trajectory of Gastrointestinal Symptoms in Previously Hospitalized COVID-19 Survivors: The Long COVID Experience Multicenter Study This multicenter cohort study used Sankey plots and exponential bar plots to visualize the fluctuating evolution and the trajectory of gastrointestinal symptoms in previously hospitalized COVID-19 survivors during the first 18 months after acute SARS-CoV-2 infection. A total of 1266 previously hospitalized COVID-19 survivors were assessed at four points: hospital admission (T0), at 8.4 months (T1), at 13.2 months (T2), and at 18.3 months (T3) after hospitalization. Participants were asked about their overall gastrointestinal symptoms and particularly diarrhea. Clinical and hospitalization data were collected from hospital medical records. The prevalence of overall gastrointestinal post-COVID symptomatology was 6.3% (n = 80) at T1, 3.99% (n = 50) at T2 and 2.39% (n = 32) at T3. The prevalence of diarrhea decreased from 10.69% (n = 135) at hospital admission (T0), to 2.55% (n = 32) at T1, to 1.04% (n = 14) at T2, and to 0.64% (n = 8) at T3. The Sankey plots revealed that just 20 (1.59%) and 4 (0.32%) patients exhibited overall gastrointestinal post-COVID symptoms or diarrhea, respectively, throughout the whole follow-up period. The recovery fitted exponential curves revealed a decreasing prevalence trend, showing that diarrhea and gastrointestinal symptoms recover during the first two or three years after COVID-19 in previously hospitalized COVID-19 survivors. The regression models did not reveal any symptoms to be associated with the presence of gastrointestinal post-COVID symptomatology or post-COVID diarrhea at hospital admission or at T1. The use of Sankey plots revealed the fluctuating evolution of gastrointestinal post-COVID symptoms during the first two years after infection. In addition, exponential bar plots revealed the decreased prevalence of gastrointestinal post-COVID symptomatology during the first three years after infection.",0,0
34853342,Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays,"Gidde PS, Prasad SS, Singh AP, Bhatheja N, Prakash S, Singh P, Saboo A, Takhar R, Gupta S, Saurav S, M V R, Singh A, Sardana V, Mahajan H, Kalyanpur A, Mandal AS, Mahajan V, Agrawal A, Agrawal A, Venugopal VK, Singh S, Dash D.",Sci Rep. 2021 Dec 1;11(1):23210. doi: 10.1038/s41598-021-02003-w.,Gidde PS,Sci Rep,2021,02-12-2021,PMC8636645,,10.1038/s41598-021-02003-w,"SARS-CoV2 pandemic exposed the limitations of artificial intelligence based medical imaging systems. Earlier in the pandemic, the absence of sufficient training data prevented effective deep learning (DL) solutions for the diagnosis of COVID-19 based on X-Ray data. Here, addressing the lacunae in existing literature and algorithms with the paucity of initial training data; we describe CovBaseAI, an explainable tool using an ensemble of three DL models and an expert decision system (EDS) for COVID-Pneumonia diagnosis, trained entirely on pre-COVID-19 datasets. The performance and explainability of CovBaseAI was primarily validated on two independent datasets. Firstly, 1401 randomly selected CxR from an Indian quarantine center to assess effectiveness in excluding radiological COVID-Pneumonia requiring higher care. Second, curated dataset; 434 RT-PCR positive cases and 471 non-COVID/Normal historical scans, to assess performance in advanced medical settings. CovBaseAI had an accuracy of 87% with a negative predictive value of 98% in the quarantine-center data. However, sensitivity was 0.66-0.90 taking RT-PCR/radiologist opinion as ground truth. This work provides new insights on the usage of EDS with DL methods and the ability of algorithms to confidently predict COVID-Pneumonia while reinforcing the established learning; that benchmarking based on RT-PCR may not serve as reliable ground truth in radiological diagnosis. Such tools can pave the path for multi-modal high throughput detection of COVID-Pneumonia in screening and referral.","Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays SARS-CoV2 pandemic exposed the limitations of artificial intelligence based medical imaging systems. Earlier in the pandemic, the absence of sufficient training data prevented effective deep learning (DL) solutions for the diagnosis of COVID-19 based on X-Ray data. Here, addressing the lacunae in existing literature and algorithms with the paucity of initial training data; we describe CovBaseAI, an explainable tool using an ensemble of three DL models and an expert decision system (EDS) for COVID-Pneumonia diagnosis, trained entirely on pre-COVID-19 datasets. The performance and explainability of CovBaseAI was primarily validated on two independent datasets. Firstly, 1401 randomly selected CxR from an Indian quarantine center to assess effectiveness in excluding radiological COVID-Pneumonia requiring higher care. Second, curated dataset; 434 RT-PCR positive cases and 471 non-COVID/Normal historical scans, to assess performance in advanced medical settings. CovBaseAI had an accuracy of 87% with a negative predictive value of 98% in the quarantine-center data. However, sensitivity was 0.66-0.90 taking RT-PCR/radiologist opinion as ground truth. This work provides new insights on the usage of EDS with DL methods and the ability of algorithms to confidently predict COVID-Pneumonia while reinforcing the established learning; that benchmarking based on RT-PCR may not serve as reliable ground truth in radiological diagnosis. Such tools can pave the path for multi-modal high throughput detection of COVID-Pneumonia in screening and referral.",0,1
30948914,Accuracy of multi-echo Dixon sequence in quantification of hepatic steatosis in Chinese children and adolescents,"Zhao YZ, Gan YG, Zhou JL, Liu JQ, Cao WG, Cheng SM, Bai DM, Wang MZ, Gao FQ, Zhou SM.",World J Gastroenterol. 2019 Mar 28;25(12):1513-1523. doi: 10.3748/wjg.v25.i12.1513.,Zhao YZ,World J Gastroenterol,2019,06-04-2019,PMC6441915,,10.3748/wjg.v25.i12.1513,"BACKGROUND: Nonalcoholic fatty liver disease (NAFLD) is currently the outstanding cause of chronic liver disease in children and adolescents, especially in overweight and obese groups. Liver biopsy is the reference standard to diagnose NAFLD but invasive, thus it is not the best choice in clinical diagnosis and follow-up. Magnetic resonance (MR) is widely used in clinical trials to noninvasively quantify liver fat content in adults and children in foreign countries. While currently, it is rarely used in Chinese children and adolescents. We postulated that quantifying hepatic steatosis by MR could be extended to children and adolescents in China.
AIM: To investigate the accuracy of MR imaging (MRI) in quantifying liver fat with MR spectroscopy (MRS) as a reference. A secondary goal was to assess the prevalence of NAFLD in overweight and obese Chinese children and adolescents.
METHODS: There were 86 children and adolescents enrolled in this study, including 65 overweight and obese children and 21 healthy children. The participants underwent MRI and MRS. MRI and MRS were performed using multi-echo Dixon and HISTO sequences, respectively, to calculate hepatic proton density fat fraction (PDFF). Hepatic steatosis was diagnosed using MRS-PDFF > 5% as the threshold. Spearman's analysis was used to evaluate the correlation between MRI and MRS. The agreement between these two methods was assessed by Bland-Altman analysis.
RESULTS: The MRI-PDFF in the MRS region of interest and the entire liver was 9.9% ± 10.3% with a range of 0.3%-39.9%, and 10.6% ± 9.4% with a range of 1.9%-38.9%, respectively. The MRS-PDFF was 9.1% ± 10.0%, with a range of 0.5%-37.8%. The incidence of hepatic steatosis detected by MRS-PDFF was 46.5% (40/86) of all participants, all of whom belonged to the overweight and obese group. Spearman's analysis indicated an excellent correlation between multi-echo Dixon and MRS (r &gt; 0.9, P &lt; 0.01). Bland-Altman analysis also demonstrated a good agreement between these two methods.
CONCLUSION: Multi-echo Dixon shows an excellent correlation and agreement with MRS in quantifying liver fat content and could be a potential tool to detect hepatic steatosis in Chinese children and adolescents.","Accuracy of multi-echo Dixon sequence in quantification of hepatic steatosis in Chinese children and adolescents BACKGROUND: Nonalcoholic fatty liver disease (NAFLD) is currently the outstanding cause of chronic liver disease in children and adolescents, especially in overweight and obese groups. Liver biopsy is the reference standard to diagnose NAFLD but invasive, thus it is not the best choice in clinical diagnosis and follow-up. Magnetic resonance (MR) is widely used in clinical trials to noninvasively quantify liver fat content in adults and children in foreign countries. While currently, it is rarely used in Chinese children and adolescents. We postulated that quantifying hepatic steatosis by MR could be extended to children and adolescents in China.
AIM: To investigate the accuracy of MR imaging (MRI) in quantifying liver fat with MR spectroscopy (MRS) as a reference. A secondary goal was to assess the prevalence of NAFLD in overweight and obese Chinese children and adolescents.
METHODS: There were 86 children and adolescents enrolled in this study, including 65 overweight and obese children and 21 healthy children. The participants underwent MRI and MRS. MRI and MRS were performed using multi-echo Dixon and HISTO sequences, respectively, to calculate hepatic proton density fat fraction (PDFF). Hepatic steatosis was diagnosed using MRS-PDFF > 5% as the threshold. Spearman's analysis was used to evaluate the correlation between MRI and MRS. The agreement between these two methods was assessed by Bland-Altman analysis.
RESULTS: The MRI-PDFF in the MRS region of interest and the entire liver was 9.9% ± 10.3% with a range of 0.3%-39.9%, and 10.6% ± 9.4% with a range of 1.9%-38.9%, respectively. The MRS-PDFF was 9.1% ± 10.0%, with a range of 0.5%-37.8%. The incidence of hepatic steatosis detected by MRS-PDFF was 46.5% (40/86) of all participants, all of whom belonged to the overweight and obese group. Spearman's analysis indicated an excellent correlation between multi-echo Dixon and MRS (r &gt; 0.9, P &lt; 0.01). Bland-Altman analysis also demonstrated a good agreement between these two methods.
CONCLUSION: Multi-echo Dixon shows an excellent correlation and agreement with MRS in quantifying liver fat content and could be a potential tool to detect hepatic steatosis in Chinese children and adolescents.",0,0
28941728,Preoperative Prediction of Microvascular Invasion in Hepatocellular Carcinoma Using Quantitative Image Analysis,"Zheng J, Chakraborty J, Chapman WC, Gerst S, Gonen M, Pak LM, Jarnagin WR, DeMatteo RP, Do RKG, Simpson AL; Hepatopancreatobiliary Service in the Department of Surgery of the Memorial Sloan Kettering Cancer Center; Research Staff in the Department of Surgery at Washington University School of Medicine.",J Am Coll Surg. 2017 Dec;225(6):778-788.e1. doi: 10.1016/j.jamcollsurg.2017.09.003. Epub 2017 Sep 21.,Zheng J,J Am Coll Surg,2017,25-09-2017,PMC5705269,NIHMS907723,10.1016/j.jamcollsurg.2017.09.003,"BACKGROUND: Microvascular invasion (MVI) is a significant risk factor for early recurrence after resection or transplantation for hepatocellular carcinoma (HCC). Knowledge of MVI status would help guide treatment recommendations, but is generally identified after operation. This study aims to predict MVI preoperatively using quantitative image analysis.
STUDY DESIGN: One hundred and twenty patients from 2 institutions underwent resection of HCC from 2003 to 2015 were included. The largest tumor from preoperative CT was subjected to quantitative image analysis, which uses an automated computer algorithm to capture regional variation in CT enhancement patterns. Quantitative imaging features by automatic analysis, qualitative radiographic descriptors by 2 radiologists, and preoperative clinical variables were included in multivariate analysis to predict histologic MVI.
RESULTS: Histologic MVI was identified in 19 (37%) patients with tumors ≤5 cm and 34 (49%) patients with tumors >5 cm. Among patients with tumors ≤5 cm, none of the clinical findings or radiographic descriptors were associated with MVI; however, quantitative features based on angle co-occurrence matrix predicted MVI with an area under curve of 0.80, positive predictive value of 63%, and negative predictive value of 85%. In patients with tumors >5 cm, higher α-fetoprotein level, larger tumor size, and viral hepatitis history were associated with MVI, and radiographic descriptors were not. However, a multivariate model combining α-fetoprotein, tumor size, hepatitis status, and quantitative feature based on local binary pattern predicted MVI with area under curve of 0.88, positive predictive value of 72%, and negative predictive value of 96%.
CONCLUSIONS: This study reveals the potential importance of quantitative image analysis as a predictor of MVI.","Preoperative Prediction of Microvascular Invasion in Hepatocellular Carcinoma Using Quantitative Image Analysis BACKGROUND: Microvascular invasion (MVI) is a significant risk factor for early recurrence after resection or transplantation for hepatocellular carcinoma (HCC). Knowledge of MVI status would help guide treatment recommendations, but is generally identified after operation. This study aims to predict MVI preoperatively using quantitative image analysis.
STUDY DESIGN: One hundred and twenty patients from 2 institutions underwent resection of HCC from 2003 to 2015 were included. The largest tumor from preoperative CT was subjected to quantitative image analysis, which uses an automated computer algorithm to capture regional variation in CT enhancement patterns. Quantitative imaging features by automatic analysis, qualitative radiographic descriptors by 2 radiologists, and preoperative clinical variables were included in multivariate analysis to predict histologic MVI.
RESULTS: Histologic MVI was identified in 19 (37%) patients with tumors ≤5 cm and 34 (49%) patients with tumors >5 cm. Among patients with tumors ≤5 cm, none of the clinical findings or radiographic descriptors were associated with MVI; however, quantitative features based on angle co-occurrence matrix predicted MVI with an area under curve of 0.80, positive predictive value of 63%, and negative predictive value of 85%. In patients with tumors >5 cm, higher α-fetoprotein level, larger tumor size, and viral hepatitis history were associated with MVI, and radiographic descriptors were not. However, a multivariate model combining α-fetoprotein, tumor size, hepatitis status, and quantitative feature based on local binary pattern predicted MVI with area under curve of 0.88, positive predictive value of 72%, and negative predictive value of 96%.
CONCLUSIONS: This study reveals the potential importance of quantitative image analysis as a predictor of MVI.",1,0
33967603,Radiomics Signature: A potential biomarker for the prediction of survival in Advanced Hepatocellular Carcinoma,"Li L, Kan X, Zhao Y, Liang B, Ye T, Yang L, Zheng C.",Int J Med Sci. 2021 Mar 30;18(11):2276-2284. doi: 10.7150/ijms.55510. eCollection 2021.,Li L,Int J Med Sci,2021,10-05-2021,PMC8100633,,10.7150/ijms.55510,"Objectives: To develop and validate radiomics nomograms for the pretreatment predictions of overall survival (OS) and time to progression (TTP) in the patients with advanced hepatocellular carcinoma (HCC) treated with apatinib plus transarterial chemoembolization (TACE), and to assess the incremental value of the clinical-radiomics nomograms for estimating individual OS and TTP. Methods: A total of 60 patients with advanced HCC (BCLC stage C) treated with apatinib plus TACE were divided into a training set (n=48) and a validation set (n=12). The predictors identified from the clinical variables and the radiomics signature constructed from the computed tomography images, such as ɑ-fetoprotein level (AFP), formfactor, the grey level co-occurrence matrix, the gray level size zone matrix, and the gray level run-length matrix, were used to build the clinical-radiomics nomograms and the radiomics nomograms for the prediction of OS and TTP. Results: Apatinib plus TACE benefited the patients with advanced HCC, with a 579-day median OS and a 270-day median TTP. The nomograms were built with the radiomics signature and AFP, and achieved favorable prediction efficacy with acceptable calibration curves. Decision curve analyses demonstrated that the clinical-radiomics nomograms outperformed the radiomics nomograms for the predictions of OS and TTP. Conclusions: Apatinib plus TACE may improve OS and prolonged TTP in the patients with advanced HCC. The clinical-radiomics nomograms, a noninvasive pretreatment prediction tool that incorporate radiomics signature and AFP, demonstrated good prediction accuracy for OS and TTP in these patients. These results indicate that the clinical-radiomics nomograms may provide novel insight for precise personalized medicine approaches in the patients with advanced HCC.","Radiomics Signature: A potential biomarker for the prediction of survival in Advanced Hepatocellular Carcinoma Objectives: To develop and validate radiomics nomograms for the pretreatment predictions of overall survival (OS) and time to progression (TTP) in the patients with advanced hepatocellular carcinoma (HCC) treated with apatinib plus transarterial chemoembolization (TACE), and to assess the incremental value of the clinical-radiomics nomograms for estimating individual OS and TTP. Methods: A total of 60 patients with advanced HCC (BCLC stage C) treated with apatinib plus TACE were divided into a training set (n=48) and a validation set (n=12). The predictors identified from the clinical variables and the radiomics signature constructed from the computed tomography images, such as ɑ-fetoprotein level (AFP), formfactor, the grey level co-occurrence matrix, the gray level size zone matrix, and the gray level run-length matrix, were used to build the clinical-radiomics nomograms and the radiomics nomograms for the prediction of OS and TTP. Results: Apatinib plus TACE benefited the patients with advanced HCC, with a 579-day median OS and a 270-day median TTP. The nomograms were built with the radiomics signature and AFP, and achieved favorable prediction efficacy with acceptable calibration curves. Decision curve analyses demonstrated that the clinical-radiomics nomograms outperformed the radiomics nomograms for the predictions of OS and TTP. Conclusions: Apatinib plus TACE may improve OS and prolonged TTP in the patients with advanced HCC. The clinical-radiomics nomograms, a noninvasive pretreatment prediction tool that incorporate radiomics signature and AFP, demonstrated good prediction accuracy for OS and TTP in these patients. These results indicate that the clinical-radiomics nomograms may provide novel insight for precise personalized medicine approaches in the patients with advanced HCC.",0,0
38131578,Digital eye strain among medical students associated with shifting to e-learning during COVID-19 pandemic: An online survey,"Bhatnagar KR, Dixit SG, Pandey L, Prakash S, Shiromani S, Singh K.",Indian J Ophthalmol. 2024 Jan 1;72(1):98-104. doi: 10.4103/IJO.IJO_492_23. Epub 2023 Dec 22.,Bhatnagar KR,Indian J Ophthalmol,2024,22-12-2023,PMC10841805,,10.4103/IJO.IJO_492_23,"PURPOSE: This study aimed to determine the prevalence, risk factors, symptoms, and awareness of computer vision syndrome (CVS) among medical students during the coronavirus disease 2019 (COVID-19) pandemic.
METHODS: A cross-sectional observational study was conducted among 283 undergraduate medical students at a tertiary healthcare center. An electronic survey was conducted to collect the data. Data were analyzed using Statistical Package for Social Sciences (SPSS version 23). The Chi-square test (Fisher's exact test when required) was used to study the significance of associations. A P value <0.05 was considered statistically significant.
RESULTS: A high prevalence of CVS was observed in which 92% reported at least one symptom while using a digital device, the most frequent being eye strain (49%). Among extraocular complaints, joint pain in the wrist and fingers was most frequent. Significant association (P < 0.05) of CVS was found with increased duration of digital device usage, refractive error, use of glasses or contact lens, preexisting dry eye disease, and use of topical eye drops. 37% of the participants were aware of the 20-20-20 rule, while only 11% followed it.
CONCLUSION: CVS is a common health concern among medical students. Hence, to increase the productivity of work, significant risk factors need to be addressed and awareness must be raised.","Digital eye strain among medical students associated with shifting to e-learning during COVID-19 pandemic: An online survey PURPOSE: This study aimed to determine the prevalence, risk factors, symptoms, and awareness of computer vision syndrome (CVS) among medical students during the coronavirus disease 2019 (COVID-19) pandemic.
METHODS: A cross-sectional observational study was conducted among 283 undergraduate medical students at a tertiary healthcare center. An electronic survey was conducted to collect the data. Data were analyzed using Statistical Package for Social Sciences (SPSS version 23). The Chi-square test (Fisher's exact test when required) was used to study the significance of associations. A P value <0.05 was considered statistically significant.
RESULTS: A high prevalence of CVS was observed in which 92% reported at least one symptom while using a digital device, the most frequent being eye strain (49%). Among extraocular complaints, joint pain in the wrist and fingers was most frequent. Significant association (P < 0.05) of CVS was found with increased duration of digital device usage, refractive error, use of glasses or contact lens, preexisting dry eye disease, and use of topical eye drops. 37% of the participants were aware of the 20-20-20 rule, while only 11% followed it.
CONCLUSION: CVS is a common health concern among medical students. Hence, to increase the productivity of work, significant risk factors need to be addressed and awareness must be raised.",0,0
39269753,Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study,"Soe NN, Yu Z, Latt PM, Lee D, Samra RS, Ge Z, Rahman R, Sun J, Ong JJ, Fairley CK, Zhang L.",J Med Internet Res. 2024 Sep 13;26:e52490. doi: 10.2196/52490.,Soe NN,J Med Internet Res,2024,13-09-2024,PMC11437223,,10.2196/52490,"BACKGROUND: The 2022 global outbreak of mpox has significantly impacted health facilities, and necessitated additional infection prevention and control measures and alterations to clinic processes. Early identification of suspected mpox cases will assist in mitigating these impacts.
OBJECTIVE: We aimed to develop and evaluate an artificial intelligence (AI)-based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic.
METHODS: We used a data set with 2200 images, that included mpox and non-mpox lesions images, collected from Melbourne Sexual Health Centre and web resources. We adopted deep learning approaches which involved 6 different deep learning architectures to train our AI models. We subsequently evaluated the performance of each model using a hold-out data set and an external validation data set to determine the optimal model for differentiating between mpox and non-mpox lesions.
RESULTS: The DenseNet-121 model outperformed other models with an overall area under the receiver operating characteristic curve (AUC) of 0.928, an accuracy of 0.848, a precision of 0.942, a recall of 0.742, and an F<sub>1</sub>-score of 0.834. Implementation of a region of interest approach significantly improved the performance of all models, with the AUC for the DenseNet-121 model increasing to 0.982. This approach resulted in an increase in the correct classification of mpox images from 79% (55/70) to 94% (66/70). The effectiveness of this approach was further validated by a visual analysis with gradient-weighted class activation mapping, demonstrating a reduction in false detection within the background of lesion images. On the external validation data set, ResNet-18 and DenseNet-121 achieved the highest performance. ResNet-18 achieved an AUC of 0.990 and an accuracy of 0.947, and DenseNet-121 achieved an AUC of 0.982 and an accuracy of 0.926.
CONCLUSIONS: Our study demonstrated it was possible to use an AI-based image recognition algorithm to accurately differentiate between mpox and common skin lesions. Our findings provide a foundation for future investigations aimed at refining the algorithm and establishing the place of such technology in a sexual health clinic.","Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study BACKGROUND: The 2022 global outbreak of mpox has significantly impacted health facilities, and necessitated additional infection prevention and control measures and alterations to clinic processes. Early identification of suspected mpox cases will assist in mitigating these impacts.
OBJECTIVE: We aimed to develop and evaluate an artificial intelligence (AI)-based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic.
METHODS: We used a data set with 2200 images, that included mpox and non-mpox lesions images, collected from Melbourne Sexual Health Centre and web resources. We adopted deep learning approaches which involved 6 different deep learning architectures to train our AI models. We subsequently evaluated the performance of each model using a hold-out data set and an external validation data set to determine the optimal model for differentiating between mpox and non-mpox lesions.
RESULTS: The DenseNet-121 model outperformed other models with an overall area under the receiver operating characteristic curve (AUC) of 0.928, an accuracy of 0.848, a precision of 0.942, a recall of 0.742, and an F<sub>1</sub>-score of 0.834. Implementation of a region of interest approach significantly improved the performance of all models, with the AUC for the DenseNet-121 model increasing to 0.982. This approach resulted in an increase in the correct classification of mpox images from 79% (55/70) to 94% (66/70). The effectiveness of this approach was further validated by a visual analysis with gradient-weighted class activation mapping, demonstrating a reduction in false detection within the background of lesion images. On the external validation data set, ResNet-18 and DenseNet-121 achieved the highest performance. ResNet-18 achieved an AUC of 0.990 and an accuracy of 0.947, and DenseNet-121 achieved an AUC of 0.982 and an accuracy of 0.926.
CONCLUSIONS: Our study demonstrated it was possible to use an AI-based image recognition algorithm to accurately differentiate between mpox and common skin lesions. Our findings provide a foundation for future investigations aimed at refining the algorithm and establishing the place of such technology in a sexual health clinic.",1,1
33957941,Comparison of liver exposure in CT-guided high-dose rate (HDR) interstitial brachytherapy versus SBRT in hepatocellular carcinoma,"Walter F, Nierer L, Rottler M, Duque AS, Weingandt H, Well J, Shpani R, Landry G, Seidensticker M, Streitparth F, Ricke J, Belka C, Corradini S.",Radiat Oncol. 2021 May 6;16(1):86. doi: 10.1186/s13014-021-01812-7.,Walter F,Radiat Oncol,2021,07-05-2021,PMC8103624,,10.1186/s13014-021-01812-7,"BACKGROUND: In unresectable hepatocellular carcinoma several local ablative treatments are available. Among others, radiation based treatments such as stereotactic body radiotherapy (SBRT) and high-dose rate interstitial brachytherapy (HDR BT) have shown good local control rates.
METHODS: We conducted a dose comparison between actually performed HDR BT versus virtually planned SBRT to evaluate the respective clinically relevant radiation exposure to uninvolved liver tissue. Moreover, dose coverage and conformity indices were assessed.
RESULTS: Overall, 46 treatment sessions (71 lesions, 38 patients) were evaluated. HDR BT was applied in a single fraction with a dose prescription of 1 × 15 Gy. D98 was 17.9 ± 1.3 Gy, D50 was 41.8 ± 8.1 Gy. The SBRT was planned with a prescribed dose of 3 × 12.5 Gy (65%-Isodose), D98 was 50.7 ± 3.1 Gy, D2 was 57.0 ± 2.3 Gy, and D50 was 55.2 ± 2.3 Gy. Regarding liver exposure Vliver10Gy<sub>BT</sub> was compared to Vliver15.9Gy<sub>SBRT</sub>, Vliver16.2Gy<sub>SBRT</sub> (EQD2 equivalent doses), and Vliver20Gy<sub>SBRT</sub> (clinically relevant dose), all results showed significant differences (p &lt; .001). In a case by case analysis Vliver10Gy<sub>BT</sub> was smaller than Vliver20Gy<sub>SBRT</sub> in 38/46 cases (83%). Dmean of the liver was significantly smaller in BT compared to SBRT (p &lt; .001). GTV volume was correlated to the liver exposure and showed an advantage of HDR BT over SBRT in comparison of clinically relevant doses, and for EQD2 equivalent doses. The advantage was more pronounced for greater liver lesions The Conformity Index (CI) was significantly better for BT, while Healthy Tissue Conformity Index (HTCI) and Conformation Number (CN) showed an advantage for SBRT (p &lt; .001).
CONCLUSION: HDR BT can be advantageous in respect of sparing of normal liver tissue as compared to SBRT, while providing excellent target conformity.","Comparison of liver exposure in CT-guided high-dose rate (HDR) interstitial brachytherapy versus SBRT in hepatocellular carcinoma BACKGROUND: In unresectable hepatocellular carcinoma several local ablative treatments are available. Among others, radiation based treatments such as stereotactic body radiotherapy (SBRT) and high-dose rate interstitial brachytherapy (HDR BT) have shown good local control rates.
METHODS: We conducted a dose comparison between actually performed HDR BT versus virtually planned SBRT to evaluate the respective clinically relevant radiation exposure to uninvolved liver tissue. Moreover, dose coverage and conformity indices were assessed.
RESULTS: Overall, 46 treatment sessions (71 lesions, 38 patients) were evaluated. HDR BT was applied in a single fraction with a dose prescription of 1 × 15 Gy. D98 was 17.9 ± 1.3 Gy, D50 was 41.8 ± 8.1 Gy. The SBRT was planned with a prescribed dose of 3 × 12.5 Gy (65%-Isodose), D98 was 50.7 ± 3.1 Gy, D2 was 57.0 ± 2.3 Gy, and D50 was 55.2 ± 2.3 Gy. Regarding liver exposure Vliver10Gy<sub>BT</sub> was compared to Vliver15.9Gy<sub>SBRT</sub>, Vliver16.2Gy<sub>SBRT</sub> (EQD2 equivalent doses), and Vliver20Gy<sub>SBRT</sub> (clinically relevant dose), all results showed significant differences (p &lt; .001). In a case by case analysis Vliver10Gy<sub>BT</sub> was smaller than Vliver20Gy<sub>SBRT</sub> in 38/46 cases (83%). Dmean of the liver was significantly smaller in BT compared to SBRT (p &lt; .001). GTV volume was correlated to the liver exposure and showed an advantage of HDR BT over SBRT in comparison of clinically relevant doses, and for EQD2 equivalent doses. The advantage was more pronounced for greater liver lesions The Conformity Index (CI) was significantly better for BT, while Healthy Tissue Conformity Index (HTCI) and Conformation Number (CN) showed an advantage for SBRT (p &lt; .001).
CONCLUSION: HDR BT can be advantageous in respect of sparing of normal liver tissue as compared to SBRT, while providing excellent target conformity.",0,0
32511486,The impact of COVID-19 on African American communities in the United States,"Cyrus E, Clarke R, Hadley D, Bursac Z, Trepka MJ, Dévieux JG, Bagci U, Furr-Holden D, Coudray M, Mariano Y, Kiplagat S, Noel I, Ravelo GJ, Paley M, Wagner E.",medRxiv [Preprint]. 2020 May 19:2020.05.15.20096552. doi: 10.1101/2020.05.15.20096552.,Cyrus E,medRxiv,2020,09-06-2020,PMC7273254,,10.1101/2020.05.15.20096552,"IMPORTANCE: The novel Coronavirus Disease 2019 (COVID-19), declared a pandemic in March 2020, may present with disproportionately higher rates in underrepresented racial/ethnic minority populations in the United States, including African American communities who have traditionally been over-represented in negative health outcomes.
STUDY OBJECTIVE: To understand the impact of the density of African American communities (defined as the percentage of African Americans in a county) on COVID-19 prevalence and death rate within the three most populous counties in each U.S. state and territory (n=152). Design: An ecological study using linear regression was employed for the study.
SETTING: The top three most populous counties of each U.S. state and territory were included in analyses for a final sample size of n=152 counties.
PARTICIPANTS: Confirmed COVID-19 cases and deaths that were accumulated between January 22, 2020 and April 12, 2020 in each of the three most populous counties in each U.S. state and territory were included.
MAIN OUTCOME MEASURES: Linear regression was used to determine the association between African American density and COVID-19 prevalence (defined as the percentage of cases for the county population), and death rate (defined as number of deaths per 100,000 population). The models were adjusted for median age and poverty.
RESULTS: There was a direct association between African American density and COVID-19 prevalence; COVID-19 prevalence increased 5% for every 1% increase in county AA density (p<.01). There was also an association between county AA density and COVID-19 deaths, such; the death rate increased 2 per 100,000 for every percentage increase in county AA density (p=.02).
CONCLUSION: These study findings indicate that communities with a high African American density have been disproportionately burdened with COVID-19. Further study is needed to indicate if this burden is related to environmental factors or individual factors such as types of employment or comorbidities that members of these community have.","The impact of COVID-19 on African American communities in the United States IMPORTANCE: The novel Coronavirus Disease 2019 (COVID-19), declared a pandemic in March 2020, may present with disproportionately higher rates in underrepresented racial/ethnic minority populations in the United States, including African American communities who have traditionally been over-represented in negative health outcomes.
STUDY OBJECTIVE: To understand the impact of the density of African American communities (defined as the percentage of African Americans in a county) on COVID-19 prevalence and death rate within the three most populous counties in each U.S. state and territory (n=152). Design: An ecological study using linear regression was employed for the study.
SETTING: The top three most populous counties of each U.S. state and territory were included in analyses for a final sample size of n=152 counties.
PARTICIPANTS: Confirmed COVID-19 cases and deaths that were accumulated between January 22, 2020 and April 12, 2020 in each of the three most populous counties in each U.S. state and territory were included.
MAIN OUTCOME MEASURES: Linear regression was used to determine the association between African American density and COVID-19 prevalence (defined as the percentage of cases for the county population), and death rate (defined as number of deaths per 100,000 population). The models were adjusted for median age and poverty.
RESULTS: There was a direct association between African American density and COVID-19 prevalence; COVID-19 prevalence increased 5% for every 1% increase in county AA density (p<.01). There was also an association between county AA density and COVID-19 deaths, such; the death rate increased 2 per 100,000 for every percentage increase in county AA density (p=.02).
CONCLUSION: These study findings indicate that communities with a high African American density have been disproportionately burdened with COVID-19. Further study is needed to indicate if this burden is related to environmental factors or individual factors such as types of employment or comorbidities that members of these community have.",0,0
28445292,Prognostic value of immunoscore to identify mortality outcomes in adults with HBV-related primary hepatocellular carcinoma,"Yao Q, Bao X, Xue R, Liu H, Liu H, Li J, Dong J, Duan Z, Ren M, Zhao J, Song Q, Yu H, Zhu Y, Lu J, Meng Q.",Medicine (Baltimore). 2017 Apr;96(17):e6735. doi: 10.1097/MD.0000000000006735.,Yao Q,Medicine (Baltimore),2017,27-04-2017,PMC5413257,,10.1097/MD.0000000000006735,"This study aimed to determine if the immunoscore (IS) staging system would be a potential prognostic factor in hepatitis B virus-related hepatocellular carcinoma (HBV-HCC) in China.IS was performed in a consecutive cohort of HBV-HCC patients (n= 92). CD3+, CD8+, and CD45RO+ T cells were quantified by immunohistochemical analyses. The patients were stratified into 5 IS groups: I0, I1, I2, I3, I4 for every 2 cell phenotypes (IS1 (CD8/CD45RO, IS2 (CD3/CD8), and IS3 (CD3/CD45RO), respectively. ImagePro Plus software was used in the calculation of the paraffin-embedded tumor sections.The staining of CD3+, CD8+, and CD45RO+ cells in the HBV-HCC tissue demonstrated that there were higher density and larger area of lymphocytes in the invasive margins (IM) region than in the center (CT). Univariate analysis showed that preoperative TNM staging (P = .01), serum gamma-glutamyl transpeptidase (GGT) level (P = .03), vascular invasion (P = .00), and density of CD3+T (CT) (P = 0.01) were correlated significantly with disease-free survival (DFS); serum alpha-fetoprotein (AFP) level (P = .02), tumor size (P = .00), serum cholinesterase (CHE) (P = .04), and GGT level (P = .01), density of CD3+T(CT) (P = .00), CD8+T(CT)(P = .00), CD45RO+T(CT) (P = .00), and CD45RO+T (IM) (P = .02) were correlated with overall survival (OS). Multivariate analysis showed that TNM staging was not an independent prognostic factor of DFS and OS. Our results showed ISs did not have a significantly correlation with DFS (P = .35, .19, and .07, respectively), but it was correlated significantly with OS (P = .00, .00, and .00, respectively). There were statistical differences among the OS of every ISs subgroup except I0 and I1 by the Cox regressions analysis.The IS staging was closely related to the outcome of patients. It can compensate the TNM tumor classification system in predicting the prognosis of HBV-HCC patients.","Prognostic value of immunoscore to identify mortality outcomes in adults with HBV-related primary hepatocellular carcinoma This study aimed to determine if the immunoscore (IS) staging system would be a potential prognostic factor in hepatitis B virus-related hepatocellular carcinoma (HBV-HCC) in China.IS was performed in a consecutive cohort of HBV-HCC patients (n= 92). CD3+, CD8+, and CD45RO+ T cells were quantified by immunohistochemical analyses. The patients were stratified into 5 IS groups: I0, I1, I2, I3, I4 for every 2 cell phenotypes (IS1 (CD8/CD45RO, IS2 (CD3/CD8), and IS3 (CD3/CD45RO), respectively. ImagePro Plus software was used in the calculation of the paraffin-embedded tumor sections.The staining of CD3+, CD8+, and CD45RO+ cells in the HBV-HCC tissue demonstrated that there were higher density and larger area of lymphocytes in the invasive margins (IM) region than in the center (CT). Univariate analysis showed that preoperative TNM staging (P = .01), serum gamma-glutamyl transpeptidase (GGT) level (P = .03), vascular invasion (P = .00), and density of CD3+T (CT) (P = 0.01) were correlated significantly with disease-free survival (DFS); serum alpha-fetoprotein (AFP) level (P = .02), tumor size (P = .00), serum cholinesterase (CHE) (P = .04), and GGT level (P = .01), density of CD3+T(CT) (P = .00), CD8+T(CT)(P = .00), CD45RO+T(CT) (P = .00), and CD45RO+T (IM) (P = .02) were correlated with overall survival (OS). Multivariate analysis showed that TNM staging was not an independent prognostic factor of DFS and OS. Our results showed ISs did not have a significantly correlation with DFS (P = .35, .19, and .07, respectively), but it was correlated significantly with OS (P = .00, .00, and .00, respectively). There were statistical differences among the OS of every ISs subgroup except I0 and I1 by the Cox regressions analysis.The IS staging was closely related to the outcome of patients. It can compensate the TNM tumor classification system in predicting the prognosis of HBV-HCC patients.",0,0
29164651,Jaw closing movement and sex differences in temporomandibular joint energy densities,"Gallo LM, Fankhauser N, Gonzalez YM, Liu H, Liu Y, Nickel JC, Iwasaki LR.",J Oral Rehabil. 2018 Feb;45(2):97-103. doi: 10.1111/joor.12588. Epub 2017 Dec 7.,Gallo LM,J Oral Rehabil,2018,23-11-2017,PMC5799013,NIHMS921859,10.1111/joor.12588,"Energy densities (ED, mJ/mm3 ) quantify mechanical work imposed on articular cartilages during function. This cross-sectional study examined differences in temporomandibular joint (TMJ) ED during asymmetric versus symmetric jaw closing in healthy females versus males. ED component variables were tested for differences between and within sexes for two types of jaw closing. Seventeen female and 17 male subjects gave informed consent to participate. Diagnostic criteria for temporomandibular disorders and images (magnetic resonance (MR), computed tomography) were used to confirm healthy TMJ status. Numerical modelling predicted TMJ loads (F<sub>normal</sub> ) consequent to unilateral canine biting. Dynamic stereometry combined MR imaging and jaw-tracking data to measure ED component variables during 10 trials of each type of jaw closing in each subject's TMJs. These data were then used to calculate TMJ ED during jaw closing asymmetrically and symmetrically. Paired and Student's t tests assessed ED between jaw closing movements and sexes, respectively. Multivariate data analyses assessed ED component variable differences between jaw closing movements and sexes (α = 0.05). Contralateral TMJ ED were 3.6-fold and significantly larger (P &lt; .0001) during asymmetric versus symmetric jaw closing, due to significantly larger (P ≤ .001) distances of TMJ stress-field translation in asymmetric versus symmetric movement. During asymmetric jaw closing, contralateral TMJ ED were twofold and significantly larger (P = .036) in females versus males, due to 1.5-fold and significantly smaller (P ≤ .010) TMJ disc cartilage volumes under stress fields in females versus males. These results suggest that in healthy individuals, asymmetric compared to symmetric jaw closure in females compared to males has higher TMJ mechanical fatigue liabilities.","Jaw closing movement and sex differences in temporomandibular joint energy densities Energy densities (ED, mJ/mm3 ) quantify mechanical work imposed on articular cartilages during function. This cross-sectional study examined differences in temporomandibular joint (TMJ) ED during asymmetric versus symmetric jaw closing in healthy females versus males. ED component variables were tested for differences between and within sexes for two types of jaw closing. Seventeen female and 17 male subjects gave informed consent to participate. Diagnostic criteria for temporomandibular disorders and images (magnetic resonance (MR), computed tomography) were used to confirm healthy TMJ status. Numerical modelling predicted TMJ loads (F<sub>normal</sub> ) consequent to unilateral canine biting. Dynamic stereometry combined MR imaging and jaw-tracking data to measure ED component variables during 10 trials of each type of jaw closing in each subject's TMJs. These data were then used to calculate TMJ ED during jaw closing asymmetrically and symmetrically. Paired and Student's t tests assessed ED between jaw closing movements and sexes, respectively. Multivariate data analyses assessed ED component variable differences between jaw closing movements and sexes (α = 0.05). Contralateral TMJ ED were 3.6-fold and significantly larger (P &lt; .0001) during asymmetric versus symmetric jaw closing, due to significantly larger (P ≤ .001) distances of TMJ stress-field translation in asymmetric versus symmetric movement. During asymmetric jaw closing, contralateral TMJ ED were twofold and significantly larger (P = .036) in females versus males, due to 1.5-fold and significantly smaller (P ≤ .010) TMJ disc cartilage volumes under stress fields in females versus males. These results suggest that in healthy individuals, asymmetric compared to symmetric jaw closure in females compared to males has higher TMJ mechanical fatigue liabilities.",0,0
30252971,Artificial Intelligence Applied to Osteoporosis: A Performance Comparison of Machine Learning Algorithms in Predicting Fragility Fractures From MRI Data,"Ferizi U, Besser H, Hysi P, Jacobs J, Rajapakse CS, Chen C, Saha PK, Honig S, Chang G.",J Magn Reson Imaging. 2019 Apr;49(4):1029-1038. doi: 10.1002/jmri.26280. Epub 2018 Sep 25.,Ferizi U,J Magn Reson Imaging,2019,26-09-2018,PMC7340101,NIHMS1033111,10.1002/jmri.26280,"BACKGROUND: A current challenge in osteoporosis is identifying patients at risk of bone fracture.
PURPOSE: To identify the machine learning classifiers that predict best osteoporotic bone fractures and, from the data, to highlight the imaging features and the anatomical regions that contribute most to prediction performance.
STUDY TYPE: Prospective (cross-sectional) case-control study.
POPULATION: Thirty-two women with prior fragility bone fractures, of mean age = 61.6 and body mass index (BMI) = 22.7 kg/m2 , and 60 women without fractures, of mean age = 62.3 and BMI = 21.4 kg/m2 . Field Strength/ Sequence: 3D FLASH at 3T.
ASSESSMENT: Quantitative MRI outcomes by software algorithms. Mechanical and topological microstructural parameters of the trabecular bone were calculated for five femoral regions, and added to the vector of features together with bone mineral density measurement, fracture risk assessment tool (FRAX) score, and personal characteristics such as age, weight, and height. We fitted 15 classifiers using 200 randomized cross-validation datasets. Statistical Tests: Data: Kolmogorov-Smirnov test for normality. Model Performance: sensitivity, specificity, precision, accuracy, F1-test, receiver operating characteristic curve (ROC). Two-sided t-test, with P < 0.05 for statistical significance.
RESULTS: The top three performing classifiers are RUS-boosted trees (in particular, performing best with head data, F1 = 0.64 ± 0.03), the logistic regression and the linear discriminant (both best with trochanteric datasets, F1 = 0.65 ± 0.03 and F1 = 0.67 ± 0.03, respectively). A permutation of these classifiers comprised the best three performers for four out of five anatomical datasets. After averaging across all the anatomical datasets, the score for the best performer, the boosted trees, was F1 = 0.63 ± 0.03 for All-features dataset, F1 = 0.52 ± 0.05 for the no-MRI dataset, and F1 = 0.48 ± 0.06 for the no-FRAX dataset. Data Conclusion: Of many classifiers, the RUS-boosted trees, the logistic regression, and the linear discriminant are best for predicting osteoporotic fracture. Both MRI and FRAX independently add value in identifying osteoporotic fractures. The femoral head, greater trochanter, and inter-trochanter anatomical regions within the proximal femur yielded better F1-scores for the best three classifiers.
LEVEL OF EVIDENCE: 2 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019;49:1029-1038.","Artificial Intelligence Applied to Osteoporosis: A Performance Comparison of Machine Learning Algorithms in Predicting Fragility Fractures From MRI Data BACKGROUND: A current challenge in osteoporosis is identifying patients at risk of bone fracture.
PURPOSE: To identify the machine learning classifiers that predict best osteoporotic bone fractures and, from the data, to highlight the imaging features and the anatomical regions that contribute most to prediction performance.
STUDY TYPE: Prospective (cross-sectional) case-control study.
POPULATION: Thirty-two women with prior fragility bone fractures, of mean age = 61.6 and body mass index (BMI) = 22.7 kg/m2 , and 60 women without fractures, of mean age = 62.3 and BMI = 21.4 kg/m2 . Field Strength/ Sequence: 3D FLASH at 3T.
ASSESSMENT: Quantitative MRI outcomes by software algorithms. Mechanical and topological microstructural parameters of the trabecular bone were calculated for five femoral regions, and added to the vector of features together with bone mineral density measurement, fracture risk assessment tool (FRAX) score, and personal characteristics such as age, weight, and height. We fitted 15 classifiers using 200 randomized cross-validation datasets. Statistical Tests: Data: Kolmogorov-Smirnov test for normality. Model Performance: sensitivity, specificity, precision, accuracy, F1-test, receiver operating characteristic curve (ROC). Two-sided t-test, with P < 0.05 for statistical significance.
RESULTS: The top three performing classifiers are RUS-boosted trees (in particular, performing best with head data, F1 = 0.64 ± 0.03), the logistic regression and the linear discriminant (both best with trochanteric datasets, F1 = 0.65 ± 0.03 and F1 = 0.67 ± 0.03, respectively). A permutation of these classifiers comprised the best three performers for four out of five anatomical datasets. After averaging across all the anatomical datasets, the score for the best performer, the boosted trees, was F1 = 0.63 ± 0.03 for All-features dataset, F1 = 0.52 ± 0.05 for the no-MRI dataset, and F1 = 0.48 ± 0.06 for the no-FRAX dataset. Data Conclusion: Of many classifiers, the RUS-boosted trees, the logistic regression, and the linear discriminant are best for predicting osteoporotic fracture. Both MRI and FRAX independently add value in identifying osteoporotic fractures. The femoral head, greater trochanter, and inter-trochanter anatomical regions within the proximal femur yielded better F1-scores for the best three classifiers.
LEVEL OF EVIDENCE: 2 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019;49:1029-1038.",1,0
30681560,Mandibular width as a novel anthropometric measure for assessing obstructive sleep apnea risk,"Maresky HS, Klar MM, Tepper J, Gavriel H, Ziv Baran T, Shapiro CM, Tal S.",Medicine (Baltimore). 2019 Jan;98(4):e14040. doi: 10.1097/MD.0000000000014040.,Maresky HS,Medicine (Baltimore),2019,26-01-2019,PMC6358386,,10.1097/MD.0000000000014040,"Craniofacial abnormalities are a known obstructive sleep apnea (OSA) risk factor, but still need to be better characterized. This study investigates the relationship between mandibular width and the risk of developing OSA.We retrospectively analyzed 3D reconstructions of head and neck computed tomography (CT) scans at our institution for mandibular width, neck circumference, neck fat volume (NFV), airway volume (AWV), and NFV:AWV ratio. Age, gender, and BMI were also documented. Patients were contacted to complete a STOP-BANG survey to assess OSA risk. Only patients with reconstructable scans and completed STOP-BANG questionnaires were included in the study. Survey results were analyzed to assess the correlation between mandible width and STOP-BANG. Mandible association was also compared to the associations of the other known risk factors.The final analysis included 427 patients with a mean age of 58.98 years (standard deviation = 16.77), 56% of whom were male. Mandibular width was found to positively correlate with STOP-BANG score (r = .416, P < .001). Statistically significant differences between mandible size for each risk group was seen (P < .001). After controlling for age and sex, mandible size was significantly different only for the low risk vs. high risk groups (odds ratio = 1.11; 95% confidence interval = 1.03-1.20; P = .007). Furthermore, when stratified according to mandible size, the small mandible group (<77.50 mm) predominantly consisted of low risk patients; the medium size mandible group (77.50-84.40 mm) was predominated by intermediate risk patients, and large mandible (>84.40 mm) was predominantly seen in high risk patients. Mandible width expressed a stronger association than NFV:AWV ratio, but neck circumference and NFV had stronger associations than did mandible width.In addition to previously documented OSA risk factors, mandibular width is positively correlated with OSA as an independent risk factor. Observation of a wide mandible (jaw) should raise awareness of OSA risk and increase screening methods when appropriate.","Mandibular width as a novel anthropometric measure for assessing obstructive sleep apnea risk Craniofacial abnormalities are a known obstructive sleep apnea (OSA) risk factor, but still need to be better characterized. This study investigates the relationship between mandibular width and the risk of developing OSA.We retrospectively analyzed 3D reconstructions of head and neck computed tomography (CT) scans at our institution for mandibular width, neck circumference, neck fat volume (NFV), airway volume (AWV), and NFV:AWV ratio. Age, gender, and BMI were also documented. Patients were contacted to complete a STOP-BANG survey to assess OSA risk. Only patients with reconstructable scans and completed STOP-BANG questionnaires were included in the study. Survey results were analyzed to assess the correlation between mandible width and STOP-BANG. Mandible association was also compared to the associations of the other known risk factors.The final analysis included 427 patients with a mean age of 58.98 years (standard deviation = 16.77), 56% of whom were male. Mandibular width was found to positively correlate with STOP-BANG score (r = .416, P < .001). Statistically significant differences between mandible size for each risk group was seen (P < .001). After controlling for age and sex, mandible size was significantly different only for the low risk vs. high risk groups (odds ratio = 1.11; 95% confidence interval = 1.03-1.20; P = .007). Furthermore, when stratified according to mandible size, the small mandible group (<77.50 mm) predominantly consisted of low risk patients; the medium size mandible group (77.50-84.40 mm) was predominated by intermediate risk patients, and large mandible (>84.40 mm) was predominantly seen in high risk patients. Mandible width expressed a stronger association than NFV:AWV ratio, but neck circumference and NFV had stronger associations than did mandible width.In addition to previously documented OSA risk factors, mandibular width is positively correlated with OSA as an independent risk factor. Observation of a wide mandible (jaw) should raise awareness of OSA risk and increase screening methods when appropriate.",0,0
31844886,"Safety and efficacy of VB-111, an anticancer gene therapy, in patients with recurrent glioblastoma: results of a phase I/II study","Brenner AJ, Peters KB, Vredenburgh J, Bokstein F, Blumenthal DT, Yust-Katz S, Peretz I, Oberman B, Freedman LS, Ellingson BM, Cloughesy TF, Sher N, Cohen YC, Lowenton-Spier N, Rachmilewitz Minei T, Yakov N, Mendel I, Breitbart E, Wen PY.",Neuro Oncol. 2020 May 15;22(5):694-704. doi: 10.1093/neuonc/noz231.,Brenner AJ,Neuro Oncol,2020,18-12-2019,PMC7229257,,10.1093/neuonc/noz231,"BACKGROUND: VB-111 is a non-replicating adenovirus carrying a Fas-chimera transgene, leading to targeted apoptosis of tumor vascular endothelium and induction of a tumor-specific immune response. This phase I/II study evaluated the safety, tolerability, and efficacy of VB-111 with and without bevacizumab in recurrent glioblastoma (rGBM).
METHODS: Patients with rGBM (n = 72) received VB-111 in 4 treatment groups: subtherapeutic (VB-111 dose escalation), limited exposure (LE; VB-111 monotherapy until progression), primed combination (VB-111 monotherapy continued upon progression with combination of bevacizumab), and unprimed combination (upfront combination of VB-111 and bevacizumab). The primary endpoint was median overall survival (OS). Secondary endpoints were safety, overall response rate, and progression-free survival (PFS).
RESULTS: VB-111 was well tolerated. The most common adverse event was transient mild-moderate fever. Median OS time was significantly longer in the primed combination group compared with both LE (414 vs 223 days; hazard ratio [HR], 0.48; P = 0.043) and unprimed combination (414 vs 141.5 days; HR, 0.24; P = 0.0056). Patients in the combination phase of the primed combination group had a median PFS time of 90 days compared with 60 in the LE group (HR, 0.36; P = 0.032), and 63 in the unprimed combination group (P = 0.72). Radiographic responders to VB-111 exhibited characteristic, expansive areas of necrosis in the areas of initial enhancing disease.
CONCLUSIONS: Patients with rGBM who were primed with VB-111 monotherapy that continued after progression with the addition of bevacizumab showed significant survival and PFS advantage, as well as specific imaging characteristics related to VB-111 mechanism of action. These results warrant further assessment in a randomized controlled study.","Safety and efficacy of VB-111, an anticancer gene therapy, in patients with recurrent glioblastoma: results of a phase I/II study BACKGROUND: VB-111 is a non-replicating adenovirus carrying a Fas-chimera transgene, leading to targeted apoptosis of tumor vascular endothelium and induction of a tumor-specific immune response. This phase I/II study evaluated the safety, tolerability, and efficacy of VB-111 with and without bevacizumab in recurrent glioblastoma (rGBM).
METHODS: Patients with rGBM (n = 72) received VB-111 in 4 treatment groups: subtherapeutic (VB-111 dose escalation), limited exposure (LE; VB-111 monotherapy until progression), primed combination (VB-111 monotherapy continued upon progression with combination of bevacizumab), and unprimed combination (upfront combination of VB-111 and bevacizumab). The primary endpoint was median overall survival (OS). Secondary endpoints were safety, overall response rate, and progression-free survival (PFS).
RESULTS: VB-111 was well tolerated. The most common adverse event was transient mild-moderate fever. Median OS time was significantly longer in the primed combination group compared with both LE (414 vs 223 days; hazard ratio [HR], 0.48; P = 0.043) and unprimed combination (414 vs 141.5 days; HR, 0.24; P = 0.0056). Patients in the combination phase of the primed combination group had a median PFS time of 90 days compared with 60 in the LE group (HR, 0.36; P = 0.032), and 63 in the unprimed combination group (P = 0.72). Radiographic responders to VB-111 exhibited characteristic, expansive areas of necrosis in the areas of initial enhancing disease.
CONCLUSIONS: Patients with rGBM who were primed with VB-111 monotherapy that continued after progression with the addition of bevacizumab showed significant survival and PFS advantage, as well as specific imaging characteristics related to VB-111 mechanism of action. These results warrant further assessment in a randomized controlled study.",0,0
35589255,Artificial intelligence for the prevention and clinical management of hepatocellular carcinoma,"Calderaro J, Seraphin TP, Luedde T, Simon TG.",J Hepatol. 2022 Jun;76(6):1348-1361. doi: 10.1016/j.jhep.2022.01.014.,Calderaro J,J Hepatol,2022,19-05-2022,PMC9126418,NIHMS1776807,10.1016/j.jhep.2022.01.014,"Hepatocellular carcinoma (HCC) currently represents the fifth most common malignancy and the third-leading cause of cancer-related death worldwide, with incidence and mortality rates that are increasing. Recently, artificial intelligence (AI) has emerged as a unique opportunity to improve the full spectrum of HCC clinical care, by improving HCC risk prediction, diagnosis, and prognostication. AI approaches include computational search algorithms, machine learning (ML) and deep learning (DL) models. ML consists of a computer running repeated iterations of models, in order to progressively improve performance of a specific task, such as classifying an outcome. DL models are a subtype of ML, based on neural network structures that are inspired by the neuroanatomy of the human brain. A growing body of recent data now apply DL models to diverse data sources - including electronic health record data, imaging modalities, histopathology and molecular biomarkers - to improve the accuracy of HCC risk prediction, detection and prediction of treatment response. Despite the promise of these early results, future research is still needed to standardise AI data, and to improve both the generalisability and interpretability of results. If such challenges can be overcome, AI has the potential to profoundly change the way in which care is provided to patients with or at risk of HCC.","Artificial intelligence for the prevention and clinical management of hepatocellular carcinoma Hepatocellular carcinoma (HCC) currently represents the fifth most common malignancy and the third-leading cause of cancer-related death worldwide, with incidence and mortality rates that are increasing. Recently, artificial intelligence (AI) has emerged as a unique opportunity to improve the full spectrum of HCC clinical care, by improving HCC risk prediction, diagnosis, and prognostication. AI approaches include computational search algorithms, machine learning (ML) and deep learning (DL) models. ML consists of a computer running repeated iterations of models, in order to progressively improve performance of a specific task, such as classifying an outcome. DL models are a subtype of ML, based on neural network structures that are inspired by the neuroanatomy of the human brain. A growing body of recent data now apply DL models to diverse data sources - including electronic health record data, imaging modalities, histopathology and molecular biomarkers - to improve the accuracy of HCC risk prediction, detection and prediction of treatment response. Despite the promise of these early results, future research is still needed to standardise AI data, and to improve both the generalisability and interpretability of results. If such challenges can be overcome, AI has the potential to profoundly change the way in which care is provided to patients with or at risk of HCC.",1,0
36688019,Artificial intelligence and inflammatory bowel disease: Where are we going?,"Da Rio L, Spadaccini M, Parigi TL, Gabbiadini R, Dal Buono A, Busacca A, Maselli R, Fugazza A, Colombo M, Carrara S, Franchellucci G, Alfarone L, Facciorusso A, Hassan C, Repici A, Armuzzi A.",World J Gastroenterol. 2023 Jan 21;29(3):508-520. doi: 10.3748/wjg.v29.i3.508.,Da Rio L,World J Gastroenterol,2023,23-01-2023,PMC9850939,,10.3748/wjg.v29.i3.508,"Inflammatory bowel diseases, namely ulcerative colitis and Crohn's disease, are chronic and relapsing conditions that pose a growing burden on healthcare systems worldwide. Because of their complex and partly unknown etiology and pathogenesis, the management of ulcerative colitis and Crohn's disease can prove challenging not only from a clinical point of view but also for resource optimization. Artificial intelligence, an umbrella term that encompasses any cognitive function developed by machines for learning or problem solving, and its subsets machine learning and deep learning are becoming ever more essential tools with a plethora of applications in most medical specialties. In this regard gastroenterology is no exception, and due to the importance of endoscopy and imaging numerous clinical studies have been gradually highlighting the relevant role that artificial intelligence has in inflammatory bowel diseases as well. The aim of this review was to summarize the most recent evidence on the use of artificial intelligence in inflammatory bowel diseases in various contexts such as diagnosis, follow-up, treatment, prognosis, cancer surveillance, data collection, and analysis. Moreover, insights into the potential further developments in this field and their effects on future clinical practice were discussed.","Artificial intelligence and inflammatory bowel disease: Where are we going? Inflammatory bowel diseases, namely ulcerative colitis and Crohn's disease, are chronic and relapsing conditions that pose a growing burden on healthcare systems worldwide. Because of their complex and partly unknown etiology and pathogenesis, the management of ulcerative colitis and Crohn's disease can prove challenging not only from a clinical point of view but also for resource optimization. Artificial intelligence, an umbrella term that encompasses any cognitive function developed by machines for learning or problem solving, and its subsets machine learning and deep learning are becoming ever more essential tools with a plethora of applications in most medical specialties. In this regard gastroenterology is no exception, and due to the importance of endoscopy and imaging numerous clinical studies have been gradually highlighting the relevant role that artificial intelligence has in inflammatory bowel diseases as well. The aim of this review was to summarize the most recent evidence on the use of artificial intelligence in inflammatory bowel diseases in various contexts such as diagnosis, follow-up, treatment, prognosis, cancer surveillance, data collection, and analysis. Moreover, insights into the potential further developments in this field and their effects on future clinical practice were discussed.",1,0
32898686,"Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective","Li JO, Liu H, Ting DSJ, Jeon S, Chan RVP, Kim JE, Sim DA, Thomas PBM, Lin H, Chen Y, Sakomoto T, Loewenstein A, Lam DSC, Pasquale LR, Wong TY, Lam LA, Ting DSW.",Prog Retin Eye Res. 2021 May;82:100900. doi: 10.1016/j.preteyeres.2020.100900. Epub 2020 Sep 6.,Li JO,Prog Retin Eye Res,2021,08-09-2020,PMC7474840,,10.1016/j.preteyeres.2020.100900,"The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a ""new normal"", the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.","Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a ""new normal"", the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.",0,0
37799217,Reimagining Healthcare: Unleashing the Power of Artificial Intelligence in Medicine,"Iqbal J, Cortés Jaimes DC, Makineni P, Subramani S, Hemaida S, Thugu TR, Butt AN, Sikto JT, Kaur P, Lak MA, Augustine M, Shahzad R, Arain M.",Cureus. 2023 Sep 4;15(9):e44658. doi: 10.7759/cureus.44658. eCollection 2023 Sep.,Iqbal J,Cureus,2023,06-10-2023,PMC10549955,,10.7759/cureus.44658,"Artificial intelligence (AI) has opened new medical avenues and revolutionized diagnostic and therapeutic practices, allowing healthcare providers to overcome significant challenges associated with cost, disease management, accessibility, and treatment optimization. Prominent AI technologies such as machine learning (ML) and deep learning (DL) have immensely influenced diagnostics, patient monitoring, novel pharmaceutical discoveries, drug development, and telemedicine. Significant innovations and improvements in disease identification and early intervention have been made using AI-generated algorithms for clinical decision support systems and disease prediction models. AI has remarkably impacted clinical drug trials by amplifying research into drug efficacy, adverse events, and candidate molecular design. AI's precision and analysis regarding patients' genetic, environmental, and lifestyle factors have led to individualized treatment strategies. During the COVID-19 pandemic, AI-assisted telemedicine set a precedent for remote healthcare delivery and patient follow-up. Moreover, AI-generated applications and wearable devices have allowed ambulatory monitoring of vital signs. However, apart from being immensely transformative, AI's contribution to healthcare is subject to ethical and regulatory concerns. AI-backed data protection and algorithm transparency should be strictly adherent to ethical principles. Vigorous governance frameworks should be in place before incorporating AI in mental health interventions through AI-operated chatbots, medical education enhancements, and virtual reality-based training. The role of AI in medical decision-making has certain limitations, necessitating the importance of hands-on experience. Therefore, reaching an optimal balance between AI's capabilities and ethical considerations to ensure impartial and neutral performance in healthcare applications is crucial. This narrative review focuses on AI's impact on healthcare and the importance of ethical and balanced incorporation to make use of its full potential.","Reimagining Healthcare: Unleashing the Power of Artificial Intelligence in Medicine Artificial intelligence (AI) has opened new medical avenues and revolutionized diagnostic and therapeutic practices, allowing healthcare providers to overcome significant challenges associated with cost, disease management, accessibility, and treatment optimization. Prominent AI technologies such as machine learning (ML) and deep learning (DL) have immensely influenced diagnostics, patient monitoring, novel pharmaceutical discoveries, drug development, and telemedicine. Significant innovations and improvements in disease identification and early intervention have been made using AI-generated algorithms for clinical decision support systems and disease prediction models. AI has remarkably impacted clinical drug trials by amplifying research into drug efficacy, adverse events, and candidate molecular design. AI's precision and analysis regarding patients' genetic, environmental, and lifestyle factors have led to individualized treatment strategies. During the COVID-19 pandemic, AI-assisted telemedicine set a precedent for remote healthcare delivery and patient follow-up. Moreover, AI-generated applications and wearable devices have allowed ambulatory monitoring of vital signs. However, apart from being immensely transformative, AI's contribution to healthcare is subject to ethical and regulatory concerns. AI-backed data protection and algorithm transparency should be strictly adherent to ethical principles. Vigorous governance frameworks should be in place before incorporating AI in mental health interventions through AI-operated chatbots, medical education enhancements, and virtual reality-based training. The role of AI in medical decision-making has certain limitations, necessitating the importance of hands-on experience. Therefore, reaching an optimal balance between AI's capabilities and ethical considerations to ensure impartial and neutral performance in healthcare applications is crucial. This narrative review focuses on AI's impact on healthcare and the importance of ethical and balanced incorporation to make use of its full potential.",1,0
37780897,"Transforming clinical virology with AI, machine learning and deep learning: a comprehensive review and outlook","Padhi A, Agarwal A, Saxena SK, Katoch CDS.",Virusdisease. 2023 Sep;34(3):345-355. doi: 10.1007/s13337-023-00841-y. Epub 2023 Sep 21.,Padhi A,Virusdisease,2023,02-10-2023,PMC10533451,,10.1007/s13337-023-00841-y,"In the rapidly evolving field of clinical virology, technological advancements have always played a pivotal role in driving transformative changes. This comprehensive review delves into the burgeoning integration of artificial intelligence (AI), machine learning, and deep learning into virological research and practice. As we elucidate, these computational tools have significantly enhanced diagnostic precision, therapeutic interventions, and epidemiological monitoring. Through in-depth analyses of notable case studies, we showcase how algorithms can optimize viral genome sequencing, accelerate drug discovery, and offer predictive insights into viral outbreaks. However, with these advancements come inherent challenges, particularly in data security, algorithmic biases, and ethical considerations. Addressing these challenges head-on, we discuss potential remedial measures and underscore the significance of interdisciplinary collaboration between virologists, data scientists, and ethicists. Conclusively, this review posits an outlook that anticipates a symbiotic relationship between AI-driven tools and virology, heralding a new era of proactive and personalized patient care.","Transforming clinical virology with AI, machine learning and deep learning: a comprehensive review and outlook In the rapidly evolving field of clinical virology, technological advancements have always played a pivotal role in driving transformative changes. This comprehensive review delves into the burgeoning integration of artificial intelligence (AI), machine learning, and deep learning into virological research and practice. As we elucidate, these computational tools have significantly enhanced diagnostic precision, therapeutic interventions, and epidemiological monitoring. Through in-depth analyses of notable case studies, we showcase how algorithms can optimize viral genome sequencing, accelerate drug discovery, and offer predictive insights into viral outbreaks. However, with these advancements come inherent challenges, particularly in data security, algorithmic biases, and ethical considerations. Addressing these challenges head-on, we discuss potential remedial measures and underscore the significance of interdisciplinary collaboration between virologists, data scientists, and ethicists. Conclusively, this review posits an outlook that anticipates a symbiotic relationship between AI-driven tools and virology, heralding a new era of proactive and personalized patient care.",0,1
35564493,"Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review","Saleem F, Al-Ghamdi ASA, Alassafi MO, AlGhamdi SA.",Int J Environ Res Public Health. 2022 Apr 22;19(9):5099. doi: 10.3390/ijerph19095099.,Saleem F,Int J Environ Res Public Health,2022,14-05-2022,PMC9099605,,10.3390/ijerph19095099,"COVID-19 is a disease caused by SARS-CoV-2 and has been declared a worldwide pandemic by the World Health Organization due to its rapid spread. Since the first case was identified in Wuhan, China, the battle against this deadly disease started and has disrupted almost every field of life. Medical staff and laboratories are leading from the front, but researchers from various fields and governmental agencies have also proposed healthy ideas to protect each other. In this article, a Systematic Literature Review (SLR) is presented to highlight the latest developments in analyzing the COVID-19 data using machine learning and deep learning algorithms. The number of studies related to Machine Learning (ML), Deep Learning (DL), and mathematical models discussed in this research has shown a significant impact on forecasting and the spread of COVID-19. The results and discussion presented in this study are based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Out of 218 articles selected at the first stage, 57 met the criteria and were included in the review process. The findings are therefore associated with those 57 studies, which recorded that CNN (DL) and SVM (ML) are the most used algorithms for forecasting, classification, and automatic detection. The importance of the compartmental models discussed is that the models are useful for measuring the epidemiological features of COVID-19. Current findings suggest that it will take around 1.7 to 140 days for the epidemic to double in size based on the selected studies. The 12 estimates for the basic reproduction range from 0 to 7.1. The main purpose of this research is to illustrate the use of ML, DL, and mathematical models that can be helpful for the researchers to generate valuable solutions for higher authorities and the healthcare industry to reduce the impact of this epidemic.","Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review COVID-19 is a disease caused by SARS-CoV-2 and has been declared a worldwide pandemic by the World Health Organization due to its rapid spread. Since the first case was identified in Wuhan, China, the battle against this deadly disease started and has disrupted almost every field of life. Medical staff and laboratories are leading from the front, but researchers from various fields and governmental agencies have also proposed healthy ideas to protect each other. In this article, a Systematic Literature Review (SLR) is presented to highlight the latest developments in analyzing the COVID-19 data using machine learning and deep learning algorithms. The number of studies related to Machine Learning (ML), Deep Learning (DL), and mathematical models discussed in this research has shown a significant impact on forecasting and the spread of COVID-19. The results and discussion presented in this study are based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Out of 218 articles selected at the first stage, 57 met the criteria and were included in the review process. The findings are therefore associated with those 57 studies, which recorded that CNN (DL) and SVM (ML) are the most used algorithms for forecasting, classification, and automatic detection. The importance of the compartmental models discussed is that the models are useful for measuring the epidemiological features of COVID-19. Current findings suggest that it will take around 1.7 to 140 days for the epidemic to double in size based on the selected studies. The 12 estimates for the basic reproduction range from 0 to 7.1. The main purpose of this research is to illustrate the use of ML, DL, and mathematical models that can be helpful for the researchers to generate valuable solutions for higher authorities and the healthcare industry to reduce the impact of this epidemic.",1,1
34629796,Artificial intelligence for hepatitis evaluation,"Liu W, Liu X, Peng M, Chen GQ, Liu PH, Cui XW, Jiang F, Dietrich CF.",World J Gastroenterol. 2021 Sep 14;27(34):5715-5726. doi: 10.3748/wjg.v27.i34.5715.,Liu W,World J Gastroenterol,2021,11-10-2021,PMC8473592,,10.3748/wjg.v27.i34.5715,"Recently, increasing attention has been paid to the application of artificial intelligence (AI) to the diagnosis of diverse hepatic diseases, which comprises traditional machine learning and deep learning. Recent studies have shown the possible value of AI based data mining in predicting the incidence of hepatitis, classifying the different stages of hepatitis, diagnosing or screening for hepatitis, forecasting the progression of hepatitis, and predicting response to antiviral drugs in chronic hepatitis C patients. More importantly, AI based on radiology has been proven to be useful in predicting hepatitis and liver fibrosis as well as grading hepatocellular carcinoma (HCC) and differentiating it from benign liver tumors. It can predict the risk of vascular invasion of HCC, the risk of hepatic encephalopathy secondary to hepatitis B related cirrhosis, and the risk of liver failure after hepatectomy in HCC patients. In this review, we summarize the application of AI in hepatitis, and identify the challenges and future perspectives.","Artificial intelligence for hepatitis evaluation Recently, increasing attention has been paid to the application of artificial intelligence (AI) to the diagnosis of diverse hepatic diseases, which comprises traditional machine learning and deep learning. Recent studies have shown the possible value of AI based data mining in predicting the incidence of hepatitis, classifying the different stages of hepatitis, diagnosing or screening for hepatitis, forecasting the progression of hepatitis, and predicting response to antiviral drugs in chronic hepatitis C patients. More importantly, AI based on radiology has been proven to be useful in predicting hepatitis and liver fibrosis as well as grading hepatocellular carcinoma (HCC) and differentiating it from benign liver tumors. It can predict the risk of vascular invasion of HCC, the risk of hepatic encephalopathy secondary to hepatitis B related cirrhosis, and the risk of liver failure after hepatectomy in HCC patients. In this review, we summarize the application of AI in hepatitis, and identify the challenges and future perspectives.",0,1
37354819,"Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations","Rafique Q, Rehman A, Afghan MS, Ahmad HM, Zafar I, Fayyaz K, Ain Q, Rayan RA, Al-Aidarous KM, Rashid S, Mushtaq G, Sharma R.",Comput Biol Med. 2023 Sep;163:107191. doi: 10.1016/j.compbiomed.2023.107191. Epub 2023 Jun 20.,Rafique Q,Comput Biol Med,2023,24-06-2023,PMC10281043,,10.1016/j.compbiomed.2023.107191,"The COVID-19 pandemic has necessitated the development of reliable diagnostic methods for accurately detecting the novel coronavirus and its variants. Deep learning (DL) techniques have shown promising potential as screening tools for COVID-19 detection. In this study, we explore the realistic development of DL-driven COVID-19 detection methods and focus on the fully automatic framework using available resources, which can effectively investigate various coronavirus variants through modalities. We conducted an exploration and comparison of several diagnostic techniques that are widely used and globally validated for the detection of COVID-19. Furthermore, we explore review-based studies that provide detailed information on synergistic medicine combinations for the treatment of COVID-19. We recommend DL methods that effectively reduce time, cost, and complexity, providing valuable guidance for utilizing available synergistic combinations in clinical and research settings. This study also highlights the implication of innovative diagnostic technical and instrumental strategies, exploring public datasets, and investigating synergistic medicines using optimised DL rules. By summarizing these findings, we aim to assist future researchers in their endeavours by providing a comprehensive overview of the implication of DL techniques in COVID-19 detection and treatment. Integrating DL methods with various diagnostic approaches holds great promise in improving the accuracy and efficiency of COVID-19 diagnostics, thus contributing to effective control and management of the ongoing pandemic.","Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations The COVID-19 pandemic has necessitated the development of reliable diagnostic methods for accurately detecting the novel coronavirus and its variants. Deep learning (DL) techniques have shown promising potential as screening tools for COVID-19 detection. In this study, we explore the realistic development of DL-driven COVID-19 detection methods and focus on the fully automatic framework using available resources, which can effectively investigate various coronavirus variants through modalities. We conducted an exploration and comparison of several diagnostic techniques that are widely used and globally validated for the detection of COVID-19. Furthermore, we explore review-based studies that provide detailed information on synergistic medicine combinations for the treatment of COVID-19. We recommend DL methods that effectively reduce time, cost, and complexity, providing valuable guidance for utilizing available synergistic combinations in clinical and research settings. This study also highlights the implication of innovative diagnostic technical and instrumental strategies, exploring public datasets, and investigating synergistic medicines using optimised DL rules. By summarizing these findings, we aim to assist future researchers in their endeavours by providing a comprehensive overview of the implication of DL techniques in COVID-19 detection and treatment. Integrating DL methods with various diagnostic approaches holds great promise in improving the accuracy and efficiency of COVID-19 diagnostics, thus contributing to effective control and management of the ongoing pandemic.",0,1
36909463,REPRODUCIBLE AND CLINICALLY TRANSLATABLE DEEP NEURAL NETWORKS FOR CANCER SCREENING,"Ahmed SR, Befano B, Lemay A, Egemen D, Rodriguez AC, Angara S, Desai K, Jeronimo J, Antani S, Campos N, Inturrisi F, Perkins R, Kreimer A, Wentzensen N, Herrero R, Del Pino M, Quint W, de Sanjose S, Schiffman M, Kalpathy-Cramer J.",Res Sq [Preprint]. 2023 Mar 3:rs.3.rs-2526701. doi: 10.21203/rs.3.rs-2526701/v1.,Ahmed SR,Res Sq,2023,13-03-2023,PMC10002800,,10.21203/rs.3.rs-2526701/v1,"Cervical cancer is a leading cause of cancer mortality, with approximately 90% of the 250,000 deaths per year occurring in low- and middle-income countries (LMIC). Secondary prevention with cervical screening involves detecting and treating precursor lesions; however, scaling screening efforts in LMIC has been hampered by infrastructure and cost constraints. Recent work has supported the development of an artificial intelligence (AI) pipeline on digital images of the cervix to achieve an accurate and reliable diagnosis of treatable precancerous lesions. In particular, WHO guidelines emphasize visual triage of women testing positive for human papillomavirus (HPV) as the primary screen, and AI could assist in this triage task. Published AI reports have exhibited overfitting, lack of portability, and unrealistic, near-perfect performance estimates. To surmount recognized issues, we implemented a comprehensive deep-learning model selection and optimization study on a large, collated, multi-institutional dataset of 9,462 women (17,013 images). We evaluated relative portability, repeatability, and classification performance. The top performing model, when combined with HPV type, achieved an area under the Receiver Operating Characteristics (ROC) curve (AUC) of 0.89 within our study population of interest, and a limited total extreme misclassification rate of 3.4%, on held-aside test sets. Our work is among the first efforts at designing a robust, repeatable, accurate and clinically translatable deep-learning model for cervical screening.","REPRODUCIBLE AND CLINICALLY TRANSLATABLE DEEP NEURAL NETWORKS FOR CANCER SCREENING Cervical cancer is a leading cause of cancer mortality, with approximately 90% of the 250,000 deaths per year occurring in low- and middle-income countries (LMIC). Secondary prevention with cervical screening involves detecting and treating precursor lesions; however, scaling screening efforts in LMIC has been hampered by infrastructure and cost constraints. Recent work has supported the development of an artificial intelligence (AI) pipeline on digital images of the cervix to achieve an accurate and reliable diagnosis of treatable precancerous lesions. In particular, WHO guidelines emphasize visual triage of women testing positive for human papillomavirus (HPV) as the primary screen, and AI could assist in this triage task. Published AI reports have exhibited overfitting, lack of portability, and unrealistic, near-perfect performance estimates. To surmount recognized issues, we implemented a comprehensive deep-learning model selection and optimization study on a large, collated, multi-institutional dataset of 9,462 women (17,013 images). We evaluated relative portability, repeatability, and classification performance. The top performing model, when combined with HPV type, achieved an area under the Receiver Operating Characteristics (ROC) curve (AUC) of 0.89 within our study population of interest, and a limited total extreme misclassification rate of 3.4%, on held-aside test sets. Our work is among the first efforts at designing a robust, repeatable, accurate and clinically translatable deep-learning model for cervical screening.",1,0
35711777,Machine Learning Advances in Microbiology: A Review of Methods and Applications,"Jiang Y, Luo J, Huang D, Liu Y, Li DD.",Front Microbiol. 2022 May 26;13:925454. doi: 10.3389/fmicb.2022.925454. eCollection 2022.,Jiang Y,Front Microbiol,2022,17-06-2022,PMC9196628,,10.3389/fmicb.2022.925454,"Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery.","Machine Learning Advances in Microbiology: A Review of Methods and Applications Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery.",1,0
35991702,Dengue outbreak and severity prediction: current methods and the future scope,"Balakumar M, Vontela HR, Shinde VV, Kulshrestha V, Mishra B, Aduri R.",Virusdisease. 2022 Jun;33(2):125-131. doi: 10.1007/s13337-022-00767-x. Epub 2022 May 13.,Balakumar M,Virusdisease,2022,22-08-2022,PMC9381676,,10.1007/s13337-022-00767-x,"Dengue virus (DENV) is the causative agent of dengue fever and severe dengue. Every year, millions of people are infected with this virus. There is no vaccine available for this disease. Dengue virus is present in four serologically varying strains, DENV 1, 2, 3, and 4, and each of these serotypes is further classified into various genotypes based on the geographic distribution and genetic variance. Mosquitoes play the role of vectors for this disease. Tropical countries and some temperate parts of the world witness outbreaks of dengue mainly during the monsoon (rainy) seasons. Several algorithms have been developed to predict the occurrence and prognosis of dengue disease. These algorithms are mainly based on epidemiological data, climate factors, and online search patterns in the infected area. Most of these algorithms are based on either machine learning or deep learning techniques. We summarize the different software tools available for predicting the outbreaks of dengue based on the aforementioned factors, briefly outline the methodology used in these algorithms, and provide a comprehensive list of programs available for the same in this article.","Dengue outbreak and severity prediction: current methods and the future scope Dengue virus (DENV) is the causative agent of dengue fever and severe dengue. Every year, millions of people are infected with this virus. There is no vaccine available for this disease. Dengue virus is present in four serologically varying strains, DENV 1, 2, 3, and 4, and each of these serotypes is further classified into various genotypes based on the geographic distribution and genetic variance. Mosquitoes play the role of vectors for this disease. Tropical countries and some temperate parts of the world witness outbreaks of dengue mainly during the monsoon (rainy) seasons. Several algorithms have been developed to predict the occurrence and prognosis of dengue disease. These algorithms are mainly based on epidemiological data, climate factors, and online search patterns in the infected area. Most of these algorithms are based on either machine learning or deep learning techniques. We summarize the different software tools available for predicting the outbreaks of dengue based on the aforementioned factors, briefly outline the methodology used in these algorithms, and provide a comprehensive list of programs available for the same in this article.",1,0
32946413,Artificial Intelligence for COVID-19: Rapid Review,"Chen J, See KC.",J Med Internet Res. 2020 Oct 27;22(10):e21476. doi: 10.2196/21476.,Chen J,J Med Internet Res,2020,18-09-2020,PMC7595751,,10.2196/21476,"BACKGROUND: COVID-19 was first discovered in December 2019 and has since evolved into a pandemic.
OBJECTIVE: To address this global health crisis, artificial intelligence (AI) has been deployed at various levels of the health care system. However, AI has both potential benefits and limitations. We therefore conducted a review of AI applications for COVID-19.
METHODS: We performed an extensive search of the PubMed and EMBASE databases for COVID-19-related English-language studies published between December 1, 2019, and March 31, 2020. We supplemented the database search with reference list checks. A thematic analysis and narrative review of AI applications for COVID-19 was conducted.
RESULTS: In total, 11 papers were included for review. AI was applied to COVID-19 in four areas: diagnosis, public health, clinical decision making, and therapeutics. We identified several limitations including insufficient data, omission of multimodal methods of AI-based assessment, delay in realization of benefits, poor internal/external validation, inability to be used by laypersons, inability to be used in resource-poor settings, presence of ethical pitfalls, and presence of legal barriers. AI could potentially be explored in four other areas: surveillance, combination with big data, operation of other core clinical services, and management of patients with COVID-19.
CONCLUSIONS: In view of the continuing increase in the number of cases, and given that multiple waves of infections may occur, there is a need for effective methods to help control the COVID-19 pandemic. Despite its shortcomings, AI holds the potential to greatly augment existing human efforts, which may otherwise be overwhelmed by high patient numbers.","Artificial Intelligence for COVID-19: Rapid Review BACKGROUND: COVID-19 was first discovered in December 2019 and has since evolved into a pandemic.
OBJECTIVE: To address this global health crisis, artificial intelligence (AI) has been deployed at various levels of the health care system. However, AI has both potential benefits and limitations. We therefore conducted a review of AI applications for COVID-19.
METHODS: We performed an extensive search of the PubMed and EMBASE databases for COVID-19-related English-language studies published between December 1, 2019, and March 31, 2020. We supplemented the database search with reference list checks. A thematic analysis and narrative review of AI applications for COVID-19 was conducted.
RESULTS: In total, 11 papers were included for review. AI was applied to COVID-19 in four areas: diagnosis, public health, clinical decision making, and therapeutics. We identified several limitations including insufficient data, omission of multimodal methods of AI-based assessment, delay in realization of benefits, poor internal/external validation, inability to be used by laypersons, inability to be used in resource-poor settings, presence of ethical pitfalls, and presence of legal barriers. AI could potentially be explored in four other areas: surveillance, combination with big data, operation of other core clinical services, and management of patients with COVID-19.
CONCLUSIONS: In view of the continuing increase in the number of cases, and given that multiple waves of infections may occur, there is a need for effective methods to help control the COVID-19 pandemic. Despite its shortcomings, AI holds the potential to greatly augment existing human efforts, which may otherwise be overwhelmed by high patient numbers.",0,1
36355921,Application of machine learning for multi-community COVID-19 outbreak predictions with wastewater surveillance,"Ai Y, He F, Lancaster E, Lee J.",PLoS One. 2022 Nov 10;17(11):e0277154. doi: 10.1371/journal.pone.0277154. eCollection 2022.,Ai Y,PLoS One,2022,10-11-2022,PMC9648834,,10.1371/journal.pone.0277154,"The potential of wastewater-based epidemiology (WBE) as a surveillance and early warning tool for the COVID-19 outbreak has been demonstrated. For areas with limited testing capacity, wastewater surveillance can provide information on the disease dynamic at a community level. A predictive model is a key to generating quantitative estimates of the infected population. Modeling longitudinal wastewater data can be challenging as biomarkers in wastewater are susceptible to variations caused by multiple factors associated with the wastewater matrix and the sewersheds characteristics. As WBE is an emerging trend, the model should be able to address the uncertainties of wastewater from different sewersheds. We proposed exploiting machine learning and deep learning techniques, which are supported by the growing WBE data. In this article, we reviewed the existing predictive models, among which the emerging machine learning/deep learning models showed great potential. However, most models are built for individual sewersheds with few features extracted from the wastewater. To fulfill the research gap, we compared different time-series and non-time-series models for their short-term predictive performance of COVID-19 cases in 9 diverse sewersheds. The time-series models, long short-term memory (LSTM) and Prophet, outcompeted the non-time-series models. Besides viral (SARS-CoV-2) loads and location identity, domain-specific features like biochemical parameters of wastewater, geographical parameters of the sewersheds, and some socioeconomic parameters of the communities can contribute to the models. With proper feature engineering and hyperparameter tuning, we believe machine learning models like LSTM can be a feasible solution for the COVID-19 trend prediction via WBE. Overall, this is a proof-of-concept study on the application of machine learning in COVID-19 WBE. Future studies are needed to deploy and maintain the model in more real-world applications.","Application of machine learning for multi-community COVID-19 outbreak predictions with wastewater surveillance The potential of wastewater-based epidemiology (WBE) as a surveillance and early warning tool for the COVID-19 outbreak has been demonstrated. For areas with limited testing capacity, wastewater surveillance can provide information on the disease dynamic at a community level. A predictive model is a key to generating quantitative estimates of the infected population. Modeling longitudinal wastewater data can be challenging as biomarkers in wastewater are susceptible to variations caused by multiple factors associated with the wastewater matrix and the sewersheds characteristics. As WBE is an emerging trend, the model should be able to address the uncertainties of wastewater from different sewersheds. We proposed exploiting machine learning and deep learning techniques, which are supported by the growing WBE data. In this article, we reviewed the existing predictive models, among which the emerging machine learning/deep learning models showed great potential. However, most models are built for individual sewersheds with few features extracted from the wastewater. To fulfill the research gap, we compared different time-series and non-time-series models for their short-term predictive performance of COVID-19 cases in 9 diverse sewersheds. The time-series models, long short-term memory (LSTM) and Prophet, outcompeted the non-time-series models. Besides viral (SARS-CoV-2) loads and location identity, domain-specific features like biochemical parameters of wastewater, geographical parameters of the sewersheds, and some socioeconomic parameters of the communities can contribute to the models. With proper feature engineering and hyperparameter tuning, we believe machine learning models like LSTM can be a feasible solution for the COVID-19 trend prediction via WBE. Overall, this is a proof-of-concept study on the application of machine learning in COVID-19 WBE. Future studies are needed to deploy and maintain the model in more real-world applications.",1,1
37930788,Deep Learning Analysis of COVID-19 Vaccine Hesitancy and Confidence Expressed on Twitter in 6 High-Income Countries: Longitudinal Observational Study,"Zhou X, Song S, Zhang Y, Hou Z.",J Med Internet Res. 2023 Nov 6;25:e49753. doi: 10.2196/49753.,Zhou X,J Med Internet Res,2023,06-11-2023,PMC10629504,,10.2196/49753,"BACKGROUND: An ongoing monitoring of national and subnational trajectory of COVID-19 vaccine hesitancy could offer support in designing tailored policies on improving vaccine uptake.
OBJECTIVE: We aim to track the temporal and spatial distribution of COVID-19 vaccine hesitancy and confidence expressed on Twitter during the entire pandemic period in major English-speaking countries.
METHODS: We collected 5,257,385 English-language tweets regarding COVID-19 vaccination between January 1, 2020, and June 30, 2022, in 6 countries-the United States, the United Kingdom, Australia, New Zealand, Canada, and Ireland. Transformer-based deep learning models were developed to classify each tweet as intent to accept or reject COVID-19 vaccination and the belief that COVID-19 vaccine is effective or unsafe. Sociodemographic factors associated with COVID-19 vaccine hesitancy and confidence in the United States were analyzed using bivariate and multivariable linear regressions.
RESULTS: The 6 countries experienced similar evolving trends of COVID-19 vaccine hesitancy and confidence. On average, the prevalence of intent to accept COVID-19 vaccination decreased from 71.38% of 44,944 tweets in March 2020 to 34.85% of 48,167 tweets in June 2022 with fluctuations. The prevalence of believing COVID-19 vaccines to be unsafe continuously rose by 7.49 times from March 2020 (2.84% of 44,944 tweets) to June 2022 (21.27% of 48,167 tweets). COVID-19 vaccine hesitancy and confidence varied by country, vaccine manufacturer, and states within a country. The democrat party and higher vaccine confidence were significantly associated with lower vaccine hesitancy across US states.
CONCLUSIONS: COVID-19 vaccine hesitancy and confidence evolved and were influenced by the development of vaccines and viruses during the pandemic. Large-scale self-generated discourses on social media and deep learning models provide a cost-efficient approach to monitoring routine vaccine hesitancy.","Deep Learning Analysis of COVID-19 Vaccine Hesitancy and Confidence Expressed on Twitter in 6 High-Income Countries: Longitudinal Observational Study BACKGROUND: An ongoing monitoring of national and subnational trajectory of COVID-19 vaccine hesitancy could offer support in designing tailored policies on improving vaccine uptake.
OBJECTIVE: We aim to track the temporal and spatial distribution of COVID-19 vaccine hesitancy and confidence expressed on Twitter during the entire pandemic period in major English-speaking countries.
METHODS: We collected 5,257,385 English-language tweets regarding COVID-19 vaccination between January 1, 2020, and June 30, 2022, in 6 countries-the United States, the United Kingdom, Australia, New Zealand, Canada, and Ireland. Transformer-based deep learning models were developed to classify each tweet as intent to accept or reject COVID-19 vaccination and the belief that COVID-19 vaccine is effective or unsafe. Sociodemographic factors associated with COVID-19 vaccine hesitancy and confidence in the United States were analyzed using bivariate and multivariable linear regressions.
RESULTS: The 6 countries experienced similar evolving trends of COVID-19 vaccine hesitancy and confidence. On average, the prevalence of intent to accept COVID-19 vaccination decreased from 71.38% of 44,944 tweets in March 2020 to 34.85% of 48,167 tweets in June 2022 with fluctuations. The prevalence of believing COVID-19 vaccines to be unsafe continuously rose by 7.49 times from March 2020 (2.84% of 44,944 tweets) to June 2022 (21.27% of 48,167 tweets). COVID-19 vaccine hesitancy and confidence varied by country, vaccine manufacturer, and states within a country. The democrat party and higher vaccine confidence were significantly associated with lower vaccine hesitancy across US states.
CONCLUSIONS: COVID-19 vaccine hesitancy and confidence evolved and were influenced by the development of vaccines and viruses during the pandemic. Large-scale self-generated discourses on social media and deep learning models provide a cost-efficient approach to monitoring routine vaccine hesitancy.",0,1
35025860,Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review,"da Silva Neto SR, Tabosa Oliveira T, Teixeira IV, Aguiar de Oliveira SB, Souza Sampaio V, Lynn T, Endo PT.",PLoS Negl Trop Dis. 2022 Jan 13;16(1):e0010061. doi: 10.1371/journal.pntd.0010061. eCollection 2022 Jan.,da Silva Neto SR,PLoS Negl Trop Dis,2022,13-01-2022,PMC8791518,,10.1371/journal.pntd.0010061,"BACKGROUND: Neglected tropical diseases (NTDs) primarily affect the poorest populations, often living in remote, rural areas, urban slums or conflict zones. Arboviruses are a significant NTD category spread by mosquitoes. Dengue, Chikungunya, and Zika are three arboviruses that affect a large proportion of the population in Latin and South America. The clinical diagnosis of these arboviral diseases is a difficult task due to the concurrent circulation of several arboviruses which present similar symptoms, inaccurate serologic tests resulting from cross-reaction and co-infection with other arboviruses.
OBJECTIVE: The goal of this paper is to present evidence on the state of the art of studies investigating the automatic classification of arboviral diseases to support clinical diagnosis based on Machine Learning (ML) and Deep Learning (DL) models.
METHOD: We carried out a Systematic Literature Review (SLR) in which Google Scholar was searched to identify key papers on the topic. From an initial 963 records (956 from string-based search and seven from a single backward snowballing procedure), only 15 relevant papers were identified.
RESULTS: Results show that current research is focused on the binary classification of Dengue, primarily using tree-based ML algorithms. Only one paper was identified using DL. Five papers presented solutions for multi-class problems, covering Dengue (and its variants) and Chikungunya. No papers were identified that investigated models to differentiate between Dengue, Chikungunya, and Zika.
CONCLUSIONS: The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment. It should help physicians in their decision-making process and, consequently, improve the use of resources and the patient's quality of life.","Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review BACKGROUND: Neglected tropical diseases (NTDs) primarily affect the poorest populations, often living in remote, rural areas, urban slums or conflict zones. Arboviruses are a significant NTD category spread by mosquitoes. Dengue, Chikungunya, and Zika are three arboviruses that affect a large proportion of the population in Latin and South America. The clinical diagnosis of these arboviral diseases is a difficult task due to the concurrent circulation of several arboviruses which present similar symptoms, inaccurate serologic tests resulting from cross-reaction and co-infection with other arboviruses.
OBJECTIVE: The goal of this paper is to present evidence on the state of the art of studies investigating the automatic classification of arboviral diseases to support clinical diagnosis based on Machine Learning (ML) and Deep Learning (DL) models.
METHOD: We carried out a Systematic Literature Review (SLR) in which Google Scholar was searched to identify key papers on the topic. From an initial 963 records (956 from string-based search and seven from a single backward snowballing procedure), only 15 relevant papers were identified.
RESULTS: Results show that current research is focused on the binary classification of Dengue, primarily using tree-based ML algorithms. Only one paper was identified using DL. Five papers presented solutions for multi-class problems, covering Dengue (and its variants) and Chikungunya. No papers were identified that investigated models to differentiate between Dengue, Chikungunya, and Zika.
CONCLUSIONS: The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment. It should help physicians in their decision-making process and, consequently, improve the use of resources and the patient's quality of life.",1,1
33907522,Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives,"Huang S, Yang J, Fong S, Zhao Q.",Int J Biol Sci. 2021 Apr 10;17(6):1581-1587. doi: 10.7150/ijbs.58855. eCollection 2021.,Huang S,Int J Biol Sci,2021,28-04-2021,PMC8071762,,10.7150/ijbs.58855,"Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic.","Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic.",1,1
33594374,SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning,"Magge A, Weissenbacher D, O'Connor K, Scotch M, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2022 Mar 21:2021.02.09.21251454. doi: 10.1101/2021.02.09.21251454.,Magge A,medRxiv,2022,17-02-2021,PMC7885933,,10.1101/2021.02.09.21251454,"The increase of social media usage across the globe has fueled efforts in digital epidemiology for mining valuable information such as medication use, adverse drug effects and reports of viral infections that directly and indirectly affect population health. Such specific information can, however, be scarce, hard to find, and mostly expressed in very colloquial language. In this work, we focus on a fundamental problem that enables social media mining for disease monitoring. We present and make available SEED, a natural language processing approach to detect symptom and disease mentions from social media data obtained from platforms such as Twitter and DailyStrength and to normalize them into UMLS terminology. Using multi-corpus training and deep learning models, the tool achieves an overall F1 score of 0.86 and 0.72 on DailyStrength and balanced Twitter datasets, significantly improving over previous approaches on the same datasets. We apply the tool on Twitter posts that report COVID19 symptoms, particularly to quantify whether the SEED system can extract symptoms absent in the training data. The study results also draw attention to the potential of multi-corpus training for performance improvements and the need for continuous training on newly obtained data for consistent performance amidst the ever-changing nature of the social media vocabulary.","SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning The increase of social media usage across the globe has fueled efforts in digital epidemiology for mining valuable information such as medication use, adverse drug effects and reports of viral infections that directly and indirectly affect population health. Such specific information can, however, be scarce, hard to find, and mostly expressed in very colloquial language. In this work, we focus on a fundamental problem that enables social media mining for disease monitoring. We present and make available SEED, a natural language processing approach to detect symptom and disease mentions from social media data obtained from platforms such as Twitter and DailyStrength and to normalize them into UMLS terminology. Using multi-corpus training and deep learning models, the tool achieves an overall F1 score of 0.86 and 0.72 on DailyStrength and balanced Twitter datasets, significantly improving over previous approaches on the same datasets. We apply the tool on Twitter posts that report COVID19 symptoms, particularly to quantify whether the SEED system can extract symptoms absent in the training data. The study results also draw attention to the potential of multi-corpus training for performance improvements and the need for continuous training on newly obtained data for consistent performance amidst the ever-changing nature of the social media vocabulary.",1,0
35326674,The Role of Artificial Intelligence in Early Cancer Diagnosis,"Hunter B, Hindocha S, Lee RW.",Cancers (Basel). 2022 Mar 16;14(6):1524. doi: 10.3390/cancers14061524.,Hunter B,Cancers (Basel),2022,25-03-2022,PMC8946688,,10.3390/cancers14061524,"Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.","The Role of Artificial Intelligence in Early Cancer Diagnosis Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.",1,0
36056223,Usage of Compartmental Models in Predicting COVID-19 Outbreaks,"Zhang P, Feng K, Gong Y, Lee J, Lomonaco S, Zhao L.",AAPS J. 2022 Sep 2;24(5):98. doi: 10.1208/s12248-022-00743-9.,Zhang P,AAPS J,2022,02-09-2022,PMC9439263,,10.1208/s12248-022-00743-9,"Accurately predicting the spread of the SARS-CoV-2, the cause of the COVID-19 pandemic, is of great value for global regulatory authorities to overcome a number of challenges including medication shortage, outcome of vaccination, and control strategies planning. Modeling methods that are used to simulate and predict the spread of COVID-19 include compartmental model, structured metapopulations, agent-based networks, deep learning, and complex network, with compartmental modeling as one of the most widely used methods. Compartmental model has two noteworthy features, a flexible framework that allows users to easily customize the model structure and its high adaptivity that allows well-matured approaches (e.g., Bayesian inference and mixed-effects modeling) to improve parameter estimation. We retrospectively evaluated the prediction performances of the compartmental models on the CDC COVID-19 Mathematical Modeling webpage based on data collected between August 2020 and February 2021, and subsequently discussed in detail their corresponding model enhancement. Finally, we presented examples using the compartmental models to assist policymaking. By evaluating all models in parallel, we systemically evaluated the performance and evolution of using compartmental models for COVID-19 pandemic prediction. In summary, as a 100-year-old epidemic approach, the compartmental model presents a powerful tool that is extremely adaptive and can be readily customized and implemented to address new data or emerging needs during a pandemic.","Usage of Compartmental Models in Predicting COVID-19 Outbreaks Accurately predicting the spread of the SARS-CoV-2, the cause of the COVID-19 pandemic, is of great value for global regulatory authorities to overcome a number of challenges including medication shortage, outcome of vaccination, and control strategies planning. Modeling methods that are used to simulate and predict the spread of COVID-19 include compartmental model, structured metapopulations, agent-based networks, deep learning, and complex network, with compartmental modeling as one of the most widely used methods. Compartmental model has two noteworthy features, a flexible framework that allows users to easily customize the model structure and its high adaptivity that allows well-matured approaches (e.g., Bayesian inference and mixed-effects modeling) to improve parameter estimation. We retrospectively evaluated the prediction performances of the compartmental models on the CDC COVID-19 Mathematical Modeling webpage based on data collected between August 2020 and February 2021, and subsequently discussed in detail their corresponding model enhancement. Finally, we presented examples using the compartmental models to assist policymaking. By evaluating all models in parallel, we systemically evaluated the performance and evolution of using compartmental models for COVID-19 pandemic prediction. In summary, as a 100-year-old epidemic approach, the compartmental model presents a powerful tool that is extremely adaptive and can be readily customized and implemented to address new data or emerging needs during a pandemic.",1,0
33326405,Role of Machine Learning Techniques to Tackle the COVID-19 Crisis: Systematic Review,"Syeda HB, Syed M, Sexton KW, Syed S, Begum S, Syed F, Prior F, Yu F Jr.",JMIR Med Inform. 2021 Jan 11;9(1):e23811. doi: 10.2196/23811.,Syeda HB,JMIR Med Inform,2021,16-12-2020,PMC7806275,,10.2196/23811,"BACKGROUND: SARS-CoV-2, the novel coronavirus responsible for COVID-19, has caused havoc worldwide, with patients presenting a spectrum of complications that have pushed health care experts to explore new technological solutions and treatment plans. Artificial Intelligence (AI)-based technologies have played a substantial role in solving complex problems, and several organizations have been swift to adopt and customize these technologies in response to the challenges posed by the COVID-19 pandemic.
OBJECTIVE: The objective of this study was to conduct a systematic review of the literature on the role of AI as a comprehensive and decisive technology to fight the COVID-19 crisis in the fields of epidemiology, diagnosis, and disease progression.
METHODS: A systematic search of PubMed, Web of Science, and CINAHL databases was performed according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analysis) guidelines to identify all potentially relevant studies published and made available online between December 1, 2019, and June 27, 2020. The search syntax was built using keywords specific to COVID-19 and AI.
RESULTS: The search strategy resulted in 419 articles published and made available online during the aforementioned period. Of these, 130 publications were selected for further analyses. These publications were classified into 3 themes based on AI applications employed to combat the COVID-19 crisis: Computational Epidemiology, Early Detection and Diagnosis, and Disease Progression. Of the 130 studies, 71 (54.6%) focused on predicting the COVID-19 outbreak, the impact of containment policies, and potential drug discoveries, which were classified under the Computational Epidemiology theme. Next, 40 of 130 (30.8%) studies that applied AI techniques to detect COVID-19 by using patients' radiological images or laboratory test results were classified under the Early Detection and Diagnosis theme. Finally, 19 of the 130 studies (14.6%) that focused on predicting disease progression, outcomes (ie, recovery and mortality), length of hospital stay, and number of days spent in the intensive care unit for patients with COVID-19 were classified under the Disease Progression theme.
CONCLUSIONS: In this systematic review, we assembled studies in the current COVID-19 literature that utilized AI-based methods to provide insights into different COVID-19 themes. Our findings highlight important variables, data types, and available COVID-19 resources that can assist in facilitating clinical and translational research.","Role of Machine Learning Techniques to Tackle the COVID-19 Crisis: Systematic Review BACKGROUND: SARS-CoV-2, the novel coronavirus responsible for COVID-19, has caused havoc worldwide, with patients presenting a spectrum of complications that have pushed health care experts to explore new technological solutions and treatment plans. Artificial Intelligence (AI)-based technologies have played a substantial role in solving complex problems, and several organizations have been swift to adopt and customize these technologies in response to the challenges posed by the COVID-19 pandemic.
OBJECTIVE: The objective of this study was to conduct a systematic review of the literature on the role of AI as a comprehensive and decisive technology to fight the COVID-19 crisis in the fields of epidemiology, diagnosis, and disease progression.
METHODS: A systematic search of PubMed, Web of Science, and CINAHL databases was performed according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analysis) guidelines to identify all potentially relevant studies published and made available online between December 1, 2019, and June 27, 2020. The search syntax was built using keywords specific to COVID-19 and AI.
RESULTS: The search strategy resulted in 419 articles published and made available online during the aforementioned period. Of these, 130 publications were selected for further analyses. These publications were classified into 3 themes based on AI applications employed to combat the COVID-19 crisis: Computational Epidemiology, Early Detection and Diagnosis, and Disease Progression. Of the 130 studies, 71 (54.6%) focused on predicting the COVID-19 outbreak, the impact of containment policies, and potential drug discoveries, which were classified under the Computational Epidemiology theme. Next, 40 of 130 (30.8%) studies that applied AI techniques to detect COVID-19 by using patients' radiological images or laboratory test results were classified under the Early Detection and Diagnosis theme. Finally, 19 of the 130 studies (14.6%) that focused on predicting disease progression, outcomes (ie, recovery and mortality), length of hospital stay, and number of days spent in the intensive care unit for patients with COVID-19 were classified under the Disease Progression theme.
CONCLUSIONS: In this systematic review, we assembled studies in the current COVID-19 literature that utilized AI-based methods to provide insights into different COVID-19 themes. Our findings highlight important variables, data types, and available COVID-19 resources that can assist in facilitating clinical and translational research.",0,0
32634717,Application of Artificial Intelligence in COVID-19 drug repurposing,"Mohanty S, Harun Ai Rashid M, Mridul M, Mohanty C, Swayamsiddha S.",Diabetes Metab Syndr. 2020 Sep-Oct;14(5):1027-1031. doi: 10.1016/j.dsx.2020.06.068. Epub 2020 Jul 3.,Mohanty S,Diabetes Metab Syndr,2020,08-07-2020,PMC7332938,,10.1016/j.dsx.2020.06.068,"BACKGROUND AND AIM: COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario.
METHODS: The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are 'COVID-19', ' AI ', and 'Drug Repurposing'.
RESULTS: AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool.
CONCLUSIONS: Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly.","Application of Artificial Intelligence in COVID-19 drug repurposing BACKGROUND AND AIM: COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario.
METHODS: The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are 'COVID-19', ' AI ', and 'Drug Repurposing'.
RESULTS: AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool.
CONCLUSIONS: Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly.",1,1
33284779,Artificial Intelligence in the Fight Against COVID-19: Scoping Review,"Abd-Alrazaq A, Alajlani M, Alhuwail D, Schneider J, Al-Kuwari S, Shah Z, Hamdi M, Househ M.",J Med Internet Res. 2020 Dec 15;22(12):e20756. doi: 10.2196/20756.,Abd-Alrazaq A,J Med Internet Res,2020,07-12-2020,PMC7744141,,10.2196/20756,"BACKGROUND: In December 2019, COVID-19 broke out in Wuhan, China, leading to national and international disruptions in health care, business, education, transportation, and nearly every aspect of our daily lives. Artificial intelligence (AI) has been leveraged amid the COVID-19 pandemic; however, little is known about its use for supporting public health efforts.
OBJECTIVE: This scoping review aims to explore how AI technology is being used during the COVID-19 pandemic, as reported in the literature. Thus, it is the first review that describes and summarizes features of the identified AI techniques and data sets used for their development and validation.
METHODS: A scoping review was conducted following the guidelines of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). We searched the most commonly used electronic databases (eg, MEDLINE, EMBASE, and PsycInfo) between April 10 and 12, 2020. These terms were selected based on the target intervention (ie, AI) and the target disease (ie, COVID-19). Two reviewers independently conducted study selection and data extraction. A narrative approach was used to synthesize the extracted data.
RESULTS: We considered 82 studies out of the 435 retrieved studies. The most common use of AI was diagnosing COVID-19 cases based on various indicators. AI was also employed in drug and vaccine discovery or repurposing and for assessing their safety. Further, the included studies used AI for forecasting the epidemic development of COVID-19 and predicting its potential hosts and reservoirs. Researchers used AI for patient outcome-related tasks such as assessing the severity of COVID-19, predicting mortality risk, its associated factors, and the length of hospital stay. AI was used for infodemiology to raise awareness to use water, sanitation, and hygiene. The most prominent AI technique used was convolutional neural network, followed by support vector machine.
CONCLUSIONS: The included studies showed that AI has the potential to fight against COVID-19. However, many of the proposed methods are not yet clinically accepted. Thus, the most rewarding research will be on methods promising value beyond COVID-19. More efforts are needed for developing standardized reporting protocols or guidelines for studies on AI.","Artificial Intelligence in the Fight Against COVID-19: Scoping Review BACKGROUND: In December 2019, COVID-19 broke out in Wuhan, China, leading to national and international disruptions in health care, business, education, transportation, and nearly every aspect of our daily lives. Artificial intelligence (AI) has been leveraged amid the COVID-19 pandemic; however, little is known about its use for supporting public health efforts.
OBJECTIVE: This scoping review aims to explore how AI technology is being used during the COVID-19 pandemic, as reported in the literature. Thus, it is the first review that describes and summarizes features of the identified AI techniques and data sets used for their development and validation.
METHODS: A scoping review was conducted following the guidelines of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). We searched the most commonly used electronic databases (eg, MEDLINE, EMBASE, and PsycInfo) between April 10 and 12, 2020. These terms were selected based on the target intervention (ie, AI) and the target disease (ie, COVID-19). Two reviewers independently conducted study selection and data extraction. A narrative approach was used to synthesize the extracted data.
RESULTS: We considered 82 studies out of the 435 retrieved studies. The most common use of AI was diagnosing COVID-19 cases based on various indicators. AI was also employed in drug and vaccine discovery or repurposing and for assessing their safety. Further, the included studies used AI for forecasting the epidemic development of COVID-19 and predicting its potential hosts and reservoirs. Researchers used AI for patient outcome-related tasks such as assessing the severity of COVID-19, predicting mortality risk, its associated factors, and the length of hospital stay. AI was used for infodemiology to raise awareness to use water, sanitation, and hygiene. The most prominent AI technique used was convolutional neural network, followed by support vector machine.
CONCLUSIONS: The included studies showed that AI has the potential to fight against COVID-19. However, many of the proposed methods are not yet clinically accepted. Thus, the most rewarding research will be on methods promising value beyond COVID-19. More efforts are needed for developing standardized reporting protocols or guidelines for studies on AI.",1,1
33930734,Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction,Younis MC.,Comput Med Imaging Graph. 2021 Jun;90:101921. doi: 10.1016/j.compmedimag.2021.101921. Epub 2021 Apr 23.,Younis MC,Comput Med Imaging Graph,2021,30-04-2021,PMC8062905,,10.1016/j.compmedimag.2021.101921,"Novel corona-virus (nCOV) has been declared as a pandemic that started from the city Wuhan of China. This deadly virus is infecting people rapidly and has targeted 4.93 million people across the world, with 227 K people being infected only in Italy. Cases of nCOV are quickly increasing whereas the number of nCOV test kits available in hospitals are limited. Under these conditions, an automated system for the classification of patients into nCOV positive and negative cases, is a much needed tool against the pandemic, helping in a selective use of the limited number of test kits. In this research, Convolutional Neural Network-based models (one block VGG, two block VGG, three block VGG, four block VGG, LetNet-5, AlexNet, and Resnet-50) have been employed for the detection of Corona-virus and SARS_MERS infected patients, distinguishing them from the healthy subjects, using lung X-ray scans, which has proven to be a challenging task, due to overlapping characteristics of different corona virus types. Furthermore, LSTM model has been used for time series forecasting of nCOV cases, in the following 10 days, in Italy. The evaluation results obtained, proved that the VGG1 model distinguishes the three classes at an accuracy of almost 91%, as compared to other models, whereas the approach based on the LSTM predicts the number of nCOV cases with 99% accuracy.","Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction Novel corona-virus (nCOV) has been declared as a pandemic that started from the city Wuhan of China. This deadly virus is infecting people rapidly and has targeted 4.93 million people across the world, with 227 K people being infected only in Italy. Cases of nCOV are quickly increasing whereas the number of nCOV test kits available in hospitals are limited. Under these conditions, an automated system for the classification of patients into nCOV positive and negative cases, is a much needed tool against the pandemic, helping in a selective use of the limited number of test kits. In this research, Convolutional Neural Network-based models (one block VGG, two block VGG, three block VGG, four block VGG, LetNet-5, AlexNet, and Resnet-50) have been employed for the detection of Corona-virus and SARS_MERS infected patients, distinguishing them from the healthy subjects, using lung X-ray scans, which has proven to be a challenging task, due to overlapping characteristics of different corona virus types. Furthermore, LSTM model has been used for time series forecasting of nCOV cases, in the following 10 days, in Italy. The evaluation results obtained, proved that the VGG1 model distinguishes the three classes at an accuracy of almost 91%, as compared to other models, whereas the approach based on the LSTM predicts the number of nCOV cases with 99% accuracy.",1,1
37889739,When Everything Becomes Bigger: Big Data for Big Poultry Production,"Franzo G, Legnardi M, Faustini G, Tucciarone CM, Cecchinato M.",Animals (Basel). 2023 May 30;13(11):1804. doi: 10.3390/ani13111804.,Franzo G,Animals (Basel),2023,27-10-2023,PMC10252109,,10.3390/ani13111804,"In future decades, the demand for poultry meat and eggs is predicted to considerably increase in pace with human population growth. Although this expansion clearly represents a remarkable opportunity for the sector, it conceals a multitude of challenges. Pollution and land erosion, competition for limited resources between animal and human nutrition, animal welfare concerns, limitations on the use of growth promoters and antimicrobial agents, and increasing risks and effects of animal infectious diseases and zoonoses are several topics that have received attention from authorities and the public. The increase in poultry production must be achieved mainly through optimization and increased efficiency. The increasing ability to generate large amounts of data (""big data"") is pervasive in both modern society and the farming industry. Information accessibility-coupled with the availability of tools and computational power to store, share, integrate, and analyze data with automatic and flexible algorithms-offers an unprecedented opportunity to develop tools to maximize farm profitability, reduce socio-environmental impacts, and increase animal and human health and welfare. A detailed description of all topics and applications of big data analysis in poultry farming would be infeasible. Therefore, the present work briefly reviews the application of sensor technologies, such as optical, acoustic, and wearable sensors, as well as infrared thermal imaging and optical flow, to poultry farming. The principles and benefits of advanced statistical techniques, such as machine learning and deep learning, and their use in developing effective and reliable classification and prediction models to benefit the farming system, are also discussed. Finally, recent progress in pathogen genome sequencing and analysis is discussed, highlighting practical applications in epidemiological tracking, and reconstruction of microorganisms' population dynamics, evolution, and spread. The benefits of the objective evaluation of the effectiveness of applied control strategies are also considered. Although human-artificial intelligence collaborations in the livestock sector can be frightening because they require farmers and employees in the sector to adapt to new roles, challenges, and competencies-and because several unknowns, limitations, and open-ended questions are inevitable-their overall benefits appear to be far greater than their drawbacks. As more farms and companies connect to technology, artificial intelligence (AI) and sensing technologies will begin to play a greater role in identifying patterns and solutions to pressing problems in modern animal farming, thus providing remarkable production-based and commercial advantages. Moreover, the combination of diverse sources and types of data will also become fundamental for the development of predictive models able to anticipate, rather than merely detect, disease occurrence. The increasing availability of sensors, infrastructures, and tools for big data collection, storage, sharing, and analysis-together with the use of open standards and integration with pathogen molecular epidemiology-have the potential to address the major challenge of producing higher-quality, more healthful food on a larger scale in a more sustainable manner, thereby protecting ecosystems, preserving natural resources, and improving animal and human welfare and health.","When Everything Becomes Bigger: Big Data for Big Poultry Production In future decades, the demand for poultry meat and eggs is predicted to considerably increase in pace with human population growth. Although this expansion clearly represents a remarkable opportunity for the sector, it conceals a multitude of challenges. Pollution and land erosion, competition for limited resources between animal and human nutrition, animal welfare concerns, limitations on the use of growth promoters and antimicrobial agents, and increasing risks and effects of animal infectious diseases and zoonoses are several topics that have received attention from authorities and the public. The increase in poultry production must be achieved mainly through optimization and increased efficiency. The increasing ability to generate large amounts of data (""big data"") is pervasive in both modern society and the farming industry. Information accessibility-coupled with the availability of tools and computational power to store, share, integrate, and analyze data with automatic and flexible algorithms-offers an unprecedented opportunity to develop tools to maximize farm profitability, reduce socio-environmental impacts, and increase animal and human health and welfare. A detailed description of all topics and applications of big data analysis in poultry farming would be infeasible. Therefore, the present work briefly reviews the application of sensor technologies, such as optical, acoustic, and wearable sensors, as well as infrared thermal imaging and optical flow, to poultry farming. The principles and benefits of advanced statistical techniques, such as machine learning and deep learning, and their use in developing effective and reliable classification and prediction models to benefit the farming system, are also discussed. Finally, recent progress in pathogen genome sequencing and analysis is discussed, highlighting practical applications in epidemiological tracking, and reconstruction of microorganisms' population dynamics, evolution, and spread. The benefits of the objective evaluation of the effectiveness of applied control strategies are also considered. Although human-artificial intelligence collaborations in the livestock sector can be frightening because they require farmers and employees in the sector to adapt to new roles, challenges, and competencies-and because several unknowns, limitations, and open-ended questions are inevitable-their overall benefits appear to be far greater than their drawbacks. As more farms and companies connect to technology, artificial intelligence (AI) and sensing technologies will begin to play a greater role in identifying patterns and solutions to pressing problems in modern animal farming, thus providing remarkable production-based and commercial advantages. Moreover, the combination of diverse sources and types of data will also become fundamental for the development of predictive models able to anticipate, rather than merely detect, disease occurrence. The increasing availability of sensors, infrastructures, and tools for big data collection, storage, sharing, and analysis-together with the use of open standards and integration with pathogen molecular epidemiology-have the potential to address the major challenge of producing higher-quality, more healthful food on a larger scale in a more sustainable manner, thereby protecting ecosystems, preserving natural resources, and improving animal and human welfare and health.",1,0
36382260,Novel computational pipelines in antiviral structure‑based drug design (Review),"Diakou I, Papakonstantinou E, Papageorgiou L, Pierouli K, Dragoumani K, Spandidos DA, Bacopoulou F, Chrousos GP, Eliopoulos E, Vlachakis D.",Biomed Rep. 2022 Oct 24;17(6):97. doi: 10.3892/br.2022.1580. eCollection 2022 Dec.,Diakou I,Biomed Rep,2022,16-11-2022,PMC9634337,,10.3892/br.2022.1580,"Viral infections constitute a fundamental and continuous challenge for the global scientific and medical community, as highlighted by the ongoing COVID-19 pandemic. In combination with prophylactic vaccines, the development of safe and effective antiviral drugs remains a pressing need for the effective management of rare and common pathogenic viruses. The design of potent antivirals can be informed by the study of the three-dimensional structure of viral protein targets. Structure-based design of antivirals in silico provides a solution to the arduous and costly process of conventional drug development pipelines. Furthermore, rapid advances in high-throughput computing, along with the growth of available biomolecular and biochemical data, enable the development of novel computational pipelines in the hunt of antivirals. The incorporation of modern methods, such as deep-learning and artificial intelligence, has the potential to revolutionize the structure-based design and repurposing of antiviral compounds, with minimal side effects and high efficacy. The present review aims to provide an outline of both traditional computational drug design and emerging, high-level computing strategies.","Novel computational pipelines in antiviral structure‑based drug design (Review) Viral infections constitute a fundamental and continuous challenge for the global scientific and medical community, as highlighted by the ongoing COVID-19 pandemic. In combination with prophylactic vaccines, the development of safe and effective antiviral drugs remains a pressing need for the effective management of rare and common pathogenic viruses. The design of potent antivirals can be informed by the study of the three-dimensional structure of viral protein targets. Structure-based design of antivirals in silico provides a solution to the arduous and costly process of conventional drug development pipelines. Furthermore, rapid advances in high-throughput computing, along with the growth of available biomolecular and biochemical data, enable the development of novel computational pipelines in the hunt of antivirals. The incorporation of modern methods, such as deep-learning and artificial intelligence, has the potential to revolutionize the structure-based design and repurposing of antiviral compounds, with minimal side effects and high efficacy. The present review aims to provide an outline of both traditional computational drug design and emerging, high-level computing strategies.",0,0
34525746,"Viral outbreaks detection and surveillance using wastewater-based epidemiology, viral air sampling, and machine learning techniques: A comprehensive review and outlook","Abdeldayem OM, Dabbish AM, Habashy MM, Mostafa MK, Elhefnawy M, Amin L, Al-Sakkari EG, Ragab A, Rene ER.",Sci Total Environ. 2022 Jan 10;803:149834. doi: 10.1016/j.scitotenv.2021.149834. Epub 2021 Aug 21.,Abdeldayem OM,Sci Total Environ,2022,16-09-2021,PMC8379898,,10.1016/j.scitotenv.2021.149834,"A viral outbreak is a global challenge that affects public health and safety. The coronavirus disease 2019 (COVID-19) has been spreading globally, affecting millions of people worldwide, and led to significant loss of lives and deterioration of the global economy. The current adverse effects caused by the COVID-19 pandemic demands finding new detection methods for future viral outbreaks. The environment's transmission pathways include and are not limited to air, surface water, and wastewater environments. The wastewater surveillance, known as wastewater-based epidemiology (WBE), can potentially monitor viral outbreaks and provide a complementary clinical testing method. Another investigated outbreak surveillance technique that has not been yet implemented in a sufficient number of studies is the surveillance of Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) in the air. Artificial intelligence (AI) and its related machine learning (ML) and deep learning (DL) technologies are currently emerging techniques for detecting viral outbreaks using global data. To date, there are no reports that illustrate the potential of using WBE with AI to detect viral outbreaks. This study investigates the transmission pathways of SARS-CoV-2 in the environment and provides current updates on the surveillance of viral outbreaks using WBE, viral air sampling, and AI. It also proposes a novel framework based on an ensemble of ML and DL algorithms to provide a beneficial supportive tool for decision-makers. The framework exploits available data from reliable sources to discover meaningful insights and knowledge that allows researchers and practitioners to build efficient methods and protocols that accurately monitor and detect viral outbreaks. The proposed framework could provide early detection of viruses, forecast risk maps and vulnerable areas, and estimate the number of infected citizens.","Viral outbreaks detection and surveillance using wastewater-based epidemiology, viral air sampling, and machine learning techniques: A comprehensive review and outlook A viral outbreak is a global challenge that affects public health and safety. The coronavirus disease 2019 (COVID-19) has been spreading globally, affecting millions of people worldwide, and led to significant loss of lives and deterioration of the global economy. The current adverse effects caused by the COVID-19 pandemic demands finding new detection methods for future viral outbreaks. The environment's transmission pathways include and are not limited to air, surface water, and wastewater environments. The wastewater surveillance, known as wastewater-based epidemiology (WBE), can potentially monitor viral outbreaks and provide a complementary clinical testing method. Another investigated outbreak surveillance technique that has not been yet implemented in a sufficient number of studies is the surveillance of Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) in the air. Artificial intelligence (AI) and its related machine learning (ML) and deep learning (DL) technologies are currently emerging techniques for detecting viral outbreaks using global data. To date, there are no reports that illustrate the potential of using WBE with AI to detect viral outbreaks. This study investigates the transmission pathways of SARS-CoV-2 in the environment and provides current updates on the surveillance of viral outbreaks using WBE, viral air sampling, and AI. It also proposes a novel framework based on an ensemble of ML and DL algorithms to provide a beneficial supportive tool for decision-makers. The framework exploits available data from reliable sources to discover meaningful insights and knowledge that allows researchers and practitioners to build efficient methods and protocols that accurately monitor and detect viral outbreaks. The proposed framework could provide early detection of viruses, forecast risk maps and vulnerable areas, and estimate the number of infected citizens.",0,1
35534142,Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review,"Comito C, Pizzuti C.",Artif Intell Med. 2022 Jun;128:102286. doi: 10.1016/j.artmed.2022.102286. Epub 2022 Mar 28.,Comito C,Artif Intell Med,2022,09-05-2022,PMC8958821,,10.1016/j.artmed.2022.102286,"The outbreak of novel corona virus 2019 (COVID-19) has been treated as a public health crisis of global concern by the World Health Organization (WHO). COVID-19 pandemic hugely affected countries worldwide raising the need to exploit novel, alternative and emerging technologies to respond to the emergency created by the weak health-care systems. In this context, Artificial Intelligence (AI) techniques can give a valid support to public health authorities, complementing traditional approaches with advanced tools. This study provides a comprehensive review of methods, algorithms, applications, and emerging AI technologies that can be utilized for forecasting and diagnosing COVID-19. The main objectives of this review are summarized as follows. (i) Understanding the importance of AI approaches such as machine learning and deep learning for COVID-19 pandemic; (ii) discussing the efficiency and impact of these methods for COVID-19 forecasting and diagnosing; (iii) providing an extensive background description of AI techniques to help non-expert to better catch the underlying concepts; (iv) for each work surveyed, give a detailed analysis of the rationale behind the approach, highlighting the method used, the type and size of data analyzed, the validation method, the target application and the results achieved; (v) focusing on some future challenges in COVID-19 forecasting and diagnosing.","Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review The outbreak of novel corona virus 2019 (COVID-19) has been treated as a public health crisis of global concern by the World Health Organization (WHO). COVID-19 pandemic hugely affected countries worldwide raising the need to exploit novel, alternative and emerging technologies to respond to the emergency created by the weak health-care systems. In this context, Artificial Intelligence (AI) techniques can give a valid support to public health authorities, complementing traditional approaches with advanced tools. This study provides a comprehensive review of methods, algorithms, applications, and emerging AI technologies that can be utilized for forecasting and diagnosing COVID-19. The main objectives of this review are summarized as follows. (i) Understanding the importance of AI approaches such as machine learning and deep learning for COVID-19 pandemic; (ii) discussing the efficiency and impact of these methods for COVID-19 forecasting and diagnosing; (iii) providing an extensive background description of AI techniques to help non-expert to better catch the underlying concepts; (iv) for each work surveyed, give a detailed analysis of the rationale behind the approach, highlighting the method used, the type and size of data analyzed, the validation method, the target application and the results achieved; (v) focusing on some future challenges in COVID-19 forecasting and diagnosing.",0,1
33886097,COVID-19 in the Age of Artificial Intelligence: A Comprehensive Review,"Rasheed J, Jamil A, Hameed AA, Al-Turjman F, Rasheed A.",Interdiscip Sci. 2021 Jun;13(2):153-175. doi: 10.1007/s12539-021-00431-w. Epub 2021 Apr 22.,Rasheed J,Interdiscip Sci,2021,22-04-2021,PMC8060789,,10.1007/s12539-021-00431-w,"The recent COVID-19 pandemic, which broke at the end of the year 2019 in Wuhan, China, has infected more than 98.52 million people by today (January 23, 2021) with over 2.11 million deaths across the globe. To combat the growing pandemic on urgent basis, there is need to design effective solutions using new techniques that could exploit recent technology, such as machine learning, deep learning, big data, artificial intelligence, Internet of Things, for identification and tracking of COVID-19 cases in near real time. These technologies have offered inexpensive and rapid solution for proper screening, analyzing, prediction and tracking of COVID-19 positive cases. In this paper, a detailed review of the role of AI as a decisive tool for prognosis, analyze, and tracking the COVID-19 cases is performed. We searched various databases including Google Scholar, IEEE Library, Scopus and Web of Science using a combination of different keywords consisting of COVID-19 and AI. We have identified various applications, where AI can help healthcare practitioners in the process of identification and monitoring of COVID-19 cases. A compact summary of the corona virus cases are first highlighted, followed by the application of AI. Finally, we conclude the paper by highlighting new research directions and discuss the research challenges. Even though scientists and researchers have gathered and exchanged sufficient knowledge over last couple of months, but this structured review also examined technological perspectives while encompassing the medical aspect to help the healthcare practitioners, policymakers, decision makers, policymakers, AI scientists and virologists to quell this infectious COVID-19 pandemic outbreak.","COVID-19 in the Age of Artificial Intelligence: A Comprehensive Review The recent COVID-19 pandemic, which broke at the end of the year 2019 in Wuhan, China, has infected more than 98.52 million people by today (January 23, 2021) with over 2.11 million deaths across the globe. To combat the growing pandemic on urgent basis, there is need to design effective solutions using new techniques that could exploit recent technology, such as machine learning, deep learning, big data, artificial intelligence, Internet of Things, for identification and tracking of COVID-19 cases in near real time. These technologies have offered inexpensive and rapid solution for proper screening, analyzing, prediction and tracking of COVID-19 positive cases. In this paper, a detailed review of the role of AI as a decisive tool for prognosis, analyze, and tracking the COVID-19 cases is performed. We searched various databases including Google Scholar, IEEE Library, Scopus and Web of Science using a combination of different keywords consisting of COVID-19 and AI. We have identified various applications, where AI can help healthcare practitioners in the process of identification and monitoring of COVID-19 cases. A compact summary of the corona virus cases are first highlighted, followed by the application of AI. Finally, we conclude the paper by highlighting new research directions and discuss the research challenges. Even though scientists and researchers have gathered and exchanged sufficient knowledge over last couple of months, but this structured review also examined technological perspectives while encompassing the medical aspect to help the healthcare practitioners, policymakers, decision makers, policymakers, AI scientists and virologists to quell this infectious COVID-19 pandemic outbreak.",0,1
34674660,GACDN: generative adversarial feature completion and diagnosis network for COVID-19,"Zhu Q, Ye H, Sun L, Li Z, Wang R, Shi F, Shen D, Zhang D.",BMC Med Imaging. 2021 Oct 21;21(1):154. doi: 10.1186/s12880-021-00681-6.,Zhu Q,BMC Med Imaging,2021,22-10-2021,PMC8529574,,10.1186/s12880-021-00681-6,"BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) causes tens of million infection world-wide. Many machine learning methods have been proposed for the computer-aided diagnosis between COVID-19 and community-acquired pneumonia (CAP) from chest computed tomography (CT) images. Most of these methods utilized the location-specific handcrafted features based on the segmentation results to improve the diagnose performance. However, the prerequisite segmentation step is time-consuming and needs the intervention by lots of expert radiologists, which cannot be achieved in the areas with limited medical resources.
METHODS: We propose a generative adversarial feature completion and diagnosis network (GACDN) that simultaneously generates handcrafted features by radiomic counterparts and makes accurate diagnoses based on both original and generated features. Specifically, we first calculate the radiomic features from the CT images. Then, in order to fast obtain the location-specific handcrafted features, we use the proposed GACDN to generate them by its corresponding radiomic features. Finally, we use both radiomic features and location-specific handcrafted features for COVID-19 diagnosis.
RESULTS: For the performance of our generated location-specific handcrafted features, the results of four basic classifiers show that it has an average of 3.21% increase in diagnoses accuracy. Besides, the experimental results on COVID-19 dataset show that our proposed method achieved superior performance in COVID-19 vs. community acquired pneumonia (CAP) classification compared with the state-of-the-art methods.
CONCLUSIONS: The proposed method significantly improves the diagnoses accuracy of COVID-19 vs. CAP in the condition of incomplete location-specific handcrafted features. Besides, it is also applicable in some regions lacking of expert radiologists and high-performance computing resources.","GACDN: generative adversarial feature completion and diagnosis network for COVID-19 BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) causes tens of million infection world-wide. Many machine learning methods have been proposed for the computer-aided diagnosis between COVID-19 and community-acquired pneumonia (CAP) from chest computed tomography (CT) images. Most of these methods utilized the location-specific handcrafted features based on the segmentation results to improve the diagnose performance. However, the prerequisite segmentation step is time-consuming and needs the intervention by lots of expert radiologists, which cannot be achieved in the areas with limited medical resources.
METHODS: We propose a generative adversarial feature completion and diagnosis network (GACDN) that simultaneously generates handcrafted features by radiomic counterparts and makes accurate diagnoses based on both original and generated features. Specifically, we first calculate the radiomic features from the CT images. Then, in order to fast obtain the location-specific handcrafted features, we use the proposed GACDN to generate them by its corresponding radiomic features. Finally, we use both radiomic features and location-specific handcrafted features for COVID-19 diagnosis.
RESULTS: For the performance of our generated location-specific handcrafted features, the results of four basic classifiers show that it has an average of 3.21% increase in diagnoses accuracy. Besides, the experimental results on COVID-19 dataset show that our proposed method achieved superior performance in COVID-19 vs. community acquired pneumonia (CAP) classification compared with the state-of-the-art methods.
CONCLUSIONS: The proposed method significantly improves the diagnoses accuracy of COVID-19 vs. CAP in the condition of incomplete location-specific handcrafted features. Besides, it is also applicable in some regions lacking of expert radiologists and high-performance computing resources.",1,1
35264189,"Application of machine learning in understanding plant virus pathogenesis: trends and perspectives on emergence, diagnosis, host-virus interplay and management","Ghosh D, Chakraborty S, Kodamana H, Chakraborty S.",Virol J. 2022 Mar 9;19(1):42. doi: 10.1186/s12985-022-01767-5.,Ghosh D,Virol J,2022,10-03-2022,PMC8905280,,10.1186/s12985-022-01767-5,"BACKGROUND: Inclusion of high throughput technologies in the field of biology has generated massive amounts of data in the recent years. Now, transforming these huge volumes of data into knowledge is the primary challenge in computational biology. The traditional methods of data analysis have failed to carry out the task. Hence, researchers are turning to machine learning based approaches for the analysis of high-dimensional big data. In machine learning, once a model is trained with a training dataset, it can be applied on a testing dataset which is independent. In current times, deep learning algorithms further promote the application of machine learning in several field of biology including plant virology.
MAIN BODY: Plant viruses have emerged as one of the principal global threats to food security due to their devastating impact on crops and vegetables. The emergence of new viral strains and species help viruses to evade the concurrent preventive methods. According to a survey conducted in 2014, plant viruses are anticipated to cause a global yield loss of more than thirty billion USD per year. In order to design effective, durable and broad-spectrum management protocols, it is very important to understand the mechanistic details of viral pathogenesis. The application of machine learning enables precise diagnosis of plant viral diseases at an early stage. Furthermore, the development of several machine learning-guided bioinformatics platforms has primed plant virologists to understand the host-virus interplay better. In addition, machine learning has tremendous potential in deciphering the pattern of plant virus evolution and emergence as well as in developing viable control options.
CONCLUSIONS: Considering a significant progress in the application of machine learning in understanding plant virology, this review highlights an introductory note on machine learning and comprehensively discusses the trends and prospects of machine learning in the diagnosis of viral diseases, understanding host-virus interplay and emergence of plant viruses.","Application of machine learning in understanding plant virus pathogenesis: trends and perspectives on emergence, diagnosis, host-virus interplay and management BACKGROUND: Inclusion of high throughput technologies in the field of biology has generated massive amounts of data in the recent years. Now, transforming these huge volumes of data into knowledge is the primary challenge in computational biology. The traditional methods of data analysis have failed to carry out the task. Hence, researchers are turning to machine learning based approaches for the analysis of high-dimensional big data. In machine learning, once a model is trained with a training dataset, it can be applied on a testing dataset which is independent. In current times, deep learning algorithms further promote the application of machine learning in several field of biology including plant virology.
MAIN BODY: Plant viruses have emerged as one of the principal global threats to food security due to their devastating impact on crops and vegetables. The emergence of new viral strains and species help viruses to evade the concurrent preventive methods. According to a survey conducted in 2014, plant viruses are anticipated to cause a global yield loss of more than thirty billion USD per year. In order to design effective, durable and broad-spectrum management protocols, it is very important to understand the mechanistic details of viral pathogenesis. The application of machine learning enables precise diagnosis of plant viral diseases at an early stage. Furthermore, the development of several machine learning-guided bioinformatics platforms has primed plant virologists to understand the host-virus interplay better. In addition, machine learning has tremendous potential in deciphering the pattern of plant virus evolution and emergence as well as in developing viable control options.
CONCLUSIONS: Considering a significant progress in the application of machine learning in understanding plant virology, this review highlights an introductory note on machine learning and comprehensively discusses the trends and prospects of machine learning in the diagnosis of viral diseases, understanding host-virus interplay and emergence of plant viruses.",1,0
34729056,AIoT Used for COVID-19 Pandemic Prevention and Control,"Chen SW, Gu XW, Wang JJ, Zhu HS.",Contrast Media Mol Imaging. 2021 Oct 13;2021:3257035. doi: 10.1155/2021/3257035. eCollection 2021.,Chen SW,Contrast Media Mol Imaging,2021,03-11-2021,PMC8514960,,10.1155/2021/3257035,"The pandemic of COVID-19 is continuing to wreak havoc in 2021, with at least 170 million victims around the world. Healthcare systems are overwhelmed by the large-scale virus infection. Luckily, Internet of Things (IoT) is one of the most effective paradigms in the intelligent world, in which the technology of artificial intelligence (AI), like cloud computing and big data analysis, is playing a vital role in preventing the spread of the pandemic of COVID-19. AI and 5G technologies are advancing by leaps and bounds, further strengthening the intelligence and connectivity of IoT applications, and conventional IoT has been gradually upgraded to be more powerful AI + IoT (AIoT). For example, in terms of remote screening and diagnosis of COVID-19 patients, AI technology based on machine learning and deep learning has recently upgraded medical equipment significantly and has reshaped the workflow with minimal contact with patients, so medical specialists can make clinical decisions more efficiently, providing the best protection not only to patients but also to specialists themselves. This paper reviews the latest progress made in combating COVID-19 with both IoT and AI and also provides comprehensive details on how to combat the pandemic of COVID-19 as well as the technologies that may be applied in the future.","AIoT Used for COVID-19 Pandemic Prevention and Control The pandemic of COVID-19 is continuing to wreak havoc in 2021, with at least 170 million victims around the world. Healthcare systems are overwhelmed by the large-scale virus infection. Luckily, Internet of Things (IoT) is one of the most effective paradigms in the intelligent world, in which the technology of artificial intelligence (AI), like cloud computing and big data analysis, is playing a vital role in preventing the spread of the pandemic of COVID-19. AI and 5G technologies are advancing by leaps and bounds, further strengthening the intelligence and connectivity of IoT applications, and conventional IoT has been gradually upgraded to be more powerful AI + IoT (AIoT). For example, in terms of remote screening and diagnosis of COVID-19 patients, AI technology based on machine learning and deep learning has recently upgraded medical equipment significantly and has reshaped the workflow with minimal contact with patients, so medical specialists can make clinical decisions more efficiently, providing the best protection not only to patients but also to specialists themselves. This paper reviews the latest progress made in combating COVID-19 with both IoT and AI and also provides comprehensive details on how to combat the pandemic of COVID-19 as well as the technologies that may be applied in the future.",0,0
35070385,Application of artificial intelligence in COVID-19 medical area: a systematic review,"Chang Z, Zhan Z, Zhao Z, You Z, Liu Y, Yan Z, Fu Y, Liang W, Zhao L.",J Thorac Dis. 2021 Dec;13(12):7034-7053. doi: 10.21037/jtd-21-747.,Chang Z,J Thorac Dis,2021,24-01-2022,PMC8743418,,10.21037/jtd-21-747,"BACKGROUND: Coronavirus disease 2019 (COVID-19) has caused a large-scale global epidemic, impacting international politics and the economy. At present, there is no particularly effective medicine and treatment plan. Therefore, it is urgent and significant to find new technologies to diagnose early, isolate early, and treat early. Multimodal data drove artificial intelligence (AI) can potentially be the option. During the COVID-19 Pandemic, AI provided cutting-edge applications in disease, medicine, treatment, and target recognition. This paper reviewed the literature on the intersection of AI and medicine to analyze and compare different AI model applications in the COVID-19 Pandemic, evaluate their effectiveness, show their advantages and differences, and introduce the main models and their characteristics.
METHODS: We searched PubMed, arXiv, medRxiv, and Google Scholar through February 2020 to identify studies on AI applications in the medical areas for the COVID-19 Pandemic.
RESULTS: We summarize the main AI applications in six areas: (I) epidemiology, (II) diagnosis, (III) progression, (IV) treatment, (V) psychological health impact, and (VI) data security. The ongoing development in AI has significantly improved prediction, contact tracing, screening, diagnosis, treatment, medication, and vaccine development for the COVID-19 Pandemic and reducing human intervention in medical practice.
DISCUSSION: This paper provides strong advice for using AI-based auxiliary tools for related applications of human diseases. We also discuss the clinicians' role in the further development of AI. They and AI researchers can integrate AI technology with current clinical processes and information systems into applications. In the future, AI personnel and medical workers will further cooperate closely.","Application of artificial intelligence in COVID-19 medical area: a systematic review BACKGROUND: Coronavirus disease 2019 (COVID-19) has caused a large-scale global epidemic, impacting international politics and the economy. At present, there is no particularly effective medicine and treatment plan. Therefore, it is urgent and significant to find new technologies to diagnose early, isolate early, and treat early. Multimodal data drove artificial intelligence (AI) can potentially be the option. During the COVID-19 Pandemic, AI provided cutting-edge applications in disease, medicine, treatment, and target recognition. This paper reviewed the literature on the intersection of AI and medicine to analyze and compare different AI model applications in the COVID-19 Pandemic, evaluate their effectiveness, show their advantages and differences, and introduce the main models and their characteristics.
METHODS: We searched PubMed, arXiv, medRxiv, and Google Scholar through February 2020 to identify studies on AI applications in the medical areas for the COVID-19 Pandemic.
RESULTS: We summarize the main AI applications in six areas: (I) epidemiology, (II) diagnosis, (III) progression, (IV) treatment, (V) psychological health impact, and (VI) data security. The ongoing development in AI has significantly improved prediction, contact tracing, screening, diagnosis, treatment, medication, and vaccine development for the COVID-19 Pandemic and reducing human intervention in medical practice.
DISCUSSION: This paper provides strong advice for using AI-based auxiliary tools for related applications of human diseases. We also discuss the clinicians' role in the further development of AI. They and AI researchers can integrate AI technology with current clinical processes and information systems into applications. In the future, AI personnel and medical workers will further cooperate closely.",1,1
32013791,Development and Validation of a Multitask Deep Learning Model for Severity Grading of Hip Osteoarthritis Features on Radiographs,"von Schacky CE, Sohn JH, Liu F, Ozhinsky E, Jungmann PM, Nardo L, Posadzy M, Foreman SC, Nevitt MC, Link TM, Pedoia V.",Radiology. 2020 Apr;295(1):136-145. doi: 10.1148/radiol.2020190925. Epub 2020 Feb 4.,von Schacky CE,Radiology,2020,05-02-2020,PMC7104703,NIHMS1582363,10.1148/radiol.2020190925,"Background A multitask deep learning model might be useful in large epidemiologic studies wherein detailed structural assessment of osteoarthritis still relies on expert radiologists' readings. The potential of such a model in clinical routine should be investigated. Purpose To develop a multitask deep learning model for grading radiographic hip osteoarthritis features on radiographs and compare its performance to that of attending-level radiologists. Materials and Methods This retrospective study analyzed hip joints seen on weight-bearing anterior-posterior pelvic radiographs from participants in the Osteoarthritis Initiative (OAI). Participants were recruited from February 2004 to May 2006 for baseline measurements, and follow-up was performed 48 months later. Femoral osteophytes (FOs), acetabular osteophytes (AOs), and joint-space narrowing (JSN) were graded as absent, mild, moderate, or severe according to the Osteoarthritis Research Society International atlas. Subchondral sclerosis and subchondral cysts were graded as present or absent. The participants were split at 80% (n = 3494), 10% (n = 437), and 10% (n = 437) by using split-sample validation into training, validation, and testing sets, respectively. The multitask neural network was based on DenseNet-161, a shared convolutional features extractor trained with multitask loss function. Model performance was evaluated in the internal test set from the OAI and in an external test set by using temporal and geographic validation consisting of routine clinical radiographs. Results A total of 4368 participants (mean age, 61.0 years ± 9.2 [standard deviation]; 2538 women) were evaluated (15 364 hip joints on 7738 weight-bearing anterior-posterior pelvic radiographs). The accuracy of the model for assessing these five features was 86.7% (1333 of 1538) for FOs, 69.9% (1075 of 1538) for AOs, 81.7% (1257 of 1538) for JSN, 95.8% (1473 of 1538) for subchondral sclerosis, and 97.6% (1501 of 1538) for subchondral cysts in the internal test set, and 82.7% (86 of 104) for FOS, 65.4% (68 of 104) for AOs, 80.8% (84 of 104) for JSN, 88.5% (92 of 104) for subchondral sclerosis, and 91.3% (95 of 104) for subchondral cysts in the external test set. Conclusion A multitask deep learning model is a feasible approach to reliably assess radiographic features of hip osteoarthritis. © RSNA, 2020 Online supplemental material is available for this article.","Development and Validation of a Multitask Deep Learning Model for Severity Grading of Hip Osteoarthritis Features on Radiographs Background A multitask deep learning model might be useful in large epidemiologic studies wherein detailed structural assessment of osteoarthritis still relies on expert radiologists' readings. The potential of such a model in clinical routine should be investigated. Purpose To develop a multitask deep learning model for grading radiographic hip osteoarthritis features on radiographs and compare its performance to that of attending-level radiologists. Materials and Methods This retrospective study analyzed hip joints seen on weight-bearing anterior-posterior pelvic radiographs from participants in the Osteoarthritis Initiative (OAI). Participants were recruited from February 2004 to May 2006 for baseline measurements, and follow-up was performed 48 months later. Femoral osteophytes (FOs), acetabular osteophytes (AOs), and joint-space narrowing (JSN) were graded as absent, mild, moderate, or severe according to the Osteoarthritis Research Society International atlas. Subchondral sclerosis and subchondral cysts were graded as present or absent. The participants were split at 80% (n = 3494), 10% (n = 437), and 10% (n = 437) by using split-sample validation into training, validation, and testing sets, respectively. The multitask neural network was based on DenseNet-161, a shared convolutional features extractor trained with multitask loss function. Model performance was evaluated in the internal test set from the OAI and in an external test set by using temporal and geographic validation consisting of routine clinical radiographs. Results A total of 4368 participants (mean age, 61.0 years ± 9.2 [standard deviation]; 2538 women) were evaluated (15 364 hip joints on 7738 weight-bearing anterior-posterior pelvic radiographs). The accuracy of the model for assessing these five features was 86.7% (1333 of 1538) for FOs, 69.9% (1075 of 1538) for AOs, 81.7% (1257 of 1538) for JSN, 95.8% (1473 of 1538) for subchondral sclerosis, and 97.6% (1501 of 1538) for subchondral cysts in the internal test set, and 82.7% (86 of 104) for FOS, 65.4% (68 of 104) for AOs, 80.8% (84 of 104) for JSN, 88.5% (92 of 104) for subchondral sclerosis, and 91.3% (95 of 104) for subchondral cysts in the external test set. Conclusion A multitask deep learning model is a feasible approach to reliably assess radiographic features of hip osteoarthritis. © RSNA, 2020 Online supplemental material is available for this article.",1,0
37950315,"Key considerations, target product profiles, and research gaps in the application of infrared spectroscopy and artificial intelligence for malaria surveillance and diagnosis","Mshani IH, Siria DJ, Mwanga EP, Sow BB, Sanou R, Opiyo M, Sikulu-Lord MT, Ferguson HM, Diabate A, Wynne K, González-Jiménez M, Baldini F, Babayan SA, Okumu F.",Malar J. 2023 Nov 10;22(1):346. doi: 10.1186/s12936-023-04780-3.,Mshani IH,Malar J,2023,11-11-2023,PMC10638832,,10.1186/s12936-023-04780-3,"Studies on the applications of infrared (IR) spectroscopy and machine learning (ML) in public health have increased greatly in recent years. These technologies show enormous potential for measuring key parameters of malaria, a disease that still causes about 250 million cases and 620,000 deaths, annually. Multiple studies have demonstrated that the combination of IR spectroscopy and machine learning (ML) can yield accurate predictions of epidemiologically relevant parameters of malaria in both laboratory and field surveys. Proven applications now include determining the age, species, and blood-feeding histories of mosquito vectors as well as detecting malaria parasite infections in both humans and mosquitoes. As the World Health Organization encourages malaria-endemic countries to improve their surveillance-response strategies, it is crucial to consider whether IR and ML techniques are likely to meet the relevant feasibility and cost-effectiveness requirements-and how best they can be deployed. This paper reviews current applications of IR spectroscopy and ML approaches for investigating malaria indicators in both field surveys and laboratory settings, and identifies key research gaps relevant to these applications. Additionally, the article suggests initial target product profiles (TPPs) that should be considered when developing or testing these technologies for use in low-income settings.","Key considerations, target product profiles, and research gaps in the application of infrared spectroscopy and artificial intelligence for malaria surveillance and diagnosis Studies on the applications of infrared (IR) spectroscopy and machine learning (ML) in public health have increased greatly in recent years. These technologies show enormous potential for measuring key parameters of malaria, a disease that still causes about 250 million cases and 620,000 deaths, annually. Multiple studies have demonstrated that the combination of IR spectroscopy and machine learning (ML) can yield accurate predictions of epidemiologically relevant parameters of malaria in both laboratory and field surveys. Proven applications now include determining the age, species, and blood-feeding histories of mosquito vectors as well as detecting malaria parasite infections in both humans and mosquitoes. As the World Health Organization encourages malaria-endemic countries to improve their surveillance-response strategies, it is crucial to consider whether IR and ML techniques are likely to meet the relevant feasibility and cost-effectiveness requirements-and how best they can be deployed. This paper reviews current applications of IR spectroscopy and ML approaches for investigating malaria indicators in both field surveys and laboratory settings, and identifies key research gaps relevant to these applications. Additionally, the article suggests initial target product profiles (TPPs) that should be considered when developing or testing these technologies for use in low-income settings.",0,0
39063538,Towards Improved XAI-Based Epidemiological Research into the Next Potential Pandemic,"Khalili H, Wimmer MA.",Life (Basel). 2024 Jun 21;14(7):783. doi: 10.3390/life14070783.,Khalili H,Life (Basel),2024,27-07-2024,PMC11278356,,10.3390/life14070783,"By applying AI techniques to a variety of pandemic-relevant data, artificial intelligence (AI) has substantially supported the control of the spread of the SARS-CoV-2 virus. Along with this, epidemiological machine learning studies of SARS-CoV-2 have been frequently published. While these models can be perceived as precise and policy-relevant to guide governments towards optimal containment policies, their black box nature can hamper building trust and relying confidently on the prescriptions proposed. This paper focuses on interpretable AI-based epidemiological models in the context of the recent SARS-CoV-2 pandemic. We systematically review existing studies, which jointly incorporate AI, SARS-CoV-2 epidemiology, and explainable AI approaches (XAI). First, we propose a conceptual framework by synthesizing the main methodological features of the existing AI pipelines of SARS-CoV-2. Upon the proposed conceptual framework and by analyzing the selected epidemiological studies, we reflect on current research gaps in epidemiological AI toolboxes and how to fill these gaps to generate enhanced policy support in the next potential pandemic.","Towards Improved XAI-Based Epidemiological Research into the Next Potential Pandemic By applying AI techniques to a variety of pandemic-relevant data, artificial intelligence (AI) has substantially supported the control of the spread of the SARS-CoV-2 virus. Along with this, epidemiological machine learning studies of SARS-CoV-2 have been frequently published. While these models can be perceived as precise and policy-relevant to guide governments towards optimal containment policies, their black box nature can hamper building trust and relying confidently on the prescriptions proposed. This paper focuses on interpretable AI-based epidemiological models in the context of the recent SARS-CoV-2 pandemic. We systematically review existing studies, which jointly incorporate AI, SARS-CoV-2 epidemiology, and explainable AI approaches (XAI). First, we propose a conceptual framework by synthesizing the main methodological features of the existing AI pipelines of SARS-CoV-2. Upon the proposed conceptual framework and by analyzing the selected epidemiological studies, we reflect on current research gaps in epidemiological AI toolboxes and how to fill these gaps to generate enhanced policy support in the next potential pandemic.",0,1
32996368,Exploring the Potential of Artificial Intelligence and Machine Learning to Combat COVID-19 and Existing Opportunities for LMIC: A Scoping Review,"Naseem M, Akhund R, Arshad H, Ibrahim MT.",J Prim Care Community Health. 2020 Jan-Dec;11:2150132720963634. doi: 10.1177/2150132720963634.,Naseem M,J Prim Care Community Health,2020,30-09-2020,PMC7533955,,10.1177/2150132720963634,"BACKGROUND: In the face of the current time-sensitive COVID-19 pandemic, the limited capacity of healthcare systems resulted in an emerging need to develop newer methods to control the spread of the pandemic. Artificial Intelligence (AI), and Machine Learning (ML) have a vast potential to exponentially optimize health care research. The use of AI-driven tools in LMIC can help in eradicating health inequalities and decrease the burden on health systems.
METHODS: The literature search for this Scoping review was conducted through the PubMed database using keywords: COVID-19, Artificial Intelligence (AI), Machine Learning (ML), and Low Middle-Income Countries (LMIC). Forty-three articles were identified and screened for eligibility and 13 were included in the final review. All the items of this Scoping review are reported using guidelines for PRISMA extension for scoping reviews (PRISMA-ScR).
RESULTS: Results were synthesized and reported under 4 themes. (a) The need of AI during this pandemic: AI can assist to increase the speed and accuracy of identification of cases and through data mining to deal with the health crisis efficiently, (b) Utility of AI in COVID-19 screening, contact tracing, and diagnosis: Efficacy for virus detection can a be increased by deploying the smart city data network using terminal tracking system along-with prediction of future outbreaks, (c) Use of AI in COVID-19 patient monitoring and drug development: A Deep learning system provides valuable information regarding protein structures associated with COVID-19 which could be utilized for vaccine formulation, and (d) AI beyond COVID-19 and opportunities for Low-Middle Income Countries (LMIC): There is a lack of financial, material, and human resources in LMIC, AI can minimize the workload on human labor and help in analyzing vast medical data, potentiating predictive and preventive healthcare.
CONCLUSION: AI-based tools can be a game-changer for diagnosis, treatment, and management of COVID-19 patients with the potential to reshape the future of healthcare in LMIC.","Exploring the Potential of Artificial Intelligence and Machine Learning to Combat COVID-19 and Existing Opportunities for LMIC: A Scoping Review BACKGROUND: In the face of the current time-sensitive COVID-19 pandemic, the limited capacity of healthcare systems resulted in an emerging need to develop newer methods to control the spread of the pandemic. Artificial Intelligence (AI), and Machine Learning (ML) have a vast potential to exponentially optimize health care research. The use of AI-driven tools in LMIC can help in eradicating health inequalities and decrease the burden on health systems.
METHODS: The literature search for this Scoping review was conducted through the PubMed database using keywords: COVID-19, Artificial Intelligence (AI), Machine Learning (ML), and Low Middle-Income Countries (LMIC). Forty-three articles were identified and screened for eligibility and 13 were included in the final review. All the items of this Scoping review are reported using guidelines for PRISMA extension for scoping reviews (PRISMA-ScR).
RESULTS: Results were synthesized and reported under 4 themes. (a) The need of AI during this pandemic: AI can assist to increase the speed and accuracy of identification of cases and through data mining to deal with the health crisis efficiently, (b) Utility of AI in COVID-19 screening, contact tracing, and diagnosis: Efficacy for virus detection can a be increased by deploying the smart city data network using terminal tracking system along-with prediction of future outbreaks, (c) Use of AI in COVID-19 patient monitoring and drug development: A Deep learning system provides valuable information regarding protein structures associated with COVID-19 which could be utilized for vaccine formulation, and (d) AI beyond COVID-19 and opportunities for Low-Middle Income Countries (LMIC): There is a lack of financial, material, and human resources in LMIC, AI can minimize the workload on human labor and help in analyzing vast medical data, potentiating predictive and preventive healthcare.
CONCLUSION: AI-based tools can be a game-changer for diagnosis, treatment, and management of COVID-19 patients with the potential to reshape the future of healthcare in LMIC.",0,1
35221080,Role of Digital Health During Coronavirus Disease 2019 Pandemic and Future Perspectives,"Ahmed A, Charate R, Pothineni NVK, Aedma SK, Gopinathannair R, Lakkireddy D.",Card Electrophysiol Clin. 2022 Mar;14(1):115-123. doi: 10.1016/j.ccep.2021.10.013. Epub 2021 Oct 30.,Ahmed A,Card Electrophysiol Clin,2022,28-02-2022,PMC8556539,,10.1016/j.ccep.2021.10.013,"Coronavirus disease 2019 revolutionized the digital health care. This pandemic was the catalyst for not only a sudden but also widespread paradigm shift in patient care, with nearly 80% of the US population indicating that they have used one form of digital health. Cardiac electrophysiology took the initiative to enroll patients in device clinics for remote monitoring and triage patients accordingly. Although challenges remain in making digital health available to masses, the future of digital health will be tested in the postpandemic time, and we believe these changes will continue to be expansive and widely applicable to physicians and patients.","Role of Digital Health During Coronavirus Disease 2019 Pandemic and Future Perspectives Coronavirus disease 2019 revolutionized the digital health care. This pandemic was the catalyst for not only a sudden but also widespread paradigm shift in patient care, with nearly 80% of the US population indicating that they have used one form of digital health. Cardiac electrophysiology took the initiative to enroll patients in device clinics for remote monitoring and triage patients accordingly. Although challenges remain in making digital health available to masses, the future of digital health will be tested in the postpandemic time, and we believe these changes will continue to be expansive and widely applicable to physicians and patients.",0,0
33041533,Applications of artificial intelligence in battling against covid-19: A literature review,Tayarani N MH.,Chaos Solitons Fractals. 2021 Jan;142:110338. doi: 10.1016/j.chaos.2020.110338. Epub 2020 Oct 3.,Tayarani N MH,Chaos Solitons Fractals,2021,12-10-2020,PMC7532790,,10.1016/j.chaos.2020.110338,"Colloquially known as coronavirus, the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2), that causes CoronaVirus Disease 2019 (COVID-19), has become a matter of grave concern for every country around the world. The rapid growth of the pandemic has wreaked havoc and prompted the need for immediate reactions to curb the effects. To manage the problems, many research in a variety of area of science have started studying the issue. Artificial Intelligence is among the area of science that has found great applications in tackling the problem in many aspects. Here, we perform an overview on the applications of AI in a variety of fields including diagnosis of the disease via different types of tests and symptoms, monitoring patients, identifying severity of a patient, processing covid-19 related imaging tests, epidemiology, pharmaceutical studies, etc. The aim of this paper is to perform a comprehensive survey on the applications of AI in battling against the difficulties the outbreak has caused. Thus we cover every way that AI approaches have been employed and to cover all the research until the writing of this paper. We try organize the works in a way that overall picture is comprehensible. Such a picture, although full of details, is very helpful in understand where AI sits in current pandemonium. We also tried to conclude the paper with ideas on how the problems can be tackled in a better way and provide some suggestions for future works.","Applications of artificial intelligence in battling against covid-19: A literature review Colloquially known as coronavirus, the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2), that causes CoronaVirus Disease 2019 (COVID-19), has become a matter of grave concern for every country around the world. The rapid growth of the pandemic has wreaked havoc and prompted the need for immediate reactions to curb the effects. To manage the problems, many research in a variety of area of science have started studying the issue. Artificial Intelligence is among the area of science that has found great applications in tackling the problem in many aspects. Here, we perform an overview on the applications of AI in a variety of fields including diagnosis of the disease via different types of tests and symptoms, monitoring patients, identifying severity of a patient, processing covid-19 related imaging tests, epidemiology, pharmaceutical studies, etc. The aim of this paper is to perform a comprehensive survey on the applications of AI in battling against the difficulties the outbreak has caused. Thus we cover every way that AI approaches have been employed and to cover all the research until the writing of this paper. We try organize the works in a way that overall picture is comprehensible. Such a picture, although full of details, is very helpful in understand where AI sits in current pandemonium. We also tried to conclude the paper with ideas on how the problems can be tackled in a better way and provide some suggestions for future works.",1,1
38700133,Artificial intelligence-assisted automated heart failure detection and classification from electronic health records,"Oo MM, Gao C, Cole C, Hummel Y, Guignard-Duff M, Jefferson E, Hare J, Voors AA, de Boer RA, Lam CSP, Mordi IR, Tromp J, Lang CC.",ESC Heart Fail. 2024 Oct;11(5):2769-2777. doi: 10.1002/ehf2.14828. Epub 2024 May 3.,Oo MM,ESC Heart Fail,2024,03-05-2024,PMC11424299,,10.1002/ehf2.14828,"AIMS: Electronic health records (EHR) linked to Digital Imaging and Communications in Medicine (DICOM), biological specimens, and deep learning (DL) algorithms could potentially improve patient care through automated case detection and surveillance. We hypothesized that by applying keyword searches to routinely stored EHR, in conjunction with AI-powered automated reading of DICOM echocardiography images and analysing biomarkers from routinely stored plasma samples, we were able to identify heart failure (HF) patients.
METHODS AND RESULTS: We used EHR data between 1993 and 2021 from Tayside and Fife (~20% of the Scottish population). We implemented a keyword search strategy complemented by filtering based on International Classification of Diseases (ICD) codes and prescription data to EHR data set. We then applied DL for the automated interpretation of echocardiographic DICOM images. These methods were then integrated with the analysis of routinely stored plasma samples to identify and categorize patients into HF with reduced ejection fraction (HFrEF), HF with preserved ejection fraction (HFpEF), and controls without HF. The final diagnosis was verified through a manual review of medical records, measured natriuretic peptides in stored blood samples, and by comparing clinical outcomes among groups. In our study, we selected the patient cohort through an algorithmic workflow. This process started with 60 850 EHR data and resulted in a final cohort of 578 patients, divided into 186 controls, 236 with HFpEF, and 156 with HFrEF, after excluding individuals with mismatched data or significant valvular heart disease. The analysis of baseline characteristics revealed that compared with controls, patients with HFrEF and HFpEF were generally older, had higher BMI, and showed a greater prevalence of co-morbidities such as diabetes, COPD, and CKD. Echocardiographic analysis, enhanced by DL, provided high coverage, and detailed insights into cardiac function, showing significant differences in parameters such as left ventricular diameter, ejection fraction, and myocardial strain among the groups. Clinical outcomes highlighted a higher risk of hospitalization and mortality for HF patients compared with controls, with particularly elevated risk ratios for both HFrEF and HFpEF groups. The concordance between the algorithmic selection of patients and manual validation demonstrated high accuracy, supporting the effectiveness of our approach in identifying and classifying HF subtypes, which could significantly impact future HF diagnosis and management strategies.
CONCLUSIONS: Our study highlights the feasibility of combining keyword searches in EHR, DL automated echocardiographic interpretation, and biobank resources to identify HF subtypes.","Artificial intelligence-assisted automated heart failure detection and classification from electronic health records AIMS: Electronic health records (EHR) linked to Digital Imaging and Communications in Medicine (DICOM), biological specimens, and deep learning (DL) algorithms could potentially improve patient care through automated case detection and surveillance. We hypothesized that by applying keyword searches to routinely stored EHR, in conjunction with AI-powered automated reading of DICOM echocardiography images and analysing biomarkers from routinely stored plasma samples, we were able to identify heart failure (HF) patients.
METHODS AND RESULTS: We used EHR data between 1993 and 2021 from Tayside and Fife (~20% of the Scottish population). We implemented a keyword search strategy complemented by filtering based on International Classification of Diseases (ICD) codes and prescription data to EHR data set. We then applied DL for the automated interpretation of echocardiographic DICOM images. These methods were then integrated with the analysis of routinely stored plasma samples to identify and categorize patients into HF with reduced ejection fraction (HFrEF), HF with preserved ejection fraction (HFpEF), and controls without HF. The final diagnosis was verified through a manual review of medical records, measured natriuretic peptides in stored blood samples, and by comparing clinical outcomes among groups. In our study, we selected the patient cohort through an algorithmic workflow. This process started with 60 850 EHR data and resulted in a final cohort of 578 patients, divided into 186 controls, 236 with HFpEF, and 156 with HFrEF, after excluding individuals with mismatched data or significant valvular heart disease. The analysis of baseline characteristics revealed that compared with controls, patients with HFrEF and HFpEF were generally older, had higher BMI, and showed a greater prevalence of co-morbidities such as diabetes, COPD, and CKD. Echocardiographic analysis, enhanced by DL, provided high coverage, and detailed insights into cardiac function, showing significant differences in parameters such as left ventricular diameter, ejection fraction, and myocardial strain among the groups. Clinical outcomes highlighted a higher risk of hospitalization and mortality for HF patients compared with controls, with particularly elevated risk ratios for both HFrEF and HFpEF groups. The concordance between the algorithmic selection of patients and manual validation demonstrated high accuracy, supporting the effectiveness of our approach in identifying and classifying HF subtypes, which could significantly impact future HF diagnosis and management strategies.
CONCLUSIONS: Our study highlights the feasibility of combining keyword searches in EHR, DL automated echocardiographic interpretation, and biobank resources to identify HF subtypes.",0,0
32585932,Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation,"Li Z, Gurgel H, Dessay N, Hu L, Xu L, Gong P.",Int J Environ Res Public Health. 2020 Jun 23;17(12):4509. doi: 10.3390/ijerph17124509.,Li Z,Int J Environ Res Public Health,2020,27-06-2020,PMC7344967,,10.3390/ijerph17124509,"In recent years there has been an increasing use of satellite Earth observation (EO) data in dengue research, in particular the identification of landscape factors affecting dengue transmission. Summarizing landscape factors and satellite EO data sources, and making the information public are helpful for guiding future research and improving health decision-making. In this case, a review of the literature would appear to be an appropriate tool. However, this is not an easy-to-use tool. The review process mainly includes defining the topic, searching, screening at both title/abstract and full-text levels and data extraction that needs consistent knowledge from experts and is time-consuming and labor intensive. In this context, this study integrates the review process, text scoring, active learning (AL) mechanism, and bidirectional long short-term memory (BiLSTM) networks, and proposes a semi-supervised text classification framework that enables the efficient and accurate selection of the relevant articles. Specifically, text scoring and BiLSTM-based active learning were used to replace the title/abstract screening and full-text screening, respectively, which greatly reduces the human workload. In this study, 101 relevant articles were selected from 4 bibliographic databases, and a catalogue of essential dengue landscape factors was identified and divided into four categories: land use (LU), land cover (LC), topography and continuous land surface features. Moreover, various satellite EO sensors and products used for identifying landscape factors were tabulated. Finally, possible future directions of applying satellite EO data in dengue research in terms of landscape patterns, satellite sensors and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context.","Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation In recent years there has been an increasing use of satellite Earth observation (EO) data in dengue research, in particular the identification of landscape factors affecting dengue transmission. Summarizing landscape factors and satellite EO data sources, and making the information public are helpful for guiding future research and improving health decision-making. In this case, a review of the literature would appear to be an appropriate tool. However, this is not an easy-to-use tool. The review process mainly includes defining the topic, searching, screening at both title/abstract and full-text levels and data extraction that needs consistent knowledge from experts and is time-consuming and labor intensive. In this context, this study integrates the review process, text scoring, active learning (AL) mechanism, and bidirectional long short-term memory (BiLSTM) networks, and proposes a semi-supervised text classification framework that enables the efficient and accurate selection of the relevant articles. Specifically, text scoring and BiLSTM-based active learning were used to replace the title/abstract screening and full-text screening, respectively, which greatly reduces the human workload. In this study, 101 relevant articles were selected from 4 bibliographic databases, and a catalogue of essential dengue landscape factors was identified and divided into four categories: land use (LU), land cover (LC), topography and continuous land surface features. Moreover, various satellite EO sensors and products used for identifying landscape factors were tabulated. Finally, possible future directions of applying satellite EO data in dengue research in terms of landscape patterns, satellite sensors and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context.",1,0
38946986,Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records,"Wang L, Novoa-Laurentiev J, Cook C, Srivatsan S, Hua Y, Yang J, Miloslavsky E, Choi HK, Zhou L, Wallace ZS.",medRxiv [Preprint]. 2024 Jun 10:2024.06.09.24308603. doi: 10.1101/2024.06.09.24308603.,Wang L,medRxiv,2024,01-07-2024,PMC11213085,,10.1101/2024.06.09.24308603,"BACKGROUND: ANCA-associated vasculitis (AAV) is a rare but serious disease. Traditional case-identification methods using claims data can be time-intensive and may miss important subgroups. We hypothesized that a deep learning model analyzing electronic health records (EHR) can more accurately identify AAV cases.
METHODS: We examined the Mass General Brigham (MGB) repository of clinical documentation from 12/1/1979 to 5/11/2021, using expert-curated keywords and ICD codes to identify a large cohort of potential AAV cases. Three labeled datasets (I, II, III) were created, each containing note sections. We trained and evaluated a range of machine learning and deep learning algorithms for note-level classification, using metrics like positive predictive value (PPV), sensitivity, F-score, area under the receiver operating characteristic curve (AUROC), and area under the precision and recall curve (AUPRC). The deep learning model was further evaluated for its ability to classify AAV cases at the patient-level, compared with rule-based algorithms in 2,000 randomly chosen samples.
RESULTS: Datasets I, II, and III comprised 6,000, 3,008, and 7,500 note sections, respectively. Deep learning achieved the highest AUROC in all three datasets, with scores of 0.983, 0.991, and 0.991. The deep learning approach also had among the highest PPVs across the three datasets (0.941, 0.954, and 0.800, respectively). In a test cohort of 2,000 cases, the deep learning model achieved a PPV of 0.262 and an estimated sensitivity of 0.975. Compared to the best rule-based algorithm, the deep learning model identified six additional AAV cases, representing 13% of the total.
CONCLUSION: The deep learning model effectively classifies clinical note sections for AAV diagnosis. Its application to EHR notes can potentially uncover additional cases missed by traditional rule-based methods.","Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records BACKGROUND: ANCA-associated vasculitis (AAV) is a rare but serious disease. Traditional case-identification methods using claims data can be time-intensive and may miss important subgroups. We hypothesized that a deep learning model analyzing electronic health records (EHR) can more accurately identify AAV cases.
METHODS: We examined the Mass General Brigham (MGB) repository of clinical documentation from 12/1/1979 to 5/11/2021, using expert-curated keywords and ICD codes to identify a large cohort of potential AAV cases. Three labeled datasets (I, II, III) were created, each containing note sections. We trained and evaluated a range of machine learning and deep learning algorithms for note-level classification, using metrics like positive predictive value (PPV), sensitivity, F-score, area under the receiver operating characteristic curve (AUROC), and area under the precision and recall curve (AUPRC). The deep learning model was further evaluated for its ability to classify AAV cases at the patient-level, compared with rule-based algorithms in 2,000 randomly chosen samples.
RESULTS: Datasets I, II, and III comprised 6,000, 3,008, and 7,500 note sections, respectively. Deep learning achieved the highest AUROC in all three datasets, with scores of 0.983, 0.991, and 0.991. The deep learning approach also had among the highest PPVs across the three datasets (0.941, 0.954, and 0.800, respectively). In a test cohort of 2,000 cases, the deep learning model achieved a PPV of 0.262 and an estimated sensitivity of 0.975. Compared to the best rule-based algorithm, the deep learning model identified six additional AAV cases, representing 13% of the total.
CONCLUSION: The deep learning model effectively classifies clinical note sections for AAV diagnosis. Its application to EHR notes can potentially uncover additional cases missed by traditional rule-based methods.",1,0
34546931,New Insights Into Drug Repurposing for COVID-19 Using Deep Learning,"Lee CY, Chen YP.",IEEE Trans Neural Netw Learn Syst. 2021 Nov;32(11):4770-4780. doi: 10.1109/TNNLS.2021.3111745. Epub 2021 Oct 27.,Lee CY,IEEE Trans Neural Netw Learn Syst,2021,21-09-2021,PMC8843052,,10.1109/TNNLS.2021.3111745,"The coronavirus disease 2019 (COVID-19) has continued to spread worldwide since late 2019. To expedite the process of providing treatment to those who have contracted the disease and to ensure the accessibility of effective drugs, numerous strategies have been implemented to find potential anti-COVID-19 drugs in a short span of time. Motivated by this critical global challenge, in this review, we detail approaches that have been used for drug repurposing for COVID-19 and suggest improvements to the existing deep learning (DL) approach to identify and repurpose drugs to treat this complex disease. By optimizing hyperparameter settings, deploying suitable activation functions, and designing optimization algorithms, the improved DL approach will be able to perform feature extraction from quality big data, turning the traditional DL approach, referred to as a ""black box,"" which generalizes and learns the transmitted data, into a ""glass box"" that will have the interpretability of its rationale while maintaining a high level of prediction accuracy. When adopted for drug repurposing for COVID-19, this improved approach will create a new generation of DL approaches that can establish a cause and effect relationship as to why the repurposed drugs are suitable for treating COVID-19. Its ability can also be extended to repurpose drugs for other complex diseases, develop appropriate treatment strategies for new diseases, and provide precision medical treatment to patients, thus paving the way to discover new drugs that can potentially be effective for treating COVID-19.","New Insights Into Drug Repurposing for COVID-19 Using Deep Learning The coronavirus disease 2019 (COVID-19) has continued to spread worldwide since late 2019. To expedite the process of providing treatment to those who have contracted the disease and to ensure the accessibility of effective drugs, numerous strategies have been implemented to find potential anti-COVID-19 drugs in a short span of time. Motivated by this critical global challenge, in this review, we detail approaches that have been used for drug repurposing for COVID-19 and suggest improvements to the existing deep learning (DL) approach to identify and repurpose drugs to treat this complex disease. By optimizing hyperparameter settings, deploying suitable activation functions, and designing optimization algorithms, the improved DL approach will be able to perform feature extraction from quality big data, turning the traditional DL approach, referred to as a ""black box,"" which generalizes and learns the transmitted data, into a ""glass box"" that will have the interpretability of its rationale while maintaining a high level of prediction accuracy. When adopted for drug repurposing for COVID-19, this improved approach will create a new generation of DL approaches that can establish a cause and effect relationship as to why the repurposed drugs are suitable for treating COVID-19. Its ability can also be extended to repurpose drugs for other complex diseases, develop appropriate treatment strategies for new diseases, and provide precision medical treatment to patients, thus paving the way to discover new drugs that can potentially be effective for treating COVID-19.",1,1
33587262,DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images,"Dhiman G, Vinoth Kumar V, Kaur A, Sharma A.",Interdiscip Sci. 2021 Jun;13(2):260-272. doi: 10.1007/s12539-021-00418-7. Epub 2021 Feb 15.,Dhiman G,Interdiscip Sci,2021,15-02-2021,PMC7882874,,10.1007/s12539-021-00418-7,"In the hospital, a limited number of COVID-19 test kits are available due to the spike in cases every day. For this reason, a rapid alternative diagnostic option should be introduced as an automated detection method to prevent COVID-19 spreading among individuals. This article proposes multi-objective optimization and a deep-learning methodology for the detection of infected coronavirus patients with X-rays. J48 decision tree method classifies the deep characteristics of affected X-ray corona images to detect the contaminated patients effectively. Eleven different convolutional neuronal network-based (CNN) models were developed in this study to detect infected patients with coronavirus pneumonia using X-ray images (AlexNet, VGG16, VGG19, GoogleNet, ResNet18, ResNet500, ResNet101, InceptionV3, InceptionResNetV2, DenseNet201 and XceptionNet). In addition, the parameters of the CNN profound learning model are described using an emperor penguin optimizer with several objectives (MOEPO). A broad review reveals that the proposed model can categorise the X-ray images at the correct rates of precision, accuracy, recall, specificity and F1-score. Extensive test results show that the proposed model outperforms competitive models with well-known efficiency metrics. The proposed model is, therefore, useful for the real-time classification of X-ray chest images of COVID-19 disease.","DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images In the hospital, a limited number of COVID-19 test kits are available due to the spike in cases every day. For this reason, a rapid alternative diagnostic option should be introduced as an automated detection method to prevent COVID-19 spreading among individuals. This article proposes multi-objective optimization and a deep-learning methodology for the detection of infected coronavirus patients with X-rays. J48 decision tree method classifies the deep characteristics of affected X-ray corona images to detect the contaminated patients effectively. Eleven different convolutional neuronal network-based (CNN) models were developed in this study to detect infected patients with coronavirus pneumonia using X-ray images (AlexNet, VGG16, VGG19, GoogleNet, ResNet18, ResNet500, ResNet101, InceptionV3, InceptionResNetV2, DenseNet201 and XceptionNet). In addition, the parameters of the CNN profound learning model are described using an emperor penguin optimizer with several objectives (MOEPO). A broad review reveals that the proposed model can categorise the X-ray images at the correct rates of precision, accuracy, recall, specificity and F1-score. Extensive test results show that the proposed model outperforms competitive models with well-known efficiency metrics. The proposed model is, therefore, useful for the real-time classification of X-ray chest images of COVID-19 disease.",1,1
37420714,"A Survey on COVID-19 Data Analysis Using AI, IoT, and Social Media","Butt MJ, Malik AK, Qamar N, Yar S, Malik AJ, Rauf U.",Sensors (Basel). 2023 Jun 13;23(12):5543. doi: 10.3390/s23125543.,Butt MJ,Sensors (Basel),2023,08-07-2023,PMC10303179,,10.3390/s23125543,"Coronaviruses are a well-established and deadly group of viruses that cause illness in both humans and animals. The novel type of this virus group, named COVID-19, was firstly reported in December 2019, and, with the passage of time, coronavirus has spread to almost all parts of the world. Coronavirus has been the cause of millions of deaths around the world. Furthermore, many countries are struggling with COVID-19 and have experimented with various kinds of vaccines to eliminate the deadly virus and its variants. This survey deals with COVID-19 data analysis and its impact on human social life. Data analysis and information related to coronavirus can greatly help scientists and governments in controlling the spread and symptoms of the deadly coronavirus. In this survey, we cover many areas of discussion related to COVID-19 data analysis, such as how artificial intelligence, along with machine learning, deep learning, and IoT, have worked together to fight against COVID-19. We also discuss artificial intelligence and IoT techniques used to forecast, detect, and diagnose patients of the novel coronavirus. Moreover, this survey also describes how fake news, doctored results, and conspiracy theories were spread over social media sites, such as Twitter, by applying various social network analysis and sentimental analysis techniques. A comprehensive comparative analysis of existing techniques has also been conducted. In the end, the Discussion section presents different data analysis techniques, provides future directions for research, and suggests general guidelines for handling coronavirus, as well as changing work and life conditions.","A Survey on COVID-19 Data Analysis Using AI, IoT, and Social Media Coronaviruses are a well-established and deadly group of viruses that cause illness in both humans and animals. The novel type of this virus group, named COVID-19, was firstly reported in December 2019, and, with the passage of time, coronavirus has spread to almost all parts of the world. Coronavirus has been the cause of millions of deaths around the world. Furthermore, many countries are struggling with COVID-19 and have experimented with various kinds of vaccines to eliminate the deadly virus and its variants. This survey deals with COVID-19 data analysis and its impact on human social life. Data analysis and information related to coronavirus can greatly help scientists and governments in controlling the spread and symptoms of the deadly coronavirus. In this survey, we cover many areas of discussion related to COVID-19 data analysis, such as how artificial intelligence, along with machine learning, deep learning, and IoT, have worked together to fight against COVID-19. We also discuss artificial intelligence and IoT techniques used to forecast, detect, and diagnose patients of the novel coronavirus. Moreover, this survey also describes how fake news, doctored results, and conspiracy theories were spread over social media sites, such as Twitter, by applying various social network analysis and sentimental analysis techniques. A comprehensive comparative analysis of existing techniques has also been conducted. In the end, the Discussion section presents different data analysis techniques, provides future directions for research, and suggests general guidelines for handling coronavirus, as well as changing work and life conditions.",0,1
34481301,Emergence and evolution of big data science in HIV research: Bibliometric analysis of federally sponsored studies 2000-2019,"Liang C, Qiao S, Olatosi B, Lyu T, Li X.",Int J Med Inform. 2021 Oct;154:104558. doi: 10.1016/j.ijmedinf.2021.104558. Epub 2021 Aug 18.,Liang C,Int J Med Inform,2021,04-09-2021,PMC8529625,NIHMS1735490,10.1016/j.ijmedinf.2021.104558,"BACKGROUND: The rapid growth of inherently complex and heterogeneous data in HIV/AIDS research underscores the importance of Big Data Science. Recently, there have been increasing uptakes of Big Data techniques in basic, clinical, and public health fields of HIV/AIDS research. However, no studies have systematically elaborated on the evolving applications of Big Data in HIV/AIDS research. We sought to explore the emergence and evolution of Big Data Science in HIV/AIDS-related publications that were funded by the US federal agencies.
METHODS: We identified HIV/AIDS and Big Data related publications that were funded by seven federal agencies from 2000 to 2019 by integrating data from National Institutes of Health (NIH) ExPORTER, MEDLINE, and MeSH. Building on bibliometrics and Natural Language Processing (NLP) methods, we constructed co-occurrence networks using bibliographic metadata (e.g., countries, institutes, MeSH terms, and keywords) of the retrieved publications. We then detected clusters among the networks as well as the temporal dynamics of clusters, followed by expert evaluation and clinical implications.
RESULTS: We harnessed nearly 600 thousand publications related to HIV/AIDS, of which 19,528 publications relating to Big Data were included in bibliometric analysis. Results showed that (1) the number of Big Data publications has been increasing since 2000, (2) US institutes have been in close collaborations with China, Canada, and Germany, (3) some institutes (e.g., University of California system, MD Anderson Cancer Center, and Harvard Medical School) are among the most productive institutes and started using Big Data in HIV/AIDS research early, (4) Big Data research was not active in public health disciplines until 2015, (5) research topics such as genomics, HIV comorbidities, population-based studies, Electronic Health Records (EHR), social media, precision medicine, and methodologies such as machine learning, Deep Learning, radiomics, and data mining emerge quickly in recent years.
CONCLUSIONS: We identified a rapid growth in the cross-disciplinary research of HIV/AIDS and Big Data over the past two decades. Our findings demonstrated patterns and trends of prevailing research topics and Big Data applications in HIV/AIDS research and suggested a number of fast-evolving areas of Big Data Science in HIV/AIDS research including secondary analysis of EHR, machine learning, Deep Learning, predictive analysis, and NLP.","Emergence and evolution of big data science in HIV research: Bibliometric analysis of federally sponsored studies 2000-2019 BACKGROUND: The rapid growth of inherently complex and heterogeneous data in HIV/AIDS research underscores the importance of Big Data Science. Recently, there have been increasing uptakes of Big Data techniques in basic, clinical, and public health fields of HIV/AIDS research. However, no studies have systematically elaborated on the evolving applications of Big Data in HIV/AIDS research. We sought to explore the emergence and evolution of Big Data Science in HIV/AIDS-related publications that were funded by the US federal agencies.
METHODS: We identified HIV/AIDS and Big Data related publications that were funded by seven federal agencies from 2000 to 2019 by integrating data from National Institutes of Health (NIH) ExPORTER, MEDLINE, and MeSH. Building on bibliometrics and Natural Language Processing (NLP) methods, we constructed co-occurrence networks using bibliographic metadata (e.g., countries, institutes, MeSH terms, and keywords) of the retrieved publications. We then detected clusters among the networks as well as the temporal dynamics of clusters, followed by expert evaluation and clinical implications.
RESULTS: We harnessed nearly 600 thousand publications related to HIV/AIDS, of which 19,528 publications relating to Big Data were included in bibliometric analysis. Results showed that (1) the number of Big Data publications has been increasing since 2000, (2) US institutes have been in close collaborations with China, Canada, and Germany, (3) some institutes (e.g., University of California system, MD Anderson Cancer Center, and Harvard Medical School) are among the most productive institutes and started using Big Data in HIV/AIDS research early, (4) Big Data research was not active in public health disciplines until 2015, (5) research topics such as genomics, HIV comorbidities, population-based studies, Electronic Health Records (EHR), social media, precision medicine, and methodologies such as machine learning, Deep Learning, radiomics, and data mining emerge quickly in recent years.
CONCLUSIONS: We identified a rapid growth in the cross-disciplinary research of HIV/AIDS and Big Data over the past two decades. Our findings demonstrated patterns and trends of prevailing research topics and Big Data applications in HIV/AIDS research and suggested a number of fast-evolving areas of Big Data Science in HIV/AIDS research including secondary analysis of EHR, machine learning, Deep Learning, predictive analysis, and NLP.",1,1
35812486,A Survey on Machine Learning and Internet of Medical Things-Based Approaches for Handling COVID-19: Meta-Analysis,"Band SS, Ardabili S, Yarahmadi A, Pahlevanzadeh B, Kiani AK, Beheshti A, Alinejad-Rokny H, Dehzangi I, Chang A, Mosavi A, Moslehpour M.",Front Public Health. 2022 Jun 23;10:869238. doi: 10.3389/fpubh.2022.869238. eCollection 2022.,Band SS,Front Public Health,2022,11-07-2022,PMC9260273,,10.3389/fpubh.2022.869238,"Early diagnosis, prioritization, screening, clustering, and tracking of patients with COVID-19, and production of drugs and vaccines are some of the applications that have made it necessary to use a new style of technology to involve, manage, and deal with this epidemic. Strategies backed by artificial intelligence (A.I.) and the Internet of Things (IoT) have been undeniably effective to understand how the virus works and prevent it from spreading. Accordingly, the main aim of this survey is to critically review the ML, IoT, and the integration of IoT and ML-based techniques in the applications related to COVID-19, from the diagnosis of the disease to the prediction of its outbreak. According to the main findings, IoT provided a prompt and efficient approach to tracking the disease spread. On the other hand, most of the studies developed by ML-based techniques aimed at the detection and handling of challenges associated with the COVID-19 pandemic. Among different approaches, Convolutional Neural Network (CNN), Support Vector Machine, Genetic CNN, and pre-trained CNN, followed by ResNet have demonstrated the best performances compared to other methods.","A Survey on Machine Learning and Internet of Medical Things-Based Approaches for Handling COVID-19: Meta-Analysis Early diagnosis, prioritization, screening, clustering, and tracking of patients with COVID-19, and production of drugs and vaccines are some of the applications that have made it necessary to use a new style of technology to involve, manage, and deal with this epidemic. Strategies backed by artificial intelligence (A.I.) and the Internet of Things (IoT) have been undeniably effective to understand how the virus works and prevent it from spreading. Accordingly, the main aim of this survey is to critically review the ML, IoT, and the integration of IoT and ML-based techniques in the applications related to COVID-19, from the diagnosis of the disease to the prediction of its outbreak. According to the main findings, IoT provided a prompt and efficient approach to tracking the disease spread. On the other hand, most of the studies developed by ML-based techniques aimed at the detection and handling of challenges associated with the COVID-19 pandemic. Among different approaches, Convolutional Neural Network (CNN), Support Vector Machine, Genetic CNN, and pre-trained CNN, followed by ResNet have demonstrated the best performances compared to other methods.",1,0
31760945,Attention-based recurrent neural network for influenza epidemic prediction,"Zhu X, Fu B, Yang Y, Ma Y, Hao J, Chen S, Liu S, Li T, Liu S, Guo W, Liao Z.",BMC Bioinformatics. 2019 Nov 25;20(Suppl 18):575. doi: 10.1186/s12859-019-3131-8.,Zhu X,BMC Bioinformatics,2019,26-11-2019,PMC6876090,,10.1186/s12859-019-3131-8,"BACKGROUND: Influenza is an infectious respiratory disease that can cause serious public health hazard. Due to its huge threat to the society, precise real-time forecasting of influenza outbreaks is of great value to our public.
RESULTS: In this paper, we propose a new deep neural network structure that forecasts a real-time influenza-like illness rate (ILI%) in Guangzhou, China. Long short-term memory (LSTM) neural networks is applied to precisely forecast accurateness due to the long-term attribute and diversity of influenza epidemic data. We devise a multi-channel LSTM neural network that can draw multiple information from different types of inputs. We also add attention mechanism to improve forecasting accuracy. By using this structure, we are able to deal with relationships between multiple inputs more appropriately. Our model fully consider the information in the data set, targetedly solving practical problems of the Guangzhou influenza epidemic forecasting.
CONCLUSION: We assess the performance of our model by comparing it with different neural network structures and other state-of-the-art methods. The experimental results indicate that our model has strong competitiveness and can provide effective real-time influenza epidemic forecasting.","Attention-based recurrent neural network for influenza epidemic prediction BACKGROUND: Influenza is an infectious respiratory disease that can cause serious public health hazard. Due to its huge threat to the society, precise real-time forecasting of influenza outbreaks is of great value to our public.
RESULTS: In this paper, we propose a new deep neural network structure that forecasts a real-time influenza-like illness rate (ILI%) in Guangzhou, China. Long short-term memory (LSTM) neural networks is applied to precisely forecast accurateness due to the long-term attribute and diversity of influenza epidemic data. We devise a multi-channel LSTM neural network that can draw multiple information from different types of inputs. We also add attention mechanism to improve forecasting accuracy. By using this structure, we are able to deal with relationships between multiple inputs more appropriately. Our model fully consider the information in the data set, targetedly solving practical problems of the Guangzhou influenza epidemic forecasting.
CONCLUSION: We assess the performance of our model by comparing it with different neural network structures and other state-of-the-art methods. The experimental results indicate that our model has strong competitiveness and can provide effective real-time influenza epidemic forecasting.",1,1
39466315,"Implications of Big Data Analytics, AI, Machine Learning, and Deep Learning in the Health Care System of Bangladesh: Scoping Review","Alam MA, Sajib MRUZ, Rahman F, Ether S, Hanson M, Sayeed A, Akter E, Nusrat N, Islam TT, Raza S, Tanvir KM, Chisti MJ, Rahman QS, Hossain A, Layek MA, Zaman A, Rana J, Rahman SM, Arifeen SE, Rahman AE, Ahmed A.",J Med Internet Res. 2024 Oct 28;26:e54710. doi: 10.2196/54710.,Alam MA,J Med Internet Res,2024,28-10-2024,PMC11555453,,10.2196/54710,"BACKGROUND: The rapid advancement of digital technologies, particularly in big data analytics (BDA), artificial intelligence (AI), machine learning (ML), and deep learning (DL), is reshaping the global health care system, including in Bangladesh. The increased adoption of these technologies in health care delivery within Bangladesh has sparked their integration into health care and public health research, resulting in a noticeable surge in related studies. However, a critical gap exists, as there is a lack of comprehensive evidence regarding the research landscape; regulatory challenges; use cases; and the application and adoption of BDA, AI, ML, and DL in the health care system of Bangladesh. This gap impedes the attainment of optimal results. As Bangladesh is a leading implementer of digital technologies, bridging this gap is urgent for the effective use of these advancing technologies.
OBJECTIVE: This scoping review aims to collate (1) the existing research in Bangladesh's health care system, using the aforementioned technologies and synthesizing their findings, and (2) the limitations faced by researchers in integrating the aforementioned technologies into health care research.
METHODS: MEDLINE (via PubMed), IEEE Xplore, Scopus, and Embase databases were searched to identify published research articles between January 1, 2000, and September 10, 2023, meeting the following inclusion criteria: (1) any study using any of the BDA, AI, ML, and DL technologies and health care and public health datasets for predicting health issues and forecasting any kind of outbreak; (2) studies primarily focusing on health care and public health issues in Bangladesh; and (3) original research articles published in peer-reviewed journals and conference proceedings written in English.
RESULTS: With the initial search, we identified 1653 studies. Following the inclusion and exclusion criteria and full-text review, 4.66% (77/1653) of the articles were finally included in this review. There was a substantial increase in studies over the last 5 years (2017-2023). Among the 77 studies, the majority (n=65, 84%) used ML models. A smaller proportion of studies incorporated AI (4/77, 5%), DL (7/77, 9%), and BDA (1/77, 1%) technologies. Among the reviewed articles, 52% (40/77) relied on primary data, while the remaining 48% (37/77) used secondary data. The primary research areas of focus were infectious diseases (15/77, 19%), noncommunicable diseases (23/77, 30%), child health (11/77, 14%), and mental health (9/77, 12%).
CONCLUSIONS: This scoping review highlights remarkable progress in leveraging BDA, AI, ML, and DL within Bangladesh's health care system. The observed surge in studies over the last 5 years underscores the increasing significance of AI and related technologies in health care research. Notably, most (65/77, 84%) studies focused on ML models, unveiling opportunities for advancements in predictive modeling. This review encapsulates the current state of technological integration and propels us into a promising era for the future of digital Bangladesh.","Implications of Big Data Analytics, AI, Machine Learning, and Deep Learning in the Health Care System of Bangladesh: Scoping Review BACKGROUND: The rapid advancement of digital technologies, particularly in big data analytics (BDA), artificial intelligence (AI), machine learning (ML), and deep learning (DL), is reshaping the global health care system, including in Bangladesh. The increased adoption of these technologies in health care delivery within Bangladesh has sparked their integration into health care and public health research, resulting in a noticeable surge in related studies. However, a critical gap exists, as there is a lack of comprehensive evidence regarding the research landscape; regulatory challenges; use cases; and the application and adoption of BDA, AI, ML, and DL in the health care system of Bangladesh. This gap impedes the attainment of optimal results. As Bangladesh is a leading implementer of digital technologies, bridging this gap is urgent for the effective use of these advancing technologies.
OBJECTIVE: This scoping review aims to collate (1) the existing research in Bangladesh's health care system, using the aforementioned technologies and synthesizing their findings, and (2) the limitations faced by researchers in integrating the aforementioned technologies into health care research.
METHODS: MEDLINE (via PubMed), IEEE Xplore, Scopus, and Embase databases were searched to identify published research articles between January 1, 2000, and September 10, 2023, meeting the following inclusion criteria: (1) any study using any of the BDA, AI, ML, and DL technologies and health care and public health datasets for predicting health issues and forecasting any kind of outbreak; (2) studies primarily focusing on health care and public health issues in Bangladesh; and (3) original research articles published in peer-reviewed journals and conference proceedings written in English.
RESULTS: With the initial search, we identified 1653 studies. Following the inclusion and exclusion criteria and full-text review, 4.66% (77/1653) of the articles were finally included in this review. There was a substantial increase in studies over the last 5 years (2017-2023). Among the 77 studies, the majority (n=65, 84%) used ML models. A smaller proportion of studies incorporated AI (4/77, 5%), DL (7/77, 9%), and BDA (1/77, 1%) technologies. Among the reviewed articles, 52% (40/77) relied on primary data, while the remaining 48% (37/77) used secondary data. The primary research areas of focus were infectious diseases (15/77, 19%), noncommunicable diseases (23/77, 30%), child health (11/77, 14%), and mental health (9/77, 12%).
CONCLUSIONS: This scoping review highlights remarkable progress in leveraging BDA, AI, ML, and DL within Bangladesh's health care system. The observed surge in studies over the last 5 years underscores the increasing significance of AI and related technologies in health care research. Notably, most (65/77, 84%) studies focused on ML models, unveiling opportunities for advancements in predictive modeling. This review encapsulates the current state of technological integration and propels us into a promising era for the future of digital Bangladesh.",0,0
33641077,Accurately Discriminating COVID-19 from Viral and Bacterial Pneumonia According to CT Images Via Deep Learning,"Zheng F, Li L, Zhang X, Song Y, Huang Z, Chong Y, Chen Z, Zhu H, Wu J, Chen W, Lu Y, Yang Y, Zha Y, Zhao H, Shen J.",Interdiscip Sci. 2021 Jun;13(2):273-285. doi: 10.1007/s12539-021-00420-z. Epub 2021 Feb 27.,Zheng F,Interdiscip Sci,2021,28-02-2021,PMC7914048,,10.1007/s12539-021-00420-z,"Computed tomography (CT) is one of the most efficient diagnostic methods for rapid diagnosis of the widespread COVID-19. However, reading CT films brings a lot of concentration and time for doctors. Therefore, it is necessary to develop an automatic CT image diagnosis system to assist doctors in diagnosis. Previous studies devoted to COVID-19 in the past months focused mostly on discriminating COVID-19 infected patients from healthy persons and/or bacterial pneumonia patients, and have ignored typical viral pneumonia since it is hard to collect samples for viral pneumonia that is less frequent in adults. In addition, it is much more challenging to discriminate COVID-19 from typical viral pneumonia as COVID-19 is also a kind of virus. In this study, we have collected CT images of 262, 100, 219, and 78 persons for COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls, respectively. To the best of our knowledge, this was the first study of quaternary classification to include also typical viral pneumonia. To effectively capture the subtle differences in CT images, we have constructed a new model by combining the ResNet50 backbone with SE blocks that was recently developed for fine image analysis. Our model was shown to outperform commonly used baseline models, achieving an overall accuracy of 0.94 with AUC of 0.96, recall of 0.94, precision of 0.95, and F1-score of 0.94. The model is available in https://github.com/Zhengfudan/COVID-19-Diagnosis-and-Pneumonia-Classification .","Accurately Discriminating COVID-19 from Viral and Bacterial Pneumonia According to CT Images Via Deep Learning Computed tomography (CT) is one of the most efficient diagnostic methods for rapid diagnosis of the widespread COVID-19. However, reading CT films brings a lot of concentration and time for doctors. Therefore, it is necessary to develop an automatic CT image diagnosis system to assist doctors in diagnosis. Previous studies devoted to COVID-19 in the past months focused mostly on discriminating COVID-19 infected patients from healthy persons and/or bacterial pneumonia patients, and have ignored typical viral pneumonia since it is hard to collect samples for viral pneumonia that is less frequent in adults. In addition, it is much more challenging to discriminate COVID-19 from typical viral pneumonia as COVID-19 is also a kind of virus. In this study, we have collected CT images of 262, 100, 219, and 78 persons for COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls, respectively. To the best of our knowledge, this was the first study of quaternary classification to include also typical viral pneumonia. To effectively capture the subtle differences in CT images, we have constructed a new model by combining the ResNet50 backbone with SE blocks that was recently developed for fine image analysis. Our model was shown to outperform commonly used baseline models, achieving an overall accuracy of 0.94 with AUC of 0.96, recall of 0.94, precision of 0.95, and F1-score of 0.94. The model is available in https://github.com/Zhengfudan/COVID-19-Diagnosis-and-Pneumonia-Classification .",1,1
34790004,Hepatocellular carcinoma risk after viral response in hepatitis C virus-advanced fibrosis: Who to screen and for how long?,"Ahumada A, Rayón L, Usón C, Bañares R, Alonso Lopez S.",World J Gastroenterol. 2021 Oct 28;27(40):6737-6749. doi: 10.3748/wjg.v27.i40.6737.,Ahumada A,World J Gastroenterol,2021,18-11-2021,PMC8567476,,10.3748/wjg.v27.i40.6737,"Hepatitis C virus (HCV) chronic infection is associated with fibrosis progression, end-stage liver complications and HCC. Not surprisingly, HCV infection is a leading cause of liver-related morbidity and mortality worldwide. After sustained virological response (SVR), the risk of developing hepatocellular carcinoma is not completely eliminated in patients with established cirrhosis or with advanced fibrosis. Therefore, lifelong surveillance is currently recommended. This strategy is likely not universally cost-effective and harmless, considering that not all patients with advanced fibrosis have the same risk of developing HCC. Factors related to the severity of liver disease and its potential to improve after SVR, the molecular and epigenetic changes that occur during infection and other associated comorbidities might account for different risk levels and are likely essential for identifying patients who would benefit from screening programs after SVR. Efforts to develop predictive models and risk calculators, biomarkers and genetic panels and even deep learning models to estimate the individual risk of HCC have been made in the direct-acting antiviral agents era, when thousands of patients with advanced fibrosis and cirrhosis have reached SVR. These tools could help to identify patients with very low HCC risk in whom surveillance might not be justified. In this review, factors affecting the probability of HCC development after SVR, the benefits and risks of surveillance, suggested strategies to estimate individualized HCC risk and the current evidence to recommend lifelong surveillance are discussed.","Hepatocellular carcinoma risk after viral response in hepatitis C virus-advanced fibrosis: Who to screen and for how long? Hepatitis C virus (HCV) chronic infection is associated with fibrosis progression, end-stage liver complications and HCC. Not surprisingly, HCV infection is a leading cause of liver-related morbidity and mortality worldwide. After sustained virological response (SVR), the risk of developing hepatocellular carcinoma is not completely eliminated in patients with established cirrhosis or with advanced fibrosis. Therefore, lifelong surveillance is currently recommended. This strategy is likely not universally cost-effective and harmless, considering that not all patients with advanced fibrosis have the same risk of developing HCC. Factors related to the severity of liver disease and its potential to improve after SVR, the molecular and epigenetic changes that occur during infection and other associated comorbidities might account for different risk levels and are likely essential for identifying patients who would benefit from screening programs after SVR. Efforts to develop predictive models and risk calculators, biomarkers and genetic panels and even deep learning models to estimate the individual risk of HCC have been made in the direct-acting antiviral agents era, when thousands of patients with advanced fibrosis and cirrhosis have reached SVR. These tools could help to identify patients with very low HCC risk in whom surveillance might not be justified. In this review, factors affecting the probability of HCC development after SVR, the benefits and risks of surveillance, suggested strategies to estimate individualized HCC risk and the current evidence to recommend lifelong surveillance are discussed.",0,0
32562732,"Optical techniques, computed tomography and deep learning role in the diagnosis of COVID-19 pandemic towards increasing the survival rate of vulnerable populations","Qureshi SA, Rehman AU.",Photodiagnosis Photodyn Ther. 2020 Sep;31:101880. doi: 10.1016/j.pdpdt.2020.101880. Epub 2020 Jun 17.,Qureshi SA,Photodiagnosis Photodyn Ther,2020,21-06-2020,PMC7834065,,10.1016/j.pdpdt.2020.101880,• Severe lung complications can be explored using computed tomography during COVID-19 pandemic. • Ultra-low dose CT can enhance COVID-19 infected patients diagnostic capability. • Optically monitored CT along with deep learning is the best solution for diagnosis of COVID-19 during pandemic. • CT scans sensitivity (88 %) is preferable on clinical approach sensitivity (59 %) for COVID-19 suspected patients. • CT and Computer aided approaches helps the radiologist to make fast and accurate diagnosis during COVID-19 pandemic.,"Optical techniques, computed tomography and deep learning role in the diagnosis of COVID-19 pandemic towards increasing the survival rate of vulnerable populations • Severe lung complications can be explored using computed tomography during COVID-19 pandemic. • Ultra-low dose CT can enhance COVID-19 infected patients diagnostic capability. • Optically monitored CT along with deep learning is the best solution for diagnosis of COVID-19 during pandemic. • CT scans sensitivity (88 %) is preferable on clinical approach sensitivity (59 %) for COVID-19 suspected patients. • CT and Computer aided approaches helps the radiologist to make fast and accurate diagnosis during COVID-19 pandemic.",0,1
33014121,Review on Diagnosis of COVID-19 from Chest CT Images Using Artificial Intelligence,"Ozsahin I, Sekeroglu B, Musa MS, Mustapha MT, Uzun Ozsahin D.",Comput Math Methods Med. 2020 Sep 26;2020:9756518. doi: 10.1155/2020/9756518. eCollection 2020.,Ozsahin I,Comput Math Methods Med,2020,05-10-2020,PMC7519983,,10.1155/2020/9756518,"The COVID-19 diagnostic approach is mainly divided into two broad categories, a laboratory-based and chest radiography approach. The last few months have witnessed a rapid increase in the number of studies use artificial intelligence (AI) techniques to diagnose COVID-19 with chest computed tomography (CT). In this study, we review the diagnosis of COVID-19 by using chest CT toward AI. We searched ArXiv, MedRxiv, and Google Scholar using the terms ""deep learning"", ""neural networks"", ""COVID-19"", and ""chest CT"". At the time of writing (August 24, 2020), there have been nearly 100 studies and 30 studies among them were selected for this review. We categorized the studies based on the classification tasks: COVID-19/normal, COVID-19/non-COVID-19, COVID-19/non-COVID-19 pneumonia, and severity. The sensitivity, specificity, precision, accuracy, area under the curve, and F1 score results were reported as high as 100%, 100%, 99.62, 99.87%, 100%, and 99.5%, respectively. However, the presented results should be carefully compared due to the different degrees of difficulty of different classification tasks.","Review on Diagnosis of COVID-19 from Chest CT Images Using Artificial Intelligence The COVID-19 diagnostic approach is mainly divided into two broad categories, a laboratory-based and chest radiography approach. The last few months have witnessed a rapid increase in the number of studies use artificial intelligence (AI) techniques to diagnose COVID-19 with chest computed tomography (CT). In this study, we review the diagnosis of COVID-19 by using chest CT toward AI. We searched ArXiv, MedRxiv, and Google Scholar using the terms ""deep learning"", ""neural networks"", ""COVID-19"", and ""chest CT"". At the time of writing (August 24, 2020), there have been nearly 100 studies and 30 studies among them were selected for this review. We categorized the studies based on the classification tasks: COVID-19/normal, COVID-19/non-COVID-19, COVID-19/non-COVID-19 pneumonia, and severity. The sensitivity, specificity, precision, accuracy, area under the curve, and F1 score results were reported as high as 100%, 100%, 99.62, 99.87%, 100%, and 99.5%, respectively. However, the presented results should be carefully compared due to the different degrees of difficulty of different classification tasks.",1,1
38263439,Comparison between a deep-learning and a pixel-based approach for the automated quantification of HIV target cells in foreskin tissue,"Shao Z, Buchanan LB, Zuanazzi D, Khan YN, Khan AR, Prodger JL.",Sci Rep. 2024 Jan 23;14(1):1985. doi: 10.1038/s41598-024-52613-3.,Shao Z,Sci Rep,2024,24-01-2024,PMC10806185,,10.1038/s41598-024-52613-3,"The availability of target cells expressing the HIV receptors CD4 and CCR5 in genital tissue is a critical determinant of HIV susceptibility during sexual transmission. Quantification of immune cells in genital tissue is therefore an important outcome for studies on HIV susceptibility and prevention. Immunofluorescence microscopy allows for precise visualization of immune cells in mucosal tissues; however, this technique is limited in clinical studies by the lack of an accurate, unbiased, high-throughput image analysis method. Current pixel-based thresholding methods for cell counting struggle in tissue regions with high cell density and autofluorescence, both of which are common features in genital tissue. We describe a deep-learning approach using the publicly available StarDist method to count cells in immunofluorescence microscopy images of foreskin stained for nuclei, CD3, CD4, and CCR5. The accuracy of the model was comparable to manual counting (gold standard) and surpassed the capability of a previously described pixel-based cell counting method. We show that the performance of our deep-learning model is robust in tissue regions with high cell density and high autofluorescence. Moreover, we show that this deep-learning analysis method is both easy to implement and to adapt for the identification of other cell types in genital mucosal tissue.","Comparison between a deep-learning and a pixel-based approach for the automated quantification of HIV target cells in foreskin tissue The availability of target cells expressing the HIV receptors CD4 and CCR5 in genital tissue is a critical determinant of HIV susceptibility during sexual transmission. Quantification of immune cells in genital tissue is therefore an important outcome for studies on HIV susceptibility and prevention. Immunofluorescence microscopy allows for precise visualization of immune cells in mucosal tissues; however, this technique is limited in clinical studies by the lack of an accurate, unbiased, high-throughput image analysis method. Current pixel-based thresholding methods for cell counting struggle in tissue regions with high cell density and autofluorescence, both of which are common features in genital tissue. We describe a deep-learning approach using the publicly available StarDist method to count cells in immunofluorescence microscopy images of foreskin stained for nuclei, CD3, CD4, and CCR5. The accuracy of the model was comparable to manual counting (gold standard) and surpassed the capability of a previously described pixel-based cell counting method. We show that the performance of our deep-learning model is robust in tissue regions with high cell density and high autofluorescence. Moreover, we show that this deep-learning analysis method is both easy to implement and to adapt for the identification of other cell types in genital mucosal tissue.",1,1
34055034,Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19,"Helwan A, Ma'aitah MKS, Hamdan H, Ozsahin DU, Tuncyurek O.",Comput Math Methods Med. 2021 May 10;2021:5527271. doi: 10.1155/2021/5527271. eCollection 2021.,Helwan A,Comput Math Methods Med,2021,31-05-2021,PMC8112196,,10.1155/2021/5527271,"The reverse transcriptase polymerase chain reaction (RT-PCR) is still the routinely used test for the diagnosis of SARS-CoV-2 (COVID-19). However, according to several reports, RT-PCR showed a low sensitivity and multiple tests may be required to rule out false negative results. Recently, chest computed tomography (CT) has been an efficient tool to diagnose COVID-19 as it is directly affecting the lungs. In this paper, we investigate the application of pre-trained models in diagnosing patients who are positive for COVID-19 and differentiating it from normal patients, who tested negative for coronavirus. The study aims to compare the generalization capabilities of deep learning models with two thoracic radiologists in diagnosing COVID-19 chest CT images. A dataset of 3000 images was obtained from the Near East Hospital, Cyprus, and used to train and to test the three employed pre-trained models. In a test set of 250 images used to evaluate the deep neural networks and the radiologists, it was found that deep networks (ResNet-18, ResNet-50, and DenseNet-201) can outperform the radiologists in terms of higher accuracy (97.8%), sensitivity (98.1%), specificity (97.3%), precision (98.4%), and F1-score (198.25%), in classifying COVID-19 images.","Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19 The reverse transcriptase polymerase chain reaction (RT-PCR) is still the routinely used test for the diagnosis of SARS-CoV-2 (COVID-19). However, according to several reports, RT-PCR showed a low sensitivity and multiple tests may be required to rule out false negative results. Recently, chest computed tomography (CT) has been an efficient tool to diagnose COVID-19 as it is directly affecting the lungs. In this paper, we investigate the application of pre-trained models in diagnosing patients who are positive for COVID-19 and differentiating it from normal patients, who tested negative for coronavirus. The study aims to compare the generalization capabilities of deep learning models with two thoracic radiologists in diagnosing COVID-19 chest CT images. A dataset of 3000 images was obtained from the Near East Hospital, Cyprus, and used to train and to test the three employed pre-trained models. In a test set of 250 images used to evaluate the deep neural networks and the radiologists, it was found that deep networks (ResNet-18, ResNet-50, and DenseNet-201) can outperform the radiologists in terms of higher accuracy (97.8%), sensitivity (98.1%), specificity (97.3%), precision (98.4%), and F1-score (198.25%), in classifying COVID-19 images.",1,1
31142826,Development and evaluation of a deep learning approach for modeling seasonality and trends in hand-foot-mouth disease incidence in mainland China,"Wang Y, Xu C, Zhang S, Yang L, Wang Z, Zhu Y, Yuan J.",Sci Rep. 2019 May 29;9(1):8046. doi: 10.1038/s41598-019-44469-9.,Wang Y,Sci Rep,2019,31-05-2019,PMC6541597,,10.1038/s41598-019-44469-9,"The high incidence, seasonal pattern and frequent outbreaks of hand, foot, and mouth disease (HFMD) represent a threat for millions of children in mainland China. And advanced response is being used to address this. Here, we aimed to model time series with a long short-term memory (LSTM) based on the HFMD notified data from June 2008 to June 2018 and the ultimate performance was compared with the autoregressive integrated moving average (ARIMA) and nonlinear auto-regressive neural network (NAR). The results indicated that the identified best-fitting LSTM with the better superiority, be it in modeling dataset or two robustness tests dataset, than the best-conducting NAR and seasonal ARIMA (SARIMA) methods in forecasting performances, including the minimum indices of root mean square error, mean absolute error and mean absolute percentage error. The epidemic trends of HFMD remained stable during the study period, but the reported cases were even at significantly high levels with a notable high-risk seasonality in summer, and the incident cases projected by the LSTM would still be fairly high with a slightly upward trend in the future. In this regard, the LSTM approach should be highlighted in forecasting the epidemics of HFMD, and therefore assisting decision makers in making efficient decisions derived from the early detection of the disease incidents.","Development and evaluation of a deep learning approach for modeling seasonality and trends in hand-foot-mouth disease incidence in mainland China The high incidence, seasonal pattern and frequent outbreaks of hand, foot, and mouth disease (HFMD) represent a threat for millions of children in mainland China. And advanced response is being used to address this. Here, we aimed to model time series with a long short-term memory (LSTM) based on the HFMD notified data from June 2008 to June 2018 and the ultimate performance was compared with the autoregressive integrated moving average (ARIMA) and nonlinear auto-regressive neural network (NAR). The results indicated that the identified best-fitting LSTM with the better superiority, be it in modeling dataset or two robustness tests dataset, than the best-conducting NAR and seasonal ARIMA (SARIMA) methods in forecasting performances, including the minimum indices of root mean square error, mean absolute error and mean absolute percentage error. The epidemic trends of HFMD remained stable during the study period, but the reported cases were even at significantly high levels with a notable high-risk seasonality in summer, and the incident cases projected by the LSTM would still be fairly high with a slightly upward trend in the future. In this regard, the LSTM approach should be highlighted in forecasting the epidemics of HFMD, and therefore assisting decision makers in making efficient decisions derived from the early detection of the disease incidents.",1,0
30779585,Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets,"Zorn KM, Lane TR, Russo DP, Clark AM, Makarov V, Ekins S.",Mol Pharm. 2019 Apr 1;16(4):1620-1632. doi: 10.1021/acs.molpharmaceut.8b01297. Epub 2019 Feb 26.,Zorn KM,Mol Pharm,2019,20-02-2019,PMC7702308,NIHMS1619910,10.1021/acs.molpharmaceut.8b01297,"The human immunodeficiency virus (HIV) causes over a million deaths every year and has a huge economic impact in many countries. The first class of drugs approved were nucleoside reverse transcriptase inhibitors. A newer generation of reverse transcriptase inhibitors have become susceptible to drug resistant strains of HIV, and hence, alternatives are urgently needed. We have recently pioneered the use of Bayesian machine learning to generate models with public data to identify new compounds for testing against different disease targets. The current study has used the NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database for machine learning studies. We curated and cleaned data from HIV-1 wild-type cell-based and reverse transcriptase (RT) DNA polymerase inhibition assays. Compounds from this database with ≤1 μM HIV-1 RT DNA polymerase activity inhibition and cell-based HIV-1 inhibition are correlated (Pearson r = 0.44, n = 1137, p < 0.0001). Models were trained using multiple machine learning approaches (Bernoulli Naive Bayes, AdaBoost Decision Tree, Random Forest, support vector classification, k-Nearest Neighbors, and deep neural networks as well as consensus approaches) and then their predictive abilities were compared. Our comparison of different machine learning methods demonstrated that support vector classification, deep learning, and a consensus were generally comparable and not significantly different from each other using 5-fold cross validation and using 24 training and test set combinations. This study demonstrates findings in line with our previous studies for various targets that training and testing with multiple data sets does not demonstrate a significant difference between support vector machine and deep neural networks.","Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets The human immunodeficiency virus (HIV) causes over a million deaths every year and has a huge economic impact in many countries. The first class of drugs approved were nucleoside reverse transcriptase inhibitors. A newer generation of reverse transcriptase inhibitors have become susceptible to drug resistant strains of HIV, and hence, alternatives are urgently needed. We have recently pioneered the use of Bayesian machine learning to generate models with public data to identify new compounds for testing against different disease targets. The current study has used the NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database for machine learning studies. We curated and cleaned data from HIV-1 wild-type cell-based and reverse transcriptase (RT) DNA polymerase inhibition assays. Compounds from this database with ≤1 μM HIV-1 RT DNA polymerase activity inhibition and cell-based HIV-1 inhibition are correlated (Pearson r = 0.44, n = 1137, p < 0.0001). Models were trained using multiple machine learning approaches (Bernoulli Naive Bayes, AdaBoost Decision Tree, Random Forest, support vector classification, k-Nearest Neighbors, and deep neural networks as well as consensus approaches) and then their predictive abilities were compared. Our comparison of different machine learning methods demonstrated that support vector classification, deep learning, and a consensus were generally comparable and not significantly different from each other using 5-fold cross validation and using 24 training and test set combinations. This study demonstrates findings in line with our previous studies for various targets that training and testing with multiple data sets does not demonstrate a significant difference between support vector machine and deep neural networks.",1,1
33394945,A National US Survey of Pediatric Emergency Department Coronavirus Pandemic Preparedness,"Auerbach MA, Abulebda K, Bona AM, Falvo L, Hughes PG, Wagner M, Barach PR, Ahmed RA.",Pediatr Emerg Care. 2021 Jan 1;37(1):48-53. doi: 10.1097/PEC.0000000000002307.,Auerbach MA,Pediatr Emerg Care,2021,04-01-2021,PMC7780930,,10.1097/PEC.0000000000002307,"OBJECTIVE: We aim to describe the current coronavirus disease 2019 (COVID-19) preparedness efforts among a diverse set of pediatric emergency departments (PEDs) within the United States.
METHODS: We conducted a prospective multicenter survey of PED medical director(s) from selected children's hospitals recruited through a long established national research network. The questionnaire was developed by physicians with expertise in pediatric emergency medicine, disaster readiness, human factors, and survey development. Thirty-five children's hospitals were identified for recruitment through an established national research network.
RESULTS: We report on survey responses from 25 (71%) of 35 PEDs, of which 64% were located within academic children's hospitals. All PEDs witnessed decreases in non-COVID-19 patients, 60% had COVID-19-dedicated units, and 32% changed their unit pediatric patient age to include adult patients. All PEDs implemented changes to their staffing model, with the most common change impacting their physician staffing (80%) and triaging model (76%). All PEDs conducted training for appropriate donning and doffing of personal protective equipment (PPE), and 62% reported shortages in PPE. The majority implemented changes in the airway management protocols (84%) and cardiac arrest management in COVID patients (76%). The most common training modalities were video/teleconference (84%) and simulation-based training (72%). The most common learning objectives were team dynamics (60%), and PPE and individual procedural skills (56%).
CONCLUSIONS: This national survey provides insight into PED preparedness efforts, training innovations, and practice changes implemented during the start of COVID-19 pandemic. Pediatric emergency departments implemented broad strategies including modifications to staffing, workflow, and clinical practice while using video/teleconference and simulation as preferred training modalities. Further research is needed to advance the level of preparedness and support deep learning about which preparedness actions were effective for future pandemics.","A National US Survey of Pediatric Emergency Department Coronavirus Pandemic Preparedness OBJECTIVE: We aim to describe the current coronavirus disease 2019 (COVID-19) preparedness efforts among a diverse set of pediatric emergency departments (PEDs) within the United States.
METHODS: We conducted a prospective multicenter survey of PED medical director(s) from selected children's hospitals recruited through a long established national research network. The questionnaire was developed by physicians with expertise in pediatric emergency medicine, disaster readiness, human factors, and survey development. Thirty-five children's hospitals were identified for recruitment through an established national research network.
RESULTS: We report on survey responses from 25 (71%) of 35 PEDs, of which 64% were located within academic children's hospitals. All PEDs witnessed decreases in non-COVID-19 patients, 60% had COVID-19-dedicated units, and 32% changed their unit pediatric patient age to include adult patients. All PEDs implemented changes to their staffing model, with the most common change impacting their physician staffing (80%) and triaging model (76%). All PEDs conducted training for appropriate donning and doffing of personal protective equipment (PPE), and 62% reported shortages in PPE. The majority implemented changes in the airway management protocols (84%) and cardiac arrest management in COVID patients (76%). The most common training modalities were video/teleconference (84%) and simulation-based training (72%). The most common learning objectives were team dynamics (60%), and PPE and individual procedural skills (56%).
CONCLUSIONS: This national survey provides insight into PED preparedness efforts, training innovations, and practice changes implemented during the start of COVID-19 pandemic. Pediatric emergency departments implemented broad strategies including modifications to staffing, workflow, and clinical practice while using video/teleconference and simulation as preferred training modalities. Further research is needed to advance the level of preparedness and support deep learning about which preparedness actions were effective for future pandemics.",0,0
32617690,A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images,"Ni Q, Sun ZY, Qi L, Chen W, Yang Y, Wang L, Zhang X, Yang L, Fang Y, Xing Z, Zhou Z, Yu Y, Lu GM, Zhang LJ.",Eur Radiol. 2020 Dec;30(12):6517-6527. doi: 10.1007/s00330-020-07044-9. Epub 2020 Jul 2.,Ni Q,Eur Radiol,2020,04-07-2020,PMC7331494,,10.1007/s00330-020-07044-9,"OBJECTIVES: To utilize a deep learning model for automatic detection of abnormalities in chest CT images from COVID-19 patients and compare its quantitative determination performance with radiological residents.
METHODS: A deep learning algorithm consisted of lesion detection, segmentation, and location was trained and validated in 14,435 participants with chest CT images and definite pathogen diagnosis. The algorithm was tested in a non-overlapping dataset of 96 confirmed COVID-19 patients in three hospitals across China during the outbreak. Quantitative detection performance of the model was compared with three radiological residents with two experienced radiologists' reading reports as reference standard by assessing the accuracy, sensitivity, specificity, and F1 score.
RESULTS: Of 96 patients, 88 had pneumonia lesions on CT images and 8 had no abnormities on CT images. For per-patient basis, the algorithm showed superior sensitivity of 1.00 (95% confidence interval (CI) 0.95, 1.00) and F1 score of 0.97 in detecting lesions from CT images of COVID-19 pneumonia patients. While for per-lung lobe basis, the algorithm achieved a sensitivity of 0.96 (95% CI 0.94, 0.98) and a slightly inferior F1 score of 0.86. The median volume of lesions calculated by algorithm was 40.10 cm3. An average running speed of 20.3 s ± 5.8 per case demonstrated the algorithm was much faster than the residents in assessing CT images (all p &lt; 0.017). The deep learning algorithm can also assist radiologists make quicker diagnosis (all p &lt; 0.0001) with superior diagnostic performance.
CONCLUSIONS: The algorithm showed excellent performance in detecting COVID-19 pneumonia on chest CT images compared with resident radiologists.
KEY POINTS: • The higher sensitivity of deep learning model in detecting COVID-19 pneumonia were found compared with radiological residents on a per-lobe and per-patient basis. • The deep learning model improves diagnosis efficiency by shortening processing time. • The deep learning model can automatically calculate the volume of the lesions and whole lung.","A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images OBJECTIVES: To utilize a deep learning model for automatic detection of abnormalities in chest CT images from COVID-19 patients and compare its quantitative determination performance with radiological residents.
METHODS: A deep learning algorithm consisted of lesion detection, segmentation, and location was trained and validated in 14,435 participants with chest CT images and definite pathogen diagnosis. The algorithm was tested in a non-overlapping dataset of 96 confirmed COVID-19 patients in three hospitals across China during the outbreak. Quantitative detection performance of the model was compared with three radiological residents with two experienced radiologists' reading reports as reference standard by assessing the accuracy, sensitivity, specificity, and F1 score.
RESULTS: Of 96 patients, 88 had pneumonia lesions on CT images and 8 had no abnormities on CT images. For per-patient basis, the algorithm showed superior sensitivity of 1.00 (95% confidence interval (CI) 0.95, 1.00) and F1 score of 0.97 in detecting lesions from CT images of COVID-19 pneumonia patients. While for per-lung lobe basis, the algorithm achieved a sensitivity of 0.96 (95% CI 0.94, 0.98) and a slightly inferior F1 score of 0.86. The median volume of lesions calculated by algorithm was 40.10 cm3. An average running speed of 20.3 s ± 5.8 per case demonstrated the algorithm was much faster than the residents in assessing CT images (all p &lt; 0.017). The deep learning algorithm can also assist radiologists make quicker diagnosis (all p &lt; 0.0001) with superior diagnostic performance.
CONCLUSIONS: The algorithm showed excellent performance in detecting COVID-19 pneumonia on chest CT images compared with resident radiologists.
KEY POINTS: • The higher sensitivity of deep learning model in detecting COVID-19 pneumonia were found compared with radiological residents on a per-lobe and per-patient basis. • The deep learning model improves diagnosis efficiency by shortening processing time. • The deep learning model can automatically calculate the volume of the lesions and whole lung.",1,1
39152187,A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection,"Abade A, Porto LF, Scholze AR, Kuntath D, Barros NDS, Berra TZ, Ramos ACV, Arcêncio RA, Alves JD.",Sci Rep. 2024 Aug 16;14(1):18991. doi: 10.1038/s41598-024-69580-4.,Abade A,Sci Rep,2024,16-08-2024,PMC11329657,,10.1038/s41598-024-69580-4,"TB/HIV coinfection poses a complex public health challenge. Accurate forecasting of future trends is essential for efficient resource allocation and intervention strategy development. This study compares classical statistical and machine learning models to predict TB/HIV coinfection cases stratified by gender and the general populations. We analyzed time series data using exponential smoothing and ARIMA to establish the baseline trend and seasonality. Subsequently, machine learning models (SVR, XGBoost, LSTM, CNN, GRU, CNN-GRU, and CNN-LSTM) were employed to capture the complex dynamics and inherent non-linearities of TB/HIV coinfection data. Performance metrics (MSE, MAE, sMAPE) and the Diebold-Mariano test were used to evaluate the model performance. Results revealed that Deep Learning models, particularly Bidirectional LSTM and CNN-LSTM, significantly outperformed classical methods. This demonstrates the effectiveness of Deep Learning for modeling TB/HIV coinfection time series and generating more accurate forecasts.","A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection TB/HIV coinfection poses a complex public health challenge. Accurate forecasting of future trends is essential for efficient resource allocation and intervention strategy development. This study compares classical statistical and machine learning models to predict TB/HIV coinfection cases stratified by gender and the general populations. We analyzed time series data using exponential smoothing and ARIMA to establish the baseline trend and seasonality. Subsequently, machine learning models (SVR, XGBoost, LSTM, CNN, GRU, CNN-GRU, and CNN-LSTM) were employed to capture the complex dynamics and inherent non-linearities of TB/HIV coinfection data. Performance metrics (MSE, MAE, sMAPE) and the Diebold-Mariano test were used to evaluate the model performance. Results revealed that Deep Learning models, particularly Bidirectional LSTM and CNN-LSTM, significantly outperformed classical methods. This demonstrates the effectiveness of Deep Learning for modeling TB/HIV coinfection time series and generating more accurate forecasts.",1,1
34302549,"Application of Big Data and Artificial Intelligence in COVID-19 Prevention, Diagnosis, Treatment and Management Decisions in China","Dong J, Wu H, Zhou D, Li K, Zhang Y, Ji H, Tong Z, Lou S, Liu Z.",J Med Syst. 2021 Jul 24;45(9):84. doi: 10.1007/s10916-021-01757-0.,Dong J,J Med Syst,2021,24-07-2021,PMC8308073,,10.1007/s10916-021-01757-0,"COVID-19, caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), spread rapidly and affected most of the world since its outbreak in Wuhan, China, which presents a major challenge to the emergency response mechanism for sudden public health events and epidemic prevention and control in all countries. In the face of the severe situation of epidemic prevention and control and the arduous task of social management, the tremendous power of science and technology in prevention and control has emerged. The new generation of information technology, represented by big data and artificial intelligence (AI) technology, has been widely used in the prevention, diagnosis, treatment and management of COVID-19 as an important basic support. Although the technology has developed, there are still challenges with respect to epidemic surveillance, accurate prevention and control, effective diagnosis and treatment, and timely judgement. The prevention and control of sudden infectious diseases usually depend on the control of infection sources, interruption of transmission channels and vaccine development. Big data and AI are effective technologies to identify the source of infection and have an irreplaceable role in distinguishing close contacts and suspicious populations. Advanced computational analysis is beneficial to accelerate the speed of vaccine research and development and to improve the quality of vaccines. AI provides support in automatically processing relevant data from medical images and clinical features, tests and examination findings; predicting disease progression and prognosis; and even recommending treatment plans and strategies. This paper reviews the application of big data and AI in the COVID-19 prevention, diagnosis, treatment and management decisions in China to explain how to apply big data and AI technology to address the common problems in the COVID-19 pandemic. Although the findings regarding the application of big data and AI technologies in sudden public health events lack validation of repeatability and universality, current studies in China have shown that the application of big data and AI is feasible in response to the COVID-19 pandemic. These studies concluded that the application of big data and AI technology can contribute to prevention, diagnosis, treatment and management decision making regarding sudden public health events in the future.","Application of Big Data and Artificial Intelligence in COVID-19 Prevention, Diagnosis, Treatment and Management Decisions in China COVID-19, caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), spread rapidly and affected most of the world since its outbreak in Wuhan, China, which presents a major challenge to the emergency response mechanism for sudden public health events and epidemic prevention and control in all countries. In the face of the severe situation of epidemic prevention and control and the arduous task of social management, the tremendous power of science and technology in prevention and control has emerged. The new generation of information technology, represented by big data and artificial intelligence (AI) technology, has been widely used in the prevention, diagnosis, treatment and management of COVID-19 as an important basic support. Although the technology has developed, there are still challenges with respect to epidemic surveillance, accurate prevention and control, effective diagnosis and treatment, and timely judgement. The prevention and control of sudden infectious diseases usually depend on the control of infection sources, interruption of transmission channels and vaccine development. Big data and AI are effective technologies to identify the source of infection and have an irreplaceable role in distinguishing close contacts and suspicious populations. Advanced computational analysis is beneficial to accelerate the speed of vaccine research and development and to improve the quality of vaccines. AI provides support in automatically processing relevant data from medical images and clinical features, tests and examination findings; predicting disease progression and prognosis; and even recommending treatment plans and strategies. This paper reviews the application of big data and AI in the COVID-19 prevention, diagnosis, treatment and management decisions in China to explain how to apply big data and AI technology to address the common problems in the COVID-19 pandemic. Although the findings regarding the application of big data and AI technologies in sudden public health events lack validation of repeatability and universality, current studies in China have shown that the application of big data and AI is feasible in response to the COVID-19 pandemic. These studies concluded that the application of big data and AI technology can contribute to prevention, diagnosis, treatment and management decision making regarding sudden public health events in the future.",0,1
35144240,Artificial Intelligence-Enabled Social Media Analysis for Pharmacovigilance of COVID-19 Vaccinations in the United Kingdom: Observational Study,"Hussain Z, Sheikh Z, Tahir A, Dashtipour K, Gogate M, Sheikh A, Hussain A.",JMIR Public Health Surveill. 2022 May 27;8(5):e32543. doi: 10.2196/32543.,Hussain Z,JMIR Public Health Surveill,2022,10-02-2022,PMC9150729,,10.2196/32543,"BACKGROUND: The rollout of vaccines for COVID-19 in the United Kingdom started in December 2020. Uptake has been high, and there has been a subsequent reduction in infections, hospitalizations, and deaths among vaccinated individuals. However, vaccine hesitancy remains a concern, in particular relating to adverse effects following immunization (AEFIs). Social media analysis has the potential to inform policy makers about AEFIs being discussed by the public as well as public attitudes toward the national immunization campaign.
OBJECTIVE: We sought to assess the frequency and nature of AEFI-related mentions on social media in the United Kingdom and to provide insights on public sentiments toward COVID-19 vaccines.
METHODS: We extracted and analyzed over 121,406 relevant Twitter and Facebook posts, from December 8, 2020, to April 30, 2021. These were thematically filtered using a 2-step approach, initially using COVID-19-related keywords and then using vaccine- and manufacturer-related keywords. We identified AEFI-related keywords and modeled their word frequency to monitor their trends over 2-week periods. We also adapted and utilized our recently developed hybrid ensemble model, which combines state-of-the-art lexicon rule-based and deep learning-based approaches, to analyze sentiment trends relating to the main vaccines available in the United Kingdom.
RESULTS: Our COVID-19 AEFI search strategy identified 46,762 unique Facebook posts by 14,346 users and 74,644 tweets (excluding retweets) by 36,446 users over the 4-month period. We identified an increasing trend in the number of mentions for each AEFI on social media over the study period. The most frequent AEFI mentions were found to be symptoms related to appetite (n=79,132, 14%), allergy (n=53,924, 9%), injection site (n=56,152, 10%), and clots (n=43,907, 8%). We also found some rarely reported AEFIs such as Bell palsy (n=11,909, 2%) and Guillain-Barre syndrome (n=9576, 2%) being discussed as frequently as more well-known side effects like headache (n=10,641, 2%), fever (n=12,707, 2%), and diarrhea (n=16,559, 3%). Overall, we found public sentiment toward vaccines and their manufacturers to be largely positive (58%), with a near equal split between negative (22%) and neutral (19%) sentiments. The sentiment trend was relatively steady over time and had minor variations, likely based on political and regulatory announcements and debates.
CONCLUSIONS: The most frequently discussed COVID-19 AEFIs on social media were found to be broadly consistent with those reported in the literature and by government pharmacovigilance. We also detected potential safety signals from our analysis that have been detected elsewhere and are currently being investigated. As such, we believe our findings support the use of social media analysis to provide a complementary data source to conventional knowledge sources being used for pharmacovigilance purposes.","Artificial Intelligence-Enabled Social Media Analysis for Pharmacovigilance of COVID-19 Vaccinations in the United Kingdom: Observational Study BACKGROUND: The rollout of vaccines for COVID-19 in the United Kingdom started in December 2020. Uptake has been high, and there has been a subsequent reduction in infections, hospitalizations, and deaths among vaccinated individuals. However, vaccine hesitancy remains a concern, in particular relating to adverse effects following immunization (AEFIs). Social media analysis has the potential to inform policy makers about AEFIs being discussed by the public as well as public attitudes toward the national immunization campaign.
OBJECTIVE: We sought to assess the frequency and nature of AEFI-related mentions on social media in the United Kingdom and to provide insights on public sentiments toward COVID-19 vaccines.
METHODS: We extracted and analyzed over 121,406 relevant Twitter and Facebook posts, from December 8, 2020, to April 30, 2021. These were thematically filtered using a 2-step approach, initially using COVID-19-related keywords and then using vaccine- and manufacturer-related keywords. We identified AEFI-related keywords and modeled their word frequency to monitor their trends over 2-week periods. We also adapted and utilized our recently developed hybrid ensemble model, which combines state-of-the-art lexicon rule-based and deep learning-based approaches, to analyze sentiment trends relating to the main vaccines available in the United Kingdom.
RESULTS: Our COVID-19 AEFI search strategy identified 46,762 unique Facebook posts by 14,346 users and 74,644 tweets (excluding retweets) by 36,446 users over the 4-month period. We identified an increasing trend in the number of mentions for each AEFI on social media over the study period. The most frequent AEFI mentions were found to be symptoms related to appetite (n=79,132, 14%), allergy (n=53,924, 9%), injection site (n=56,152, 10%), and clots (n=43,907, 8%). We also found some rarely reported AEFIs such as Bell palsy (n=11,909, 2%) and Guillain-Barre syndrome (n=9576, 2%) being discussed as frequently as more well-known side effects like headache (n=10,641, 2%), fever (n=12,707, 2%), and diarrhea (n=16,559, 3%). Overall, we found public sentiment toward vaccines and their manufacturers to be largely positive (58%), with a near equal split between negative (22%) and neutral (19%) sentiments. The sentiment trend was relatively steady over time and had minor variations, likely based on political and regulatory announcements and debates.
CONCLUSIONS: The most frequently discussed COVID-19 AEFIs on social media were found to be broadly consistent with those reported in the literature and by government pharmacovigilance. We also detected potential safety signals from our analysis that have been detected elsewhere and are currently being investigated. As such, we believe our findings support the use of social media analysis to provide a complementary data source to conventional knowledge sources being used for pharmacovigilance purposes.",1,1
33905341,A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study,"Wang S, Dong D, Li L, Li H, Bai Y, Hu Y, Huang Y, Yu X, Liu S, Qiu X, Lu L, Wang M, Zha Y, Tian J.",IEEE J Biomed Health Inform. 2021 Jul;25(7):2353-2362. doi: 10.1109/JBHI.2021.3076086. Epub 2021 Jul 27.,Wang S,IEEE J Biomed Health Inform,2021,27-04-2021,PMC8545077,,10.1109/JBHI.2021.3076086,"OBJECTIVE: Coronavirus disease 2019 (COVID-19) has caused considerable morbidity and mortality, especially in patients with underlying health conditions. A precise prognostic tool to identify poor outcomes among such cases is desperately needed.
METHODS: Total 400 COVID-19 patients with underlying health conditions were retrospectively recruited from 4 centers, including 54 dead cases (labeled as poor outcomes) and 346 patients discharged or hospitalized for at least 7 days since initial CT scan. Patients were allocated to a training set (n = 271), a test set (n = 68), and an external test set (n = 61). We proposed an initial CT-derived hybrid model by combining a 3D-ResNet10 based deep learning model and a quantitative 3D radiomics model to predict the probability of COVID-19 patients reaching poor outcome. The model performance was assessed by area under the receiver operating characteristic curve (AUC), survival analysis, and subgroup analysis.
RESULTS: The hybrid model achieved AUCs of 0.876 (95% confidence interval: 0.752-0.999) and 0.864 (0.766-0.962) in test and external test sets, outperforming other models. The survival analysis verified the hybrid model as a significant risk factor for mortality (hazard ratio, 2.049 [1.462-2.871], P < 0.001) that could well stratify patients into high-risk and low-risk of reaching poor outcomes (P < 0.001).
CONCLUSION: The hybrid model that combined deep learning and radiomics could accurately identify poor outcomes in COVID-19 patients with underlying health conditions from initial CT scans. The great risk stratification ability could help alert risk of death and allow for timely surveillance plans.","A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study OBJECTIVE: Coronavirus disease 2019 (COVID-19) has caused considerable morbidity and mortality, especially in patients with underlying health conditions. A precise prognostic tool to identify poor outcomes among such cases is desperately needed.
METHODS: Total 400 COVID-19 patients with underlying health conditions were retrospectively recruited from 4 centers, including 54 dead cases (labeled as poor outcomes) and 346 patients discharged or hospitalized for at least 7 days since initial CT scan. Patients were allocated to a training set (n = 271), a test set (n = 68), and an external test set (n = 61). We proposed an initial CT-derived hybrid model by combining a 3D-ResNet10 based deep learning model and a quantitative 3D radiomics model to predict the probability of COVID-19 patients reaching poor outcome. The model performance was assessed by area under the receiver operating characteristic curve (AUC), survival analysis, and subgroup analysis.
RESULTS: The hybrid model achieved AUCs of 0.876 (95% confidence interval: 0.752-0.999) and 0.864 (0.766-0.962) in test and external test sets, outperforming other models. The survival analysis verified the hybrid model as a significant risk factor for mortality (hazard ratio, 2.049 [1.462-2.871], P < 0.001) that could well stratify patients into high-risk and low-risk of reaching poor outcomes (P < 0.001).
CONCLUSION: The hybrid model that combined deep learning and radiomics could accurately identify poor outcomes in COVID-19 patients with underlying health conditions from initial CT scans. The great risk stratification ability could help alert risk of death and allow for timely surveillance plans.",0,1
33236007,AI-Driven Multiscale Simulations Illuminate Mechanisms of SARS-CoV-2 Spike Dynamics,"Casalino L, Dommer A, Gaieb Z, Barros EP, Sztain T, Ahn SH, Trifan A, Brace A, Bogetti A, Ma H, Lee H, Turilli M, Khalid S, Chong L, Simmerling C, Hardy DJ, Maia JDC, Phillips JC, Kurth T, Stern A, Huang L, McCalpin J, Tatineni M, Gibbs T, Stone JE, Jha S, Ramanathan A, Amaro RE.",bioRxiv [Preprint]. 2020 Nov 20:2020.11.19.390187. doi: 10.1101/2020.11.19.390187.,Casalino L,bioRxiv,2020,25-11-2020,PMC7685317,,10.1101/2020.11.19.390187,"We develop a generalizable AI-driven workflow that leverages heterogeneous HPC resources to explore the time-dependent dynamics of molecular systems. We use this workflow to investigate the mechanisms of infectivity of the SARS-CoV-2 spike protein, the main viral infection machinery. Our workflow enables more efficient investigation of spike dynamics in a variety of complex environments, including within a complete SARS-CoV-2 viral envelope simulation, which contains 305 million atoms and shows strong scaling on ORNL Summit using NAMD. We present several novel scientific discoveries, including the elucidation of the spike's full glycan shield, the role of spike glycans in modulating the infectivity of the virus, and the characterization of the flexible interactions between the spike and the human ACE2 receptor. We also demonstrate how AI can accelerate conformational sampling across different systems and pave the way for the future application of such methods to additional studies in SARS-CoV-2 and other molecular systems.","AI-Driven Multiscale Simulations Illuminate Mechanisms of SARS-CoV-2 Spike Dynamics We develop a generalizable AI-driven workflow that leverages heterogeneous HPC resources to explore the time-dependent dynamics of molecular systems. We use this workflow to investigate the mechanisms of infectivity of the SARS-CoV-2 spike protein, the main viral infection machinery. Our workflow enables more efficient investigation of spike dynamics in a variety of complex environments, including within a complete SARS-CoV-2 viral envelope simulation, which contains 305 million atoms and shows strong scaling on ORNL Summit using NAMD. We present several novel scientific discoveries, including the elucidation of the spike's full glycan shield, the role of spike glycans in modulating the infectivity of the virus, and the characterization of the flexible interactions between the spike and the human ACE2 receptor. We also demonstrate how AI can accelerate conformational sampling across different systems and pave the way for the future application of such methods to additional studies in SARS-CoV-2 and other molecular systems.",0,1
32353457,COVID-19 pandemic and personal protective equipment shortage: protective efficacy comparing masks and scientific methods for respirator reuse,"Boškoski I, Gallo C, Wallace MB, Costamagna G.",Gastrointest Endosc. 2020 Sep;92(3):519-523. doi: 10.1016/j.gie.2020.04.048. Epub 2020 Apr 27.,Boškoski I,Gastrointest Endosc,2020,01-05-2020,PMC7184993,,10.1016/j.gie.2020.04.048,"BACKGROUND AND AIMS: The abrupt outbreak of the novel coronavirus disease 2019 and its rapid spread over many healthcare systems throughout the world has led to a shortage in personal protective equipment (PPE), which cannot be solved by reducing their use or by increasing production. It is thus necessary to promote PPE rational use, highlighting possible differences in terms of efficacy and promoting an effective technique to reuse them.
METHODS: A literature search was performed on PubMed, Scopus, Cochrane database, and Google Scholar, and from the 25 top cited articles, 15 were selected for relevance and impact.
RESULTS: Most studies on previous respiratory virus epidemics to date suggest surgical masks are not inferior compared with N95 respirators in terms of protective efficacy among healthcare workers. Therefore, the use of N95 respirators should be limited to high-risk situations. Concerning respirator reuse, highly energetic, short-wave, ultraviolet germicidal irradiation (UVGI) at 254 nm was determined to decontaminate N95 respirators from viral respiratory agents, but UVGI requires careful consideration of the type of respirator and of the biologic target.
CONCLUSIONS: Rational use and successful reuse of respirators can help in the shortage of PPE during a pandemic. Further studies testing UVGI and other decontamination techniques are an unmet need. The definitive answer to pandemic issues can be found in artificial intelligence and deep learning. These groundbreaking modalities could help in identifying high-risk patients and in suggesting appropriate types and use of PPE.","COVID-19 pandemic and personal protective equipment shortage: protective efficacy comparing masks and scientific methods for respirator reuse BACKGROUND AND AIMS: The abrupt outbreak of the novel coronavirus disease 2019 and its rapid spread over many healthcare systems throughout the world has led to a shortage in personal protective equipment (PPE), which cannot be solved by reducing their use or by increasing production. It is thus necessary to promote PPE rational use, highlighting possible differences in terms of efficacy and promoting an effective technique to reuse them.
METHODS: A literature search was performed on PubMed, Scopus, Cochrane database, and Google Scholar, and from the 25 top cited articles, 15 were selected for relevance and impact.
RESULTS: Most studies on previous respiratory virus epidemics to date suggest surgical masks are not inferior compared with N95 respirators in terms of protective efficacy among healthcare workers. Therefore, the use of N95 respirators should be limited to high-risk situations. Concerning respirator reuse, highly energetic, short-wave, ultraviolet germicidal irradiation (UVGI) at 254 nm was determined to decontaminate N95 respirators from viral respiratory agents, but UVGI requires careful consideration of the type of respirator and of the biologic target.
CONCLUSIONS: Rational use and successful reuse of respirators can help in the shortage of PPE during a pandemic. Further studies testing UVGI and other decontamination techniques are an unmet need. The definitive answer to pandemic issues can be found in artificial intelligence and deep learning. These groundbreaking modalities could help in identifying high-risk patients and in suggesting appropriate types and use of PPE.",0,0
33170848,Comparing machine learning with case-control models to identify confirmed dengue cases,"Ho TS, Weng TC, Wang JD, Han HC, Cheng HC, Yang CC, Yu CH, Liu YJ, Hu CH, Huang CY, Chen MH, King CC, Oyang YJ, Liu CC.",PLoS Negl Trop Dis. 2020 Nov 10;14(11):e0008843. doi: 10.1371/journal.pntd.0008843. eCollection 2020 Nov.,Ho TS,PLoS Negl Trop Dis,2020,10-11-2020,PMC7654779,,10.1371/journal.pntd.0008843,"In recent decades, the global incidence of dengue has increased. Affected countries have responded with more effective surveillance strategies to detect outbreaks early, monitor the trends, and implement prevention and control measures. We have applied newly developed machine learning approaches to identify laboratory-confirmed dengue cases from 4,894 emergency department patients with dengue-like illness (DLI) who received laboratory tests. Among them, 60.11% (2942 cases) were confirmed to have dengue. Using just four input variables [age, body temperature, white blood cells counts (WBCs) and platelets], not only the state-of-the-art deep neural network (DNN) prediction models but also the conventional decision tree (DT) and logistic regression (LR) models delivered performances with receiver operating characteristic (ROC) curves areas under curves (AUCs) of the ranging from 83.75% to 85.87% [for DT, DNN and LR: 84.60% ± 0.03%, 85.87% ± 0.54%, 83.75% ± 0.17%, respectively]. Subgroup analyses found all the models were very sensitive particularly in the pre-epidemic period. Pre-peak sensitivities (<35 weeks) were 92.6%, 92.9%, and 93.1% in DT, DNN, and LR respectively. Adjusted odds ratios examined with LR for low WBCs [≤ 3.2 (x103/μL)], fever (≥38°C), low platelet counts [< 100 (x103/μL)], and elderly (≥ 65 years) were 5.17 [95% confidence interval (CI): 3.96-6.76], 3.17 [95%CI: 2.74-3.66], 3.10 [95%CI: 2.44-3.94], and 1.77 [95%CI: 1.50-2.10], respectively. Our prediction models can readily be used in resource-poor countries where viral/serologic tests are inconvenient and can also be applied for real-time syndromic surveillance to monitor trends of dengue cases and even be integrated with mosquito/environment surveillance for early warning and immediate prevention/control measures. In other words, a local community hospital/clinic with an instrument of complete blood counts (including platelets) can provide a sentinel screening during outbreaks. In conclusion, the machine learning approach can facilitate medical and public health efforts to minimize the health threat of dengue epidemics. However, laboratory confirmation remains the primary goal of surveillance and outbreak investigation.","Comparing machine learning with case-control models to identify confirmed dengue cases In recent decades, the global incidence of dengue has increased. Affected countries have responded with more effective surveillance strategies to detect outbreaks early, monitor the trends, and implement prevention and control measures. We have applied newly developed machine learning approaches to identify laboratory-confirmed dengue cases from 4,894 emergency department patients with dengue-like illness (DLI) who received laboratory tests. Among them, 60.11% (2942 cases) were confirmed to have dengue. Using just four input variables [age, body temperature, white blood cells counts (WBCs) and platelets], not only the state-of-the-art deep neural network (DNN) prediction models but also the conventional decision tree (DT) and logistic regression (LR) models delivered performances with receiver operating characteristic (ROC) curves areas under curves (AUCs) of the ranging from 83.75% to 85.87% [for DT, DNN and LR: 84.60% ± 0.03%, 85.87% ± 0.54%, 83.75% ± 0.17%, respectively]. Subgroup analyses found all the models were very sensitive particularly in the pre-epidemic period. Pre-peak sensitivities (<35 weeks) were 92.6%, 92.9%, and 93.1% in DT, DNN, and LR respectively. Adjusted odds ratios examined with LR for low WBCs [≤ 3.2 (x103/μL)], fever (≥38°C), low platelet counts [< 100 (x103/μL)], and elderly (≥ 65 years) were 5.17 [95% confidence interval (CI): 3.96-6.76], 3.17 [95%CI: 2.74-3.66], 3.10 [95%CI: 2.44-3.94], and 1.77 [95%CI: 1.50-2.10], respectively. Our prediction models can readily be used in resource-poor countries where viral/serologic tests are inconvenient and can also be applied for real-time syndromic surveillance to monitor trends of dengue cases and even be integrated with mosquito/environment surveillance for early warning and immediate prevention/control measures. In other words, a local community hospital/clinic with an instrument of complete blood counts (including platelets) can provide a sentinel screening during outbreaks. In conclusion, the machine learning approach can facilitate medical and public health efforts to minimize the health threat of dengue epidemics. However, laboratory confirmation remains the primary goal of surveillance and outbreak investigation.",0,1
34679127,Stratifying the early radiologic trajectory in dyspneic patients with COVID-19 pneumonia,"Kim JY, Jung KJ, Yoo SJ, Yoon SH.",PLoS One. 2021 Oct 22;16(10):e0259010. doi: 10.1371/journal.pone.0259010. eCollection 2021.,Kim JY,PLoS One,2021,22-10-2021,PMC8535425,,10.1371/journal.pone.0259010,"OBJECTIVE: This study aimed to stratify the early pneumonia trajectory on chest radiographs and compare patient characteristics in dyspneic patients with coronavirus disease 2019 (COVID-19).
MATERIALS AND METHODS: We retrospectively included 139 COVID-19 patients with dyspnea (87 men, 62.7±16.3 years) and serial chest radiographs from January to September 2020. Radiographic pneumonia extent was quantified as a percentage using a previously-developed deep learning algorithm. A group-based trajectory model was used to categorize the pneumonia trajectory after symptom onset during hospitalization. Clinical findings, and outcomes were compared, and Cox regression was performed for survival analysis.
RESULTS: Radiographic pneumonia trajectories were categorized into four groups. Group 1 (n = 83, 59.7%) had negligible pneumonia, and group 2 (n = 29, 20.9%) had mild pneumonia. Group 3 (n = 13, 9.4%) and group 4 (n = 14, 10.1%) showed similar considerable pneumonia extents at baseline, but group 3 had decreasing pneumonia extent at 1-2 weeks, while group 4 had increasing pneumonia extent. Intensive care unit admission and mortality were significantly more frequent in groups 3 and 4 than in groups 1 and 2 (P < .05). Groups 3 and 4 shared similar clinical and laboratory findings, but thrombocytopenia (<150×103/μL) was exclusively observed in group 4 (P = .016). When compared to groups 1 and 2, group 4 (hazard ratio, 63.3; 95% confidence interval, 7.9-504.9) had a two-fold higher risk for mortality than group 3 (hazard ratio, 31.2; 95% confidence interval, 3.5-280.2), and this elevated risk was maintained after adjusting confounders.
CONCLUSION: Monitoring the early radiologic trajectory beyond baseline further prognosticated at-risk COVID-19 patients, who potentially had thrombo-inflammatory responses.","Stratifying the early radiologic trajectory in dyspneic patients with COVID-19 pneumonia OBJECTIVE: This study aimed to stratify the early pneumonia trajectory on chest radiographs and compare patient characteristics in dyspneic patients with coronavirus disease 2019 (COVID-19).
MATERIALS AND METHODS: We retrospectively included 139 COVID-19 patients with dyspnea (87 men, 62.7±16.3 years) and serial chest radiographs from January to September 2020. Radiographic pneumonia extent was quantified as a percentage using a previously-developed deep learning algorithm. A group-based trajectory model was used to categorize the pneumonia trajectory after symptom onset during hospitalization. Clinical findings, and outcomes were compared, and Cox regression was performed for survival analysis.
RESULTS: Radiographic pneumonia trajectories were categorized into four groups. Group 1 (n = 83, 59.7%) had negligible pneumonia, and group 2 (n = 29, 20.9%) had mild pneumonia. Group 3 (n = 13, 9.4%) and group 4 (n = 14, 10.1%) showed similar considerable pneumonia extents at baseline, but group 3 had decreasing pneumonia extent at 1-2 weeks, while group 4 had increasing pneumonia extent. Intensive care unit admission and mortality were significantly more frequent in groups 3 and 4 than in groups 1 and 2 (P < .05). Groups 3 and 4 shared similar clinical and laboratory findings, but thrombocytopenia (<150×103/μL) was exclusively observed in group 4 (P = .016). When compared to groups 1 and 2, group 4 (hazard ratio, 63.3; 95% confidence interval, 7.9-504.9) had a two-fold higher risk for mortality than group 3 (hazard ratio, 31.2; 95% confidence interval, 3.5-280.2), and this elevated risk was maintained after adjusting confounders.
CONCLUSION: Monitoring the early radiologic trajectory beyond baseline further prognosticated at-risk COVID-19 patients, who potentially had thrombo-inflammatory responses.",1,0
34097708,COVID-19 pneumonia on chest X-rays: Performance of a deep learning-based computer-aided detection system,"Hwang EJ, Kim KB, Kim JY, Lim JK, Nam JG, Choi H, Kim H, Yoon SH, Goo JM, Park CM.",PLoS One. 2021 Jun 7;16(6):e0252440. doi: 10.1371/journal.pone.0252440. eCollection 2021.,Hwang EJ,PLoS One,2021,07-06-2021,PMC8184006,,10.1371/journal.pone.0252440,"Chest X-rays (CXRs) can help triage for Coronavirus disease (COVID-19) patients in resource-constrained environments, and a computer-aided detection system (CAD) that can identify pneumonia on CXR may help the triage of patients in those environment where expert radiologists are not available. However, the performance of existing CAD for identifying COVID-19 and associated pneumonia on CXRs has been scarcely investigated. In this study, CXRs of patients with and without COVID-19 confirmed by reverse transcriptase polymerase chain reaction (RT-PCR) were retrospectively collected from four and one institution, respectively, and a commercialized, regulatory-approved CAD that can identify various abnormalities including pneumonia was used to analyze each CXR. Performance of the CAD was evaluated using area under the receiver operating characteristic curves (AUCs), with reference standards of the RT-PCR results and the presence of findings of pneumonia on chest CTs obtained within 24 hours from the CXR. For comparison, 5 thoracic radiologists and 5 non-radiologist physicians independently interpreted the CXRs. Afterward, they re-interpreted the CXRs with corresponding CAD results. The performance of CAD (AUCs, 0.714 and 0.790 against RT-PCR and chest CT, respectively hereinafter) were similar with those of thoracic radiologists (AUCs, 0.701 and 0.784), and higher than those of non-radiologist physicians (AUCs, 0.584 and 0.650). Non-radiologist physicians showed significantly improved performance when assisted with the CAD (AUCs, 0.584 to 0.664 and 0.650 to 0.738). In addition, inter-reader agreement among physicians was also improved in the CAD-assisted interpretation (Fleiss' kappa coefficient, 0.209 to 0.322). In conclusion, radiologist-level performance of the CAD in identifying COVID-19 and associated pneumonia on CXR and enhanced performance of non-radiologist physicians with the CAD assistance suggest that the CAD can support physicians in interpreting CXRs and helping image-based triage of COVID-19 patients in resource-constrained environment.","COVID-19 pneumonia on chest X-rays: Performance of a deep learning-based computer-aided detection system Chest X-rays (CXRs) can help triage for Coronavirus disease (COVID-19) patients in resource-constrained environments, and a computer-aided detection system (CAD) that can identify pneumonia on CXR may help the triage of patients in those environment where expert radiologists are not available. However, the performance of existing CAD for identifying COVID-19 and associated pneumonia on CXRs has been scarcely investigated. In this study, CXRs of patients with and without COVID-19 confirmed by reverse transcriptase polymerase chain reaction (RT-PCR) were retrospectively collected from four and one institution, respectively, and a commercialized, regulatory-approved CAD that can identify various abnormalities including pneumonia was used to analyze each CXR. Performance of the CAD was evaluated using area under the receiver operating characteristic curves (AUCs), with reference standards of the RT-PCR results and the presence of findings of pneumonia on chest CTs obtained within 24 hours from the CXR. For comparison, 5 thoracic radiologists and 5 non-radiologist physicians independently interpreted the CXRs. Afterward, they re-interpreted the CXRs with corresponding CAD results. The performance of CAD (AUCs, 0.714 and 0.790 against RT-PCR and chest CT, respectively hereinafter) were similar with those of thoracic radiologists (AUCs, 0.701 and 0.784), and higher than those of non-radiologist physicians (AUCs, 0.584 and 0.650). Non-radiologist physicians showed significantly improved performance when assisted with the CAD (AUCs, 0.584 to 0.664 and 0.650 to 0.738). In addition, inter-reader agreement among physicians was also improved in the CAD-assisted interpretation (Fleiss' kappa coefficient, 0.209 to 0.322). In conclusion, radiologist-level performance of the CAD in identifying COVID-19 and associated pneumonia on CXR and enhanced performance of non-radiologist physicians with the CAD assistance suggest that the CAD can support physicians in interpreting CXRs and helping image-based triage of COVID-19 patients in resource-constrained environment.",1,1
32735549,Prognostic Modeling of COVID-19 Using Artificial Intelligence in the United Kingdom: Model Development and Validation,"Abdulaal A, Patel A, Charani E, Denny S, Mughal N, Moore L.",J Med Internet Res. 2020 Aug 25;22(8):e20259. doi: 10.2196/20259.,Abdulaal A,J Med Internet Res,2020,01-08-2020,PMC7451108,,10.2196/20259,"BACKGROUND: The current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) outbreak is a public health emergency and the case fatality rate in the United Kingdom is significant. Although there appear to be several early predictors of outcome, there are no currently validated prognostic models or scoring systems applicable specifically to patients with confirmed SARS-CoV-2.
OBJECTIVE: We aim to create a point-of-admission mortality risk scoring system using an artificial neural network (ANN).
METHODS: We present an ANN that can provide a patient-specific, point-of-admission mortality risk prediction to inform clinical management decisions at the earliest opportunity. The ANN analyzes a set of patient features including demographics, comorbidities, smoking history, and presenting symptoms and predicts patient-specific mortality risk during the current hospital admission. The model was trained and validated on data extracted from 398 patients admitted to hospital with a positive real-time reverse transcription polymerase chain reaction (RT-PCR) test for SARS-CoV-2.
RESULTS: Patient-specific mortality was predicted with 86.25% accuracy, with a sensitivity of 87.50% (95% CI 61.65%-98.45%) and specificity of 85.94% (95% CI 74.98%-93.36%). The positive predictive value was 60.87% (95% CI 45.23%-74.56%), and the negative predictive value was 96.49% (95% CI 88.23%-99.02%). The area under the receiver operating characteristic curve was 90.12%.
CONCLUSIONS: This analysis demonstrates an adaptive ANN trained on data at a single site, which demonstrates the early utility of deep learning approaches in a rapidly evolving pandemic with no established or validated prognostic scoring systems.","Prognostic Modeling of COVID-19 Using Artificial Intelligence in the United Kingdom: Model Development and Validation BACKGROUND: The current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) outbreak is a public health emergency and the case fatality rate in the United Kingdom is significant. Although there appear to be several early predictors of outcome, there are no currently validated prognostic models or scoring systems applicable specifically to patients with confirmed SARS-CoV-2.
OBJECTIVE: We aim to create a point-of-admission mortality risk scoring system using an artificial neural network (ANN).
METHODS: We present an ANN that can provide a patient-specific, point-of-admission mortality risk prediction to inform clinical management decisions at the earliest opportunity. The ANN analyzes a set of patient features including demographics, comorbidities, smoking history, and presenting symptoms and predicts patient-specific mortality risk during the current hospital admission. The model was trained and validated on data extracted from 398 patients admitted to hospital with a positive real-time reverse transcription polymerase chain reaction (RT-PCR) test for SARS-CoV-2.
RESULTS: Patient-specific mortality was predicted with 86.25% accuracy, with a sensitivity of 87.50% (95% CI 61.65%-98.45%) and specificity of 85.94% (95% CI 74.98%-93.36%). The positive predictive value was 60.87% (95% CI 45.23%-74.56%), and the negative predictive value was 96.49% (95% CI 88.23%-99.02%). The area under the receiver operating characteristic curve was 90.12%.
CONCLUSIONS: This analysis demonstrates an adaptive ANN trained on data at a single site, which demonstrates the early utility of deep learning approaches in a rapidly evolving pandemic with no established or validated prognostic scoring systems.",1,1
36150046,Emotions and Topics Expressed on Twitter During the COVID-19 Pandemic in the United Kingdom: Comparative Geolocation and Text Mining Analysis,"Alhuzali H, Zhang T, Ananiadou S.",J Med Internet Res. 2022 Oct 5;24(10):e40323. doi: 10.2196/40323.,Alhuzali H,J Med Internet Res,2022,23-09-2022,PMC9536769,,10.2196/40323,"BACKGROUND: In recent years, the COVID-19 pandemic has brought great changes to public health, society, and the economy. Social media provide a platform for people to discuss health concerns, living conditions, and policies during the epidemic, allowing policymakers to use this content to analyze the public emotions and attitudes for decision-making.
OBJECTIVE: The aim of this study was to use deep learning-based methods to understand public emotions on topics related to the COVID-19 pandemic in the United Kingdom through a comparative geolocation and text mining analysis on Twitter.
METHODS: Over 500,000 tweets related to COVID-19 from 48 different cities in the United Kingdom were extracted, with the data covering the period of the last 2 years (from February 2020 to November 2021). We leveraged three advanced deep learning-based models for topic modeling to geospatially analyze the sentiment, emotion, and topics of tweets in the United Kingdom: SenticNet 6 for sentiment analysis, SpanEmo for emotion recognition, and combined topic modeling (CTM).
RESULTS: We observed a significant change in the number of tweets as the epidemiological situation and vaccination situation shifted over the 2 years. There was a sharp increase in the number of tweets from January 2020 to February 2020 due to the outbreak of COVID-19 in the United Kingdom. Then, the number of tweets gradually declined as of February 2020. Moreover, with identification of the COVID-19 Omicron variant in the United Kingdom in November 2021, the number of tweets grew again. Our findings reveal people's attitudes and emotions toward topics related to COVID-19. For sentiment, approximately 60% of tweets were positive, 20% were neutral, and 20% were negative. For emotion, people tended to express highly positive emotions in the beginning of 2020, while expressing highly negative emotions over time toward the end of 2021. The topics also changed during the pandemic.
CONCLUSIONS: Through large-scale text mining of Twitter, our study found meaningful differences in public emotions and topics regarding the COVID-19 pandemic among different UK cities. Furthermore, efficient location-based and time-based comparative analysis can be used to track people's thoughts and feelings, and to understand their behaviors. Based on our analysis, positive attitudes were common during the pandemic; optimism and anticipation were the dominant emotions. With the outbreak and epidemiological change, the government developed control measures and vaccination policies, and the topics also shifted over time. Overall, the proportion and expressions of emojis, sentiments, emotions, and topics varied geographically and temporally. Therefore, our approach of exploring public emotions and topics on the pandemic from Twitter can potentially lead to informing how public policies are received in a particular geographical area.","Emotions and Topics Expressed on Twitter During the COVID-19 Pandemic in the United Kingdom: Comparative Geolocation and Text Mining Analysis BACKGROUND: In recent years, the COVID-19 pandemic has brought great changes to public health, society, and the economy. Social media provide a platform for people to discuss health concerns, living conditions, and policies during the epidemic, allowing policymakers to use this content to analyze the public emotions and attitudes for decision-making.
OBJECTIVE: The aim of this study was to use deep learning-based methods to understand public emotions on topics related to the COVID-19 pandemic in the United Kingdom through a comparative geolocation and text mining analysis on Twitter.
METHODS: Over 500,000 tweets related to COVID-19 from 48 different cities in the United Kingdom were extracted, with the data covering the period of the last 2 years (from February 2020 to November 2021). We leveraged three advanced deep learning-based models for topic modeling to geospatially analyze the sentiment, emotion, and topics of tweets in the United Kingdom: SenticNet 6 for sentiment analysis, SpanEmo for emotion recognition, and combined topic modeling (CTM).
RESULTS: We observed a significant change in the number of tweets as the epidemiological situation and vaccination situation shifted over the 2 years. There was a sharp increase in the number of tweets from January 2020 to February 2020 due to the outbreak of COVID-19 in the United Kingdom. Then, the number of tweets gradually declined as of February 2020. Moreover, with identification of the COVID-19 Omicron variant in the United Kingdom in November 2021, the number of tweets grew again. Our findings reveal people's attitudes and emotions toward topics related to COVID-19. For sentiment, approximately 60% of tweets were positive, 20% were neutral, and 20% were negative. For emotion, people tended to express highly positive emotions in the beginning of 2020, while expressing highly negative emotions over time toward the end of 2021. The topics also changed during the pandemic.
CONCLUSIONS: Through large-scale text mining of Twitter, our study found meaningful differences in public emotions and topics regarding the COVID-19 pandemic among different UK cities. Furthermore, efficient location-based and time-based comparative analysis can be used to track people's thoughts and feelings, and to understand their behaviors. Based on our analysis, positive attitudes were common during the pandemic; optimism and anticipation were the dominant emotions. With the outbreak and epidemiological change, the government developed control measures and vaccination policies, and the topics also shifted over time. Overall, the proportion and expressions of emojis, sentiments, emotions, and topics varied geographically and temporally. Therefore, our approach of exploring public emotions and topics on the pandemic from Twitter can potentially lead to informing how public policies are received in a particular geographical area.",1,0
38308256,Susceptibility of AutoML mortality prediction algorithms to model drift caused by the COVID pandemic,"Kagerbauer SM, Ulm B, Podtschaske AH, Andonov DI, Blobner M, Jungwirth B, Graessner M.",BMC Med Inform Decis Mak. 2024 Feb 2;24(1):34. doi: 10.1186/s12911-024-02428-z.,Kagerbauer SM,BMC Med Inform Decis Mak,2024,02-02-2024,PMC10837894,,10.1186/s12911-024-02428-z,"BACKGROUND: Concept drift and covariate shift lead to a degradation of machine learning (ML) models. The objective of our study was to characterize sudden data drift as caused by the COVID pandemic. Furthermore, we investigated the suitability of certain methods in model training to prevent model degradation caused by data drift.
METHODS: We trained different ML models with the H2O AutoML method on a dataset comprising 102,666 cases of surgical patients collected in the years 2014-2019 to predict postoperative mortality using preoperatively available data. Models applied were Generalized Linear Model with regularization, Default Random Forest, Gradient Boosting Machine, eXtreme Gradient Boosting, Deep Learning and Stacked Ensembles comprising all base models. Further, we modified the original models by applying three different methods when training on the original pre-pandemic dataset: (Rahmani K, et al, Int J Med Inform 173:104930, 2023) we weighted older data weaker, (Morger A, et al, Sci Rep 12:7244, 2022) used only the most recent data for model training and (Dilmegani C, 2023) performed a z-transformation of the numerical input parameters. Afterwards, we tested model performance on a pre-pandemic and an in-pandemic data set not used in the training process, and analysed common features.
RESULTS: The models produced showed excellent areas under receiver-operating characteristic and acceptable precision-recall curves when tested on a dataset from January-March 2020, but significant degradation when tested on a dataset collected in the first wave of the COVID pandemic from April-May 2020. When comparing the probability distributions of the input parameters, significant differences between pre-pandemic and in-pandemic data were found. The endpoint of our models, in-hospital mortality after surgery, did not differ significantly between pre- and in-pandemic data and was about 1% in each case. However, the models varied considerably in the composition of their input parameters. None of our applied modifications prevented a loss of performance, although very different models emerged from it, using a large variety of parameters.
CONCLUSIONS: Our results show that none of our tested easy-to-implement measures in model training can prevent deterioration in the case of sudden external events. Therefore, we conclude that, in the presence of concept drift and covariate shift, close monitoring and critical review of model predictions are necessary.","Susceptibility of AutoML mortality prediction algorithms to model drift caused by the COVID pandemic BACKGROUND: Concept drift and covariate shift lead to a degradation of machine learning (ML) models. The objective of our study was to characterize sudden data drift as caused by the COVID pandemic. Furthermore, we investigated the suitability of certain methods in model training to prevent model degradation caused by data drift.
METHODS: We trained different ML models with the H2O AutoML method on a dataset comprising 102,666 cases of surgical patients collected in the years 2014-2019 to predict postoperative mortality using preoperatively available data. Models applied were Generalized Linear Model with regularization, Default Random Forest, Gradient Boosting Machine, eXtreme Gradient Boosting, Deep Learning and Stacked Ensembles comprising all base models. Further, we modified the original models by applying three different methods when training on the original pre-pandemic dataset: (Rahmani K, et al, Int J Med Inform 173:104930, 2023) we weighted older data weaker, (Morger A, et al, Sci Rep 12:7244, 2022) used only the most recent data for model training and (Dilmegani C, 2023) performed a z-transformation of the numerical input parameters. Afterwards, we tested model performance on a pre-pandemic and an in-pandemic data set not used in the training process, and analysed common features.
RESULTS: The models produced showed excellent areas under receiver-operating characteristic and acceptable precision-recall curves when tested on a dataset from January-March 2020, but significant degradation when tested on a dataset collected in the first wave of the COVID pandemic from April-May 2020. When comparing the probability distributions of the input parameters, significant differences between pre-pandemic and in-pandemic data were found. The endpoint of our models, in-hospital mortality after surgery, did not differ significantly between pre- and in-pandemic data and was about 1% in each case. However, the models varied considerably in the composition of their input parameters. None of our applied modifications prevented a loss of performance, although very different models emerged from it, using a large variety of parameters.
CONCLUSIONS: Our results show that none of our tested easy-to-implement measures in model training can prevent deterioration in the case of sudden external events. Therefore, we conclude that, in the presence of concept drift and covariate shift, close monitoring and critical review of model predictions are necessary.",1,1
38231538,Mobile Apps for COVID-19 Detection and Diagnosis for Future Pandemic Control: Multidimensional Systematic Review,"Gheisari M, Ghaderzadeh M, Li H, Taami T, Fernández-Campusano C, Sadeghsalehi H, Afzaal Abbasi A.",JMIR Mhealth Uhealth. 2024 Feb 22;12:e44406. doi: 10.2196/44406.,Gheisari M,JMIR Mhealth Uhealth,2024,17-01-2024,PMC10896318,,10.2196/44406,"BACKGROUND: In the modern world, mobile apps are essential for human advancement, and pandemic control is no exception. The use of mobile apps and technology for the detection and diagnosis of COVID-19 has been the subject of numerous investigations, although no thorough analysis of COVID-19 pandemic prevention has been conducted using mobile apps, creating a gap.
OBJECTIVE: With the intention of helping software companies and clinical researchers, this study provides comprehensive information regarding the different fields in which mobile apps were used to diagnose COVID-19 during the pandemic.
METHODS: In this systematic review, 535 studies were found after searching 5 major research databases (ScienceDirect, Scopus, PubMed, Web of Science, and IEEE). Of these, only 42 (7.9%) studies concerned with diagnosing and detecting COVID-19 were chosen after applying inclusion and exclusion criteria using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) protocol.
RESULTS: Mobile apps were categorized into 6 areas based on the content of these 42 studies: contact tracing, data gathering, data visualization, artificial intelligence (AI)-based diagnosis, rule- and guideline-based diagnosis, and data transformation. Patients with COVID-19 were identified via mobile apps using a variety of clinical, geographic, demographic, radiological, serological, and laboratory data. Most studies concentrated on using AI methods to identify people who might have COVID-19. Additionally, symptoms, cough sounds, and radiological images were used more frequently compared to other data types. Deep learning techniques, such as convolutional neural networks, performed comparatively better in the processing of health care data than other types of AI techniques, which improved the diagnosis of COVID-19.
CONCLUSIONS: Mobile apps could soon play a significant role as a powerful tool for data collection, epidemic health data analysis, and the early identification of suspected cases. These technologies can work with the internet of things, cloud storage, 5th-generation technology, and cloud computing. Processing pipelines can be moved to mobile device processing cores using new deep learning methods, such as lightweight neural networks. In the event of future pandemics, mobile apps will play a critical role in rapid diagnosis using various image data and clinical symptoms. Consequently, the rapid diagnosis of these diseases can improve the management of their effects and obtain excellent results in treating patients.","Mobile Apps for COVID-19 Detection and Diagnosis for Future Pandemic Control: Multidimensional Systematic Review BACKGROUND: In the modern world, mobile apps are essential for human advancement, and pandemic control is no exception. The use of mobile apps and technology for the detection and diagnosis of COVID-19 has been the subject of numerous investigations, although no thorough analysis of COVID-19 pandemic prevention has been conducted using mobile apps, creating a gap.
OBJECTIVE: With the intention of helping software companies and clinical researchers, this study provides comprehensive information regarding the different fields in which mobile apps were used to diagnose COVID-19 during the pandemic.
METHODS: In this systematic review, 535 studies were found after searching 5 major research databases (ScienceDirect, Scopus, PubMed, Web of Science, and IEEE). Of these, only 42 (7.9%) studies concerned with diagnosing and detecting COVID-19 were chosen after applying inclusion and exclusion criteria using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) protocol.
RESULTS: Mobile apps were categorized into 6 areas based on the content of these 42 studies: contact tracing, data gathering, data visualization, artificial intelligence (AI)-based diagnosis, rule- and guideline-based diagnosis, and data transformation. Patients with COVID-19 were identified via mobile apps using a variety of clinical, geographic, demographic, radiological, serological, and laboratory data. Most studies concentrated on using AI methods to identify people who might have COVID-19. Additionally, symptoms, cough sounds, and radiological images were used more frequently compared to other data types. Deep learning techniques, such as convolutional neural networks, performed comparatively better in the processing of health care data than other types of AI techniques, which improved the diagnosis of COVID-19.
CONCLUSIONS: Mobile apps could soon play a significant role as a powerful tool for data collection, epidemic health data analysis, and the early identification of suspected cases. These technologies can work with the internet of things, cloud storage, 5th-generation technology, and cloud computing. Processing pipelines can be moved to mobile device processing cores using new deep learning methods, such as lightweight neural networks. In the event of future pandemics, mobile apps will play a critical role in rapid diagnosis using various image data and clinical symptoms. Consequently, the rapid diagnosis of these diseases can improve the management of their effects and obtain excellent results in treating patients.",1,1
33870846,Viral quasispecies quantitative analysis: a novel approach for appraising the immune tolerant phase of chronic hepatitis B virus infection,"Wang M, Chen L, Dong M, Li J, Zhu B, Yang Z, Gong Q, Han Y, Yu D, Zhang D, Zoulim F, Zhang J, Zhang X.",Emerg Microbes Infect. 2021 Dec;10(1):842-851. doi: 10.1080/22221751.2021.1919033.,Wang M,Emerg Microbes Infect,2021,19-04-2021,PMC8812768,,10.1080/22221751.2021.1919033,"Few non-invasive models were established for precisely identifying the immune tolerant (IT) phase from chronic hepatitis B (CHB). This study aimed to develop a novel approach that combined next-generation sequencing (NGS) and machine learning algorithms using our recently published viral quasispecies (QS) analysis package. 290 HBeAg positive patients from whom liver biopsies were taken were enrolled and divided into a training group (n = 148) and a validation group (n = 142). HBV DNA was extracted and QS sequences were obtained by NGS. Hierarchical clustering analysis (HCA) and principal component analysis (PCA) based on viral operational taxonomic units (OTUs) were performed to explore the correlations among QS and clinical phenotypes. Three machine learning algorithms, including K-nearest neighbour, support vector machine, and random forest algorithm, were used to construct diagnostic models for IT phase classification. Based on histopathology, 90 IT patients and 200 CHB patients were diagnosed. HBsAg titres for IT patients were higher than those of CHB patients (p &lt; 0.001). HCA and PCA analysis grouped IT and CHB patients into two distinct clusters. The relative abundance of viral OTUs differed mainly within the BCP/precore/core region and was significantly correlated with liver inflammation and fibrosis. For the IT phase classification, all machine-learning models showed higher AUC values compared to models based on HBsAg, APRI, and FIB-4. The relative abundance of viral OTUs reflects the severity of liver inflammation and fibrosis. The novel QS quantitative analysis approach could be used to diagnose IT patients more precisely and reduce the need for liver biopsy.","Viral quasispecies quantitative analysis: a novel approach for appraising the immune tolerant phase of chronic hepatitis B virus infection Few non-invasive models were established for precisely identifying the immune tolerant (IT) phase from chronic hepatitis B (CHB). This study aimed to develop a novel approach that combined next-generation sequencing (NGS) and machine learning algorithms using our recently published viral quasispecies (QS) analysis package. 290 HBeAg positive patients from whom liver biopsies were taken were enrolled and divided into a training group (n = 148) and a validation group (n = 142). HBV DNA was extracted and QS sequences were obtained by NGS. Hierarchical clustering analysis (HCA) and principal component analysis (PCA) based on viral operational taxonomic units (OTUs) were performed to explore the correlations among QS and clinical phenotypes. Three machine learning algorithms, including K-nearest neighbour, support vector machine, and random forest algorithm, were used to construct diagnostic models for IT phase classification. Based on histopathology, 90 IT patients and 200 CHB patients were diagnosed. HBsAg titres for IT patients were higher than those of CHB patients (p &lt; 0.001). HCA and PCA analysis grouped IT and CHB patients into two distinct clusters. The relative abundance of viral OTUs differed mainly within the BCP/precore/core region and was significantly correlated with liver inflammation and fibrosis. For the IT phase classification, all machine-learning models showed higher AUC values compared to models based on HBsAg, APRI, and FIB-4. The relative abundance of viral OTUs reflects the severity of liver inflammation and fibrosis. The novel QS quantitative analysis approach could be used to diagnose IT patients more precisely and reduce the need for liver biopsy.",1,0
34400884,Multidimensional Evaluation of All-Cause Mortality Risk and Survival Analysis for Hospitalized Patients with COVID-19,"Li J, Luo H, Deng G, Chang J, Qiu X, Liu C, Qin B.",Int J Med Sci. 2021 Jun 26;18(14):3140-3149. doi: 10.7150/ijms.58889. eCollection 2021.,Li J,Int J Med Sci,2021,17-08-2021,PMC8364453,,10.7150/ijms.58889,"Background: Coronavirus disease 2019 (COVID-19) has caused over 3.8 million deaths globally. Up to date, the number of death in 2021 is more than that in 2020 globally. Here, we aimed to compare clinical characteristics of deceased patients and recovered patients, and analyze the risk factors of death to help reduce mortality of COVID-19. Methods: In this retrospective study, a total of 2719 COVID-19 patients were enrolled, including 109 deceased patients and 2610 recovered patients. Medical records of all patients were collected between February 4, 2020, and April 7, 2020. Clinical characteristics, laboratory indices, treatments, and deep-learning system- assessed lung lesion volumes were analyzed. The effect of different medications on survival time of fatal cases was also investigated. Results: The deceased patients were older (73 years versus 60 years) and had a male predominance. Nausea (10.1% versus 4.1%) and dyspnea (54.1% versus 39.2%) were more common in deceased patients. The proportion of patients with comorbidities in deceased patients was significantly higher than those in recovered patients. The median times from hospital admission to outcome in deceased patients and recovered patients were 9 days and 13 days, respectively. Patients with severe or critical COVID-19 were more frequent in deceased group. Leukocytosis (11.35×109/L versus 5.60×109/L) and lymphocytopenia (0.52×109/L versus 1.58×109/L) were shown in patients who died. The level of prothrombin time, activated partial prothrombin time, D-dimer, aspartate aminotransferase, alanine aminotransferase, urea, creatinine, creatine kinase, glucose, brain natriuretic peptide, and inflammatory indicators were significantly higher in deceased patients than in recovered patients. The volumes of ground-glass, consolidation, total lesions and total lung in all patients were quantified. Complications were more common in deceased patients than in recovered patients; respiratory failure (57.8%), septic shock (36.7%), and acute respiratory distress syndrome (26.6%) were the most common complications in patients who died. Many treatments were more frequent in deceased patients, such as antibiotic therapy (88.1% versus 53.7%), glucocorticoid treatment (70.6% versus 11.0%), intravenous immunoglobin treatment (36.6% versus 4.9%), invasive mechanical ventilation (62.3% versus 3.8%). Antivirals, antibiotics, traditional Chinese medicines and glucocorticoid treatment may significantly increase the survival time of fatal cases. Quantitative computed tomography imaging results were correlated with biochemical markers. Conclusions: Most patients with fatal outcomes were more likely to have common comorbidities. The leading causes of death were respiratory failure and multiple organ dysfunction syndrome. Acute respiratory distress syndrome, respiratory failure and septic shock were the most common serious complications. Antivirals, antibiotics, traditional Chinese medicines, and glucocorticoid treatment may prolong the survival time of deceased patients with COVID-19.","Multidimensional Evaluation of All-Cause Mortality Risk and Survival Analysis for Hospitalized Patients with COVID-19 Background: Coronavirus disease 2019 (COVID-19) has caused over 3.8 million deaths globally. Up to date, the number of death in 2021 is more than that in 2020 globally. Here, we aimed to compare clinical characteristics of deceased patients and recovered patients, and analyze the risk factors of death to help reduce mortality of COVID-19. Methods: In this retrospective study, a total of 2719 COVID-19 patients were enrolled, including 109 deceased patients and 2610 recovered patients. Medical records of all patients were collected between February 4, 2020, and April 7, 2020. Clinical characteristics, laboratory indices, treatments, and deep-learning system- assessed lung lesion volumes were analyzed. The effect of different medications on survival time of fatal cases was also investigated. Results: The deceased patients were older (73 years versus 60 years) and had a male predominance. Nausea (10.1% versus 4.1%) and dyspnea (54.1% versus 39.2%) were more common in deceased patients. The proportion of patients with comorbidities in deceased patients was significantly higher than those in recovered patients. The median times from hospital admission to outcome in deceased patients and recovered patients were 9 days and 13 days, respectively. Patients with severe or critical COVID-19 were more frequent in deceased group. Leukocytosis (11.35×109/L versus 5.60×109/L) and lymphocytopenia (0.52×109/L versus 1.58×109/L) were shown in patients who died. The level of prothrombin time, activated partial prothrombin time, D-dimer, aspartate aminotransferase, alanine aminotransferase, urea, creatinine, creatine kinase, glucose, brain natriuretic peptide, and inflammatory indicators were significantly higher in deceased patients than in recovered patients. The volumes of ground-glass, consolidation, total lesions and total lung in all patients were quantified. Complications were more common in deceased patients than in recovered patients; respiratory failure (57.8%), septic shock (36.7%), and acute respiratory distress syndrome (26.6%) were the most common complications in patients who died. Many treatments were more frequent in deceased patients, such as antibiotic therapy (88.1% versus 53.7%), glucocorticoid treatment (70.6% versus 11.0%), intravenous immunoglobin treatment (36.6% versus 4.9%), invasive mechanical ventilation (62.3% versus 3.8%). Antivirals, antibiotics, traditional Chinese medicines and glucocorticoid treatment may significantly increase the survival time of fatal cases. Quantitative computed tomography imaging results were correlated with biochemical markers. Conclusions: Most patients with fatal outcomes were more likely to have common comorbidities. The leading causes of death were respiratory failure and multiple organ dysfunction syndrome. Acute respiratory distress syndrome, respiratory failure and septic shock were the most common serious complications. Antivirals, antibiotics, traditional Chinese medicines, and glucocorticoid treatment may prolong the survival time of deceased patients with COVID-19.",0,0
33528225,Combining In Vivo Corneal Confocal Microscopy With Deep Learning-Based Analysis Reveals Sensory Nerve Fiber Loss in Acute Simian Immunodeficiency Virus Infection,"McCarron ME, Weinberg RL, Izzi JM, Queen SE, Tarwater PM, Misra SL, Russakoff DB, Oakley JD, Mankowski JL.",Cornea. 2021 May 1;40(5):635-642. doi: 10.1097/ICO.0000000000002661.,McCarron ME,Cornea,2021,02-02-2021,PMC8009813,NIHMS1653938,10.1097/ICO.0000000000002661,"PURPOSE: To characterize corneal subbasal nerve plexus features of normal and simian immunodeficiency virus (SIV)-infected macaques by combining in vivo corneal confocal microscopy (IVCM) with automated assessments using deep learning-based methods customized for macaques.
METHODS: IVCM images were collected from both male and female age-matched rhesus and pigtailed macaques housed at the Johns Hopkins University breeding colony using the Heidelberg HRTIII with Rostock Corneal Module. We also obtained repeat IVCM images of 12 SIV-infected animals including preinfection and 10-day post-SIV infection time points. All IVCM images were analyzed using a deep convolutional neural network architecture developed specifically for macaque studies.
RESULTS: Deep learning-based segmentation of subbasal nerves in IVCM images from macaques demonstrated that corneal nerve fiber length and fractal dimension measurements did not differ between species, but pigtailed macaques had significantly higher baseline corneal nerve fiber tortuosity than rhesus macaques (P = 0.005). Neither sex nor age of macaques was associated with differences in any of the assessed corneal subbasal nerve parameters. In the SIV/macaque model of human immunodeficiency virus, acute SIV infection induced significant decreases in both corneal nerve fiber length and fractal dimension (P = 0.01 and P = 0.008, respectively).
CONCLUSIONS: The combination of IVCM and robust objective deep learning analysis is a powerful tool to track sensory nerve damage, enabling early detection of neuropathy. Adapting deep learning analyses to clinical corneal nerve assessments will improve monitoring of small sensory nerve fiber damage in numerous clinical settings including human immunodeficiency virus.","Combining In Vivo Corneal Confocal Microscopy With Deep Learning-Based Analysis Reveals Sensory Nerve Fiber Loss in Acute Simian Immunodeficiency Virus Infection PURPOSE: To characterize corneal subbasal nerve plexus features of normal and simian immunodeficiency virus (SIV)-infected macaques by combining in vivo corneal confocal microscopy (IVCM) with automated assessments using deep learning-based methods customized for macaques.
METHODS: IVCM images were collected from both male and female age-matched rhesus and pigtailed macaques housed at the Johns Hopkins University breeding colony using the Heidelberg HRTIII with Rostock Corneal Module. We also obtained repeat IVCM images of 12 SIV-infected animals including preinfection and 10-day post-SIV infection time points. All IVCM images were analyzed using a deep convolutional neural network architecture developed specifically for macaque studies.
RESULTS: Deep learning-based segmentation of subbasal nerves in IVCM images from macaques demonstrated that corneal nerve fiber length and fractal dimension measurements did not differ between species, but pigtailed macaques had significantly higher baseline corneal nerve fiber tortuosity than rhesus macaques (P = 0.005). Neither sex nor age of macaques was associated with differences in any of the assessed corneal subbasal nerve parameters. In the SIV/macaque model of human immunodeficiency virus, acute SIV infection induced significant decreases in both corneal nerve fiber length and fractal dimension (P = 0.01 and P = 0.008, respectively).
CONCLUSIONS: The combination of IVCM and robust objective deep learning analysis is a powerful tool to track sensory nerve damage, enabling early detection of neuropathy. Adapting deep learning analyses to clinical corneal nerve assessments will improve monitoring of small sensory nerve fiber damage in numerous clinical settings including human immunodeficiency virus.",0,1
36993761,Predicting metabolite response to dietary intervention using deep learning,"Wang T, Holscher HD, Maslov S, Hu FB, Weiss ST, Liu YY.",bioRxiv [Preprint]. 2024 Sep 19:2023.03.14.532589. doi: 10.1101/2023.03.14.532589.,Wang T,bioRxiv,2024,30-03-2023,PMC10054958,,10.1101/2023.03.14.532589,"Due to highly personalized biological and lifestyle characteristics, different individuals may have different metabolite responses to specific foods and nutrients. In particular, the gut microbiota, a collection of trillions of microorganisms living in the gastrointestinal tract, is highly personalized and plays a key role in the metabolite responses to foods and nutrients. Accurately predicting metabolite responses to dietary interventions based on individuals' gut microbial compositions holds great promise for precision nutrition. Existing prediction methods are typically limited to traditional machine learning models. Deep learning methods dedicated to such tasks are still lacking. Here we develop a method McMLP (Metabolite response predictor using coupled Multilayer Perceptrons) to fill in this gap. We provide clear evidence that McMLP outperforms existing methods on both synthetic data generated by the microbial consumer-resource model and real data obtained from six dietary intervention studies. Furthermore, we perform sensitivity analysis of McMLP to infer the tripartite food-microbe-metabolite interactions, which are then validated using the ground-truth (or literature evidence) for synthetic (or real) data, respectively. The presented tool has the potential to inform the design of microbiota-based personalized dietary strategies to achieve precision nutrition.","Predicting metabolite response to dietary intervention using deep learning Due to highly personalized biological and lifestyle characteristics, different individuals may have different metabolite responses to specific foods and nutrients. In particular, the gut microbiota, a collection of trillions of microorganisms living in the gastrointestinal tract, is highly personalized and plays a key role in the metabolite responses to foods and nutrients. Accurately predicting metabolite responses to dietary interventions based on individuals' gut microbial compositions holds great promise for precision nutrition. Existing prediction methods are typically limited to traditional machine learning models. Deep learning methods dedicated to such tasks are still lacking. Here we develop a method McMLP (Metabolite response predictor using coupled Multilayer Perceptrons) to fill in this gap. We provide clear evidence that McMLP outperforms existing methods on both synthetic data generated by the microbial consumer-resource model and real data obtained from six dietary intervention studies. Furthermore, we perform sensitivity analysis of McMLP to infer the tripartite food-microbe-metabolite interactions, which are then validated using the ground-truth (or literature evidence) for synthetic (or real) data, respectively. The presented tool has the potential to inform the design of microbiota-based personalized dietary strategies to achieve precision nutrition.",1,0
33968885,Clinical Factors and Quantitative CT Parameters Associated With ICU Admission in Patients of COVID-19 Pneumonia: A Multicenter Study,"Yan C, Chang Y, Yu H, Xu J, Huang C, Yang M, Wang Y, Wang D, Yu T, Wei S, Li Z, Gong F, Kou M, Gou W, Zhao Q, Sun P, Jia X, Fan Z, Xu J, Li S, Yang Q.",Front Public Health. 2021 Apr 22;9:648360. doi: 10.3389/fpubh.2021.648360. eCollection 2021.,Yan C,Front Public Health,2021,10-05-2021,PMC8101702,,10.3389/fpubh.2021.648360,"The clinical spectrum of COVID-19 pneumonia is varied. Thus, it is important to identify risk factors at an early stage for predicting deterioration that require transferring the patients to ICU. A retrospective multicenter study was conducted on COVID-19 patients admitted to designated hospitals in China from Jan 17, 2020, to Feb 17, 2020. Clinical presentation, laboratory data, and quantitative CT parameters were also collected. The result showed that increasing risks of ICU admission were associated with age &gt; 60 years (odds ratio [OR], 12.72; 95% confidence interval [CI], 2.42-24.61; P = 0.032), coexisting conditions (OR, 5.55; 95% CI, 1.59-19.38; P = 0.007) and CT derived total opacity percentage (TOP) (OR, 8.0; 95% CI, 1.45-39.29; P = 0.016). In conclusion, older age, coexisting conditions, larger TOP at the time of hospital admission are associated with ICU admission in patients with COVID-19 pneumonia. Early monitoring the progression of the disease and implementing appropriate therapies are warranted.","Clinical Factors and Quantitative CT Parameters Associated With ICU Admission in Patients of COVID-19 Pneumonia: A Multicenter Study The clinical spectrum of COVID-19 pneumonia is varied. Thus, it is important to identify risk factors at an early stage for predicting deterioration that require transferring the patients to ICU. A retrospective multicenter study was conducted on COVID-19 patients admitted to designated hospitals in China from Jan 17, 2020, to Feb 17, 2020. Clinical presentation, laboratory data, and quantitative CT parameters were also collected. The result showed that increasing risks of ICU admission were associated with age &gt; 60 years (odds ratio [OR], 12.72; 95% confidence interval [CI], 2.42-24.61; P = 0.032), coexisting conditions (OR, 5.55; 95% CI, 1.59-19.38; P = 0.007) and CT derived total opacity percentage (TOP) (OR, 8.0; 95% CI, 1.45-39.29; P = 0.016). In conclusion, older age, coexisting conditions, larger TOP at the time of hospital admission are associated with ICU admission in patients with COVID-19 pneumonia. Early monitoring the progression of the disease and implementing appropriate therapies are warranted.",0,0
33956083,Identification of Risk of Cardiovascular Disease by Automatic Quantification of Coronary Artery Calcifications on Radiotherapy Planning CT Scans in Patients With Breast Cancer,"Gal R, van Velzen SGM, Hooning MJ, Emaus MJ, van der Leij F, Gregorowitsch ML, Blezer ELA, Gernaat SAM, Lessmann N, Sattler MGA, Leiner T, de Jong PA, Teske AJ, Verloop J, Penninkhof JJ, Vaartjes I, Meijer H, van Tol-Geerdink JJ, Pignol JP, van den Bongard DHJG, Išgum I, Verkooijen HM.",JAMA Oncol. 2021 Jul 1;7(7):1024-1032. doi: 10.1001/jamaoncol.2021.1144.,Gal R,JAMA Oncol,2021,06-05-2021,PMC8283560,,10.1001/jamaoncol.2021.1144,"IMPORTANCE: Cardiovascular disease (CVD) is common in patients treated for breast cancer, especially in patients treated with systemic treatment and radiotherapy and in those with preexisting CVD risk factors. Coronary artery calcium (CAC), a strong independent CVD risk factor, can be automatically quantified on radiotherapy planning computed tomography (CT) scans and may help identify patients at increased CVD risk.
OBJECTIVE: To evaluate the association of CAC with CVD and coronary artery disease (CAD) in patients with breast cancer.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter cohort study of 15 915 patients with breast cancer receiving radiotherapy between 2005 and 2016 who were followed until December 31, 2018, age, calendar year, and treatment-adjusted Cox proportional hazard models were used to evaluate the association of CAC with CVD and CAD.
EXPOSURES: Overall CAC scores were automatically extracted from planning CT scans using a deep learning algorithm. Patients were classified into Agatston risk categories (0, 1-10, 11-100, 101-399, >400 units).
MAIN OUTCOMES AND MEASURES: Occurrence of fatal and nonfatal CVD and CAD were obtained from national registries.
RESULTS: Of the 15 915 participants included in this study, the mean (SD) age at CT scan was 59.0 (11.2; range, 22-95) years, and 15 879 (99.8%) were women. Seventy percent (n = 11 179) had no CAC. Coronary artery calcium scores of 1 to 10, 11 to 100, 101 to 400, and greater than 400 were present in 10.0% (n = 1584), 11.5% (n = 1825), 5.2% (n = 830), and 3.1% (n = 497) respectively. After a median follow-up of 51.2 months, CVD risks increased from 5.2% in patients with no CAC to 28.2% in patients with CAC scores higher than 400. After adjustment, CVD risk increased with higher CAC score (hazard ratio [HR]CAC = 1-10 = 1.1; 95% CI, 0.9-1.4; HRCAC = 11-100 = 1.8; 95% CI, 1.5-2.1; HRCAC = 101-400 = 2.1; 95% CI, 1.7-2.6; and HRCAC>400 = 3.4; 95% CI, 2.8-4.2). Coronary artery calcium was particularly strongly associated with CAD (HRCAC>400 = 7.8; 95% CI, 5.5-11.2). The association between CAC and CVD was strongest in patients treated with anthracyclines (HRCAC>400 = 5.8; 95% CI, 3.0-11.4) and patients who received a radiation boost (HRCAC>400 = 6.1; 95% CI, 3.8-9.7).
CONCLUSIONS AND RELEVANCE: This cohort study found that coronary artery calcium on breast cancer radiotherapy planning CT scan results was associated with CVD, especially CAD. Automated CAC scoring on radiotherapy planning CT scans may be used as a fast and low-cost tool to identify patients with breast cancer at increased risk of CVD, allowing implementing CVD risk-mitigating strategies with the aim to reduce the risk of CVD burden after breast cancer.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT03206333.","Identification of Risk of Cardiovascular Disease by Automatic Quantification of Coronary Artery Calcifications on Radiotherapy Planning CT Scans in Patients With Breast Cancer IMPORTANCE: Cardiovascular disease (CVD) is common in patients treated for breast cancer, especially in patients treated with systemic treatment and radiotherapy and in those with preexisting CVD risk factors. Coronary artery calcium (CAC), a strong independent CVD risk factor, can be automatically quantified on radiotherapy planning computed tomography (CT) scans and may help identify patients at increased CVD risk.
OBJECTIVE: To evaluate the association of CAC with CVD and coronary artery disease (CAD) in patients with breast cancer.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter cohort study of 15 915 patients with breast cancer receiving radiotherapy between 2005 and 2016 who were followed until December 31, 2018, age, calendar year, and treatment-adjusted Cox proportional hazard models were used to evaluate the association of CAC with CVD and CAD.
EXPOSURES: Overall CAC scores were automatically extracted from planning CT scans using a deep learning algorithm. Patients were classified into Agatston risk categories (0, 1-10, 11-100, 101-399, >400 units).
MAIN OUTCOMES AND MEASURES: Occurrence of fatal and nonfatal CVD and CAD were obtained from national registries.
RESULTS: Of the 15 915 participants included in this study, the mean (SD) age at CT scan was 59.0 (11.2; range, 22-95) years, and 15 879 (99.8%) were women. Seventy percent (n = 11 179) had no CAC. Coronary artery calcium scores of 1 to 10, 11 to 100, 101 to 400, and greater than 400 were present in 10.0% (n = 1584), 11.5% (n = 1825), 5.2% (n = 830), and 3.1% (n = 497) respectively. After a median follow-up of 51.2 months, CVD risks increased from 5.2% in patients with no CAC to 28.2% in patients with CAC scores higher than 400. After adjustment, CVD risk increased with higher CAC score (hazard ratio [HR]CAC = 1-10 = 1.1; 95% CI, 0.9-1.4; HRCAC = 11-100 = 1.8; 95% CI, 1.5-2.1; HRCAC = 101-400 = 2.1; 95% CI, 1.7-2.6; and HRCAC>400 = 3.4; 95% CI, 2.8-4.2). Coronary artery calcium was particularly strongly associated with CAD (HRCAC>400 = 7.8; 95% CI, 5.5-11.2). The association between CAC and CVD was strongest in patients treated with anthracyclines (HRCAC>400 = 5.8; 95% CI, 3.0-11.4) and patients who received a radiation boost (HRCAC>400 = 6.1; 95% CI, 3.8-9.7).
CONCLUSIONS AND RELEVANCE: This cohort study found that coronary artery calcium on breast cancer radiotherapy planning CT scan results was associated with CVD, especially CAD. Automated CAC scoring on radiotherapy planning CT scans may be used as a fast and low-cost tool to identify patients with breast cancer at increased risk of CVD, allowing implementing CVD risk-mitigating strategies with the aim to reduce the risk of CVD burden after breast cancer.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT03206333.",0,0
38872398,Internal validation of Automated Visual Evaluation (AVE) on smartphone images for cervical cancer screening in a prospective study in Zambia,"Hu L, Mwanahamuntu MH, Sahasrabuddhe VV, Barrett C, Horning MP, Shah I, Laverriere Z, Banik D, Ji Y, Shibemba AL, Chisele S, Munalula MK, Kaunga F, Musonda F, Malyangu E, Hariharan KM, Parham GP.",Cancer Med. 2024 Jun;13(11):e7355. doi: 10.1002/cam4.7355.,Hu L,Cancer Med,2024,14-06-2024,PMC11176573,,10.1002/cam4.7355,"OBJECTIVES: Visual inspection with acetic acid (VIA) is a low-cost approach for cervical cancer screening used in most low- and middle-income countries (LMICs) but, similar to other visual tests, is subjective and requires sustained training and quality assurance. We developed, trained, and validated an artificial-intelligence-based ""Automated Visual Evaluation"" (AVE) tool that can be adapted to run on smartphones to assess smartphone-captured images of the cervix and identify precancerous lesions, helping augment VIA performance.
DESIGN: Prospective study.
SETTING: Eight public health facilities in Zambia.
PARTICIPANTS: A total of 8204 women aged 25-55.
INTERVENTIONS: Cervical images captured on commonly used low-cost smartphone models were matched with key clinical information including human immunodeficiency virus (HIV) and human papillomavirus (HPV) status, plus histopathology analysis (where applicable), to develop and train an AVE algorithm and evaluate its performance for use as a primary screen and triage test for women who are HPV positive.
MAIN OUTCOME MEASURES: Area under the receiver operating curve (AUC); sensitivity; specificity.
RESULTS: As a general population screening tool for cervical precancerous lesions, AVE identified cases of cervical precancerous and cancerous (CIN2+) lesions with high performance (AUC = 0.91, 95% confidence interval [CI] = 0.89-0.93), which translates to a sensitivity of 85% (95% CI = 81%-90%) and specificity of 86% (95% CI = 84%-88%) based on maximizing the Youden's index. This represents a considerable improvement over naked eye VIA, which as per a meta-analysis by the World Health Organization (WHO) has a sensitivity of 66% and specificity of 87%. For women living with HIV, the AUC of AVE was 0.91 (95% CI = 0.88-0.93), and among those testing positive for high-risk HPV types, the AUC was 0.87 (95% CI = 0.83-0.91).
CONCLUSIONS: These results demonstrate the feasibility of utilizing AVE on images captured using a commonly available smartphone by nurses in a screening program, and support our ongoing efforts for moving to more broadly evaluate AVE for its clinical sensitivity, specificity, feasibility, and acceptability across a wider range of settings. Limitations of this study include potential inflation of performance estimates due to verification bias (as biopsies were only obtained from participants with visible aceto-white cervical lesions) and due to this being an internal validation (the test data, while independent from that used to develop the algorithm was drawn from the same study).","Internal validation of Automated Visual Evaluation (AVE) on smartphone images for cervical cancer screening in a prospective study in Zambia OBJECTIVES: Visual inspection with acetic acid (VIA) is a low-cost approach for cervical cancer screening used in most low- and middle-income countries (LMICs) but, similar to other visual tests, is subjective and requires sustained training and quality assurance. We developed, trained, and validated an artificial-intelligence-based ""Automated Visual Evaluation"" (AVE) tool that can be adapted to run on smartphones to assess smartphone-captured images of the cervix and identify precancerous lesions, helping augment VIA performance.
DESIGN: Prospective study.
SETTING: Eight public health facilities in Zambia.
PARTICIPANTS: A total of 8204 women aged 25-55.
INTERVENTIONS: Cervical images captured on commonly used low-cost smartphone models were matched with key clinical information including human immunodeficiency virus (HIV) and human papillomavirus (HPV) status, plus histopathology analysis (where applicable), to develop and train an AVE algorithm and evaluate its performance for use as a primary screen and triage test for women who are HPV positive.
MAIN OUTCOME MEASURES: Area under the receiver operating curve (AUC); sensitivity; specificity.
RESULTS: As a general population screening tool for cervical precancerous lesions, AVE identified cases of cervical precancerous and cancerous (CIN2+) lesions with high performance (AUC = 0.91, 95% confidence interval [CI] = 0.89-0.93), which translates to a sensitivity of 85% (95% CI = 81%-90%) and specificity of 86% (95% CI = 84%-88%) based on maximizing the Youden's index. This represents a considerable improvement over naked eye VIA, which as per a meta-analysis by the World Health Organization (WHO) has a sensitivity of 66% and specificity of 87%. For women living with HIV, the AUC of AVE was 0.91 (95% CI = 0.88-0.93), and among those testing positive for high-risk HPV types, the AUC was 0.87 (95% CI = 0.83-0.91).
CONCLUSIONS: These results demonstrate the feasibility of utilizing AVE on images captured using a commonly available smartphone by nurses in a screening program, and support our ongoing efforts for moving to more broadly evaluate AVE for its clinical sensitivity, specificity, feasibility, and acceptability across a wider range of settings. Limitations of this study include potential inflation of performance estimates due to verification bias (as biopsies were only obtained from participants with visible aceto-white cervical lesions) and due to this being an internal validation (the test data, while independent from that used to develop the algorithm was drawn from the same study).",0,0
33301414,An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model,"Ko H, Chung H, Kang WS, Park C, Kim DW, Kim SE, Chung CR, Ko RE, Lee H, Seo JH, Choi TY, Jaimes R, Kim KW, Lee J.",J Med Internet Res. 2020 Dec 23;22(12):e25442. doi: 10.2196/25442.,Ko H,J Med Internet Res,2020,10-12-2020,PMC7759509,,10.2196/25442,"BACKGROUND: COVID-19, which is accompanied by acute respiratory distress, multiple organ failure, and death, has spread worldwide much faster than previously thought. However, at present, it has limited treatments.
OBJECTIVE: To overcome this issue, we developed an artificial intelligence (AI) model of COVID-19, named EDRnet (ensemble learning model based on deep neural network and random forest models), to predict in-hospital mortality using a routine blood sample at the time of hospital admission.
METHODS: We selected 28 blood biomarkers and used the age and gender information of patients as model inputs. To improve the mortality prediction, we adopted an ensemble approach combining deep neural network and random forest models. We trained our model with a database of blood samples from 361 COVID-19 patients in Wuhan, China, and applied it to 106 COVID-19 patients in three Korean medical institutions.
RESULTS: In the testing data sets, EDRnet provided high sensitivity (100%), specificity (91%), and accuracy (92%). To extend the number of patient data points, we developed a web application (BeatCOVID19) where anyone can access the model to predict mortality and can register his or her own blood laboratory results.
CONCLUSIONS: Our new AI model, EDRnet, accurately predicts the mortality rate for COVID-19. It is publicly available and aims to help health care providers fight COVID-19 and improve patients' outcomes.","An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model BACKGROUND: COVID-19, which is accompanied by acute respiratory distress, multiple organ failure, and death, has spread worldwide much faster than previously thought. However, at present, it has limited treatments.
OBJECTIVE: To overcome this issue, we developed an artificial intelligence (AI) model of COVID-19, named EDRnet (ensemble learning model based on deep neural network and random forest models), to predict in-hospital mortality using a routine blood sample at the time of hospital admission.
METHODS: We selected 28 blood biomarkers and used the age and gender information of patients as model inputs. To improve the mortality prediction, we adopted an ensemble approach combining deep neural network and random forest models. We trained our model with a database of blood samples from 361 COVID-19 patients in Wuhan, China, and applied it to 106 COVID-19 patients in three Korean medical institutions.
RESULTS: In the testing data sets, EDRnet provided high sensitivity (100%), specificity (91%), and accuracy (92%). To extend the number of patient data points, we developed a web application (BeatCOVID19) where anyone can access the model to predict mortality and can register his or her own blood laboratory results.
CONCLUSIONS: Our new AI model, EDRnet, accurately predicts the mortality rate for COVID-19. It is publicly available and aims to help health care providers fight COVID-19 and improve patients' outcomes.",0,1
28464015,Forecasting influenza in Hong Kong with Google search queries and statistical model fusion,"Xu Q, Gel YR, Ramirez Ramirez LL, Nezafati K, Zhang Q, Tsui KL.",PLoS One. 2017 May 2;12(5):e0176690. doi: 10.1371/journal.pone.0176690. eCollection 2017.,Xu Q,PLoS One,2017,03-05-2017,PMC5413039,,10.1371/journal.pone.0176690,"BACKGROUND: The objective of this study is to investigate predictive utility of online social media and web search queries, particularly, Google search data, to forecast new cases of influenza-like-illness (ILI) in general outpatient clinics (GOPC) in Hong Kong. To mitigate the impact of sensitivity to self-excitement (i.e., fickle media interest) and other artifacts of online social media data, in our approach we fuse multiple offline and online data sources.
METHODS: Four individual models: generalized linear model (GLM), least absolute shrinkage and selection operator (LASSO), autoregressive integrated moving average (ARIMA), and deep learning (DL) with Feedforward Neural Networks (FNN) are employed to forecast ILI-GOPC both one week and two weeks in advance. The covariates include Google search queries, meteorological data, and previously recorded offline ILI. To our knowledge, this is the first study that introduces deep learning methodology into surveillance of infectious diseases and investigates its predictive utility. Furthermore, to exploit the strength from each individual forecasting models, we use statistical model fusion, using Bayesian model averaging (BMA), which allows a systematic integration of multiple forecast scenarios. For each model, an adaptive approach is used to capture the recent relationship between ILI and covariates.
RESULTS: DL with FNN appears to deliver the most competitive predictive performance among the four considered individual models. Combing all four models in a comprehensive BMA framework allows to further improve such predictive evaluation metrics as root mean squared error (RMSE) and mean absolute predictive error (MAPE). Nevertheless, DL with FNN remains the preferred method for predicting locations of influenza peaks.
CONCLUSIONS: The proposed approach can be viewed a feasible alternative to forecast ILI in Hong Kong or other countries where ILI has no constant seasonal trend and influenza data resources are limited. The proposed methodology is easily tractable and computationally efficient.","Forecasting influenza in Hong Kong with Google search queries and statistical model fusion BACKGROUND: The objective of this study is to investigate predictive utility of online social media and web search queries, particularly, Google search data, to forecast new cases of influenza-like-illness (ILI) in general outpatient clinics (GOPC) in Hong Kong. To mitigate the impact of sensitivity to self-excitement (i.e., fickle media interest) and other artifacts of online social media data, in our approach we fuse multiple offline and online data sources.
METHODS: Four individual models: generalized linear model (GLM), least absolute shrinkage and selection operator (LASSO), autoregressive integrated moving average (ARIMA), and deep learning (DL) with Feedforward Neural Networks (FNN) are employed to forecast ILI-GOPC both one week and two weeks in advance. The covariates include Google search queries, meteorological data, and previously recorded offline ILI. To our knowledge, this is the first study that introduces deep learning methodology into surveillance of infectious diseases and investigates its predictive utility. Furthermore, to exploit the strength from each individual forecasting models, we use statistical model fusion, using Bayesian model averaging (BMA), which allows a systematic integration of multiple forecast scenarios. For each model, an adaptive approach is used to capture the recent relationship between ILI and covariates.
RESULTS: DL with FNN appears to deliver the most competitive predictive performance among the four considered individual models. Combing all four models in a comprehensive BMA framework allows to further improve such predictive evaluation metrics as root mean squared error (RMSE) and mean absolute predictive error (MAPE). Nevertheless, DL with FNN remains the preferred method for predicting locations of influenza peaks.
CONCLUSIONS: The proposed approach can be viewed a feasible alternative to forecast ILI in Hong Kong or other countries where ILI has no constant seasonal trend and influenza data resources are limited. The proposed methodology is easily tractable and computationally efficient.",1,1
32919186,COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review,"Suri JS, Puvvula A, Biswas M, Majhail M, Saba L, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Sanches JM, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Kolluri R, Teji J, Maini MA, Agbakoba A, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PR, Naidu S.",Comput Biol Med. 2020 Sep;124:103960. doi: 10.1016/j.compbiomed.2020.103960. Epub 2020 Aug 14.,Suri JS,Comput Biol Med,2020,12-09-2020,PMC7426723,,10.1016/j.compbiomed.2020.103960,"Artificial intelligence (AI) has penetrated the field of medicine, particularly the field of radiology. Since its emergence, the highly virulent coronavirus disease 2019 (COVID-19) has infected over 10 million people, leading to over 500,000 deaths as of July 1st, 2020. Since the outbreak began, almost 28,000 articles about COVID-19 have been published (https://pubmed.ncbi.nlm.nih.gov); however, few have explored the role of imaging and artificial intelligence in COVID-19 patients-specifically, those with comorbidities. This paper begins by presenting the four pathways that can lead to heart and brain injuries following a COVID-19 infection. Our survey also offers insights into the role that imaging can play in the treatment of comorbid patients, based on probabilities derived from COVID-19 symptom statistics. Such symptoms include myocardial injury, hypoxia, plaque rupture, arrhythmias, venous thromboembolism, coronary thrombosis, encephalitis, ischemia, inflammation, and lung injury. At its core, this study considers the role of image-based AI, which can be used to characterize the tissues of a COVID-19 patient and classify the severity of their infection. Image-based AI is more important than ever as the pandemic surges and countries worldwide grapple with limited medical resources for detection and diagnosis.","COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review Artificial intelligence (AI) has penetrated the field of medicine, particularly the field of radiology. Since its emergence, the highly virulent coronavirus disease 2019 (COVID-19) has infected over 10 million people, leading to over 500,000 deaths as of July 1st, 2020. Since the outbreak began, almost 28,000 articles about COVID-19 have been published (https://pubmed.ncbi.nlm.nih.gov); however, few have explored the role of imaging and artificial intelligence in COVID-19 patients-specifically, those with comorbidities. This paper begins by presenting the four pathways that can lead to heart and brain injuries following a COVID-19 infection. Our survey also offers insights into the role that imaging can play in the treatment of comorbid patients, based on probabilities derived from COVID-19 symptom statistics. Such symptoms include myocardial injury, hypoxia, plaque rupture, arrhythmias, venous thromboembolism, coronary thrombosis, encephalitis, ischemia, inflammation, and lung injury. At its core, this study considers the role of image-based AI, which can be used to characterize the tissues of a COVID-19 patient and classify the severity of their infection. Image-based AI is more important than ever as the pandemic surges and countries worldwide grapple with limited medical resources for detection and diagnosis.",1,1
37961168,Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders,"Rancati S, Nicora G, Prosperi M, Bellazzi R, Salemi M, Marini S.",bioRxiv [Preprint]. 2024 Sep 26:2023.10.24.563721. doi: 10.1101/2023.10.24.563721.,Rancati S,bioRxiv,2024,14-11-2023,PMC10634784,,10.1101/2023.10.24.563721,"The coronavirus disease of 2019 (COVID-19) pandemic is characterized by sequential emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) variants, lineages, and sublineages, outcompeting previously circulating ones because of, among other factors, increased transmissibility and immune escape. We propose DeepAutoCoV, an unsupervised deep learning anomaly detection system to predict future dominant lineages (FDLs). We define FDLs as viral (sub)lineages that will constitute more than 10% of all the viral sequences added to the GISAID database on a given week. DeepAutoCoV is trained and validated by assembling global and country-specific data sets from over 16 million Spike protein sequences sampled over a period of about 4 years. DeepAutoCoV successfully flags FDLs at very low frequencies (0.01% - 3%), with median lead times of 4-17 weeks, and predicts FDLs ~5 and ~25 times better than a baseline approach For example, the B.1.617.2 vaccine reference strain was flagged as FDL when its frequency was only 0.01%, more than a year before it was considered for an updated COVID-19 vaccine. Furthermore, DeepAutoCoV outputs interpretable results by pinpointing specific mutations potentially linked to increased fitness, and may provide significant insights for the optimization of public health pre-emptive intervention strategies.","Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders The coronavirus disease of 2019 (COVID-19) pandemic is characterized by sequential emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) variants, lineages, and sublineages, outcompeting previously circulating ones because of, among other factors, increased transmissibility and immune escape. We propose DeepAutoCoV, an unsupervised deep learning anomaly detection system to predict future dominant lineages (FDLs). We define FDLs as viral (sub)lineages that will constitute more than 10% of all the viral sequences added to the GISAID database on a given week. DeepAutoCoV is trained and validated by assembling global and country-specific data sets from over 16 million Spike protein sequences sampled over a period of about 4 years. DeepAutoCoV successfully flags FDLs at very low frequencies (0.01% - 3%), with median lead times of 4-17 weeks, and predicts FDLs ~5 and ~25 times better than a baseline approach For example, the B.1.617.2 vaccine reference strain was flagged as FDL when its frequency was only 0.01%, more than a year before it was considered for an updated COVID-19 vaccine. Furthermore, DeepAutoCoV outputs interpretable results by pinpointing specific mutations potentially linked to increased fitness, and may provide significant insights for the optimization of public health pre-emptive intervention strategies.",0,1
39103945,Phenotyping COVID-19 respiratory failure in spontaneously breathing patients with AI on lung CT-scan,"Rezoagli E, Xin Y, Signori D, Sun W, Gerard S, Delucchi KL, Magliocca A, Vitale G, Giacomini M, Mussoni L, Montomoli J, Subert M, Ponti A, Spadaro S, Poli G, Casola F, Herrmann J, Foti G, Calfee CS, Laffey J, Bellani G, Cereda M; CT-COVID19 Multicenter Study Group.",Crit Care. 2024 Aug 5;28(1):263. doi: 10.1186/s13054-024-05046-3.,Rezoagli E,Crit Care,2024,05-08-2024,PMC11301830,,10.1186/s13054-024-05046-3,"BACKGROUND: Automated analysis of lung computed tomography (CT) scans may help characterize subphenotypes of acute respiratory illness. We integrated lung CT features measured via deep learning with clinical and laboratory data in spontaneously breathing subjects to enhance the identification of COVID-19 subphenotypes.
METHODS: This is a multicenter observational cohort study in spontaneously breathing patients with COVID-19 respiratory failure exposed to early lung CT within 7 days of admission. We explored lung CT images using deep learning approaches to quantitative and qualitative analyses; latent class analysis (LCA) by using clinical, laboratory and lung CT variables; regional differences between subphenotypes following 3D spatial trajectories.
RESULTS: Complete datasets were available in 559 patients. LCA identified two subphenotypes (subphenotype 1 and 2). As compared with subphenotype 2 (n = 403), subphenotype 1 patients (n = 156) were older, had higher inflammatory biomarkers, and were more hypoxemic. Lungs in subphenotype 1 had a higher density gravitational gradient with a greater proportion of consolidated lungs as compared with subphenotype 2. In contrast, subphenotype 2 had a higher density submantellar-hilar gradient with a greater proportion of ground glass opacities as compared with subphenotype 1. Subphenotype 1 showed higher prevalence of comorbidities associated with endothelial dysfunction and higher 90-day mortality than subphenotype 2, even after adjustment for clinically meaningful variables.
CONCLUSIONS: Integrating lung-CT data in a LCA allowed us to identify two subphenotypes of COVID-19, with different clinical trajectories. These exploratory findings suggest a role of automated imaging characterization guided by machine learning in subphenotyping patients with respiratory failure.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT04395482. Registration date: 19/05/2020.","Phenotyping COVID-19 respiratory failure in spontaneously breathing patients with AI on lung CT-scan BACKGROUND: Automated analysis of lung computed tomography (CT) scans may help characterize subphenotypes of acute respiratory illness. We integrated lung CT features measured via deep learning with clinical and laboratory data in spontaneously breathing subjects to enhance the identification of COVID-19 subphenotypes.
METHODS: This is a multicenter observational cohort study in spontaneously breathing patients with COVID-19 respiratory failure exposed to early lung CT within 7 days of admission. We explored lung CT images using deep learning approaches to quantitative and qualitative analyses; latent class analysis (LCA) by using clinical, laboratory and lung CT variables; regional differences between subphenotypes following 3D spatial trajectories.
RESULTS: Complete datasets were available in 559 patients. LCA identified two subphenotypes (subphenotype 1 and 2). As compared with subphenotype 2 (n = 403), subphenotype 1 patients (n = 156) were older, had higher inflammatory biomarkers, and were more hypoxemic. Lungs in subphenotype 1 had a higher density gravitational gradient with a greater proportion of consolidated lungs as compared with subphenotype 2. In contrast, subphenotype 2 had a higher density submantellar-hilar gradient with a greater proportion of ground glass opacities as compared with subphenotype 1. Subphenotype 1 showed higher prevalence of comorbidities associated with endothelial dysfunction and higher 90-day mortality than subphenotype 2, even after adjustment for clinically meaningful variables.
CONCLUSIONS: Integrating lung-CT data in a LCA allowed us to identify two subphenotypes of COVID-19, with different clinical trajectories. These exploratory findings suggest a role of automated imaging characterization guided by machine learning in subphenotyping patients with respiratory failure.
TRIAL REGISTRATION: ClinicalTrials.gov Identifier: NCT04395482. Registration date: 19/05/2020.",0,1
33232368,Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study,"Jang SB, Lee SH, Lee DE, Park SY, Kim JK, Cho JW, Cho J, Kim KB, Park B, Park J, Lim JK.",PLoS One. 2020 Nov 24;15(11):e0242759. doi: 10.1371/journal.pone.0242759. eCollection 2020.,Jang SB,PLoS One,2020,24-11-2020,PMC7685476,,10.1371/journal.pone.0242759,"The recent medical applications of deep-learning (DL) algorithms have demonstrated their clinical efficacy in improving speed and accuracy of image interpretation. If the DL algorithm achieves a performance equivalent to that achieved by physicians in chest radiography (CR) diagnoses with Coronavirus disease 2019 (COVID-19) pneumonia, the automatic interpretation of the CR with DL algorithms can significantly reduce the burden on clinicians and radiologists in sudden surges of suspected COVID-19 patients. The aim of this study was to evaluate the efficacy of the DL algorithm for detecting COVID-19 pneumonia on CR compared with formal radiology reports. This is a retrospective study of adult patients that were diagnosed as positive COVID-19 cases based on the reverse transcription polymerase chain reaction among all the patients who were admitted to five emergency departments and one community treatment center in Korea from February 18, 2020 to May 1, 2020. The CR images were evaluated with a publicly available DL algorithm. For reference, CR images without chest computed tomography (CT) scans classified as positive for COVID-19 pneumonia were used given that the radiologist identified ground-glass opacity, consolidation, or other infiltration in retrospectively reviewed CR images. Patients with evidence of pneumonia on chest CT scans were also classified as COVID-19 pneumonia positive outcomes. The overall sensitivity and specificity of the DL algorithm for detecting COVID-19 pneumonia on CR were 95.6%, and 88.7%, respectively. The area under the curve value of the DL algorithm for the detection of COVID-19 with pneumonia was 0.921. The DL algorithm demonstrated a satisfactory diagnostic performance comparable with that of formal radiology reports in the CR-based diagnosis of pneumonia in COVID-19 patients. The DL algorithm may offer fast and reliable examinations that can facilitate patient screening and isolation decisions, which can reduce the medical staff workload during COVID-19 pandemic situations.","Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study The recent medical applications of deep-learning (DL) algorithms have demonstrated their clinical efficacy in improving speed and accuracy of image interpretation. If the DL algorithm achieves a performance equivalent to that achieved by physicians in chest radiography (CR) diagnoses with Coronavirus disease 2019 (COVID-19) pneumonia, the automatic interpretation of the CR with DL algorithms can significantly reduce the burden on clinicians and radiologists in sudden surges of suspected COVID-19 patients. The aim of this study was to evaluate the efficacy of the DL algorithm for detecting COVID-19 pneumonia on CR compared with formal radiology reports. This is a retrospective study of adult patients that were diagnosed as positive COVID-19 cases based on the reverse transcription polymerase chain reaction among all the patients who were admitted to five emergency departments and one community treatment center in Korea from February 18, 2020 to May 1, 2020. The CR images were evaluated with a publicly available DL algorithm. For reference, CR images without chest computed tomography (CT) scans classified as positive for COVID-19 pneumonia were used given that the radiologist identified ground-glass opacity, consolidation, or other infiltration in retrospectively reviewed CR images. Patients with evidence of pneumonia on chest CT scans were also classified as COVID-19 pneumonia positive outcomes. The overall sensitivity and specificity of the DL algorithm for detecting COVID-19 pneumonia on CR were 95.6%, and 88.7%, respectively. The area under the curve value of the DL algorithm for the detection of COVID-19 with pneumonia was 0.921. The DL algorithm demonstrated a satisfactory diagnostic performance comparable with that of formal radiology reports in the CR-based diagnosis of pneumonia in COVID-19 patients. The DL algorithm may offer fast and reliable examinations that can facilitate patient screening and isolation decisions, which can reduce the medical staff workload during COVID-19 pandemic situations.",1,1
33221381,Epicardial adipose tissue is associated with extent of pneumonia and adverse outcomes in patients with COVID-19,"Grodecki K, Lin A, Razipour A, Cadet S, McElhinney PA, Chan C, Pressman BD, Julien P, Maurovich-Horvat P, Gaibazzi N, Thakur U, Mancini E, Agalbato C, Menè R, Parati G, Cernigliaro F, Nerlekar N, Torlasco C, Pontone G, Slomka PJ, Dey D.",Metabolism. 2021 Feb;115:154436. doi: 10.1016/j.metabol.2020.154436. Epub 2020 Nov 19.,Grodecki K,Metabolism,2021,22-11-2020,PMC7676319,,10.1016/j.metabol.2020.154436,"AIM: We sought to examine the association of epicardial adipose tissue (EAT) quantified on chest computed tomography (CT) with the extent of pneumonia and adverse outcomes in patients with coronavirus disease 2019 (COVID-19).
METHODS: We performed a post-hoc analysis of a prospective international registry comprising 109 consecutive patients (age 64 ± 16 years; 62% male) with laboratory-confirmed COVID-19 and noncontrast chest CT imaging. Using semi-automated software, we quantified the burden (%) of lung abnormalities associated with COVID-19 pneumonia. EAT volume (mL) and attenuation (Hounsfield units) were measured using deep learning software. The primary outcome was clinical deterioration (intensive care unit admission, invasive mechanical ventilation, or vasopressor therapy) or in-hospital death.
RESULTS: In multivariable linear regression analysis adjusted for patient comorbidities, the total burden of COVID-19 pneumonia was associated with EAT volume (β = 10.6, p = 0.005) and EAT attenuation (β = 5.2, p = 0.004). EAT volume correlated with serum levels of lactate dehydrogenase (r = 0.361, p = 0.001) and C-reactive protein (r = 0.450, p < 0.001). Clinical deterioration or death occurred in 23 (21.1%) patients at a median of 3 days (IQR 1-13 days) following the chest CT. In multivariable logistic regression analysis, EAT volume (OR 5.1 [95% CI 1.8-14.1] per doubling p = 0.011) and EAT attenuation (OR 3.4 [95% CI 1.5-7.5] per 5 Hounsfield unit increase, p = 0.003) were independent predictors of clinical deterioration or death, as was total pneumonia burden (OR 2.5, 95% CI 1.4-4.6, p = 0.002), chronic lung disease (OR 1.3 [95% CI 1.1-1.7], p = 0.011), and history of heart failure (OR 3.5 [95% 1.1-8.2], p = 0.037).
CONCLUSIONS: EAT measures quantified from chest CT are independently associated with extent of pneumonia and adverse outcomes in patients with COVID-19, lending support to their use in clinical risk stratification.","Epicardial adipose tissue is associated with extent of pneumonia and adverse outcomes in patients with COVID-19 AIM: We sought to examine the association of epicardial adipose tissue (EAT) quantified on chest computed tomography (CT) with the extent of pneumonia and adverse outcomes in patients with coronavirus disease 2019 (COVID-19).
METHODS: We performed a post-hoc analysis of a prospective international registry comprising 109 consecutive patients (age 64 ± 16 years; 62% male) with laboratory-confirmed COVID-19 and noncontrast chest CT imaging. Using semi-automated software, we quantified the burden (%) of lung abnormalities associated with COVID-19 pneumonia. EAT volume (mL) and attenuation (Hounsfield units) were measured using deep learning software. The primary outcome was clinical deterioration (intensive care unit admission, invasive mechanical ventilation, or vasopressor therapy) or in-hospital death.
RESULTS: In multivariable linear regression analysis adjusted for patient comorbidities, the total burden of COVID-19 pneumonia was associated with EAT volume (β = 10.6, p = 0.005) and EAT attenuation (β = 5.2, p = 0.004). EAT volume correlated with serum levels of lactate dehydrogenase (r = 0.361, p = 0.001) and C-reactive protein (r = 0.450, p < 0.001). Clinical deterioration or death occurred in 23 (21.1%) patients at a median of 3 days (IQR 1-13 days) following the chest CT. In multivariable logistic regression analysis, EAT volume (OR 5.1 [95% CI 1.8-14.1] per doubling p = 0.011) and EAT attenuation (OR 3.4 [95% CI 1.5-7.5] per 5 Hounsfield unit increase, p = 0.003) were independent predictors of clinical deterioration or death, as was total pneumonia burden (OR 2.5, 95% CI 1.4-4.6, p = 0.002), chronic lung disease (OR 1.3 [95% CI 1.1-1.7], p = 0.011), and history of heart failure (OR 3.5 [95% 1.1-8.2], p = 0.037).
CONCLUSIONS: EAT measures quantified from chest CT are independently associated with extent of pneumonia and adverse outcomes in patients with COVID-19, lending support to their use in clinical risk stratification.",0,1
32832047,Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach,"Mishra AK, Das SK, Roy P, Bandyopadhyay S.",J Healthc Eng. 2020 Aug 11;2020:8843664. doi: 10.1155/2020/8843664. eCollection 2020.,Mishra AK,J Healthc Eng,2020,25-08-2020,PMC7424536,,10.1155/2020/8843664,"Coronavirus Disease (COVID19) is a fast-spreading infectious disease that is currently causing a healthcare crisis around the world. Due to the current limitations of the reverse transcription-polymerase chain reaction (RT-PCR) based tests for detecting COVID19, recently radiology imaging based ideas have been proposed by various works. In this work, various Deep CNN based approaches are explored for detecting the presence of COVID19 from chest CT images. A decision fusion based approach is also proposed, which combines predictions from multiple individual models, to produce a final prediction. Experimental results show that the proposed decision fusion based approach is able to achieve above 86% results across all the performance metrics under consideration, with average AUROC and F1-Score being 0.883 and 0.867, respectively. The experimental observations suggest the potential applicability of such Deep CNN based approach in real diagnostic scenarios, which could be of very high utility in terms of achieving fast testing for COVID19.","Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach Coronavirus Disease (COVID19) is a fast-spreading infectious disease that is currently causing a healthcare crisis around the world. Due to the current limitations of the reverse transcription-polymerase chain reaction (RT-PCR) based tests for detecting COVID19, recently radiology imaging based ideas have been proposed by various works. In this work, various Deep CNN based approaches are explored for detecting the presence of COVID19 from chest CT images. A decision fusion based approach is also proposed, which combines predictions from multiple individual models, to produce a final prediction. Experimental results show that the proposed decision fusion based approach is able to achieve above 86% results across all the performance metrics under consideration, with average AUROC and F1-Score being 0.883 and 0.867, respectively. The experimental observations suggest the potential applicability of such Deep CNN based approach in real diagnostic scenarios, which could be of very high utility in terms of achieving fast testing for COVID19.",1,1
32750973,Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models,"Bridge J, Meng Y, Zhao Y, Du Y, Zhao M, Sun R, Zheng Y.",IEEE J Biomed Health Inform. 2020 Oct;24(10):2776-2786. doi: 10.1109/JBHI.2020.3012383. Epub 2020 Jul 28.,Bridge J,IEEE J Biomed Health Inform,2020,06-08-2020,PMC8545159,,10.1109/JBHI.2020.3012383,"Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.","Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.",1,0
36945456,Conserved cysteine residues in Kaposi's sarcoma herpesvirus ORF34 are necessary for viral production and viral pre-initiation complex formation,"Watanabe T, McGraw A, Narayan K, Tibebe H, Kuriyama K, Nishimura M, Izumi T, Fujimuro M, Ohno S.",bioRxiv [Preprint]. 2024 Jun 11:2023.03.08.531831. doi: 10.1101/2023.03.08.531831.,Watanabe T,bioRxiv,2024,22-03-2023,PMC10028899,,10.1101/2023.03.08.531831,"Kaposi's sarcoma herpesvirus (KSHV) ORF34 plays a significant role as a component of the viral pre-initiation complex (vPIC), which is indispensable for late gene expression across beta and gamma herpesviruses. Although the key role of ORF34 within the vPIC and its function as a hub protein have been recognized, further clarification regarding its specific contribution to vPIC functionality and interactions with other components is required. This study employed a deep-learning algorithm-assisted structural model of ORF34, revealing highly conserved amino acid residues across human beta- and gamma-herpesviruses localized in structured domains. Thus, we engineered ORF34 alanine-scanning mutants by substituting conserved residues with alanine. These mutants were evaluated for their ability to interact with other vPIC factors and restore viral production in cells harboring the ORF34-deficient KSHV-BAC. Our experimental results highlight the crucial role of the 4 cysteine residues conserved in ORF34: a tetrahedral arrangement consisting of a pair of C-X<sub>n</sub>-C consensus motifs. This suggests the potential incorporation of metal cations in interacting with ORF24 and ORF66 vPIC components, facilitating late gene transcription, and promoting overall virus production by capturing metal cations. In summary, our findings underline the essential role of conserved cysteines in KSHV ORF34 for effective vPIC assembly and viral replication, thereby enhancing our understanding of the complex interplay between the vPIC components.","Conserved cysteine residues in Kaposi's sarcoma herpesvirus ORF34 are necessary for viral production and viral pre-initiation complex formation Kaposi's sarcoma herpesvirus (KSHV) ORF34 plays a significant role as a component of the viral pre-initiation complex (vPIC), which is indispensable for late gene expression across beta and gamma herpesviruses. Although the key role of ORF34 within the vPIC and its function as a hub protein have been recognized, further clarification regarding its specific contribution to vPIC functionality and interactions with other components is required. This study employed a deep-learning algorithm-assisted structural model of ORF34, revealing highly conserved amino acid residues across human beta- and gamma-herpesviruses localized in structured domains. Thus, we engineered ORF34 alanine-scanning mutants by substituting conserved residues with alanine. These mutants were evaluated for their ability to interact with other vPIC factors and restore viral production in cells harboring the ORF34-deficient KSHV-BAC. Our experimental results highlight the crucial role of the 4 cysteine residues conserved in ORF34: a tetrahedral arrangement consisting of a pair of C-X<sub>n</sub>-C consensus motifs. This suggests the potential incorporation of metal cations in interacting with ORF24 and ORF66 vPIC components, facilitating late gene transcription, and promoting overall virus production by capturing metal cations. In summary, our findings underline the essential role of conserved cysteines in KSHV ORF34 for effective vPIC assembly and viral replication, thereby enhancing our understanding of the complex interplay between the vPIC components.",0,1
36147628,Artificial intelligence performance in image-based ovarian cancer identification: A systematic review and meta-analysis,"Xu HL, Gong TT, Liu FH, Chen HY, Xiao Q, Hou Y, Huang Y, Sun HZ, Shi Y, Gao S, Lou Y, Chang Q, Zhao YH, Gao QL, Wu QJ.",EClinicalMedicine. 2022 Sep 17;53:101662. doi: 10.1016/j.eclinm.2022.101662. eCollection 2022 Nov.,Xu HL,EClinicalMedicine,2022,23-09-2022,PMC9486055,,10.1016/j.eclinm.2022.101662,"BACKGROUND: Accurate identification of ovarian cancer (OC) is of paramount importance in clinical treatment success. Artificial intelligence (AI) is a potentially reliable assistant for the medical imaging recognition. We systematically review articles on the diagnostic performance of AI in OC from medical imaging for the first time.
METHODS: The Medline, Embase, IEEE, PubMed, Web of Science, and the Cochrane library databases were searched for related studies published until August 1, 2022. Inclusion criteria were studies that developed or used AI algorithms in the diagnosis of OC from medical images. The binary diagnostic accuracy data were extracted to derive the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022324611.
FINDINGS: Thirty-four eligible studies were identified, of which twenty-eight studies were included in the meta-analysis with a pooled SE of 88% (95%CI: 85-90%), SP of 85% (82-88%), and AUC of 0.93 (0.91-0.95). Analysis for different algorithms revealed a pooled SE of 89% (85-92%) and SP of 88% (82-92%) for machine learning; and a pooled SE of 88% (84-91%) and SP of 84% (80-87%) for deep learning. Acceptable diagnostic performance was demonstrated in subgroup analyses stratified by imaging modalities (Ultrasound, Magnetic Resonance Imaging, or Computed Tomography), sample size (≤300 or >300), AI algorithms versus clinicians, year of publication (before or after 2020), geographical distribution (Asia or non Asia), and the different risk of bias levels (≥3 domain low risk or < 3 domain low risk).
INTERPRETATION: AI algorithms exhibited favorable performance for the diagnosis of OC through medical imaging. More rigorous reporting standards that address specific challenges of AI research could improve future studies.
FUNDING: This work was supported by the Natural Science Foundation of China (No. 82073647 to Q-JW and No. 82103914 to T-TG), LiaoNing Revitalization Talents Program (No. XLYC1907102 to Q-JW), and 345 Talent Project of Shengjing Hospital of China Medical University (No. M0268 to Q-JW and No. M0952 to T-TG).","Artificial intelligence performance in image-based ovarian cancer identification: A systematic review and meta-analysis BACKGROUND: Accurate identification of ovarian cancer (OC) is of paramount importance in clinical treatment success. Artificial intelligence (AI) is a potentially reliable assistant for the medical imaging recognition. We systematically review articles on the diagnostic performance of AI in OC from medical imaging for the first time.
METHODS: The Medline, Embase, IEEE, PubMed, Web of Science, and the Cochrane library databases were searched for related studies published until August 1, 2022. Inclusion criteria were studies that developed or used AI algorithms in the diagnosis of OC from medical images. The binary diagnostic accuracy data were extracted to derive the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022324611.
FINDINGS: Thirty-four eligible studies were identified, of which twenty-eight studies were included in the meta-analysis with a pooled SE of 88% (95%CI: 85-90%), SP of 85% (82-88%), and AUC of 0.93 (0.91-0.95). Analysis for different algorithms revealed a pooled SE of 89% (85-92%) and SP of 88% (82-92%) for machine learning; and a pooled SE of 88% (84-91%) and SP of 84% (80-87%) for deep learning. Acceptable diagnostic performance was demonstrated in subgroup analyses stratified by imaging modalities (Ultrasound, Magnetic Resonance Imaging, or Computed Tomography), sample size (≤300 or >300), AI algorithms versus clinicians, year of publication (before or after 2020), geographical distribution (Asia or non Asia), and the different risk of bias levels (≥3 domain low risk or < 3 domain low risk).
INTERPRETATION: AI algorithms exhibited favorable performance for the diagnosis of OC through medical imaging. More rigorous reporting standards that address specific challenges of AI research could improve future studies.
FUNDING: This work was supported by the Natural Science Foundation of China (No. 82073647 to Q-JW and No. 82103914 to T-TG), LiaoNing Revitalization Talents Program (No. XLYC1907102 to Q-JW), and 345 Talent Project of Shengjing Hospital of China Medical University (No. M0268 to Q-JW and No. M0952 to T-TG).",1,0
38959500,Artificial Intelligence-Based Electrocardiographic Biomarker for Outcome Prediction in Patients With Acute Heart Failure: Prospective Cohort Study,"Cho Y, Yoon M, Kim J, Lee JH, Oh IY, Lee CJ, Kang SM, Choi DJ.",J Med Internet Res. 2024 Jul 3;26:e52139. doi: 10.2196/52139.,Cho Y,J Med Internet Res,2024,03-07-2024,PMC11255523,,10.2196/52139,"BACKGROUND: Although several biomarkers exist for patients with heart failure (HF), their use in routine clinical practice is often constrained by high costs and limited availability.
OBJECTIVE: We examined the utility of an artificial intelligence (AI) algorithm that analyzes printed electrocardiograms (ECGs) for outcome prediction in patients with acute HF.
METHODS: We retrospectively analyzed prospectively collected data of patients with acute HF at two tertiary centers in Korea. Baseline ECGs were analyzed using a deep-learning system called Quantitative ECG (QCG), which was trained to detect several urgent clinical conditions, including shock, cardiac arrest, and reduced left ventricular ejection fraction (LVEF).
RESULTS: Among the 1254 patients enrolled, in-hospital cardiac death occurred in 53 (4.2%) patients, and the QCG score for critical events (QCG-Critical) was significantly higher in these patients than in survivors (mean 0.57, SD 0.23 vs mean 0.29, SD 0.20; P<.001). The QCG-Critical score was an independent predictor of in-hospital cardiac death after adjustment for age, sex, comorbidities, HF etiology/type, atrial fibrillation, and QRS widening (adjusted odds ratio [OR] 1.68, 95% CI 1.47-1.92 per 0.1 increase; P<.001), and remained a significant predictor after additional adjustments for echocardiographic LVEF and N-terminal prohormone of brain natriuretic peptide level (adjusted OR 1.59, 95% CI 1.36-1.87 per 0.1 increase; P<.001). During long-term follow-up, patients with higher QCG-Critical scores (>0.5) had higher mortality rates than those with low QCG-Critical scores (<0.25) (adjusted hazard ratio 2.69, 95% CI 2.14-3.38; P<.001).
CONCLUSIONS: Predicting outcomes in patients with acute HF using the QCG-Critical score is feasible, indicating that this AI-based ECG score may be a novel biomarker for these patients.
TRIAL REGISTRATION: ClinicalTrials.gov NCT01389843; https://clinicaltrials.gov/study/NCT01389843.","Artificial Intelligence-Based Electrocardiographic Biomarker for Outcome Prediction in Patients With Acute Heart Failure: Prospective Cohort Study BACKGROUND: Although several biomarkers exist for patients with heart failure (HF), their use in routine clinical practice is often constrained by high costs and limited availability.
OBJECTIVE: We examined the utility of an artificial intelligence (AI) algorithm that analyzes printed electrocardiograms (ECGs) for outcome prediction in patients with acute HF.
METHODS: We retrospectively analyzed prospectively collected data of patients with acute HF at two tertiary centers in Korea. Baseline ECGs were analyzed using a deep-learning system called Quantitative ECG (QCG), which was trained to detect several urgent clinical conditions, including shock, cardiac arrest, and reduced left ventricular ejection fraction (LVEF).
RESULTS: Among the 1254 patients enrolled, in-hospital cardiac death occurred in 53 (4.2%) patients, and the QCG score for critical events (QCG-Critical) was significantly higher in these patients than in survivors (mean 0.57, SD 0.23 vs mean 0.29, SD 0.20; P<.001). The QCG-Critical score was an independent predictor of in-hospital cardiac death after adjustment for age, sex, comorbidities, HF etiology/type, atrial fibrillation, and QRS widening (adjusted odds ratio [OR] 1.68, 95% CI 1.47-1.92 per 0.1 increase; P<.001), and remained a significant predictor after additional adjustments for echocardiographic LVEF and N-terminal prohormone of brain natriuretic peptide level (adjusted OR 1.59, 95% CI 1.36-1.87 per 0.1 increase; P<.001). During long-term follow-up, patients with higher QCG-Critical scores (>0.5) had higher mortality rates than those with low QCG-Critical scores (<0.25) (adjusted hazard ratio 2.69, 95% CI 2.14-3.38; P<.001).
CONCLUSIONS: Predicting outcomes in patients with acute HF using the QCG-Critical score is feasible, indicating that this AI-based ECG score may be a novel biomarker for these patients.
TRIAL REGISTRATION: ClinicalTrials.gov NCT01389843; https://clinicaltrials.gov/study/NCT01389843.",0,0
38254941,Methodological Considerations in Longitudinal Analyses of Microbiome Data: A Comprehensive Review,"Lyu R, Qu Y, Divaris K, Wu D.",Genes (Basel). 2023 Dec 28;15(1):0. doi: 10.3390/genes15010051.,Lyu R,Genes (Basel),2023,23-01-2024,PMC11154524,,10.3390/genes15010051,"Biological processes underlying health and disease are inherently dynamic and are best understood when characterized in a time-informed manner. In this comprehensive review, we discuss challenges inherent in time-series microbiome data analyses and compare available approaches and methods to overcome them. Appropriate handling of longitudinal microbiome data can shed light on important roles, functions, patterns, and potential interactions between large numbers of microbial taxa or genes in the context of health, disease, or interventions. We present a comprehensive review and comparison of existing microbiome time-series analysis methods, for both preprocessing and downstream analyses, including differential analysis, clustering, network inference, and trait classification. We posit that the careful selection and appropriate utilization of computational tools for longitudinal microbiome analyses can help advance our understanding of the dynamic host-microbiome relationships that underlie health-maintaining homeostases, progressions to disease-promoting dysbioses, as well as phases of physiologic development like those encountered in childhood.","Methodological Considerations in Longitudinal Analyses of Microbiome Data: A Comprehensive Review Biological processes underlying health and disease are inherently dynamic and are best understood when characterized in a time-informed manner. In this comprehensive review, we discuss challenges inherent in time-series microbiome data analyses and compare available approaches and methods to overcome them. Appropriate handling of longitudinal microbiome data can shed light on important roles, functions, patterns, and potential interactions between large numbers of microbial taxa or genes in the context of health, disease, or interventions. We present a comprehensive review and comparison of existing microbiome time-series analysis methods, for both preprocessing and downstream analyses, including differential analysis, clustering, network inference, and trait classification. We posit that the careful selection and appropriate utilization of computational tools for longitudinal microbiome analyses can help advance our understanding of the dynamic host-microbiome relationships that underlie health-maintaining homeostases, progressions to disease-promoting dysbioses, as well as phases of physiologic development like those encountered in childhood.",0,0
33961583,Addressing Biodisaster X Threats With Artificial Intelligence and 6G Technologies: Literature Review and Critical Insights,"Su Z, McDonnell D, Bentley BL, He J, Shi F, Cheshmehzangi A, Ahmad J, Jia P.",J Med Internet Res. 2021 May 25;23(5):e26109. doi: 10.2196/26109.,Su Z,J Med Internet Res,2021,07-05-2021,PMC8153034,,10.2196/26109,"BACKGROUND: With advances in science and technology, biotechnology is becoming more accessible to people of all demographics. These advances inevitably hold the promise to improve personal and population well-being and welfare substantially. It is paradoxical that while greater access to biotechnology on a population level has many advantages, it may also increase the likelihood and frequency of biodisasters due to accidental or malicious use. Similar to ""Disease X"" (describing unknown naturally emerging pathogenic diseases with a pandemic potential), we term this unknown risk from biotechnologies ""Biodisaster X."" To date, no studies have examined the potential role of information technologies in preventing and mitigating Biodisaster X.
OBJECTIVE: This study aimed to explore (1) what Biodisaster X might entail and (2) solutions that use artificial intelligence (AI) and emerging 6G technologies to help monitor and manage Biodisaster X threats.
METHODS: A review of the literature on applying AI and 6G technologies for monitoring and managing biodisasters was conducted on PubMed, using articles published from database inception through to November 16, 2020.
RESULTS: Our findings show that Biodisaster X has the potential to upend lives and livelihoods and destroy economies, essentially posing a looming risk for civilizations worldwide. To shed light on Biodisaster X threats, we detailed effective AI and 6G-enabled strategies, ranging from natural language processing to deep learning-based image analysis to address issues ranging from early Biodisaster X detection (eg, identification of suspicious behaviors), remote design and development of pharmaceuticals (eg, treatment development), and public health interventions (eg, reactive shelter-at-home mandate enforcement), as well as disaster recovery (eg, sentiment analysis of social media posts to shed light on the public's feelings and readiness for recovery building).
CONCLUSIONS: Biodisaster X is a looming but avoidable catastrophe. Considering the potential human and economic consequences Biodisaster X could cause, actions that can effectively monitor and manage Biodisaster X threats must be taken promptly and proactively. Rather than solely depending on overstretched professional attention of health experts and government officials, it is perhaps more cost-effective and practical to deploy technology-based solutions to prevent and control Biodisaster X threats. This study discusses what Biodisaster X could entail and emphasizes the importance of monitoring and managing Biodisaster X threats by AI techniques and 6G technologies. Future studies could explore how the convergence of AI and 6G systems may further advance the preparedness for high-impact, less likely events beyond Biodisaster X.","Addressing Biodisaster X Threats With Artificial Intelligence and 6G Technologies: Literature Review and Critical Insights BACKGROUND: With advances in science and technology, biotechnology is becoming more accessible to people of all demographics. These advances inevitably hold the promise to improve personal and population well-being and welfare substantially. It is paradoxical that while greater access to biotechnology on a population level has many advantages, it may also increase the likelihood and frequency of biodisasters due to accidental or malicious use. Similar to ""Disease X"" (describing unknown naturally emerging pathogenic diseases with a pandemic potential), we term this unknown risk from biotechnologies ""Biodisaster X."" To date, no studies have examined the potential role of information technologies in preventing and mitigating Biodisaster X.
OBJECTIVE: This study aimed to explore (1) what Biodisaster X might entail and (2) solutions that use artificial intelligence (AI) and emerging 6G technologies to help monitor and manage Biodisaster X threats.
METHODS: A review of the literature on applying AI and 6G technologies for monitoring and managing biodisasters was conducted on PubMed, using articles published from database inception through to November 16, 2020.
RESULTS: Our findings show that Biodisaster X has the potential to upend lives and livelihoods and destroy economies, essentially posing a looming risk for civilizations worldwide. To shed light on Biodisaster X threats, we detailed effective AI and 6G-enabled strategies, ranging from natural language processing to deep learning-based image analysis to address issues ranging from early Biodisaster X detection (eg, identification of suspicious behaviors), remote design and development of pharmaceuticals (eg, treatment development), and public health interventions (eg, reactive shelter-at-home mandate enforcement), as well as disaster recovery (eg, sentiment analysis of social media posts to shed light on the public's feelings and readiness for recovery building).
CONCLUSIONS: Biodisaster X is a looming but avoidable catastrophe. Considering the potential human and economic consequences Biodisaster X could cause, actions that can effectively monitor and manage Biodisaster X threats must be taken promptly and proactively. Rather than solely depending on overstretched professional attention of health experts and government officials, it is perhaps more cost-effective and practical to deploy technology-based solutions to prevent and control Biodisaster X threats. This study discusses what Biodisaster X could entail and emphasizes the importance of monitoring and managing Biodisaster X threats by AI techniques and 6G technologies. Future studies could explore how the convergence of AI and 6G systems may further advance the preparedness for high-impact, less likely events beyond Biodisaster X.",0,1
35885449,Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review,"Suri JS, Maindarkar MA, Paul S, Ahluwalia P, Bhagawati M, Saba L, Faa G, Saxena S, Singh IM, Chadha PS, Turk M, Johri A, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou AD, Misra DP, Agarwal V, Kitas GD, Kolluri R, Teji JS, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Omerzu T, Naidu S, Nicolaides A, Paraskevas KI, Kalra M, Ruzsa Z, Fouda MM.",Diagnostics (Basel). 2022 Jun 24;12(7):1543. doi: 10.3390/diagnostics12071543.,Suri JS,Diagnostics (Basel),2022,27-07-2022,PMC9324237,,10.3390/diagnostics12071543,"Background and Motivation: Parkinson's disease (PD) is one of the most serious, non-curable, and expensive to treat. Recently, machine learning (ML) has shown to be able to predict cardiovascular/stroke risk in PD patients. The presence of COVID-19 causes the ML systems to become severely non-linear and poses challenges in cardiovascular/stroke risk stratification. Further, due to comorbidity, sample size constraints, and poor scientific and clinical validation techniques, there have been no well-explained ML paradigms. Deep neural networks are powerful learning machines that generalize non-linear conditions. This study presents a novel investigation of deep learning (DL) solutions for CVD/stroke risk prediction in PD patients affected by the COVID-19 framework. Method: The PRISMA search strategy was used for the selection of 292 studies closely associated with the effect of PD on CVD risk in the COVID-19 framework. We study the hypothesis that PD in the presence of COVID-19 can cause more harm to the heart and brain than in non-COVID-19 conditions. COVID-19 lung damage severity can be used as a covariate during DL training model designs. We, therefore, propose a DL model for the estimation of, (i) COVID-19 lesions in computed tomography (CT) scans and (ii) combining the covariates of PD, COVID-19 lesions, office and laboratory arterial atherosclerotic image-based biomarkers, and medicine usage for the PD patients for the design of DL point-based models for CVD/stroke risk stratification. Results: We validated the feasibility of CVD/stroke risk stratification in PD patients in the presence of a COVID-19 environment and this was also verified. DL architectures like long short-term memory (LSTM), and recurrent neural network (RNN) were studied for CVD/stroke risk stratification showing powerful designs. Lastly, we examined the artificial intelligence bias and provided recommendations for early detection of CVD/stroke in PD patients in the presence of COVID-19. Conclusion: The DL is a very powerful tool for predicting CVD/stroke risk in PD patients affected by COVID-19.","Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review Background and Motivation: Parkinson's disease (PD) is one of the most serious, non-curable, and expensive to treat. Recently, machine learning (ML) has shown to be able to predict cardiovascular/stroke risk in PD patients. The presence of COVID-19 causes the ML systems to become severely non-linear and poses challenges in cardiovascular/stroke risk stratification. Further, due to comorbidity, sample size constraints, and poor scientific and clinical validation techniques, there have been no well-explained ML paradigms. Deep neural networks are powerful learning machines that generalize non-linear conditions. This study presents a novel investigation of deep learning (DL) solutions for CVD/stroke risk prediction in PD patients affected by the COVID-19 framework. Method: The PRISMA search strategy was used for the selection of 292 studies closely associated with the effect of PD on CVD risk in the COVID-19 framework. We study the hypothesis that PD in the presence of COVID-19 can cause more harm to the heart and brain than in non-COVID-19 conditions. COVID-19 lung damage severity can be used as a covariate during DL training model designs. We, therefore, propose a DL model for the estimation of, (i) COVID-19 lesions in computed tomography (CT) scans and (ii) combining the covariates of PD, COVID-19 lesions, office and laboratory arterial atherosclerotic image-based biomarkers, and medicine usage for the PD patients for the design of DL point-based models for CVD/stroke risk stratification. Results: We validated the feasibility of CVD/stroke risk stratification in PD patients in the presence of a COVID-19 environment and this was also verified. DL architectures like long short-term memory (LSTM), and recurrent neural network (RNN) were studied for CVD/stroke risk stratification showing powerful designs. Lastly, we examined the artificial intelligence bias and provided recommendations for early detection of CVD/stroke in PD patients in the presence of COVID-19. Conclusion: The DL is a very powerful tool for predicting CVD/stroke risk in PD patients affected by COVID-19.",1,1
35078755,"Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery","Abubaker Bagabir S, Ibrahim NK, Abubaker Bagabir H, Hashem Ateeq R.",J Infect Public Health. 2022 Feb;15(2):289-296. doi: 10.1016/j.jiph.2022.01.011. Epub 2022 Jan 19.,Abubaker Bagabir S,J Infect Public Health,2022,26-01-2022,PMC8767913,,10.1016/j.jiph.2022.01.011,"OBJECTIVES: To clarify the work done by using AI for identifying the genomic sequences, development of drugs and vaccines for COVID-19 and to recognize the advantages and challenges of using such technology.
METHODS: A non-systematic review was done. All articles published on Pub-Med, Medline, Google, and Google Scholar on AI or digital health regarding genomic sequencing, drug development, and vaccines of COVID-19 were scrutinized and summarized.
RESULTS: The sequence of SARS- CoV-2 was identified with the help of AI. It can help also in the prompt identification of variants of concern (VOC) as delta strains and Omicron. Furthermore, there are many drugs applied with the help of AI. These drugs included Atazanavir, Remdesivir, Efavirenz, Ritonavir, and Dolutegravir, PARP1 inhibitors (Olaparib and CVL218 which is Mefuparib hydrochloride), Abacavir, Roflumilast, Almitrine, and Mesylate. Many vaccines were developed utilizing the new technology of bioinformatics, databases, immune-informatics, machine learning, and reverse vaccinology to the whole SARS-CoV-2 proteomes or the structural proteins. Examples of these vaccines are the messenger RNA and viral vector vaccines. AI provides cost-saving and agility. However, the challenges of its usage are the difficulty of collecting data, the internal and external validation, ethical consideration, therapeutic effect, and the time needed for clinical trials after drug approval. Moreover, there is a common problem in the deep learning (DL) model which is the shortage of interpretability.
CONCLUSION: The growth of AI techniques in health care opened a broad gate for discovering the genomic sequences of the COVID-19 virus and the VOC. AI helps also in the development of vaccines and drugs (including drug repurposing) to obtain potential preventive and therapeutic agents for controlling the COVID-19 pandemic.","Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery OBJECTIVES: To clarify the work done by using AI for identifying the genomic sequences, development of drugs and vaccines for COVID-19 and to recognize the advantages and challenges of using such technology.
METHODS: A non-systematic review was done. All articles published on Pub-Med, Medline, Google, and Google Scholar on AI or digital health regarding genomic sequencing, drug development, and vaccines of COVID-19 were scrutinized and summarized.
RESULTS: The sequence of SARS- CoV-2 was identified with the help of AI. It can help also in the prompt identification of variants of concern (VOC) as delta strains and Omicron. Furthermore, there are many drugs applied with the help of AI. These drugs included Atazanavir, Remdesivir, Efavirenz, Ritonavir, and Dolutegravir, PARP1 inhibitors (Olaparib and CVL218 which is Mefuparib hydrochloride), Abacavir, Roflumilast, Almitrine, and Mesylate. Many vaccines were developed utilizing the new technology of bioinformatics, databases, immune-informatics, machine learning, and reverse vaccinology to the whole SARS-CoV-2 proteomes or the structural proteins. Examples of these vaccines are the messenger RNA and viral vector vaccines. AI provides cost-saving and agility. However, the challenges of its usage are the difficulty of collecting data, the internal and external validation, ethical consideration, therapeutic effect, and the time needed for clinical trials after drug approval. Moreover, there is a common problem in the deep learning (DL) model which is the shortage of interpretability.
CONCLUSION: The growth of AI techniques in health care opened a broad gate for discovering the genomic sequences of the COVID-19 virus and the VOC. AI helps also in the development of vaccines and drugs (including drug repurposing) to obtain potential preventive and therapeutic agents for controlling the COVID-19 pandemic.",1,1
33714840,Machine learning models to predict electroencephalographic seizures in critically ill children,"Hu J, Fung FW, Jacobwitz M, Parikh DS, Vala L, Donnelly M, Topjian AA, Abend NS, Xiao R.",Seizure. 2021 Apr;87:61-68. doi: 10.1016/j.seizure.2021.03.001. Epub 2021 Mar 4.,Hu J,Seizure,2021,14-03-2021,PMC8044039,NIHMS1685129,10.1016/j.seizure.2021.03.001,"OBJECTIVE: To determine whether machine learning techniques would enhance our ability to incorporate key variables into a parsimonious model with optimized prediction performance for electroencephalographic seizure (ES) prediction in critically ill children.
METHODS: We analyzed data from a prospective observational cohort study of 719 consecutive critically ill children with encephalopathy who underwent clinically-indicated continuous EEG monitoring (CEEG). We implemented and compared three state-of-the-art machine learning methods for ES prediction: (1) random forest; (2) Least Absolute Shrinkage and Selection Operator (LASSO); and (3) Deep Learning Important FeaTures (DeepLIFT). We developed a ranking algorithm based on the relative importance of each variable derived from the machine learning methods.
RESULTS: Based on our ranking algorithm, the top five variables for ES prediction were: (1) epileptiform discharges in the initial 30 minutes, (2) clinical seizures prior to CEEG initiation, (3) sex, (4) age dichotomized at 1 year, and (5) epileptic encephalopathy. Compared to the stepwise selection-based approach in logistic regression, the top variables selected by our ranking algorithm were more informative as models utilizing the top variables achieved better prediction performance evaluated by prediction accuracy, AUROC and F1 score. Adding additional variables did not improve and sometimes worsened model performance.
CONCLUSION: The ranking algorithm was helpful in deriving a parsimonious model for ES prediction with optimal performance. However, application of state-of-the-art machine learning models did not substantially improve model performance compared to prior logistic regression models. Thus, to further improve the ES prediction, we may need to collect more samples and variables that provide additional information.","Machine learning models to predict electroencephalographic seizures in critically ill children OBJECTIVE: To determine whether machine learning techniques would enhance our ability to incorporate key variables into a parsimonious model with optimized prediction performance for electroencephalographic seizure (ES) prediction in critically ill children.
METHODS: We analyzed data from a prospective observational cohort study of 719 consecutive critically ill children with encephalopathy who underwent clinically-indicated continuous EEG monitoring (CEEG). We implemented and compared three state-of-the-art machine learning methods for ES prediction: (1) random forest; (2) Least Absolute Shrinkage and Selection Operator (LASSO); and (3) Deep Learning Important FeaTures (DeepLIFT). We developed a ranking algorithm based on the relative importance of each variable derived from the machine learning methods.
RESULTS: Based on our ranking algorithm, the top five variables for ES prediction were: (1) epileptiform discharges in the initial 30 minutes, (2) clinical seizures prior to CEEG initiation, (3) sex, (4) age dichotomized at 1 year, and (5) epileptic encephalopathy. Compared to the stepwise selection-based approach in logistic regression, the top variables selected by our ranking algorithm were more informative as models utilizing the top variables achieved better prediction performance evaluated by prediction accuracy, AUROC and F1 score. Adding additional variables did not improve and sometimes worsened model performance.
CONCLUSION: The ranking algorithm was helpful in deriving a parsimonious model for ES prediction with optimal performance. However, application of state-of-the-art machine learning models did not substantially improve model performance compared to prior logistic regression models. Thus, to further improve the ES prediction, we may need to collect more samples and variables that provide additional information.",0,0
38081870,Identifying primary aldosteronism patients who require adrenal venous sampling: a multi-center study﻿,"Kitamoto T, Idé T, Tezuka Y, Wada N, Shibayama Y, Tsurutani Y, Takiguchi T, Inoue K, Suematsu S, Omata K, Ono Y, Morimoto R, Yamazaki Y, Saito J, Sasano H, Satoh F, Nishikawa T.",Sci Rep. 2023 Dec 11;13(1):21722. doi: 10.1038/s41598-023-47967-z.,Kitamoto T,Sci Rep,2023,11-12-2023,PMC10713522,,10.1038/s41598-023-47967-z,"Adrenal venous sampling (AVS) is crucial for subtyping primary aldosteronism (PA) to explore the possibility of curing hypertension. Because AVS availability is limited, efforts have been made to develop strategies to bypass it. However, it has so far proven unsuccessful in applying clinical practice, partly due to heterogeneity and missing values of the cohorts. For this purpose, we retrospectively assessed 210 PA cases from three institutions where segment-selective AVS, which is more accurate and sensitive for detecting PA cases with surgical indications, was available. A machine learning-based classification model featuring a new cross-center domain adaptation capability was developed. The model identified 102 patients with PA who benefited from surgery in the present cohort. A new data imputation technique was used to address cross-center heterogeneity, making a common prediction model applicable across multiple cohorts. Logistic regression demonstrated higher accuracy than Random Forest and Deep Learning [(0.89, 0.86) vs. (0.84, 0.84), (0.82, 0.84) for surgical or medical indications in terms of f-score]. A derived integrated flowchart revealed that 35.2% of PA cases required AVS with 94.1% accuracy. The present model enabled us to reduce the burden of AVS on patients who would benefit the most.","Identifying primary aldosteronism patients who require adrenal venous sampling: a multi-center study﻿ Adrenal venous sampling (AVS) is crucial for subtyping primary aldosteronism (PA) to explore the possibility of curing hypertension. Because AVS availability is limited, efforts have been made to develop strategies to bypass it. However, it has so far proven unsuccessful in applying clinical practice, partly due to heterogeneity and missing values of the cohorts. For this purpose, we retrospectively assessed 210 PA cases from three institutions where segment-selective AVS, which is more accurate and sensitive for detecting PA cases with surgical indications, was available. A machine learning-based classification model featuring a new cross-center domain adaptation capability was developed. The model identified 102 patients with PA who benefited from surgery in the present cohort. A new data imputation technique was used to address cross-center heterogeneity, making a common prediction model applicable across multiple cohorts. Logistic regression demonstrated higher accuracy than Random Forest and Deep Learning [(0.89, 0.86) vs. (0.84, 0.84), (0.82, 0.84) for surgical or medical indications in terms of f-score]. A derived integrated flowchart revealed that 35.2% of PA cases required AVS with 94.1% accuracy. The present model enabled us to reduce the burden of AVS on patients who would benefit the most.",0,0
31479448,A systematic review of the diagnostic accuracy of artificial intelligence-based computer programs to analyze chest x-rays for pulmonary tuberculosis,"Harris M, Qi A, Jeagal L, Torabi N, Menzies D, Korobitsyn A, Pai M, Nathavitharana RR, Ahmad Khan F.",PLoS One. 2019 Sep 3;14(9):e0221339. doi: 10.1371/journal.pone.0221339. eCollection 2019.,Harris M,PLoS One,2019,04-09-2019,PMC6719854,,10.1371/journal.pone.0221339,"We undertook a systematic review of the diagnostic accuracy of artificial intelligence-based software for identification of radiologic abnormalities (computer-aided detection, or CAD) compatible with pulmonary tuberculosis on chest x-rays (CXRs). We searched four databases for articles published between January 2005-February 2019. We summarized data on CAD type, study design, and diagnostic accuracy. We assessed risk of bias with QUADAS-2. We included 53 of the 4712 articles reviewed: 40 focused on CAD design methods (""Development"" studies) and 13 focused on evaluation of CAD (""Clinical"" studies). Meta-analyses were not performed due to methodological differences. Development studies were more likely to use CXR databases with greater potential for bias as compared to Clinical studies. Areas under the receiver operating characteristic curve (median AUC [IQR]) were significantly higher: in Development studies AUC: 0.88 [0.82-0.90]) versus Clinical studies (0.75 [0.66-0.87]; p-value 0.004); and with deep-learning (0.91 [0.88-0.99]) versus machine-learning (0.82 [0.75-0.89]; p = 0.001). We conclude that CAD programs are promising, but the majority of work thus far has been on development rather than clinical evaluation. We provide concrete suggestions on what study design elements should be improved.","A systematic review of the diagnostic accuracy of artificial intelligence-based computer programs to analyze chest x-rays for pulmonary tuberculosis We undertook a systematic review of the diagnostic accuracy of artificial intelligence-based software for identification of radiologic abnormalities (computer-aided detection, or CAD) compatible with pulmonary tuberculosis on chest x-rays (CXRs). We searched four databases for articles published between January 2005-February 2019. We summarized data on CAD type, study design, and diagnostic accuracy. We assessed risk of bias with QUADAS-2. We included 53 of the 4712 articles reviewed: 40 focused on CAD design methods (""Development"" studies) and 13 focused on evaluation of CAD (""Clinical"" studies). Meta-analyses were not performed due to methodological differences. Development studies were more likely to use CXR databases with greater potential for bias as compared to Clinical studies. Areas under the receiver operating characteristic curve (median AUC [IQR]) were significantly higher: in Development studies AUC: 0.88 [0.82-0.90]) versus Clinical studies (0.75 [0.66-0.87]; p-value 0.004); and with deep-learning (0.91 [0.88-0.99]) versus machine-learning (0.82 [0.75-0.89]; p = 0.001). We conclude that CAD programs are promising, but the majority of work thus far has been on development rather than clinical evaluation. We provide concrete suggestions on what study design elements should be improved.",0,1
34146566,Mucosal Biofilms Are an Endoscopic Feature of Irritable Bowel Syndrome and Ulcerative Colitis,"Baumgartner M, Lang M, Holley H, Crepaz D, Hausmann B, Pjevac P, Moser D, Haller F, Hof F, Beer A, Orgler E, Frick A, Khare V, Evstatiev R, Strohmaier S, Primas C, Dolak W, Köcher T, Klavins K, Rath T, Neurath MF, Berry D, Makristathis A, Muttenthaler M, Gasche C.",Gastroenterology. 2021 Oct;161(4):1245-1256.e20. doi: 10.1053/j.gastro.2021.06.024. Epub 2021 Jun 17.,Baumgartner M,Gastroenterology,2021,19-06-2021,PMC8527885,,10.1053/j.gastro.2021.06.024,"BACKGROUND & AIMS: Irritable bowel syndrome (IBS) and inflammatory bowel diseases result in a substantial reduction in quality of life and a considerable socioeconomic impact. In IBS, diagnosis and treatment options are limited, but evidence for involvement of the gut microbiome in disease pathophysiology is emerging. Here we analyzed the prevalence of endoscopically visible mucosal biofilms in gastrointestinal disease and associated changes in microbiome composition and metabolism.
METHODS: The presence of mucosal biofilms was assessed in 1426 patients at 2 European university-based endoscopy centers. One-hundred and seventeen patients were selected for in-depth molecular and microscopic analysis using 16S ribosomal RNA gene amplicon-sequencing of colonic biopsies and fecal samples, confocal microscopy with deep learning-based image analysis, scanning electron microscopy, metabolomics, and in vitro biofilm formation assays.
RESULTS: Biofilms were present in 57% of patients with IBS and 34% of patients with ulcerative colitis compared with 6% of controls (P < .001). These yellow-green adherent layers of the ileum and right-sided colon were microscopically confirmed to be dense bacterial biofilms. 16S-sequencing links the presence of biofilms to a dysbiotic gut microbiome, including overgrowth of Escherichia coli and Ruminococcus gnavus. R. gnavus isolates cultivated from patient biofilms also formed biofilms in vitro. Metabolomic analysis found an accumulation of bile acids within biofilms that correlated with fecal bile acid excretion, linking this phenotype with a mechanism of diarrhea.
CONCLUSIONS: The presence of mucosal biofilms is an endoscopic feature in a subgroup of IBS and ulcerative colitis with disrupted bile acid metabolism and bacterial dysbiosis. They provide novel insight into the pathophysiology of IBS and ulcerative colitis, illustrating that biofilm can be seen as a tipping point in the development of dysbiosis and disease.","Mucosal Biofilms Are an Endoscopic Feature of Irritable Bowel Syndrome and Ulcerative Colitis BACKGROUND & AIMS: Irritable bowel syndrome (IBS) and inflammatory bowel diseases result in a substantial reduction in quality of life and a considerable socioeconomic impact. In IBS, diagnosis and treatment options are limited, but evidence for involvement of the gut microbiome in disease pathophysiology is emerging. Here we analyzed the prevalence of endoscopically visible mucosal biofilms in gastrointestinal disease and associated changes in microbiome composition and metabolism.
METHODS: The presence of mucosal biofilms was assessed in 1426 patients at 2 European university-based endoscopy centers. One-hundred and seventeen patients were selected for in-depth molecular and microscopic analysis using 16S ribosomal RNA gene amplicon-sequencing of colonic biopsies and fecal samples, confocal microscopy with deep learning-based image analysis, scanning electron microscopy, metabolomics, and in vitro biofilm formation assays.
RESULTS: Biofilms were present in 57% of patients with IBS and 34% of patients with ulcerative colitis compared with 6% of controls (P < .001). These yellow-green adherent layers of the ileum and right-sided colon were microscopically confirmed to be dense bacterial biofilms. 16S-sequencing links the presence of biofilms to a dysbiotic gut microbiome, including overgrowth of Escherichia coli and Ruminococcus gnavus. R. gnavus isolates cultivated from patient biofilms also formed biofilms in vitro. Metabolomic analysis found an accumulation of bile acids within biofilms that correlated with fecal bile acid excretion, linking this phenotype with a mechanism of diarrhea.
CONCLUSIONS: The presence of mucosal biofilms is an endoscopic feature in a subgroup of IBS and ulcerative colitis with disrupted bile acid metabolism and bacterial dysbiosis. They provide novel insight into the pathophysiology of IBS and ulcerative colitis, illustrating that biofilm can be seen as a tipping point in the development of dysbiosis and disease.",0,0
34151987,The application of artificial intelligence and data integration in COVID-19 studies: a scoping review,"Guo Y, Zhang Y, Lyu T, Prosperi M, Wang F, Xu H, Bian J.",J Am Med Inform Assoc. 2021 Aug 13;28(9):2050-2067. doi: 10.1093/jamia/ocab098.,Guo Y,J Am Med Inform Assoc,2021,21-06-2021,PMC8344463,,10.1093/jamia/ocab098,"OBJECTIVE: To summarize how artificial intelligence (AI) is being applied in COVID-19 research and determine whether these AI applications integrated heterogenous data from different sources for modeling.
MATERIALS AND METHODS: We searched 2 major COVID-19 literature databases, the National Institutes of Health's LitCovid and the World Health Organization's COVID-19 database on March 9, 2021. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline, 2 reviewers independently reviewed all the articles in 2 rounds of screening.
RESULTS: In the 794 studies included in the final qualitative analysis, we identified 7 key COVID-19 research areas in which AI was applied, including disease forecasting, medical imaging-based diagnosis and prognosis, early detection and prognosis (non-imaging), drug repurposing and early drug discovery, social media data analysis, genomic, transcriptomic, and proteomic data analysis, and other COVID-19 research topics. We also found that there was a lack of heterogenous data integration in these AI applications.
DISCUSSION: Risk factors relevant to COVID-19 outcomes exist in heterogeneous data sources, including electronic health records, surveillance systems, sociodemographic datasets, and many more. However, most AI applications in COVID-19 research adopted a single-sourced approach that could omit important risk factors and thus lead to biased algorithms. Integrating heterogeneous data for modeling will help realize the full potential of AI algorithms, improve precision, and reduce bias.
CONCLUSION: There is a lack of data integration in the AI applications in COVID-19 research and a need for a multilevel AI framework that supports the analysis of heterogeneous data from different sources.","The application of artificial intelligence and data integration in COVID-19 studies: a scoping review OBJECTIVE: To summarize how artificial intelligence (AI) is being applied in COVID-19 research and determine whether these AI applications integrated heterogenous data from different sources for modeling.
MATERIALS AND METHODS: We searched 2 major COVID-19 literature databases, the National Institutes of Health's LitCovid and the World Health Organization's COVID-19 database on March 9, 2021. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline, 2 reviewers independently reviewed all the articles in 2 rounds of screening.
RESULTS: In the 794 studies included in the final qualitative analysis, we identified 7 key COVID-19 research areas in which AI was applied, including disease forecasting, medical imaging-based diagnosis and prognosis, early detection and prognosis (non-imaging), drug repurposing and early drug discovery, social media data analysis, genomic, transcriptomic, and proteomic data analysis, and other COVID-19 research topics. We also found that there was a lack of heterogenous data integration in these AI applications.
DISCUSSION: Risk factors relevant to COVID-19 outcomes exist in heterogeneous data sources, including electronic health records, surveillance systems, sociodemographic datasets, and many more. However, most AI applications in COVID-19 research adopted a single-sourced approach that could omit important risk factors and thus lead to biased algorithms. Integrating heterogeneous data for modeling will help realize the full potential of AI algorithms, improve precision, and reduce bias.
CONCLUSION: There is a lack of data integration in the AI applications in COVID-19 research and a need for a multilevel AI framework that supports the analysis of heterogeneous data from different sources.",0,1
32616597,Development of a clinical decision support system for severity risk prediction and triage of COVID-19 patients at hospital admission: an international multicentre study,"Wu G, Yang P, Xie Y, Woodruff HC, Rao X, Guiot J, Frix AN, Louis R, Moutschen M, Li J, Li J, Yan C, Du D, Zhao S, Ding Y, Liu B, Sun W, Albarello F, D'Abramo A, Schininà V, Nicastri E, Occhipinti M, Barisione G, Barisione E, Halilaj I, Lovinfosse P, Wang X, Wu J, Lambin P.",Eur Respir J. 2020 Aug 20;56(2):2001104. doi: 10.1183/13993003.01104-2020. Print 2020 Aug.,Wu G,Eur Respir J,2020,04-07-2020,PMC7331655,,10.1183/13993003.01104-2020,"BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) has globally strained medical resources and caused significant mortality.
OBJECTIVE: To develop and validate a machine-learning model based on clinical features for severity risk assessment and triage for COVID-19 patients at hospital admission.
METHOD: 725 patients were used to train and validate the model. This included a retrospective cohort from Wuhan, China of 299 hospitalised COVID-19 patients from 23 December 2019 to 13 February 2020, and five cohorts with 426 patients from eight centres in China, Italy and Belgium from 20 February 2020 to 21 March 2020. The main outcome was the onset of severe or critical illness during hospitalisation. Model performances were quantified using the area under the receiver operating characteristic curve (AUC) and metrics derived from the confusion matrix.
RESULTS: In the retrospective cohort, the median age was 50 years and 137 (45.8%) were male. In the five test cohorts, the median age was 62 years and 236 (55.4%) were male. The model was prospectively validated on five cohorts yielding AUCs ranging from 0.84 to 0.93, with accuracies ranging from 74.4% to 87.5%, sensitivities ranging from 75.0% to 96.9%, and specificities ranging from 55.0% to 88.0%, most of which performed better than the pneumonia severity index. The cut-off values of the low-, medium- and high-risk probabilities were 0.21 and 0.80. The online calculators can be found at www.covid19risk.ai.
CONCLUSION: The machine-learning model, nomogram and online calculator might be useful to access the onset of severe and critical illness among COVID-19 patients and triage at hospital admission.","Development of a clinical decision support system for severity risk prediction and triage of COVID-19 patients at hospital admission: an international multicentre study BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) has globally strained medical resources and caused significant mortality.
OBJECTIVE: To develop and validate a machine-learning model based on clinical features for severity risk assessment and triage for COVID-19 patients at hospital admission.
METHOD: 725 patients were used to train and validate the model. This included a retrospective cohort from Wuhan, China of 299 hospitalised COVID-19 patients from 23 December 2019 to 13 February 2020, and five cohorts with 426 patients from eight centres in China, Italy and Belgium from 20 February 2020 to 21 March 2020. The main outcome was the onset of severe or critical illness during hospitalisation. Model performances were quantified using the area under the receiver operating characteristic curve (AUC) and metrics derived from the confusion matrix.
RESULTS: In the retrospective cohort, the median age was 50 years and 137 (45.8%) were male. In the five test cohorts, the median age was 62 years and 236 (55.4%) were male. The model was prospectively validated on five cohorts yielding AUCs ranging from 0.84 to 0.93, with accuracies ranging from 74.4% to 87.5%, sensitivities ranging from 75.0% to 96.9%, and specificities ranging from 55.0% to 88.0%, most of which performed better than the pneumonia severity index. The cut-off values of the low-, medium- and high-risk probabilities were 0.21 and 0.80. The online calculators can be found at www.covid19risk.ai.
CONCLUSION: The machine-learning model, nomogram and online calculator might be useful to access the onset of severe and critical illness among COVID-19 patients and triage at hospital admission.",1,0
38617272,Single-cell image-based genetic screens systematically identify regulators of Ebola virus subcellular infection dynamics,"Carlson RJ, Patten JJ, Stefanakis G, Soong BY, Radhakrishnan A, Singh A, Thakur N, Amarasinghe GK, Hacohen N, Basler CF, Leung D, Uhler C, Davey RA, Blainey PC.",bioRxiv [Preprint]. 2024 Apr 7:2024.04.06.588168. doi: 10.1101/2024.04.06.588168.,Carlson RJ,bioRxiv,2024,15-04-2024,PMC11014611,,10.1101/2024.04.06.588168,"Ebola virus (EBOV) is a high-consequence filovirus that gives rise to frequent epidemics with high case fatality rates and few therapeutic options. Here, we applied image-based screening of a genome-wide CRISPR library to systematically identify host cell regulators of Ebola virus infection in 39,085,093 million single cells. Measuring viral RNA and protein levels together with their localization in cells identified over 998 related host factors and provided detailed information about the role of each gene across the virus replication cycle. We trained a deep learning model on single-cell images to associate each host factor with predicted replication steps, and confirmed the predicted relationship for select host factors. Among the findings, we showed that the mitochondrial complex III subunit UQCRB is a post-entry regulator of Ebola virus RNA replication, and demonstrated that UQCRB inhibition with a small molecule reduced overall Ebola virus infection with an IC50 of 5 μM. Using a random forest model, we also identified perturbations that reduced infection by disrupting the equilibrium between viral RNA and protein. One such protein, STRAP, is a spliceosome-associated factor that was found to be closely associated with VP35, a viral protein required for RNA processing. Loss of STRAP expression resulted in a reduction in full-length viral genome production and subsequent production of non-infectious virus particles. Overall, the data produced in this genome-wide high-content single-cell screen and secondary screens in additional cell lines and related filoviruses (MARV and SUDV) revealed new insights about the role of host factors in virus replication and potential new targets for therapeutic intervention.","Single-cell image-based genetic screens systematically identify regulators of Ebola virus subcellular infection dynamics Ebola virus (EBOV) is a high-consequence filovirus that gives rise to frequent epidemics with high case fatality rates and few therapeutic options. Here, we applied image-based screening of a genome-wide CRISPR library to systematically identify host cell regulators of Ebola virus infection in 39,085,093 million single cells. Measuring viral RNA and protein levels together with their localization in cells identified over 998 related host factors and provided detailed information about the role of each gene across the virus replication cycle. We trained a deep learning model on single-cell images to associate each host factor with predicted replication steps, and confirmed the predicted relationship for select host factors. Among the findings, we showed that the mitochondrial complex III subunit UQCRB is a post-entry regulator of Ebola virus RNA replication, and demonstrated that UQCRB inhibition with a small molecule reduced overall Ebola virus infection with an IC50 of 5 μM. Using a random forest model, we also identified perturbations that reduced infection by disrupting the equilibrium between viral RNA and protein. One such protein, STRAP, is a spliceosome-associated factor that was found to be closely associated with VP35, a viral protein required for RNA processing. Loss of STRAP expression resulted in a reduction in full-length viral genome production and subsequent production of non-infectious virus particles. Overall, the data produced in this genome-wide high-content single-cell screen and secondary screens in additional cell lines and related filoviruses (MARV and SUDV) revealed new insights about the role of host factors in virus replication and potential new targets for therapeutic intervention.",0,0
38798507,Deconvolution of polygenic risk score in single cells unravels cellular and molecular heterogeneity of complex human diseases,"Zhang S, Shu H, Zhou J, Rubin-Sigler J, Yang X, Liu Y, Cooper-Knock J, Monte E, Zhu C, Tu S, Li H, Tong M, Ecker JR, Ichida JK, Shen Y, Zeng J, Tsao PS, Snyder MP.",bioRxiv [Preprint]. 2024 May 14:2024.05.14.594252. doi: 10.1101/2024.05.14.594252.,Zhang S,bioRxiv,2024,27-05-2024,PMC11118500,,10.1101/2024.05.14.594252,"Polygenic risk scores (PRSs) are commonly used for predicting an individual's genetic risk of complex diseases. Yet, their implication for disease pathogenesis remains largely limited. Here, we introduce scPRS, a geometric deep learning model that constructs single-cell-resolved PRS leveraging reference single-cell chromatin accessibility profiling data to enhance biological discovery as well as disease prediction. Real-world applications across multiple complex diseases, including type 2 diabetes (T2D), hypertrophic cardiomyopathy (HCM), and Alzheimer's disease (AD), showcase the superior prediction power of scPRS compared to traditional PRS methods. Importantly, scPRS not only predicts disease risk but also uncovers disease-relevant cells, such as hormone-high alpha and beta cells for T2D, cardiomyocytes and pericytes for HCM, and astrocytes, microglia and oligodendrocyte progenitor cells for AD. Facilitated by a layered multi-omic analysis, scPRS further identifies cell-type-specific genetic underpinnings, linking disease-associated genetic variants to gene regulation within corresponding cell types. We substantiate the disease relevance of scPRS-prioritized HCM genes and demonstrate that the suppression of these genes in HCM cardiomyocytes is rescued by Mavacamten treatment. Additionally, we establish a novel microglia-specific regulatory relationship between the AD risk variant rs7922621 and its target genes ANXA11 and TSPAN14. We further illustrate the detrimental effects of suppressing these two genes on microglia phagocytosis. Our work provides a multi-tasking, interpretable framework for precise disease prediction and systematic investigation of the genetic, cellular, and molecular basis of complex diseases, laying the methodological foundation for single-cell genetics.","Deconvolution of polygenic risk score in single cells unravels cellular and molecular heterogeneity of complex human diseases Polygenic risk scores (PRSs) are commonly used for predicting an individual's genetic risk of complex diseases. Yet, their implication for disease pathogenesis remains largely limited. Here, we introduce scPRS, a geometric deep learning model that constructs single-cell-resolved PRS leveraging reference single-cell chromatin accessibility profiling data to enhance biological discovery as well as disease prediction. Real-world applications across multiple complex diseases, including type 2 diabetes (T2D), hypertrophic cardiomyopathy (HCM), and Alzheimer's disease (AD), showcase the superior prediction power of scPRS compared to traditional PRS methods. Importantly, scPRS not only predicts disease risk but also uncovers disease-relevant cells, such as hormone-high alpha and beta cells for T2D, cardiomyocytes and pericytes for HCM, and astrocytes, microglia and oligodendrocyte progenitor cells for AD. Facilitated by a layered multi-omic analysis, scPRS further identifies cell-type-specific genetic underpinnings, linking disease-associated genetic variants to gene regulation within corresponding cell types. We substantiate the disease relevance of scPRS-prioritized HCM genes and demonstrate that the suppression of these genes in HCM cardiomyocytes is rescued by Mavacamten treatment. Additionally, we establish a novel microglia-specific regulatory relationship between the AD risk variant rs7922621 and its target genes ANXA11 and TSPAN14. We further illustrate the detrimental effects of suppressing these two genes on microglia phagocytosis. Our work provides a multi-tasking, interpretable framework for precise disease prediction and systematic investigation of the genetic, cellular, and molecular basis of complex diseases, laying the methodological foundation for single-cell genetics.",0,0
33550068,A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence,"Suri JS, Agarwal S, Gupta SK, Puvvula A, Biswas M, Saba L, Bit A, Tandel GS, Agarwal M, Patrick A, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Miguel Sanches J, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Teji J, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PK, Naidu S.",Comput Biol Med. 2021 Mar;130:104210. doi: 10.1016/j.compbiomed.2021.104210. Epub 2021 Jan 18.,Suri JS,Comput Biol Med,2021,07-02-2021,PMC7813499,,10.1016/j.compbiomed.2021.104210,"COVID-19 has infected 77.4 million people worldwide and has caused 1.7 million fatalities as of December 21, 2020. The primary cause of death due to COVID-19 is Acute Respiratory Distress Syndrome (ARDS). According to the World Health Organization (WHO), people who are at least 60 years old or have comorbidities that have primarily been targeted are at the highest risk from SARS-CoV-2. Medical imaging provides a non-invasive, touch-free, and relatively safer alternative tool for diagnosis during the current ongoing pandemic. Artificial intelligence (AI) scientists are developing several intelligent computer-aided diagnosis (CAD) tools in multiple imaging modalities, i.e., lung computed tomography (CT), chest X-rays, and lung ultrasounds. These AI tools assist the pulmonary and critical care clinicians through (a) faster detection of the presence of a virus, (b) classifying pneumonia types, and (c) measuring the severity of viral damage in COVID-19-infected patients. Thus, it is of the utmost importance to fully understand the requirements of for a fast and successful, and timely lung scans analysis. This narrative review first presents the pathological layout of the lungs in the COVID-19 scenario, followed by understanding and then explains the comorbid statistical distributions in the ARDS framework. The novelty of this review is the approach to classifying the AI models as per the by school of thought (SoTs), exhibiting based on segregation of techniques and their characteristics. The study also discusses the identification of AI models and its extension from non-ARDS lungs (pre-COVID-19) to ARDS lungs (post-COVID-19). Furthermore, it also presents AI workflow considerations of for medical imaging modalities in the COVID-19 framework. Finally, clinical AI design considerations will be discussed. We conclude that the design of the current existing AI models can be improved by considering comorbidity as an independent factor. Furthermore, ARDS post-processing clinical systems must involve include (i) the clinical validation and verification of AI-models, (ii) reliability and stability criteria, and (iii) easily adaptable, and (iv) generalization assessments of AI systems for their use in pulmonary, critical care, and radiological settings.","A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence COVID-19 has infected 77.4 million people worldwide and has caused 1.7 million fatalities as of December 21, 2020. The primary cause of death due to COVID-19 is Acute Respiratory Distress Syndrome (ARDS). According to the World Health Organization (WHO), people who are at least 60 years old or have comorbidities that have primarily been targeted are at the highest risk from SARS-CoV-2. Medical imaging provides a non-invasive, touch-free, and relatively safer alternative tool for diagnosis during the current ongoing pandemic. Artificial intelligence (AI) scientists are developing several intelligent computer-aided diagnosis (CAD) tools in multiple imaging modalities, i.e., lung computed tomography (CT), chest X-rays, and lung ultrasounds. These AI tools assist the pulmonary and critical care clinicians through (a) faster detection of the presence of a virus, (b) classifying pneumonia types, and (c) measuring the severity of viral damage in COVID-19-infected patients. Thus, it is of the utmost importance to fully understand the requirements of for a fast and successful, and timely lung scans analysis. This narrative review first presents the pathological layout of the lungs in the COVID-19 scenario, followed by understanding and then explains the comorbid statistical distributions in the ARDS framework. The novelty of this review is the approach to classifying the AI models as per the by school of thought (SoTs), exhibiting based on segregation of techniques and their characteristics. The study also discusses the identification of AI models and its extension from non-ARDS lungs (pre-COVID-19) to ARDS lungs (post-COVID-19). Furthermore, it also presents AI workflow considerations of for medical imaging modalities in the COVID-19 framework. Finally, clinical AI design considerations will be discussed. We conclude that the design of the current existing AI models can be improved by considering comorbidity as an independent factor. Furthermore, ARDS post-processing clinical systems must involve include (i) the clinical validation and verification of AI-models, (ii) reliability and stability criteria, and (iii) easily adaptable, and (iv) generalization assessments of AI systems for their use in pulmonary, critical care, and radiological settings.",1,1
36005433,"Vascular Implications of COVID-19: Role of Radiological Imaging, Artificial Intelligence, and Tissue Characterization: A Special Report","Khanna NN, Maindarkar M, Puvvula A, Paul S, Bhagawati M, Ahluwalia P, Ruzsa Z, Sharma A, Munjral S, Kolluri R, Krishnan PR, Singh IM, Laird JR, Fatemi M, Alizad A, Dhanjil SK, Saba L, Balestrieri A, Faa G, Paraskevas KI, Misra DP, Agarwal V, Sharma A, Teji J, Al-Maini M, Nicolaides A, Rathore V, Naidu S, Liblik K, Johri AM, Turk M, Sobel DW, Pareek G, Miner M, Viskovic K, Tsoulfas G, Protogerou AD, Mavrogeni S, Kitas GD, Fouda MM, Kalra MK, Suri JS.",J Cardiovasc Dev Dis. 2022 Aug 15;9(8):268. doi: 10.3390/jcdd9080268.,Khanna NN,J Cardiovasc Dev Dis,2022,25-08-2022,PMC9409845,,10.3390/jcdd9080268,"The SARS-CoV-2 virus has caused a pandemic, infecting nearly 80 million people worldwide, with mortality exceeding six million. The average survival span is just 14 days from the time the symptoms become aggressive. The present study delineates the deep-driven vascular damage in the pulmonary, renal, coronary, and carotid vessels due to SARS-CoV-2. This special report addresses an important gap in the literature in understanding (i) the pathophysiology of vascular damage and the role of medical imaging in the visualization of the damage caused by SARS-CoV-2, and (ii) further understanding the severity of COVID-19 using artificial intelligence (AI)-based tissue characterization (TC). PRISMA was used to select 296 studies for AI-based TC. Radiological imaging techniques such as magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound were selected for imaging of the vasculature infected by COVID-19. Four kinds of hypotheses are presented for showing the vascular damage in radiological images due to COVID-19. Three kinds of AI models, namely, machine learning, deep learning, and transfer learning, are used for TC. Further, the study presents recommendations for improving AI-based architectures for vascular studies. We conclude that the process of vascular damage due to COVID-19 has similarities across vessel types, even though it results in multi-organ dysfunction. Although the mortality rate is ~2% of those infected, the long-term effect of COVID-19 needs monitoring to avoid deaths. AI seems to be penetrating the health care industry at warp speed, and we expect to see an emerging role in patient care, reduce the mortality and morbidity rate.","Vascular Implications of COVID-19: Role of Radiological Imaging, Artificial Intelligence, and Tissue Characterization: A Special Report The SARS-CoV-2 virus has caused a pandemic, infecting nearly 80 million people worldwide, with mortality exceeding six million. The average survival span is just 14 days from the time the symptoms become aggressive. The present study delineates the deep-driven vascular damage in the pulmonary, renal, coronary, and carotid vessels due to SARS-CoV-2. This special report addresses an important gap in the literature in understanding (i) the pathophysiology of vascular damage and the role of medical imaging in the visualization of the damage caused by SARS-CoV-2, and (ii) further understanding the severity of COVID-19 using artificial intelligence (AI)-based tissue characterization (TC). PRISMA was used to select 296 studies for AI-based TC. Radiological imaging techniques such as magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound were selected for imaging of the vasculature infected by COVID-19. Four kinds of hypotheses are presented for showing the vascular damage in radiological images due to COVID-19. Three kinds of AI models, namely, machine learning, deep learning, and transfer learning, are used for TC. Further, the study presents recommendations for improving AI-based architectures for vascular studies. We conclude that the process of vascular damage due to COVID-19 has similarities across vessel types, even though it results in multi-organ dysfunction. Although the mortality rate is ~2% of those infected, the long-term effect of COVID-19 needs monitoring to avoid deaths. AI seems to be penetrating the health care industry at warp speed, and we expect to see an emerging role in patient care, reduce the mortality and morbidity rate.",1,1
28886603,Review of Epidemiological Studies of Drinking-Water Turbidity in Relation to Acute Gastrointestinal Illness,"De Roos AJ, Gurian PL, Robinson LF, Rai A, Zakeri I, Kondo MC.",Environ Health Perspect. 2017 Aug 17;125(8):086003. doi: 10.1289/EHP1090.,De Roos AJ,Environ Health Perspect,2017,09-09-2017,PMC5882241,,10.1289/EHP1090,"BACKGROUND: Turbidity has been used as an indicator of microbiological contamination of drinking water in time-series studies attempting to discern the presence of waterborne gastrointestinal illness; however, the utility of turbidity as a proxy exposure measure has been questioned.
OBJECTIVES: We conducted a review of epidemiological studies of the association between turbidity of drinking-water supplies and incidence of acute gastrointestinal illness (AGI), including a synthesis of the overall weight of evidence. Our goal was to evaluate the potential for causal inference from the studies.
METHODS: We identified 14 studies on the topic (distinct by region, time period and/or population). We evaluated each study with regard to modeling approaches, potential biases, and the strength of evidence. We also considered consistencies and differences in the collective results.
DISCUSSION: Positive associations between drinking-water turbidity and AGI incidence were found in different cities and time periods, and with both unfiltered and filtered supplies. There was some evidence for a stronger association at higher turbidity levels. The studies appeared to adequately adjust for confounding. There was fair consistency in the notable lags between turbidity measurement and AGI identification, which fell between 6 and 10 d in many studies.
CONCLUSIONS: The observed associations suggest a detectable incidence of waterborne AGI from drinking water in the systems and time periods studied. However, some discrepant results indicate that the association may be context specific. Combining turbidity with seasonal and climatic factors, additional water quality measures, and treatment data may enhance predictive modeling in future studies. https://doi.org/10.1289/EHP1090.","Review of Epidemiological Studies of Drinking-Water Turbidity in Relation to Acute Gastrointestinal Illness BACKGROUND: Turbidity has been used as an indicator of microbiological contamination of drinking water in time-series studies attempting to discern the presence of waterborne gastrointestinal illness; however, the utility of turbidity as a proxy exposure measure has been questioned.
OBJECTIVES: We conducted a review of epidemiological studies of the association between turbidity of drinking-water supplies and incidence of acute gastrointestinal illness (AGI), including a synthesis of the overall weight of evidence. Our goal was to evaluate the potential for causal inference from the studies.
METHODS: We identified 14 studies on the topic (distinct by region, time period and/or population). We evaluated each study with regard to modeling approaches, potential biases, and the strength of evidence. We also considered consistencies and differences in the collective results.
DISCUSSION: Positive associations between drinking-water turbidity and AGI incidence were found in different cities and time periods, and with both unfiltered and filtered supplies. There was some evidence for a stronger association at higher turbidity levels. The studies appeared to adequately adjust for confounding. There was fair consistency in the notable lags between turbidity measurement and AGI identification, which fell between 6 and 10 d in many studies.
CONCLUSIONS: The observed associations suggest a detectable incidence of waterborne AGI from drinking water in the systems and time periods studied. However, some discrepant results indicate that the association may be context specific. Combining turbidity with seasonal and climatic factors, additional water quality measures, and treatment data may enhance predictive modeling in future studies. https://doi.org/10.1289/EHP1090.",0,0
36778495,Bacteroides ovatus alleviates dysbiotic microbiota-induced intestinal graft-versus-host disease,"Hayase E, Hayase T, Mukherjee A, Stinson SC, Jamal MA, Ortega MR, Sanchez CA, Ahmed SS, Karmouch JL, Chang CC, Flores II, McDaniel LK, Brown AN, El-Himri RK, Chapa VA, Tan L, Tran BQ, Pham D, Halsey TM, Jin Y, Tsai WB, Prasad R, Glover IK, Ajami NJ, Wargo JA, Shelburne S, Okhuysen PC, Liu C, Fowler SW, Conner ME, Peterson CB, Rondon G, Molldrem JJ, Champlin RE, Shpall EJ, Lorenzi PL, Mehta RS, Martens EC, Alousi AM, Jenq RR.",Res Sq [Preprint]. 2023 Jan 31:rs.3.rs-2460097. doi: 10.21203/rs.3.rs-2460097/v1.,Hayase E,Res Sq,2023,13-02-2023,PMC9915792,,10.21203/rs.3.rs-2460097/v1,"Acute gastrointestinal intestinal GVHD (aGI-GVHD) is a serious complication of allogeneic hematopoietic stem cell transplantation, and the intestinal microbiota is known to impact on its severity. However, an association between treatment response of aGI-GVHD and the intestinal microbiota has not been well-studied. In a cohort of patients with aGI-GVHD (n=37), we found that non-response to standard therapy with corticosteroids was associated with prior treatment with carbapenem antibiotics and loss of Bacteroides ovatus from the microbiome. In a mouse model of carbapenem-aggravated GVHD, introducing Bacteroides ovatus reduced severity of GVHD and improved survival. Bacteroides ovatus reduced degradation of colonic mucus by another intestinal commensal, Bacteroides thetaiotaomicron, via its ability to metabolize dietary polysaccharides into monosaccharides, which then inhibit mucus degradation by Bacteroides thetaiotaomicron and reduce GVHD-related mortality.","Bacteroides ovatus alleviates dysbiotic microbiota-induced intestinal graft-versus-host disease Acute gastrointestinal intestinal GVHD (aGI-GVHD) is a serious complication of allogeneic hematopoietic stem cell transplantation, and the intestinal microbiota is known to impact on its severity. However, an association between treatment response of aGI-GVHD and the intestinal microbiota has not been well-studied. In a cohort of patients with aGI-GVHD (n=37), we found that non-response to standard therapy with corticosteroids was associated with prior treatment with carbapenem antibiotics and loss of Bacteroides ovatus from the microbiome. In a mouse model of carbapenem-aggravated GVHD, introducing Bacteroides ovatus reduced severity of GVHD and improved survival. Bacteroides ovatus reduced degradation of colonic mucus by another intestinal commensal, Bacteroides thetaiotaomicron, via its ability to metabolize dietary polysaccharides into monosaccharides, which then inhibit mucus degradation by Bacteroides thetaiotaomicron and reduce GVHD-related mortality.",0,0
29686471,Analysis of aggressiveness factors in hepatocellular carcinoma patients undergoing transarterial chemoembolization,"Ventura Y, Carr BI, Kori I, Guerra V, Shibolet O.",World J Gastroenterol. 2018 Apr 21;24(15):1641-1649. doi: 10.3748/wjg.v24.i15.1641.,Ventura Y,World J Gastroenterol,2018,25-04-2018,PMC5910547,,10.3748/wjg.v24.i15.1641,"AIM: To investigate novel predictors of survival in hepatocellular carcinoma (HCC) patients following transarterial chemoembolization (TACE).
METHODS: One hundred sixty seven patients with un-resectable HCC were retrospectively analyzed to identify factors that might contribute to their HCC biology and aggressiveness. We correlated routine laboratory results (total bilirubin, AST, ALKP, GGTP, albumin etc.) to maximum tumor diameter, number of tumor nodules, portal vein thrombosis and blood alpha-fetoprotein levels. These 4 parameters were previously combined to form an aggressiveness index (AgI). We used The Wilcoxon rank-sum (Mann-Whitney), to test the correlation between the AgI categories and liver function parameters. The Cox proportional hazards model was applied to evaluate the categories of AgI associated with overall survival.
RESULTS: The AgI was strongly correlated with survival in this novel patient population. Three year survival probability for AgI &gt; or &lt; 4 was 42.4% vs 61.8%; P &lt; 0.0863 respectively. Several factors independently correlated with AgI using univariate multiple logistic regression of AgI with 8 laboratory parameters. Lower albumin levels had an OR of 2.56 (95%CI: 1.120-5.863 P &lt; 0.026), elevated Alkaline phosphatase and gamma glutamyl transpeptidase (GGTP) had ORs of 1.01 (95%CI: 1.003-1.026, P &lt; 0.017) and 0.99 (95%CI: 0.99-1.00, P &lt; 0.053) respectively. In a Cox proportional hazard model combining mortality for AgI score and liver function parameters, only GGTP levels and the AgI were independently associated with survival. An AgI &gt; 4 had HR for mortality of 2.18 (95%CI: 1.108-4.310, P &lt; 0.024). GGTP's single unit change had a HR for mortality of 1.003 (95%CI: 1.001-1.006, P &lt; 0.016). These were considered in the final multivariate model with the total cohort. An AgI &gt; 4 had a HR for mortality of 2.26 (95%CI: 1.184-4.327, P &lt; 0.016). GGTP had a HR of 1.003 (95%CI: 1.001-1.004, P &lt; 0.001).
CONCLUSION: Our study validates the AgI in a new population with un-resectable HCC patients undergoing TACE. The analysis establishes a correlation between GGTP and the AgI.","Analysis of aggressiveness factors in hepatocellular carcinoma patients undergoing transarterial chemoembolization AIM: To investigate novel predictors of survival in hepatocellular carcinoma (HCC) patients following transarterial chemoembolization (TACE).
METHODS: One hundred sixty seven patients with un-resectable HCC were retrospectively analyzed to identify factors that might contribute to their HCC biology and aggressiveness. We correlated routine laboratory results (total bilirubin, AST, ALKP, GGTP, albumin etc.) to maximum tumor diameter, number of tumor nodules, portal vein thrombosis and blood alpha-fetoprotein levels. These 4 parameters were previously combined to form an aggressiveness index (AgI). We used The Wilcoxon rank-sum (Mann-Whitney), to test the correlation between the AgI categories and liver function parameters. The Cox proportional hazards model was applied to evaluate the categories of AgI associated with overall survival.
RESULTS: The AgI was strongly correlated with survival in this novel patient population. Three year survival probability for AgI &gt; or &lt; 4 was 42.4% vs 61.8%; P &lt; 0.0863 respectively. Several factors independently correlated with AgI using univariate multiple logistic regression of AgI with 8 laboratory parameters. Lower albumin levels had an OR of 2.56 (95%CI: 1.120-5.863 P &lt; 0.026), elevated Alkaline phosphatase and gamma glutamyl transpeptidase (GGTP) had ORs of 1.01 (95%CI: 1.003-1.026, P &lt; 0.017) and 0.99 (95%CI: 0.99-1.00, P &lt; 0.053) respectively. In a Cox proportional hazard model combining mortality for AgI score and liver function parameters, only GGTP levels and the AgI were independently associated with survival. An AgI &gt; 4 had HR for mortality of 2.18 (95%CI: 1.108-4.310, P &lt; 0.024). GGTP's single unit change had a HR for mortality of 1.003 (95%CI: 1.001-1.006, P &lt; 0.016). These were considered in the final multivariate model with the total cohort. An AgI &gt; 4 had a HR for mortality of 2.26 (95%CI: 1.184-4.327, P &lt; 0.016). GGTP had a HR of 1.003 (95%CI: 1.001-1.004, P &lt; 0.001).
CONCLUSION: Our study validates the AgI in a new population with un-resectable HCC patients undergoing TACE. The analysis establishes a correlation between GGTP and the AgI.",1,0
35504769,Nutritional intake and gastro-intestinal symptoms in critically ill COVID-19 patients,"Lakenman PLM, van Schie JC, van der Hoven B, Baart SJ, Eveleens RD, van Bommel J, Olieman JF, Joosten KFM.",Clin Nutr. 2022 Dec;41(12):2903-2909. doi: 10.1016/j.clnu.2022.04.001. Epub 2022 Apr 6.,Lakenman PLM,Clin Nutr,2022,03-05-2022,PMC8986274,,10.1016/j.clnu.2022.04.001,"BACKGROUND & AIMS: Critically ill COVID-19 patients seem hypermetabolic and difficult to feed enterally, due to gastro-intestinal (GI) symptoms such as high gastric residual volumes (GRV) and diarrhea. Our aim was to describe the association of nutritional intake and GI symptoms during first 14 days of ICU admission.
METHODS: Observational study including critically ill adult COVID-19 patients. Data on nutritional intake [enteral nutrition (EN) or parenteral nutrition] and GI symptoms were collected during 14 days after ICU admission. Target energy and protein feeding goals were calculated conform ESPEN guidelines. GI symptoms included GRV (ml/d), vomiting, abdominal distension, and faeces (ml/d). High GRV's were classified as ≥2 times ≥150 ml/d and diarrhea as Bristol stool chart ≥6. GI symptoms were defined as mild if at least one symptom occurred and as moderate when ≥2 symptoms occurred. Acute gastrointestinal injury (AGI) grades of III were classified as GI dysfunction and grades of IV were considered as GI failure with severe impact on distant organs. Linear mixed model analysis was performed to explore the development of nutritional intake and GI symptoms over time at day (D) 0, 4, 10, and 14.
RESULTS: One hundred and fifty patients were included [75% male; median age 64 years (IQR 54-70)]. BMI upon admission was 28 kg/m2 (IQR 25-33), of which 43% obese (BMI &gt; 30 kg/m2). Most patients received EN during admission (98% D4; 96% D10-14). Mean energy goals increased from 87% at D4 to 93% D10-14 and protein goals (g/kg) were increasingly achieved during admission (84% D4; 93% D10-14). Presence of moderate GI symptoms decreased (10% D0; 6% D4-10; 5% D14), reversely mild GI symptoms increased. Occurrence of GI dysfunction fluctuated (1% D0; 18% D4; 12% D10; 8% D14) and none of patients developed grade IV GI failure. Development of high GRV fluctuated (5% D0; 23% D4; 14% D10; 8% D14) and occurrence of diarrhea slightly increased during admission (5% D0; 22% D4; 25% D10; 27% D14). Linear mixed models showed only an association between AGI grades III and lower protein intake at day 10 (p = 0.020).
CONCLUSION: Occurrence of GI symptoms was limited and seems no major barrier for EN in our group of critically COVID-19 patients. Nutritional intake was just below requirements during the first 14 days of ICU admission. The effect on nutritional status remains to be studied.","Nutritional intake and gastro-intestinal symptoms in critically ill COVID-19 patients BACKGROUND & AIMS: Critically ill COVID-19 patients seem hypermetabolic and difficult to feed enterally, due to gastro-intestinal (GI) symptoms such as high gastric residual volumes (GRV) and diarrhea. Our aim was to describe the association of nutritional intake and GI symptoms during first 14 days of ICU admission.
METHODS: Observational study including critically ill adult COVID-19 patients. Data on nutritional intake [enteral nutrition (EN) or parenteral nutrition] and GI symptoms were collected during 14 days after ICU admission. Target energy and protein feeding goals were calculated conform ESPEN guidelines. GI symptoms included GRV (ml/d), vomiting, abdominal distension, and faeces (ml/d). High GRV's were classified as ≥2 times ≥150 ml/d and diarrhea as Bristol stool chart ≥6. GI symptoms were defined as mild if at least one symptom occurred and as moderate when ≥2 symptoms occurred. Acute gastrointestinal injury (AGI) grades of III were classified as GI dysfunction and grades of IV were considered as GI failure with severe impact on distant organs. Linear mixed model analysis was performed to explore the development of nutritional intake and GI symptoms over time at day (D) 0, 4, 10, and 14.
RESULTS: One hundred and fifty patients were included [75% male; median age 64 years (IQR 54-70)]. BMI upon admission was 28 kg/m2 (IQR 25-33), of which 43% obese (BMI &gt; 30 kg/m2). Most patients received EN during admission (98% D4; 96% D10-14). Mean energy goals increased from 87% at D4 to 93% D10-14 and protein goals (g/kg) were increasingly achieved during admission (84% D4; 93% D10-14). Presence of moderate GI symptoms decreased (10% D0; 6% D4-10; 5% D14), reversely mild GI symptoms increased. Occurrence of GI dysfunction fluctuated (1% D0; 18% D4; 12% D10; 8% D14) and none of patients developed grade IV GI failure. Development of high GRV fluctuated (5% D0; 23% D4; 14% D10; 8% D14) and occurrence of diarrhea slightly increased during admission (5% D0; 22% D4; 25% D10; 27% D14). Linear mixed models showed only an association between AGI grades III and lower protein intake at day 10 (p = 0.020).
CONCLUSION: Occurrence of GI symptoms was limited and seems no major barrier for EN in our group of critically COVID-19 patients. Nutritional intake was just below requirements during the first 14 days of ICU admission. The effect on nutritional status remains to be studied.",0,0
38755442,Effects of different treatments for type 2 diabetes mellitus on mortality of coronavirus disease from 2019 to 2021 in China: a multi-institutional retrospective study,"Xu K, He W, Yu B, Zhong K, Zhou D, Wang DW.",Mol Biomed. 2024 May 17;5(1):18. doi: 10.1186/s43556-024-00183-1.,Xu K,Mol Biomed,2024,16-05-2024,PMC11099001,,10.1186/s43556-024-00183-1,"The coronavirus disease (COVID-19) pandemic has continued for 5 years. Sporadic cases continue to occur in different locations. Type 2 diabetes mellitus (T2DM) is associated with a high risk of a poor prognosis in patients with COVID-19. Successful control of blood glucose levels can effectively decrease the risks of severe infections and mortality. However, the effects of different treatments were reported differently and even adversely. This retrospective study included 4,922 patients who have been diagnosed as COVID-19 and T2DM from 138 Hubei hospitals. The clinical characteristics and outcomes were compared and calculated their risk for death using multivariate Cox regression and Kaplan-Meier curves. After adjustment of age, sex, comorbidities, and in-hospital medications, metformin and alpha-glucosidase inhibitor (AGI) use performed lower all-cause mortality (adjusted hazard ratio [HR], 0.41; 95% confidence interval [CI]: 0.24-0.71; p = 0.001 for metformin; 0.53, 0.35-0.80, p = 0.002 for AGIs), while insulin use was associated with increased all-cause mortality (adjusted HR, 2.07, 95% CI, 1.61-2.67, p < 0.001). After propensity score-matched (PSM) analysis, adjusted HRs for insulin, metformin, and AGIs associated with all-cause mortality were 1.32 (95% CI, 1.03-1.81; p = 0.012), 0.48 (95% CI, 0.23-0.83, p = 0.014), and 0.59 (95% CI, 0.35-0.98, p = 0.05). Therefore, metformin and AGIs might be more suitable for patients with COVID-19 and T2DM while insulin might be used with caution.","Effects of different treatments for type 2 diabetes mellitus on mortality of coronavirus disease from 2019 to 2021 in China: a multi-institutional retrospective study The coronavirus disease (COVID-19) pandemic has continued for 5 years. Sporadic cases continue to occur in different locations. Type 2 diabetes mellitus (T2DM) is associated with a high risk of a poor prognosis in patients with COVID-19. Successful control of blood glucose levels can effectively decrease the risks of severe infections and mortality. However, the effects of different treatments were reported differently and even adversely. This retrospective study included 4,922 patients who have been diagnosed as COVID-19 and T2DM from 138 Hubei hospitals. The clinical characteristics and outcomes were compared and calculated their risk for death using multivariate Cox regression and Kaplan-Meier curves. After adjustment of age, sex, comorbidities, and in-hospital medications, metformin and alpha-glucosidase inhibitor (AGI) use performed lower all-cause mortality (adjusted hazard ratio [HR], 0.41; 95% confidence interval [CI]: 0.24-0.71; p = 0.001 for metformin; 0.53, 0.35-0.80, p = 0.002 for AGIs), while insulin use was associated with increased all-cause mortality (adjusted HR, 2.07, 95% CI, 1.61-2.67, p < 0.001). After propensity score-matched (PSM) analysis, adjusted HRs for insulin, metformin, and AGIs associated with all-cause mortality were 1.32 (95% CI, 1.03-1.81; p = 0.012), 0.48 (95% CI, 0.23-0.83, p = 0.014), and 0.59 (95% CI, 0.35-0.98, p = 0.05). Therefore, metformin and AGIs might be more suitable for patients with COVID-19 and T2DM while insulin might be used with caution.",0,0
29052771,Standardized radiographic interpretation of thoracic tuberculosis in children,"Concepcion NDP, Laya BF, Andronikou S, Daltro PAN, Sanchez MO, Uy JAU, Lim TRU.",Pediatr Radiol. 2017 Sep;47(10):1237-1248. doi: 10.1007/s00247-017-3868-z. Epub 2017 Aug 29.,Concepcion NDP,Pediatr Radiol,2017,21-10-2017,PMC5574960,,10.1007/s00247-017-3868-z,"There is a lack of standardized approach and terminology to classify the diverse spectrum of manifestations in tuberculosis. It is important to recognize the different clinical and radiographic patterns to guide treatment. As a result of changing epidemiology, there is considerable overlap in the radiologic presentations of primary tuberculosis and post-primary tuberculosis. In this article we promote a standardized approach in clinical and radiographic classification for children suspected of having or diagnosed with childhood tuberculosis. We propose standardized terms to diminish confusion and miscommunication, which can affect management. In addition, we present pitfalls and limitations of imaging.","Standardized radiographic interpretation of thoracic tuberculosis in children There is a lack of standardized approach and terminology to classify the diverse spectrum of manifestations in tuberculosis. It is important to recognize the different clinical and radiographic patterns to guide treatment. As a result of changing epidemiology, there is considerable overlap in the radiologic presentations of primary tuberculosis and post-primary tuberculosis. In this article we promote a standardized approach in clinical and radiographic classification for children suspected of having or diagnosed with childhood tuberculosis. We propose standardized terms to diminish confusion and miscommunication, which can affect management. In addition, we present pitfalls and limitations of imaging.",0,0
32815060,Characterization of Patients Who Return to Hospital Following Discharge from Hospitalization for COVID-19,"Somani SS, Richter F, Fuster V, De Freitas JK, Naik N, Sigel K; Mount Sinai COVID Informatics Center; Bottinger EP, Levin MA, Fayad Z, Just AC, Charney AW, Zhao S, Glicksberg BS, Lala A, Nadkarni GN.",J Gen Intern Med. 2020 Oct;35(10):2838-2844. doi: 10.1007/s11606-020-06120-6. Epub 2020 Aug 19.,Somani SS,J Gen Intern Med,2020,21-08-2020,PMC7437962,,10.1007/s11606-020-06120-6,"BACKGROUND: Data on patients with coronavirus disease 2019 (COVID-19) who return to hospital after discharge are scarce. Characterization of these patients may inform post-hospitalization care.
OBJECTIVE: To describe clinical characteristics of patients with COVID-19 who returned to the emergency department (ED) or required readmission within 14 days of discharge.
DESIGN: Retrospective cohort study of SARS-COV-2-positive patients with index hospitalization between February 27 and April 12, 2020, with ≥ 14-day follow-up. Significance was defined as P < 0.05 after multiplying P by 125 study-wide comparisons.
PARTICIPANTS: Hospitalized patients with confirmed SARS-CoV-2 discharged alive from five New York City hospitals.
MAIN MEASURES: Readmission or return to ED following discharge.
RESULTS: Of 2864 discharged patients, 103 (3.6%) returned for emergency care after a median of 4.5 days, with 56 requiring inpatient readmission. The most common reason for return was respiratory distress (50%). Compared with patients who did not return, there were higher proportions of COPD (6.8% vs 2.9%) and hypertension (36% vs 22.1%) among those who returned. Patients who returned also had a shorter median length of stay (LOS) during index hospitalization (4.5 [2.9,9.1] vs 6.7 [3.5, 11.5] days; P<sub>adjusted</sub> = 0.006), and were less likely to have required intensive care on index hospitalization (5.8% vs 19%; P<sub>adjusted</sub> = 0.001). A trend towards association between absence of in-hospital treatment-dose anticoagulation on index admission and return to hospital was also observed (20.9% vs 30.9%, P<sub>adjusted</sub> = 0.06). On readmission, rates of intensive care and death were 5.8% and 3.6%, respectively.
CONCLUSIONS: Return to hospital after admission for COVID-19 was infrequent within 14 days of discharge. The most common cause for return was respiratory distress. Patients who returned more likely had COPD and hypertension, shorter LOS on index-hospitalization, and lower rates of in-hospital treatment-dose anticoagulation. Future studies should focus on whether these comorbid conditions, longer LOS, and anticoagulation are associated with reduced readmissions.","Characterization of Patients Who Return to Hospital Following Discharge from Hospitalization for COVID-19 BACKGROUND: Data on patients with coronavirus disease 2019 (COVID-19) who return to hospital after discharge are scarce. Characterization of these patients may inform post-hospitalization care.
OBJECTIVE: To describe clinical characteristics of patients with COVID-19 who returned to the emergency department (ED) or required readmission within 14 days of discharge.
DESIGN: Retrospective cohort study of SARS-COV-2-positive patients with index hospitalization between February 27 and April 12, 2020, with ≥ 14-day follow-up. Significance was defined as P < 0.05 after multiplying P by 125 study-wide comparisons.
PARTICIPANTS: Hospitalized patients with confirmed SARS-CoV-2 discharged alive from five New York City hospitals.
MAIN MEASURES: Readmission or return to ED following discharge.
RESULTS: Of 2864 discharged patients, 103 (3.6%) returned for emergency care after a median of 4.5 days, with 56 requiring inpatient readmission. The most common reason for return was respiratory distress (50%). Compared with patients who did not return, there were higher proportions of COPD (6.8% vs 2.9%) and hypertension (36% vs 22.1%) among those who returned. Patients who returned also had a shorter median length of stay (LOS) during index hospitalization (4.5 [2.9,9.1] vs 6.7 [3.5, 11.5] days; P<sub>adjusted</sub> = 0.006), and were less likely to have required intensive care on index hospitalization (5.8% vs 19%; P<sub>adjusted</sub> = 0.001). A trend towards association between absence of in-hospital treatment-dose anticoagulation on index admission and return to hospital was also observed (20.9% vs 30.9%, P<sub>adjusted</sub> = 0.06). On readmission, rates of intensive care and death were 5.8% and 3.6%, respectively.
CONCLUSIONS: Return to hospital after admission for COVID-19 was infrequent within 14 days of discharge. The most common cause for return was respiratory distress. Patients who returned more likely had COPD and hypertension, shorter LOS on index-hospitalization, and lower rates of in-hospital treatment-dose anticoagulation. Future studies should focus on whether these comorbid conditions, longer LOS, and anticoagulation are associated with reduced readmissions.",0,0
32843080,Sepsis related mortality of extremely low gestational age newborns after the introduction of colonization screening for multi-drug resistant organisms,"Härtel C, Faust K, Fortmann I, Humberg A, Pagel J, Haug C, Kühl R, Bohnhorst B, Pirr S, Viemann D, Simon A, Zemlin M, Poralla S, Müller A, Köstlin-Gille N, Gille C, Heckmann M, Rupp J, Herting E, Göpel W.",Antimicrob Resist Infect Control. 2020 Aug 26;9(1):144. doi: 10.1186/s13756-020-00804-8.,Härtel C,Antimicrob Resist Infect Control,2020,27-08-2020,PMC7449086,,10.1186/s13756-020-00804-8,"BACKGROUND: In 2013 German infection surveillance guidelines recommended weekly colonization screening for multidrug-resistant (MDRO) or highly epidemic organisms for neonatal intensive care units (NICUs) and extended hygiene measures based on screening results. It remains a matter of debate whether screening is worth the effort. We therefore aimed to evaluate sepsis related outcomes before and after the guideline update.
METHODS: The German Neonatal Network (GNN) is a prospective cohort study including data from extremely preterm infants between 22 + 0 and 28 + 6 gestational weeks born in 62 German level III NICUs.
RESULTS: Infants treated after guideline update (n = 8.903) had a lower mortality (12.5% vs. 13.8%, p = 0.036), reduced rates for clinical sepsis (31.4 vs. 42.8%, p <  0.001) and culture-proven sepsis (14.4% vs. 16.5%, p = 0.003) as compared to infants treated before update (n = 3.920). In a multivariate logistic regression analysis, nine pathogens of culture-proven sepsis were associated with sepsis-related death, e.g. Pseudomonas aeruginosa [OR 59 (19-180), p <  0.001)]. However, the guideline update had no significant effect on pathogen-specific case fatality, total sepsis-related mortality and culture-proven sepsis rates with MDRO. While the exposure of GNN infants to cefotaxime declined over time (31.1 vs. 40.1%, p <  0.001), the treatment rate with meropenem was increased (31.6 vs. 26.3%, p <  0.001).
CONCLUSIONS: The introduction of weekly screening and extended hygiene measures is associated with reduced sepsis rates, but has no effects on sepsis-related mortality and sepsis with screening-relevant pathogens. The high exposure rate to meropenem should be a target of antibiotic stewardship programs.","Sepsis related mortality of extremely low gestational age newborns after the introduction of colonization screening for multi-drug resistant organisms BACKGROUND: In 2013 German infection surveillance guidelines recommended weekly colonization screening for multidrug-resistant (MDRO) or highly epidemic organisms for neonatal intensive care units (NICUs) and extended hygiene measures based on screening results. It remains a matter of debate whether screening is worth the effort. We therefore aimed to evaluate sepsis related outcomes before and after the guideline update.
METHODS: The German Neonatal Network (GNN) is a prospective cohort study including data from extremely preterm infants between 22 + 0 and 28 + 6 gestational weeks born in 62 German level III NICUs.
RESULTS: Infants treated after guideline update (n = 8.903) had a lower mortality (12.5% vs. 13.8%, p = 0.036), reduced rates for clinical sepsis (31.4 vs. 42.8%, p <  0.001) and culture-proven sepsis (14.4% vs. 16.5%, p = 0.003) as compared to infants treated before update (n = 3.920). In a multivariate logistic regression analysis, nine pathogens of culture-proven sepsis were associated with sepsis-related death, e.g. Pseudomonas aeruginosa [OR 59 (19-180), p <  0.001)]. However, the guideline update had no significant effect on pathogen-specific case fatality, total sepsis-related mortality and culture-proven sepsis rates with MDRO. While the exposure of GNN infants to cefotaxime declined over time (31.1 vs. 40.1%, p <  0.001), the treatment rate with meropenem was increased (31.6 vs. 26.3%, p <  0.001).
CONCLUSIONS: The introduction of weekly screening and extended hygiene measures is associated with reduced sepsis rates, but has no effects on sepsis-related mortality and sepsis with screening-relevant pathogens. The high exposure rate to meropenem should be a target of antibiotic stewardship programs.",0,0
34379602,Factors Associated With Longitudinal Psychological and Physiological Stress in Health Care Workers During the COVID-19 Pandemic: Observational Study Using Apple Watch Data,"Hirten RP, Danieletto M, Tomalin L, Choi KH, Zweig M, Golden E, Kaur S, Helmus D, Biello A, Pyzik R, Calcagno C, Freeman R, Sands BE, Charney D, Bottinger EP, Murrough JW, Keefer L, Suarez-Farinas M, Nadkarni GN, Fayad ZA.",J Med Internet Res. 2021 Sep 13;23(9):e31295. doi: 10.2196/31295.,Hirten RP,J Med Internet Res,2021,11-08-2021,PMC8439178,,10.2196/31295,"BACKGROUND: The COVID-19 pandemic has resulted in a high degree of psychological distress among health care workers (HCWs). There is a need to characterize which HCWs are at an increased risk of developing psychological effects from the pandemic. Given the differences in the response of individuals to stress, an analysis of both the perceived and physiological consequences of stressors can provide a comprehensive evaluation of its impact.
OBJECTIVE: This study aimed to determine characteristics associated with longitudinal perceived stress in HCWs and to assess whether changes in heart rate variability (HRV), a marker of autonomic nervous system function, are associated with features protective against longitudinal stress.
METHODS: HCWs across 7 hospitals in New York City, NY, were prospectively followed in an ongoing observational digital study using the custom Warrior Watch Study app. Participants wore an Apple Watch for the duration of the study to measure HRV throughout the follow-up period. Surveys measuring perceived stress, resilience, emotional support, quality of life, and optimism were collected at baseline and longitudinally.
RESULTS: A total of 361 participants (mean age 36.8, SD 10.1 years; female: n=246, 69.3%) were enrolled. Multivariate analysis found New York City's COVID-19 case count to be associated with increased longitudinal stress (P=.008). Baseline emotional support, quality of life, and resilience were associated with decreased longitudinal stress (P<.001). A significant reduction in stress during the 4-week period after COVID-19 diagnosis was observed in the highest tertial of emotional support (P=.03) and resilience (P=.006). Participants in the highest tertial of baseline emotional support and resilience had a significantly different circadian pattern of longitudinally collected HRV compared to subjects in the low or medium tertial.
CONCLUSIONS: High resilience, emotional support, and quality of life place HCWs at reduced risk of longitudinal perceived stress and have a distinct physiological stress profile. Our findings support the use of these characteristics to identify HCWs at risk of the psychological and physiological stress effects of the pandemic.","Factors Associated With Longitudinal Psychological and Physiological Stress in Health Care Workers During the COVID-19 Pandemic: Observational Study Using Apple Watch Data BACKGROUND: The COVID-19 pandemic has resulted in a high degree of psychological distress among health care workers (HCWs). There is a need to characterize which HCWs are at an increased risk of developing psychological effects from the pandemic. Given the differences in the response of individuals to stress, an analysis of both the perceived and physiological consequences of stressors can provide a comprehensive evaluation of its impact.
OBJECTIVE: This study aimed to determine characteristics associated with longitudinal perceived stress in HCWs and to assess whether changes in heart rate variability (HRV), a marker of autonomic nervous system function, are associated with features protective against longitudinal stress.
METHODS: HCWs across 7 hospitals in New York City, NY, were prospectively followed in an ongoing observational digital study using the custom Warrior Watch Study app. Participants wore an Apple Watch for the duration of the study to measure HRV throughout the follow-up period. Surveys measuring perceived stress, resilience, emotional support, quality of life, and optimism were collected at baseline and longitudinally.
RESULTS: A total of 361 participants (mean age 36.8, SD 10.1 years; female: n=246, 69.3%) were enrolled. Multivariate analysis found New York City's COVID-19 case count to be associated with increased longitudinal stress (P=.008). Baseline emotional support, quality of life, and resilience were associated with decreased longitudinal stress (P<.001). A significant reduction in stress during the 4-week period after COVID-19 diagnosis was observed in the highest tertial of emotional support (P=.03) and resilience (P=.006). Participants in the highest tertial of baseline emotional support and resilience had a significantly different circadian pattern of longitudinally collected HRV compared to subjects in the low or medium tertial.
CONCLUSIONS: High resilience, emotional support, and quality of life place HCWs at reduced risk of longitudinal perceived stress and have a distinct physiological stress profile. Our findings support the use of these characteristics to identify HCWs at risk of the psychological and physiological stress effects of the pandemic.",0,0
28117397,Sepsis and septic shock,"Hotchkiss RS, Moldawer LL, Opal SM, Reinhart K, Turnbull IR, Vincent JL.",Nat Rev Dis Primers. 2016 Jun 30;2:16045. doi: 10.1038/nrdp.2016.45.,Hotchkiss RS,Nat Rev Dis Primers,2016,25-01-2017,PMC5538252,NIHMS883730,10.1038/nrdp.2016.45,"For more than two decades, sepsis was defined as a microbial infection that produces fever (or hypothermia), tachycardia, tachypnoea and blood leukocyte changes. Sepsis is now increasingly being considered a dysregulated systemic inflammatory and immune response to microbial invasion that produces organ injury for which mortality rates are declining to 15-25%. Septic shock remains defined as sepsis with hyperlactataemia and concurrent hypotension requiring vasopressor therapy, with in-hospital mortality rates approaching 30-50%. With earlier recognition and more compliance to best practices, sepsis has become less of an immediate life-threatening disorder and more of a long-term chronic critical illness, often associated with prolonged inflammation, immune suppression, organ injury and lean tissue wasting. Furthermore, patients who survive sepsis have continuing risk of mortality after discharge, as well as long-term cognitive and functional deficits. Earlier recognition and improved implementation of best practices have reduced in-hospital mortality, but results from the use of immunomodulatory agents to date have been disappointing. Similarly, no biomarker can definitely diagnose sepsis or predict its clinical outcome. Because of its complexity, improvements in sepsis outcomes are likely to continue to be slow and incremental.","Sepsis and septic shock For more than two decades, sepsis was defined as a microbial infection that produces fever (or hypothermia), tachycardia, tachypnoea and blood leukocyte changes. Sepsis is now increasingly being considered a dysregulated systemic inflammatory and immune response to microbial invasion that produces organ injury for which mortality rates are declining to 15-25%. Septic shock remains defined as sepsis with hyperlactataemia and concurrent hypotension requiring vasopressor therapy, with in-hospital mortality rates approaching 30-50%. With earlier recognition and more compliance to best practices, sepsis has become less of an immediate life-threatening disorder and more of a long-term chronic critical illness, often associated with prolonged inflammation, immune suppression, organ injury and lean tissue wasting. Furthermore, patients who survive sepsis have continuing risk of mortality after discharge, as well as long-term cognitive and functional deficits. Earlier recognition and improved implementation of best practices have reduced in-hospital mortality, but results from the use of immunomodulatory agents to date have been disappointing. Similarly, no biomarker can definitely diagnose sepsis or predict its clinical outcome. Because of its complexity, improvements in sepsis outcomes are likely to continue to be slow and incremental.",0,0
27034776,The implications of whole-genome sequencing in the control of tuberculosis,"Lee RS, Behr MA.",Ther Adv Infect Dis. 2016 Apr;3(2):47-62. doi: 10.1177/2049936115624630. Epub 2015 Dec 30.,Lee RS,Ther Adv Infect Dis,2016,02-04-2016,PMC4784569,,10.1177/2049936115624630,"The availability of whole-genome sequencing (WGS) as a tool for the diagnosis and clinical management of tuberculosis (TB) offers considerable promise in the fight against this stubborn epidemic. However, like other new technologies, the best application of WGS remains to be determined, for both conceptual and technical reasons. In this review, we consider the potential value of WGS in the clinical laboratory for the detection of Mycobacterium tuberculosis and the prediction of antibiotic resistance. We also discuss issues pertaining to data generation, interpretation and dissemination, given that WGS has to date been generally performed in research labs where results are not necessarily packaged in a clinician-friendly format. Although WGS is far more accessible now than it was in the past, the transition from a research tool to study TB into a clinical test to manage this disease may require further fine-tuning. Improvements will likely come through iterative efforts that involve both the laboratories ready to move TB into the genomic era and the front-line clinical/public health staff who will be interpreting the results to inform management decisions.","The implications of whole-genome sequencing in the control of tuberculosis The availability of whole-genome sequencing (WGS) as a tool for the diagnosis and clinical management of tuberculosis (TB) offers considerable promise in the fight against this stubborn epidemic. However, like other new technologies, the best application of WGS remains to be determined, for both conceptual and technical reasons. In this review, we consider the potential value of WGS in the clinical laboratory for the detection of Mycobacterium tuberculosis and the prediction of antibiotic resistance. We also discuss issues pertaining to data generation, interpretation and dissemination, given that WGS has to date been generally performed in research labs where results are not necessarily packaged in a clinician-friendly format. Although WGS is far more accessible now than it was in the past, the transition from a research tool to study TB into a clinical test to manage this disease may require further fine-tuning. Improvements will likely come through iterative efforts that involve both the laboratories ready to move TB into the genomic era and the front-line clinical/public health staff who will be interpreting the results to inform management decisions.",0,0
32564017,The Role of Genetic Sex and Mitochondria in Response to COVID-19 Infection,"Kloc M, Ghobrial RM, Kubiak JZ.",Int Arch Allergy Immunol. 2020;181(8):629-634. doi: 10.1159/000508560. Epub 2020 Jun 19.,Kloc M,Int Arch Allergy Immunol,2020,22-06-2020,PMC7360490,,10.1159/000508560,"The difference between the female and male immune response to COVID-19 infection, and infections in general, is multifactorial. The well-known determiners of the immune response, such as X and Y chromosomes, sex hormones, and microbiota, are functionally interconnected and influence each other in shaping the organism's immunity. We focus our commentary on the interplay between the genetic sex and mitochondria and how this may affect a sex-dependent immune response in COVID-19 infection. Realizing the existence of these interactions may help in designing novel methods or fine-tuning the existing and routine therapies to fight COVID-19 and other infections.","The Role of Genetic Sex and Mitochondria in Response to COVID-19 Infection The difference between the female and male immune response to COVID-19 infection, and infections in general, is multifactorial. The well-known determiners of the immune response, such as X and Y chromosomes, sex hormones, and microbiota, are functionally interconnected and influence each other in shaping the organism's immunity. We focus our commentary on the interplay between the genetic sex and mitochondria and how this may affect a sex-dependent immune response in COVID-19 infection. Realizing the existence of these interactions may help in designing novel methods or fine-tuning the existing and routine therapies to fight COVID-19 and other infections.",0,0
33968472,Management of HAM/TSP: Systematic Review and Consensus-based Recommendations 2019,"Araujo A, Bangham CRM, Casseb J, Gotuzzo E, Jacobson S, Martin F, Penalva de Oliveira A, Puccioni-Sohler M, Taylor GP, Yamano Y.",Neurol Clin Pract. 2021 Feb;11(1):49-56. doi: 10.1212/CPJ.0000000000000832.,Araujo A,Neurol Clin Pract,2021,10-05-2021,PMC8101298,,10.1212/CPJ.0000000000000832,"PURPOSE OF REVIEW: To provide an evidence-based approach to the use of therapies that are prescribed to improve the natural history of HTLV-1-associated myelopathy/tropical spastic paraparesis (HAM/TSP)-a rare disease.
RECENT FINDINGS: All 41 articles on the clinical outcome of disease-modifying therapy for HAM/TSP were included in a systematic review by members of the International Retrovirology Association; we report here the consensus assessment and recommendations. The quality of available evidence is low, based for the most part on observational studies, with only 1 double-masked placebo-controlled randomized trial.
SUMMARY: There is evidence to support the use of both high-dose pulsed methyl prednisolone for induction and low-dose (5 mg) oral prednisolone as maintenance therapy for progressive disease. There is no evidence to support the use of antiretroviral therapy. There is insufficient evidence to support the use of interferon-α as a first-line therapy.","Management of HAM/TSP: Systematic Review and Consensus-based Recommendations 2019 PURPOSE OF REVIEW: To provide an evidence-based approach to the use of therapies that are prescribed to improve the natural history of HTLV-1-associated myelopathy/tropical spastic paraparesis (HAM/TSP)-a rare disease.
RECENT FINDINGS: All 41 articles on the clinical outcome of disease-modifying therapy for HAM/TSP were included in a systematic review by members of the International Retrovirology Association; we report here the consensus assessment and recommendations. The quality of available evidence is low, based for the most part on observational studies, with only 1 double-masked placebo-controlled randomized trial.
SUMMARY: There is evidence to support the use of both high-dose pulsed methyl prednisolone for induction and low-dose (5 mg) oral prednisolone as maintenance therapy for progressive disease. There is no evidence to support the use of antiretroviral therapy. There is insufficient evidence to support the use of interferon-α as a first-line therapy.",0,0
31629602,Influenza A Virus Hemagglutinin-Neuraminidase-Receptor Balance: Preserving Virus Motility,"de Vries E, Du W, Guo H, de Haan CAM.",Trends Microbiol. 2020 Jan;28(1):57-67. doi: 10.1016/j.tim.2019.08.010. Epub 2019 Oct 17.,de Vries E,Trends Microbiol,2020,21-10-2019,PMC7172302,,10.1016/j.tim.2019.08.010,"Influenza A viruses (IAVs) occasionally cross the species barrier and adapt to novel host species. This requires readjustment of the functional balance of the sialic acid receptor-binding hemagglutinin (HA) and the receptor-destroying neuraminidase (NA) to the sialoglycan-receptor repertoire of the new host. Novel techniques have revealed mechanistic details of this HA-NA-receptor balance, emphasizing a previously underappreciated crucial role for NA in driving the motility of receptor-associated IAV particles. Motility enables virion penetration of the sialylated mucus layer as well as attachment to, and uptake into, underlying epithelial cells. As IAVs are essentially irreversibly bound in the absence of NA activity, the fine-tuning of the HA-NA-receptor balance rather than the binding avidity of IAV particles per se is an important factor in determining host species tropism.","Influenza A Virus Hemagglutinin-Neuraminidase-Receptor Balance: Preserving Virus Motility Influenza A viruses (IAVs) occasionally cross the species barrier and adapt to novel host species. This requires readjustment of the functional balance of the sialic acid receptor-binding hemagglutinin (HA) and the receptor-destroying neuraminidase (NA) to the sialoglycan-receptor repertoire of the new host. Novel techniques have revealed mechanistic details of this HA-NA-receptor balance, emphasizing a previously underappreciated crucial role for NA in driving the motility of receptor-associated IAV particles. Motility enables virion penetration of the sialylated mucus layer as well as attachment to, and uptake into, underlying epithelial cells. As IAVs are essentially irreversibly bound in the absence of NA activity, the fine-tuning of the HA-NA-receptor balance rather than the binding avidity of IAV particles per se is an important factor in determining host species tropism.",0,0
29085369,Sugar or Fat?-Metabolic Requirements for Immunity to Viral Infections,"Shehata HM, Murphy AJ, Lee MKS, Gardiner CM, Crowe SM, Sanjabi S, Finlay DK, Palmer CS.",Front Immunol. 2017 Oct 16;8:1311. doi: 10.3389/fimmu.2017.01311. eCollection 2017.,Shehata HM,Front Immunol,2017,01-11-2017,PMC5649203,,10.3389/fimmu.2017.01311,The realization that an intricate link exists between the metabolic state of immune cells and the nature of the elicited immune responses has brought a dramatic evolution to the field of immunology. We will focus on how metabolic reprogramming through the use of glycolysis and fatty-acid oxidation (sugar or fat) regulates the capacity of immune cells to mount robust and effective immune responses. We will also discuss how fine-tuning sugar and fat metabolism may be exploited as a novel immunotherapeutic strategy to fight viral infections or improve vaccine efficacy.,Sugar or Fat?-Metabolic Requirements for Immunity to Viral Infections The realization that an intricate link exists between the metabolic state of immune cells and the nature of the elicited immune responses has brought a dramatic evolution to the field of immunology. We will focus on how metabolic reprogramming through the use of glycolysis and fatty-acid oxidation (sugar or fat) regulates the capacity of immune cells to mount robust and effective immune responses. We will also discuss how fine-tuning sugar and fat metabolism may be exploited as a novel immunotherapeutic strategy to fight viral infections or improve vaccine efficacy.,0,0
34471260,SARS-CoV-2-specific T cells in infection and vaccination,"Bertoletti A, Le Bert N, Qui M, Tan AT.",Cell Mol Immunol. 2021 Oct;18(10):2307-2312. doi: 10.1038/s41423-021-00743-3. Epub 2021 Sep 1.,Bertoletti A,Cell Mol Immunol,2021,02-09-2021,PMC8408362,,10.1038/s41423-021-00743-3,"During viral infections, antibodies and T cells act together to prevent pathogen spread and remove virus-infected cells. Virus-specific adaptive immunity can, however, also trigger pathological processes characterized by localized or systemic inflammatory events. The protective and/or pathological role of virus-specific T cells in SARS-CoV-2 infection has been the focus of many studies in COVID-19 patients and in vaccinated individuals. Here, we review the works that have elucidated the function of SARS-CoV-2-specific T cells in patients and in vaccinated individuals. Understanding whether SARS-CoV-2-specific T cells are more linked to protection or pathogenesis is pivotal to define future therapeutic and prophylactic strategies to manage the current pandemic.","SARS-CoV-2-specific T cells in infection and vaccination During viral infections, antibodies and T cells act together to prevent pathogen spread and remove virus-infected cells. Virus-specific adaptive immunity can, however, also trigger pathological processes characterized by localized or systemic inflammatory events. The protective and/or pathological role of virus-specific T cells in SARS-CoV-2 infection has been the focus of many studies in COVID-19 patients and in vaccinated individuals. Here, we review the works that have elucidated the function of SARS-CoV-2-specific T cells in patients and in vaccinated individuals. Understanding whether SARS-CoV-2-specific T cells are more linked to protection or pathogenesis is pivotal to define future therapeutic and prophylactic strategies to manage the current pandemic.",0,0
29316747,Immunotherapy for Chronic Hepatitis B Virus Infection,"Bertoletti A, Le Bert N.",Gut Liver. 2018 Sep 15;12(5):497-507. doi: 10.5009/gnl17233.,Bertoletti A,Gut Liver,2018,11-01-2018,PMC6143456,,10.5009/gnl17233,"While new therapies for chronic hepatitis C virus infection have delivered remarkable cure rates, curative therapies for chronic hepatitis B virus (HBV) infection remain a distant goal. Although current direct antiviral therapies are very efficient in controlling viral replication and limiting the progression to cirrhosis, these treatments require lifelong administration due to the frequent viral rebound upon treatment cessation, and immune modulation with interferon is only effective in a subgroup of patients. Specific immunotherapies can offer the possibility of eliminating or at least stably maintaining low levels of HBV replication under the control of a functional host antiviral response. Here, we review the development of immune cell therapy for HBV, highlighting the potential antiviral efficiency and potential toxicities in different groups of chronically infected HBV patients. We also discuss the chronic hepatitis B patient populations that best benefit from therapeutic immune interventions.","Immunotherapy for Chronic Hepatitis B Virus Infection While new therapies for chronic hepatitis C virus infection have delivered remarkable cure rates, curative therapies for chronic hepatitis B virus (HBV) infection remain a distant goal. Although current direct antiviral therapies are very efficient in controlling viral replication and limiting the progression to cirrhosis, these treatments require lifelong administration due to the frequent viral rebound upon treatment cessation, and immune modulation with interferon is only effective in a subgroup of patients. Specific immunotherapies can offer the possibility of eliminating or at least stably maintaining low levels of HBV replication under the control of a functional host antiviral response. Here, we review the development of immune cell therapy for HBV, highlighting the potential antiviral efficiency and potential toxicities in different groups of chronically infected HBV patients. We also discuss the chronic hepatitis B patient populations that best benefit from therapeutic immune interventions.",0,0
37986764,Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation,"Ge J, Sun S, Owens J, Galvez V, Gologorskaya O, Lai JC, Pletcher MJ, Lai K.",medRxiv [Preprint]. 2023 Nov 10:2023.11.10.23298364. doi: 10.1101/2023.11.10.23298364.,Ge J,medRxiv,2023,21-11-2023,PMC10659484,,10.1101/2023.11.10.23298364,"BACKGROUND: Large language models (LLMs) have significant capabilities in clinical information processing tasks. Commercially available LLMs, however, are not optimized for clinical uses and are prone to generating incorrect or hallucinatory information. Retrieval-augmented generation (RAG) is an enterprise architecture that allows embedding of customized data into LLMs. This approach ""specializes"" the LLMs and is thought to reduce hallucinations.
METHODS: We developed ""LiVersa,"" a liver disease-specific LLM, by using our institution's protected health information (PHI)-complaint text embedding and LLM platform, ""Versa."" We conducted RAG on 30 publicly available American Association for the Study of Liver Diseases (AASLD) guidelines and guidance documents to be incorporated into LiVersa. We evaluated LiVersa's performance by comparing its responses versus those of trainees from a previously published knowledge assessment study regarding hepatitis B (HBV) treatment and hepatocellular carcinoma (HCC) surveillance.
RESULTS: LiVersa answered all 10 questions correctly when forced to provide a ""yes"" or ""no"" answer. Full detailed responses with justifications and rationales, however, were not completely correct for three of the questions.
DISCUSSIONS: In this study, we demonstrated the ability to build disease-specific and PHI-compliant LLMs using RAG. While our LLM, LiVersa, demonstrated more specificity in answering questions related to clinical hepatology - there were some knowledge deficiencies due to limitations set by the number and types of documents used for RAG. The LiVersa prototype, however, is a proof of concept for utilizing RAG to customize LLMs for clinical uses and a potential strategy to realize personalized medicine in the future.","Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation BACKGROUND: Large language models (LLMs) have significant capabilities in clinical information processing tasks. Commercially available LLMs, however, are not optimized for clinical uses and are prone to generating incorrect or hallucinatory information. Retrieval-augmented generation (RAG) is an enterprise architecture that allows embedding of customized data into LLMs. This approach ""specializes"" the LLMs and is thought to reduce hallucinations.
METHODS: We developed ""LiVersa,"" a liver disease-specific LLM, by using our institution's protected health information (PHI)-complaint text embedding and LLM platform, ""Versa."" We conducted RAG on 30 publicly available American Association for the Study of Liver Diseases (AASLD) guidelines and guidance documents to be incorporated into LiVersa. We evaluated LiVersa's performance by comparing its responses versus those of trainees from a previously published knowledge assessment study regarding hepatitis B (HBV) treatment and hepatocellular carcinoma (HCC) surveillance.
RESULTS: LiVersa answered all 10 questions correctly when forced to provide a ""yes"" or ""no"" answer. Full detailed responses with justifications and rationales, however, were not completely correct for three of the questions.
DISCUSSIONS: In this study, we demonstrated the ability to build disease-specific and PHI-compliant LLMs using RAG. While our LLM, LiVersa, demonstrated more specificity in answering questions related to clinical hepatology - there were some knowledge deficiencies due to limitations set by the number and types of documents used for RAG. The LiVersa prototype, however, is a proof of concept for utilizing RAG to customize LLMs for clinical uses and a potential strategy to realize personalized medicine in the future.",1,1
33751621,The next-generation coronavirus diagnostic techniques with particular emphasis on the SARS-CoV-2,Hemida MG.,J Med Virol. 2021 Jul;93(7):4219-4241. doi: 10.1002/jmv.26926. Epub 2021 Mar 26.,Hemida MG,J Med Virol,2021,22-03-2021,PMC8207115,,10.1002/jmv.26926,"The potential zoonotic coronaviruses (SARS-CoV, MERS-CoV, and SARS-CoV-2) are of global health concerns. Early diagnosis is the milestone in their mitigation, control, and eradication. Many diagnostic techniques are showing great success and have many advantages, such as the rapid turnover of the results, high accuracy, and high specificity and sensitivity. However, some of these techniques have several pitfalls if samples were not collected, processed, and transported in the standard ways and if these techniques were not practiced with extreme caution and precision. This may lead to false-negative/positive results. This may affect the downstream management of the affected cases. These techniques require regular fine-tuning, upgrading, and optimization. The continuous evolution of new strains and viruses belong to the coronaviruses is hampering the success of many classical techniques. There are urgent needs for next generations of coronaviruses diagnostic assays that overcome these pitfalls. This new generation of diagnostic tests should be able to do simultaneous, multiplex, and high-throughput detection of various coronavirus in one reaction. Furthermore, the development of novel assays and techniques that enable the in situ detection of the virus on the environmental samples, especially air, water, and surfaces, should be given considerable attention in the future. These approaches will have a substantial positive impact on the mitigation and eradication of coronaviruses, including the current SARS-CoV-2 pandemic.","The next-generation coronavirus diagnostic techniques with particular emphasis on the SARS-CoV-2 The potential zoonotic coronaviruses (SARS-CoV, MERS-CoV, and SARS-CoV-2) are of global health concerns. Early diagnosis is the milestone in their mitigation, control, and eradication. Many diagnostic techniques are showing great success and have many advantages, such as the rapid turnover of the results, high accuracy, and high specificity and sensitivity. However, some of these techniques have several pitfalls if samples were not collected, processed, and transported in the standard ways and if these techniques were not practiced with extreme caution and precision. This may lead to false-negative/positive results. This may affect the downstream management of the affected cases. These techniques require regular fine-tuning, upgrading, and optimization. The continuous evolution of new strains and viruses belong to the coronaviruses is hampering the success of many classical techniques. There are urgent needs for next generations of coronaviruses diagnostic assays that overcome these pitfalls. This new generation of diagnostic tests should be able to do simultaneous, multiplex, and high-throughput detection of various coronavirus in one reaction. Furthermore, the development of novel assays and techniques that enable the in situ detection of the virus on the environmental samples, especially air, water, and surfaces, should be given considerable attention in the future. These approaches will have a substantial positive impact on the mitigation and eradication of coronaviruses, including the current SARS-CoV-2 pandemic.",1,0
35246954,Impact of structural dynamics on biological functions of flaviviruses,"Stiasny K, Medits I, Roßbacher L, Heinz FX.",FEBS J. 2023 Apr;290(8):1973-1985. doi: 10.1111/febs.16419. Epub 2022 Mar 11.,Stiasny K,FEBS J,2023,05-03-2022,PMC10952610,,10.1111/febs.16419,"Flaviviruses comprise a number of mosquito- or tick-transmitted human pathogens of global public health importance. Advances in structural biology techniques have contributed substantially to our current understanding of the life cycle of these small enveloped RNA viruses and led to deep insights into details of virus assembly, maturation and cell entry. In addition to large-scale conformational changes and oligomeric rearrangements of envelope proteins during these processes, there is increasing evidence that smaller-scale protein dynamics (referred to as virus ""breathing"") can confer extra flexibility to these viruses for the fine-tuning of their interactions with the immune system and possibly with cellular factors they encounter in their complex ecological cycles in arthropod and vertebrate hosts. In this review, we discuss how work with tick-borne encephalitis virus has extended our view on flavivirus breathing, leading to the identification of a novel mechanism of antibody-mediated infection enhancement and demonstrating breathing intermediates of the envelope protein in the process of membrane fusion. These data are discussed in the context of other flaviviruses and the perspective of a potential role of virus breathing to cope with the requirements of adaptation and replication in evolutionarily very different hosts.","Impact of structural dynamics on biological functions of flaviviruses Flaviviruses comprise a number of mosquito- or tick-transmitted human pathogens of global public health importance. Advances in structural biology techniques have contributed substantially to our current understanding of the life cycle of these small enveloped RNA viruses and led to deep insights into details of virus assembly, maturation and cell entry. In addition to large-scale conformational changes and oligomeric rearrangements of envelope proteins during these processes, there is increasing evidence that smaller-scale protein dynamics (referred to as virus ""breathing"") can confer extra flexibility to these viruses for the fine-tuning of their interactions with the immune system and possibly with cellular factors they encounter in their complex ecological cycles in arthropod and vertebrate hosts. In this review, we discuss how work with tick-borne encephalitis virus has extended our view on flavivirus breathing, leading to the identification of a novel mechanism of antibody-mediated infection enhancement and demonstrating breathing intermediates of the envelope protein in the process of membrane fusion. These data are discussed in the context of other flaviviruses and the perspective of a potential role of virus breathing to cope with the requirements of adaptation and replication in evolutionarily very different hosts.",0,0
37066106,Imaging Spectrum of HTLV-1-Related Neurologic Disease: A Pooled Series and Review,"Dixon L, McNamara C, Dhasmana D, Taylor GP, Davies N.",Neurol Clin Pract. 2023 Jun;13(3):e200147. doi: 10.1212/CPJ.0000000000200147. Epub 2023 Mar 27.,Dixon L,Neurol Clin Pract,2023,17-04-2023,PMC10092304,,10.1212/CPJ.0000000000200147,"PURPOSE OF REVIEW: Human T-cell lymphotropic virus type 1 (HTLV-1)-associated myelopathy (HAM) is a well-recognized neurologic complication of HTLV-1. Beyond HAM, several other neurologic manifestations are increasingly recognized, including acute myelopathy, encephalopathy, and myositis. The clinical and imaging features of these presentations are less well understood and potentially underdiagnosed. In this study, we summarize the imaging features of HTLV-1-related neurologic disease, providing both a pictorial review and pooled series of the less well-recognized presentations.
RECENT FINDINGS: 35 cases of acute/subacute HAM and 12 cases of HTLV-1-related encephalopathy were found. In subacute HAM, cervical and upper thoracic longitudinally extensive tranverse myelitis was noted, while in HTLV-1-related encephalopathy, confluent lesions in the frontoparietal white matter and along the corticospinal tracts were the most prevalent finding.
SUMMARY: There are varied clinical and imaging presentations of HTLV-1-related neurologic disease. Recognition of these features aids early diagnosis where therapy may have the greatest benefit.","Imaging Spectrum of HTLV-1-Related Neurologic Disease: A Pooled Series and Review PURPOSE OF REVIEW: Human T-cell lymphotropic virus type 1 (HTLV-1)-associated myelopathy (HAM) is a well-recognized neurologic complication of HTLV-1. Beyond HAM, several other neurologic manifestations are increasingly recognized, including acute myelopathy, encephalopathy, and myositis. The clinical and imaging features of these presentations are less well understood and potentially underdiagnosed. In this study, we summarize the imaging features of HTLV-1-related neurologic disease, providing both a pictorial review and pooled series of the less well-recognized presentations.
RECENT FINDINGS: 35 cases of acute/subacute HAM and 12 cases of HTLV-1-related encephalopathy were found. In subacute HAM, cervical and upper thoracic longitudinally extensive tranverse myelitis was noted, while in HTLV-1-related encephalopathy, confluent lesions in the frontoparietal white matter and along the corticospinal tracts were the most prevalent finding.
SUMMARY: There are varied clinical and imaging presentations of HTLV-1-related neurologic disease. Recognition of these features aids early diagnosis where therapy may have the greatest benefit.",0,0
31852501,p30 protein: a critical regulator of HTLV-1 viral latency and host immunity,"Moles R, Sarkis S, Galli V, Omsland M, Purcell DFJ, Yurick D, Khoury G, Pise-Masison CA, Franchini G.",Retrovirology. 2019 Dec 18;16(1):42. doi: 10.1186/s12977-019-0501-2.,Moles R,Retrovirology,2019,20-12-2019,PMC6921414,,10.1186/s12977-019-0501-2,"The extraordinarily high prevalence of HTLV-1 subtype C (HTLV-1C) in some isolated indigenous communities in Oceania and the severity of the health conditions associated with the virus impress the great need for basic and translational research to prevent and treat HTLV-1 infection. The genome of the virus's most common subtype, HTLV-1A, encodes structural, enzymatic, and regulatory proteins that contribute to viral persistence and pathogenesis. Among these is the p30 protein encoded by the doubly spliced Tax-orf II mRNA, a nuclear/nucleolar protein with both transcriptional and post-transcriptional activity. The p30 protein inhibits the productive replication cycle via nuclear retention of the mRNA that encodes for both the viral transcriptional trans-activator Tax, and the Rex proteins that regulate the transport of incompletely spliced viral mRNA to the cytoplasm. In myeloid cells, p30 inhibits the PU-1 transcription factor that regulates interferon expression and is a critical mediator of innate and adaptive immunity. Furthermore, p30 alters gene expression, cell cycle progression, and DNA damage responses in T-cells, raising the hypothesis that p30 may directly contribute to T cell transformation. By fine-tuning viral expression while also inhibiting host innate responses, p30 is likely essential for viral infection and persistence. This concept is supported by the finding that macaques, a natural host for the closely genetically related simian T-cell leukemia virus 1 (STLV-1), exposed to an HTLV-1 knockout for p30 expression by a single point mutation do not became infected unless reversion and selection of the wild type HTLV-1 genotype occurs. All together, these data suggest that inhibition of p30 may help to curb and eventually eradicate viral infection by exposing infected cells to an effective host immune response.","p30 protein: a critical regulator of HTLV-1 viral latency and host immunity The extraordinarily high prevalence of HTLV-1 subtype C (HTLV-1C) in some isolated indigenous communities in Oceania and the severity of the health conditions associated with the virus impress the great need for basic and translational research to prevent and treat HTLV-1 infection. The genome of the virus's most common subtype, HTLV-1A, encodes structural, enzymatic, and regulatory proteins that contribute to viral persistence and pathogenesis. Among these is the p30 protein encoded by the doubly spliced Tax-orf II mRNA, a nuclear/nucleolar protein with both transcriptional and post-transcriptional activity. The p30 protein inhibits the productive replication cycle via nuclear retention of the mRNA that encodes for both the viral transcriptional trans-activator Tax, and the Rex proteins that regulate the transport of incompletely spliced viral mRNA to the cytoplasm. In myeloid cells, p30 inhibits the PU-1 transcription factor that regulates interferon expression and is a critical mediator of innate and adaptive immunity. Furthermore, p30 alters gene expression, cell cycle progression, and DNA damage responses in T-cells, raising the hypothesis that p30 may directly contribute to T cell transformation. By fine-tuning viral expression while also inhibiting host innate responses, p30 is likely essential for viral infection and persistence. This concept is supported by the finding that macaques, a natural host for the closely genetically related simian T-cell leukemia virus 1 (STLV-1), exposed to an HTLV-1 knockout for p30 expression by a single point mutation do not became infected unless reversion and selection of the wild type HTLV-1 genotype occurs. All together, these data suggest that inhibition of p30 may help to curb and eventually eradicate viral infection by exposing infected cells to an effective host immune response.",0,0
38836759,Evaluating the Base Excision Repair Inhibitor TRC102 and Temozolomide for Patients with Recurrent Glioblastoma in the Phase 2 Adult Brain Tumor Consortium Trial BERT,"Ahluwalia MS, Ozair A, Drappatz J, Ye X, Peng S, Lee M, Rath S, Dhruv H, Hao Y, Berens ME, Walbert T, Holdhoff M, Lesser GJ, Cloughesy TF, Sloan AE, Takebe N, Couce M, Peereboom DM, Nabors B, Wen PY, Grossman SA, Rogers LR.",Clin Cancer Res. 2024 Aug 1;30(15):3167-3178. doi: 10.1158/1078-0432.CCR-23-4098.,Ahluwalia MS,Clin Cancer Res,2024,05-06-2024,PMC11293959,NIHMS1996136,10.1158/1078-0432.CCR-23-4098,"PURPOSE: Patients with glioblastoma (GBM) have a dismal prognosis. Although the DNA alkylating agent temozolomide (TMZ) is the mainstay of chemotherapy, therapeutic resistance rapidly develops in patients. Base excision repair inhibitor TRC102 (methoxyamine) reverses TMZ resistance in preclinical glioma models. We aimed to investigate the efficacy and safety of oral TRC102+TMZ in recurrent GBM (rGBM).
PATIENTS AND METHODS: A preregistered (NCT02395692), nonrandomized, multicenter, phase 2 clinical trial (BERT) was planned and conducted through the Adult Brain Tumor Consortium (ABTC-1402). Arm 1 included patients with bevacizumab-naïve GBM at the first recurrence, with the primary endpoint of response rates. If sufficient activity was identified, a second arm was planned for the bevacizumab-refractory patients. The secondary endpoints were overall survival (OS), progression-free survival (PFS), PFS at 6 months (PFS6), and toxicity.
RESULTS: Arm 1 enrolled 19 patients with a median of two treatment cycles. Objective responses were not observed; hence, arm 2 did not open. The median OS was 11.1 months [95% confidence interval (CI), 8.2-17.9]. The median PFS was 1.9 months (95% CI, 1.8-3.7). The PFS6 was 10.5% (95% CI, 1.3%-33.1%). Most toxicities were grades 1 and 2, with two grade 3 lymphopenias and one grade 4 thrombocytopenia. Two patients with PFS ≥ 17 months and OS > 32 months were deemed ""extended survivors."" RNA sequencing of tumor tissue, obtained at diagnosis, demonstrated significantly enriched signatures of DNA damage response (DDR), chromosomal instability (CIN70, CIN25), and cellular proliferation (PCNA25) in ""extended survivors.""
CONCLUSIONS: These findings confirm the safety and feasibility of TRC102+TMZ in patients with rGBM. They also warrant further evaluation of combination therapy in biomarker-enriched trials enrolling GBM patients with baseline hyperactivated DDR pathways.","Evaluating the Base Excision Repair Inhibitor TRC102 and Temozolomide for Patients with Recurrent Glioblastoma in the Phase 2 Adult Brain Tumor Consortium Trial BERT PURPOSE: Patients with glioblastoma (GBM) have a dismal prognosis. Although the DNA alkylating agent temozolomide (TMZ) is the mainstay of chemotherapy, therapeutic resistance rapidly develops in patients. Base excision repair inhibitor TRC102 (methoxyamine) reverses TMZ resistance in preclinical glioma models. We aimed to investigate the efficacy and safety of oral TRC102+TMZ in recurrent GBM (rGBM).
PATIENTS AND METHODS: A preregistered (NCT02395692), nonrandomized, multicenter, phase 2 clinical trial (BERT) was planned and conducted through the Adult Brain Tumor Consortium (ABTC-1402). Arm 1 included patients with bevacizumab-naïve GBM at the first recurrence, with the primary endpoint of response rates. If sufficient activity was identified, a second arm was planned for the bevacizumab-refractory patients. The secondary endpoints were overall survival (OS), progression-free survival (PFS), PFS at 6 months (PFS6), and toxicity.
RESULTS: Arm 1 enrolled 19 patients with a median of two treatment cycles. Objective responses were not observed; hence, arm 2 did not open. The median OS was 11.1 months [95% confidence interval (CI), 8.2-17.9]. The median PFS was 1.9 months (95% CI, 1.8-3.7). The PFS6 was 10.5% (95% CI, 1.3%-33.1%). Most toxicities were grades 1 and 2, with two grade 3 lymphopenias and one grade 4 thrombocytopenia. Two patients with PFS ≥ 17 months and OS > 32 months were deemed ""extended survivors."" RNA sequencing of tumor tissue, obtained at diagnosis, demonstrated significantly enriched signatures of DNA damage response (DDR), chromosomal instability (CIN70, CIN25), and cellular proliferation (PCNA25) in ""extended survivors.""
CONCLUSIONS: These findings confirm the safety and feasibility of TRC102+TMZ in patients with rGBM. They also warrant further evaluation of combination therapy in biomarker-enriched trials enrolling GBM patients with baseline hyperactivated DDR pathways.",0,0
38757942,Highlights from the 2023 International Meeting on the Molecular Biology of Hepatitis B virus,"HBV2023; Allweiss L, Cohen C, Dias J, Fumagalli V, Guo H, Harris JM, Hu J, Iannacone M, Isogawa M, Jeng WJ, Kim KH, Kramvis A, Li W, Lucifora J, Muramatsu M, Neuveut C, Ploss A, Pollicino T, Protzer U, Tan A, Tanaka Y, Tu T, Tsukuda S, Thimme R, Urban S, Watashi K, Yuan Z, Yeh SH, McKeating JA, Revill PA.",J Gen Virol. 2024 May;105(5):001978. doi: 10.1099/jgv.0.001978.,HBV2023,J Gen Virol,2024,17-05-2024,PMC11258880,,10.1099/jgv.0.001978,"Since its discovery in 1965, our understanding of the hepatitis B virus (HBV) replication cycle and host immune responses has increased markedly. In contrast, our knowledge of the molecular biology of hepatitis delta virus (HDV), which is associated with more severe liver disease, is less well understood. Despite the progress made, critical gaps remain in our knowledge of HBV and HDV replication and the mechanisms underlying viral persistence and evasion of host immunity. The International HBV Meeting is the leading annual scientific meeting for presenting the latest advances in HBV and HDV molecular virology, immunology, and epidemiology. In 2023, the annual scientific meeting was held in Kobe, Japan and this review summarises some of the advances presented at the Meeting and lists gaps in our knowledge that may facilitate the development of new therapies.","Highlights from the 2023 International Meeting on the Molecular Biology of Hepatitis B virus Since its discovery in 1965, our understanding of the hepatitis B virus (HBV) replication cycle and host immune responses has increased markedly. In contrast, our knowledge of the molecular biology of hepatitis delta virus (HDV), which is associated with more severe liver disease, is less well understood. Despite the progress made, critical gaps remain in our knowledge of HBV and HDV replication and the mechanisms underlying viral persistence and evasion of host immunity. The International HBV Meeting is the leading annual scientific meeting for presenting the latest advances in HBV and HDV molecular virology, immunology, and epidemiology. In 2023, the annual scientific meeting was held in Kobe, Japan and this review summarises some of the advances presented at the Meeting and lists gaps in our knowledge that may facilitate the development of new therapies.",0,0
26951645,"Defining characteristics and risk indicators for diagnosing nursing home-acquired pneumonia and aspiration pneumonia in nursing home residents, using the electronically-modified Delphi Method","Hollaar V, van der Maarel-Wierink C, van der Putten GJ, van der Sanden W, de Swart B, de Baat C.",BMC Geriatr. 2016 Mar 7;16:60. doi: 10.1186/s12877-016-0231-4.,Hollaar V,BMC Geriatr,2016,09-03-2016,PMC4782327,,10.1186/s12877-016-0231-4,"BACKGROUND: In nursing home residents, it is not possible to distinguish pneumonia and aspiration pneumonia clinically. International literature reveals no consensus on which and how many characteristics and risk indicators must be present to diagnose (nursing home-acquired) pneumonia and aspiration pneumonia. The aim of this survey was to reach consensus among a panel of clinical medical experts in geriatrics and pulmonology about the characteristics required for diagnosing pneumonia, and about the risk indicators needed to consider the diagnosis aspiration pneumonia in nursing home residents with pneumonia.
METHODS: Literature review and three expert-rating iterations using the electronically-modified Delphi Method were carried out. After each expert rating iteration, data analysis was performed. Qualitative responses and additional (nursing home-acquired) pneumonia characteristics which were mentioned in reply to structured open-ended questions were summarised, whilst similar responses were combined and these combinations were ordered by frequency in order to use them in the next iteration. Characteristics which failed to reach consensus were considered as inconclusive and eliminated. Consensus was reached when at least 70 % of the participants agreed.
RESULTS: Literature review revealed 16 currently used common characteristics for diagnosing (nursing home-acquired) pneumonia. No consensus was reached about characteristics and the number of characteristics required for diagnosing (nursing home-acquired) pneumonia. However, 57 % agreed that dyspnea, fever, deterioration of general functioning, tachypnea and crepitation with auscultation are the most important characteristics and the responses by the participants suggested that two or three characteristics should be present. Subsequently, 80 % of the participants agreed on the risk indicators dysphagia, choking incident, (history of) tube feeding, neurological disease and cognitive impairment for considering the diagnosis aspiration pneumonia in nursing home residents with pneumonia.
CONCLUSIONS: No final consensus could be reached about which and how many characteristics are required for diagnosing pneumonia in nursing home residents. However, the results indicated that dyspnea, fever, deterioration of general functioning, tachypnea and crepitation with auscultation are characteristics of some importance and that at least two or three characteristics should be present. With regard to considering aspiration pneumonia in nursing home residents with pneumonia, final consensus was reached about the risk indicators dysphagia, choking incident, (history of) tube feeding, neurological disease and cognitive impairment.","Defining characteristics and risk indicators for diagnosing nursing home-acquired pneumonia and aspiration pneumonia in nursing home residents, using the electronically-modified Delphi Method BACKGROUND: In nursing home residents, it is not possible to distinguish pneumonia and aspiration pneumonia clinically. International literature reveals no consensus on which and how many characteristics and risk indicators must be present to diagnose (nursing home-acquired) pneumonia and aspiration pneumonia. The aim of this survey was to reach consensus among a panel of clinical medical experts in geriatrics and pulmonology about the characteristics required for diagnosing pneumonia, and about the risk indicators needed to consider the diagnosis aspiration pneumonia in nursing home residents with pneumonia.
METHODS: Literature review and three expert-rating iterations using the electronically-modified Delphi Method were carried out. After each expert rating iteration, data analysis was performed. Qualitative responses and additional (nursing home-acquired) pneumonia characteristics which were mentioned in reply to structured open-ended questions were summarised, whilst similar responses were combined and these combinations were ordered by frequency in order to use them in the next iteration. Characteristics which failed to reach consensus were considered as inconclusive and eliminated. Consensus was reached when at least 70 % of the participants agreed.
RESULTS: Literature review revealed 16 currently used common characteristics for diagnosing (nursing home-acquired) pneumonia. No consensus was reached about characteristics and the number of characteristics required for diagnosing (nursing home-acquired) pneumonia. However, 57 % agreed that dyspnea, fever, deterioration of general functioning, tachypnea and crepitation with auscultation are the most important characteristics and the responses by the participants suggested that two or three characteristics should be present. Subsequently, 80 % of the participants agreed on the risk indicators dysphagia, choking incident, (history of) tube feeding, neurological disease and cognitive impairment for considering the diagnosis aspiration pneumonia in nursing home residents with pneumonia.
CONCLUSIONS: No final consensus could be reached about which and how many characteristics are required for diagnosing pneumonia in nursing home residents. However, the results indicated that dyspnea, fever, deterioration of general functioning, tachypnea and crepitation with auscultation are characteristics of some importance and that at least two or three characteristics should be present. With regard to considering aspiration pneumonia in nursing home residents with pneumonia, final consensus was reached about the risk indicators dysphagia, choking incident, (history of) tube feeding, neurological disease and cognitive impairment.",0,0
37197952,Gaps in the Care of Subjects with Familial Hypercholesterolemia: Insights from the Thai Familial Hypercholesterolemia Registry,"Ganokroj P, Muanpetch S, Deerochanawong C, Phimphilai M, Leelawattana R, Thongtang N, Krittayaphong R, Anthanont P, Vathesatogkit P, Sriphrapradang C, Senthong V, Torpongpun A, Suteerayongprasert P, Pengpong N, Sathavarodom N, Sunanta U, Porntharukchareon T, Kiatpanabhikul P, Kaewkrasaesin C, Suraamornkul S, Kongkit J, Umphonsathien M, Chattranukulchai P, Jiamjarasrungsi W, Khovidhunkit W.",J Atheroscler Thromb. 2023 Dec 1;30(12):1803-1816. doi: 10.5551/jat.64081. Epub 2023 May 18.,Ganokroj P,J Atheroscler Thromb,2023,17-05-2023,PMC10703574,,10.5551/jat.64081,"AIMS: Familial hypercholesterolemia (FH) is currently underdiagnosed and undertreated. The establishment of a FH registry could facilitate a deeper understanding of this disease. We described the clinical characteristics of subjects with FH from the Thai FH Registry, compared our data with the regional and global data, and identified gaps in the care of these subjects.
METHODS: A multicenter, nationwide prospective FH registry was established in Thailand. Our data were compared with those of the European Atherosclerosis Society-FH Studies Collaboration. Multiple logistic regression analyses were performed for variables associated with lipid-lowering medication (LLM) use and the attainment of low-density lipoprotein-cholesterol (LDL-C) goal.
RESULTS: The study includes 472 subjects with FH (mean age at FH diagnosis: 46±12 years, 61.4% women). A history of premature coronary artery disease was found in 12%. The percentage of LLM use in subjects with a Dutch Lipid Clinic Network score of ≥ 6 (probable or definite FH) in our registry (64%) was slightly lower than the regional data but higher than the global data. Among those who received statins, 25.2% and 6.4% achieved LDL-C levels of ＜100 mg/dL and ＜70 mg/dL, respectively. Women with FH were less likely to achieve LDL-C ＜70 mg/dL (adjusted odds ratio: 0.22, 95% confidence interval: 0.06-0.71, p=0.012).
CONCLUSIONS: FH in Thailand was diagnosed late, and treatment was inadequate for the majority of subjects. Women with FH were less likely to achieve LDL-C goals. Our insights could potentially help raise awareness and narrow the gap in patient care.","Gaps in the Care of Subjects with Familial Hypercholesterolemia: Insights from the Thai Familial Hypercholesterolemia Registry AIMS: Familial hypercholesterolemia (FH) is currently underdiagnosed and undertreated. The establishment of a FH registry could facilitate a deeper understanding of this disease. We described the clinical characteristics of subjects with FH from the Thai FH Registry, compared our data with the regional and global data, and identified gaps in the care of these subjects.
METHODS: A multicenter, nationwide prospective FH registry was established in Thailand. Our data were compared with those of the European Atherosclerosis Society-FH Studies Collaboration. Multiple logistic regression analyses were performed for variables associated with lipid-lowering medication (LLM) use and the attainment of low-density lipoprotein-cholesterol (LDL-C) goal.
RESULTS: The study includes 472 subjects with FH (mean age at FH diagnosis: 46±12 years, 61.4% women). A history of premature coronary artery disease was found in 12%. The percentage of LLM use in subjects with a Dutch Lipid Clinic Network score of ≥ 6 (probable or definite FH) in our registry (64%) was slightly lower than the regional data but higher than the global data. Among those who received statins, 25.2% and 6.4% achieved LDL-C levels of ＜100 mg/dL and ＜70 mg/dL, respectively. Women with FH were less likely to achieve LDL-C ＜70 mg/dL (adjusted odds ratio: 0.22, 95% confidence interval: 0.06-0.71, p=0.012).
CONCLUSIONS: FH in Thailand was diagnosed late, and treatment was inadequate for the majority of subjects. Women with FH were less likely to achieve LDL-C goals. Our insights could potentially help raise awareness and narrow the gap in patient care.",0,0
34727955,Hospitals with and without neurosurgery: a comparative study evaluating the outcome of patients with traumatic brain injury,"Giugni A, Gamberini L, Carrara G, Antiga L, Brissy O, Buldini V, Calamai I, Csomos A, De Luca A, Ferri E, Fleming JM, Gradisek P, Kaps R, Kyprianou T, Lagomarsino S, Lazar I, Martino C, Mikaszewska-Sokolewicz M, Montis A, Nardai G, Nattino G, Nattino G, Paci G, Portolani L, Xirouchaki N, Chieregato A, Bertolini G; CREACTIVE consortium.",Scand J Trauma Resusc Emerg Med. 2021 Nov 2;29(1):158. doi: 10.1186/s13049-021-00959-2.,Giugni A,Scand J Trauma Resusc Emerg Med,2021,03-11-2021,PMC8561979,,10.1186/s13049-021-00959-2,"BACKGROUND: We leveraged the data of the international CREACTIVE consortium to investigate whether the outcome of traumatic brain injury (TBI) patients admitted to intensive care units (ICU) in hospitals without on-site neurosurgical capabilities (no-NSH) would differ had the same patients been admitted to ICUs in hospitals with neurosurgical capabilities (NSH).
METHODS: The CREACTIVE observational study enrolled more than 8000 patients from 83 ICUs. Adult TBI patients admitted to no-NSH ICUs within 48 h of trauma were propensity-score matched 1:3 with patients admitted to NSH ICUs. The primary outcome was the 6-month extended Glasgow Outcome Scale (GOS-E), while secondary outcomes were ICU and hospital mortality.
RESULTS: A total of 232 patients, less than 5% of the eligible cohort, were admitted to no-NSH ICUs. Each of them was matched to 3 NSH patients, leading to a study sample of 928 TBI patients where the no-NSH and NSH groups were well-balanced with respect to all of the variables included into the propensity score. Patients admitted to no-NSH ICUs experienced significantly higher ICU and in-hospital mortality. Compared to the matched NSH ICU admissions, their 6-month GOS-E scores showed a significantly higher prevalence of upper good recovery for cases with mild TBI and low expected mortality risk at admission, along with a progressively higher incidence of poor outcomes with increased TBI severity and mortality risk.
CONCLUSIONS: In our study, centralization of TBI patients significantly impacted short- and long-term outcomes. For TBI patients admitted to no-NSH centers, our results suggest that the least critically ill can effectively be managed in centers without neurosurgical capabilities. Conversely, the most complex patients would benefit from being treated in high-volume, neuro-oriented ICUs.","Hospitals with and without neurosurgery: a comparative study evaluating the outcome of patients with traumatic brain injury BACKGROUND: We leveraged the data of the international CREACTIVE consortium to investigate whether the outcome of traumatic brain injury (TBI) patients admitted to intensive care units (ICU) in hospitals without on-site neurosurgical capabilities (no-NSH) would differ had the same patients been admitted to ICUs in hospitals with neurosurgical capabilities (NSH).
METHODS: The CREACTIVE observational study enrolled more than 8000 patients from 83 ICUs. Adult TBI patients admitted to no-NSH ICUs within 48 h of trauma were propensity-score matched 1:3 with patients admitted to NSH ICUs. The primary outcome was the 6-month extended Glasgow Outcome Scale (GOS-E), while secondary outcomes were ICU and hospital mortality.
RESULTS: A total of 232 patients, less than 5% of the eligible cohort, were admitted to no-NSH ICUs. Each of them was matched to 3 NSH patients, leading to a study sample of 928 TBI patients where the no-NSH and NSH groups were well-balanced with respect to all of the variables included into the propensity score. Patients admitted to no-NSH ICUs experienced significantly higher ICU and in-hospital mortality. Compared to the matched NSH ICU admissions, their 6-month GOS-E scores showed a significantly higher prevalence of upper good recovery for cases with mild TBI and low expected mortality risk at admission, along with a progressively higher incidence of poor outcomes with increased TBI severity and mortality risk.
CONCLUSIONS: In our study, centralization of TBI patients significantly impacted short- and long-term outcomes. For TBI patients admitted to no-NSH centers, our results suggest that the least critically ill can effectively be managed in centers without neurosurgical capabilities. Conversely, the most complex patients would benefit from being treated in high-volume, neuro-oriented ICUs.",0,0
29613958,The impact of age on the innate immune response and outcomes after severe sepsis/septic shock in trauma and surgical intensive care unit patients,"Brakenridge SC, Efron PA, Stortz JA, Ozrazgat-Baslanti T, Ghita G, Wang Z, Bihorac A, Mohr AM, Brumback BA, Moldawer LL, Moore FA.",J Trauma Acute Care Surg. 2018 Aug;85(2):247-255. doi: 10.1097/TA.0000000000001921.,Brakenridge SC,J Trauma Acute Care Surg,2018,04-04-2018,PMC6081244,NIHMS953627,10.1097/TA.0000000000001921,"BACKGROUND: Advancing age is a strong risk factor for adverse outcomes across multiple disease processes. However, septic surgical and trauma patients are unique in that they incur two or more inflammatory insults. The effects of advanced age on sepsis pathophysiology and outcomes remain unclear.
METHODS: We performed a single-center, prospective observational cohort study of surgical intensive care unit patients with severe sepsis/septic shock. Peripheral blood was collected for genomic, cytokine, and biomarker analysis at 0.5 day, 1 day, 4 days, 7 days, 14 days, 21 days, and 28 days after sepsis onset. Based on sensitivity analysis, cohorts were defined as ""young"" (<55 years) and ""aged"" (≥55 years). We compared age-defined cohorts to determine differences in patient characteristics, biomarker profiles, and clinical outcomes.
RESULTS: The cohort included 173 patients with severe sepsis (n = 93; 53.8%) or septic shock (n = 80; 46.2%), with a mean age of 60.9 (±14.5) years. Intra-abdominal sepsis was the leading source (n = 81; 46.8%), followed by necrotizing soft tissue infection (n = 33, 19.1%) and pneumonia (n = 30; 17.3%). Aged patients had a higher comorbidity burden, but were otherwise similar to the young cohort. The aged cohort had a higher severity of early physiologic derangement (median APACHE II, 23 vs. 18; p = 0.002), greater incidence of multiple organ failure (64.3% vs. 40.4%, p = 0.006), and hospital mortality (15.9% vs. 2.1%; p = 0.016). Six-month mortality was significantly higher in the aged cohort as compared with young cohort (31% vs. 9%; p = 0.003). Aged septic patients biomarker trajectories suggestive of persistent immunosuppression (absolute lymphocyte count, soluble programed death ligand-1) and catabolism (Urine 3MH-Cr ratio, insulin growth factor, IGF1BP3, albumin) out to 28 days after sepsis.
CONCLUSION: Aged, critically ill surgical patients have greater organ dysfunction and incidence of adverse clinical outcomes after sepsis. Biomarker profiles suggest an immunophenotype of persistent immunosuppression and catabolism. Advanced age may necessitate novel therapeutic strategies to promote multisystem organ recovery and improve survival after sepsis.
LEVEL OF EVIDENCE: Prognostic, level II.","The impact of age on the innate immune response and outcomes after severe sepsis/septic shock in trauma and surgical intensive care unit patients BACKGROUND: Advancing age is a strong risk factor for adverse outcomes across multiple disease processes. However, septic surgical and trauma patients are unique in that they incur two or more inflammatory insults. The effects of advanced age on sepsis pathophysiology and outcomes remain unclear.
METHODS: We performed a single-center, prospective observational cohort study of surgical intensive care unit patients with severe sepsis/septic shock. Peripheral blood was collected for genomic, cytokine, and biomarker analysis at 0.5 day, 1 day, 4 days, 7 days, 14 days, 21 days, and 28 days after sepsis onset. Based on sensitivity analysis, cohorts were defined as ""young"" (<55 years) and ""aged"" (≥55 years). We compared age-defined cohorts to determine differences in patient characteristics, biomarker profiles, and clinical outcomes.
RESULTS: The cohort included 173 patients with severe sepsis (n = 93; 53.8%) or septic shock (n = 80; 46.2%), with a mean age of 60.9 (±14.5) years. Intra-abdominal sepsis was the leading source (n = 81; 46.8%), followed by necrotizing soft tissue infection (n = 33, 19.1%) and pneumonia (n = 30; 17.3%). Aged patients had a higher comorbidity burden, but were otherwise similar to the young cohort. The aged cohort had a higher severity of early physiologic derangement (median APACHE II, 23 vs. 18; p = 0.002), greater incidence of multiple organ failure (64.3% vs. 40.4%, p = 0.006), and hospital mortality (15.9% vs. 2.1%; p = 0.016). Six-month mortality was significantly higher in the aged cohort as compared with young cohort (31% vs. 9%; p = 0.003). Aged septic patients biomarker trajectories suggestive of persistent immunosuppression (absolute lymphocyte count, soluble programed death ligand-1) and catabolism (Urine 3MH-Cr ratio, insulin growth factor, IGF1BP3, albumin) out to 28 days after sepsis.
CONCLUSION: Aged, critically ill surgical patients have greater organ dysfunction and incidence of adverse clinical outcomes after sepsis. Biomarker profiles suggest an immunophenotype of persistent immunosuppression and catabolism. Advanced age may necessitate novel therapeutic strategies to promote multisystem organ recovery and improve survival after sepsis.
LEVEL OF EVIDENCE: Prognostic, level II.",0,0
35162380,"Analysis of Clinical Parameters, Drug Consumption and Use of Health Resources in a Southern European Population with Alcohol Abuse Disorder during COVID-19 Pandemic","Lear-Claveras A, González-Álvarez B, Couso-Viana S, Clavería A, Oliván-Blázquez B.",Int J Environ Res Public Health. 2022 Jan 26;19(3):1358. doi: 10.3390/ijerph19031358.,Lear-Claveras A,Int J Environ Res Public Health,2022,15-02-2022,PMC8835241,,10.3390/ijerph19031358,"The disruption in healthcare attention to people with alcohol dependence, along with psychological decompensation as a consequence of lockdown derived from the COVID-19 pandemic could have a negative impact on people who suffer from alcohol abuse disorder. Observational real world data pre-post study included 9966 men aged &gt;16 years registered as having the diagnosis of alcohol abuse disorder in the electronic medical records (EMR) of the Aragon Regional Health Service (Spain). Clinical (Glutamate-oxaloacetate -GOT-, Glutamate pyruvate -GPT-, creatinine, glomerular filtration, systolic blood pressure -SBP-, diastolic blood pressure -DBP-, total cholesterol, LDL, HDL, triglycerides, and body mass index -BMI-), pharmacological (dose per inhabitant per day, DHD, of drugs used in addictive disorders, benzodiazepines and antidepressants) and health resource use variables (primary and specialized care) were considered. A Student's t-test for matched samples was performed to analyze the changes in clinical variables between alcohol abuse disorder patients with and without COVID-19. Only creatinine and LDL showed a significant but clinically irrelevant change six months after the end of the strict lockdown. The total number of DHDs for all drugs included in the study (except for benzodiazepines), decreased. In the same way, the use of health services by these patients also decreased. The impact of COVID-19 among this group of patients has been moderate. The reorganization of health and social services after the declaration of the state of alarm in our country made possible the maintenance of care for this vulnerable population.","Analysis of Clinical Parameters, Drug Consumption and Use of Health Resources in a Southern European Population with Alcohol Abuse Disorder during COVID-19 Pandemic The disruption in healthcare attention to people with alcohol dependence, along with psychological decompensation as a consequence of lockdown derived from the COVID-19 pandemic could have a negative impact on people who suffer from alcohol abuse disorder. Observational real world data pre-post study included 9966 men aged &gt;16 years registered as having the diagnosis of alcohol abuse disorder in the electronic medical records (EMR) of the Aragon Regional Health Service (Spain). Clinical (Glutamate-oxaloacetate -GOT-, Glutamate pyruvate -GPT-, creatinine, glomerular filtration, systolic blood pressure -SBP-, diastolic blood pressure -DBP-, total cholesterol, LDL, HDL, triglycerides, and body mass index -BMI-), pharmacological (dose per inhabitant per day, DHD, of drugs used in addictive disorders, benzodiazepines and antidepressants) and health resource use variables (primary and specialized care) were considered. A Student's t-test for matched samples was performed to analyze the changes in clinical variables between alcohol abuse disorder patients with and without COVID-19. Only creatinine and LDL showed a significant but clinically irrelevant change six months after the end of the strict lockdown. The total number of DHDs for all drugs included in the study (except for benzodiazepines), decreased. In the same way, the use of health services by these patients also decreased. The impact of COVID-19 among this group of patients has been moderate. The reorganization of health and social services after the declaration of the state of alarm in our country made possible the maintenance of care for this vulnerable population.",0,0
35902218,Early-onset neonatal sepsis in the Paris area: a population-based surveillance study from 2019 to 2021,"Sikias P, Biran V, Foix-L'Hélias L, Plainvert C, Boileau P, Bonacorsi S; EOS study group.",Arch Dis Child Fetal Neonatal Ed. 2023 Mar;108(2):114-120. doi: 10.1136/archdischild-2022-324080. Epub 2022 Jul 28.,Sikias P,Arch Dis Child Fetal Neonatal Ed,2023,28-07-2022,PMC9985718,,10.1136/archdischild-2022-324080,"BACKGROUND: Early-onset neonatal sepsis (EOS) is a rare condition but an important cause of severe morbidity and mortality in neonates.
METHODS: This is a prospective observational study in neonates born at ≥34 weeks of gestation (WG). The primary endpoint was EOS, defined by isolation of pathogenic species from blood culture and/or cerebrospinal fluid culture within 72 hours after birth. Data on EOS were collected exhaustively from all maternity wards in Paris area (April 2019-March 2021).
RESULTS: 108 EOS were recorded (annual incidence, 0.32 per 1000 live births; 95% CI 0.26 to 0.38). In term infants, the most frequent pathogens were group B Streptococcus (GBS) (n=47) and Escherichia coli (n=20); in late preterm infants, the most frequent pathogens were E. coli (n=15) and GBS (n=7). Fifteen meningitis cases were diagnosed. Five E. coli strains (14%) were resistant to both amoxicillin and gentamicin, which is an empiric treatment for EOS. Of the 54 infants with GBS infections, 35 were born from mothers with negative GBS prepartum screening test and 8 from mothers with no screening. Two deaths were reported, both in term infants (Proteus mirabilis and E. coli).
CONCLUSION: In neonates ≥34 WG born in the Paris area, GBS was twice as frequent as E. coli in term infants. EOS was six times more frequent in late preterm than in term infants and was due to E. coli in 60% of cases. Prevention of GBS EOS and empiric antibiotic treatment of EOS could be improved.","Early-onset neonatal sepsis in the Paris area: a population-based surveillance study from 2019 to 2021 BACKGROUND: Early-onset neonatal sepsis (EOS) is a rare condition but an important cause of severe morbidity and mortality in neonates.
METHODS: This is a prospective observational study in neonates born at ≥34 weeks of gestation (WG). The primary endpoint was EOS, defined by isolation of pathogenic species from blood culture and/or cerebrospinal fluid culture within 72 hours after birth. Data on EOS were collected exhaustively from all maternity wards in Paris area (April 2019-March 2021).
RESULTS: 108 EOS were recorded (annual incidence, 0.32 per 1000 live births; 95% CI 0.26 to 0.38). In term infants, the most frequent pathogens were group B Streptococcus (GBS) (n=47) and Escherichia coli (n=20); in late preterm infants, the most frequent pathogens were E. coli (n=15) and GBS (n=7). Fifteen meningitis cases were diagnosed. Five E. coli strains (14%) were resistant to both amoxicillin and gentamicin, which is an empiric treatment for EOS. Of the 54 infants with GBS infections, 35 were born from mothers with negative GBS prepartum screening test and 8 from mothers with no screening. Two deaths were reported, both in term infants (Proteus mirabilis and E. coli).
CONCLUSION: In neonates ≥34 WG born in the Paris area, GBS was twice as frequent as E. coli in term infants. EOS was six times more frequent in late preterm than in term infants and was due to E. coli in 60% of cases. Prevention of GBS EOS and empiric antibiotic treatment of EOS could be improved.",0,0
29251709,Benchmarking clinical outcomes and the immunocatabolic phenotype of chronic critical illness after sepsis in surgical intensive care unit patients,"Stortz JA, Mira JC, Raymond SL, Loftus TJ, Ozrazgat-Baslanti T, Wang Z, Ghita GL, Leeuwenburgh C, Segal MS, Bihorac A, Brumback BA, Mohr AM, Efron PA, Moldawer LL, Moore FA, Brakenridge SC.",J Trauma Acute Care Surg. 2018 Feb;84(2):342-349. doi: 10.1097/TA.0000000000001758.,Stortz JA,J Trauma Acute Care Surg,2018,19-12-2017,PMC5780256,NIHMS923506,10.1097/TA.0000000000001758,"BACKGROUND: A growing number of patients survive sepsis but remain chronically critically ill. We sought to define clinical outcomes and incidence of chronic critical illness (CCI) after sepsis and to determine whether selected biomarkers of inflammation, immunosuppression, and catabolism differ between these patients and those that rapidly recover (RAP).
METHODS: This 3-year prospective observational cohort study (NCT02276417) evaluated 145 surgical intensive care unit patients with sepsis for the development of CCI (≥14 days of intensive care unit resource utilization with persistent organ dysfunction). Patient clinical demographics, outcomes, and serial serum/urine samples were collected for plasma protein and urinary metabolite analyses.
RESULTS: Of 145 sepsis patients enrolled, 19 (13%) died during their hospitalization and 71 (49%) developed CCI. The CCI patients were significantly older (mean, 63 ± 15 vs. 58 ± 13 years, p = 0.006) and more likely to be discharged to long-term acute care facilities (32% vs. 3%, p < 0.0001), whereas those with RAP were more often discharged to home or a rehabilitation facility. Six-month mortality was significantly higher in CCI as compared with RAP cohort (37% vs. 2%; p < 0.01). Multivariate logistic regression modeling revealed delayed onset sepsis (>48 hours after admission; odds ratio [OR], 10.93; 95% confidence interval [CI], 4.15-28.82]), interfacility transfer (OR, 3.58; 95% CI, 1.43-8.96), vasopressor-dependent septic shock (OR, 3.75; 95% CI, 1.47-9.54), and Sequential Organ Failure Assessment score of 5 or greater at 72 hours (OR, 5.03; 95% CI, 2.00-12.62) as independent risk factors for the development of CCI. The CCI patients also demonstrated greater elevations in inflammatory cytokines (IL-6, IL-8, IL-10), and biomarker profiles are consistent with persistent immunosuppression (absolute lymphocyte count and soluble programmed death ligand 1) and catabolism (plasma insulin-like growth factor binding protein 3 and urinary 3-methylhistidine excretion).
CONCLUSION: The development of CCI has become the predominant clinical trajectory in critically ill surgical patients with sepsis. These patients exhibit biomarker profiles consistent with an immunocatabolic phenotype of persistent inflammation, immunosuppression, and catabolism.
LEVEL OF EVIDENCE: Prognostic, level II.","Benchmarking clinical outcomes and the immunocatabolic phenotype of chronic critical illness after sepsis in surgical intensive care unit patients BACKGROUND: A growing number of patients survive sepsis but remain chronically critically ill. We sought to define clinical outcomes and incidence of chronic critical illness (CCI) after sepsis and to determine whether selected biomarkers of inflammation, immunosuppression, and catabolism differ between these patients and those that rapidly recover (RAP).
METHODS: This 3-year prospective observational cohort study (NCT02276417) evaluated 145 surgical intensive care unit patients with sepsis for the development of CCI (≥14 days of intensive care unit resource utilization with persistent organ dysfunction). Patient clinical demographics, outcomes, and serial serum/urine samples were collected for plasma protein and urinary metabolite analyses.
RESULTS: Of 145 sepsis patients enrolled, 19 (13%) died during their hospitalization and 71 (49%) developed CCI. The CCI patients were significantly older (mean, 63 ± 15 vs. 58 ± 13 years, p = 0.006) and more likely to be discharged to long-term acute care facilities (32% vs. 3%, p < 0.0001), whereas those with RAP were more often discharged to home or a rehabilitation facility. Six-month mortality was significantly higher in CCI as compared with RAP cohort (37% vs. 2%; p < 0.01). Multivariate logistic regression modeling revealed delayed onset sepsis (>48 hours after admission; odds ratio [OR], 10.93; 95% confidence interval [CI], 4.15-28.82]), interfacility transfer (OR, 3.58; 95% CI, 1.43-8.96), vasopressor-dependent septic shock (OR, 3.75; 95% CI, 1.47-9.54), and Sequential Organ Failure Assessment score of 5 or greater at 72 hours (OR, 5.03; 95% CI, 2.00-12.62) as independent risk factors for the development of CCI. The CCI patients also demonstrated greater elevations in inflammatory cytokines (IL-6, IL-8, IL-10), and biomarker profiles are consistent with persistent immunosuppression (absolute lymphocyte count and soluble programmed death ligand 1) and catabolism (plasma insulin-like growth factor binding protein 3 and urinary 3-methylhistidine excretion).
CONCLUSION: The development of CCI has become the predominant clinical trajectory in critically ill surgical patients with sepsis. These patients exhibit biomarker profiles consistent with an immunocatabolic phenotype of persistent inflammation, immunosuppression, and catabolism.
LEVEL OF EVIDENCE: Prognostic, level II.",0,0
31343620,The Relationship Between Physical Activity and Cardiorespiratory Fitness Among People Living With Human Immunodeficiency Virus Throughout the Life Span,"Webel AR, Perazzo J, Phillips JC, Nokes KM, Rentrope C, Schnall R, Musanti R, Adams Tufts K, Sefcik E, Hamilton MJ, Portillo C, Chaiphibalsarisdi P, Orton P, Davis L, Rose CD.",J Cardiovasc Nurs. 2019 Sep/Oct;34(5):364-371. doi: 10.1097/JCN.0000000000000589.,Webel AR,J Cardiovasc Nurs,2019,26-07-2019,PMC6690753,NIHMS1527429,10.1097/JCN.0000000000000589,"BACKGROUND: People living with human immunodeficiency virus (PLHIV) are at an increased risk for developing cardiovascular disease (CVD). Physical activity and cardiorespiratory fitness in PLHIV are poorly understood.
OBJECTIVE: The aims of this study were to describe physical activity and cardiorespiratory fitness by sex and age and to examine the association between physical activity and cardiorespiratory fitness in PLHIV, controlling for covariates.
METHODS: Seven hundred two PLHIV participated in a cross-sectional study and completed validated measures of self-reported physical activity (7-day Physical Activity Recall) and cardiorespiratory fitness (6-minute walk test). Participants were recruited from 7 diverse sites in the United States and Thailand, and data were analyzed using descriptive statistics and multiple regression to examine the relationship between physical activity and cardiorespiratory fitness.
RESULTS: On average, participants self-reported engaging in 115 minutes of, mostly light (75%), physical activity. Men reported twice the amount of physical activity as women (155 vs 73 minutes, P = .01). Participants' ability to achieve their predicted 6-minute walk test distances was similar between men (68%) and women (69%) (P > .01). For women, vigorous physical activity was associated with a 6.6% increase in cardiorespiratory fitness and being temporarily unemployed was associated with an 18% decline in cardiorespiratory fitness. Cardiorespiratory fitness increased with age (P < .01).
CONCLUSIONS: Weekly physical activity of people living with human immunodeficiency virus averaged 85 minutes of mostly light activity, well below the recommended 150 minutes of moderate activity. Vigorous physical activity was associated with improved cardiorespiratory fitness in women, but not men. Although PLHIV would benefit from interventions to increase physical activity, our data suggest a need to develop sex-specific physical activity strategies.","The Relationship Between Physical Activity and Cardiorespiratory Fitness Among People Living With Human Immunodeficiency Virus Throughout the Life Span BACKGROUND: People living with human immunodeficiency virus (PLHIV) are at an increased risk for developing cardiovascular disease (CVD). Physical activity and cardiorespiratory fitness in PLHIV are poorly understood.
OBJECTIVE: The aims of this study were to describe physical activity and cardiorespiratory fitness by sex and age and to examine the association between physical activity and cardiorespiratory fitness in PLHIV, controlling for covariates.
METHODS: Seven hundred two PLHIV participated in a cross-sectional study and completed validated measures of self-reported physical activity (7-day Physical Activity Recall) and cardiorespiratory fitness (6-minute walk test). Participants were recruited from 7 diverse sites in the United States and Thailand, and data were analyzed using descriptive statistics and multiple regression to examine the relationship between physical activity and cardiorespiratory fitness.
RESULTS: On average, participants self-reported engaging in 115 minutes of, mostly light (75%), physical activity. Men reported twice the amount of physical activity as women (155 vs 73 minutes, P = .01). Participants' ability to achieve their predicted 6-minute walk test distances was similar between men (68%) and women (69%) (P > .01). For women, vigorous physical activity was associated with a 6.6% increase in cardiorespiratory fitness and being temporarily unemployed was associated with an 18% decline in cardiorespiratory fitness. Cardiorespiratory fitness increased with age (P < .01).
CONCLUSIONS: Weekly physical activity of people living with human immunodeficiency virus averaged 85 minutes of mostly light activity, well below the recommended 150 minutes of moderate activity. Vigorous physical activity was associated with improved cardiorespiratory fitness in women, but not men. Although PLHIV would benefit from interventions to increase physical activity, our data suggest a need to develop sex-specific physical activity strategies.",0,0
33261208,Reopening Schools during the COVID-19 Pandemic: Overview and Rapid Systematic Review of Guidelines and Recommendations on Preventive Measures and the Management of Cases,"Lo Moro G, Sinigaglia T, Bert F, Savatteri A, Gualano MR, Siliquini R.",Int J Environ Res Public Health. 2020 Nov 27;17(23):8839. doi: 10.3390/ijerph17238839.,Lo Moro G,Int J Environ Res Public Health,2020,02-12-2020,PMC7731329,,10.3390/ijerph17238839,"Given the limited evidence of school closure effectiveness in containing the pandemic and the consequences for young people, reopening schools with appropriate measures is essential. This overview aimed to describe the main measures planned for the 2020-2021 academic year within the WHO European Region. A rapid systematic review of scientific databases was also performed. The websites of the government, Ministry of Health, and Ministry of Education of European Region countries were searched through 1 October for official documents about the prevention and management of suspected cases/confirmed cases in primary and secondary schools. To find further suggestions, a rapid systematic review was conducted through 20 October searching Pubmed, Scopus, and Embase. There were 23 official documents. France, Luxembourg, Malta, Ireland, Italy, Portugal, the UK, Spain, and San Marino were considered. Performing the rapid review, 855 records were identified and 7 papers were finally selected. The recommendations mostly agreed. However, there was no consensus on the criteria for the return to school of students that tested positive, and the flexibility between attendance at school and remote education for high-risk children often varied. School closure was commonly considered as the very last resort for COVID-19 control. Studies are required to evaluate the impact of different recommendations during this autumn term.","Reopening Schools during the COVID-19 Pandemic: Overview and Rapid Systematic Review of Guidelines and Recommendations on Preventive Measures and the Management of Cases Given the limited evidence of school closure effectiveness in containing the pandemic and the consequences for young people, reopening schools with appropriate measures is essential. This overview aimed to describe the main measures planned for the 2020-2021 academic year within the WHO European Region. A rapid systematic review of scientific databases was also performed. The websites of the government, Ministry of Health, and Ministry of Education of European Region countries were searched through 1 October for official documents about the prevention and management of suspected cases/confirmed cases in primary and secondary schools. To find further suggestions, a rapid systematic review was conducted through 20 October searching Pubmed, Scopus, and Embase. There were 23 official documents. France, Luxembourg, Malta, Ireland, Italy, Portugal, the UK, Spain, and San Marino were considered. Performing the rapid review, 855 records were identified and 7 papers were finally selected. The recommendations mostly agreed. However, there was no consensus on the criteria for the return to school of students that tested positive, and the flexibility between attendance at school and remote education for high-risk children often varied. School closure was commonly considered as the very last resort for COVID-19 control. Studies are required to evaluate the impact of different recommendations during this autumn term.",0,0
33831536,A comparative analysis of system features used in the TREC-COVID information retrieval challenge,"Chen JS, Hersh WR.",J Biomed Inform. 2021 May;117:103745. doi: 10.1016/j.jbi.2021.103745. Epub 2021 Apr 6.,Chen JS,J Biomed Inform,2021,08-04-2021,PMC8021447,,10.1016/j.jbi.2021.103745,"The COVID-19 pandemic has resulted in a rapidly growing quantity of scientific publications from journal articles, preprints, and other sources. The TREC-COVID Challenge was created to evaluate information retrieval (IR) methods and systems for this quickly expanding corpus. Using the COVID-19 Open Research Dataset (CORD-19), several dozen research teams participated in over 5 rounds of the TREC-COVID Challenge. While previous work has compared IR techniques used on other test collections, there are no studies that have analyzed the methods used by participants in the TREC-COVID Challenge. We manually reviewed team run reports from Rounds 2 and 5, extracted features from the documented methodologies, and used a univariate and multivariate regression-based analysis to identify features associated with higher retrieval performance. We observed that fine-tuning datasets with relevance judgments, MS-MARCO, and CORD-19 document vectors was associated with improved performance in Round 2 but not in Round 5. Though the relatively decreased heterogeneity of runs in Round 5 may explain the lack of significance in that round, fine-tuning has been found to improve search performance in previous challenge evaluations by improving a system's ability to map relevant queries and phrases to documents. Furthermore, term expansion was associated with improvement in system performance, and the use of the narrative field in the TREC-COVID topics was associated with decreased system performance in both rounds. These findings emphasize the need for clear queries in search. While our study has some limitations in its generalizability and scope of techniques analyzed, we identified some IR techniques that may be useful in building search systems for COVID-19 using the TREC-COVID test collections.","A comparative analysis of system features used in the TREC-COVID information retrieval challenge The COVID-19 pandemic has resulted in a rapidly growing quantity of scientific publications from journal articles, preprints, and other sources. The TREC-COVID Challenge was created to evaluate information retrieval (IR) methods and systems for this quickly expanding corpus. Using the COVID-19 Open Research Dataset (CORD-19), several dozen research teams participated in over 5 rounds of the TREC-COVID Challenge. While previous work has compared IR techniques used on other test collections, there are no studies that have analyzed the methods used by participants in the TREC-COVID Challenge. We manually reviewed team run reports from Rounds 2 and 5, extracted features from the documented methodologies, and used a univariate and multivariate regression-based analysis to identify features associated with higher retrieval performance. We observed that fine-tuning datasets with relevance judgments, MS-MARCO, and CORD-19 document vectors was associated with improved performance in Round 2 but not in Round 5. Though the relatively decreased heterogeneity of runs in Round 5 may explain the lack of significance in that round, fine-tuning has been found to improve search performance in previous challenge evaluations by improving a system's ability to map relevant queries and phrases to documents. Furthermore, term expansion was associated with improvement in system performance, and the use of the narrative field in the TREC-COVID topics was associated with decreased system performance in both rounds. These findings emphasize the need for clear queries in search. While our study has some limitations in its generalizability and scope of techniques analyzed, we identified some IR techniques that may be useful in building search systems for COVID-19 using the TREC-COVID test collections.",1,0
26756579,PD-1 Expression and Cytokine Secretion Profiles of Mycobacterium tuberculosis-Specific CD4+ T-Cell Subsets; Potential Correlates of Containment in HIV-TB Co-Infection,"Pollock KM, Montamat-Sicotte DJ, Grass L, Cooke GS, Kapembwa MS, Kon OM, Sampson RD, Taylor GP, Lalvani A.",PLoS One. 2016 Jan 12;11(1):e0146905. doi: 10.1371/journal.pone.0146905. eCollection 2016.,Pollock KM,PLoS One,2016,13-01-2016,PMC4710462,,10.1371/journal.pone.0146905,"HIV co-infection is an important risk factor for tuberculosis (TB) providing a powerful model in which to dissect out defective, protective and dysfunctional Mycobacterium tuberculosis (MTB)-specific immune responses. To identify the changes induced by HIV co-infection we compared MTB-specific CD4+ responses in subjects with active TB and latent TB infection (LTBI), with and without HIV co-infection. CD4+ T-cell subsets producing interferon-gamma (IFN-γ), interleukin-2 (IL-2) and tumour necrosis factor-alpha (TNF-α) and expressing CD279 (PD-1) were measured using polychromatic flow-cytometry. HIV-TB co-infection was consistently and independently associated with a reduced frequency of CD4+ IFN-γ and IL-2-dual secreting T-cells and the proportion correlated inversely with HIV viral load (VL). The impact of HIV co-infection on this key MTB-specific T-cell subset identifies them as a potential correlate of mycobacterial immune containment. The percentage of MTB-specific IFN-γ-secreting T-cell subsets that expressed PD-1 was increased in active TB with HIV co-infection and correlated with VL. This identifies a novel correlate of dysregulated immunity to MTB, which may in part explain the paucity of inflammatory response in the face of mycobacterial dissemination that characterizes active TB with HIV co-infection.","PD-1 Expression and Cytokine Secretion Profiles of Mycobacterium tuberculosis-Specific CD4+ T-Cell Subsets; Potential Correlates of Containment in HIV-TB Co-Infection HIV co-infection is an important risk factor for tuberculosis (TB) providing a powerful model in which to dissect out defective, protective and dysfunctional Mycobacterium tuberculosis (MTB)-specific immune responses. To identify the changes induced by HIV co-infection we compared MTB-specific CD4+ responses in subjects with active TB and latent TB infection (LTBI), with and without HIV co-infection. CD4+ T-cell subsets producing interferon-gamma (IFN-γ), interleukin-2 (IL-2) and tumour necrosis factor-alpha (TNF-α) and expressing CD279 (PD-1) were measured using polychromatic flow-cytometry. HIV-TB co-infection was consistently and independently associated with a reduced frequency of CD4+ IFN-γ and IL-2-dual secreting T-cells and the proportion correlated inversely with HIV viral load (VL). The impact of HIV co-infection on this key MTB-specific T-cell subset identifies them as a potential correlate of mycobacterial immune containment. The percentage of MTB-specific IFN-γ-secreting T-cell subsets that expressed PD-1 was increased in active TB with HIV co-infection and correlated with VL. This identifies a novel correlate of dysregulated immunity to MTB, which may in part explain the paucity of inflammatory response in the face of mycobacterial dissemination that characterizes active TB with HIV co-infection.",0,0
25036046,Faecal carriage of extended-spectrum β-lactamase (ESBL)-producing enterobacteria in liver disease patients from two hospitals in Egypt and France: a comparative epidemiological study,"Fam NS, Defasque S, Bert F, Leflon-Guibout V, El-Ray A, El-Ghannam M, Attia ME, Omar M, Desouki DG, Valla D, Nicolas-Chanoine MH.",Epidemiol Infect. 2015 Apr;143(6):1247-55. doi: 10.1017/S0950268814001812. Epub 2014 Jul 18.,Fam NS,Epidemiol Infect,2015,19-07-2014,PMC9507165,,10.1017/S0950268814001812,"This study aimed to assess and compare the epidemiology of faecal carriage of extended spectrum β-lactamase-producing enterobacteria (ESBL-E) in Hepatology departments of two hospitals specializing in liver diseases, Theodor Bilharz Research Institute (TBRI) in Cairo (Egypt) and Beaujon Hospital (Bj) in Clichy (France). CTX-M groups were identified by PCR, and TEM and SHV derivatives with the check-point system. Phylogenetic groups of E. coli were determined by multiplex PCR, and clone ST131 by PCR of gene pabB. Prevalence of ESBL-E was 77·6% (45/58) in TBRI and 6·5% (13/199) in Bj (P < 10-7). Previous hospitalization was more common (P = 0·003) in Bj patients (93%) than in TBRI patients (45%) suggesting high prevalence of ESBL-E in the Egyptian community. The presence of E. coli B2 ST131 among ESBL-E faecal E. coli in Egypt confirms its pervasiveness in the community and raises concern regarding this highly virulent and resistant clone.","Faecal carriage of extended-spectrum β-lactamase (ESBL)-producing enterobacteria in liver disease patients from two hospitals in Egypt and France: a comparative epidemiological study This study aimed to assess and compare the epidemiology of faecal carriage of extended spectrum β-lactamase-producing enterobacteria (ESBL-E) in Hepatology departments of two hospitals specializing in liver diseases, Theodor Bilharz Research Institute (TBRI) in Cairo (Egypt) and Beaujon Hospital (Bj) in Clichy (France). CTX-M groups were identified by PCR, and TEM and SHV derivatives with the check-point system. Phylogenetic groups of E. coli were determined by multiplex PCR, and clone ST131 by PCR of gene pabB. Prevalence of ESBL-E was 77·6% (45/58) in TBRI and 6·5% (13/199) in Bj (P < 10-7). Previous hospitalization was more common (P = 0·003) in Bj patients (93%) than in TBRI patients (45%) suggesting high prevalence of ESBL-E in the Egyptian community. The presence of E. coli B2 ST131 among ESBL-E faecal E. coli in Egypt confirms its pervasiveness in the community and raises concern regarding this highly virulent and resistant clone.",0,0
30852938,Factors predicting influenza vaccination adherence among patients in dialysis: an Italian survey,"Battistella C, Quattrin R, Celotto D, d'Angelo M, Fabbro E, Brusaferro S, Agodi A, Astengo M, Baldo V, Baldovin T, Bert F, Biancone L, Calò LA, Canale A, Castellino P, Carli A, Icardi G, Lopalco PL, Righi A, Siliquini R, Tardivo S, Tassinari F, Veroux M.",Hum Vaccin Immunother. 2019;15(10):2434-2439. doi: 10.1080/21645515.2019.1588005. Epub 2019 Apr 4.,Battistella C,Hum Vaccin Immunother,2019,12-03-2019,PMC6816406,,10.1080/21645515.2019.1588005,"Introduction: The aim of this study was to investigate knowledge and practices about influenza among patients on dialysis services of Italian hospitals at risk of severe influenza infection and vaccine and to identify predictive factors to vaccination adherence. Methods: A cross-sectional observational study was carried out from January 2017 to July 2017 after the 2016/2017 influenza vaccination campaign. The questionnaire was administered to all patients treated in seven large Italian dialysis services. It consisted of influenza vaccination coverage, knowledge about influenza and its vaccination, perceived risk of influenza complications, recommendations on influenza uptake received by general practitioner (GP) and nephrologist. Results: Response rate was 90% (703/781). Patients' knowledge about influenza infection and vaccine were detected by nine closed questions: 35.6% of responders answered correctly to ≥ 6 sentences, 47.5% of them reported that ""influenza vaccine can cause influenza"" and 45.7% believed that ""antibiotics are a correct strategy to treat influenza"". Levels of perceived risks of hospitalisation and death were low in 39.3% and 16.5% of patients respectively. The adherence to the last seasonal influenza vaccination was 57.5%. The multivariate predictors of influenza vaccination uptake resulted: age ≥65, male, consulting TV/radio, asking information to GP and/or nephrologist. Conclusions: The study reveals the low adherence to influenza vaccination and the subotpimal level of knowledge in dialysis patients. Different strategies, including a greater alliance among nephrologists and GPs to prevent influenza should be encouraged to improve the adherence to influenza vaccination in this at risk group.","Factors predicting influenza vaccination adherence among patients in dialysis: an Italian survey Introduction: The aim of this study was to investigate knowledge and practices about influenza among patients on dialysis services of Italian hospitals at risk of severe influenza infection and vaccine and to identify predictive factors to vaccination adherence. Methods: A cross-sectional observational study was carried out from January 2017 to July 2017 after the 2016/2017 influenza vaccination campaign. The questionnaire was administered to all patients treated in seven large Italian dialysis services. It consisted of influenza vaccination coverage, knowledge about influenza and its vaccination, perceived risk of influenza complications, recommendations on influenza uptake received by general practitioner (GP) and nephrologist. Results: Response rate was 90% (703/781). Patients' knowledge about influenza infection and vaccine were detected by nine closed questions: 35.6% of responders answered correctly to ≥ 6 sentences, 47.5% of them reported that ""influenza vaccine can cause influenza"" and 45.7% believed that ""antibiotics are a correct strategy to treat influenza"". Levels of perceived risks of hospitalisation and death were low in 39.3% and 16.5% of patients respectively. The adherence to the last seasonal influenza vaccination was 57.5%. The multivariate predictors of influenza vaccination uptake resulted: age ≥65, male, consulting TV/radio, asking information to GP and/or nephrologist. Conclusions: The study reveals the low adherence to influenza vaccination and the subotpimal level of knowledge in dialysis patients. Different strategies, including a greater alliance among nephrologists and GPs to prevent influenza should be encouraged to improve the adherence to influenza vaccination in this at risk group.",0,0
34326052,Primary care for patients with respiratory tract infection before and early on in the COVID-19 pandemic: an observational study in 16 European countries,"van der Velden AW, Bax EA, Bongard E, Munck Aabenhus R, Anastasaki M, Anthierens S, Balan A, Böhmer F, Bruno P, Chlabicz S, Coenen S, Colliers A, Emmerich S, Garcia-Sangenis A, Ghazaryan H, van der Linde SR, Malania L, Pauer J, Tomacinschii A, Tonkin-Crine S, Vellinga A, Zastavnyy I, Verheij T, Goossens H, Butler CC.",BMJ Open. 2021 Jul 29;11(7):e049257. doi: 10.1136/bmjopen-2021-049257.,van der Velden AW,BMJ Open,2021,30-07-2021,PMC8326026,,10.1136/bmjopen-2021-049257,"OBJECTIVE: To describe primary health care (consultation characteristics and management) for patients contacting their general practitioner (GP) with a respiratory tract infection (RTI) early on in the COVID-19 pandemic in contrasting European countries, with comparison to prepandemic findings.
SETTING: Primary care in 16 countries (79 practices), when no routine SARS-CoV-2 testing was generally available.
DESIGN AND PARTICIPANTS: Before (n=4376) and early in the pandemic (n=3301), patients with RTI symptoms were registered in this prospective audit study.
OUTCOME MEASURES: Consultation characteristics (type of contact and use of PPE) and management characteristics (clinical assessments, diagnostic testing, prescribing, advice and referral) were registered. Differences in these characteristics between countries and between pandemic and prepandemic care are described.
RESULTS: Care for patients with RTIs rapidly switched to telephone/video consultations (10% in Armenia, 91% in Denmark), and when consultations were face-to-face, GPs used PPE during 97% (95% CI 96% to 98%) of contacts. Laboratory testing for SARS-CoV-2 in primary care patients with RTIs was rapidly implemented in Denmark (59%) and Germany (31%), while overall testing for C reactive protein decreased. The proportion of patients prescribed antibiotics varied considerably between countries (3% in Belgium, 48% in UK) and was lower during the pandemic compared with the months before, except for Greece, Poland and UK. GPs provided frequent and varied COVID-related advice and more frequently scheduled a follow-up contact (50%, 95% CI 48% to 52%). GPs reported a slightly higher degree of confidence in the likely effectiveness of their management in face-to-face (73% (very) confident, 95% CI 71% to 76%) than in virtual consultations (69%, 95% CI 67% to 71%).
CONCLUSIONS: Despite between-country variation in consultation characteristics, access to SARS-CoV-2 laboratory testing and medication prescribing, GPs reported a high degree of confidence in managing their patients with RTIs in the emerging pandemic. Insight in the highly variable pandemic responses, as measured in this multicountry audit, can aid in fine-tuning national action and in coordinating a pan-European response during future pandemic threats.","Primary care for patients with respiratory tract infection before and early on in the COVID-19 pandemic: an observational study in 16 European countries OBJECTIVE: To describe primary health care (consultation characteristics and management) for patients contacting their general practitioner (GP) with a respiratory tract infection (RTI) early on in the COVID-19 pandemic in contrasting European countries, with comparison to prepandemic findings.
SETTING: Primary care in 16 countries (79 practices), when no routine SARS-CoV-2 testing was generally available.
DESIGN AND PARTICIPANTS: Before (n=4376) and early in the pandemic (n=3301), patients with RTI symptoms were registered in this prospective audit study.
OUTCOME MEASURES: Consultation characteristics (type of contact and use of PPE) and management characteristics (clinical assessments, diagnostic testing, prescribing, advice and referral) were registered. Differences in these characteristics between countries and between pandemic and prepandemic care are described.
RESULTS: Care for patients with RTIs rapidly switched to telephone/video consultations (10% in Armenia, 91% in Denmark), and when consultations were face-to-face, GPs used PPE during 97% (95% CI 96% to 98%) of contacts. Laboratory testing for SARS-CoV-2 in primary care patients with RTIs was rapidly implemented in Denmark (59%) and Germany (31%), while overall testing for C reactive protein decreased. The proportion of patients prescribed antibiotics varied considerably between countries (3% in Belgium, 48% in UK) and was lower during the pandemic compared with the months before, except for Greece, Poland and UK. GPs provided frequent and varied COVID-related advice and more frequently scheduled a follow-up contact (50%, 95% CI 48% to 52%). GPs reported a slightly higher degree of confidence in the likely effectiveness of their management in face-to-face (73% (very) confident, 95% CI 71% to 76%) than in virtual consultations (69%, 95% CI 67% to 71%).
CONCLUSIONS: Despite between-country variation in consultation characteristics, access to SARS-CoV-2 laboratory testing and medication prescribing, GPs reported a high degree of confidence in managing their patients with RTIs in the emerging pandemic. Insight in the highly variable pandemic responses, as measured in this multicountry audit, can aid in fine-tuning national action and in coordinating a pan-European response during future pandemic threats.",0,0
38725026,Impact of COVID-19 on antimicrobial stewardship activities in Italy: a region-wide assessment,"Vicentini C, Corcione S, Lo Moro G, Mara A, De Rosa FG, Zotti CM; collaborating group “Unità Prevenzione Rischio Infettivo (UPRI), Regione Piemonte”.",Antimicrob Resist Infect Control. 2024 May 9;13(1):48. doi: 10.1186/s13756-024-01407-3.,Vicentini C,Antimicrob Resist Infect Control,2024,09-05-2024,PMC11084085,,10.1186/s13756-024-01407-3,"BACKGROUND: In the region of Piedmont, in Northern Italy, formal monitoring of antimicrobial stewardship (AMS) programs has been in place since 2012. The objective of our study was to provide an updated assessment of AMS programs operating in our region, and to assess the impact of the COVID-19 pandemic on stewardship activities.
METHODS: A retrospective observational study was conducted to investigate AMS programs implemented in acute-care trusts participating in a broader healthcare-associated infections and antimicrobial resistance (AMR) prevention and control program, promoted by the regional health department. Within this program, structure, process, and outcome indicators of AMS programs were investigated, using a previously developed scoring system. Differences between scores prior to (2019) and during the pandemic (2021) were assessed. Linear regression was used to assess whether the 5-year trends (2017-2021) in outcome measures in relation to structure and process scores were statistically significant. Compound annual growth rates (CAGR) for each outcome were calculated to illustrate changes in outcome rates over time.
RESULTS: All public trusts in the Region (20) and a small number of private institutions (3) provided data for this study. A modest, non-significant improvement was found for 2021 structure, process, and total scores compared to respective 2019 scores. A significant improvement was found concerning the definition of a formal mission statement, whereas significantly less trusts included monitoring adherence to antimicrobial policy or treatment guidelines in their programs. Overall consumption of antibiotics for systemic use saw an increase in 2021, with 2021 recording the highest median overall consumption compared to all previous years considered in this study. Methicillin-resistant Staphylococcus aureus (MRSA) and carbapenem-resistant enterobacteria (CRE) rates decreased over the 5-year period. Significant downwards trends in MRSA rates were identified for high-outlier structure and process groups.
CONCLUSIONS: Results of this study suggest AMS programs in Piedmont were not set back following the pandemic. This outcome was possible thanks to well-established programs, coordinated within a regional framework. Continued efforts should be dedicated to supporting AMS programs and contrasting AMR, even when the focus is shifted towards other public health emergencies.","Impact of COVID-19 on antimicrobial stewardship activities in Italy: a region-wide assessment BACKGROUND: In the region of Piedmont, in Northern Italy, formal monitoring of antimicrobial stewardship (AMS) programs has been in place since 2012. The objective of our study was to provide an updated assessment of AMS programs operating in our region, and to assess the impact of the COVID-19 pandemic on stewardship activities.
METHODS: A retrospective observational study was conducted to investigate AMS programs implemented in acute-care trusts participating in a broader healthcare-associated infections and antimicrobial resistance (AMR) prevention and control program, promoted by the regional health department. Within this program, structure, process, and outcome indicators of AMS programs were investigated, using a previously developed scoring system. Differences between scores prior to (2019) and during the pandemic (2021) were assessed. Linear regression was used to assess whether the 5-year trends (2017-2021) in outcome measures in relation to structure and process scores were statistically significant. Compound annual growth rates (CAGR) for each outcome were calculated to illustrate changes in outcome rates over time.
RESULTS: All public trusts in the Region (20) and a small number of private institutions (3) provided data for this study. A modest, non-significant improvement was found for 2021 structure, process, and total scores compared to respective 2019 scores. A significant improvement was found concerning the definition of a formal mission statement, whereas significantly less trusts included monitoring adherence to antimicrobial policy or treatment guidelines in their programs. Overall consumption of antibiotics for systemic use saw an increase in 2021, with 2021 recording the highest median overall consumption compared to all previous years considered in this study. Methicillin-resistant Staphylococcus aureus (MRSA) and carbapenem-resistant enterobacteria (CRE) rates decreased over the 5-year period. Significant downwards trends in MRSA rates were identified for high-outlier structure and process groups.
CONCLUSIONS: Results of this study suggest AMS programs in Piedmont were not set back following the pandemic. This outcome was possible thanks to well-established programs, coordinated within a regional framework. Continued efforts should be dedicated to supporting AMS programs and contrasting AMR, even when the focus is shifted towards other public health emergencies.",0,0
30921214,Herb induced liver injury after using herbal medicine: A systemic review and case-control study,"Lin NH, Yang HW, Su YJ, Chang CW.",Medicine (Baltimore). 2019 Mar;98(13):e14992. doi: 10.1097/MD.0000000000014992.,Lin NH,Medicine (Baltimore),2019,29-03-2019,PMC6456154,,10.1097/MD.0000000000014992,"In Taiwan, traditional herbal medication was included in Taiwan's National Health Insurance (NHI) system since 1996 and in 9 out of 10 hospitals have developed their own departments of traditional medicine. This study aims to address the herb-induced liver injury (HILI) after using herbal medicine on the relationship between age, gender, epidemiology, laboratory data, pathogenesis, mobility, and mortality.We searched the PubMed database with ""hepatitis after herbal medicine"" and ""in human"" till 2018 April and returned 163 articles in a systemic review manner. Two cases reports describing in-vitro liver injury were excluded. Reviews and articles without the detailed report, laboratory data and history were excluded from this study. In the end, there were 53 articles enrolled in this study. These enrolled literatures are from France (n = 13), Germany (n = 12), Switzerland (n = 5) United States of America (n = 4), Korea (n = 4), Hong Kong (n = 4), Greece (n = 3), China (n = 2), Canada (n = 1), Italy (n = 1), Thailand (n = 1), Finland (n = 1), Taiwan (n = 1), and Japan (n = 1). The data were analyzed with a commercial statistical software Stata/SE 12.0 program Stata Corporation, College Station, TX, USA. Statistical χ tests were performed and the significance was set at a P value of less than .05 (2-tailed).The ages are ranged from 15 to 78 years with the mean ± SD (standard deviation) of 48.3 ± 16.2 years old. The majority of cases are female (n = 37). In elderly, man is more commonly seen than female in HILI (37.5% vs 10.5%, P = .02). Female is vulnerable to cholestatic type of HILI than male (21.1% vs 0.0%, P = .04). Of all the cases in HILI, using pure substance are more commonly seen than mixed substance (P = .02). In gender, male patients have higher alanine aminotransferase (GPT) (IU/L) level in HILI than female ones (1560 ± 819 vs 1047 ± 706, P = .03).In HILI, the female is more commonly seen than male, but less than male in the elderly. The pure substance more often happens to HILI than mixture substance. Female is predominant in the cholestatic type of HILI. The major prevalence of HILI is in Europe rather than Asia. HILI cases in Europe is 2.75-fold than in Asia. This could be due to fewer reports of the herb induced liver injury in Asia compared to Europe. Prevention of HILI is the best policy, because it needs to take 78 ± 59 days to recover.","Herb induced liver injury after using herbal medicine: A systemic review and case-control study In Taiwan, traditional herbal medication was included in Taiwan's National Health Insurance (NHI) system since 1996 and in 9 out of 10 hospitals have developed their own departments of traditional medicine. This study aims to address the herb-induced liver injury (HILI) after using herbal medicine on the relationship between age, gender, epidemiology, laboratory data, pathogenesis, mobility, and mortality.We searched the PubMed database with ""hepatitis after herbal medicine"" and ""in human"" till 2018 April and returned 163 articles in a systemic review manner. Two cases reports describing in-vitro liver injury were excluded. Reviews and articles without the detailed report, laboratory data and history were excluded from this study. In the end, there were 53 articles enrolled in this study. These enrolled literatures are from France (n = 13), Germany (n = 12), Switzerland (n = 5) United States of America (n = 4), Korea (n = 4), Hong Kong (n = 4), Greece (n = 3), China (n = 2), Canada (n = 1), Italy (n = 1), Thailand (n = 1), Finland (n = 1), Taiwan (n = 1), and Japan (n = 1). The data were analyzed with a commercial statistical software Stata/SE 12.0 program Stata Corporation, College Station, TX, USA. Statistical χ tests were performed and the significance was set at a P value of less than .05 (2-tailed).The ages are ranged from 15 to 78 years with the mean ± SD (standard deviation) of 48.3 ± 16.2 years old. The majority of cases are female (n = 37). In elderly, man is more commonly seen than female in HILI (37.5% vs 10.5%, P = .02). Female is vulnerable to cholestatic type of HILI than male (21.1% vs 0.0%, P = .04). Of all the cases in HILI, using pure substance are more commonly seen than mixed substance (P = .02). In gender, male patients have higher alanine aminotransferase (GPT) (IU/L) level in HILI than female ones (1560 ± 819 vs 1047 ± 706, P = .03).In HILI, the female is more commonly seen than male, but less than male in the elderly. The pure substance more often happens to HILI than mixture substance. Female is predominant in the cholestatic type of HILI. The major prevalence of HILI is in Europe rather than Asia. HILI cases in Europe is 2.75-fold than in Asia. This could be due to fewer reports of the herb induced liver injury in Asia compared to Europe. Prevention of HILI is the best policy, because it needs to take 78 ± 59 days to recover.",0,0
33655259,"The SARS-CoV-2 antibody landscape is lower in magnitude for structural proteins, diversified for accessory proteins and stable long-term in children","Hachim A, Gu H, Kavian O, Kwan MY, Chan WH, Yau YS, Chiu SS, Tsang OT, Hui DS, Ma F, Lau EH, Cheng SM, Poon LL, Peiris JM, Valkenburg SA, Kavian N.",medRxiv [Preprint]. 2021 Jan 4:2021.01.03.21249180. doi: 10.1101/2021.01.03.21249180.,Hachim A,medRxiv,2021,03-03-2021,PMC7924280,,10.1101/2021.01.03.21249180,"BACKGROUND: Children are less clinically affected by SARS-CoV-2 infection than adults with the majority of cases being mild or asymptomatic and the differences in infection outcomes are poorly understood. The kinetics, magnitude and landscape of the antibody response may impact the clinical severity and serological diagnosis of COVID-19. Thus, a comprehensive investigation of the antibody landscape in children and adults is needed.
METHODS: We tested 254 plasma from 122 children with symptomatic and asymptomatic SARS-CoV-2 infections in Hong Kong up to 206 days post symptom onset, including 146 longitudinal samples from 58 children. Adult COVID-19 patients and pre-pandemic controls were included for comparison. We assessed antibodies to a 14-wide panel of SARS-CoV-2 structural and accessory proteins by Luciferase Immunoprecipitation System (LIPS).
FINDINGS: Children have lower levels of Spike and Nucleocapsid antibodies than adults, and their cumulative humoral response is more expanded to accessory proteins (NSP1 and Open Reading Frames (ORFs)). Sensitive serology using the three N, ORF3b, ORF8 antibodies can discriminate COVID-19 in children. Principal component analysis revealed distinct serological signatures in children and the highest contribution to variance were responses to non-structural proteins ORF3b, NSP1, ORF7a and ORF8. Longitudinal sampling revealed maintenance or increase of antibodies for at least 6 months, except for ORF7b antibodies which showed decline. It was interesting to note that children have higher antibody responses towards known IFN antagonists: ORF3b, ORF6 and ORF7a. The diversified SARS-CoV-2 antibody response in children may be an important factor in driving control of SARS-CoV-2 infection.","The SARS-CoV-2 antibody landscape is lower in magnitude for structural proteins, diversified for accessory proteins and stable long-term in children BACKGROUND: Children are less clinically affected by SARS-CoV-2 infection than adults with the majority of cases being mild or asymptomatic and the differences in infection outcomes are poorly understood. The kinetics, magnitude and landscape of the antibody response may impact the clinical severity and serological diagnosis of COVID-19. Thus, a comprehensive investigation of the antibody landscape in children and adults is needed.
METHODS: We tested 254 plasma from 122 children with symptomatic and asymptomatic SARS-CoV-2 infections in Hong Kong up to 206 days post symptom onset, including 146 longitudinal samples from 58 children. Adult COVID-19 patients and pre-pandemic controls were included for comparison. We assessed antibodies to a 14-wide panel of SARS-CoV-2 structural and accessory proteins by Luciferase Immunoprecipitation System (LIPS).
FINDINGS: Children have lower levels of Spike and Nucleocapsid antibodies than adults, and their cumulative humoral response is more expanded to accessory proteins (NSP1 and Open Reading Frames (ORFs)). Sensitive serology using the three N, ORF3b, ORF8 antibodies can discriminate COVID-19 in children. Principal component analysis revealed distinct serological signatures in children and the highest contribution to variance were responses to non-structural proteins ORF3b, NSP1, ORF7a and ORF8. Longitudinal sampling revealed maintenance or increase of antibodies for at least 6 months, except for ORF7b antibodies which showed decline. It was interesting to note that children have higher antibody responses towards known IFN antagonists: ORF3b, ORF6 and ORF7a. The diversified SARS-CoV-2 antibody response in children may be an important factor in driving control of SARS-CoV-2 infection.",0,0
34246332,Prevalence of syphilis among men who have sex with men: a global systematic review and meta-analysis from 2000-20,"Tsuboi M, Evans J, Davies EP, Rowley J, Korenromp EL, Clayton T, Taylor MM, Mabey D, Chico RM.",Lancet Glob Health. 2021 Aug;9(8):e1110-e1118. doi: 10.1016/S2214-109X(21)00221-7. Epub 2021 Jul 8.,Tsuboi M,Lancet Glob Health,2021,11-07-2021,PMC9150735,NIHMS1804808,10.1016/S2214-109X(21)00221-7,"BACKGROUND: The WHO Global Health Sector Strategy aims to reduce worldwide syphilis incidence by 90% between 2018 and 2030. If this goal is to be achieved, interventions that target high-burden groups, including men who have sex with men (MSM), will be required. However, there are no global prevalence estimates of syphilis among MSM to serve as a baseline for monitoring or modelling disease burden. We aimed to assess the global prevalence of syphilis among MSM using the available literature.
METHODS: In this global systematic review and meta-analysis, we searched MEDLINE, Embase, LILACS, and AIM databases, and Integrated Bio-Behavioral Surveillance (IBBS) reports between April 23, 2019, and Feb 1, 2020, to identify studies done between Jan 1, 2000, and Feb 1, 2020, with syphilis point prevalence data measured by biological assay among MSM (defined as people who were assigned as male at birth and had oral or anal sex with at least one other man in their lifetime). Studies were excluded if participants were exclusively HIV-infected MSM, injection-drug users, only seeking care for sexually transmitted infections (STIs) or genital symptoms, or routine STI clinic attendees. Data were extracted onto standardised forms and cross-checked for accuracy and validity. We used random-effects models to generate pooled prevalence estimates across the eight regions of the Sustainable Development Goals. We calculated risk of study bias based on the Appraisal tool for Cross-Sectional Studies, and stratified results based on low versus high risk of bias. This systematic review and meta-analysis was registered with PROSPERO, CRD42019144594.
FINDINGS: We reviewed 4339 records, 228 IBBS reports, and ten articles from other sources. Of these, 1301 duplicate records were excluded, 2467 records were excluded after title and abstract screening, and 534 articles were excluded after full-text analysis. We identified 345 prevalence data points from 275 studies across 77 countries, with a total of 606 232 participants. Global pooled prevalence from 2000-20 was 7·5% (95% CI 7·0-8·0%), ranging from 1·9% (1·0-3·1%) in Australia and New Zealand to 10·6% (8·5-12·9%) in Latin America and the Caribbean.
INTERPRETATION: Unacceptably high syphilis prevalence among MSM warrants urgent action.
FUNDING: Wellcome Trust.","Prevalence of syphilis among men who have sex with men: a global systematic review and meta-analysis from 2000-20 BACKGROUND: The WHO Global Health Sector Strategy aims to reduce worldwide syphilis incidence by 90% between 2018 and 2030. If this goal is to be achieved, interventions that target high-burden groups, including men who have sex with men (MSM), will be required. However, there are no global prevalence estimates of syphilis among MSM to serve as a baseline for monitoring or modelling disease burden. We aimed to assess the global prevalence of syphilis among MSM using the available literature.
METHODS: In this global systematic review and meta-analysis, we searched MEDLINE, Embase, LILACS, and AIM databases, and Integrated Bio-Behavioral Surveillance (IBBS) reports between April 23, 2019, and Feb 1, 2020, to identify studies done between Jan 1, 2000, and Feb 1, 2020, with syphilis point prevalence data measured by biological assay among MSM (defined as people who were assigned as male at birth and had oral or anal sex with at least one other man in their lifetime). Studies were excluded if participants were exclusively HIV-infected MSM, injection-drug users, only seeking care for sexually transmitted infections (STIs) or genital symptoms, or routine STI clinic attendees. Data were extracted onto standardised forms and cross-checked for accuracy and validity. We used random-effects models to generate pooled prevalence estimates across the eight regions of the Sustainable Development Goals. We calculated risk of study bias based on the Appraisal tool for Cross-Sectional Studies, and stratified results based on low versus high risk of bias. This systematic review and meta-analysis was registered with PROSPERO, CRD42019144594.
FINDINGS: We reviewed 4339 records, 228 IBBS reports, and ten articles from other sources. Of these, 1301 duplicate records were excluded, 2467 records were excluded after title and abstract screening, and 534 articles were excluded after full-text analysis. We identified 345 prevalence data points from 275 studies across 77 countries, with a total of 606 232 participants. Global pooled prevalence from 2000-20 was 7·5% (95% CI 7·0-8·0%), ranging from 1·9% (1·0-3·1%) in Australia and New Zealand to 10·6% (8·5-12·9%) in Latin America and the Caribbean.
INTERPRETATION: Unacceptably high syphilis prevalence among MSM warrants urgent action.
FUNDING: Wellcome Trust.",0,0
33977022,Using data mining techniques to fight and control epidemics: A scoping review,"Safdari R, Rezayi S, Saeedi S, Tanhapour M, Gholamzadeh M.",Health Technol (Berl). 2021;11(4):759-771. doi: 10.1007/s12553-021-00553-7. Epub 2021 May 7.,Safdari R,Health Technol (Berl),2021,12-05-2021,PMC8102070,,10.1007/s12553-021-00553-7,"The main objective of this survey is to study the published articles to determine the most favorite data mining methods and gap of knowledge. Since the threat of pandemics has raised concerns for public health, data mining techniques were applied by researchers to reveal the hidden knowledge. Web of Science, Scopus, and PubMed databases were selected for systematic searches. Then, all of the retrieved articles were screened in the stepwise process according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist to select appropriate articles. All of the results were analyzed and summarized based on some classifications. Out of 335 citations were retrieved, 50 articles were determined as eligible articles through a scoping review. The review results showed that the most favorite DM belonged to Natural language processing (22%) and the most commonly proposed approach was revealing disease characteristics (22%). Regarding diseases, the most addressed disease was COVID-19. The studies show a predominance of applying supervised learning techniques (90%). Concerning healthcare scopes, we found that infectious disease (36%) to be the most frequent, closely followed by epidemiology discipline. The most common software used in the studies was SPSS (22%) and R (20%). The results revealed that some valuable researches conducted by employing the capabilities of knowledge discovery methods to understand the unknown dimensions of diseases in pandemics. But most researches will need in terms of treatment and disease control.","Using data mining techniques to fight and control epidemics: A scoping review The main objective of this survey is to study the published articles to determine the most favorite data mining methods and gap of knowledge. Since the threat of pandemics has raised concerns for public health, data mining techniques were applied by researchers to reveal the hidden knowledge. Web of Science, Scopus, and PubMed databases were selected for systematic searches. Then, all of the retrieved articles were screened in the stepwise process according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist to select appropriate articles. All of the results were analyzed and summarized based on some classifications. Out of 335 citations were retrieved, 50 articles were determined as eligible articles through a scoping review. The review results showed that the most favorite DM belonged to Natural language processing (22%) and the most commonly proposed approach was revealing disease characteristics (22%). Regarding diseases, the most addressed disease was COVID-19. The studies show a predominance of applying supervised learning techniques (90%). Concerning healthcare scopes, we found that infectious disease (36%) to be the most frequent, closely followed by epidemiology discipline. The most common software used in the studies was SPSS (22%) and R (20%). The results revealed that some valuable researches conducted by employing the capabilities of knowledge discovery methods to understand the unknown dimensions of diseases in pandemics. But most researches will need in terms of treatment and disease control.",1,0
37683661,Amniotic Sludge and Prematurity: Systematic Review and Meta-analysis,"Pannain GD, Pereira AMG, Rocha MLTLFD, Lopes RGC.",Rev Bras Ginecol Obstet. 2023 Aug;45(8):e489-e498. doi: 10.1055/s-0043-1772189. Epub 2023 Sep 8.,Pannain GD,Rev Bras Ginecol Obstet,2023,08-09-2023,PMC10491474,,10.1055/s-0043-1772189,"OBJECTIVE:  To perform a systematic review and meta-analysis of studies on maternal, fetal, and neonatal outcomes of women with singleton pregnancies, after spontaneous conception, and with the diagnosis of amniotic sludge before 37 weeks of gestational age.
DATA SOURCES:  We conducted a search on the PubMed, Cochrane, Bireme, and Theses databases until June 2022.
SELECTION OF STUDIES: Using the keywords intra-amniotic sludge or fluid sludge or echogenic particles, we found 263 articles, 132 of which were duplicates, and 70 were discarded because they did not meet the inclusion criteria.
DATA COLLECTION:  The articles retrieved were analyzed by 2 reviewers; 61 were selected for full-text analysis, 18 were included for a qualitative analysis, and 14, for a quantitative analysis.
DATA SYNTHESIS:  Among the maternal outcomes analyzed, there was an increased risk of preterm labor (95% confidence interval [95%CI]: 1.45-2.03), premature rupture of ovular membranes (95%CI: 1.99-3.79), and clinical (95%CI: 1.41-6.19) and histological chorioamnionitis (95%CI: 1.75-3.12). Regarding the fetal outcomes, there was a significant increase in the risk of morbidity (95%CI: 1.80-3.17), mortality (95%CI: 1.14-18.57), admission to the Neonatal Intensive Care Unit (NICU; 95%CI: 1.17-1.95), and neonatal sepsis (95%CI: 2.29-7.55).
CONCLUSION:  The results of the present study indicate that the presence of amniotic sludge is a risk marker for preterm delivery. Despite the heterogeneity of the studies analyzed, even in patients with other risk factors for prematurity, such as short cervix and previous preterm delivery, the presence of amniotic sludge increases the risk of premature labor. Moreover, antibiotic therapy seems to be a treatment for amniotic sludge, and it may prolong pregnancy.","Amniotic Sludge and Prematurity: Systematic Review and Meta-analysis OBJECTIVE:  To perform a systematic review and meta-analysis of studies on maternal, fetal, and neonatal outcomes of women with singleton pregnancies, after spontaneous conception, and with the diagnosis of amniotic sludge before 37 weeks of gestational age.
DATA SOURCES:  We conducted a search on the PubMed, Cochrane, Bireme, and Theses databases until June 2022.
SELECTION OF STUDIES: Using the keywords intra-amniotic sludge or fluid sludge or echogenic particles, we found 263 articles, 132 of which were duplicates, and 70 were discarded because they did not meet the inclusion criteria.
DATA COLLECTION:  The articles retrieved were analyzed by 2 reviewers; 61 were selected for full-text analysis, 18 were included for a qualitative analysis, and 14, for a quantitative analysis.
DATA SYNTHESIS:  Among the maternal outcomes analyzed, there was an increased risk of preterm labor (95% confidence interval [95%CI]: 1.45-2.03), premature rupture of ovular membranes (95%CI: 1.99-3.79), and clinical (95%CI: 1.41-6.19) and histological chorioamnionitis (95%CI: 1.75-3.12). Regarding the fetal outcomes, there was a significant increase in the risk of morbidity (95%CI: 1.80-3.17), mortality (95%CI: 1.14-18.57), admission to the Neonatal Intensive Care Unit (NICU; 95%CI: 1.17-1.95), and neonatal sepsis (95%CI: 2.29-7.55).
CONCLUSION:  The results of the present study indicate that the presence of amniotic sludge is a risk marker for preterm delivery. Despite the heterogeneity of the studies analyzed, even in patients with other risk factors for prematurity, such as short cervix and previous preterm delivery, the presence of amniotic sludge increases the risk of premature labor. Moreover, antibiotic therapy seems to be a treatment for amniotic sludge, and it may prolong pregnancy.",1,0
33279995,Text mining approaches for dealing with the rapidly expanding literature on COVID-19,"Wang LL, Lo K.",Brief Bioinform. 2021 Mar 22;22(2):781-799. doi: 10.1093/bib/bbaa296.,Wang LL,Brief Bioinform,2021,06-12-2020,PMC7799291,,10.1093/bib/bbaa296,"More than 50 000 papers have been published about COVID-19 since the beginning of 2020 and several hundred new papers continue to be published every day. This incredible rate of scientific productivity leads to information overload, making it difficult for researchers, clinicians and public health officials to keep up with the latest findings. Automated text mining techniques for searching, reading and summarizing papers are helpful for addressing information overload. In this review, we describe the many resources that have been introduced to support text mining applications over the COVID-19 literature; specifically, we discuss the corpora, modeling resources, systems and shared tasks that have been introduced for COVID-19. We compile a list of 39 systems that provide functionality such as search, discovery, visualization and summarization over the COVID-19 literature. For each system, we provide a qualitative description and assessment of the system's performance, unique data or user interface features and modeling decisions. Many systems focus on search and discovery, though several systems provide novel features, such as the ability to summarize findings over multiple documents or linking between scientific articles and clinical trials. We also describe the public corpora, models and shared tasks that have been introduced to help reduce repeated effort among community members; some of these resources (especially shared tasks) can provide a basis for comparing the performance of different systems. Finally, we summarize promising results and open challenges for text mining the COVID-19 literature.","Text mining approaches for dealing with the rapidly expanding literature on COVID-19 More than 50 000 papers have been published about COVID-19 since the beginning of 2020 and several hundred new papers continue to be published every day. This incredible rate of scientific productivity leads to information overload, making it difficult for researchers, clinicians and public health officials to keep up with the latest findings. Automated text mining techniques for searching, reading and summarizing papers are helpful for addressing information overload. In this review, we describe the many resources that have been introduced to support text mining applications over the COVID-19 literature; specifically, we discuss the corpora, modeling resources, systems and shared tasks that have been introduced for COVID-19. We compile a list of 39 systems that provide functionality such as search, discovery, visualization and summarization over the COVID-19 literature. For each system, we provide a qualitative description and assessment of the system's performance, unique data or user interface features and modeling decisions. Many systems focus on search and discovery, though several systems provide novel features, such as the ability to summarize findings over multiple documents or linking between scientific articles and clinical trials. We also describe the public corpora, models and shared tasks that have been introduced to help reduce repeated effort among community members; some of these resources (especially shared tasks) can provide a basis for comparing the performance of different systems. Finally, we summarize promising results and open challenges for text mining the COVID-19 literature.",1,0
35430265,Text mining in mosquito-borne disease: A systematic review,"Ong SQ, Pauzi MBM, Gan KH.",Acta Trop. 2022 Jul;231:106447. doi: 10.1016/j.actatropica.2022.106447. Epub 2022 Apr 14.,Ong SQ,Acta Trop,2022,17-04-2022,PMC9663275,,10.1016/j.actatropica.2022.106447,"Mosquito-borne diseases are emerging and re-emerging across the globe, especially after the COVID19 pandemic. The recent advances in text mining in infectious diseases hold the potential of providing timely access to explicit and implicit associations among information in the text. In the past few years, the availability of online text data in the form of unstructured or semi-structured text with rich content of information from this domain enables many studies to provide solutions in this area, e.g., disease-related knowledge discovery, disease surveillance, early detection system, etc. However, a recent review of text mining in the domain of mosquito-borne disease was not available to the best of our knowledge. In this review, we survey the recent works in the text mining techniques used in combating mosquito-borne diseases. We highlight the corpus sources, technologies, applications, and the challenges faced by the studies, followed by the possible future directions that can be taken further in this domain. We present a bibliometric analysis of the 294 scientific articles that have been published in Scopus and PubMed in the domain of text mining in mosquito-borne diseases, from the year 2016 to 2021. The papers were further filtered and reviewed based on the techniques used to analyze the text related to mosquito-borne diseases. Based on the corpus of 158 selected articles, we found 27 of the articles were relevant and used text mining in mosquito-borne diseases. These articles covered the majority of Zika (38.70%), Dengue (32.26%), and Malaria (29.03%), with extremely low numbers or none of the other crucial mosquito-borne diseases like chikungunya, yellow fever, West Nile fever. Twitter was the dominant corpus resource to perform text mining in mosquito-borne diseases, followed by PubMed and LexisNexis databases. Sentiment analysis was the most popular technique of text mining to understand the discourse of the disease and followed by information extraction, which dependency relation and co-occurrence-based approach to extract relations and events. Surveillance was the main usage of most of the reviewed studies and followed by treatment, which focused on the drug-disease or symptom-disease association. The advance in text mining could improve the management of mosquito-borne diseases. However, the technique and application posed many limitations and challenges, including biases like user authentication and language, real-world implementation, etc. We discussed the future direction which can be useful to expand this area and domain. This review paper contributes mainly as a library for text mining in mosquito-borne diseases and could further explore the system for other neglected diseases.","Text mining in mosquito-borne disease: A systematic review Mosquito-borne diseases are emerging and re-emerging across the globe, especially after the COVID19 pandemic. The recent advances in text mining in infectious diseases hold the potential of providing timely access to explicit and implicit associations among information in the text. In the past few years, the availability of online text data in the form of unstructured or semi-structured text with rich content of information from this domain enables many studies to provide solutions in this area, e.g., disease-related knowledge discovery, disease surveillance, early detection system, etc. However, a recent review of text mining in the domain of mosquito-borne disease was not available to the best of our knowledge. In this review, we survey the recent works in the text mining techniques used in combating mosquito-borne diseases. We highlight the corpus sources, technologies, applications, and the challenges faced by the studies, followed by the possible future directions that can be taken further in this domain. We present a bibliometric analysis of the 294 scientific articles that have been published in Scopus and PubMed in the domain of text mining in mosquito-borne diseases, from the year 2016 to 2021. The papers were further filtered and reviewed based on the techniques used to analyze the text related to mosquito-borne diseases. Based on the corpus of 158 selected articles, we found 27 of the articles were relevant and used text mining in mosquito-borne diseases. These articles covered the majority of Zika (38.70%), Dengue (32.26%), and Malaria (29.03%), with extremely low numbers or none of the other crucial mosquito-borne diseases like chikungunya, yellow fever, West Nile fever. Twitter was the dominant corpus resource to perform text mining in mosquito-borne diseases, followed by PubMed and LexisNexis databases. Sentiment analysis was the most popular technique of text mining to understand the discourse of the disease and followed by information extraction, which dependency relation and co-occurrence-based approach to extract relations and events. Surveillance was the main usage of most of the reviewed studies and followed by treatment, which focused on the drug-disease or symptom-disease association. The advance in text mining could improve the management of mosquito-borne diseases. However, the technique and application posed many limitations and challenges, including biases like user authentication and language, real-world implementation, etc. We discussed the future direction which can be useful to expand this area and domain. This review paper contributes mainly as a library for text mining in mosquito-borne diseases and could further explore the system for other neglected diseases.",1,0
34042593,The Use of Social Media for Health Research Purposes: Scoping Review,"Bour C, Ahne A, Schmitz S, Perchoux C, Dessenne C, Fagherazzi G.",J Med Internet Res. 2021 May 27;23(5):e25736. doi: 10.2196/25736.,Bour C,J Med Internet Res,2021,27-05-2021,PMC8193478,,10.2196/25736,"BACKGROUND: As social media are increasingly used worldwide, more and more scientists are relying on them for their health-related projects. However, social media features, methodologies, and ethical issues are unclear so far because, to our knowledge, there has been no overview of this relatively young field of research.
OBJECTIVE: This scoping review aimed to provide an evidence map of the different uses of social media for health research purposes, their fields of application, and their analysis methods.
METHODS: We followed the scoping review methodologies developed by Arksey and O'Malley and the Joanna Briggs Institute. After developing search strategies based on keywords (eg, social media, health research), comprehensive searches were conducted in the PubMed/MEDLINE and Web of Science databases. We limited the search strategies to documents written in English and published between January 1, 2005, and April 9, 2020. After removing duplicates, articles were screened at the title and abstract level and at the full text level by two independent reviewers. One reviewer extracted data, which were descriptively analyzed to map the available evidence.
RESULTS: After screening 1237 titles and abstracts and 407 full texts, 268 unique papers were included, dating from 2009 to 2020 with an average annual growth rate of 32.71% for the 2009-2019 period. Studies mainly came from the Americas (173/268, 64.6%, including 151 from the United States). Articles used machine learning or data mining techniques (60/268) to analyze the data, discussed opportunities and limitations of the use of social media for research (59/268), assessed the feasibility of recruitment strategies (45/268), or discussed ethical issues (16/268). Communicable (eg, influenza, 40/268) and then chronic (eg, cancer, 24/268) diseases were the two main areas of interest.
CONCLUSIONS: Since their early days, social media have been recognized as resources with high potential for health research purposes, yet the field is still suffering from strong heterogeneity in the methodologies used, which prevents the research from being compared and generalized. For the field to be fully recognized as a valid, complementary approach to more traditional health research study designs, there is now a need for more guidance by types of applications of social media for health research, both from a methodological and an ethical perspective.
INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): RR2-10.1136/bmjopen-2020-040671.","The Use of Social Media for Health Research Purposes: Scoping Review BACKGROUND: As social media are increasingly used worldwide, more and more scientists are relying on them for their health-related projects. However, social media features, methodologies, and ethical issues are unclear so far because, to our knowledge, there has been no overview of this relatively young field of research.
OBJECTIVE: This scoping review aimed to provide an evidence map of the different uses of social media for health research purposes, their fields of application, and their analysis methods.
METHODS: We followed the scoping review methodologies developed by Arksey and O'Malley and the Joanna Briggs Institute. After developing search strategies based on keywords (eg, social media, health research), comprehensive searches were conducted in the PubMed/MEDLINE and Web of Science databases. We limited the search strategies to documents written in English and published between January 1, 2005, and April 9, 2020. After removing duplicates, articles were screened at the title and abstract level and at the full text level by two independent reviewers. One reviewer extracted data, which were descriptively analyzed to map the available evidence.
RESULTS: After screening 1237 titles and abstracts and 407 full texts, 268 unique papers were included, dating from 2009 to 2020 with an average annual growth rate of 32.71% for the 2009-2019 period. Studies mainly came from the Americas (173/268, 64.6%, including 151 from the United States). Articles used machine learning or data mining techniques (60/268) to analyze the data, discussed opportunities and limitations of the use of social media for research (59/268), assessed the feasibility of recruitment strategies (45/268), or discussed ethical issues (16/268). Communicable (eg, influenza, 40/268) and then chronic (eg, cancer, 24/268) diseases were the two main areas of interest.
CONCLUSIONS: Since their early days, social media have been recognized as resources with high potential for health research purposes, yet the field is still suffering from strong heterogeneity in the methodologies used, which prevents the research from being compared and generalized. For the field to be fully recognized as a valid, complementary approach to more traditional health research study designs, there is now a need for more guidance by types of applications of social media for health research, both from a methodological and an ethical perspective.
INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): RR2-10.1136/bmjopen-2020-040671.",0,0
28052483,Natural language processing to ascertain two key variables from operative reports in ophthalmology,"Liu L, Shorstein NH, Amsden LB, Herrinton LJ.",Pharmacoepidemiol Drug Saf. 2017 Apr;26(4):378-385. doi: 10.1002/pds.4149. Epub 2017 Jan 3.,Liu L,Pharmacoepidemiol Drug Saf,2017,05-01-2017,PMC5380560,NIHMS832904,10.1002/pds.4149,"PURPOSE: Antibiotic prophylaxis is critical to ophthalmology and other surgical specialties. We performed natural language processing (NLP) of 743 838 operative notes recorded for 315 246 surgeries to ascertain two variables needed to study the comparative effectiveness of antibiotic prophylaxis in cataract surgery. The first key variable was an exposure variable, intracameral antibiotic injection. The second was an intraoperative complication, posterior capsular rupture (PCR), which functioned as a potential confounder. To help other researchers use NLP in their settings, we describe our NLP protocol and lessons learned.
METHODS: For each of the two variables, we used SAS Text Miner and other SAS text-processing modules with a training set of 10 000 (1.3%) operative notes to develop a lexicon. The lexica identified misspellings, abbreviations, and negations, and linked words into concepts (e.g. ""antibiotic"" linked with ""injection""). We confirmed the NLP tools by iteratively obtaining random samples of 2000 (0.3%) notes, with replacement.
RESULTS: The NLP tools identified approximately 60 000 intracameral antibiotic injections and 3500 cases of PCR. The positive and negative predictive values for intracameral antibiotic injection exceeded 99%. For the intraoperative complication, they exceeded 94%.
CONCLUSION: NLP was a valid and feasible method for obtaining critical variables needed for a research study of surgical safety. These NLP tools were intended for use in the study sample. Use with external datasets or future datasets in our own setting would require further testing. Copyright © 2017 John Wiley & Sons, Ltd.","Natural language processing to ascertain two key variables from operative reports in ophthalmology PURPOSE: Antibiotic prophylaxis is critical to ophthalmology and other surgical specialties. We performed natural language processing (NLP) of 743 838 operative notes recorded for 315 246 surgeries to ascertain two variables needed to study the comparative effectiveness of antibiotic prophylaxis in cataract surgery. The first key variable was an exposure variable, intracameral antibiotic injection. The second was an intraoperative complication, posterior capsular rupture (PCR), which functioned as a potential confounder. To help other researchers use NLP in their settings, we describe our NLP protocol and lessons learned.
METHODS: For each of the two variables, we used SAS Text Miner and other SAS text-processing modules with a training set of 10 000 (1.3%) operative notes to develop a lexicon. The lexica identified misspellings, abbreviations, and negations, and linked words into concepts (e.g. ""antibiotic"" linked with ""injection""). We confirmed the NLP tools by iteratively obtaining random samples of 2000 (0.3%) notes, with replacement.
RESULTS: The NLP tools identified approximately 60 000 intracameral antibiotic injections and 3500 cases of PCR. The positive and negative predictive values for intracameral antibiotic injection exceeded 99%. For the intraoperative complication, they exceeded 94%.
CONCLUSION: NLP was a valid and feasible method for obtaining critical variables needed for a research study of surgical safety. These NLP tools were intended for use in the study sample. Use with external datasets or future datasets in our own setting would require further testing. Copyright © 2017 John Wiley & Sons, Ltd.",1,0
32694268,Artificial intelligence in ophthalmology during COVID-19 and in the post COVID-19 era,"Hallak JA, Scanzera AC, Azar DT, Chan RVP.",Curr Opin Ophthalmol. 2020 Sep;31(5):447-453. doi: 10.1097/ICU.0000000000000685.,Hallak JA,Curr Opin Ophthalmol,2020,23-07-2020,PMC8516074,NIHMS1744118,10.1097/ICU.0000000000000685,"PURPOSE OF REVIEW: To highlight artificial intelligence applications in ophthalmology during the COVID-19 pandemic that can be used to: describe ocular findings and changes correlated with COVID-19; extract information from scholarly articles on SARS-CoV-2 and COVID-19 specific to ophthalmology; and implement efficient patient triage and telemedicine care.
RECENT FINDINGS: Ophthalmology has been leading in artificial intelligence and technology applications. With medical imaging analysis, pixel-annotated distinguishable features on COVID-19 patients may help with noninvasive diagnosis and severity outcome predictions. Using natural language processing (NLP) and data integration methods, topic modeling on more than 200 ophthalmology-related articles on COVID-19 can summarize ocular manifestations, viral transmission, treatment strategies, and patient care and practice management. Artificial intelligence for telemedicine applications can address the high demand, prioritize and triage patients, as well as improve at home-monitoring devices and secure data transfers.
SUMMARY: COVID-19 is significantly impacting the way we are delivering healthcare. Given the already successful implementation of artificial intelligence applications and telemedicine in ophthalmology, we expect that these systems will be embraced more as tools for research, education, and patient care.","Artificial intelligence in ophthalmology during COVID-19 and in the post COVID-19 era PURPOSE OF REVIEW: To highlight artificial intelligence applications in ophthalmology during the COVID-19 pandemic that can be used to: describe ocular findings and changes correlated with COVID-19; extract information from scholarly articles on SARS-CoV-2 and COVID-19 specific to ophthalmology; and implement efficient patient triage and telemedicine care.
RECENT FINDINGS: Ophthalmology has been leading in artificial intelligence and technology applications. With medical imaging analysis, pixel-annotated distinguishable features on COVID-19 patients may help with noninvasive diagnosis and severity outcome predictions. Using natural language processing (NLP) and data integration methods, topic modeling on more than 200 ophthalmology-related articles on COVID-19 can summarize ocular manifestations, viral transmission, treatment strategies, and patient care and practice management. Artificial intelligence for telemedicine applications can address the high demand, prioritize and triage patients, as well as improve at home-monitoring devices and secure data transfers.
SUMMARY: COVID-19 is significantly impacting the way we are delivering healthcare. Given the already successful implementation of artificial intelligence applications and telemedicine in ophthalmology, we expect that these systems will be embraced more as tools for research, education, and patient care.",1,1
38055548,Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection,"Silva RPD, Pollettini JT, Pazin Filho A.",Cad Saude Publica. 2023 Dec 4;39(11):e00243722. doi: 10.1590/0102-311XPT243722. eCollection 2023.,Silva RPD,Cad Saude Publica,2023,06-12-2023,PMC10695477,,10.1590/0102-311XPT243722,"Patients with post-COVID-19 syndrome benefit from health promotion programs. Their rapid identification is important for the cost-effective use of these programs. Traditional identification techniques perform poorly especially in pandemics. A descriptive observational study was carried out using 105,008 prior authorizations paid by a private health care provider with the application of an unsupervised natural language processing method by topic modeling to identify patients suspected of being infected by COVID-19. A total of 6 models were generated: 3 using the BERTopic algorithm and 3 Word2Vec models. The BERTopic model automatically creates disease groups. In the Word2Vec model, manual analysis of the first 100 cases of each topic was necessary to define the topics related to COVID-19. The BERTopic model with more than 1,000 authorizations per topic without word treatment selected more severe patients - average cost per prior authorizations paid of BRL 10,206 and total expenditure of BRL 20.3 million (5.4%) in 1,987 prior authorizations (1.9%). It had 70% accuracy compared to human analysis and 20% of cases with potential interest, all subject to analysis for inclusion in a health promotion program. It had an important loss of cases when compared to the traditional research model with structured language and identified other groups of diseases - orthopedic, mental and cancer. The BERTopic model served as an exploratory method to be used in case labeling and subsequent application in supervised models. The automatic identification of other diseases raises ethical questions about the treatment of health information by machine learning.","Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection Patients with post-COVID-19 syndrome benefit from health promotion programs. Their rapid identification is important for the cost-effective use of these programs. Traditional identification techniques perform poorly especially in pandemics. A descriptive observational study was carried out using 105,008 prior authorizations paid by a private health care provider with the application of an unsupervised natural language processing method by topic modeling to identify patients suspected of being infected by COVID-19. A total of 6 models were generated: 3 using the BERTopic algorithm and 3 Word2Vec models. The BERTopic model automatically creates disease groups. In the Word2Vec model, manual analysis of the first 100 cases of each topic was necessary to define the topics related to COVID-19. The BERTopic model with more than 1,000 authorizations per topic without word treatment selected more severe patients - average cost per prior authorizations paid of BRL 10,206 and total expenditure of BRL 20.3 million (5.4%) in 1,987 prior authorizations (1.9%). It had 70% accuracy compared to human analysis and 20% of cases with potential interest, all subject to analysis for inclusion in a health promotion program. It had an important loss of cases when compared to the traditional research model with structured language and identified other groups of diseases - orthopedic, mental and cancer. The BERTopic model served as an exploratory method to be used in case labeling and subsequent application in supervised models. The automatic identification of other diseases raises ethical questions about the treatment of health information by machine learning.",1,1
32521776,Studies of Novel Coronavirus Disease 19 (COVID-19) Pandemic: A Global Analysis of Literature,"Tran BX, Ha GH, Nguyen LH, Vu GT, Hoang MT, Le HT, Latkin CA, Ho CSH, Ho RCM.",Int J Environ Res Public Health. 2020 Jun 8;17(11):4095. doi: 10.3390/ijerph17114095.,Tran BX,Int J Environ Res Public Health,2020,12-06-2020,PMC7312200,,10.3390/ijerph17114095,"Novel coronavirus disease 19 (COVID-19) is a global threat to millions of lives. Enormous efforts in knowledge production have been made in the last few months, requiring a comprehensive analysis to examine the research gaps and to help guide an agenda for further studies. This study aims to explore the current research foci and their country variations regarding levels of income and COVID-19 transmission features. This textual analysis of 5780 publications extracted from the Web of Science, Medline, and Scopus databases was performed to explore the current research foci and propose further research agenda. The Latent Dirichlet allocation was used for topic modeling. Regression analysis was conducted to examine country variations in the research foci. Results indicate that publications are mainly contributed by the United States, China, and European countries. Guidelines for emergency care and surgical, viral pathogenesis, and global responses in the COVID-19 pandemic are the most common topics. There is variation in the research approaches to mitigate COVID-19 problems in countries with different income and transmission levels. Findings highlighted the need for global research collaborations among high- and low/middle-income countries in the different stages of pandemic prevention and control.","Studies of Novel Coronavirus Disease 19 (COVID-19) Pandemic: A Global Analysis of Literature Novel coronavirus disease 19 (COVID-19) is a global threat to millions of lives. Enormous efforts in knowledge production have been made in the last few months, requiring a comprehensive analysis to examine the research gaps and to help guide an agenda for further studies. This study aims to explore the current research foci and their country variations regarding levels of income and COVID-19 transmission features. This textual analysis of 5780 publications extracted from the Web of Science, Medline, and Scopus databases was performed to explore the current research foci and propose further research agenda. The Latent Dirichlet allocation was used for topic modeling. Regression analysis was conducted to examine country variations in the research foci. Results indicate that publications are mainly contributed by the United States, China, and European countries. Guidelines for emergency care and surgical, viral pathogenesis, and global responses in the COVID-19 pandemic are the most common topics. There is variation in the research approaches to mitigate COVID-19 problems in countries with different income and transmission levels. Findings highlighted the need for global research collaborations among high- and low/middle-income countries in the different stages of pandemic prevention and control.",1,1
34063087,Structural Insights into the Respiratory Syncytial Virus RNA Synthesis Complexes,"Cao D, Gao Y, Liang B.",Viruses. 2021 May 5;13(5):834. doi: 10.3390/v13050834.,Cao D,Viruses,2021,02-06-2021,PMC8147935,,10.3390/v13050834,"RNA synthesis in respiratory syncytial virus (RSV), a negative-sense (-) nonsegmented RNA virus, consists of viral gene transcription and genome replication. Gene transcription includes the positive-sense (+) viral mRNA synthesis, 5'-RNA capping and methylation, and 3' end polyadenylation. Genome replication includes (+) RNA antigenome and (-) RNA genome synthesis. RSV executes the viral RNA synthesis using an RNA synthesis ribonucleoprotein (RNP) complex, comprising four proteins, the nucleoprotein (N), the large protein (L), the phosphoprotein (P), and the M2-1 protein. We provide an overview of the RSV RNA synthesis and the structural insights into the RSV gene transcription and genome replication process. We propose a model of how the essential four proteins coordinate their activities in different RNA synthesis processes.","Structural Insights into the Respiratory Syncytial Virus RNA Synthesis Complexes RNA synthesis in respiratory syncytial virus (RSV), a negative-sense (-) nonsegmented RNA virus, consists of viral gene transcription and genome replication. Gene transcription includes the positive-sense (+) viral mRNA synthesis, 5'-RNA capping and methylation, and 3' end polyadenylation. Genome replication includes (+) RNA antigenome and (-) RNA genome synthesis. RSV executes the viral RNA synthesis using an RNA synthesis ribonucleoprotein (RNP) complex, comprising four proteins, the nucleoprotein (N), the large protein (L), the phosphoprotein (P), and the M2-1 protein. We provide an overview of the RSV RNA synthesis and the structural insights into the RSV gene transcription and genome replication process. We propose a model of how the essential four proteins coordinate their activities in different RNA synthesis processes.",0,0
26379035,Environmental and Behavioural Determinants of Leptospirosis Transmission: A Systematic Review,"Mwachui MA, Crump L, Hartskeerl R, Zinsstag J, Hattendorf J.",PLoS Negl Trop Dis. 2015 Sep 17;9(9):e0003843. doi: 10.1371/journal.pntd.0003843. eCollection 2015.,Mwachui MA,PLoS Negl Trop Dis,2015,18-09-2015,PMC4574979,,10.1371/journal.pntd.0003843,"BACKGROUND: Leptospirosis is one of the most widespread zoonotic diseases, which is of global medical and veterinary importance, and also a re-emerging infectious disease. The main tracks of transmission are known; however, the relative importance of each of the components and the respective environmental risk factors are unclear. We aimed to assess and specify quantitative evidence of environmental risks of leptospirosis transmission.
METHODS/FINDINGS: A database of pre-selected studies, with publication dates from 1970 until 2008, was provided by an expert group. The database has been updated until 2015 using a text mining algorithm. Study selection was based on stringent quality criteria. A descriptive data analysis was performed to calculate the medians of the log transformed odds ratios. From a selection of 2723 unique publications containing information on leptospirosis, 428 papers dealing with risk factors were identified. Of these, 53 fulfilled the quality criteria, allowing us to identify trends in different geo-climatic regions. Water associated exposures were, with few exceptions, associated with an increased leptospirosis risk. In resource poor countries, floods and rainfall were of particular importance, whereas recreational water activities were more relevant in developed countries. Rodents were associated with increased leptospirosis risk, but the variation among studies was high, which might be partly explained by differences in exposure definition. Livestock contact was commonly associated with increased risk; however, several studies found no association. The median odds ratios associated with dog and cat contacts were close to unity. Sanitation and behavioural risk factors were almost always strongly associated with leptospirosis, although their impact was rarely investigated in Europe or North America.
CONCLUSION: This review confirms the complex environmental transmission pathways of leptospirosis, as previously established. Although, floods appeared to be among the most important drivers on islands and in Asia, the consistent pattern observed for exposure to rodents and behavioural and sanitation related risk factors indicate potential areas for intervention.","Environmental and Behavioural Determinants of Leptospirosis Transmission: A Systematic Review BACKGROUND: Leptospirosis is one of the most widespread zoonotic diseases, which is of global medical and veterinary importance, and also a re-emerging infectious disease. The main tracks of transmission are known; however, the relative importance of each of the components and the respective environmental risk factors are unclear. We aimed to assess and specify quantitative evidence of environmental risks of leptospirosis transmission.
METHODS/FINDINGS: A database of pre-selected studies, with publication dates from 1970 until 2008, was provided by an expert group. The database has been updated until 2015 using a text mining algorithm. Study selection was based on stringent quality criteria. A descriptive data analysis was performed to calculate the medians of the log transformed odds ratios. From a selection of 2723 unique publications containing information on leptospirosis, 428 papers dealing with risk factors were identified. Of these, 53 fulfilled the quality criteria, allowing us to identify trends in different geo-climatic regions. Water associated exposures were, with few exceptions, associated with an increased leptospirosis risk. In resource poor countries, floods and rainfall were of particular importance, whereas recreational water activities were more relevant in developed countries. Rodents were associated with increased leptospirosis risk, but the variation among studies was high, which might be partly explained by differences in exposure definition. Livestock contact was commonly associated with increased risk; however, several studies found no association. The median odds ratios associated with dog and cat contacts were close to unity. Sanitation and behavioural risk factors were almost always strongly associated with leptospirosis, although their impact was rarely investigated in Europe or North America.
CONCLUSION: This review confirms the complex environmental transmission pathways of leptospirosis, as previously established. Although, floods appeared to be among the most important drivers on islands and in Asia, the consistent pattern observed for exposure to rodents and behavioural and sanitation related risk factors indicate potential areas for intervention.",1,0
33489245,The prevalence of mental health problems in sub-Saharan adolescents living with HIV: a systematic review,"Dessauvagie AS, Jörns-Presentati A, Napp AK, Stein DJ, Jonker D, Breet E, Charles W, Swart RL, Lahti M, Suliman S, Jansen R, van den Heuvel LL, Seedat S, Groen G.",Glob Ment Health (Camb). 2020 Oct 26;7:e29. doi: 10.1017/gmh.2020.18. eCollection 2020.,Dessauvagie AS,Glob Ment Health (Camb),2020,25-01-2021,PMC7786273,,10.1017/gmh.2020.18,"Despite the progress made in HIV treatment and prevention, HIV remains a major cause of adolescent morbidity and mortality in sub-Saharan Africa. As perinatally infected children increasingly survive into adulthood, the quality of life and mental health of this population has increased in importance. This review provides a synthesis of the prevalence of mental health problems in this population and explores associated factors. A systematic database search (Medline, PsycINFO, Scopus) with an additional hand search was conducted. Peer-reviewed studies on adolescents (aged 10-19), published between 2008 and 2019, assessing mental health symptoms or psychiatric disorders, either by standardized questionnaires or by diagnostic interviews, were included. The search identified 1461 articles, of which 301 were eligible for full-text analysis. Fourteen of these, concerning HIV-positive adolescents, met the inclusion criteria and were critically appraised. Mental health problems were highly prevalent among this group, with around 25% scoring positive for any psychiatric disorder and 30-50% showing emotional or behavioral difficulties or significant psychological distress. Associated factors found by regression analysis were older age, not being in school, impaired family functioning, HIV-related stigma and bullying, and poverty. Social support and parental competence were protective factors. Mental health problems among HIV-positive adolescents are highly prevalent and should be addressed as part of regular HIV care.","The prevalence of mental health problems in sub-Saharan adolescents living with HIV: a systematic review Despite the progress made in HIV treatment and prevention, HIV remains a major cause of adolescent morbidity and mortality in sub-Saharan Africa. As perinatally infected children increasingly survive into adulthood, the quality of life and mental health of this population has increased in importance. This review provides a synthesis of the prevalence of mental health problems in this population and explores associated factors. A systematic database search (Medline, PsycINFO, Scopus) with an additional hand search was conducted. Peer-reviewed studies on adolescents (aged 10-19), published between 2008 and 2019, assessing mental health symptoms or psychiatric disorders, either by standardized questionnaires or by diagnostic interviews, were included. The search identified 1461 articles, of which 301 were eligible for full-text analysis. Fourteen of these, concerning HIV-positive adolescents, met the inclusion criteria and were critically appraised. Mental health problems were highly prevalent among this group, with around 25% scoring positive for any psychiatric disorder and 30-50% showing emotional or behavioral difficulties or significant psychological distress. Associated factors found by regression analysis were older age, not being in school, impaired family functioning, HIV-related stigma and bullying, and poverty. Social support and parental competence were protective factors. Mental health problems among HIV-positive adolescents are highly prevalent and should be addressed as part of regular HIV care.",1,0
37220197,Understanding Mobile Health and Youth Mental Health: Scoping Review,"Ding X, Wuerth K, Sakakibara B, Schmidt J, Parde N, Holsti L, Barbic S.",JMIR Mhealth Uhealth. 2023 Jun 16;11:e44951. doi: 10.2196/44951.,Ding X,JMIR Mhealth Uhealth,2023,23-05-2023,PMC10278734,,10.2196/44951,"BACKGROUND: A total of 75% of people with mental health disorders have an onset of illness between the ages of 12 and 24 years. Many in this age group report substantial obstacles to receiving quality youth-centered mental health care services. With the rapid development of technology and the recent COVID-19 pandemic, mobile health (mHealth) has presented new opportunities for youth mental health research, practice, and policy.
OBJECTIVE: The research objectives were to (1) synthesize the current evidence supporting mHealth interventions for youths who experience mental health challenges and (2) identify current gaps in the mHealth field related to youth's access to mental health services and health outcomes.
METHODS: Guided by the methods of Arksey and O'Malley, we conducted a scoping review of peer-reviewed studies that used mHealth tools to improve youth mental health (January 2016-February 2022). We searched MEDLINE, PubMed, PsycINFO, and Embase databases using the following key terms: (1) mHealth; (2) youth and young adults; and (3) mental health. The current gaps were analyzed using content analysis.
RESULTS: The search produced 4270 records, of which 151 met inclusion criteria. Included articles highlight the comprehensive aspects of youth mHealth intervention resource allocation for targeted conditions, mHealth delivery methods, measurement tools, evaluation of mHealth intervention, and youth engagement. The median age for participants in all studies is 17 (IQR 14-21) years. Only 3 (2%) studies involved participants who reported their sex or gender outside of the binary option. Many studies (68/151, 45%) were published after the onset of the COVID-19 outbreak. Study types and designs varied, with 60 (40%) identified as randomized controlled trials. Notably, 143 out of 151 (95%) studies came from developed countries, suggesting an evidence shortfall on the feasibility of implementing mHealth services in lower-resourced settings. Additionally, the results highlight concerns related to inadequate resources devoted to self-harm and substance uses, weak study design, expert engagement, and the variety of outcome measures selected to capture impact or changes over time. There is also a lack of standardized regulations and guidelines for researching mHealth technologies for youths and the use of non-youth-centered approaches to implementing results.
CONCLUSIONS: This study may be used to inform future work as well as the development of youth-centered mHealth tools that can be implemented and sustained over time for diverse types of youths. Implementation science research that prioritizes youths' engagement is needed to advance the current understanding of mHealth implementation. Moreover, core outcome sets may support a youth-centered measurement strategy to capture outcomes in a systematic way that prioritizes equity, diversity, inclusion, and robust measurement science. Finally, this study suggests that future practice and policy research are needed to ensure the risk of mHealth is minimized and that this innovative health care service is meeting the emerging needs of youths over time.","Understanding Mobile Health and Youth Mental Health: Scoping Review BACKGROUND: A total of 75% of people with mental health disorders have an onset of illness between the ages of 12 and 24 years. Many in this age group report substantial obstacles to receiving quality youth-centered mental health care services. With the rapid development of technology and the recent COVID-19 pandemic, mobile health (mHealth) has presented new opportunities for youth mental health research, practice, and policy.
OBJECTIVE: The research objectives were to (1) synthesize the current evidence supporting mHealth interventions for youths who experience mental health challenges and (2) identify current gaps in the mHealth field related to youth's access to mental health services and health outcomes.
METHODS: Guided by the methods of Arksey and O'Malley, we conducted a scoping review of peer-reviewed studies that used mHealth tools to improve youth mental health (January 2016-February 2022). We searched MEDLINE, PubMed, PsycINFO, and Embase databases using the following key terms: (1) mHealth; (2) youth and young adults; and (3) mental health. The current gaps were analyzed using content analysis.
RESULTS: The search produced 4270 records, of which 151 met inclusion criteria. Included articles highlight the comprehensive aspects of youth mHealth intervention resource allocation for targeted conditions, mHealth delivery methods, measurement tools, evaluation of mHealth intervention, and youth engagement. The median age for participants in all studies is 17 (IQR 14-21) years. Only 3 (2%) studies involved participants who reported their sex or gender outside of the binary option. Many studies (68/151, 45%) were published after the onset of the COVID-19 outbreak. Study types and designs varied, with 60 (40%) identified as randomized controlled trials. Notably, 143 out of 151 (95%) studies came from developed countries, suggesting an evidence shortfall on the feasibility of implementing mHealth services in lower-resourced settings. Additionally, the results highlight concerns related to inadequate resources devoted to self-harm and substance uses, weak study design, expert engagement, and the variety of outcome measures selected to capture impact or changes over time. There is also a lack of standardized regulations and guidelines for researching mHealth technologies for youths and the use of non-youth-centered approaches to implementing results.
CONCLUSIONS: This study may be used to inform future work as well as the development of youth-centered mHealth tools that can be implemented and sustained over time for diverse types of youths. Implementation science research that prioritizes youths' engagement is needed to advance the current understanding of mHealth implementation. Moreover, core outcome sets may support a youth-centered measurement strategy to capture outcomes in a systematic way that prioritizes equity, diversity, inclusion, and robust measurement science. Finally, this study suggests that future practice and policy research are needed to ensure the risk of mHealth is minimized and that this innovative health care service is meeting the emerging needs of youths over time.",0,0
32936777,Natural Language Processing Reveals Vulnerable Mental Health Support Groups and Heightened Health Anxiety on Reddit During COVID-19: Observational Study,"Low DM, Rumker L, Talkar T, Torous J, Cecchi G, Ghosh SS.",J Med Internet Res. 2020 Oct 12;22(10):e22635. doi: 10.2196/22635.,Low DM,J Med Internet Res,2020,16-09-2020,PMC7575341,,10.2196/22635,"BACKGROUND: The COVID-19 pandemic is impacting mental health, but it is not clear how people with different types of mental health problems were differentially impacted as the initial wave of cases hit.
OBJECTIVE: The aim of this study is to leverage natural language processing (NLP) with the goal of characterizing changes in 15 of the world's largest mental health support groups (eg, r/schizophrenia, r/SuicideWatch, r/Depression) found on the website Reddit, along with 11 non-mental health groups (eg, r/PersonalFinance, r/conspiracy) during the initial stage of the pandemic.
METHODS: We created and released the Reddit Mental Health Dataset including posts from 826,961 unique users from 2018 to 2020. Using regression, we analyzed trends from 90 text-derived features such as sentiment analysis, personal pronouns, and semantic categories. Using supervised machine learning, we classified posts into their respective support groups and interpreted important features to understand how different problems manifest in language. We applied unsupervised methods such as topic modeling and unsupervised clustering to uncover concerns throughout Reddit before and during the pandemic.
RESULTS: We found that the r/HealthAnxiety forum showed spikes in posts about COVID-19 early on in January, approximately 2 months before other support groups started posting about the pandemic. There were many features that significantly increased during COVID-19 for specific groups including the categories ""economic stress,"" ""isolation,"" and ""home,"" while others such as ""motion"" significantly decreased. We found that support groups related to attention-deficit/hyperactivity disorder, eating disorders, and anxiety showed the most negative semantic change during the pandemic out of all mental health groups. Health anxiety emerged as a general theme across Reddit through independent supervised and unsupervised machine learning analyses. For instance, we provide evidence that the concerns of a diverse set of individuals are converging in this unique moment of history; we discovered that the more users posted about COVID-19, the more linguistically similar (less distant) the mental health support groups became to r/HealthAnxiety (ρ=-0.96, P<.001). Using unsupervised clustering, we found the suicidality and loneliness clusters more than doubled in the number of posts during the pandemic. Specifically, the support groups for borderline personality disorder and posttraumatic stress disorder became significantly associated with the suicidality cluster. Furthermore, clusters surrounding self-harm and entertainment emerged.
CONCLUSIONS: By using a broad set of NLP techniques and analyzing a baseline of prepandemic posts, we uncovered patterns of how specific mental health problems manifest in language, identified at-risk users, and revealed the distribution of concerns across Reddit, which could help provide better resources to its millions of users. We then demonstrated that textual analysis is sensitive to uncover mental health complaints as they appear in real time, identifying vulnerable groups and alarming themes during COVID-19, and thus may have utility during the ongoing pandemic and other world-changing events such as elections and protests.","Natural Language Processing Reveals Vulnerable Mental Health Support Groups and Heightened Health Anxiety on Reddit During COVID-19: Observational Study BACKGROUND: The COVID-19 pandemic is impacting mental health, but it is not clear how people with different types of mental health problems were differentially impacted as the initial wave of cases hit.
OBJECTIVE: The aim of this study is to leverage natural language processing (NLP) with the goal of characterizing changes in 15 of the world's largest mental health support groups (eg, r/schizophrenia, r/SuicideWatch, r/Depression) found on the website Reddit, along with 11 non-mental health groups (eg, r/PersonalFinance, r/conspiracy) during the initial stage of the pandemic.
METHODS: We created and released the Reddit Mental Health Dataset including posts from 826,961 unique users from 2018 to 2020. Using regression, we analyzed trends from 90 text-derived features such as sentiment analysis, personal pronouns, and semantic categories. Using supervised machine learning, we classified posts into their respective support groups and interpreted important features to understand how different problems manifest in language. We applied unsupervised methods such as topic modeling and unsupervised clustering to uncover concerns throughout Reddit before and during the pandemic.
RESULTS: We found that the r/HealthAnxiety forum showed spikes in posts about COVID-19 early on in January, approximately 2 months before other support groups started posting about the pandemic. There were many features that significantly increased during COVID-19 for specific groups including the categories ""economic stress,"" ""isolation,"" and ""home,"" while others such as ""motion"" significantly decreased. We found that support groups related to attention-deficit/hyperactivity disorder, eating disorders, and anxiety showed the most negative semantic change during the pandemic out of all mental health groups. Health anxiety emerged as a general theme across Reddit through independent supervised and unsupervised machine learning analyses. For instance, we provide evidence that the concerns of a diverse set of individuals are converging in this unique moment of history; we discovered that the more users posted about COVID-19, the more linguistically similar (less distant) the mental health support groups became to r/HealthAnxiety (ρ=-0.96, P<.001). Using unsupervised clustering, we found the suicidality and loneliness clusters more than doubled in the number of posts during the pandemic. Specifically, the support groups for borderline personality disorder and posttraumatic stress disorder became significantly associated with the suicidality cluster. Furthermore, clusters surrounding self-harm and entertainment emerged.
CONCLUSIONS: By using a broad set of NLP techniques and analyzing a baseline of prepandemic posts, we uncovered patterns of how specific mental health problems manifest in language, identified at-risk users, and revealed the distribution of concerns across Reddit, which could help provide better resources to its millions of users. We then demonstrated that textual analysis is sensitive to uncover mental health complaints as they appear in real time, identifying vulnerable groups and alarming themes during COVID-19, and thus may have utility during the ongoing pandemic and other world-changing events such as elections and protests.",1,0
37533519,Sentiment analysis of epidemiological surveillance reports on COVID-19 in Greece using machine learning models,"Stefanis C, Giorgi E, Kalentzis K, Tselemponis A, Nena E, Tsigalou C, Kontogiorgis C, Kourkoutas Y, Chatzak E, Dokas I, Constantinidis T, Bezirtzoglou E.",Front Public Health. 2023 Jul 18;11:1191730. doi: 10.3389/fpubh.2023.1191730. eCollection 2023.,Stefanis C,Front Public Health,2023,03-08-2023,PMC10392838,,10.3389/fpubh.2023.1191730,"The present research deals with sentiment analysis performed with Microsoft Azure Machine Learning Studio to classify Facebook posts on the Greek National Public Health Organization (EODY) from November 2021 to January 2022 during the pandemic. Positive, negative and neutral sentiments were included after processing 300 reviews. This approach involved analyzing the words appearing in the comments and exploring the sentiments related to daily surveillance reports of COVID-19 published on the EODY Facebook page. Moreover, machine learning algorithms were implemented to predict the classification of sentiments. This research assesses the efficiency of a few popular machine learning models, which is one of the initial efforts in Greece in this domain. People have negative sentiments toward COVID surveillance reports. Words with the highest frequency of occurrence include government, vaccinated people, unvaccinated, telephone communication, health measures, virus, COVID-19 rapid/molecular tests, and of course, COVID-19. The experimental results disclose additionally that two classifiers, namely two class Neural Network and two class Bayes Point Machine, achieved high sentiment analysis accuracy and F1 score, particularly 87% and over 35%. A significant limitation of this study may be the need for more comparison with other research attempts that identified the sentiments of the EODY surveillance reports of COVID in Greece. Machine learning models can provide critical information combating public health hazards and enrich communication strategies and proactive actions in public health issues and opinion management during the COVID-19 pandemic.","Sentiment analysis of epidemiological surveillance reports on COVID-19 in Greece using machine learning models The present research deals with sentiment analysis performed with Microsoft Azure Machine Learning Studio to classify Facebook posts on the Greek National Public Health Organization (EODY) from November 2021 to January 2022 during the pandemic. Positive, negative and neutral sentiments were included after processing 300 reviews. This approach involved analyzing the words appearing in the comments and exploring the sentiments related to daily surveillance reports of COVID-19 published on the EODY Facebook page. Moreover, machine learning algorithms were implemented to predict the classification of sentiments. This research assesses the efficiency of a few popular machine learning models, which is one of the initial efforts in Greece in this domain. People have negative sentiments toward COVID surveillance reports. Words with the highest frequency of occurrence include government, vaccinated people, unvaccinated, telephone communication, health measures, virus, COVID-19 rapid/molecular tests, and of course, COVID-19. The experimental results disclose additionally that two classifiers, namely two class Neural Network and two class Bayes Point Machine, achieved high sentiment analysis accuracy and F1 score, particularly 87% and over 35%. A significant limitation of this study may be the need for more comparison with other research attempts that identified the sentiments of the EODY surveillance reports of COVID in Greece. Machine learning models can provide critical information combating public health hazards and enrich communication strategies and proactive actions in public health issues and opinion management during the COVID-19 pandemic.",1,0
38296310,Prevalence and clinical characteristics of patients with rheumatoid arthritis with interstitial lung disease using unstructured healthcare data and machine learning,"Román Ivorra JA, Trallero-Araguas E, Lopez Lasanta M, Cebrián L, Lojo L, López-Muñíz B, Fernández-Melon J, Núñez B, Silva-Fernández L, Veiga Cabello R, Ahijado P, De la Morena Barrio I, Costas Torrijo N, Safont B, Ornilla E, Restrepo J, Campo A, Andreu JL, Díez E, López Robles A, Bollo E, Benavent D, Vilanova D, Luján Valdés S, Castellanos-Moreira R.",RMD Open. 2024 Jan 30;10(1):e003353. doi: 10.1136/rmdopen-2023-003353.,Román Ivorra JA,RMD Open,2024,31-01-2024,PMC10836356,,10.1136/rmdopen-2023-003353,"OBJECTIVES: Real-world data regarding rheumatoid arthritis (RA) and its association with interstitial lung disease (ILD) is still scarce. This study aimed to estimate the prevalence of RA and ILD in patients with RA (RAILD) in Spain, and to compare clinical characteristics of patients with RA with and without ILD using natural language processing (NLP) on electronic health records (EHR).
METHODS: Observational case-control, retrospective and multicentre study based on the secondary use of unstructured clinical data from patients with adult RA and RAILD from nine hospitals between 2014 and 2019. NLP was used to extract unstructured clinical information from EHR and standardise it into a SNOMED-CT terminology. Prevalence of RA and RAILD were calculated, and a descriptive analysis was performed. Characteristics between patients with RAILD and RA patients without ILD (RAnonILD) were compared.
RESULTS: From a source population of 3 176 165 patients and 64 241 683 EHRs, 13 958 patients with RA were identified. Of those, 5.1% patients additionally had ILD (RAILD). The overall age-adjusted prevalence of RA and RAILD were 0.53% and 0.02%, respectively. The most common ILD subtype was usual interstitial pneumonia (29.3%). When comparing RAILD versus RAnonILD patients, RAILD patients were older and had more comorbidities, notably concerning infections (33.6% vs 16.5%, p<0.001), malignancies (15.9% vs 8.5%, p<0.001) and cardiovascular disease (25.8% vs 13.9%, p<0.001) than RAnonILD. RAILD patients also had higher inflammatory burden reflected in more pharmacological prescriptions and higher inflammatory parameters and presented a higher in-hospital mortality with a higher risk of death (HR 2.32; 95% CI 1.59 to 2.81, p<0.001).
CONCLUSIONS: We found an estimated age-adjusted prevalence of RA and RAILD by analysing real-world data through NLP. RAILD patients were more vulnerable at the time of inclusion with higher comorbidity and inflammatory burden than RAnonILD, which correlated with higher mortality.","Prevalence and clinical characteristics of patients with rheumatoid arthritis with interstitial lung disease using unstructured healthcare data and machine learning OBJECTIVES: Real-world data regarding rheumatoid arthritis (RA) and its association with interstitial lung disease (ILD) is still scarce. This study aimed to estimate the prevalence of RA and ILD in patients with RA (RAILD) in Spain, and to compare clinical characteristics of patients with RA with and without ILD using natural language processing (NLP) on electronic health records (EHR).
METHODS: Observational case-control, retrospective and multicentre study based on the secondary use of unstructured clinical data from patients with adult RA and RAILD from nine hospitals between 2014 and 2019. NLP was used to extract unstructured clinical information from EHR and standardise it into a SNOMED-CT terminology. Prevalence of RA and RAILD were calculated, and a descriptive analysis was performed. Characteristics between patients with RAILD and RA patients without ILD (RAnonILD) were compared.
RESULTS: From a source population of 3 176 165 patients and 64 241 683 EHRs, 13 958 patients with RA were identified. Of those, 5.1% patients additionally had ILD (RAILD). The overall age-adjusted prevalence of RA and RAILD were 0.53% and 0.02%, respectively. The most common ILD subtype was usual interstitial pneumonia (29.3%). When comparing RAILD versus RAnonILD patients, RAILD patients were older and had more comorbidities, notably concerning infections (33.6% vs 16.5%, p<0.001), malignancies (15.9% vs 8.5%, p<0.001) and cardiovascular disease (25.8% vs 13.9%, p<0.001) than RAnonILD. RAILD patients also had higher inflammatory burden reflected in more pharmacological prescriptions and higher inflammatory parameters and presented a higher in-hospital mortality with a higher risk of death (HR 2.32; 95% CI 1.59 to 2.81, p<0.001).
CONCLUSIONS: We found an estimated age-adjusted prevalence of RA and RAILD by analysing real-world data through NLP. RAILD patients were more vulnerable at the time of inclusion with higher comorbidity and inflammatory burden than RAnonILD, which correlated with higher mortality.",1,0
27515422,Human herpes viruses in burn patients: A systematic review,"Wurzer P, Guillory A, Parvizi D, Clayton RP, Branski LK, Kamolz LP, Finnerty CC, Herndon DN, Lee JO.",Burns. 2017 Feb;43(1):25-33. doi: 10.1016/j.burns.2016.02.003. Epub 2016 Aug 8.,Wurzer P,Burns,2017,13-08-2016,PMC5239736,NIHMS759013,10.1016/j.burns.2016.02.003,"OBJECTIVE: The contribution of human herpes viruses, including herpes simplex virus (HSV), cytomegalovirus (CMV), and varicella zoster virus (VZV) to morbidity and mortality after burns remains controversial. This systematic review was undertaken to assess evidence of herpes virus-related morbidity and mortality in burns.
MATERIALS AND METHODS: PubMed, Ovid, and Web of Science were searched to identify studies of HSV, CMV, or VZV infections in burn patients. Exclusion criteria included: A level of evidence (LoE) of IV or V; nonhuman in vivo studies; and non-English articles. There was no limitation by publication date.
RESULTS: Fifty articles were subjected to full-text analysis. Of these, 18 had LoE between I-III and were included in the final review (2 LoE I, 16 LoE II-III). Eight had a prospective study design, 9 had a retrospective study design, and 1 included both.
CONCLUSIONS: No direct evidence linked CMV and HSV infection with increased morbidity and mortality in burns. Following burn, CMV reactivation was more common than a primary CMV infection. Active HSV infection impaired wound healing but was not directly correlated to mortality. Infections with VZV are rare after burns but when they occur, VZV infections were associated with severe complications including mortality. The therapeutic effect of antiviral agents administered after burns warrants investigation via prospective randomized controlled trials.","Human herpes viruses in burn patients: A systematic review OBJECTIVE: The contribution of human herpes viruses, including herpes simplex virus (HSV), cytomegalovirus (CMV), and varicella zoster virus (VZV) to morbidity and mortality after burns remains controversial. This systematic review was undertaken to assess evidence of herpes virus-related morbidity and mortality in burns.
MATERIALS AND METHODS: PubMed, Ovid, and Web of Science were searched to identify studies of HSV, CMV, or VZV infections in burn patients. Exclusion criteria included: A level of evidence (LoE) of IV or V; nonhuman in vivo studies; and non-English articles. There was no limitation by publication date.
RESULTS: Fifty articles were subjected to full-text analysis. Of these, 18 had LoE between I-III and were included in the final review (2 LoE I, 16 LoE II-III). Eight had a prospective study design, 9 had a retrospective study design, and 1 included both.
CONCLUSIONS: No direct evidence linked CMV and HSV infection with increased morbidity and mortality in burns. Following burn, CMV reactivation was more common than a primary CMV infection. Active HSV infection impaired wound healing but was not directly correlated to mortality. Infections with VZV are rare after burns but when they occur, VZV infections were associated with severe complications including mortality. The therapeutic effect of antiviral agents administered after burns warrants investigation via prospective randomized controlled trials.",1,0
34488645,Applying a novel approach to scoping review incorporating artificial intelligence: mapping the natural history of gonorrhoea,"Whelan J, Ghoniem M, Médoc N, Apicella M, Beck E.",BMC Med Res Methodol. 2021 Sep 6;21(1):183. doi: 10.1186/s12874-021-01367-x.,Whelan J,BMC Med Res Methodol,2021,07-09-2021,PMC8418964,,10.1186/s12874-021-01367-x,"BACKGROUND: Systematic and scoping literature searches are increasingly resource intensive. We present the results of a scoping review which combines the use of a novel artificial-intelligence-(AI)-assisted Medline search tool with two other 'traditional' literature search methods. We illustrate this novel approach with a case study to identify and map the range of conditions (clinical presentations, complications, coinfections and health problems) associated with gonorrhoea infection.
METHODS: To fully characterize the range of health outcomes associated with gonorrhoea, we combined a high yield preliminary search with a traditional systematic search, then supplemented with the output of a novel AI-assisted Medline search tool based on natural language processing methods to identify eligible literature.
RESULTS: We identified 189 health conditions associated with gonorrhoea infection of which: 53 were identified through the initial 'high yield' search; 99 through the systematic search; and 124 through the AI-assisted search. These were extracted from 107 unique references and 21 International Statistical Classification of Diseases and Related Health Problems Ninth and Tenth Revision (ICD 9/10) or Read codes. Health conditions were mapped to the urogenital tract (n = 86), anorectal tract (n = 6) oropharyngeal tract (n = 5) and the eye (n = 14); and other conditions such as systemic (n = 61) and neonatal conditions (n = 7), psychosocial associations (n = 3), and co-infections (n = 7). The 107 unique references attained a Scottish Intercollegiate Guidelines Network (SIGN) score of ≥2++ (n = 2), 2+ (14 [13%]), 2- (30 [28%]) and 3 (45 [42%]), respectively. The remaining papers (n = 16) were reviews.
CONCLUSIONS: Through AI screening of Medline, we captured - titles, abstracts, case reports and case series related to rare but serious health conditions related to gonorrhoea infection. These outcomes might otherwise have been missed during a systematic search. The AI-assisted search provided a useful addition to traditional/manual literature searches especially when rapid results are required in an exploratory setting.","Applying a novel approach to scoping review incorporating artificial intelligence: mapping the natural history of gonorrhoea BACKGROUND: Systematic and scoping literature searches are increasingly resource intensive. We present the results of a scoping review which combines the use of a novel artificial-intelligence-(AI)-assisted Medline search tool with two other 'traditional' literature search methods. We illustrate this novel approach with a case study to identify and map the range of conditions (clinical presentations, complications, coinfections and health problems) associated with gonorrhoea infection.
METHODS: To fully characterize the range of health outcomes associated with gonorrhoea, we combined a high yield preliminary search with a traditional systematic search, then supplemented with the output of a novel AI-assisted Medline search tool based on natural language processing methods to identify eligible literature.
RESULTS: We identified 189 health conditions associated with gonorrhoea infection of which: 53 were identified through the initial 'high yield' search; 99 through the systematic search; and 124 through the AI-assisted search. These were extracted from 107 unique references and 21 International Statistical Classification of Diseases and Related Health Problems Ninth and Tenth Revision (ICD 9/10) or Read codes. Health conditions were mapped to the urogenital tract (n = 86), anorectal tract (n = 6) oropharyngeal tract (n = 5) and the eye (n = 14); and other conditions such as systemic (n = 61) and neonatal conditions (n = 7), psychosocial associations (n = 3), and co-infections (n = 7). The 107 unique references attained a Scottish Intercollegiate Guidelines Network (SIGN) score of ≥2++ (n = 2), 2+ (14 [13%]), 2- (30 [28%]) and 3 (45 [42%]), respectively. The remaining papers (n = 16) were reviews.
CONCLUSIONS: Through AI screening of Medline, we captured - titles, abstracts, case reports and case series related to rare but serious health conditions related to gonorrhoea infection. These outcomes might otherwise have been missed during a systematic search. The AI-assisted search provided a useful addition to traditional/manual literature searches especially when rapid results are required in an exploratory setting.",0,1
34051088,"Privacy-protecting, reliable response data discovery using COVID-19 patient observations","Kim J, Neumann L, Paul P, Day ME, Aratow M, Bell DS, Doctor JN, Hinske LC, Jiang X, Kim KK, Matheny ME, Meeker D, Pletcher MJ, Schilling LM, SooHoo S, Xu H, Zheng K, Ohno-Machado L; R2D2 Consortium.",J Am Med Inform Assoc. 2021 Jul 30;28(8):1765-1776. doi: 10.1093/jamia/ocab054.,Kim J,J Am Med Inform Assoc,2021,29-05-2021,PMC8194878,,10.1093/jamia/ocab054,"OBJECTIVE: To utilize, in an individual and institutional privacy-preserving manner, electronic health record (EHR) data from 202 hospitals by analyzing answers to COVID-19-related questions and posting these answers online.
MATERIALS AND METHODS: We developed a distributed, federated network of 12 health systems that harmonized their EHRs and submitted aggregate answers to consortia questions posted at https://www.covid19questions.org. Our consortium developed processes and implemented distributed algorithms to produce answers to a variety of questions. We were able to generate counts, descriptive statistics, and build a multivariate, iterative regression model without centralizing individual-level data.
RESULTS: Our public website contains answers to various clinical questions, a web form for users to ask questions in natural language, and a list of items that are currently pending responses. The results show, for example, that patients who were taking angiotensin-converting enzyme inhibitors and angiotensin II receptor blockers, within the year before admission, had lower unadjusted in-hospital mortality rates. We also showed that, when adjusted for, age, sex, and ethnicity were not significantly associated with mortality. We demonstrated that it is possible to answer questions about COVID-19 using EHR data from systems that have different policies and must follow various regulations, without moving data out of their health systems.
DISCUSSION AND CONCLUSIONS: We present an alternative or a complement to centralized COVID-19 registries of EHR data. We can use multivariate distributed logistic regression on observations recorded in the process of care to generate results without transferring individual-level data outside the health systems.","Privacy-protecting, reliable response data discovery using COVID-19 patient observations OBJECTIVE: To utilize, in an individual and institutional privacy-preserving manner, electronic health record (EHR) data from 202 hospitals by analyzing answers to COVID-19-related questions and posting these answers online.
MATERIALS AND METHODS: We developed a distributed, federated network of 12 health systems that harmonized their EHRs and submitted aggregate answers to consortia questions posted at https://www.covid19questions.org. Our consortium developed processes and implemented distributed algorithms to produce answers to a variety of questions. We were able to generate counts, descriptive statistics, and build a multivariate, iterative regression model without centralizing individual-level data.
RESULTS: Our public website contains answers to various clinical questions, a web form for users to ask questions in natural language, and a list of items that are currently pending responses. The results show, for example, that patients who were taking angiotensin-converting enzyme inhibitors and angiotensin II receptor blockers, within the year before admission, had lower unadjusted in-hospital mortality rates. We also showed that, when adjusted for, age, sex, and ethnicity were not significantly associated with mortality. We demonstrated that it is possible to answer questions about COVID-19 using EHR data from systems that have different policies and must follow various regulations, without moving data out of their health systems.
DISCUSSION AND CONCLUSIONS: We present an alternative or a complement to centralized COVID-19 registries of EHR data. We can use multivariate distributed logistic regression on observations recorded in the process of care to generate results without transferring individual-level data outside the health systems.",0,0
32068085,"FIB-4 stage of liver fibrosis is associated with incident heart failure with preserved, but not reduced, ejection fraction among people with and without HIV or hepatitis C","So-Armah KA, Lim JK, Lo Re V 3rd, Tate JP, Chang CH, Butt AA, Gibert CL, Rimland D, Marconi VC, Goetz MB, Ramachandran V, Brittain E, Long M, Nguyen KL, Rodriguez-Barradas MC, Budoff MJ, Tindle HA, Samet JH, Justice AC, Freiberg MS; VACS Project Team.",Prog Cardiovasc Dis. 2020 Mar-Apr;63(2):184-191. doi: 10.1016/j.pcad.2020.02.010. Epub 2020 Feb 15.,So-Armah KA,Prog Cardiovasc Dis,2020,19-02-2020,PMC7278895,NIHMS1587068,10.1016/j.pcad.2020.02.010,"BACKGROUND: Liver fibrosis, is independently associated with incident heart failure (HF). Investigating the association between liver fibrosis and type of HF, specifically HF with reduced ejection fraction (EF; HFrEF) or HF with preserved ejection fraction (HFpEF), may provide mechanistic insight into this association. We sought to determine the association between liver fibrosis score (FIB-4) and type of HF, and to assess whether HIV or hepatitis C status modified this association.
METHODS: We included patients alive on or after 4/1/2003 from the Veterans Aging Cohort Study. We followed patients without prevalent cardiovascular disease until their first HF event, death, last clinic visit, or 9/30/2015. We defined liver fibrosis as: likely advanced fibrosis (FIB-4 > 3.25), indeterminate (FIB-4 range 1.45-3.25), unlikely advanced fibrosis (FIB-4 < 1.45). Primary outcomes were HFrEF and HFpEF (defined using ICD-9 diagnoses for HF, and EF extracted from electronic medical records using natural language processing). Cox proportional hazards models were adjusted for potential confounders and used to estimate hazard ratios (HR).
RESULTS: Among 108,708 predominantly male (96%) participants mean age was 49 years. Likely advanced fibrosis was present in 4% at baseline and was associated with an increased risk of HFpEF [HR (95% confidence interval)] [1.70 (1.3-2.3)]; and non-significantly with HFrEF [1.20 (0.9-1.7)]. These associations were not modified by HIV or hepatitis C status.
CONCLUSION: Likely advanced fibrosis was independently associated with incident HFpEF but not HFrEF. This suggests that risk factors and/or mechanisms for liver fibrosis may have greater overlap with those for HFpEF than HFrEF.","FIB-4 stage of liver fibrosis is associated with incident heart failure with preserved, but not reduced, ejection fraction among people with and without HIV or hepatitis C BACKGROUND: Liver fibrosis, is independently associated with incident heart failure (HF). Investigating the association between liver fibrosis and type of HF, specifically HF with reduced ejection fraction (EF; HFrEF) or HF with preserved ejection fraction (HFpEF), may provide mechanistic insight into this association. We sought to determine the association between liver fibrosis score (FIB-4) and type of HF, and to assess whether HIV or hepatitis C status modified this association.
METHODS: We included patients alive on or after 4/1/2003 from the Veterans Aging Cohort Study. We followed patients without prevalent cardiovascular disease until their first HF event, death, last clinic visit, or 9/30/2015. We defined liver fibrosis as: likely advanced fibrosis (FIB-4 > 3.25), indeterminate (FIB-4 range 1.45-3.25), unlikely advanced fibrosis (FIB-4 < 1.45). Primary outcomes were HFrEF and HFpEF (defined using ICD-9 diagnoses for HF, and EF extracted from electronic medical records using natural language processing). Cox proportional hazards models were adjusted for potential confounders and used to estimate hazard ratios (HR).
RESULTS: Among 108,708 predominantly male (96%) participants mean age was 49 years. Likely advanced fibrosis was present in 4% at baseline and was associated with an increased risk of HFpEF [HR (95% confidence interval)] [1.70 (1.3-2.3)]; and non-significantly with HFrEF [1.20 (0.9-1.7)]. These associations were not modified by HIV or hepatitis C status.
CONCLUSION: Likely advanced fibrosis was independently associated with incident HFpEF but not HFrEF. This suggests that risk factors and/or mechanisms for liver fibrosis may have greater overlap with those for HFpEF than HFrEF.",0,0
33737920,"Applications of Machine Learning in Human Microbiome Studies: A Review on Feature Selection, Biomarker Identification, Disease Prediction and Treatment","Marcos-Zambrano LJ, Karaduzovic-Hadziabdic K, Loncar Turukalo T, Przymus P, Trajkovik V, Aasmets O, Berland M, Gruca A, Hasic J, Hron K, Klammsteiner T, Kolev M, Lahti L, Lopes MB, Moreno V, Naskinova I, Org E, Paciência I, Papoutsoglou G, Shigdel R, Stres B, Vilne B, Yousef M, Zdravevski E, Tsamardinos I, Carrillo de Santa Pau E, Claesson MJ, Moreno-Indias I, Truu J.",Front Microbiol. 2021 Feb 19;12:634511. doi: 10.3389/fmicb.2021.634511. eCollection 2021.,Marcos-Zambrano LJ,Front Microbiol,2021,19-03-2021,PMC7962872,,10.3389/fmicb.2021.634511,"The number of microbiome-related studies has notably increased the availability of data on human microbiome composition and function. These studies provide the essential material to deeply explore host-microbiome associations and their relation to the development and progression of various complex diseases. Improved data-analytical tools are needed to exploit all information from these biological datasets, taking into account the peculiarities of microbiome data, i.e., compositional, heterogeneous and sparse nature of these datasets. The possibility of predicting host-phenotypes based on taxonomy-informed feature selection to establish an association between microbiome and predict disease states is beneficial for personalized medicine. In this regard, machine learning (ML) provides new insights into the development of models that can be used to predict outputs, such as classification and prediction in microbiology, infer host phenotypes to predict diseases and use microbial communities to stratify patients by their characterization of state-specific microbial signatures. Here we review the state-of-the-art ML methods and respective software applied in human microbiome studies, performed as part of the COST Action ML4Microbiome activities. This scoping review focuses on the application of ML in microbiome studies related to association and clinical use for diagnostics, prognostics, and therapeutics. Although the data presented here is more related to the bacterial community, many algorithms could be applied in general, regardless of the feature type. This literature and software review covering this broad topic is aligned with the scoping review methodology. The manual identification of data sources has been complemented with: (1) automated publication search through digital libraries of the three major publishers using natural language processing (NLP) Toolkit, and (2) an automated identification of relevant software repositories on GitHub and ranking of the related research papers relying on learning to rank approach.","Applications of Machine Learning in Human Microbiome Studies: A Review on Feature Selection, Biomarker Identification, Disease Prediction and Treatment The number of microbiome-related studies has notably increased the availability of data on human microbiome composition and function. These studies provide the essential material to deeply explore host-microbiome associations and their relation to the development and progression of various complex diseases. Improved data-analytical tools are needed to exploit all information from these biological datasets, taking into account the peculiarities of microbiome data, i.e., compositional, heterogeneous and sparse nature of these datasets. The possibility of predicting host-phenotypes based on taxonomy-informed feature selection to establish an association between microbiome and predict disease states is beneficial for personalized medicine. In this regard, machine learning (ML) provides new insights into the development of models that can be used to predict outputs, such as classification and prediction in microbiology, infer host phenotypes to predict diseases and use microbial communities to stratify patients by their characterization of state-specific microbial signatures. Here we review the state-of-the-art ML methods and respective software applied in human microbiome studies, performed as part of the COST Action ML4Microbiome activities. This scoping review focuses on the application of ML in microbiome studies related to association and clinical use for diagnostics, prognostics, and therapeutics. Although the data presented here is more related to the bacterial community, many algorithms could be applied in general, regardless of the feature type. This literature and software review covering this broad topic is aligned with the scoping review methodology. The manual identification of data sources has been complemented with: (1) automated publication search through digital libraries of the three major publishers using natural language processing (NLP) Toolkit, and (2) an automated identification of relevant software repositories on GitHub and ranking of the related research papers relying on learning to rank approach.",1,0
34127492,Ascertaining Framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre Atherosclerosis Risk in Communities (ARIC) validation study,"Moore CR, Jain S, Haas S, Yadav H, Whitsel E, Rosamand W, Heiss G, Kucharska-Newton AM.",BMJ Open. 2021 Jun 14;11(6):e047356. doi: 10.1136/bmjopen-2020-047356.,Moore CR,BMJ Open,2021,15-06-2021,PMC8204176,,10.1136/bmjopen-2020-047356,"OBJECTIVES: Using free-text clinical notes and reports from hospitalised patients, determine the performance of natural language processing (NLP) ascertainment of Framingham heart failure (HF) criteria and phenotype.
STUDY DESIGN: A retrospective observational study design of patients hospitalised in 2015 from four hospitals participating in the Atherosclerosis Risk in Communities (ARIC) study was used to determine NLP performance in the ascertainment of Framingham HF criteria and phenotype.
SETTING: Four ARIC study hospitals, each representing an ARIC study region in the USA.
PARTICIPANTS: A stratified random sample of hospitalisations identified using a broad range of International Classification of Disease, ninth revision, diagnostic codes indicative of an HF event and occurring during 2015 was drawn for this study. A randomly selected set of 394 hospitalisations was used as the derivation dataset and 406 hospitalisations was used as the validation dataset.
INTERVENTION: Use of NLP on free-text clinical notes and reports to ascertain Framingham HF criteria and phenotype.
PRIMARY AND SECONDARY OUTCOME MEASURES: NLP performance as measured by sensitivity, specificity, positive-predictive value (PPV) and agreement in ascertainment of Framingham HF criteria and phenotype. Manual medical record review by trained ARIC abstractors was used as the reference standard.
RESULTS: Overall, performance of NLP ascertainment of Framingham HF phenotype in the validation dataset was good, with 78.8%, 81.7%, 84.4% and 80.0% for sensitivity, specificity, PPV and agreement, respectively.
CONCLUSIONS: By decreasing the need for manual chart review, our results on the use of NLP to ascertain Framingham HF phenotype from free-text electronic health record data suggest that validated NLP technology holds the potential for significantly improving the feasibility and efficiency of conducting large-scale epidemiologic surveillance of HF prevalence and incidence.","Ascertaining Framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre Atherosclerosis Risk in Communities (ARIC) validation study OBJECTIVES: Using free-text clinical notes and reports from hospitalised patients, determine the performance of natural language processing (NLP) ascertainment of Framingham heart failure (HF) criteria and phenotype.
STUDY DESIGN: A retrospective observational study design of patients hospitalised in 2015 from four hospitals participating in the Atherosclerosis Risk in Communities (ARIC) study was used to determine NLP performance in the ascertainment of Framingham HF criteria and phenotype.
SETTING: Four ARIC study hospitals, each representing an ARIC study region in the USA.
PARTICIPANTS: A stratified random sample of hospitalisations identified using a broad range of International Classification of Disease, ninth revision, diagnostic codes indicative of an HF event and occurring during 2015 was drawn for this study. A randomly selected set of 394 hospitalisations was used as the derivation dataset and 406 hospitalisations was used as the validation dataset.
INTERVENTION: Use of NLP on free-text clinical notes and reports to ascertain Framingham HF criteria and phenotype.
PRIMARY AND SECONDARY OUTCOME MEASURES: NLP performance as measured by sensitivity, specificity, positive-predictive value (PPV) and agreement in ascertainment of Framingham HF criteria and phenotype. Manual medical record review by trained ARIC abstractors was used as the reference standard.
RESULTS: Overall, performance of NLP ascertainment of Framingham HF phenotype in the validation dataset was good, with 78.8%, 81.7%, 84.4% and 80.0% for sensitivity, specificity, PPV and agreement, respectively.
CONCLUSIONS: By decreasing the need for manual chart review, our results on the use of NLP to ascertain Framingham HF phenotype from free-text electronic health record data suggest that validated NLP technology holds the potential for significantly improving the feasibility and efficiency of conducting large-scale epidemiologic surveillance of HF prevalence and incidence.",1,0
35248103,Concerns among people who use opioids during the COVID-19 pandemic: a natural language processing analysis of social media posts,"Sarker A, Nataraj N, Siu W, Li S, Jones CM, Sumner SA.",Subst Abuse Treat Prev Policy. 2022 Mar 5;17(1):16. doi: 10.1186/s13011-022-00442-w.,Sarker A,Subst Abuse Treat Prev Policy,2022,06-03-2022,PMC8897722,,10.1186/s13011-022-00442-w,"BACKGROUND: Timely data from official sources regarding the impact of the COVID-19 pandemic on people who use prescription and illegal opioids is lacking. We conducted a large-scale, natural language processing (NLP) analysis of conversations on opioid-related drug forums to better understand concerns among people who use opioids.
METHODS: In this retrospective observational study, we analyzed posts from 14 opioid-related forums on the social network Reddit. We applied NLP to identify frequently mentioned substances and phrases, and grouped the phrases manually based on their contents into three broad key themes: (i) prescription and/or illegal opioid use; (ii) substance use disorder treatment access and care; and (iii) withdrawal. Phrases that were unmappable to any particular theme were discarded. We computed the frequencies of substance and theme mentions, and quantified their volumes over time. We compared changes in post volumes by key themes and substances between pre-COVID-19 (1/1/2019-2/29/2020) and COVID-19 (3/1/2020-11/30/2020) periods.
RESULTS: Seventy-seven thousand six hundred fifty-two and 119,168 posts were collected for the pre-COVID-19 and COVID-19 periods, respectively. By theme, posts about treatment and access to care increased by 300%, from 0.631 to 2.526 per 1000 posts between the pre-COVID-19 and COVID-19 periods. Conversations about withdrawal increased by 812% between the same periods (0.026 to 0.235 per 1,000 posts). Posts about drug use did not increase (0.219 to 0.218 per 1,000 posts). By substance, among medications for opioid use disorder, methadone had the largest increase in conversations (20.751 to 56.313 per 1,000 posts; 171.4% increase). Among other medications, posts about diphenhydramine exhibited the largest increase (0.341 to 0.927 per 1,000 posts; 171.8% increase).
CONCLUSIONS: Conversations on opioid-related forums among people who use opioids revealed increased concerns about treatment and access to care along with withdrawal following the emergence of COVID-19. Greater attention to social media data may help inform timely responses to the needs of people who use opioids during COVID-19.","Concerns among people who use opioids during the COVID-19 pandemic: a natural language processing analysis of social media posts BACKGROUND: Timely data from official sources regarding the impact of the COVID-19 pandemic on people who use prescription and illegal opioids is lacking. We conducted a large-scale, natural language processing (NLP) analysis of conversations on opioid-related drug forums to better understand concerns among people who use opioids.
METHODS: In this retrospective observational study, we analyzed posts from 14 opioid-related forums on the social network Reddit. We applied NLP to identify frequently mentioned substances and phrases, and grouped the phrases manually based on their contents into three broad key themes: (i) prescription and/or illegal opioid use; (ii) substance use disorder treatment access and care; and (iii) withdrawal. Phrases that were unmappable to any particular theme were discarded. We computed the frequencies of substance and theme mentions, and quantified their volumes over time. We compared changes in post volumes by key themes and substances between pre-COVID-19 (1/1/2019-2/29/2020) and COVID-19 (3/1/2020-11/30/2020) periods.
RESULTS: Seventy-seven thousand six hundred fifty-two and 119,168 posts were collected for the pre-COVID-19 and COVID-19 periods, respectively. By theme, posts about treatment and access to care increased by 300%, from 0.631 to 2.526 per 1000 posts between the pre-COVID-19 and COVID-19 periods. Conversations about withdrawal increased by 812% between the same periods (0.026 to 0.235 per 1,000 posts). Posts about drug use did not increase (0.219 to 0.218 per 1,000 posts). By substance, among medications for opioid use disorder, methadone had the largest increase in conversations (20.751 to 56.313 per 1,000 posts; 171.4% increase). Among other medications, posts about diphenhydramine exhibited the largest increase (0.341 to 0.927 per 1,000 posts; 171.8% increase).
CONCLUSIONS: Conversations on opioid-related forums among people who use opioids revealed increased concerns about treatment and access to care along with withdrawal following the emergence of COVID-19. Greater attention to social media data may help inform timely responses to the needs of people who use opioids during COVID-19.",1,0
33835932,"Using a Secure, Continually Updating, Web Source Processing Pipeline to Support the Real-Time Data Synthesis and Analysis of Scientific Literature: Development and Validation Study","Vaghela U, Rabinowicz S, Bratsos P, Martin G, Fritzilas E, Markar S, Purkayastha S, Stringer K, Singh H, Llewellyn C, Dutta D, Clarke JM, Howard M; PanSurg REDASA Curators; Serban O, Kinross J.",J Med Internet Res. 2021 May 6;23(5):e25714. doi: 10.2196/25714.,Vaghela U,J Med Internet Res,2021,09-04-2021,PMC8104004,,10.2196/25714,"BACKGROUND: The scale and quality of the global scientific response to the COVID-19 pandemic have unquestionably saved lives. However, the COVID-19 pandemic has also triggered an unprecedented ""infodemic""; the velocity and volume of data production have overwhelmed many key stakeholders such as clinicians and policy makers, as they have been unable to process structured and unstructured data for evidence-based decision making. Solutions that aim to alleviate this data synthesis-related challenge are unable to capture heterogeneous web data in real time for the production of concomitant answers and are not based on the high-quality information in responses to a free-text query.
OBJECTIVE: The main objective of this project is to build a generic, real-time, continuously updating curation platform that can support the data synthesis and analysis of a scientific literature framework. Our secondary objective is to validate this platform and the curation methodology for COVID-19-related medical literature by expanding the COVID-19 Open Research Dataset via the addition of new, unstructured data.
METHODS: To create an infrastructure that addresses our objectives, the PanSurg Collaborative at Imperial College London has developed a unique data pipeline based on a web crawler extraction methodology. This data pipeline uses a novel curation methodology that adopts a human-in-the-loop approach for the characterization of quality, relevance, and key evidence across a range of scientific literature sources.
RESULTS: REDASA (Realtime Data Synthesis and Analysis) is now one of the world's largest and most up-to-date sources of COVID-19-related evidence; it consists of 104,000 documents. By capturing curators' critical appraisal methodologies through the discrete labeling and rating of information, REDASA rapidly developed a foundational, pooled, data science data set of over 1400 articles in under 2 weeks. These articles provide COVID-19-related information and represent around 10% of all papers about COVID-19.
CONCLUSIONS: This data set can act as ground truth for the future implementation of a live, automated systematic review. The three benefits of REDASA's design are as follows: (1) it adopts a user-friendly, human-in-the-loop methodology by embedding an efficient, user-friendly curation platform into a natural language processing search engine; (2) it provides a curated data set in the JavaScript Object Notation format for experienced academic reviewers' critical appraisal choices and decision-making methodologies; and (3) due to the wide scope and depth of its web crawling method, REDASA has already captured one of the world's largest COVID-19-related data corpora for searches and curation.","Using a Secure, Continually Updating, Web Source Processing Pipeline to Support the Real-Time Data Synthesis and Analysis of Scientific Literature: Development and Validation Study BACKGROUND: The scale and quality of the global scientific response to the COVID-19 pandemic have unquestionably saved lives. However, the COVID-19 pandemic has also triggered an unprecedented ""infodemic""; the velocity and volume of data production have overwhelmed many key stakeholders such as clinicians and policy makers, as they have been unable to process structured and unstructured data for evidence-based decision making. Solutions that aim to alleviate this data synthesis-related challenge are unable to capture heterogeneous web data in real time for the production of concomitant answers and are not based on the high-quality information in responses to a free-text query.
OBJECTIVE: The main objective of this project is to build a generic, real-time, continuously updating curation platform that can support the data synthesis and analysis of a scientific literature framework. Our secondary objective is to validate this platform and the curation methodology for COVID-19-related medical literature by expanding the COVID-19 Open Research Dataset via the addition of new, unstructured data.
METHODS: To create an infrastructure that addresses our objectives, the PanSurg Collaborative at Imperial College London has developed a unique data pipeline based on a web crawler extraction methodology. This data pipeline uses a novel curation methodology that adopts a human-in-the-loop approach for the characterization of quality, relevance, and key evidence across a range of scientific literature sources.
RESULTS: REDASA (Realtime Data Synthesis and Analysis) is now one of the world's largest and most up-to-date sources of COVID-19-related evidence; it consists of 104,000 documents. By capturing curators' critical appraisal methodologies through the discrete labeling and rating of information, REDASA rapidly developed a foundational, pooled, data science data set of over 1400 articles in under 2 weeks. These articles provide COVID-19-related information and represent around 10% of all papers about COVID-19.
CONCLUSIONS: This data set can act as ground truth for the future implementation of a live, automated systematic review. The three benefits of REDASA's design are as follows: (1) it adopts a user-friendly, human-in-the-loop methodology by embedding an efficient, user-friendly curation platform into a natural language processing search engine; (2) it provides a curated data set in the JavaScript Object Notation format for experienced academic reviewers' critical appraisal choices and decision-making methodologies; and (3) due to the wide scope and depth of its web crawling method, REDASA has already captured one of the world's largest COVID-19-related data corpora for searches and curation.",1,0
26195183,A Robust e-Epidemiology Tool in Phenotyping Heart Failure with Differentiation for Preserved and Reduced Ejection Fraction: the Electronic Medical Records and Genomics (eMERGE) Network,"Bielinski SJ, Pathak J, Carrell DS, Takahashi PY, Olson JE, Larson NB, Liu H, Sohn S, Wells QS, Denny JC, Rasmussen-Torvik LJ, Pacheco JA, Jackson KL, Lesnick TG, Gullerud RE, Decker PA, Pereira NL, Ryu E, Dart RA, Peissig P, Linneman JG, Jarvik GP, Larson EB, Bock JA, Tromp GC, de Andrade M, Roger VL.",J Cardiovasc Transl Res. 2015 Nov;8(8):475-83. doi: 10.1007/s12265-015-9644-2. Epub 2015 Jul 21.,Bielinski SJ,J Cardiovasc Transl Res,2015,22-07-2015,PMC4651838,NIHMS709879,10.1007/s12265-015-9644-2,"Identifying populations of heart failure (HF) patients is paramount to research efforts aimed at developing strategies to effectively reduce the burden of this disease. The use of electronic medical record (EMR) data for this purpose is challenging given the syndromic nature of HF and the need to distinguish HF with preserved or reduced ejection fraction. Using a gold standard cohort of manually abstracted cases, an EMR-driven phenotype algorithm based on structured and unstructured data was developed to identify all the cases. The resulting algorithm was executed in two cohorts from the Electronic Medical Records and Genomics (eMERGE) Network with a positive predictive value of >95 %. The algorithm was expanded to include three hierarchical definitions of HF (i.e., definite, probable, possible) based on the degree of confidence of the classification to capture HF cases in a whole population whereby increasing the algorithm utility for use in e-Epidemiologic research.","A Robust e-Epidemiology Tool in Phenotyping Heart Failure with Differentiation for Preserved and Reduced Ejection Fraction: the Electronic Medical Records and Genomics (eMERGE) Network Identifying populations of heart failure (HF) patients is paramount to research efforts aimed at developing strategies to effectively reduce the burden of this disease. The use of electronic medical record (EMR) data for this purpose is challenging given the syndromic nature of HF and the need to distinguish HF with preserved or reduced ejection fraction. Using a gold standard cohort of manually abstracted cases, an EMR-driven phenotype algorithm based on structured and unstructured data was developed to identify all the cases. The resulting algorithm was executed in two cohorts from the Electronic Medical Records and Genomics (eMERGE) Network with a positive predictive value of >95 %. The algorithm was expanded to include three hierarchical definitions of HF (i.e., definite, probable, possible) based on the degree of confidence of the classification to capture HF cases in a whole population whereby increasing the algorithm utility for use in e-Epidemiologic research.",0,0
37577535,Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,"Weissenbacher D, O'Connor K, Klein A, Golder S, Flores I, Elyaderani A, Scotch M, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2023 Aug 4:2023.07.29.23293370. doi: 10.1101/2023.07.29.23293370.,Weissenbacher D,medRxiv,2023,14-08-2023,PMC10418574,,10.1101/2023.07.29.23293370,"There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GISAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.","Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GISAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.",1,1
39117794,Global Research on Pandemics or Epidemics and Mental Health: A Natural Language Processing Study,"Ye X, Wang X, Lin H.",J Epidemiol Glob Health. 2024 Sep;14(3):1268-1280. doi: 10.1007/s44197-024-00284-8. Epub 2024 Aug 8.,Ye X,J Epidemiol Glob Health,2024,08-08-2024,PMC11442711,,10.1007/s44197-024-00284-8,"BACKGROUND: The global research on pandemics or epidemics and mental health has been growing exponentially recently, which cannot be integrated through traditional systematic review. Our study aims to systematically synthesize the evidence using natural language processing (NLP) techniques.
METHODS: Multiple databases were searched using titles, abstracts, and keywords. We systematically identified relevant literature published prior to Dec 31, 2023, using NLP techniques such as text classification, topic modelling and geoparsing methods. Relevant articles were categorized by content, date, and geographic location, outputting evidence heat maps, geographical maps, and narrative synthesis of trends in related publications.
RESULTS: Our NLP analysis identified 77,915 studies in the area of pandemics or epidemics and mental health published before Dec 31, 2023. The Covid pandemic was the most common, followed by SARS and HIV/AIDS; Anxiety and stress were the most frequently studied mental health outcomes; Social support and healthcare were the most common way of coping. Geographically, the evidence base was dominated by studies from high-income countries, with scant evidence from low-income counties. Co-occurrence of pandemics or epidemics and fear, depression, stress was common. Anxiety was one of the three most common topics in all continents except North America.
CONCLUSION: Our findings suggest the importance and feasibility of using NLP to comprehensively map pandemics or epidemics and mental health in the age of big literature. The review identifies clear themes for future clinical and public health research, and is critical for designing evidence-based approaches to reduce the negative mental health impacts of pandemics or epidemics.","Global Research on Pandemics or Epidemics and Mental Health: A Natural Language Processing Study BACKGROUND: The global research on pandemics or epidemics and mental health has been growing exponentially recently, which cannot be integrated through traditional systematic review. Our study aims to systematically synthesize the evidence using natural language processing (NLP) techniques.
METHODS: Multiple databases were searched using titles, abstracts, and keywords. We systematically identified relevant literature published prior to Dec 31, 2023, using NLP techniques such as text classification, topic modelling and geoparsing methods. Relevant articles were categorized by content, date, and geographic location, outputting evidence heat maps, geographical maps, and narrative synthesis of trends in related publications.
RESULTS: Our NLP analysis identified 77,915 studies in the area of pandemics or epidemics and mental health published before Dec 31, 2023. The Covid pandemic was the most common, followed by SARS and HIV/AIDS; Anxiety and stress were the most frequently studied mental health outcomes; Social support and healthcare were the most common way of coping. Geographically, the evidence base was dominated by studies from high-income countries, with scant evidence from low-income counties. Co-occurrence of pandemics or epidemics and fear, depression, stress was common. Anxiety was one of the three most common topics in all continents except North America.
CONCLUSION: Our findings suggest the importance and feasibility of using NLP to comprehensively map pandemics or epidemics and mental health in the age of big literature. The review identifies clear themes for future clinical and public health research, and is critical for designing evidence-based approaches to reduce the negative mental health impacts of pandemics or epidemics.",1,0
35608886,Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method,"Zheng C, Duffy J, Liu IA, Sy LS, Navarro RA, Kim SS, Ryan DS, Chen W, Qian L, Mercado C, Jacobsen SJ.",JMIR Public Health Surveill. 2022 May 24;8(5):e30426. doi: 10.2196/30426.,Zheng C,JMIR Public Health Surveill,2022,24-05-2022,PMC9175103,,10.2196/30426,"BACKGROUND: Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce.
OBJECTIVE: The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes.
METHODS: We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases.
RESULTS: In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively.
CONCLUSIONS: The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation.","Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method BACKGROUND: Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce.
OBJECTIVE: The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes.
METHODS: We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases.
RESULTS: In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively.
CONCLUSIONS: The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation.",1,0
37457889,Mapping Research Trends of Medications for Multidrug-Resistant Pulmonary Tuberculosis Based on the Co-Occurrence of Specific Semantic Types in the MeSH Tree: A Bibliometric and Visualization-Based Analysis of PubMed Literature (1966-2020),"Xu S, Fu Y, Xu D, Han S, Wu M, Ju X, Liu M, Huang DS, Guan P.",Drug Des Devel Ther. 2023 Jul 10;17:2035-2049. doi: 10.2147/DDDT.S409604. eCollection 2023.,Xu S,Drug Des Devel Ther,2023,17-07-2023,PMC10348322,,10.2147/DDDT.S409604,"BACKGROUND: Before the COVID-19 pandemic, tuberculosis is the leading cause of death from a single infectious agent worldwide for the past 30 years. Progress in the control of tuberculosis has been undermined by the emergence of multidrug-resistant tuberculosis. The aim of the study is to reveal the trends of research on medications for multidrug-resistant pulmonary tuberculosis (MDR-PTB) through a novel method of bibliometrics that co-occurs specific semantic Medical Subject Headings (MeSH).
METHODS: PubMed was used to identify the original publications related to medications for MDR-PTB. An R package for text mining of PubMed, pubMR, was adopted to extract data and construct the co-occurrence matrix-specific semantic types. Biclustering analysis of high-frequency MeSH term co-occurrence matrix was performed by gCLUTO. Scientific knowledge maps were constructed by VOSviewer to create overlay visualization and density visualization. Burst detection was performed by CiteSpace to identify the future research hotspots.
RESULTS: Two hundred and eight substances (chemical, drug, protein) and 147 diseases related to MDR-PTB were extracted to form a specific semantic co-occurrence matrix. MeSH terms with frequency greater than or equal to six were selected to construct high-frequency co-occurrence matrix (42 × 20) of specific semantic types contains 42 substances and 20 diseases. Biclustering analysis divided the medications for MDR-PTB into five clusters and reflected the characteristics of drug composition. The overlay map indicated the average age gradients of 42 high-frequency drugs. Fifteen top keywords and 37 top terms with the strongest citation bursts were detected.
CONCLUSION: This study evaluated the literatures related to MDR-PTB drug therapy, providing a co-occurrence matrix model based on the specific semantic types and a new attempt for text knowledge mining. Compared with the macro knowledge structure or hot spot analysis, this method may have a wider scope of application and a more in-depth degree of analysis.","Mapping Research Trends of Medications for Multidrug-Resistant Pulmonary Tuberculosis Based on the Co-Occurrence of Specific Semantic Types in the MeSH Tree: A Bibliometric and Visualization-Based Analysis of PubMed Literature (1966-2020) BACKGROUND: Before the COVID-19 pandemic, tuberculosis is the leading cause of death from a single infectious agent worldwide for the past 30 years. Progress in the control of tuberculosis has been undermined by the emergence of multidrug-resistant tuberculosis. The aim of the study is to reveal the trends of research on medications for multidrug-resistant pulmonary tuberculosis (MDR-PTB) through a novel method of bibliometrics that co-occurs specific semantic Medical Subject Headings (MeSH).
METHODS: PubMed was used to identify the original publications related to medications for MDR-PTB. An R package for text mining of PubMed, pubMR, was adopted to extract data and construct the co-occurrence matrix-specific semantic types. Biclustering analysis of high-frequency MeSH term co-occurrence matrix was performed by gCLUTO. Scientific knowledge maps were constructed by VOSviewer to create overlay visualization and density visualization. Burst detection was performed by CiteSpace to identify the future research hotspots.
RESULTS: Two hundred and eight substances (chemical, drug, protein) and 147 diseases related to MDR-PTB were extracted to form a specific semantic co-occurrence matrix. MeSH terms with frequency greater than or equal to six were selected to construct high-frequency co-occurrence matrix (42 × 20) of specific semantic types contains 42 substances and 20 diseases. Biclustering analysis divided the medications for MDR-PTB into five clusters and reflected the characteristics of drug composition. The overlay map indicated the average age gradients of 42 high-frequency drugs. Fifteen top keywords and 37 top terms with the strongest citation bursts were detected.
CONCLUSION: This study evaluated the literatures related to MDR-PTB drug therapy, providing a co-occurrence matrix model based on the specific semantic types and a new attempt for text knowledge mining. Compared with the macro knowledge structure or hot spot analysis, this method may have a wider scope of application and a more in-depth degree of analysis.",1,1
36827297,Surveillance of communicable diseases using social media: A systematic review,"Pilipiec P, Samsten I, Bota A.",PLoS One. 2023 Feb 24;18(2):e0282101. doi: 10.1371/journal.pone.0282101. eCollection 2023.,Pilipiec P,PLoS One,2023,24-02-2023,PMC9956027,,10.1371/journal.pone.0282101,"BACKGROUND: Communicable diseases pose a severe threat to public health and economic growth. The traditional methods that are used for public health surveillance, however, involve many drawbacks, such as being labor intensive to operate and resulting in a lag between data collection and reporting. To effectively address the limitations of these traditional methods and to mitigate the adverse effects of these diseases, a proactive and real-time public health surveillance system is needed. Previous studies have indicated the usefulness of performing text mining on social media.
OBJECTIVE: To conduct a systematic review of the literature that used textual content published to social media for the purpose of the surveillance and prediction of communicable diseases.
METHODOLOGY: Broad search queries were formulated and performed in four databases. Both journal articles and conference materials were included. The quality of the studies, operationalized as reliability and validity, was assessed. This qualitative systematic review was guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.
RESULTS: Twenty-three publications were included in this systematic review. All studies reported positive results for using textual social media content to surveille communicable diseases. Most studies used Twitter as a source for these data. Influenza was studied most frequently, while other communicable diseases received far less attention. Journal articles had a higher quality (reliability and validity) than conference papers. However, studies often failed to provide important information about procedures and implementation.
CONCLUSION: Text mining of health-related content published on social media can serve as a novel and powerful tool for the automated, real-time, and remote monitoring of public health and for the surveillance and prediction of communicable diseases in particular. This tool can address limitations related to traditional surveillance methods, and it has the potential to supplement traditional methods for public health surveillance.","Surveillance of communicable diseases using social media: A systematic review BACKGROUND: Communicable diseases pose a severe threat to public health and economic growth. The traditional methods that are used for public health surveillance, however, involve many drawbacks, such as being labor intensive to operate and resulting in a lag between data collection and reporting. To effectively address the limitations of these traditional methods and to mitigate the adverse effects of these diseases, a proactive and real-time public health surveillance system is needed. Previous studies have indicated the usefulness of performing text mining on social media.
OBJECTIVE: To conduct a systematic review of the literature that used textual content published to social media for the purpose of the surveillance and prediction of communicable diseases.
METHODOLOGY: Broad search queries were formulated and performed in four databases. Both journal articles and conference materials were included. The quality of the studies, operationalized as reliability and validity, was assessed. This qualitative systematic review was guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.
RESULTS: Twenty-three publications were included in this systematic review. All studies reported positive results for using textual social media content to surveille communicable diseases. Most studies used Twitter as a source for these data. Influenza was studied most frequently, while other communicable diseases received far less attention. Journal articles had a higher quality (reliability and validity) than conference papers. However, studies often failed to provide important information about procedures and implementation.
CONCLUSION: Text mining of health-related content published on social media can serve as a novel and powerful tool for the automated, real-time, and remote monitoring of public health and for the surveillance and prediction of communicable diseases in particular. This tool can address limitations related to traditional surveillance methods, and it has the potential to supplement traditional methods for public health surveillance.",1,1
34293316,COVID-19 and Risk of VTE in Ethnically Diverse Populations,"Go AS, Reynolds K, Tabada GH, Prasad PA, Sung SH, Garcia E, Portugal C, Fan D, Pai AP, Fang MC.",Chest. 2021 Oct;160(4):1459-1470. doi: 10.1016/j.chest.2021.07.025. Epub 2021 Jul 19.,Go AS,Chest,2021,22-07-2021,PMC8288227,,10.1016/j.chest.2021.07.025,"BACKGROUND: Limited existing data suggest that the novel COVID-19 may increase risk of VTE, but information from large, ethnically diverse populations with appropriate control participants is lacking.
RESEARCH QUESTION: Does the rate of VTE among adults hospitalized with COVID-19 differ from matched hospitalized control participants without COVID-19?
STUDY DESIGN AND METHODS: We conducted a retrospective study among hospitalized adults with laboratory-confirmed COVID-19 and hospitalized adults without evidence of COVID-19 matched for age, sex, race or ethnicity, acute illness severity, and month of hospitalization between January 2020 and August 2020 from two integrated health care delivery systems with 36 hospitals. Outcomes included VTE (DVT or pulmonary embolism ascertained using diagnosis codes combined with validated natural language processing algorithms applied to electronic health records) and death resulting from any cause at 30 days. Fine and Gray hazards regression was performed to evaluate the association of COVID-19 with VTE after accounting for competing risk of death and residual differences between groups, as well as to identify predictors of VTE in patients with COVID-19.
RESULTS: We identified 6,319 adults with COVID-19 and 6,319 matched adults without COVID-19, with mean ± SD age of 60.0 ± 17.2 years, 46% women, 53.1% Hispanic, 14.6% Asian/Pacific Islander, and 10.3% Black. During 30-day follow-up, 313 validated cases of VTE (160 COVID-19, 153 control participants) and 1,172 deaths (817 in patients with COVID-19, 355 in control participants) occurred. Adults with COVID-19 showed a more than threefold adjusted risk of VTE (adjusted hazard ratio, 3.48; 95% CI, 2.03-5.98) compared with matched control participants. Predictors of VTE in patients with COVID-19 included age ≥ 55 years, Black race, prior VTE, diagnosed sepsis, prior moderate or severe liver disease, BMI ≥ 40 kg/m2, and platelet count &gt; 217 k/μL.
INTERPRETATION: Among ethnically diverse hospitalized adults, COVID-19 infection increased the risk of VTE, and selected patient characteristics were associated with higher thromboembolic risk in the setting of COVID-19.","COVID-19 and Risk of VTE in Ethnically Diverse Populations BACKGROUND: Limited existing data suggest that the novel COVID-19 may increase risk of VTE, but information from large, ethnically diverse populations with appropriate control participants is lacking.
RESEARCH QUESTION: Does the rate of VTE among adults hospitalized with COVID-19 differ from matched hospitalized control participants without COVID-19?
STUDY DESIGN AND METHODS: We conducted a retrospective study among hospitalized adults with laboratory-confirmed COVID-19 and hospitalized adults without evidence of COVID-19 matched for age, sex, race or ethnicity, acute illness severity, and month of hospitalization between January 2020 and August 2020 from two integrated health care delivery systems with 36 hospitals. Outcomes included VTE (DVT or pulmonary embolism ascertained using diagnosis codes combined with validated natural language processing algorithms applied to electronic health records) and death resulting from any cause at 30 days. Fine and Gray hazards regression was performed to evaluate the association of COVID-19 with VTE after accounting for competing risk of death and residual differences between groups, as well as to identify predictors of VTE in patients with COVID-19.
RESULTS: We identified 6,319 adults with COVID-19 and 6,319 matched adults without COVID-19, with mean ± SD age of 60.0 ± 17.2 years, 46% women, 53.1% Hispanic, 14.6% Asian/Pacific Islander, and 10.3% Black. During 30-day follow-up, 313 validated cases of VTE (160 COVID-19, 153 control participants) and 1,172 deaths (817 in patients with COVID-19, 355 in control participants) occurred. Adults with COVID-19 showed a more than threefold adjusted risk of VTE (adjusted hazard ratio, 3.48; 95% CI, 2.03-5.98) compared with matched control participants. Predictors of VTE in patients with COVID-19 included age ≥ 55 years, Black race, prior VTE, diagnosed sepsis, prior moderate or severe liver disease, BMI ≥ 40 kg/m2, and platelet count &gt; 217 k/μL.
INTERPRETATION: Among ethnically diverse hospitalized adults, COVID-19 infection increased the risk of VTE, and selected patient characteristics were associated with higher thromboembolic risk in the setting of COVID-19.",0,0
35671409,COVID-19 Vaccine Fact-Checking Posts on Facebook: Observational Study,"Xue H, Gong X, Stevens H.",J Med Internet Res. 2022 Jun 21;24(6):e38423. doi: 10.2196/38423.,Xue H,J Med Internet Res,2022,07-06-2022,PMC9217154,,10.2196/38423,"BACKGROUND: Effective interventions aimed at correcting COVID-19 vaccine misinformation, known as fact-checking messages, are needed to combat the mounting antivaccine infodemic and alleviate vaccine hesitancy.
OBJECTIVE: This work investigates (1) the changes in the public's attitude toward COVID-19 vaccines over time, (2) the effectiveness of COVID-19 vaccine fact-checking information on social media engagement and attitude change, and (3) the emotional and linguistic features of the COVID-19 vaccine fact-checking information ecosystem.
METHODS: We collected a data set of 12,553 COVID-19 vaccine fact-checking Facebook posts and their associated comments (N=122,362) from January 2020 to March 2022 and conducted a series of natural language processing and statistical analyses to investigate trends in public attitude toward the vaccine in COVID-19 vaccine fact-checking posts and comments, and emotional and linguistic features of the COVID-19 fact-checking information ecosystem.
RESULTS: The percentage of fact-checking posts relative to all COVID-19 vaccine posts peaked in May 2020 and then steadily decreased as the pandemic progressed (r=-0.92, df=21, t=-10.94, 95% CI -0.97 to -0.82, P<.001). The salience of COVID-19 vaccine entities was significantly lower in comments (mean 0.03, SD 0.03, t=39.28, P<.001) than in posts (mean 0.09, SD 0.11). Third-party fact checkers have been playing a more important role in more fact-checking over time (r=0.63, df=25, t=4.06, 95% CI 0.33-0.82, P<.001). COVID-19 vaccine fact-checking posts continued to be more analytical (r=0.81, df=25, t=6.88, 95% CI 0.62-0.91, P<.001) and more confident (r=0.59, df=25, t=3.68, 95% CI 0.27-0.79, P=.001) over time. Although comments did not exhibit a significant increase in confidence over time, tentativeness in comments significantly decreased (r=-0.62, df=25, t=-3.94, 95% CI -0.81 to -0.31, P=.001). In addition, although hospitals receive less engagement than other information sources, the comments expressed more positive attitudinal valence in comments compared to other information sources (b=0.06, 95% CI 0.00-0.12, t=2.03, P=.04).
CONCLUSIONS: The percentage of fact-checking posts relative to all posts about the vaccine steadily decreased after May 2020. As the pandemic progressed, third-party fact checkers played a larger role in posting fact-checking COVID-19 vaccine posts. COVID-19 vaccine fact-checking posts continued to be more analytical and more confident over time, reflecting increased confidence in posts. Similarly, tentativeness in comments decreased; this likewise suggests that public uncertainty diminished over time. COVID-19 fact-checking vaccine posts from hospitals yielded more positive attitudes toward vaccination than other information sources. At the same time, hospitals received less engagement than other information sources. This suggests that hospitals should invest more in generating engaging public health campaigns on social media.","COVID-19 Vaccine Fact-Checking Posts on Facebook: Observational Study BACKGROUND: Effective interventions aimed at correcting COVID-19 vaccine misinformation, known as fact-checking messages, are needed to combat the mounting antivaccine infodemic and alleviate vaccine hesitancy.
OBJECTIVE: This work investigates (1) the changes in the public's attitude toward COVID-19 vaccines over time, (2) the effectiveness of COVID-19 vaccine fact-checking information on social media engagement and attitude change, and (3) the emotional and linguistic features of the COVID-19 vaccine fact-checking information ecosystem.
METHODS: We collected a data set of 12,553 COVID-19 vaccine fact-checking Facebook posts and their associated comments (N=122,362) from January 2020 to March 2022 and conducted a series of natural language processing and statistical analyses to investigate trends in public attitude toward the vaccine in COVID-19 vaccine fact-checking posts and comments, and emotional and linguistic features of the COVID-19 fact-checking information ecosystem.
RESULTS: The percentage of fact-checking posts relative to all COVID-19 vaccine posts peaked in May 2020 and then steadily decreased as the pandemic progressed (r=-0.92, df=21, t=-10.94, 95% CI -0.97 to -0.82, P<.001). The salience of COVID-19 vaccine entities was significantly lower in comments (mean 0.03, SD 0.03, t=39.28, P<.001) than in posts (mean 0.09, SD 0.11). Third-party fact checkers have been playing a more important role in more fact-checking over time (r=0.63, df=25, t=4.06, 95% CI 0.33-0.82, P<.001). COVID-19 vaccine fact-checking posts continued to be more analytical (r=0.81, df=25, t=6.88, 95% CI 0.62-0.91, P<.001) and more confident (r=0.59, df=25, t=3.68, 95% CI 0.27-0.79, P=.001) over time. Although comments did not exhibit a significant increase in confidence over time, tentativeness in comments significantly decreased (r=-0.62, df=25, t=-3.94, 95% CI -0.81 to -0.31, P=.001). In addition, although hospitals receive less engagement than other information sources, the comments expressed more positive attitudinal valence in comments compared to other information sources (b=0.06, 95% CI 0.00-0.12, t=2.03, P=.04).
CONCLUSIONS: The percentage of fact-checking posts relative to all posts about the vaccine steadily decreased after May 2020. As the pandemic progressed, third-party fact checkers played a larger role in posting fact-checking COVID-19 vaccine posts. COVID-19 vaccine fact-checking posts continued to be more analytical and more confident over time, reflecting increased confidence in posts. Similarly, tentativeness in comments decreased; this likewise suggests that public uncertainty diminished over time. COVID-19 fact-checking vaccine posts from hospitals yielded more positive attitudes toward vaccination than other information sources. At the same time, hospitals received less engagement than other information sources. This suggests that hospitals should invest more in generating engaging public health campaigns on social media.",0,1
32955571,Novel Method to Flag Cardiac Implantable Device Infections by Integrating Text Mining With Structured Data in the Veterans Health Administration's Electronic Medical Record,"Mull HJ, Stolzmann KL, Shin MH, Kalver E, Schweizer ML, Branch-Elliman W.",JAMA Netw Open. 2020 Sep 1;3(9):e2012264. doi: 10.1001/jamanetworkopen.2020.12264.,Mull HJ,JAMA Netw Open,2020,21-09-2020,PMC7506515,,10.1001/jamanetworkopen.2020.12264,"IMPORTANCE: Health care-associated infections (HAIs) are preventable, harmful, and costly; however, few resources are dedicated to infection surveillance of nonsurgical procedures, particularly cardiovascular implantable electronic device (CIED) procedures.
OBJECTIVE: To develop a method that includes text mining of electronic clinical notes to reliably and efficiently measure HAIs for CIED procedures.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter, national cohort study using electronic medical record data for patients undergoing CIED procedures in Veterans Health Administration (VA) facilities for fiscal years (FYs) 2016 and 2017, an algorithm to flag cases with a true CIED-related infection based on structured (eg, microbiology orders, vital signs) and free text diagnostic and therapeutic data (eg, procedure notes, discharge summaries, microbiology results) was developed and validated. Procedure data were divided into development and validation data sets. Criterion validity (ie, positive predictive validity [PPV], sensitivity, and specificity) was assessed via criterion-standard manual medical record review.
EXPOSURES: CIED procedure.
MAIN OUTCOMES AND MEASURES: The concordance between medical record review and the study algorithm with respect to the presence or absence of a CIED infection. CIED infection in the algorithm included 90-day mortality, congestive heart failure and nonmetastatic tumor comorbidities, CIED or surgical site infection International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Clinical Modification (ICD-10-CM) diagnosis codes, antibiotic treatment of Staphylococci, a microbiology test of a cardiac specimen, and text documentation of infection in specific clinical notes (eg, cardiology, infectious diseases, inpatient discharge summaries).
RESULTS: The algorithm sample consisted of 19 212 CIED procedures; 15 077 patients (78.5%) were White individuals, 1487 (15.5%) were African American; 18 766 (97.7%) were men. The mean (SD) age in our sample was 71.8 (10.6) years. The infection detection threshold of predicted probability was set to greater than 0.10 and the algorithm flagged 276 of 9606 (2.9%) cases in the development data set (9606 procedures); PPV in this group was 41.4% (95% CI, 31.6%-51.8%). In the validation set (9606 procedures), at predicted probability 0.10 or more the algorithm PPV was 43.5% (95% CI, 37.1%-50.2%), and overall sensitivity and specificity were 94.4% (95% CI, 88.2%-97.9%) and 48.8% (95% CI, 42.6%-55.1%), respectively.
CONCLUSIONS AND RELEVANCE: The findings of this study suggest that the method of combining structured and text data in VA electronic medical records can be used to expand infection surveillance beyond traditional boundaries to include outpatient and procedural areas.","Novel Method to Flag Cardiac Implantable Device Infections by Integrating Text Mining With Structured Data in the Veterans Health Administration's Electronic Medical Record IMPORTANCE: Health care-associated infections (HAIs) are preventable, harmful, and costly; however, few resources are dedicated to infection surveillance of nonsurgical procedures, particularly cardiovascular implantable electronic device (CIED) procedures.
OBJECTIVE: To develop a method that includes text mining of electronic clinical notes to reliably and efficiently measure HAIs for CIED procedures.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter, national cohort study using electronic medical record data for patients undergoing CIED procedures in Veterans Health Administration (VA) facilities for fiscal years (FYs) 2016 and 2017, an algorithm to flag cases with a true CIED-related infection based on structured (eg, microbiology orders, vital signs) and free text diagnostic and therapeutic data (eg, procedure notes, discharge summaries, microbiology results) was developed and validated. Procedure data were divided into development and validation data sets. Criterion validity (ie, positive predictive validity [PPV], sensitivity, and specificity) was assessed via criterion-standard manual medical record review.
EXPOSURES: CIED procedure.
MAIN OUTCOMES AND MEASURES: The concordance between medical record review and the study algorithm with respect to the presence or absence of a CIED infection. CIED infection in the algorithm included 90-day mortality, congestive heart failure and nonmetastatic tumor comorbidities, CIED or surgical site infection International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Clinical Modification (ICD-10-CM) diagnosis codes, antibiotic treatment of Staphylococci, a microbiology test of a cardiac specimen, and text documentation of infection in specific clinical notes (eg, cardiology, infectious diseases, inpatient discharge summaries).
RESULTS: The algorithm sample consisted of 19 212 CIED procedures; 15 077 patients (78.5%) were White individuals, 1487 (15.5%) were African American; 18 766 (97.7%) were men. The mean (SD) age in our sample was 71.8 (10.6) years. The infection detection threshold of predicted probability was set to greater than 0.10 and the algorithm flagged 276 of 9606 (2.9%) cases in the development data set (9606 procedures); PPV in this group was 41.4% (95% CI, 31.6%-51.8%). In the validation set (9606 procedures), at predicted probability 0.10 or more the algorithm PPV was 43.5% (95% CI, 37.1%-50.2%), and overall sensitivity and specificity were 94.4% (95% CI, 88.2%-97.9%) and 48.8% (95% CI, 42.6%-55.1%), respectively.
CONCLUSIONS AND RELEVANCE: The findings of this study suggest that the method of combining structured and text data in VA electronic medical records can be used to expand infection surveillance beyond traditional boundaries to include outpatient and procedural areas.",1,0
33684054,COVID-19 Discourse on Twitter in Four Asian Countries: Case Study of Risk Communication,"Park S, Han S, Kim J, Molaie MM, Vu HD, Singh K, Han J, Lee W, Cha M.",J Med Internet Res. 2021 Mar 16;23(3):e23272. doi: 10.2196/23272.,Park S,J Med Internet Res,2021,08-03-2021,PMC8108572,,10.2196/23272,"BACKGROUND: COVID-19, caused by SARS-CoV-2, has led to a global pandemic. The World Health Organization has also declared an infodemic (ie, a plethora of information regarding COVID-19 containing both false and accurate information circulated on the internet). Hence, it has become critical to test the veracity of information shared online and analyze the evolution of discussed topics among citizens related to the pandemic.
OBJECTIVE: This research analyzes the public discourse on COVID-19. It characterizes risk communication patterns in four Asian countries with outbreaks at varying degrees of severity: South Korea, Iran, Vietnam, and India.
METHODS: We collected tweets on COVID-19 from four Asian countries in the early phase of the disease outbreak from January to March 2020. The data set was collected by relevant keywords in each language, as suggested by locals. We present a method to automatically extract a time-topic cohesive relationship in an unsupervised fashion based on natural language processing. The extracted topics were evaluated qualitatively based on their semantic meanings.
RESULTS: This research found that each government's official phases of the epidemic were not well aligned with the degree of public attention represented by the daily tweet counts. Inspired by the issue-attention cycle theory, the presented natural language processing model can identify meaningful transition phases in the discussed topics among citizens. The analysis revealed an inverse relationship between the tweet count and topic diversity.
CONCLUSIONS: This paper compares similarities and differences of pandemic-related social media discourse in Asian countries. We observed multiple prominent peaks in the daily tweet counts across all countries, indicating multiple issue-attention cycles. Our analysis identified which topics the public concentrated on; some of these topics were related to misinformation and hate speech. These findings and the ability to quickly identify key topics can empower global efforts to fight against an infodemic during a pandemic.","COVID-19 Discourse on Twitter in Four Asian Countries: Case Study of Risk Communication BACKGROUND: COVID-19, caused by SARS-CoV-2, has led to a global pandemic. The World Health Organization has also declared an infodemic (ie, a plethora of information regarding COVID-19 containing both false and accurate information circulated on the internet). Hence, it has become critical to test the veracity of information shared online and analyze the evolution of discussed topics among citizens related to the pandemic.
OBJECTIVE: This research analyzes the public discourse on COVID-19. It characterizes risk communication patterns in four Asian countries with outbreaks at varying degrees of severity: South Korea, Iran, Vietnam, and India.
METHODS: We collected tweets on COVID-19 from four Asian countries in the early phase of the disease outbreak from January to March 2020. The data set was collected by relevant keywords in each language, as suggested by locals. We present a method to automatically extract a time-topic cohesive relationship in an unsupervised fashion based on natural language processing. The extracted topics were evaluated qualitatively based on their semantic meanings.
RESULTS: This research found that each government's official phases of the epidemic were not well aligned with the degree of public attention represented by the daily tweet counts. Inspired by the issue-attention cycle theory, the presented natural language processing model can identify meaningful transition phases in the discussed topics among citizens. The analysis revealed an inverse relationship between the tweet count and topic diversity.
CONCLUSIONS: This paper compares similarities and differences of pandemic-related social media discourse in Asian countries. We observed multiple prominent peaks in the daily tweet counts across all countries, indicating multiple issue-attention cycles. Our analysis identified which topics the public concentrated on; some of these topics were related to misinformation and hate speech. These findings and the ability to quickly identify key topics can empower global efforts to fight against an infodemic during a pandemic.",1,0
26042846,What can we learn about the Ebola outbreak from tweets?,"Odlum M, Yoon S.",Am J Infect Control. 2015 Jun;43(6):563-71. doi: 10.1016/j.ajic.2015.02.023.,Odlum M,Am J Infect Control,2015,05-06-2015,PMC4591071,NIHMS723184,10.1016/j.ajic.2015.02.023,"BACKGROUND: Twitter can address the challenges of the current Ebola outbreak surveillance. The aims of this study are to demonstrate the use of Twitter as a real-time method of Ebola outbreak surveillance to monitor information spread, capture early epidemic detection, and examine content of public knowledge and attitudes.
METHODS: We collected tweets mentioning Ebola in English during the early stage of the current Ebola outbreak from July 24-August 1, 2014. Our analysis for this observational study includes time series analysis with geologic visualization to observe information dissemination and content analysis using natural language processing to examine public knowledge and attitudes.
RESULTS: A total of 42,236 tweets (16,499 unique and 25,737 retweets) mentioning Ebola were posted and disseminated to 9,362,267,048 people, 63 times higher than the initial number. Tweets started to rise in Nigeria 3-7 days prior to the official announcement of the first probable Ebola case. The topics discussed in tweets include risk factors, prevention education, disease trends, and compassion.
CONCLUSION: Because of the analysis of a unique Twitter dataset captured in the early stage of the current Ebola outbreak, our results provide insight into the intersection of social media and public health outbreak surveillance. Findings demonstrate the usefulness of Twitter mining to inform public health education.","What can we learn about the Ebola outbreak from tweets? BACKGROUND: Twitter can address the challenges of the current Ebola outbreak surveillance. The aims of this study are to demonstrate the use of Twitter as a real-time method of Ebola outbreak surveillance to monitor information spread, capture early epidemic detection, and examine content of public knowledge and attitudes.
METHODS: We collected tweets mentioning Ebola in English during the early stage of the current Ebola outbreak from July 24-August 1, 2014. Our analysis for this observational study includes time series analysis with geologic visualization to observe information dissemination and content analysis using natural language processing to examine public knowledge and attitudes.
RESULTS: A total of 42,236 tweets (16,499 unique and 25,737 retweets) mentioning Ebola were posted and disseminated to 9,362,267,048 people, 63 times higher than the initial number. Tweets started to rise in Nigeria 3-7 days prior to the official announcement of the first probable Ebola case. The topics discussed in tweets include risk factors, prevention education, disease trends, and compassion.
CONCLUSION: Because of the analysis of a unique Twitter dataset captured in the early stage of the current Ebola outbreak, our results provide insight into the intersection of social media and public health outbreak surveillance. Findings demonstrate the usefulness of Twitter mining to inform public health education.",1,1
36566779,Post-Acute COVID-19 Respiratory Symptoms in Patients With Asthma: An Electronic Health Records-Based Study,"Wang L, Foer D, Zhang Y, Karlson EW, Bates DW, Zhou L.",J Allergy Clin Immunol Pract. 2023 Mar;11(3):825-835.e3. doi: 10.1016/j.jaip.2022.12.003. Epub 2022 Dec 22.,Wang L,J Allergy Clin Immunol Pract,2023,25-12-2022,PMC9773736,,10.1016/j.jaip.2022.12.003,"BACKGROUND: Post-viral respiratory symptoms are common among patients with asthma. Respiratory symptoms after acute COVID-19 are widely reported in the general population, but large-scale studies identifying symptom risk for patients with asthma are lacking.
OBJECTIVE: To identify and compare risk for post-acute COVID-19 respiratory symptoms in patients with and without asthma.
METHODS: This retrospective, observational cohort study included COVID-19-positive patients between March 4, 2020, and January 20, 2021, with up to 180 days of health care follow-up in a health care system in the Northeastern United States. Respiratory symptoms recorded in clinical notes from days 28 to 180 after COVID-19 diagnosis were extracted using natural language processing. Cohorts were stratified by hospitalization status during the acute COVID-19 period. Univariable and multivariable analyses were used to compare symptoms among patients with and without asthma adjusting for demographic and clinical confounders.
RESULTS: Among 31,084 eligible patients with COVID-19, 2863 (9.2%) had hospitalization during the acute COVID-19 period; 4049 (13.0%) had a history of asthma, accounting for 13.8% of hospitalized and 12.9% of nonhospitalized patients. In the post-acute COVID-19 period, patients with asthma had significantly higher risk of shortness of breath, cough, bronchospasm, and wheezing than patients without an asthma history. Incident respiratory symptoms of bronchospasm and wheezing were also higher in patients with asthma. Patients with asthma who had not been hospitalized during acute COVID-19 had additionally higher risk of cough, abnormal breathing, sputum changes, and a wider range of incident respiratory symptoms.
CONCLUSION: Patients with asthma may have an under-recognized burden of respiratory symptoms after COVID-19 warranting increased awareness and monitoring in this population.","Post-Acute COVID-19 Respiratory Symptoms in Patients With Asthma: An Electronic Health Records-Based Study BACKGROUND: Post-viral respiratory symptoms are common among patients with asthma. Respiratory symptoms after acute COVID-19 are widely reported in the general population, but large-scale studies identifying symptom risk for patients with asthma are lacking.
OBJECTIVE: To identify and compare risk for post-acute COVID-19 respiratory symptoms in patients with and without asthma.
METHODS: This retrospective, observational cohort study included COVID-19-positive patients between March 4, 2020, and January 20, 2021, with up to 180 days of health care follow-up in a health care system in the Northeastern United States. Respiratory symptoms recorded in clinical notes from days 28 to 180 after COVID-19 diagnosis were extracted using natural language processing. Cohorts were stratified by hospitalization status during the acute COVID-19 period. Univariable and multivariable analyses were used to compare symptoms among patients with and without asthma adjusting for demographic and clinical confounders.
RESULTS: Among 31,084 eligible patients with COVID-19, 2863 (9.2%) had hospitalization during the acute COVID-19 period; 4049 (13.0%) had a history of asthma, accounting for 13.8% of hospitalized and 12.9% of nonhospitalized patients. In the post-acute COVID-19 period, patients with asthma had significantly higher risk of shortness of breath, cough, bronchospasm, and wheezing than patients without an asthma history. Incident respiratory symptoms of bronchospasm and wheezing were also higher in patients with asthma. Patients with asthma who had not been hospitalized during acute COVID-19 had additionally higher risk of cough, abnormal breathing, sputum changes, and a wider range of incident respiratory symptoms.
CONCLUSION: Patients with asthma may have an under-recognized burden of respiratory symptoms after COVID-19 warranting increased awareness and monitoring in this population.",0,0
31043825,U.S. prevalence of endocrine therapy-naïve locally advanced or metastatic breast cancer,"Nunes AP, Liang C, Gradishar WJ, Dalvi T, Lewis J, Jones N, Green E, Doherty M, Seeger JD.",Curr Oncol. 2019 Apr;26(2):e180-e187. doi: 10.3747/co.26.4163. Epub 2019 Apr 1.,Nunes AP,Curr Oncol,2019,03-05-2019,PMC6476436,,10.3747/co.26.4163,"BACKGROUND: Variations in treatment choice, or late stage at first diagnosis, mean that, despite guideline recommendations, not all patients with hormone receptor (hr)-positive locally advanced or metastatic breast cancer (la/mbca) will have received endocrine therapy before disease progression. In the present study, we aimed to estimate the proportion of women with postmenopausal hr-positive la/mbca in the United States who are endocrine therapy-naïve.
METHODS: Women in the Optum Electronic Health Record (ehr) database with a breast cancer (bca) diagnosis (January 2008-March 2015) were included. Patient and malignancy characteristics were identified using structured data fields and natural-language processing of free-text clinical notes. The proportion of women with postmenopausal hr-positive, human epidermal growth factor 2 (her2)-negative (or unknown) la/mbca who had not received prior endocrine therapy was determined. Results were extrapolated to the entire U.S. population using the U.S. National Cancer Institute's Surveillance, Epidemiology, and End Results database. Results are presented descriptively.
RESULTS: In the ehr database, 11,831 women with bca had discernible information on postmenopausal status, hr status, and disease stage. Of those women, 1923 (16.3%) had postmenopausal hr-positive, her2-negative (or unknown) la/mbca, and 70.7% of those 1923 patients (n = 1360) had not received prior endocrine therapy, accounting for 11.5% of the overall population. Extrapolating those estimates nationally suggests an annual incidence of 14,784 cases, and a 5-year limited duration prevalence of 50,638 cases.
CONCLUSIONS: A substantial proportion of women with postmenopausal hr-positive la/mbca in the United States could be endocrine therapy-naïve.","U.S. prevalence of endocrine therapy-naïve locally advanced or metastatic breast cancer BACKGROUND: Variations in treatment choice, or late stage at first diagnosis, mean that, despite guideline recommendations, not all patients with hormone receptor (hr)-positive locally advanced or metastatic breast cancer (la/mbca) will have received endocrine therapy before disease progression. In the present study, we aimed to estimate the proportion of women with postmenopausal hr-positive la/mbca in the United States who are endocrine therapy-naïve.
METHODS: Women in the Optum Electronic Health Record (ehr) database with a breast cancer (bca) diagnosis (January 2008-March 2015) were included. Patient and malignancy characteristics were identified using structured data fields and natural-language processing of free-text clinical notes. The proportion of women with postmenopausal hr-positive, human epidermal growth factor 2 (her2)-negative (or unknown) la/mbca who had not received prior endocrine therapy was determined. Results were extrapolated to the entire U.S. population using the U.S. National Cancer Institute's Surveillance, Epidemiology, and End Results database. Results are presented descriptively.
RESULTS: In the ehr database, 11,831 women with bca had discernible information on postmenopausal status, hr status, and disease stage. Of those women, 1923 (16.3%) had postmenopausal hr-positive, her2-negative (or unknown) la/mbca, and 70.7% of those 1923 patients (n = 1360) had not received prior endocrine therapy, accounting for 11.5% of the overall population. Extrapolating those estimates nationally suggests an annual incidence of 14,784 cases, and a 5-year limited duration prevalence of 50,638 cases.
CONCLUSIONS: A substantial proportion of women with postmenopausal hr-positive la/mbca in the United States could be endocrine therapy-naïve.",1,0
33482968,Prevalence and Characteristics of Chronic Cough in Adults Identified by Administrative Data,"Zeiger RS, Xie F, Schatz M, Hong BD, Weaver JP, Bali V, Schelfhout J, Chen W.",Perm J. 2020 Dec;24:1-3. doi: 10.7812/TPP/20.022.,Zeiger RS,Perm J,2020,23-01-2021,PMC7849260,,10.7812/TPP/20.022,"CONTEXT: International Classification of Diseases-9/10 codes for chronic cough (CC) do not exist, limiting investigation.
OBJECTIVE: To develop a computerized algorithm to determine CC prevalence and its characteristics.
DESIGN: This observational study using administrative data identified hierarchically patients aged 18 to 85 years with CC from 2013 to 2016. First, a specialist-diagnosed CC group was identified using an internal CC encounter code during an outpatient visit to a pulmonologist, allergist, otolaryngologist, or gastroenterologist. Subsequently, an event-diagnosed CC group was identified based on clinical notes through natural language processing, ICD-9/ICD-10 cough codes, and dispensed antitussives.
MAIN OUTCOME MEASURES: Prevalence of CC and comparison of clinical characteristics between specialist-diagnosed and event-diagnosed CC subgroups.
RESULTS: A total of 50,163 patients with CC of more than 8 weeks were identified. Of these, 11,290 (22.5%) were specialist diagnosed, and 38,873 (77.5%) were event diagnosed. The CC cohort was 57.4 ± 16.5 years of age; 67.6% were female. The overall prevalence was 1.04% (95% confidence interval = 1.03-1.06) in 2016. Prevalence in 2016 was higher in female patients (1.21%) than in male patients (0.81%), higher in patients aged 65 to 85 years (2.2%) than in patients aged 18 to 44 years (0.43%), and higher in Blacks (1.38%) than in Whites (1.21%). Compared with patients with event-diagnosed CC, patients with specialist-diagnosed CC exhibited significantly higher frequencies of laboratory tests and respiratory and nonrespiratory comorbidities and dispensed medication and lower frequency of pneumonia, all-cause and respiratory-cause emergency department visits and hospitalizations, and dispensed antitussives.
CONCLUSIONS: We identified a CC cohort using electronic data in a managed care organization. Prevalences varied by sex, age, and ethnicity. Clinical characteristics varied between specialist-diagnosed and event-diagnosed CC.","Prevalence and Characteristics of Chronic Cough in Adults Identified by Administrative Data CONTEXT: International Classification of Diseases-9/10 codes for chronic cough (CC) do not exist, limiting investigation.
OBJECTIVE: To develop a computerized algorithm to determine CC prevalence and its characteristics.
DESIGN: This observational study using administrative data identified hierarchically patients aged 18 to 85 years with CC from 2013 to 2016. First, a specialist-diagnosed CC group was identified using an internal CC encounter code during an outpatient visit to a pulmonologist, allergist, otolaryngologist, or gastroenterologist. Subsequently, an event-diagnosed CC group was identified based on clinical notes through natural language processing, ICD-9/ICD-10 cough codes, and dispensed antitussives.
MAIN OUTCOME MEASURES: Prevalence of CC and comparison of clinical characteristics between specialist-diagnosed and event-diagnosed CC subgroups.
RESULTS: A total of 50,163 patients with CC of more than 8 weeks were identified. Of these, 11,290 (22.5%) were specialist diagnosed, and 38,873 (77.5%) were event diagnosed. The CC cohort was 57.4 ± 16.5 years of age; 67.6% were female. The overall prevalence was 1.04% (95% confidence interval = 1.03-1.06) in 2016. Prevalence in 2016 was higher in female patients (1.21%) than in male patients (0.81%), higher in patients aged 65 to 85 years (2.2%) than in patients aged 18 to 44 years (0.43%), and higher in Blacks (1.38%) than in Whites (1.21%). Compared with patients with event-diagnosed CC, patients with specialist-diagnosed CC exhibited significantly higher frequencies of laboratory tests and respiratory and nonrespiratory comorbidities and dispensed medication and lower frequency of pneumonia, all-cause and respiratory-cause emergency department visits and hospitalizations, and dispensed antitussives.
CONCLUSIONS: We identified a CC cohort using electronic data in a managed care organization. Prevalences varied by sex, age, and ethnicity. Clinical characteristics varied between specialist-diagnosed and event-diagnosed CC.",0,0
38721180,"Redefining Healthcare With Artificial Intelligence (AI): The Contributions of ChatGPT, Gemini, and Co-pilot",Alhur A.,Cureus. 2024 Apr 7;16(4):e57795. doi: 10.7759/cureus.57795. eCollection 2024 Apr.,Alhur A,Cureus,2024,09-05-2024,PMC11077095,,10.7759/cureus.57795,"Artificial Intelligence (AI) in healthcare marks a new era of innovation and efficiency, characterized by the emergence of sophisticated language models such as ChatGPT (OpenAI, San Francisco, CA, USA), Gemini Advanced (Google LLC, Mountain View, CA, USA), and Co-pilot (Microsoft Corp, Redmond, WA, USA). This review explores the transformative impact of these AI technologies on various facets of healthcare, from enhancing patient care and treatment protocols to revolutionizing medical research and tackling intricate health science challenges. ChatGPT, with its advanced natural language processing capabilities, leads the way in providing personalized mental health support and improving chronic condition management. Gemini Advanced extends the boundary of AI in healthcare through data analytics, facilitating early disease detection and supporting medical decision-making. Co-pilot, by integrating seamlessly with healthcare systems, optimizes clinical workflows and encourages a culture of innovation among healthcare professionals. Additionally, the review highlights the significant contributions of AI in accelerating medical research, particularly in genomics and drug discovery, thus paving the path for personalized medicine and more effective treatments. The pivotal role of AI in epidemiology, especially in managing infectious diseases such as COVID-19, is also emphasized, demonstrating its value in enhancing public health strategies. However, the integration of AI technologies in healthcare comes with challenges. Concerns about data privacy, security, and the need for comprehensive cybersecurity measures are discussed, along with the importance of regulatory compliance and transparent consent management to uphold ethical standards and patient autonomy. The review points out the necessity for seamless integration, interoperability, and the maintenance of AI systems' reliability and accuracy to fully leverage AI's potential in advancing healthcare.","Redefining Healthcare With Artificial Intelligence (AI): The Contributions of ChatGPT, Gemini, and Co-pilot Artificial Intelligence (AI) in healthcare marks a new era of innovation and efficiency, characterized by the emergence of sophisticated language models such as ChatGPT (OpenAI, San Francisco, CA, USA), Gemini Advanced (Google LLC, Mountain View, CA, USA), and Co-pilot (Microsoft Corp, Redmond, WA, USA). This review explores the transformative impact of these AI technologies on various facets of healthcare, from enhancing patient care and treatment protocols to revolutionizing medical research and tackling intricate health science challenges. ChatGPT, with its advanced natural language processing capabilities, leads the way in providing personalized mental health support and improving chronic condition management. Gemini Advanced extends the boundary of AI in healthcare through data analytics, facilitating early disease detection and supporting medical decision-making. Co-pilot, by integrating seamlessly with healthcare systems, optimizes clinical workflows and encourages a culture of innovation among healthcare professionals. Additionally, the review highlights the significant contributions of AI in accelerating medical research, particularly in genomics and drug discovery, thus paving the path for personalized medicine and more effective treatments. The pivotal role of AI in epidemiology, especially in managing infectious diseases such as COVID-19, is also emphasized, demonstrating its value in enhancing public health strategies. However, the integration of AI technologies in healthcare comes with challenges. Concerns about data privacy, security, and the need for comprehensive cybersecurity measures are discussed, along with the importance of regulatory compliance and transparent consent management to uphold ethical standards and patient autonomy. The review points out the necessity for seamless integration, interoperability, and the maintenance of AI systems' reliability and accuracy to fully leverage AI's potential in advancing healthcare.",0,0
30685678,"Differences in statin utilization and lipid lowering by race, ethnicity, and HIV status in a real-world cohort of persons with human immunodeficiency virus and uninfected persons","Riestenberg RA, Furman A, Cowen A, Pawlowksi A, Schneider D, Lewis AA, Kelly S, Taiwo B, Achenbach C, Palella F, Stone NJ, Lloyd-Jones DM, Feinstein MJ.",Am Heart J. 2019 Mar;209:79-87. doi: 10.1016/j.ahj.2018.11.012. Epub 2018 Dec 20.,Riestenberg RA,Am Heart J,2019,28-01-2019,PMC9274984,NIHMS1654027,10.1016/j.ahj.2018.11.012,"BACKGROUND: Risks for cardiovascular diseases, including myocardial infarction and stroke, are elevated in people with HIV infection (PWH). However, no trials of statin utilization with clinical cardiovascular disease (CVD) end points have been completed in PWH, and there are sparse real-world data regarding statin use and lipid-lowering effectiveness. We therefore used a unique cohort of PWH and uninfected controls to evaluate (1) differences in statin types used for PWH versus uninfected persons; (2) lipid lowering achieved by statin use for PWH versus uninfected persons; and (3) racial and ethnic disparities in appropriate statin use among PWH and uninfected persons.
METHODS: We analyzed a cohort of 5,039 PWH and 10,011 uninfected demographically matched controls who received care at a large urban medical center between January 1, 2000, and May 17, 2017. Medication administration records, prescription data, and validated natural language processing algorithms were used to determine statin utilization. Statins were categorized by generic active ingredient name and intensity (high, moderate, or low). Lipid values collected in routine clinical care were available for analysis. The first set of analyses was restricted to PWH and uninfected matched controls taking statins and compared (1) differences in statin type and (2) difference in cholesterol levels after versus before statin initiation by HIV status. For the second set of analyses, we first used prevalent CVD risk factors to determine participants with statin indications and then determined how many of these participants were taking statins. We then compared statin utilization among persons with indications for statins by race/ethnic group for PWH and uninfected matched controls using multivariable-adjusted logistic regression.
RESULTS: Among people prescribed statins, PWH were more likely than controls to have ever taken pravastatin (34.8% vs 12.3%, P < .001) or atorvastatin (72.2% vs 65.6%, P = .002) and less likely to have ever taken simvastatin (14.2% vs 39.5%, P < .001). Among PWH with indications for statin utilization, 55.7% of whites, 39.4% of blacks, and 45.8% of Hispanics were prescribed statins (P < .001). These differences in statin prescription by race/ethnicity remained significant after adjustment for demographics (including insurance status), cardiovascular risk factors, antiretroviral therapy use, HIV viremia, and CD4 count. These racial/ethnic disparities in statin utilization were less pronounced among uninfected persons.
CONCLUSIONS: Among PWH with statin indication(s), blacks and Hispanics were less likely than whites to have been prescribed a statin. These racial/ethnic disparities were less pronounced among uninfected persons. There were significant differences in type of statin used for PWH compared to uninfected matched controls. Future efforts addressing disparities in CVD prevention among PWH are warranted.","Differences in statin utilization and lipid lowering by race, ethnicity, and HIV status in a real-world cohort of persons with human immunodeficiency virus and uninfected persons BACKGROUND: Risks for cardiovascular diseases, including myocardial infarction and stroke, are elevated in people with HIV infection (PWH). However, no trials of statin utilization with clinical cardiovascular disease (CVD) end points have been completed in PWH, and there are sparse real-world data regarding statin use and lipid-lowering effectiveness. We therefore used a unique cohort of PWH and uninfected controls to evaluate (1) differences in statin types used for PWH versus uninfected persons; (2) lipid lowering achieved by statin use for PWH versus uninfected persons; and (3) racial and ethnic disparities in appropriate statin use among PWH and uninfected persons.
METHODS: We analyzed a cohort of 5,039 PWH and 10,011 uninfected demographically matched controls who received care at a large urban medical center between January 1, 2000, and May 17, 2017. Medication administration records, prescription data, and validated natural language processing algorithms were used to determine statin utilization. Statins were categorized by generic active ingredient name and intensity (high, moderate, or low). Lipid values collected in routine clinical care were available for analysis. The first set of analyses was restricted to PWH and uninfected matched controls taking statins and compared (1) differences in statin type and (2) difference in cholesterol levels after versus before statin initiation by HIV status. For the second set of analyses, we first used prevalent CVD risk factors to determine participants with statin indications and then determined how many of these participants were taking statins. We then compared statin utilization among persons with indications for statins by race/ethnic group for PWH and uninfected matched controls using multivariable-adjusted logistic regression.
RESULTS: Among people prescribed statins, PWH were more likely than controls to have ever taken pravastatin (34.8% vs 12.3%, P < .001) or atorvastatin (72.2% vs 65.6%, P = .002) and less likely to have ever taken simvastatin (14.2% vs 39.5%, P < .001). Among PWH with indications for statin utilization, 55.7% of whites, 39.4% of blacks, and 45.8% of Hispanics were prescribed statins (P < .001). These differences in statin prescription by race/ethnicity remained significant after adjustment for demographics (including insurance status), cardiovascular risk factors, antiretroviral therapy use, HIV viremia, and CD4 count. These racial/ethnic disparities in statin utilization were less pronounced among uninfected persons.
CONCLUSIONS: Among PWH with statin indication(s), blacks and Hispanics were less likely than whites to have been prescribed a statin. These racial/ethnic disparities were less pronounced among uninfected persons. There were significant differences in type of statin used for PWH compared to uninfected matched controls. Future efforts addressing disparities in CVD prevention among PWH are warranted.",0,0
39318625,Variation in worldwide incidence of Guillain-Barré syndrome: a population-based study in urban China and existing global evidence,"Xu L, Zhao C, Bao Y, Liu Y, Liang Y, Wei J, Liu G, Wang J, Zhan S, Wang S, Fan D.",Front Immunol. 2024 Sep 10;15:1415986. doi: 10.3389/fimmu.2024.1415986. eCollection 2024.,Xu L,Front Immunol,2024,25-09-2024,PMC11420027,,10.3389/fimmu.2024.1415986,"BACKGROUND AND OBJECTIVES: Geographical variation existed in the incidences of Guillain-Barré syndrome (GBS), but no national population-based study has evaluated the incidences of GBS in China. This study aimed to estimate the incidence of GBS in urban China and evaluate the worldwide variation in the incidence of GBS.
METHODS: Firstly, we did a population-based study to calculate the incidence of GBS in urban China based on the National Urban Medical Insurance database from 2013 to 2017. To identify GBS cases, natural language processing was used first for handling the lengthy and unstructured diagnostic information and then checked by prestigious neurologists. Secondly, a systematic review and meta-analysis were performed to analyze the incidence of GBS worldwide. Up to July 4, 2022, Medline, Embase, and Web of Science were retrieved to identify the population-based studies regarding the incidence of GBS. The basic information and the statistics regarding incidence were extracted. Quality assessment considered sample representativeness, condition assessment, and statistical methods.
RESULTS: A total of 1.44 billion person-years in insurance data was covered, with 3,534 GBS cases identified. The annual incidences of GBS in urban China between 2013 and 2017 ranged from 0.41 (95% CI: 0.27 to 0.58) to 0.58 (95% CI: 0.38 to 0.82) per 100,000 person-years. The incidence was the highest in Northwest China and the lowest in Northeast China. The meta-analysis included 122 articles. The quality assessment showed that the quality scores of 43.3% of studies were ≥ 0.75 (the total score is 1). The global incidence of GBS was 1.12 (95% CI: 0.98 to 1.27) per 100,000 person-years. The incidences in West Europe, South Asia, and North Europe were higher, while the incidences in Australia and New Zealand, Southeast Asia, and North Africa were lower. The incidence of enteric infections was positively associated with the incidence of GBS (coefficient=0.0000185, P=0.007). The incidence in Europe, Australia, and America rose significantly from 1960 to 2020 (coefficient=0.01, t=2.52, P=0.015).
DISCUSSION: There is a clear regional variation of the GBS incidence at both national and global levels. Careful control of enteric infections should be conducted to reduce the disease burden.","Variation in worldwide incidence of Guillain-Barré syndrome: a population-based study in urban China and existing global evidence BACKGROUND AND OBJECTIVES: Geographical variation existed in the incidences of Guillain-Barré syndrome (GBS), but no national population-based study has evaluated the incidences of GBS in China. This study aimed to estimate the incidence of GBS in urban China and evaluate the worldwide variation in the incidence of GBS.
METHODS: Firstly, we did a population-based study to calculate the incidence of GBS in urban China based on the National Urban Medical Insurance database from 2013 to 2017. To identify GBS cases, natural language processing was used first for handling the lengthy and unstructured diagnostic information and then checked by prestigious neurologists. Secondly, a systematic review and meta-analysis were performed to analyze the incidence of GBS worldwide. Up to July 4, 2022, Medline, Embase, and Web of Science were retrieved to identify the population-based studies regarding the incidence of GBS. The basic information and the statistics regarding incidence were extracted. Quality assessment considered sample representativeness, condition assessment, and statistical methods.
RESULTS: A total of 1.44 billion person-years in insurance data was covered, with 3,534 GBS cases identified. The annual incidences of GBS in urban China between 2013 and 2017 ranged from 0.41 (95% CI: 0.27 to 0.58) to 0.58 (95% CI: 0.38 to 0.82) per 100,000 person-years. The incidence was the highest in Northwest China and the lowest in Northeast China. The meta-analysis included 122 articles. The quality assessment showed that the quality scores of 43.3% of studies were ≥ 0.75 (the total score is 1). The global incidence of GBS was 1.12 (95% CI: 0.98 to 1.27) per 100,000 person-years. The incidences in West Europe, South Asia, and North Europe were higher, while the incidences in Australia and New Zealand, Southeast Asia, and North Africa were lower. The incidence of enteric infections was positively associated with the incidence of GBS (coefficient=0.0000185, P=0.007). The incidence in Europe, Australia, and America rose significantly from 1960 to 2020 (coefficient=0.01, t=2.52, P=0.015).
DISCUSSION: There is a clear regional variation of the GBS incidence at both national and global levels. Careful control of enteric infections should be conducted to reduce the disease burden.",1,0
32795992,"Social, Behavioral, and Cultural factors of HIV in Malawi: Semi-Automated Systematic Review","Thiabaud A, Triulzi I, Orel E, Tal K, Keiser O.",J Med Internet Res. 2020 Aug 14;22(8):e18747. doi: 10.2196/18747.,Thiabaud A,J Med Internet Res,2020,16-08-2020,PMC7455873,,10.2196/18747,"BACKGROUND: Demographic and sociobehavioral factors are strong drivers of HIV infection rates in sub-Saharan Africa. These factors are often studied in qualitative research but ignored in quantitative analyses. However, they provide in-depth insight into the local behavior and may help to improve HIV prevention.
OBJECTIVE: To obtain a comprehensive overview of the sociobehavioral factors influencing HIV prevalence and incidence in Malawi, we systematically reviewed the literature using a newly programmed tool for automatizing part of the systematic review process.
METHODS: Due to the choice of broad search terms (""HIV AND Malawi""), our preliminary search revealed many thousands of articles. We, therefore, developed a Python tool to automatically extract, process, and categorize open-access articles published from January 1, 1987 to October 1, 2019 in the PubMed, PubMed Central, JSTOR, Paperity, and arXiV databases. We then used a topic modelling algorithm to classify and identify publications of interest.
RESULTS: Our tool extracted 22,709 unique articles; 16,942 could be further processed. After topic modelling, 519 of these were clustered into relevant topics, of which 20 were kept after manual screening. We retrieved 7 more publications after examining the references so that 27 publications were finally included in the review. Reducing the 16,942 articles to 519 potentially relevant articles using the software took 5 days. Several factors contributing to the risk of HIV infection were identified, including religion, gender and relationship dynamics, beliefs, and sociobehavioral attitudes.
CONCLUSIONS: Our software does not replace traditional systematic reviews, but it returns useful results to broad queries of open-access literature in under a week, without a priori knowledge. This produces a ""seed dataset"" of relevance that could be further developed. It identified known factors and factors that may be specific to Malawi. In the future, we aim to expand the tool by adding more social science databases and applying it to other sub-Saharan African countries.","Social, Behavioral, and Cultural factors of HIV in Malawi: Semi-Automated Systematic Review BACKGROUND: Demographic and sociobehavioral factors are strong drivers of HIV infection rates in sub-Saharan Africa. These factors are often studied in qualitative research but ignored in quantitative analyses. However, they provide in-depth insight into the local behavior and may help to improve HIV prevention.
OBJECTIVE: To obtain a comprehensive overview of the sociobehavioral factors influencing HIV prevalence and incidence in Malawi, we systematically reviewed the literature using a newly programmed tool for automatizing part of the systematic review process.
METHODS: Due to the choice of broad search terms (""HIV AND Malawi""), our preliminary search revealed many thousands of articles. We, therefore, developed a Python tool to automatically extract, process, and categorize open-access articles published from January 1, 1987 to October 1, 2019 in the PubMed, PubMed Central, JSTOR, Paperity, and arXiV databases. We then used a topic modelling algorithm to classify and identify publications of interest.
RESULTS: Our tool extracted 22,709 unique articles; 16,942 could be further processed. After topic modelling, 519 of these were clustered into relevant topics, of which 20 were kept after manual screening. We retrieved 7 more publications after examining the references so that 27 publications were finally included in the review. Reducing the 16,942 articles to 519 potentially relevant articles using the software took 5 days. Several factors contributing to the risk of HIV infection were identified, including religion, gender and relationship dynamics, beliefs, and sociobehavioral attitudes.
CONCLUSIONS: Our software does not replace traditional systematic reviews, but it returns useful results to broad queries of open-access literature in under a week, without a priori knowledge. This produces a ""seed dataset"" of relevance that could be further developed. It identified known factors and factors that may be specific to Malawi. In the future, we aim to expand the tool by adding more social science databases and applying it to other sub-Saharan African countries.",1,0
36764726,Influence of the COVID-19 pandemic and social media on the behaviour of pregnant and lactating women towards vaccination: a scoping review,"De Brabandere L, Hendrickx G, Poels K, Daelemans W, Van Damme P, Maertens K.",BMJ Open. 2023 Feb 10;13(2):e066367. doi: 10.1136/bmjopen-2022-066367.,De Brabandere L,BMJ Open,2023,10-02-2023,PMC9922880,,10.1136/bmjopen-2022-066367,"BACKGROUND: Pregnant women, foetuses and infants are at risk of infectious disease-related complications. Maternal vaccination is a strategy developed to better protect pregnant women and their offspring against infectious disease-related morbidity and mortality. Vaccines against influenza, pertussis and recently also COVID-19 are widely recommended for pregnant women. Yet, there is still a significant amount of hesitation towards maternal vaccination policies. Furthermore, contradictory messages circulating social media impact vaccine confidence.
OBJECTIVES: This scoping review aims to reveal how COVID-19 and COVID-19 vaccination impacted vaccine confidence in pregnant and lactating women. Additionally, this review studied the role social media plays in creating opinions towards vaccination in these target groups.
ELIGIBILITY CRITERIA: Articles published between 23 November 2018 and 18 July 2022 that are linked to the objectives of this review were included. Reviews, articles not focusing on the target group, abstracts, articles describing outcomes of COVID-19 infection/COVID-19 vaccination were excluded.
SOURCES OF EVIDENCE: The PubMed database was searched to select articles. Search terms used were linked to pregnancy, lactation, vaccination, vaccine hesitancy, COVID-19 and social media.
CHARTING METHODS: Included articles were abstracted and synthesised by one reviewer. Verification was done by a second reviewer. Disagreements were addressed through discussion between reviewers and other researchers.
RESULTS: Pregnant and lactating women are generally less likely to accept a COVID-19 vaccine compared with non-pregnant and non-nursing women. The main reason to refuse maternal vaccination is safety concerns. A positive link was detected between COVID-19 vaccine willingness and acceptance of other vaccines during pregnancy. The internet and social media are identified as important information sources for maternal vaccination.
DISCUSSION AND CONCLUSION: Vaccine hesitancy in pregnant and lactating women remains an important issue, expressing the need for effective interventions to increase vaccine confidence and coverage. The role social media plays in vaccine uptake remains unclear.","Influence of the COVID-19 pandemic and social media on the behaviour of pregnant and lactating women towards vaccination: a scoping review BACKGROUND: Pregnant women, foetuses and infants are at risk of infectious disease-related complications. Maternal vaccination is a strategy developed to better protect pregnant women and their offspring against infectious disease-related morbidity and mortality. Vaccines against influenza, pertussis and recently also COVID-19 are widely recommended for pregnant women. Yet, there is still a significant amount of hesitation towards maternal vaccination policies. Furthermore, contradictory messages circulating social media impact vaccine confidence.
OBJECTIVES: This scoping review aims to reveal how COVID-19 and COVID-19 vaccination impacted vaccine confidence in pregnant and lactating women. Additionally, this review studied the role social media plays in creating opinions towards vaccination in these target groups.
ELIGIBILITY CRITERIA: Articles published between 23 November 2018 and 18 July 2022 that are linked to the objectives of this review were included. Reviews, articles not focusing on the target group, abstracts, articles describing outcomes of COVID-19 infection/COVID-19 vaccination were excluded.
SOURCES OF EVIDENCE: The PubMed database was searched to select articles. Search terms used were linked to pregnancy, lactation, vaccination, vaccine hesitancy, COVID-19 and social media.
CHARTING METHODS: Included articles were abstracted and synthesised by one reviewer. Verification was done by a second reviewer. Disagreements were addressed through discussion between reviewers and other researchers.
RESULTS: Pregnant and lactating women are generally less likely to accept a COVID-19 vaccine compared with non-pregnant and non-nursing women. The main reason to refuse maternal vaccination is safety concerns. A positive link was detected between COVID-19 vaccine willingness and acceptance of other vaccines during pregnancy. The internet and social media are identified as important information sources for maternal vaccination.
DISCUSSION AND CONCLUSION: Vaccine hesitancy in pregnant and lactating women remains an important issue, expressing the need for effective interventions to increase vaccine confidence and coverage. The role social media plays in vaccine uptake remains unclear.",0,0
29954337,Development and validation of a heart failure with preserved ejection fraction cohort using electronic medical records,"Patel YR, Robbins JM, Kurgansky KE, Imran T, Orkaby AR, McLean RR, Ho YL, Cho K, Michael Gaziano J, Djousse L, Gagnon DR, Joseph J.",BMC Cardiovasc Disord. 2018 Jun 28;18(1):128. doi: 10.1186/s12872-018-0866-5.,Patel YR,BMC Cardiovasc Disord,2018,30-06-2018,PMC6022342,,10.1186/s12872-018-0866-5,"BACKGROUND: Heart failure (HF) with preserved ejection fraction (HFpEF) comprises nearly half of prevalent HF, yet is challenging to curate in a large database of electronic medical records (EMR) since it requires both accurate HF diagnosis and left ventricular ejection fraction (EF) values to be consistently ≥50%.
METHODS: We used the national Veterans Affairs EMR to curate a cohort of HFpEF patients from 2002 to 2014. EF values were extracted from clinical documents utilizing natural language processing and an iterative approach was used to refine the algorithm for verification of clinical HFpEF. The final algorithm utilized the following inclusion criteria: any International Classification of Diseases-9 (ICD-9) code of HF (428.xx); all recorded EF ≥50%; and either B-type natriuretic peptide (BNP) or aminoterminal pro-BNP (NT-proBNP) values recorded OR diuretic use within one month of diagnosis of HF. Validation of the algorithm was performed by 3 independent reviewers doing manual chart review of 100 HFpEF cases and 100 controls.
RESULTS: We established a HFpEF cohort of 80,248 patients (out of a total 1,155,376 patients with the ICD-9 diagnosis of HF). Mean age was 72 years; 96% were males and 12% were African-Americans. Validation analysis of the HFpEF algorithm had a sensitivity of 88%, specificity of 96%, positive predictive value of 96%, and a negative predictive value of 87% to identify HFpEF cases.
CONCLUSION: We developed a sensitive, highly specific algorithm for detecting HFpEF in a large national database. This approach may be applicable to other large EMR databases to identify HFpEF patients.","Development and validation of a heart failure with preserved ejection fraction cohort using electronic medical records BACKGROUND: Heart failure (HF) with preserved ejection fraction (HFpEF) comprises nearly half of prevalent HF, yet is challenging to curate in a large database of electronic medical records (EMR) since it requires both accurate HF diagnosis and left ventricular ejection fraction (EF) values to be consistently ≥50%.
METHODS: We used the national Veterans Affairs EMR to curate a cohort of HFpEF patients from 2002 to 2014. EF values were extracted from clinical documents utilizing natural language processing and an iterative approach was used to refine the algorithm for verification of clinical HFpEF. The final algorithm utilized the following inclusion criteria: any International Classification of Diseases-9 (ICD-9) code of HF (428.xx); all recorded EF ≥50%; and either B-type natriuretic peptide (BNP) or aminoterminal pro-BNP (NT-proBNP) values recorded OR diuretic use within one month of diagnosis of HF. Validation of the algorithm was performed by 3 independent reviewers doing manual chart review of 100 HFpEF cases and 100 controls.
RESULTS: We established a HFpEF cohort of 80,248 patients (out of a total 1,155,376 patients with the ICD-9 diagnosis of HF). Mean age was 72 years; 96% were males and 12% were African-Americans. Validation analysis of the HFpEF algorithm had a sensitivity of 88%, specificity of 96%, positive predictive value of 96%, and a negative predictive value of 87% to identify HFpEF cases.
CONCLUSION: We developed a sensitive, highly specific algorithm for detecting HFpEF in a large national database. This approach may be applicable to other large EMR databases to identify HFpEF patients.",0,0
34298499,Determinants of Shielding Behavior During the COVID-19 Pandemic and Associations With Well-being Among National Health Service Patients: Longitudinal Observational Study,"Bachtiger P, Adamson A, Maclean WA, Kelshiker MA, Quint JK, Peters NS.",JMIR Public Health Surveill. 2021 Sep 20;7(9):e30460. doi: 10.2196/30460.,Bachtiger P,JMIR Public Health Surveill,2021,23-07-2021,PMC8454693,,10.2196/30460,"BACKGROUND: The UK National Health Service (NHS) classified 2.2 million people as clinically extremely vulnerable (CEV) during the first wave of the 2020 COVID-19 pandemic, advising them to ""shield"" (to not leave home for any reason).
OBJECTIVE: The aim of this study was to measure the determinants of shielding behavior and associations with well-being in a large NHS patient population for informing future health policy.
METHODS: Patients contributing to an ongoing longitudinal participatory epidemiology study (Longitudinal Effects on Wellbeing of the COVID-19 Pandemic [LoC-19], n=42,924) received weekly email invitations to complete questionnaires (17-week shielding period starting April 9, 2020) within their NHS personal electronic health record. Question items focused on well-being. Participants were stratified into four groups by self-reported CEV status (qualifying condition) and adoption of shielding behavior (baselined at week 1 or 2). The distribution of CEV criteria was reported alongside situational variables and univariable and multivariable logistic regression. Longitudinal trends in physical and mental well-being were displayed graphically. Free-text responses reporting variables impacting well-being were semiquantified using natural language processing. In the lead up to a second national lockdown (October 23, 2020), a follow-up questionnaire evaluated subjective concern if further shielding was advised.
RESULTS: The study included 7240 participants. In the CEV group (n=2391), 1133 (47.3%) assumed shielding behavior at baseline, compared with 633 (13.0%) in the non-CEV group (n=4849). CEV participants who shielded were more likely to be Asian (odds ratio [OR] 2.02, 95% CI 1.49-2.76), female (OR 1.24, 95% CI 1.05-1.45), older (OR per year increase 1.01, 95% CI 1.00-1.02), living in a home with an outdoor space (OR 1.34, 95% CI 1.06-1.70) or three to four other inhabitants (three: OR 1.49, 95% CI 1.15-1.94; four: OR 1.49, 95% CI 1.10-2.01), or solid organ transplant recipients (OR 2.85, 95% CI 2.18-3.77), or have severe chronic lung disease (OR 1.63, 95% CI 1.30-2.04). Receipt of a government letter advising shielding was reported in 1115 (46.6%) CEV participants and 180 (3.7%) non-CEV participants, and was associated with adopting shielding behavior (OR 3.34, 95% CI 2.82-3.95 and OR 2.88, 95% CI 2.04-3.99, respectively). In CEV participants, shielding at baseline was associated with a lower rating of mental well-being and physical well-being. Similar results were found for non-CEV participants. Concern for well-being if future shielding was required was most prevalent among CEV participants who had originally shielded.
CONCLUSIONS: Future health policy must balance the potential protection from COVID-19 against our findings that shielding negatively impacted well-being and was adopted in many in whom it was not indicated and variably in whom it was indicated. This therefore also requires clearer public health messaging and support for well-being if shielding is to be advised in future pandemic scenarios.","Determinants of Shielding Behavior During the COVID-19 Pandemic and Associations With Well-being Among National Health Service Patients: Longitudinal Observational Study BACKGROUND: The UK National Health Service (NHS) classified 2.2 million people as clinically extremely vulnerable (CEV) during the first wave of the 2020 COVID-19 pandemic, advising them to ""shield"" (to not leave home for any reason).
OBJECTIVE: The aim of this study was to measure the determinants of shielding behavior and associations with well-being in a large NHS patient population for informing future health policy.
METHODS: Patients contributing to an ongoing longitudinal participatory epidemiology study (Longitudinal Effects on Wellbeing of the COVID-19 Pandemic [LoC-19], n=42,924) received weekly email invitations to complete questionnaires (17-week shielding period starting April 9, 2020) within their NHS personal electronic health record. Question items focused on well-being. Participants were stratified into four groups by self-reported CEV status (qualifying condition) and adoption of shielding behavior (baselined at week 1 or 2). The distribution of CEV criteria was reported alongside situational variables and univariable and multivariable logistic regression. Longitudinal trends in physical and mental well-being were displayed graphically. Free-text responses reporting variables impacting well-being were semiquantified using natural language processing. In the lead up to a second national lockdown (October 23, 2020), a follow-up questionnaire evaluated subjective concern if further shielding was advised.
RESULTS: The study included 7240 participants. In the CEV group (n=2391), 1133 (47.3%) assumed shielding behavior at baseline, compared with 633 (13.0%) in the non-CEV group (n=4849). CEV participants who shielded were more likely to be Asian (odds ratio [OR] 2.02, 95% CI 1.49-2.76), female (OR 1.24, 95% CI 1.05-1.45), older (OR per year increase 1.01, 95% CI 1.00-1.02), living in a home with an outdoor space (OR 1.34, 95% CI 1.06-1.70) or three to four other inhabitants (three: OR 1.49, 95% CI 1.15-1.94; four: OR 1.49, 95% CI 1.10-2.01), or solid organ transplant recipients (OR 2.85, 95% CI 2.18-3.77), or have severe chronic lung disease (OR 1.63, 95% CI 1.30-2.04). Receipt of a government letter advising shielding was reported in 1115 (46.6%) CEV participants and 180 (3.7%) non-CEV participants, and was associated with adopting shielding behavior (OR 3.34, 95% CI 2.82-3.95 and OR 2.88, 95% CI 2.04-3.99, respectively). In CEV participants, shielding at baseline was associated with a lower rating of mental well-being and physical well-being. Similar results were found for non-CEV participants. Concern for well-being if future shielding was required was most prevalent among CEV participants who had originally shielded.
CONCLUSIONS: Future health policy must balance the potential protection from COVID-19 against our findings that shielding negatively impacted well-being and was adopted in many in whom it was not indicated and variably in whom it was indicated. This therefore also requires clearer public health messaging and support for well-being if shielding is to be advised in future pandemic scenarios.",1,0
39546783,AI for Analyzing Mental Health Disorders Among Social Media Users: Quarter-Century Narrative Review of Progress and Challenges,"Owen D, Lynham AJ, Smart SE, Pardiñas AF, Camacho Collados J.",J Med Internet Res. 2024 Nov 15;26:e59225. doi: 10.2196/59225.,Owen D,J Med Internet Res,2024,15-11-2024,PMC11607554,,10.2196/59225,"BACKGROUND: Mental health disorders are currently the main contributor to poor quality of life and years lived with disability. Symptoms common to many mental health disorders lead to impairments or changes in the use of language, which are observable in the routine use of social media. Detection of these linguistic cues has been explored throughout the last quarter century, but interest and methodological development have burgeoned following the COVID-19 pandemic. The next decade may see the development of reliable methods for predicting mental health status using social media data. This might have implications for clinical practice and public health policy, particularly in the context of early intervention in mental health care.
OBJECTIVE: This study aims to examine the state of the art in methods for predicting mental health statuses of social media users. Our focus is the development of artificial intelligence-driven methods, particularly natural language processing, for analyzing large volumes of written text. This study details constraints affecting research in this area. These include the dearth of high-quality public datasets for methodological benchmarking and the need to adopt ethical and privacy frameworks acknowledging the stigma experienced by those with a mental illness.
METHODS: A Google Scholar search yielded peer-reviewed articles dated between 1999 and 2024. We manually grouped the articles by 4 primary areas of interest: datasets on social media and mental health, methods for predicting mental health status, longitudinal analyses of mental health, and ethical aspects of the data and analysis of mental health. Selected articles from these groups formed our narrative review.
RESULTS: Larger datasets with precise dates of participants' diagnoses are needed to support the development of methods for predicting mental health status, particularly in severe disorders such as schizophrenia. Inviting users to donate their social media data for research purposes could help overcome widespread ethical and privacy concerns. In any event, multimodal methods for predicting mental health status appear likely to provide advancements that may not be achievable using natural language processing alone.
CONCLUSIONS: Multimodal methods for predicting mental health status from voice, image, and video-based social media data need to be further developed before they may be considered for adoption in health care, medical support, or as consumer-facing products. Such methods are likely to garner greater public confidence in their efficacy than those that rely on text alone. To achieve this, more high-quality social media datasets need to be made available and privacy concerns regarding the use of these data must be formally addressed. A social media platform feature that invites users to share their data upon publication is a possible solution. Finally, a review of literature studying the effects of social media use on a user's depression and anxiety is merited.","AI for Analyzing Mental Health Disorders Among Social Media Users: Quarter-Century Narrative Review of Progress and Challenges BACKGROUND: Mental health disorders are currently the main contributor to poor quality of life and years lived with disability. Symptoms common to many mental health disorders lead to impairments or changes in the use of language, which are observable in the routine use of social media. Detection of these linguistic cues has been explored throughout the last quarter century, but interest and methodological development have burgeoned following the COVID-19 pandemic. The next decade may see the development of reliable methods for predicting mental health status using social media data. This might have implications for clinical practice and public health policy, particularly in the context of early intervention in mental health care.
OBJECTIVE: This study aims to examine the state of the art in methods for predicting mental health statuses of social media users. Our focus is the development of artificial intelligence-driven methods, particularly natural language processing, for analyzing large volumes of written text. This study details constraints affecting research in this area. These include the dearth of high-quality public datasets for methodological benchmarking and the need to adopt ethical and privacy frameworks acknowledging the stigma experienced by those with a mental illness.
METHODS: A Google Scholar search yielded peer-reviewed articles dated between 1999 and 2024. We manually grouped the articles by 4 primary areas of interest: datasets on social media and mental health, methods for predicting mental health status, longitudinal analyses of mental health, and ethical aspects of the data and analysis of mental health. Selected articles from these groups formed our narrative review.
RESULTS: Larger datasets with precise dates of participants' diagnoses are needed to support the development of methods for predicting mental health status, particularly in severe disorders such as schizophrenia. Inviting users to donate their social media data for research purposes could help overcome widespread ethical and privacy concerns. In any event, multimodal methods for predicting mental health status appear likely to provide advancements that may not be achievable using natural language processing alone.
CONCLUSIONS: Multimodal methods for predicting mental health status from voice, image, and video-based social media data need to be further developed before they may be considered for adoption in health care, medical support, or as consumer-facing products. Such methods are likely to garner greater public confidence in their efficacy than those that rely on text alone. To achieve this, more high-quality social media datasets need to be made available and privacy concerns regarding the use of these data must be formally addressed. A social media platform feature that invites users to share their data upon publication is a possible solution. Finally, a review of literature studying the effects of social media use on a user's depression and anxiety is merited.",1,0
32511492,"Extending A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter to England, UK","Golder S, Klein AZ, Magge A, O'Connor K, Cai H, Weissenbacher D, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2020 May 8:2020.05.05.20083436. doi: 10.1101/2020.05.05.20083436.,Golder S,medRxiv,2020,09-06-2020,PMC7273260,,10.1101/2020.05.05.20083436,"The rapidly evolving COVID-19 pandemic presents challenges for actively monitoring its transmission. In this study, we extend a social media mining approach used in the US to automatically identify personal reports of COVID-19 on Twitter in England, UK. The findings indicate that natural language processing and machine learning framework could help provide an early indication of the chronological and geographical distribution of COVID-19 in England.","Extending A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter to England, UK The rapidly evolving COVID-19 pandemic presents challenges for actively monitoring its transmission. In this study, we extend a social media mining approach used in the US to automatically identify personal reports of COVID-19 on Twitter in England, UK. The findings indicate that natural language processing and machine learning framework could help provide an early indication of the chronological and geographical distribution of COVID-19 in England.",1,0
38516566,Social vulnerabilities among immigrants and refugees in emergencies and disasters: a systematic review,"Doust Mohammadi MM, Salmani I, Farahmandnia H.",Front Public Health. 2024 Mar 7;11:1235464. doi: 10.3389/fpubh.2023.1235464. eCollection 2023.,Doust Mohammadi MM,Front Public Health,2024,22-03-2024,PMC10956690,,10.3389/fpubh.2023.1235464,"BACKGROUND: Due to cultural, economic, and societal factors, immigrants and refugees are pivotal groups in dealing with social vulnerability in disasters. Ignoring or inadequate attention to those groups in preparing for and responding to disasters and health emergencies could decrease the effectiveness of efforts. This article aims to identify the most basic social vulnerabilities among immigrants and refugees and provide effective solutions to alleviate or eliminate these vulnerabilities.
METHODS: This systematic review was performed based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The main keywords include Social Vulnerabilities, Immigrants, Refugees, and Disasters. All articles published up to February 2023 were reviewed regardless of language and location. A total of 575 articles were extracted from SCOPUS, Web of Science, ScienceDirect, ProQuest, PubMed, EMBASE, and PsycINFO databases, and finally, 14 articles were selected for full-text analysis. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) was used to evaluate the quality of the selected articles.
RESULTS: Fourteen articles including 4 qualitative and 10 quantitative articles were selected and analyzed in this review. The findings showed: 1. According to the consensus of the studies, the most vulnerable people who need urgent care during an epidemic due to their special conditions are immigrants and refugees; 2. In most countries, no database provides reliable, up-to-date, and accurate statistics about these people; 3. Refugees usually hesitate to express their vulnerability and receive services due to the fear of deportation; and 4. The main challenges faced by refugees are socio-economic problems such as language problems, lack of emotional and social support, and living in crowded places.
CONCLUSION: Considering the prevalence of migration among countries, it is essential to identify the social problems and vulnerabilities of immigrants and provide effective solutions to cope with their challenges, especially during crises and emergencies.
SYSTEMATIC REVIEW REGISTRATION: https://clinicaltrials.gov/, identifier CRD42022371345.","Social vulnerabilities among immigrants and refugees in emergencies and disasters: a systematic review BACKGROUND: Due to cultural, economic, and societal factors, immigrants and refugees are pivotal groups in dealing with social vulnerability in disasters. Ignoring or inadequate attention to those groups in preparing for and responding to disasters and health emergencies could decrease the effectiveness of efforts. This article aims to identify the most basic social vulnerabilities among immigrants and refugees and provide effective solutions to alleviate or eliminate these vulnerabilities.
METHODS: This systematic review was performed based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The main keywords include Social Vulnerabilities, Immigrants, Refugees, and Disasters. All articles published up to February 2023 were reviewed regardless of language and location. A total of 575 articles were extracted from SCOPUS, Web of Science, ScienceDirect, ProQuest, PubMed, EMBASE, and PsycINFO databases, and finally, 14 articles were selected for full-text analysis. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) was used to evaluate the quality of the selected articles.
RESULTS: Fourteen articles including 4 qualitative and 10 quantitative articles were selected and analyzed in this review. The findings showed: 1. According to the consensus of the studies, the most vulnerable people who need urgent care during an epidemic due to their special conditions are immigrants and refugees; 2. In most countries, no database provides reliable, up-to-date, and accurate statistics about these people; 3. Refugees usually hesitate to express their vulnerability and receive services due to the fear of deportation; and 4. The main challenges faced by refugees are socio-economic problems such as language problems, lack of emotional and social support, and living in crowded places.
CONCLUSION: Considering the prevalence of migration among countries, it is essential to identify the social problems and vulnerabilities of immigrants and provide effective solutions to cope with their challenges, especially during crises and emergencies.
SYSTEMATIC REVIEW REGISTRATION: https://clinicaltrials.gov/, identifier CRD42022371345.",1,0
33620282,"Trends of pulmonary fungal infections from 2013 to 2019: an AI-based real-world observational study in Guangzhou, China","Li Z, Li Y, Chen Y, Li J, Li S, Li C, Lin Y, Jian W, Shi J, Zhan Y, Cheng J, Zheng J, Zhong N, Ye F.",Emerg Microbes Infect. 2021 Dec;10(1):450-460. doi: 10.1080/22221751.2021.1894902.,Li Z,Emerg Microbes Infect,2021,23-02-2021,PMC7971272,,10.1080/22221751.2021.1894902,"Recently, the prevalence trend of pulmonary fungal infection (PFI) has rapidly increased. Changes in the risk factors for, distributions of underlying diseases associated with and clinical characteristics of some individual PFIs have been reported in the past decade. However, data regarding PFIs remain uncertain. This study reports the epidemiological characteristics and trends of PFIs over time in recent years. We applied an automated natural language processing (NLP) system to extract clinically relevant information from the electronic health records (EHRs) of PFI patients at the First Affiliated Hospital of Guangzhou Medical University. Then, a trend analysis was performed. From January 1, 2013, to December 31, 2019, 40,504 inpatients and 219,414 outpatients with respiratory diseases were screened, in which 1368 inpatients and 1313 outpatients with PFI were identified. These patients were from throughout the country, but most patients were from southern China. Upward trends in PFIs were observed in both hospitalized patients and outpatients (P&lt;0.05). The stratification by age showed that the incidence of hospitalized patients aged 14-30 years exhibited the most obvious upward trend, increasing from 9.5 per 1000 patients in 2013 to 88.3 per 1000 patients in 2019. Aspergillosis (56.69%) was the most common PFI, but notably, the incidence rates of Talaromyces marneffei, which used to be considered uncommon, exhibited the most rapid increases. In younger PFI patients, the incidence and trend of PFIs have increased. Infection by previously uncommon pathogens has also gradually increased. Increased attention should be paid to young PFI patients and uncommon PFI pathogen infections.","Trends of pulmonary fungal infections from 2013 to 2019: an AI-based real-world observational study in Guangzhou, China Recently, the prevalence trend of pulmonary fungal infection (PFI) has rapidly increased. Changes in the risk factors for, distributions of underlying diseases associated with and clinical characteristics of some individual PFIs have been reported in the past decade. However, data regarding PFIs remain uncertain. This study reports the epidemiological characteristics and trends of PFIs over time in recent years. We applied an automated natural language processing (NLP) system to extract clinically relevant information from the electronic health records (EHRs) of PFI patients at the First Affiliated Hospital of Guangzhou Medical University. Then, a trend analysis was performed. From January 1, 2013, to December 31, 2019, 40,504 inpatients and 219,414 outpatients with respiratory diseases were screened, in which 1368 inpatients and 1313 outpatients with PFI were identified. These patients were from throughout the country, but most patients were from southern China. Upward trends in PFIs were observed in both hospitalized patients and outpatients (P&lt;0.05). The stratification by age showed that the incidence of hospitalized patients aged 14-30 years exhibited the most obvious upward trend, increasing from 9.5 per 1000 patients in 2013 to 88.3 per 1000 patients in 2019. Aspergillosis (56.69%) was the most common PFI, but notably, the incidence rates of Talaromyces marneffei, which used to be considered uncommon, exhibited the most rapid increases. In younger PFI patients, the incidence and trend of PFIs have increased. Infection by previously uncommon pathogens has also gradually increased. Increased attention should be paid to young PFI patients and uncommon PFI pathogen infections.",1,1
32511608,A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter,"Klein AZ, Magge A, O'Connor KMS, Cai H, Weissenbacher D, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2020 Apr 22:2020.04.19.20069948. doi: 10.1101/2020.04.19.20069948.,Klein AZ,medRxiv,2020,09-06-2020,PMC7276035,,10.1101/2020.04.19.20069948,"The rapidly evolving outbreak of COVID-19 presents challenges for actively monitoring its spread. In this study, we assessed a social media mining approach for automatically analyzing the chronological and geographical distribution of users in the United States reporting personal information related to COVID-19 on Twitter. The results suggest that our natural language processing and machine learning framework could help provide an early indication of the spread of COVID-19.","A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter The rapidly evolving outbreak of COVID-19 presents challenges for actively monitoring its spread. In this study, we assessed a social media mining approach for automatically analyzing the chronological and geographical distribution of users in the United States reporting personal information related to COVID-19 on Twitter. The results suggest that our natural language processing and machine learning framework could help provide an early indication of the spread of COVID-19.",1,0
37546903,Looking at the Full Picture: Utilizing Topic Modeling to Determine Disease-Associated Microbiome Communities,"Shrode RL, Ollberding NJ, Mangalam AK.",bioRxiv [Preprint]. 2023 Jul 25:2023.07.21.549984. doi: 10.1101/2023.07.21.549984.,Shrode RL,bioRxiv,2023,07-08-2023,PMC10401927,,10.1101/2023.07.21.549984,"The microbiome is a complex micro-ecosystem that provides the host with pathogen defense, food metabolism, and other vital processes. Alterations of the microbiome (dysbiosis) have been linked with a number of diseases such as cancers, multiple sclerosis (MS), Alzheimer's disease, etc. Generally, differential abundance testing between the healthy and patient groups is performed to identify important bacteria (enriched or depleted in one group). However, simply providing a singular species of bacteria to an individual lacking that species for health improvement has not been as successful as fecal matter transplant (FMT) therapy. Interestingly, FMT therapy transfers the entire gut microbiome of a healthy (or mixture of) individual to an individual with a disease. FMTs do, however, have limited success, possibly due to concerns that not all bacteria in the community may be responsible for the healthy phenotype. Therefore, it is important to identify the community of microorganisms linked to the health as well as the disease state of the host. Here we applied topic modeling, a natural language processing tool, to assess latent interactions occurring among microbes; thus, providing a representation of the community of bacteria relevant to healthy vs. disease state. Specifically, we utilized our previously published data that studied the gut microbiome of patients with relapsing-remitting MS (RRMS), a neurodegenerative autoimmune disease that has been linked to a variety of factors, including a dysbiotic gut microbiome. With topic modeling we identified communities of bacteria associated with RRMS, including genera previously discovered, but also other taxa that would have been overlooked simply with differential abundance testing. Our work shows that topic modeling can be a useful tool for analyzing the microbiome in dysbiosis and that it could be considered along with the commonly utilized differential abundance tests to better understand the role of the gut microbiome in health and disease.","Looking at the Full Picture: Utilizing Topic Modeling to Determine Disease-Associated Microbiome Communities The microbiome is a complex micro-ecosystem that provides the host with pathogen defense, food metabolism, and other vital processes. Alterations of the microbiome (dysbiosis) have been linked with a number of diseases such as cancers, multiple sclerosis (MS), Alzheimer's disease, etc. Generally, differential abundance testing between the healthy and patient groups is performed to identify important bacteria (enriched or depleted in one group). However, simply providing a singular species of bacteria to an individual lacking that species for health improvement has not been as successful as fecal matter transplant (FMT) therapy. Interestingly, FMT therapy transfers the entire gut microbiome of a healthy (or mixture of) individual to an individual with a disease. FMTs do, however, have limited success, possibly due to concerns that not all bacteria in the community may be responsible for the healthy phenotype. Therefore, it is important to identify the community of microorganisms linked to the health as well as the disease state of the host. Here we applied topic modeling, a natural language processing tool, to assess latent interactions occurring among microbes; thus, providing a representation of the community of bacteria relevant to healthy vs. disease state. Specifically, we utilized our previously published data that studied the gut microbiome of patients with relapsing-remitting MS (RRMS), a neurodegenerative autoimmune disease that has been linked to a variety of factors, including a dysbiotic gut microbiome. With topic modeling we identified communities of bacteria associated with RRMS, including genera previously discovered, but also other taxa that would have been overlooked simply with differential abundance testing. Our work shows that topic modeling can be a useful tool for analyzing the microbiome in dysbiosis and that it could be considered along with the commonly utilized differential abundance tests to better understand the role of the gut microbiome in health and disease.",1,0
37334464,Does medical waste research during COVID-19 meet the challenge induced by the pandemic to waste management?,"Wang Q, Zhang M, Li R.",Waste Manag Res. 2024 Mar;42(3):244-259. doi: 10.1177/0734242X231178226. Epub 2023 Jun 18.,Wang Q,Waste Manag Res,2024,19-06-2023,PMC10277880,,10.1177/0734242X231178226,"The COVID-19 pandemic has resulted in an unprecedented amount of medical waste, presenting significant challenges for the safe disposal of hazardous waste. A systematic review of existing research on COVID-19 and medical waste can help address these challenges by providing insights and recommendations for effective management of the massive medical waste generated during the pandemic. This study utilized bibliometric and text mining methods to survey the scientific outcomes related to COVID-19 and medical waste, drawing on data from the Scopus database. The results show that the spatial distribution of medical waste research is unbalanced. Surprisingly, developing countries rather than developed countries lead research in this area. Especially, China, a major contributor to the field, has the highest number of publications and citations, and is also a centre of international cooperation. The main study authors and research institutions are also mainly from China. And the research on medical waste is a multidisciplinary field. Text mining analysis shows that COVID-19 and medical waste research is mainly organized around four themes: (i) medical waste from personal protective equipment; (ii) research on medical waste in Wuhan, China; (iii) threats of medical waste to the environment and (iv) disposal and management of medical waste. This would serve to better understand the current state of medical waste research and to provide some implications for future research.","Does medical waste research during COVID-19 meet the challenge induced by the pandemic to waste management? The COVID-19 pandemic has resulted in an unprecedented amount of medical waste, presenting significant challenges for the safe disposal of hazardous waste. A systematic review of existing research on COVID-19 and medical waste can help address these challenges by providing insights and recommendations for effective management of the massive medical waste generated during the pandemic. This study utilized bibliometric and text mining methods to survey the scientific outcomes related to COVID-19 and medical waste, drawing on data from the Scopus database. The results show that the spatial distribution of medical waste research is unbalanced. Surprisingly, developing countries rather than developed countries lead research in this area. Especially, China, a major contributor to the field, has the highest number of publications and citations, and is also a centre of international cooperation. The main study authors and research institutions are also mainly from China. And the research on medical waste is a multidisciplinary field. Text mining analysis shows that COVID-19 and medical waste research is mainly organized around four themes: (i) medical waste from personal protective equipment; (ii) research on medical waste in Wuhan, China; (iii) threats of medical waste to the environment and (iv) disposal and management of medical waste. This would serve to better understand the current state of medical waste research and to provide some implications for future research.",0,0
31824670,Evidence-based Clinical Decision Support Systems for the prediction and detection of three disease states in critical care: A systematic literature review,"Medic G, Kosaner Kließ M, Atallah L, Weichert J, Panda S, Postma M, El-Kerdi A.",F1000Res. 2019 Oct 8;8:1728. doi: 10.12688/f1000research.20498.2. eCollection 2019.,Medic G,F1000Res,2019,14-12-2019,PMC6894361,,10.12688/f1000research.20498.2,"Background: Clinical decision support (CDS) systems have emerged as tools providing intelligent decision making to address challenges of critical care. CDS systems can be based on existing guidelines or best practices; and can also utilize machine learning to provide a diagnosis, recommendation, or therapy course. Methods: This research aimed to identify evidence-based study designs and outcome measures to determine the clinical effectiveness of clinical decision support systems in the detection and prediction of hemodynamic instability, respiratory distress, and infection within critical care settings. PubMed, ClinicalTrials.gov and Cochrane Database of Systematic Reviews were systematically searched to identify primary research published in English between 2013 and 2018. Studies conducted in the USA, Canada, UK, Germany and France with more than 10 participants per arm were included. Results: In studies on hemodynamic instability, the prediction and management of septic shock were the most researched topics followed by the early prediction of heart failure. For respiratory distress, the most popular topics were pneumonia detection and prediction followed by pulmonary embolisms. Given the importance of imaging and clinical notes, this area combined Machine Learning with image analysis and natural language processing. In studies on infection, the most researched areas were the detection, prediction, and management of sepsis, surgical site infections, as well as acute kidney injury. Overall, a variety of Machine Learning algorithms were utilized frequently, particularly support vector machines, boosting techniques, random forest classifiers and neural networks. Sensitivity, specificity, and ROC AUC were the most frequently reported performance measures. Conclusion: This review showed an increasing use of Machine Learning for CDS in all three areas. Large datasets are required for training these algorithms; making it imperative to appropriately address, challenges such as class imbalance, correct labelling of data and missing data. Recommendations are formulated for the development and successful adoption of CDS systems.","Evidence-based Clinical Decision Support Systems for the prediction and detection of three disease states in critical care: A systematic literature review Background: Clinical decision support (CDS) systems have emerged as tools providing intelligent decision making to address challenges of critical care. CDS systems can be based on existing guidelines or best practices; and can also utilize machine learning to provide a diagnosis, recommendation, or therapy course. Methods: This research aimed to identify evidence-based study designs and outcome measures to determine the clinical effectiveness of clinical decision support systems in the detection and prediction of hemodynamic instability, respiratory distress, and infection within critical care settings. PubMed, ClinicalTrials.gov and Cochrane Database of Systematic Reviews were systematically searched to identify primary research published in English between 2013 and 2018. Studies conducted in the USA, Canada, UK, Germany and France with more than 10 participants per arm were included. Results: In studies on hemodynamic instability, the prediction and management of septic shock were the most researched topics followed by the early prediction of heart failure. For respiratory distress, the most popular topics were pneumonia detection and prediction followed by pulmonary embolisms. Given the importance of imaging and clinical notes, this area combined Machine Learning with image analysis and natural language processing. In studies on infection, the most researched areas were the detection, prediction, and management of sepsis, surgical site infections, as well as acute kidney injury. Overall, a variety of Machine Learning algorithms were utilized frequently, particularly support vector machines, boosting techniques, random forest classifiers and neural networks. Sensitivity, specificity, and ROC AUC were the most frequently reported performance measures. Conclusion: This review showed an increasing use of Machine Learning for CDS in all three areas. Large datasets are required for training these algorithms; making it imperative to appropriately address, challenges such as class imbalance, correct labelling of data and missing data. Recommendations are formulated for the development and successful adoption of CDS systems.",1,0
38814687,Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development and Validation,"Invernici F, Bernasconi A, Ceri S.",J Med Internet Res. 2024 May 30;26:e52655. doi: 10.2196/52655.,Invernici F,J Med Internet Res,2024,30-05-2024,PMC11176882,,10.2196/52655,"BACKGROUND: Since the beginning of the COVID-19 pandemic, >1 million studies have been collected within the COVID-19 Open Research Dataset, a corpus of manuscripts created to accelerate research against the disease. Their related abstracts hold a wealth of information that remains largely unexplored and difficult to search due to its unstructured nature. Keyword-based search is the standard approach, which allows users to retrieve the documents of a corpus that contain (all or some of) the words in a target list. This type of search, however, does not provide visual support to the task and is not suited to expressing complex queries or compensating for missing specifications.
OBJECTIVE: This study aims to consider small graphs of concepts and exploit them for expressing graph searches over existing COVID-19-related literature, leveraging the increasing use of graphs to represent and query scientific knowledge and providing a user-friendly search and exploration experience.
METHODS: We considered the COVID-19 Open Research Dataset corpus and summarized its content by annotating the publications' abstracts using terms selected from the Unified Medical Language System and the Ontology of Coronavirus Infectious Disease. Then, we built a co-occurrence network that includes all relevant concepts mentioned in the corpus, establishing connections when their mutual information is relevant. A sophisticated graph query engine was built to allow the identification of the best matches of graph queries on the network. It also supports partial matches and suggests potential query completions using shortest paths.
RESULTS: We built a large co-occurrence network, consisting of 128,249 entities and 47,198,965 relationships; the GRAPH-SEARCH interface allows users to explore the network by formulating or adapting graph queries; it produces a bibliography of publications, which are globally ranked; and each publication is further associated with the specific parts of the query that it explains, thereby allowing the user to understand each aspect of the matching.
CONCLUSIONS: Our approach supports the process of query formulation and evidence search upon a large text corpus; it can be reapplied to any scientific domain where documents corpora and curated ontologies are made available.","Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development and Validation BACKGROUND: Since the beginning of the COVID-19 pandemic, >1 million studies have been collected within the COVID-19 Open Research Dataset, a corpus of manuscripts created to accelerate research against the disease. Their related abstracts hold a wealth of information that remains largely unexplored and difficult to search due to its unstructured nature. Keyword-based search is the standard approach, which allows users to retrieve the documents of a corpus that contain (all or some of) the words in a target list. This type of search, however, does not provide visual support to the task and is not suited to expressing complex queries or compensating for missing specifications.
OBJECTIVE: This study aims to consider small graphs of concepts and exploit them for expressing graph searches over existing COVID-19-related literature, leveraging the increasing use of graphs to represent and query scientific knowledge and providing a user-friendly search and exploration experience.
METHODS: We considered the COVID-19 Open Research Dataset corpus and summarized its content by annotating the publications' abstracts using terms selected from the Unified Medical Language System and the Ontology of Coronavirus Infectious Disease. Then, we built a co-occurrence network that includes all relevant concepts mentioned in the corpus, establishing connections when their mutual information is relevant. A sophisticated graph query engine was built to allow the identification of the best matches of graph queries on the network. It also supports partial matches and suggests potential query completions using shortest paths.
RESULTS: We built a large co-occurrence network, consisting of 128,249 entities and 47,198,965 relationships; the GRAPH-SEARCH interface allows users to explore the network by formulating or adapting graph queries; it produces a bibliography of publications, which are globally ranked; and each publication is further associated with the specific parts of the query that it explains, thereby allowing the user to understand each aspect of the matching.
CONCLUSIONS: Our approach supports the process of query formulation and evidence search upon a large text corpus; it can be reapplied to any scientific domain where documents corpora and curated ontologies are made available.",1,0
35789657,"The needs of cancer patients during the COVID-19 pandemic-psychosocial, ethical and spiritual aspects-systematic review","Zapała J, Matecka M, Zok A, Baum E.",PeerJ. 2022 Jun 29;10:e13480. doi: 10.7717/peerj.13480. eCollection 2022.,Zapała J,PeerJ,2022,05-07-2022,PMC9250307,,10.7717/peerj.13480,"The COVID-19 pandemic resulted in unprecedented changes in the functioning of the health care system, which were connected with the occurrence of new challenges for both the health care system's employees and for the patients. The purpose of the present article is to analyze the needs of persons with oncological diseases. Taking into account the multiple aspects of the term health, psychological, social, and existential needs of the patients were analyzed. This article is directed mainly at persons who remain in a direct therapeutic relation with a patient. It is to facilitate recognizing the needs of ill people and to increase sensitivity to the issue of maintaining or improving the well-being of patients which requires paying special attention to their psychological, social, and existential needs during the period of hindered access to the health care system. This systematic review takes advantage of quantitative and qualitative methods of text analysis with phenomenological analysis factored in. The COVID-19 pandemic resulted in the appearance of new problems in the population of oncological patients or it made the existing problems more severe. As a consequence, it made it significantly more difficult to meet their needs on various levels and sometimes it even made it impossible. It seems necessary to determine and introduce strategies to ensure that patients with oncological diseases have access to psychological and spiritual support in the period of the pandemic.","The needs of cancer patients during the COVID-19 pandemic-psychosocial, ethical and spiritual aspects-systematic review The COVID-19 pandemic resulted in unprecedented changes in the functioning of the health care system, which were connected with the occurrence of new challenges for both the health care system's employees and for the patients. The purpose of the present article is to analyze the needs of persons with oncological diseases. Taking into account the multiple aspects of the term health, psychological, social, and existential needs of the patients were analyzed. This article is directed mainly at persons who remain in a direct therapeutic relation with a patient. It is to facilitate recognizing the needs of ill people and to increase sensitivity to the issue of maintaining or improving the well-being of patients which requires paying special attention to their psychological, social, and existential needs during the period of hindered access to the health care system. This systematic review takes advantage of quantitative and qualitative methods of text analysis with phenomenological analysis factored in. The COVID-19 pandemic resulted in the appearance of new problems in the population of oncological patients or it made the existing problems more severe. As a consequence, it made it significantly more difficult to meet their needs on various levels and sometimes it even made it impossible. It seems necessary to determine and introduce strategies to ensure that patients with oncological diseases have access to psychological and spiritual support in the period of the pandemic.",1,0
38045356,Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data,"Klein AZ, Kunatharaju S, Golder S, Levine LD, Figueiredo JC, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2023 Nov 21:2023.11.17.23298696. doi: 10.1101/2023.11.17.23298696.,Klein AZ,medRxiv,2023,04-12-2023,PMC10690358,,10.1101/2023.11.17.23298696,"BACKGROUND: Preterm birth, defined as birth at <37 weeks of gestation, is the leading cause of neonatal death globally and, together with low birthweight, the second leading cause of infant mortality in the United States. There is mounting evidence that COVID-19 infection during pregnancy is associated with an increased risk of preterm birth; however, data remain limited by trimester of infection. The ability to study COVID-19 infection during the earlier stages of pregnancy has been limited by available sources of data. The objective of this study was to use self-reports in large-scale, longitudinal social media data to assess the association between trimester of COVID-19 infection and preterm birth.
METHODS: In this retrospective cohort study, we used natural language processing and machine learning, followed by manual validation, to identify pregnant Twitter users and to search their longitudinal collection of publicly available tweets for reports of COVID-19 infection during pregnancy and, subsequently, a preterm birth or term birth (i.e., a gestational age ≥37 weeks) outcome. Among the users who reported their pregnancy on Twitter, we also identified a 1:1 age-matched control group, consisting of users with a due date prior to January 1, 2020-that is, without COVID-19 infection during pregnancy. We calculated the odds ratios (ORs) with 95% confidence intervals (CIs) to compare the overall rates of preterm birth for pregnancies with and without COVID-19 infection and by timing of infection: first trimester (weeks 1-13), second trimester (weeks 1427), or third trimester (weeks 28-36).
RESULTS: Through August 2022, we identified 298 Twitter users who reported COVID-19 infection during pregnancy, a preterm birth or term birth outcome, and maternal age: 94 (31.5%) with first-trimester infection, 110 (36.9%) second-trimester infection, and 95 (31.9%) third-trimester infection. In total, 26 (8.8%) of these 298 users reported preterm birth: 8 (8.5%) were infected during the first trimester, 7 (6.4%) were infected during the second trimester, and 12 (12.6%) were infected during the third trimester. In the 1:1 age-matched control group, 13 (4.4%) of the 298 users reported preterm birth. Overall, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection compared to those without (OR 2.1, 95% CI 1.06-4.16). In particular, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection during the third trimester (OR 3.17, CI 1.39-7.21).
CONCLUSION: The results of our study suggest that COVID-19 infection particularly during the third trimester is associated with an increased risk of preterm birth.","Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data BACKGROUND: Preterm birth, defined as birth at <37 weeks of gestation, is the leading cause of neonatal death globally and, together with low birthweight, the second leading cause of infant mortality in the United States. There is mounting evidence that COVID-19 infection during pregnancy is associated with an increased risk of preterm birth; however, data remain limited by trimester of infection. The ability to study COVID-19 infection during the earlier stages of pregnancy has been limited by available sources of data. The objective of this study was to use self-reports in large-scale, longitudinal social media data to assess the association between trimester of COVID-19 infection and preterm birth.
METHODS: In this retrospective cohort study, we used natural language processing and machine learning, followed by manual validation, to identify pregnant Twitter users and to search their longitudinal collection of publicly available tweets for reports of COVID-19 infection during pregnancy and, subsequently, a preterm birth or term birth (i.e., a gestational age ≥37 weeks) outcome. Among the users who reported their pregnancy on Twitter, we also identified a 1:1 age-matched control group, consisting of users with a due date prior to January 1, 2020-that is, without COVID-19 infection during pregnancy. We calculated the odds ratios (ORs) with 95% confidence intervals (CIs) to compare the overall rates of preterm birth for pregnancies with and without COVID-19 infection and by timing of infection: first trimester (weeks 1-13), second trimester (weeks 1427), or third trimester (weeks 28-36).
RESULTS: Through August 2022, we identified 298 Twitter users who reported COVID-19 infection during pregnancy, a preterm birth or term birth outcome, and maternal age: 94 (31.5%) with first-trimester infection, 110 (36.9%) second-trimester infection, and 95 (31.9%) third-trimester infection. In total, 26 (8.8%) of these 298 users reported preterm birth: 8 (8.5%) were infected during the first trimester, 7 (6.4%) were infected during the second trimester, and 12 (12.6%) were infected during the third trimester. In the 1:1 age-matched control group, 13 (4.4%) of the 298 users reported preterm birth. Overall, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection compared to those without (OR 2.1, 95% CI 1.06-4.16). In particular, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection during the third trimester (OR 3.17, CI 1.39-7.21).
CONCLUSION: The results of our study suggest that COVID-19 infection particularly during the third trimester is associated with an increased risk of preterm birth.",1,0
38805611,A Bayesian System to Detect and Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases: Algorithm Development and Validation,"Aronis JM, Ye Y, Espino J, Hochheiser H, Michaels MG, Cooper GF.",JMIR Public Health Surveill. 2024 Aug 13;10:e57349. doi: 10.2196/57349.,Aronis JM,JMIR Public Health Surveill,2024,28-05-2024,PMC11350309,,10.2196/57349,"BACKGROUND:  The early identification of outbreaks of both known and novel influenza-like illnesses (ILIs) is an important public health problem.
OBJECTIVE:  This study aimed to describe the design and testing of a tool that detects and tracks outbreaks of both known and novel ILIs, such as the SARS-CoV-2 worldwide pandemic, accurately and early.
METHODS:  This paper describes the ILI Tracker algorithm that first models the daily occurrence of a set of known ILIs in hospital emergency departments in a monitored region using findings extracted from patient care reports using natural language processing. We then show how the algorithm can be extended to detect and track the presence of an unmodeled disease that may represent a novel disease outbreak.
RESULTS:  We include results based on modeling diseases like influenza, respiratory syncytial virus, human metapneumovirus, and parainfluenza for 5 emergency departments in Allegheny County, Pennsylvania, from June 1, 2014, to May 31, 2015. We also include the results of detecting the outbreak of an unmodeled disease, which in retrospect was very likely an outbreak of the enterovirus D68 (EV-D68).
CONCLUSIONS:  The results reported in this paper provide support that ILI Tracker was able to track well the incidence of 4 modeled influenza-like diseases over a 1-year period, relative to laboratory-confirmed cases, and it was computationally efficient in doing so. The system was also able to detect a likely novel outbreak of EV-D68 early in an outbreak that occurred in Allegheny County in 2014 as well as clinically characterize that outbreak disease accurately.","A Bayesian System to Detect and Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases: Algorithm Development and Validation BACKGROUND:  The early identification of outbreaks of both known and novel influenza-like illnesses (ILIs) is an important public health problem.
OBJECTIVE:  This study aimed to describe the design and testing of a tool that detects and tracks outbreaks of both known and novel ILIs, such as the SARS-CoV-2 worldwide pandemic, accurately and early.
METHODS:  This paper describes the ILI Tracker algorithm that first models the daily occurrence of a set of known ILIs in hospital emergency departments in a monitored region using findings extracted from patient care reports using natural language processing. We then show how the algorithm can be extended to detect and track the presence of an unmodeled disease that may represent a novel disease outbreak.
RESULTS:  We include results based on modeling diseases like influenza, respiratory syncytial virus, human metapneumovirus, and parainfluenza for 5 emergency departments in Allegheny County, Pennsylvania, from June 1, 2014, to May 31, 2015. We also include the results of detecting the outbreak of an unmodeled disease, which in retrospect was very likely an outbreak of the enterovirus D68 (EV-D68).
CONCLUSIONS:  The results reported in this paper provide support that ILI Tracker was able to track well the incidence of 4 modeled influenza-like diseases over a 1-year period, relative to laboratory-confirmed cases, and it was computationally efficient in doing so. The system was also able to detect a likely novel outbreak of EV-D68 early in an outbreak that occurred in Allegheny County in 2014 as well as clinically characterize that outbreak disease accurately.",1,0
35593186,Signs and symptoms to determine if a patient presenting in primary care or hospital outpatient settings has COVID-19,"Struyf T, Deeks JJ, Dinnes J, Takwoingi Y, Davenport C, Leeflang MM, Spijker R, Hooft L, Emperador D, Domen J, Tans A, Janssens S, Wickramasinghe D, Lannoy V, Horn SRA, Van den Bruel A; Cochrane COVID-19 Diagnostic Test Accuracy Group.",Cochrane Database Syst Rev. 2022 May 20;5(5):CD013665. doi: 10.1002/14651858.CD013665.pub3.,Struyf T,Cochrane Database Syst Rev,2022,20-05-2022,PMC9121352,,10.1002/14651858.CD013665.pub3,"BACKGROUND: COVID-19 illness is highly variable, ranging from infection with no symptoms through to pneumonia and life-threatening consequences. Symptoms such as fever, cough, or loss of sense of smell (anosmia) or taste (ageusia), can help flag early on if the disease is present. Such information could be used either to rule out COVID-19 disease, or to identify people who need to go for COVID-19 diagnostic tests. This is the second update of this review, which was first published in 2020.
OBJECTIVES: To assess the diagnostic accuracy of signs and symptoms to determine if a person presenting in primary care or to hospital outpatient settings, such as the emergency department or dedicated COVID-19 clinics, has COVID-19.
SEARCH METHODS: We undertook electronic searches up to 10 June 2021 in the University of Bern living search database. In addition, we checked repositories of COVID-19 publications. We used artificial intelligence text analysis to conduct an initial classification of documents. We did not apply any language restrictions.
SELECTION CRITERIA: Studies were eligible if they included people with clinically suspected COVID-19, or recruited known cases with COVID-19 and also controls without COVID-19 from a single-gate cohort. Studies were eligible when they recruited people presenting to primary care or hospital outpatient settings. Studies that included people who contracted SARS-CoV-2 infection while admitted to hospital were not eligible. The minimum eligible sample size of studies was 10 participants. All signs and symptoms were eligible for this review, including individual signs and symptoms or combinations. We accepted a range of reference standards.
DATA COLLECTION AND ANALYSIS: Pairs of review authors independently selected all studies, at both title and abstract, and full-text stage. They resolved any disagreements by discussion with a third review author. Two review authors independently extracted data and assessed risk of bias using the QUADAS-2 checklist, and resolved disagreements by discussion with a third review author. Analyses were restricted to prospective studies only. We presented sensitivity and specificity in paired forest plots, in receiver operating characteristic (ROC) space and in dumbbell plots. We estimated summary parameters using a bivariate random-effects meta-analysis whenever five or more primary prospective studies were available, and whenever heterogeneity across studies was deemed acceptable.
MAIN RESULTS: We identified 90 studies; for this update we focused on the results of 42 prospective studies with 52,608 participants. Prevalence of COVID-19 disease varied from 3.7% to 60.6% with a median of 27.4%. Thirty-five studies were set in emergency departments or outpatient test centres (46,878 participants), three in primary care settings (1230 participants), two in a mixed population of in- and outpatients in a paediatric hospital setting (493 participants), and two overlapping studies in nursing homes (4007 participants). The studies did not clearly distinguish mild COVID-19 disease from COVID-19 pneumonia, so we present the results for both conditions together. Twelve studies had a high risk of bias for selection of participants because they used a high level of preselection to decide whether reverse transcription polymerase chain reaction (RT-PCR) testing was needed, or because they enrolled a non-consecutive sample, or because they excluded individuals while they were part of the study base. We rated 36 of the 42 studies as high risk of bias for the index tests because there was little or no detail on how, by whom and when, the symptoms were measured. For most studies, eligibility for testing was dependent on the local case definition and testing criteria that were in effect at the time of the study, meaning most people who were included in studies had already been referred to health services based on the symptoms that we are evaluating in this review. The applicability of the results of this review iteration improved in comparison with the previous reviews. This version has more studies of people presenting to ambulatory settings, which is where the majority of assessments for COVID-19 take place. Only three studies presented any data on children separately, and only one focused specifically on older adults. We found data on 96 symptoms or combinations of signs and symptoms. Evidence on individual signs as diagnostic tests was rarely reported, so this review reports mainly on the diagnostic value of symptoms. Results were highly variable across studies. Most had very low sensitivity and high specificity. RT-PCR was the most often used reference standard (40/42 studies). Only cough (11 studies) had a summary sensitivity above 50% (62.4%, 95% CI 50.6% to 72.9%)); its specificity was low (45.4%, 95% CI 33.5% to 57.9%)). Presence of fever had a sensitivity of 37.6% (95% CI 23.4% to 54.3%) and a specificity of 75.2% (95% CI 56.3% to 87.8%). The summary positive likelihood ratio of cough was 1.14 (95% CI 1.04 to 1.25) and that of fever 1.52 (95% CI 1.10 to 2.10). Sore throat had a summary positive likelihood ratio of 0.814 (95% CI 0.714 to 0.929), which means that its presence increases the probability of having an infectious disease other than COVID-19. Dyspnoea (12 studies) and fatigue (8 studies) had a sensitivity of 23.3% (95% CI 16.4% to 31.9%) and 40.2% (95% CI 19.4% to 65.1%) respectively. Their specificity was 75.7% (95% CI 65.2% to 83.9%) and 73.6% (95% CI 48.4% to 89.3%). The summary positive likelihood ratio of dyspnoea was 0.96 (95% CI 0.83 to 1.11) and that of fatigue 1.52 (95% CI 1.21 to 1.91), which means that the presence of fatigue slightly increases the probability of having COVID-19. Anosmia alone (7 studies), ageusia alone (5 studies), and anosmia or ageusia (6 studies) had summary sensitivities below 50% but summary specificities over 90%. Anosmia had a summary sensitivity of 26.4% (95% CI 13.8% to 44.6%) and a specificity of 94.2% (95% CI 90.6% to 96.5%). Ageusia had a summary sensitivity of 23.2% (95% CI 10.6% to 43.3%) and a specificity of 92.6% (95% CI 83.1% to 97.0%). Anosmia or ageusia had a summary sensitivity of 39.2% (95% CI 26.5% to 53.6%) and a specificity of 92.1% (95% CI 84.5% to 96.2%). The summary positive likelihood ratios of anosmia alone and anosmia or ageusia were 4.55 (95% CI 3.46 to 5.97) and 4.99 (95% CI 3.22 to 7.75) respectively, which is just below our arbitrary definition of a 'red flag', that is, a positive likelihood ratio of at least 5. The summary positive likelihood ratio of ageusia alone was 3.14 (95% CI 1.79 to 5.51). Twenty-four studies assessed combinations of different signs and symptoms, mostly combining olfactory symptoms. By combining symptoms with other information such as contact or travel history, age, gender, and a local recent case detection rate, some multivariable prediction scores reached a sensitivity as high as 90%.
AUTHORS' CONCLUSIONS: Most individual symptoms included in this review have poor diagnostic accuracy. Neither absence nor presence of symptoms are accurate enough to rule in or rule out the disease. The presence of anosmia or ageusia may be useful as a red flag for the presence of COVID-19. The presence of cough also supports further testing. There is currently no evidence to support further testing with PCR in any individuals presenting only with upper respiratory symptoms such as sore throat, coryza or rhinorrhoea. Combinations of symptoms with other readily available information such as contact or travel history, or the local recent case detection rate may prove more useful and should be further investigated in an unselected population presenting to primary care or hospital outpatient settings. The diagnostic accuracy of symptoms for COVID-19 is moderate to low and any testing strategy using symptoms as selection mechanism will result in both large numbers of missed cases and large numbers of people requiring testing. Which one of these is minimised, is determined by the goal of COVID-19 testing strategies, that is, controlling the epidemic by isolating every possible case versus identifying those with clinically important disease so that they can be monitored or treated to optimise their prognosis. The former will require a testing strategy that uses very few symptoms as entry criterion for testing, the latter could focus on more specific symptoms such as fever and anosmia.","Signs and symptoms to determine if a patient presenting in primary care or hospital outpatient settings has COVID-19 BACKGROUND: COVID-19 illness is highly variable, ranging from infection with no symptoms through to pneumonia and life-threatening consequences. Symptoms such as fever, cough, or loss of sense of smell (anosmia) or taste (ageusia), can help flag early on if the disease is present. Such information could be used either to rule out COVID-19 disease, or to identify people who need to go for COVID-19 diagnostic tests. This is the second update of this review, which was first published in 2020.
OBJECTIVES: To assess the diagnostic accuracy of signs and symptoms to determine if a person presenting in primary care or to hospital outpatient settings, such as the emergency department or dedicated COVID-19 clinics, has COVID-19.
SEARCH METHODS: We undertook electronic searches up to 10 June 2021 in the University of Bern living search database. In addition, we checked repositories of COVID-19 publications. We used artificial intelligence text analysis to conduct an initial classification of documents. We did not apply any language restrictions.
SELECTION CRITERIA: Studies were eligible if they included people with clinically suspected COVID-19, or recruited known cases with COVID-19 and also controls without COVID-19 from a single-gate cohort. Studies were eligible when they recruited people presenting to primary care or hospital outpatient settings. Studies that included people who contracted SARS-CoV-2 infection while admitted to hospital were not eligible. The minimum eligible sample size of studies was 10 participants. All signs and symptoms were eligible for this review, including individual signs and symptoms or combinations. We accepted a range of reference standards.
DATA COLLECTION AND ANALYSIS: Pairs of review authors independently selected all studies, at both title and abstract, and full-text stage. They resolved any disagreements by discussion with a third review author. Two review authors independently extracted data and assessed risk of bias using the QUADAS-2 checklist, and resolved disagreements by discussion with a third review author. Analyses were restricted to prospective studies only. We presented sensitivity and specificity in paired forest plots, in receiver operating characteristic (ROC) space and in dumbbell plots. We estimated summary parameters using a bivariate random-effects meta-analysis whenever five or more primary prospective studies were available, and whenever heterogeneity across studies was deemed acceptable.
MAIN RESULTS: We identified 90 studies; for this update we focused on the results of 42 prospective studies with 52,608 participants. Prevalence of COVID-19 disease varied from 3.7% to 60.6% with a median of 27.4%. Thirty-five studies were set in emergency departments or outpatient test centres (46,878 participants), three in primary care settings (1230 participants), two in a mixed population of in- and outpatients in a paediatric hospital setting (493 participants), and two overlapping studies in nursing homes (4007 participants). The studies did not clearly distinguish mild COVID-19 disease from COVID-19 pneumonia, so we present the results for both conditions together. Twelve studies had a high risk of bias for selection of participants because they used a high level of preselection to decide whether reverse transcription polymerase chain reaction (RT-PCR) testing was needed, or because they enrolled a non-consecutive sample, or because they excluded individuals while they were part of the study base. We rated 36 of the 42 studies as high risk of bias for the index tests because there was little or no detail on how, by whom and when, the symptoms were measured. For most studies, eligibility for testing was dependent on the local case definition and testing criteria that were in effect at the time of the study, meaning most people who were included in studies had already been referred to health services based on the symptoms that we are evaluating in this review. The applicability of the results of this review iteration improved in comparison with the previous reviews. This version has more studies of people presenting to ambulatory settings, which is where the majority of assessments for COVID-19 take place. Only three studies presented any data on children separately, and only one focused specifically on older adults. We found data on 96 symptoms or combinations of signs and symptoms. Evidence on individual signs as diagnostic tests was rarely reported, so this review reports mainly on the diagnostic value of symptoms. Results were highly variable across studies. Most had very low sensitivity and high specificity. RT-PCR was the most often used reference standard (40/42 studies). Only cough (11 studies) had a summary sensitivity above 50% (62.4%, 95% CI 50.6% to 72.9%)); its specificity was low (45.4%, 95% CI 33.5% to 57.9%)). Presence of fever had a sensitivity of 37.6% (95% CI 23.4% to 54.3%) and a specificity of 75.2% (95% CI 56.3% to 87.8%). The summary positive likelihood ratio of cough was 1.14 (95% CI 1.04 to 1.25) and that of fever 1.52 (95% CI 1.10 to 2.10). Sore throat had a summary positive likelihood ratio of 0.814 (95% CI 0.714 to 0.929), which means that its presence increases the probability of having an infectious disease other than COVID-19. Dyspnoea (12 studies) and fatigue (8 studies) had a sensitivity of 23.3% (95% CI 16.4% to 31.9%) and 40.2% (95% CI 19.4% to 65.1%) respectively. Their specificity was 75.7% (95% CI 65.2% to 83.9%) and 73.6% (95% CI 48.4% to 89.3%). The summary positive likelihood ratio of dyspnoea was 0.96 (95% CI 0.83 to 1.11) and that of fatigue 1.52 (95% CI 1.21 to 1.91), which means that the presence of fatigue slightly increases the probability of having COVID-19. Anosmia alone (7 studies), ageusia alone (5 studies), and anosmia or ageusia (6 studies) had summary sensitivities below 50% but summary specificities over 90%. Anosmia had a summary sensitivity of 26.4% (95% CI 13.8% to 44.6%) and a specificity of 94.2% (95% CI 90.6% to 96.5%). Ageusia had a summary sensitivity of 23.2% (95% CI 10.6% to 43.3%) and a specificity of 92.6% (95% CI 83.1% to 97.0%). Anosmia or ageusia had a summary sensitivity of 39.2% (95% CI 26.5% to 53.6%) and a specificity of 92.1% (95% CI 84.5% to 96.2%). The summary positive likelihood ratios of anosmia alone and anosmia or ageusia were 4.55 (95% CI 3.46 to 5.97) and 4.99 (95% CI 3.22 to 7.75) respectively, which is just below our arbitrary definition of a 'red flag', that is, a positive likelihood ratio of at least 5. The summary positive likelihood ratio of ageusia alone was 3.14 (95% CI 1.79 to 5.51). Twenty-four studies assessed combinations of different signs and symptoms, mostly combining olfactory symptoms. By combining symptoms with other information such as contact or travel history, age, gender, and a local recent case detection rate, some multivariable prediction scores reached a sensitivity as high as 90%.
AUTHORS' CONCLUSIONS: Most individual symptoms included in this review have poor diagnostic accuracy. Neither absence nor presence of symptoms are accurate enough to rule in or rule out the disease. The presence of anosmia or ageusia may be useful as a red flag for the presence of COVID-19. The presence of cough also supports further testing. There is currently no evidence to support further testing with PCR in any individuals presenting only with upper respiratory symptoms such as sore throat, coryza or rhinorrhoea. Combinations of symptoms with other readily available information such as contact or travel history, or the local recent case detection rate may prove more useful and should be further investigated in an unselected population presenting to primary care or hospital outpatient settings. The diagnostic accuracy of symptoms for COVID-19 is moderate to low and any testing strategy using symptoms as selection mechanism will result in both large numbers of missed cases and large numbers of people requiring testing. Which one of these is minimised, is determined by the goal of COVID-19 testing strategies, that is, controlling the epidemic by isolating every possible case versus identifying those with clinically important disease so that they can be monitored or treated to optimise their prognosis. The former will require a testing strategy that uses very few symptoms as entry criterion for testing, the latter could focus on more specific symptoms such as fever and anosmia.",1,0
38562836,"Health activism, vaccine, and mpox discourse: BERTopic based mixed-method analyses of tweets from sexual minority men and gender diverse (SMMGD) individuals in the U.S","Wang Y, O'Connor K, Flores I, Berdahl CT, Urbanowicz RJ, Stevens R, Bauermeister JA, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2024 Mar 19:2024.03.19.24304519. doi: 10.1101/2024.03.19.24304519.,Wang Y,medRxiv,2024,02-04-2024,PMC10984054,,10.1101/2024.03.19.24304519,"OBJECTIVES: To synthesize discussions among sexual minority men and gender diverse (SMMGD) individuals on mpox, given limited representation of SMMGD voices in existing mpox literature.
METHODS: BERTopic (a topic modeling technique) was employed with human validations to analyze mpox-related tweets (n = 8,688; October 2020-September 2022) from 2,326 self-identified SMMGD individuals in the U.S.; followed by content analysis and geographic analysis.
RESULTS: BERTopic identified 11 topics: health activism (29.81%); mpox vaccination (25.81%) and adverse events (0.98%); sarcasm, jokes, emotional expressions (14.04%); COVID-19 and mpox (7.32%); government/public health response (6.12%); mpox symptoms (2.74%); case reports (2.21%); puns on the virus' naming (i.e., monkeypox; 0.86%); media publicity (0.68%); mpox in children (0.67%). Mpox health activism negatively correlated with LGB social climate index at U.S. state level, ρ = -0.322, p = 0.031.
CONCLUSIONS: SMMGD discussions on mpox encompassed utilitarian (e.g., vaccine access, case reports, mpox symptoms) and emotionally-charged themes-advocating against homophobia, misinformation, and stigma. Mpox health activism was more prevalent in states with lower LGB social acceptance.
PUBLIC HEALTH IMPLICATIONS: Findings illuminate SMMGD engagement with mpox discourse, underscoring the need for more inclusive health communication strategies in infectious disease outbreaks to control associated stigma.","Health activism, vaccine, and mpox discourse: BERTopic based mixed-method analyses of tweets from sexual minority men and gender diverse (SMMGD) individuals in the U.S OBJECTIVES: To synthesize discussions among sexual minority men and gender diverse (SMMGD) individuals on mpox, given limited representation of SMMGD voices in existing mpox literature.
METHODS: BERTopic (a topic modeling technique) was employed with human validations to analyze mpox-related tweets (n = 8,688; October 2020-September 2022) from 2,326 self-identified SMMGD individuals in the U.S.; followed by content analysis and geographic analysis.
RESULTS: BERTopic identified 11 topics: health activism (29.81%); mpox vaccination (25.81%) and adverse events (0.98%); sarcasm, jokes, emotional expressions (14.04%); COVID-19 and mpox (7.32%); government/public health response (6.12%); mpox symptoms (2.74%); case reports (2.21%); puns on the virus' naming (i.e., monkeypox; 0.86%); media publicity (0.68%); mpox in children (0.67%). Mpox health activism negatively correlated with LGB social climate index at U.S. state level, ρ = -0.322, p = 0.031.
CONCLUSIONS: SMMGD discussions on mpox encompassed utilitarian (e.g., vaccine access, case reports, mpox symptoms) and emotionally-charged themes-advocating against homophobia, misinformation, and stigma. Mpox health activism was more prevalent in states with lower LGB social acceptance.
PUBLIC HEALTH IMPLICATIONS: Findings illuminate SMMGD engagement with mpox discourse, underscoring the need for more inclusive health communication strategies in infectious disease outbreaks to control associated stigma.",0,1
37461046,"Global incidence, prevalence and disease burden of silicosis: 30 years' overview and forecasted trends","Liu X, Jiang Q, Wu P, Han L, Zhou P.",BMC Public Health. 2023 Jul 17;23(1):1366. doi: 10.1186/s12889-023-16295-2.,Liu X,BMC Public Health,2023,17-07-2023,PMC10353232,,10.1186/s12889-023-16295-2,"BACKGROUND: Globally, silicosis accounts for 90% of all pneumoconiosis cases and is a serious public health issue. It is characterized by progressive inflammation and irreversible pulmonary fibrosis. A comprehensive analysis at temporal, spatial and population levels with the most updated data from GBD 2019 is provided in this study to estimate the disease burden of silicosis from 1990 to 2019 and make predictions to 2029.
METHODS: We delineated silicosis data on incidence, prevalence, and disability-adjusted life years (DALYs) as well as age-standardized rates (ASRs) across 30 years from GBD 2019. Joinpoint regression analysis was employed to detect temporal changes and estimate annual percentage change (APC) of each trend segment. Measures were stratified by time, location, age, and sociodemographic index (SDI). Back propagation artificial neural network (BP-ANN) model was applied to elaborate ASR trends from 1990 to 2019 and projections to the next 10 years.
RESULTS: Globally, silicosis incident, prevalent cases, and DALYs increased by 64.6%, 91.4%, and 20.8%, respectively. However, all the corresponding ASRs showed overall downward trends with an estimated average APC (AAPC) of -0.5(-0.7 to -0.3), -0.2(-0.5 to 0.0), and - 2.0(-2.2 to -1.8), respectively. Middle and high-middle SDI regions carried the heaviest disease burden. The highest disease burden of silicosis was mainly transferred to the older from 1990 to 2019. The trend of ASRs demonstrated a rapid decline between 2005 and 2019, followed by a continuous decline until 2029.
CONCLUSION: Though disease burden of silicosis has been on a decline in general from 1990 to 2019, which shows a promising prospect but cannot be ignored. We should pay more attention to implementing preventive tactics and improving the life quality of present sufferers.","Global incidence, prevalence and disease burden of silicosis: 30 years' overview and forecasted trends BACKGROUND: Globally, silicosis accounts for 90% of all pneumoconiosis cases and is a serious public health issue. It is characterized by progressive inflammation and irreversible pulmonary fibrosis. A comprehensive analysis at temporal, spatial and population levels with the most updated data from GBD 2019 is provided in this study to estimate the disease burden of silicosis from 1990 to 2019 and make predictions to 2029.
METHODS: We delineated silicosis data on incidence, prevalence, and disability-adjusted life years (DALYs) as well as age-standardized rates (ASRs) across 30 years from GBD 2019. Joinpoint regression analysis was employed to detect temporal changes and estimate annual percentage change (APC) of each trend segment. Measures were stratified by time, location, age, and sociodemographic index (SDI). Back propagation artificial neural network (BP-ANN) model was applied to elaborate ASR trends from 1990 to 2019 and projections to the next 10 years.
RESULTS: Globally, silicosis incident, prevalent cases, and DALYs increased by 64.6%, 91.4%, and 20.8%, respectively. However, all the corresponding ASRs showed overall downward trends with an estimated average APC (AAPC) of -0.5(-0.7 to -0.3), -0.2(-0.5 to 0.0), and - 2.0(-2.2 to -1.8), respectively. Middle and high-middle SDI regions carried the heaviest disease burden. The highest disease burden of silicosis was mainly transferred to the older from 1990 to 2019. The trend of ASRs demonstrated a rapid decline between 2005 and 2019, followed by a continuous decline until 2029.
CONCLUSION: Though disease burden of silicosis has been on a decline in general from 1990 to 2019, which shows a promising prospect but cannot be ignored. We should pay more attention to implementing preventive tactics and improving the life quality of present sufferers.",1,0
36798683,"Epidemiology, pathophysiology, and classification of the neurological symptoms of post-COVID-19 syndrome","Carod-Artal FJ, García-Moncó JC.",Neurol Perspect. 2021 Dec;1:S5-S15. doi: 10.1016/j.neurop.2021.07.005. Epub 2021 Dec 14.,Carod-Artal FJ,Neurol Perspect,2021,17-02-2023,PMC8669691,,10.1016/j.neurop.2021.07.005,"INTRODUCTION: Post-COVID-19 syndrome is a series of chronic signs and symptoms that may appear after SARS-CoV-2 infection, including fatigue, dyspnoea, chest pain, palpitations, anxiety, depression, and joint and muscle pain. The purpose of this study was to review the controversies on post-COVID-19 syndrome, the frequency of neurological symptoms, and the potential pathophysiological mechanisms.
METHODS: We present a narrative review of studies published in PubMed since the beginning of the pandemic (January 2020-July 2021).
RESULTS: Patients with history of COVID-19 have been found to present persistent neurological symptoms, including cognitive complaints, memory and concentration problems, headache, anosmia, ageusia, vertigo, and insomnia. Post-COVID-19 syndrome is a heterogeneous disease that lacks a universally accepted definition, which may explain the great variability in the estimated prevalence (2.3%-85%) and symptom duration. The criteria differentiating post-COVID-19 syndrome from chronic fatigue syndrome or critical illness syndrome are ambiguous. Risk factors include older age, female sex, certain comorbidities, and greater number of symptoms in the acute phase. The pathophysiology of the syndrome is largely unknown, although it is probably multifactorial, including immunological mechanisms, neural network dysfunction, neurotransmitter alterations, persistent viral damage, and functional impairment.
CONCLUSIONS: Post-COVID-19 syndrome may present after mild or even asymptomatic SARS-CoV-2 infection, causing limitations in activities of daily living and in quality of life. Further research will clarify the origin and most appropriate management of these neurological alterations.","Epidemiology, pathophysiology, and classification of the neurological symptoms of post-COVID-19 syndrome INTRODUCTION: Post-COVID-19 syndrome is a series of chronic signs and symptoms that may appear after SARS-CoV-2 infection, including fatigue, dyspnoea, chest pain, palpitations, anxiety, depression, and joint and muscle pain. The purpose of this study was to review the controversies on post-COVID-19 syndrome, the frequency of neurological symptoms, and the potential pathophysiological mechanisms.
METHODS: We present a narrative review of studies published in PubMed since the beginning of the pandemic (January 2020-July 2021).
RESULTS: Patients with history of COVID-19 have been found to present persistent neurological symptoms, including cognitive complaints, memory and concentration problems, headache, anosmia, ageusia, vertigo, and insomnia. Post-COVID-19 syndrome is a heterogeneous disease that lacks a universally accepted definition, which may explain the great variability in the estimated prevalence (2.3%-85%) and symptom duration. The criteria differentiating post-COVID-19 syndrome from chronic fatigue syndrome or critical illness syndrome are ambiguous. Risk factors include older age, female sex, certain comorbidities, and greater number of symptoms in the acute phase. The pathophysiology of the syndrome is largely unknown, although it is probably multifactorial, including immunological mechanisms, neural network dysfunction, neurotransmitter alterations, persistent viral damage, and functional impairment.
CONCLUSIONS: Post-COVID-19 syndrome may present after mild or even asymptomatic SARS-CoV-2 infection, causing limitations in activities of daily living and in quality of life. Further research will clarify the origin and most appropriate management of these neurological alterations.",0,0
33726693,Artificial neural network model to predict post-hepatectomy early recurrence of hepatocellular carcinoma without macroscopic vascular invasion,"Mai RY, Zeng J, Meng WD, Lu HZ, Liang R, Lin Y, Wu GB, Li LQ, Ma L, Ye JZ, Bai T.",BMC Cancer. 2021 Mar 16;21(1):283. doi: 10.1186/s12885-021-07969-4.,Mai RY,BMC Cancer,2021,17-03-2021,PMC7962237,,10.1186/s12885-021-07969-4,"BACKGROUND: The accurate prediction of post-hepatectomy early recurrence (PHER) of hepatocellular carcinoma (HCC) is vital in determining postoperative adjuvant treatment and monitoring. This study aimed to develop and validate an artificial neural network (ANN) model to predict PHER in HCC patients without macroscopic vascular invasion.
METHODS: Nine hundred and three patients who underwent curative liver resection for HCC participated in this study. They were randomly divided into derivation (n = 679) and validation (n = 224) cohorts. The ANN model was developed in the derivation cohort and subsequently verified in the validation cohort.
RESULTS: PHER morbidity in the derivation and validation cohorts was 34.8 and 39.2%, respectively. A multivariable analysis revealed that hepatitis B virus deoxyribonucleic acid load, γ-glutamyl transpeptidase level, α-fetoprotein level, tumor size, tumor differentiation, microvascular invasion, satellite nodules, and blood loss were significantly associated with PHER. These factors were incorporated into an ANN model, which displayed greater discriminatory abilities than a Cox's proportional hazards model, preexisting recurrence models, and commonly used staging systems for predicting PHER. The recurrence-free survival curves were significantly different between patients that had been stratified into two risk groups.
CONCLUSION: When compared to other models and staging systems, the ANN model has a significant advantage in predicting PHER for HCC patients without macroscopic vascular invasion.","Artificial neural network model to predict post-hepatectomy early recurrence of hepatocellular carcinoma without macroscopic vascular invasion BACKGROUND: The accurate prediction of post-hepatectomy early recurrence (PHER) of hepatocellular carcinoma (HCC) is vital in determining postoperative adjuvant treatment and monitoring. This study aimed to develop and validate an artificial neural network (ANN) model to predict PHER in HCC patients without macroscopic vascular invasion.
METHODS: Nine hundred and three patients who underwent curative liver resection for HCC participated in this study. They were randomly divided into derivation (n = 679) and validation (n = 224) cohorts. The ANN model was developed in the derivation cohort and subsequently verified in the validation cohort.
RESULTS: PHER morbidity in the derivation and validation cohorts was 34.8 and 39.2%, respectively. A multivariable analysis revealed that hepatitis B virus deoxyribonucleic acid load, γ-glutamyl transpeptidase level, α-fetoprotein level, tumor size, tumor differentiation, microvascular invasion, satellite nodules, and blood loss were significantly associated with PHER. These factors were incorporated into an ANN model, which displayed greater discriminatory abilities than a Cox's proportional hazards model, preexisting recurrence models, and commonly used staging systems for predicting PHER. The recurrence-free survival curves were significantly different between patients that had been stratified into two risk groups.
CONCLUSION: When compared to other models and staging systems, the ANN model has a significant advantage in predicting PHER for HCC patients without macroscopic vascular invasion.",0,0
35421101,Dissecting recurrent waves of pertussis across the boroughs of London,"Saeidpour A, Bansal S, Rohani P.",PLoS Comput Biol. 2022 Apr 14;18(4):e1009898. doi: 10.1371/journal.pcbi.1009898. eCollection 2022 Apr.,Saeidpour A,PLoS Comput Biol,2022,14-04-2022,PMC9041754,,10.1371/journal.pcbi.1009898,"Pertussis has resurfaced in the UK, with incidence levels not seen since the 1980s. While the fundamental causes of this resurgence remain the subject of much conjecture, the study of historical patterns of pathogen diffusion can be illuminating. Here, we examined time series of pertussis incidence in the boroughs of Greater London from 1982 to 2013 to document the spatial epidemiology of this bacterial infection and to identify the potential drivers of its percolation. The incidence of pertussis over this period is characterized by 3 distinct stages: a period exhibiting declining trends with 4-year inter-epidemic cycles from 1982 to 1994, followed by a deep trough until 2006 and the subsequent resurgence. We observed systematic temporal trends in the age distribution of cases and the fade-out profile of pertussis coincident with increasing national vaccine coverage from 1982 to 1990. To quantify the hierarchy of epidemic phases across the boroughs of London, we used the Hilbert transform. We report a consistent pattern of spatial organization from 1982 to the early 1990s, with some boroughs consistently leading epidemic waves and others routinely lagging. To determine the potential drivers of these geographic patterns, a comprehensive parallel database of borough-specific features was compiled, comprising of demographic, movement and socio-economic factors that were used in statistical analyses to predict epidemic phase relationships among boroughs. Specifically, we used a combination of a feed-forward neural network (FFNN), and SHapley Additive exPlanations (SHAP) values to quantify the contribution of each covariate to model predictions. Our analyses identified a number of predictors of a borough's historical epidemic phase, specifically the age composition of households, the number of agricultural and skilled manual workers, latitude, the population of public transport commuters and high-occupancy households. Univariate regression analysis of the 2012 epidemic identified the ratio of cumulative unvaccinated children to the total population and population of Pakistan-born population to have moderate positive and negative association, respectively, with the timing of epidemic. In addition to providing a comprehensive overview of contemporary pertussis transmission in a large metropolitan population, this study has identified the characteristics that determine the spatial spread of this bacterium across the boroughs of London.","Dissecting recurrent waves of pertussis across the boroughs of London Pertussis has resurfaced in the UK, with incidence levels not seen since the 1980s. While the fundamental causes of this resurgence remain the subject of much conjecture, the study of historical patterns of pathogen diffusion can be illuminating. Here, we examined time series of pertussis incidence in the boroughs of Greater London from 1982 to 2013 to document the spatial epidemiology of this bacterial infection and to identify the potential drivers of its percolation. The incidence of pertussis over this period is characterized by 3 distinct stages: a period exhibiting declining trends with 4-year inter-epidemic cycles from 1982 to 1994, followed by a deep trough until 2006 and the subsequent resurgence. We observed systematic temporal trends in the age distribution of cases and the fade-out profile of pertussis coincident with increasing national vaccine coverage from 1982 to 1990. To quantify the hierarchy of epidemic phases across the boroughs of London, we used the Hilbert transform. We report a consistent pattern of spatial organization from 1982 to the early 1990s, with some boroughs consistently leading epidemic waves and others routinely lagging. To determine the potential drivers of these geographic patterns, a comprehensive parallel database of borough-specific features was compiled, comprising of demographic, movement and socio-economic factors that were used in statistical analyses to predict epidemic phase relationships among boroughs. Specifically, we used a combination of a feed-forward neural network (FFNN), and SHapley Additive exPlanations (SHAP) values to quantify the contribution of each covariate to model predictions. Our analyses identified a number of predictors of a borough's historical epidemic phase, specifically the age composition of households, the number of agricultural and skilled manual workers, latitude, the population of public transport commuters and high-occupancy households. Univariate regression analysis of the 2012 epidemic identified the ratio of cumulative unvaccinated children to the total population and population of Pakistan-born population to have moderate positive and negative association, respectively, with the timing of epidemic. In addition to providing a comprehensive overview of contemporary pertussis transmission in a large metropolitan population, this study has identified the characteristics that determine the spatial spread of this bacterium across the boroughs of London.",0,1
32188419,Artificial neural network-based models used for predicting 28- and 90-day mortality of patients with hepatitis B-associated acute-on-chronic liver failure,"Hou Y, Zhang Q, Gao F, Mao D, Li J, Gong Z, Luo X, Chen G, Li Y, Yang Z, Sun K, Wang X.",BMC Gastroenterol. 2020 Mar 13;20(1):75. doi: 10.1186/s12876-020-01191-5.,Hou Y,BMC Gastroenterol,2020,20-03-2020,PMC7081680,,10.1186/s12876-020-01191-5,"BACKGROUND: This study aimed to develop prognostic models for predicting 28- and 90-day mortality rates of hepatitis B virus (HBV)-associated acute-on-chronic liver failure (HBV-ACLF) through artificial neural network (ANN) systems.
METHODS: Six hundred and eight-four cases of consecutive HBV-ACLF patients were retrospectively reviewed. Four hundred and twenty-three cases were used for training and constructing ANN models, and the remaining 261 cases were for validating the established models. Predictors associated with mortality were determined by univariate analysis and were then included in ANN models for predicting prognosis of mortality. The receiver operating characteristic curve analysis was used to evaluate the predictive performance of the ANN models in comparison with various current prognostic models.
RESULTS: Variables with statistically significant difference or important clinical characteristics were input in the ANN training process, and eight independent risk factors, including age, hepatic encephalopathy, serum sodium, prothrombin activity, γ-glutamyltransferase, hepatitis B e antigen, alkaline phosphatase and total bilirubin, were eventually used to establish ANN models. For 28-day mortality in the training cohort, the model's predictive accuracy (AUR 0.948, 95% CI 0.925-0.970) was significantly higher than that of the Model for End-stage Liver Disease (MELD), MELD-sodium (MELD-Na), Chronic Liver Failure-ACLF (CLIF-ACLF), and Child-Turcotte-Pugh (CTP) (all p < 0.001). In the validation cohorts the predictive accuracy of ANN model (AUR 0.748, 95% CI: 0.673-0.822) was significantly higher than that of MELD (p = 0.0099) and insignificantly higher than that of MELD-Na, CTP and CLIF-ACLF (p > 0.05). For 90-day mortality in the training cohort, the model's predictive accuracy (AUR 0.913, 95% CI 0.887-0.938) was significantly higher than that of MELD, MELD-Na, CTP and CLIF-ACLF (all p < 0.001). In the validation cohorts, the prediction accuracy of the ANN model (AUR 0.754, 95% CI: 0.697-0.812 was significantly higher than that of MELD (p = 0.019) and insignificantly higher than MELD-Na, CTP and CLIF-ACLF (p > 0.05).
CONCLUSIONS: The established ANN models can more accurately predict short-term mortality risk in patients with HBV- ACLF. The main content has been postered as an abstract at the AASLD Hepatology Conference (https://doi.org/10.1002/hep.30257).","Artificial neural network-based models used for predicting 28- and 90-day mortality of patients with hepatitis B-associated acute-on-chronic liver failure BACKGROUND: This study aimed to develop prognostic models for predicting 28- and 90-day mortality rates of hepatitis B virus (HBV)-associated acute-on-chronic liver failure (HBV-ACLF) through artificial neural network (ANN) systems.
METHODS: Six hundred and eight-four cases of consecutive HBV-ACLF patients were retrospectively reviewed. Four hundred and twenty-three cases were used for training and constructing ANN models, and the remaining 261 cases were for validating the established models. Predictors associated with mortality were determined by univariate analysis and were then included in ANN models for predicting prognosis of mortality. The receiver operating characteristic curve analysis was used to evaluate the predictive performance of the ANN models in comparison with various current prognostic models.
RESULTS: Variables with statistically significant difference or important clinical characteristics were input in the ANN training process, and eight independent risk factors, including age, hepatic encephalopathy, serum sodium, prothrombin activity, γ-glutamyltransferase, hepatitis B e antigen, alkaline phosphatase and total bilirubin, were eventually used to establish ANN models. For 28-day mortality in the training cohort, the model's predictive accuracy (AUR 0.948, 95% CI 0.925-0.970) was significantly higher than that of the Model for End-stage Liver Disease (MELD), MELD-sodium (MELD-Na), Chronic Liver Failure-ACLF (CLIF-ACLF), and Child-Turcotte-Pugh (CTP) (all p < 0.001). In the validation cohorts the predictive accuracy of ANN model (AUR 0.748, 95% CI: 0.673-0.822) was significantly higher than that of MELD (p = 0.0099) and insignificantly higher than that of MELD-Na, CTP and CLIF-ACLF (p > 0.05). For 90-day mortality in the training cohort, the model's predictive accuracy (AUR 0.913, 95% CI 0.887-0.938) was significantly higher than that of MELD, MELD-Na, CTP and CLIF-ACLF (all p < 0.001). In the validation cohorts, the prediction accuracy of the ANN model (AUR 0.754, 95% CI: 0.697-0.812 was significantly higher than that of MELD (p = 0.019) and insignificantly higher than MELD-Na, CTP and CLIF-ACLF (p > 0.05).
CONCLUSIONS: The established ANN models can more accurately predict short-term mortality risk in patients with HBV- ACLF. The main content has been postered as an abstract at the AASLD Hepatology Conference (https://doi.org/10.1002/hep.30257).",1,1
32132525,A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections,"Mayhew MB, Buturovic L, Luethy R, Midic U, Moore AR, Roque JA, Shaller BD, Asuni T, Rawling D, Remmel M, Choi K, Wacker J, Khatri P, Rogers AJ, Sweeney TE.",Nat Commun. 2020 Mar 4;11(1):1177. doi: 10.1038/s41467-020-14975-w.,Mayhew MB,Nat Commun,2020,06-03-2020,PMC7055276,,10.1038/s41467-020-14975-w,"Improved identification of bacterial and viral infections would reduce morbidity from sepsis, reduce antibiotic overuse, and lower healthcare costs. Here, we develop a generalizable host-gene-expression-based classifier for acute bacterial and viral infections. We use training data (N = 1069) from 18 retrospective transcriptomic studies. Using only 29 preselected host mRNAs, we train a neural-network classifier with a bacterial-vs-other area under the receiver-operating characteristic curve (AUROC) 0.92 (95% CI 0.90-0.93) and a viral-vs-other AUROC 0.92 (95% CI 0.90-0.93). We then apply this classifier, inflammatix-bacterial-viral-noninfected-version 1 (IMX-BVN-1), without retraining, to an independent cohort (N = 163). In this cohort, IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.86 (95% CI 0.77-0.93), and viral-vs.-other 0.85 (95% CI 0.76-0.93). In patients enrolled within 36 h of hospital admission (N = 70), IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.92 (95% CI 0.83-0.99), and viral-vs.-other 0.91 (95% CI 0.82-0.98). With further study, IMX-BVN-1 could provide a tool for assessing patients with suspected infection and sepsis at hospital admission.","A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections Improved identification of bacterial and viral infections would reduce morbidity from sepsis, reduce antibiotic overuse, and lower healthcare costs. Here, we develop a generalizable host-gene-expression-based classifier for acute bacterial and viral infections. We use training data (N = 1069) from 18 retrospective transcriptomic studies. Using only 29 preselected host mRNAs, we train a neural-network classifier with a bacterial-vs-other area under the receiver-operating characteristic curve (AUROC) 0.92 (95% CI 0.90-0.93) and a viral-vs-other AUROC 0.92 (95% CI 0.90-0.93). We then apply this classifier, inflammatix-bacterial-viral-noninfected-version 1 (IMX-BVN-1), without retraining, to an independent cohort (N = 163). In this cohort, IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.86 (95% CI 0.77-0.93), and viral-vs.-other 0.85 (95% CI 0.76-0.93). In patients enrolled within 36 h of hospital admission (N = 70), IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.92 (95% CI 0.83-0.99), and viral-vs.-other 0.91 (95% CI 0.82-0.98). With further study, IMX-BVN-1 could provide a tool for assessing patients with suspected infection and sepsis at hospital admission.",0,1
27538955,Network or regression-based methods for disease discrimination: a comparison study,"Zhang X, Yuan Z, Ji J, Li H, Xue F.",BMC Med Res Methodol. 2016 Aug 18;16:100. doi: 10.1186/s12874-016-0207-2.,Zhang X,BMC Med Res Methodol,2016,20-08-2016,PMC4991108,,10.1186/s12874-016-0207-2,"BACKGROUND: In stark contrast to network-centric view for complex disease, regression-based methods are preferred in disease prediction, especially for epidemiologists and clinical professionals. It remains a controversy whether the network-based methods have advantageous performance than regression-based methods, and to what extent do they outperform.
METHODS: Simulations under different scenarios (the input variables are independent or in network relationship) as well as an application were conducted to assess the prediction performance of four typical methods including Bayesian network, neural network, logistic regression and regression splines.
RESULTS: The simulation results reveal that Bayesian network showed a better performance when the variables were in a network relationship or in a chain structure. For the special wheel network structure, logistic regression had a considerable performance compared to others. Further application on GWAS of leprosy show Bayesian network still outperforms other methods.
CONCLUSION: Although regression-based methods are still popular and widely used, network-based approaches should be paid more attention, since they capture the complex relationship between variables.","Network or regression-based methods for disease discrimination: a comparison study BACKGROUND: In stark contrast to network-centric view for complex disease, regression-based methods are preferred in disease prediction, especially for epidemiologists and clinical professionals. It remains a controversy whether the network-based methods have advantageous performance than regression-based methods, and to what extent do they outperform.
METHODS: Simulations under different scenarios (the input variables are independent or in network relationship) as well as an application were conducted to assess the prediction performance of four typical methods including Bayesian network, neural network, logistic regression and regression splines.
RESULTS: The simulation results reveal that Bayesian network showed a better performance when the variables were in a network relationship or in a chain structure. For the special wheel network structure, logistic regression had a considerable performance compared to others. Further application on GWAS of leprosy show Bayesian network still outperforms other methods.
CONCLUSION: Although regression-based methods are still popular and widely used, network-based approaches should be paid more attention, since they capture the complex relationship between variables.",0,0
32853285,"Predicting and analyzing the COVID-19 epidemic in China: Based on SEIRD, LSTM and GWR models","Liu F, Wang J, Liu J, Li Y, Liu D, Tong J, Li Z, Yu D, Fan Y, Bi X, Zhang X, Mo S.",PLoS One. 2020 Aug 27;15(8):e0238280. doi: 10.1371/journal.pone.0238280. eCollection 2020.,Liu F,PLoS One,2020,28-08-2020,PMC7451659,,10.1371/journal.pone.0238280,"In December 2019, the novel coronavirus pneumonia (COVID-19) occurred in Wuhan, Hubei Province, China. The epidemic quickly broke out and spread throughout the country. Now it becomes a pandemic that affects the whole world. In this study, three models were used to fit and predict the epidemic situation in China: a modified SEIRD (Susceptible-Exposed-Infected-Recovered-Dead) dynamic model, a neural network method LSTM (Long Short-Term Memory), and a GWR (Geographically Weighted Regression) model reflecting spatial heterogeneity. Overall, all the three models performed well with great accuracy. The dynamic SEIRD prediction APE (absolute percent error) of China had been ≤ 1.0% since Mid-February. The LSTM model showed comparable accuracy. The GWR model took into account the influence of geographical differences, with R2 = 99.98% in fitting and 97.95% in prediction. Wilcoxon test showed that none of the three models outperformed the other two at the significance level of 0.05. The parametric analysis of the infectious rate and recovery rate demonstrated that China's national policies had effectively slowed down the spread of the epidemic. Furthermore, the models in this study provided a wide range of implications for other countries to predict the short-term and long-term trend of COVID-19, and to evaluate the intensity and effect of their interventions.","Predicting and analyzing the COVID-19 epidemic in China: Based on SEIRD, LSTM and GWR models In December 2019, the novel coronavirus pneumonia (COVID-19) occurred in Wuhan, Hubei Province, China. The epidemic quickly broke out and spread throughout the country. Now it becomes a pandemic that affects the whole world. In this study, three models were used to fit and predict the epidemic situation in China: a modified SEIRD (Susceptible-Exposed-Infected-Recovered-Dead) dynamic model, a neural network method LSTM (Long Short-Term Memory), and a GWR (Geographically Weighted Regression) model reflecting spatial heterogeneity. Overall, all the three models performed well with great accuracy. The dynamic SEIRD prediction APE (absolute percent error) of China had been ≤ 1.0% since Mid-February. The LSTM model showed comparable accuracy. The GWR model took into account the influence of geographical differences, with R2 = 99.98% in fitting and 97.95% in prediction. Wilcoxon test showed that none of the three models outperformed the other two at the significance level of 0.05. The parametric analysis of the infectious rate and recovery rate demonstrated that China's national policies had effectively slowed down the spread of the epidemic. Furthermore, the models in this study provided a wide range of implications for other countries to predict the short-term and long-term trend of COVID-19, and to evaluate the intensity and effect of their interventions.",1,1
34260529,An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission: Development and validation study,"Lin JK, Chien TW, Wang LY, Chou W.",Medicine (Baltimore). 2021 Jul 16;100(28):e26532. doi: 10.1097/MD.0000000000026532.,Lin JK,Medicine (Baltimore),2021,14-07-2021,PMC8284724,,10.1097/MD.0000000000026532,"BACKGROUND:: In a pandemic situation (e.g., COVID-19), the most important issue is to select patients at risk of high mortality at an early stage and to provide appropriate treatments. However, a few studies applied the model to predict in-hospital mortality using routine blood samples at the time of hospital admission. This study aimed to develop an app, name predict the mortality of COVID-19 patients (PMCP) app, to predict the mortality of COVID-19 patients at hospital-admission time.
METHODS:: We downloaded patient records from 2 studies, including 361 COVID-19 patients in Wuhan, China, and 106 COVID-19 patients in 3 Korean medical institutions. A total of 30 feature variables were retrieved, consisting of 28 blood biomarkers and 2 demographic variables (i.e., age and gender) of patients. Two models, namely, artificial neural network (ANN) and convolutional neural network (CNN), were compared with each other across 2 scenarios using: 1. raw laboratory versus normalized data and 2. training vs testing datasets (n = 361 and n = 106/361≅30%) to verify the model performance (e.g., sensitivity [SENS], specificity [SPEC], and area under the receiver operating characteristic curve [AUC]). An app for predicting the mortality of COVID-19 patients was developed using the model's estimated parameters for the prediction and classification of PMCP at an earlier stage. Feature variables and prediction results were visualized using the forest plot and category probability curves shown on Google Maps.
RESULTS:: We observed that: 1. the normalized dataset gains a relatively higher AUC(>0.9) when compared to that(<0.9) in the raw-laboratory dataset based on training data, 2. the normalized dataset in ANN yielded a high AUC of 0.96 that that(=0.91) in CNN based on testing data, and 3. a ready and available app, where anyone can access the model to predict mortality, for PMCP was developed in this study.
CONCLUSIONS:: Our new PMCP app with ANN model accurately predicts the mortality probability for COVID-19 patients. It is publicly available and aims to help health care providers fight COVID-19 and improve patients’ classifications against treatment risk.","An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission: Development and validation study BACKGROUND:: In a pandemic situation (e.g., COVID-19), the most important issue is to select patients at risk of high mortality at an early stage and to provide appropriate treatments. However, a few studies applied the model to predict in-hospital mortality using routine blood samples at the time of hospital admission. This study aimed to develop an app, name predict the mortality of COVID-19 patients (PMCP) app, to predict the mortality of COVID-19 patients at hospital-admission time.
METHODS:: We downloaded patient records from 2 studies, including 361 COVID-19 patients in Wuhan, China, and 106 COVID-19 patients in 3 Korean medical institutions. A total of 30 feature variables were retrieved, consisting of 28 blood biomarkers and 2 demographic variables (i.e., age and gender) of patients. Two models, namely, artificial neural network (ANN) and convolutional neural network (CNN), were compared with each other across 2 scenarios using: 1. raw laboratory versus normalized data and 2. training vs testing datasets (n = 361 and n = 106/361≅30%) to verify the model performance (e.g., sensitivity [SENS], specificity [SPEC], and area under the receiver operating characteristic curve [AUC]). An app for predicting the mortality of COVID-19 patients was developed using the model's estimated parameters for the prediction and classification of PMCP at an earlier stage. Feature variables and prediction results were visualized using the forest plot and category probability curves shown on Google Maps.
RESULTS:: We observed that: 1. the normalized dataset gains a relatively higher AUC(>0.9) when compared to that(<0.9) in the raw-laboratory dataset based on training data, 2. the normalized dataset in ANN yielded a high AUC of 0.96 that that(=0.91) in CNN based on testing data, and 3. a ready and available app, where anyone can access the model to predict mortality, for PMCP was developed in this study.
CONCLUSIONS:: Our new PMCP app with ANN model accurately predicts the mortality probability for COVID-19 patients. It is publicly available and aims to help health care providers fight COVID-19 and improve patients’ classifications against treatment risk.",0,1
26940103,Salmonella infections modelling in Mississippi using neural network and geographical information system (GIS),"Akil L, Ahmad HA.",BMJ Open. 2016 Mar 3;6(3):e009255. doi: 10.1136/bmjopen-2015-009255.,Akil L,BMJ Open,2016,05-03-2016,PMC4785344,,10.1136/bmjopen-2015-009255,"OBJECTIVES: Mississippi (MS) is one of the southern states with high rates of foodborne infections. The objectives of this paper are to determine the extent of Salmonella and Escherichia coli infections in MS, and determine the Salmonella infections correlation with socioeconomic status using geographical information system (GIS) and neural network models.
METHODS: In this study, the relevant updated data of foodborne illness for southern states, from 2002 to 2011, were collected and used in the GIS and neural networks models. Data were collected from the Centers for Disease Control and Prevention (CDC), MS state Department of Health and the other states department of health. The correlation between low socioeconomic status and Salmonella infections were determined using models created by several software packages, including SAS, ArcGIS @RISK and NeuroShell.
RESULTS: Results of this study showed a significant increase in Salmonella outbreaks in MS during the study period, with highest rates in 2011 (47.84 ± 24.41 cases/100,000; p<0.001). MS had the highest rates of Salmonella outbreaks compared with other states (36 ± 6.29 cases/100,000; p<0.001). Regional and district variations in the rates were also observed. GIS maps of Salmonella outbreaks in MS in 2010 and 2011 showed the districts with higher rates of Salmonella. Regression analysis and neural network models showed a moderate correlation between cases of Salmonella infections and low socioeconomic factors. Poverty was shown to have a negative correlation with Salmonella outbreaks (R(2)=0.152, p<0.05).
CONCLUSIONS: Geographic location besides socioeconomic status may contribute to the high rates of Salmonella outbreaks in MS. Understanding the geographical and economic relationship with infectious diseases will help to determine effective methods to reduce outbreaks within low socioeconomic status communities.","Salmonella infections modelling in Mississippi using neural network and geographical information system (GIS) OBJECTIVES: Mississippi (MS) is one of the southern states with high rates of foodborne infections. The objectives of this paper are to determine the extent of Salmonella and Escherichia coli infections in MS, and determine the Salmonella infections correlation with socioeconomic status using geographical information system (GIS) and neural network models.
METHODS: In this study, the relevant updated data of foodborne illness for southern states, from 2002 to 2011, were collected and used in the GIS and neural networks models. Data were collected from the Centers for Disease Control and Prevention (CDC), MS state Department of Health and the other states department of health. The correlation between low socioeconomic status and Salmonella infections were determined using models created by several software packages, including SAS, ArcGIS @RISK and NeuroShell.
RESULTS: Results of this study showed a significant increase in Salmonella outbreaks in MS during the study period, with highest rates in 2011 (47.84 ± 24.41 cases/100,000; p<0.001). MS had the highest rates of Salmonella outbreaks compared with other states (36 ± 6.29 cases/100,000; p<0.001). Regional and district variations in the rates were also observed. GIS maps of Salmonella outbreaks in MS in 2010 and 2011 showed the districts with higher rates of Salmonella. Regression analysis and neural network models showed a moderate correlation between cases of Salmonella infections and low socioeconomic factors. Poverty was shown to have a negative correlation with Salmonella outbreaks (R(2)=0.152, p<0.05).
CONCLUSIONS: Geographic location besides socioeconomic status may contribute to the high rates of Salmonella outbreaks in MS. Understanding the geographical and economic relationship with infectious diseases will help to determine effective methods to reduce outbreaks within low socioeconomic status communities.",0,1
38190131,Effect of Remote and Virtual Technology on Home Dialysis,"Lew SQ, Manani SM, Ronco C, Rosner MH, Sloand JA.",Clin J Am Soc Nephrol. 2024 Oct 1;19(10):1330-1337. doi: 10.2215/CJN.0000000000000405. Epub 2024 Jan 22.,Lew SQ,Clin J Am Soc Nephrol,2024,08-01-2024,PMC11469790,,10.2215/CJN.0000000000000405,"In the United States, regulatory changes dictate telehealth activities. Telehealth was available to patients on home dialysis as early as 2019, allowing patients to opt for telehealth with home as the originating site and without geographic restriction. In 2020, coronavirus disease 2019 was an unexpected accelerant for telehealth use in the United States. Within nephrology, remote patient monitoring has most often been applied to the care of patients on home dialysis modalities. The effect that remote and virtual technologies have on home dialysis patients, telehealth and health care disparities, and health care providers' workflow changes are discussed here. Moreover, the future use of remote and virtual technologies to include artificial intelligence and artificial neural network model to optimize and personalize treatments will be highlighted. Despite these advances in technology challenges continue to exist, leaving room for future innovation to improve patient health outcome and equity. Prospective studies are needed to further understand the effect of using virtual technologies and remote monitoring on home dialysis outcomes, cost, and patient engagement.","Effect of Remote and Virtual Technology on Home Dialysis In the United States, regulatory changes dictate telehealth activities. Telehealth was available to patients on home dialysis as early as 2019, allowing patients to opt for telehealth with home as the originating site and without geographic restriction. In 2020, coronavirus disease 2019 was an unexpected accelerant for telehealth use in the United States. Within nephrology, remote patient monitoring has most often been applied to the care of patients on home dialysis modalities. The effect that remote and virtual technologies have on home dialysis patients, telehealth and health care disparities, and health care providers' workflow changes are discussed here. Moreover, the future use of remote and virtual technologies to include artificial intelligence and artificial neural network model to optimize and personalize treatments will be highlighted. Despite these advances in technology challenges continue to exist, leaving room for future innovation to improve patient health outcome and equity. Prospective studies are needed to further understand the effect of using virtual technologies and remote monitoring on home dialysis outcomes, cost, and patient engagement.",0,0
31600206,Management of insecticide resistance in the major Aedes vectors of arboviruses: Advances and challenges,"Dusfour I, Vontas J, David JP, Weetman D, Fonseca DM, Corbel V, Raghavendra K, Coulibaly MB, Martins AJ, Kasai S, Chandre F.",PLoS Negl Trop Dis. 2019 Oct 10;13(10):e0007615. doi: 10.1371/journal.pntd.0007615. eCollection 2019 Oct.,Dusfour I,PLoS Negl Trop Dis,2019,11-10-2019,PMC6786541,,10.1371/journal.pntd.0007615,"BACKGROUND: The landscape of mosquito-borne disease risk has changed dramatically in recent decades, due to the emergence and reemergence of urban transmission cycles driven by invasive Aedes aegypti and Ae. albopictus. Insecticide resistance is already widespread in the yellow fever mosquito, Ae. Aegypti; is emerging in the Asian tiger mosquito Ae. Albopictus; and is now threatening the global fight against human arboviral diseases such as dengue, yellow fever, chikungunya, and Zika. Because the panel of insecticides available for public health is limited, it is of primary importance to preserve the efficacy of existing and upcoming active ingredients. Timely implementation of insecticide resistance management (IRM) is crucial to maintain the arsenal of effective public health insecticides and sustain arbovirus vector control.
METHODOLOGY AND PRINCIPAL FINDINGS: This Review is one of a series being generated by the Worldwide Insecticide resistance Network (WIN) and aims at defining the principles and concepts underlying IRM, identifying the main factors affecting the evolution of resistance, and evaluating the value of existing tools for resistance monitoring. Based on the lessons taken from resistance strategies used for other vector species and agricultural pests, we propose a framework for the implementation of IRM strategies for Aedes mosquito vectors.
CONCLUSIONS AND SIGNIFICANCE: Although IRM should be a fixture of all vector control programs, it is currently often absent from the strategic plans to control mosquito-borne diseases, especially arboviruses. Experiences from other public health disease vectors and agricultural pests underscore the need for urgent action in implementing IRM for invasive Aedes mosquitoes. Based on a plan developed for malaria vectors, here we propose some key activities to establish a global plan for IRM in Aedes spp.","Management of insecticide resistance in the major Aedes vectors of arboviruses: Advances and challenges BACKGROUND: The landscape of mosquito-borne disease risk has changed dramatically in recent decades, due to the emergence and reemergence of urban transmission cycles driven by invasive Aedes aegypti and Ae. albopictus. Insecticide resistance is already widespread in the yellow fever mosquito, Ae. Aegypti; is emerging in the Asian tiger mosquito Ae. Albopictus; and is now threatening the global fight against human arboviral diseases such as dengue, yellow fever, chikungunya, and Zika. Because the panel of insecticides available for public health is limited, it is of primary importance to preserve the efficacy of existing and upcoming active ingredients. Timely implementation of insecticide resistance management (IRM) is crucial to maintain the arsenal of effective public health insecticides and sustain arbovirus vector control.
METHODOLOGY AND PRINCIPAL FINDINGS: This Review is one of a series being generated by the Worldwide Insecticide resistance Network (WIN) and aims at defining the principles and concepts underlying IRM, identifying the main factors affecting the evolution of resistance, and evaluating the value of existing tools for resistance monitoring. Based on the lessons taken from resistance strategies used for other vector species and agricultural pests, we propose a framework for the implementation of IRM strategies for Aedes mosquito vectors.
CONCLUSIONS AND SIGNIFICANCE: Although IRM should be a fixture of all vector control programs, it is currently often absent from the strategic plans to control mosquito-borne diseases, especially arboviruses. Experiences from other public health disease vectors and agricultural pests underscore the need for urgent action in implementing IRM for invasive Aedes mosquitoes. Based on a plan developed for malaria vectors, here we propose some key activities to establish a global plan for IRM in Aedes spp.",0,0
35954895,The Prediction of Public Risk Perception by Internal Characteristics and External Environment: Machine Learning on Big Data,"Xie Q, Xue Y.",Int J Environ Res Public Health. 2022 Aug 3;19(15):9545. doi: 10.3390/ijerph19159545.,Xie Q,Int J Environ Res Public Health,2022,12-08-2022,PMC9368627,,10.3390/ijerph19159545,"Presently, the public's perception of risk in terms of topical social issues is mainly measured quantitively using a psychological scale, but this approach is not accurate enough for everyday data. In this paper, we explored the ways in which public risk perception can be more accurately predicted in the era of big data. We obtained internal characteristics and external environment predictor variables through a literature review, and then built our prediction model using the machine learning of a BP neural network via three steps: the calculation of the node number of the implication level, a performance test of the BP neural network, and the computation of the weight of every input node. Taking the public risk perception of the Sino-US trade friction and the COVID-19 pandemic in China as research cases, we found that, according to our tests, the node number of the implication level was 15 in terms of the Sino-US trade friction and 14 in terms of the COVID-19 pandemic. Following this, machine learning was conducted, through which we found that the R2 of the BP neural network prediction model was 0.88651 and 0.87125, respectively, for the two cases, which accurately predicted the public's risk perception of the data on a certain day, and simultaneously obtained the weight of every predictor variable in each case. In this paper, we provide comments and suggestions for building a model to predict the public's perception of topical issues.","The Prediction of Public Risk Perception by Internal Characteristics and External Environment: Machine Learning on Big Data Presently, the public's perception of risk in terms of topical social issues is mainly measured quantitively using a psychological scale, but this approach is not accurate enough for everyday data. In this paper, we explored the ways in which public risk perception can be more accurately predicted in the era of big data. We obtained internal characteristics and external environment predictor variables through a literature review, and then built our prediction model using the machine learning of a BP neural network via three steps: the calculation of the node number of the implication level, a performance test of the BP neural network, and the computation of the weight of every input node. Taking the public risk perception of the Sino-US trade friction and the COVID-19 pandemic in China as research cases, we found that, according to our tests, the node number of the implication level was 15 in terms of the Sino-US trade friction and 14 in terms of the COVID-19 pandemic. Following this, machine learning was conducted, through which we found that the R2 of the BP neural network prediction model was 0.88651 and 0.87125, respectively, for the two cases, which accurately predicted the public's risk perception of the data on a certain day, and simultaneously obtained the weight of every predictor variable in each case. In this paper, we provide comments and suggestions for building a model to predict the public's perception of topical issues.",1,1
36231693,Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review,"Saegner T, Austys D.",Int J Environ Res Public Health. 2022 Sep 29;19(19):12394. doi: 10.3390/ijerph191912394.,Saegner T,Int J Environ Res Public Health,2022,14-10-2022,PMC9566212,,10.3390/ijerph191912394,"The probability of future Coronavirus Disease (COVID)-19 waves remains high, thus COVID-19 surveillance and forecasting remains important. Online search engines harvest vast amounts of data from the general population in real time and make these data publicly accessible via such tools as Google Trends (GT). Therefore, the aim of this study was to review the literature about possible use of GT for COVID-19 surveillance and prediction of its outbreaks. We collected and reviewed articles about the possible use of GT for COVID-19 surveillance published in the first 2 years of the pandemic. We resulted in 54 publications that were used in this review. The majority of the studies (83.3%) included in this review showed positive results of the possible use of GT for forecasting COVID-19 outbreaks. Most of the studies were performed in English-speaking countries (61.1%). The most frequently used keyword was ""coronavirus"" (53.7%), followed by ""COVID-19"" (31.5%) and ""COVID"" (20.4%). Many authors have made analyses in multiple countries (46.3%) and obtained the same results for the majority of them, thus showing the robustness of the chosen methods. Various methods including long short-term memory (3.7%), random forest regression (3.7%), Adaboost algorithm (1.9%), autoregressive integrated moving average, neural network autoregression (1.9%), and vector error correction modeling (1.9%) were used for the analysis. It was seen that most of the publications with positive results (72.2%) were using data from the first wave of the COVID-19 pandemic. Later, the search volumes reduced even though the incidence peaked. In most countries, the use of GT data showed to be beneficial for forecasting and surveillance of COVID-19 spread.","Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review The probability of future Coronavirus Disease (COVID)-19 waves remains high, thus COVID-19 surveillance and forecasting remains important. Online search engines harvest vast amounts of data from the general population in real time and make these data publicly accessible via such tools as Google Trends (GT). Therefore, the aim of this study was to review the literature about possible use of GT for COVID-19 surveillance and prediction of its outbreaks. We collected and reviewed articles about the possible use of GT for COVID-19 surveillance published in the first 2 years of the pandemic. We resulted in 54 publications that were used in this review. The majority of the studies (83.3%) included in this review showed positive results of the possible use of GT for forecasting COVID-19 outbreaks. Most of the studies were performed in English-speaking countries (61.1%). The most frequently used keyword was ""coronavirus"" (53.7%), followed by ""COVID-19"" (31.5%) and ""COVID"" (20.4%). Many authors have made analyses in multiple countries (46.3%) and obtained the same results for the majority of them, thus showing the robustness of the chosen methods. Various methods including long short-term memory (3.7%), random forest regression (3.7%), Adaboost algorithm (1.9%), autoregressive integrated moving average, neural network autoregression (1.9%), and vector error correction modeling (1.9%) were used for the analysis. It was seen that most of the publications with positive results (72.2%) were using data from the first wave of the COVID-19 pandemic. Later, the search volumes reduced even though the incidence peaked. In most countries, the use of GT data showed to be beneficial for forecasting and surveillance of COVID-19 spread.",0,1
30173661,"Scoping review on vector-borne diseases in urban areas: transmission dynamics, vectorial capacity and co-infection","Eder M, Cortes F, Teixeira de Siqueira Filha N, Araújo de França GV, Degroote S, Braga C, Ridde V, Turchi Martelli CM.",Infect Dis Poverty. 2018 Sep 3;7(1):90. doi: 10.1186/s40249-018-0475-7.,Eder M,Infect Dis Poverty,2018,04-09-2018,PMC6120094,,10.1186/s40249-018-0475-7,"BACKGROUND: Transmission dynamics, vectorial capacity, and co-infections have substantial impacts on vector-borne diseases (VBDs) affecting urban and suburban populations. Reviewing key factors can provide insight into priority research areas and offer suggestions for potential interventions.
MAIN BODY: Through a scoping review, we identify knowledge gaps on transmission dynamics, vectorial capacity, and co-infections regarding VBDs in urban areas. Peer-reviewed and grey literature published between 2000 and 2016 was searched. We screened abstracts and full texts to select studies. Using an extraction grid, we retrieved general data, results, lessons learned and recommendations, future research avenues, and practice implications. We classified studies by VBD and country/continent and identified relevant knowledge gaps. Of 773 articles selected for full-text screening, 50 were included in the review: 23 based on research in the Americas, 15 in Asia, 10 in Africa, and one each in Europe and Australia. The largest body of evidence concerning VBD epidemiology in urban areas concerned dengue and malaria. Other arboviruses covered included chikungunya and West Nile virus, other parasitic diseases such as leishmaniasis and trypanosomiasis, and bacterial rickettsiosis and plague. Most articles retrieved in our review combined transmission dynamics and vectorial capacity; only two combined transmission dynamics and co-infection. The review identified significant knowledge gaps on the role of asymptomatic individuals, the effects of co-infection and other host factors, and the impacts of climatic, environmental, and socioeconomic factors on VBD transmission in urban areas. Limitations included the trade-off from narrowing the search strategy (missing out on classical modelling studies), a lack of studies on co-infections, most studies being only descriptive, and few offering concrete public health recommendations. More research is needed on transmission risk in homes and workplaces, given increasingly dynamic and mobile populations. The lack of studies on co-infection hampers monitoring of infections transmitted by the same vector.
CONCLUSIONS: Strengthening VBD surveillance and control, particularly in asymptomatic cases and mobile populations, as well as using early warning tools to predict increasing transmission, were key strategies identified for public health policy and practice.","Scoping review on vector-borne diseases in urban areas: transmission dynamics, vectorial capacity and co-infection BACKGROUND: Transmission dynamics, vectorial capacity, and co-infections have substantial impacts on vector-borne diseases (VBDs) affecting urban and suburban populations. Reviewing key factors can provide insight into priority research areas and offer suggestions for potential interventions.
MAIN BODY: Through a scoping review, we identify knowledge gaps on transmission dynamics, vectorial capacity, and co-infections regarding VBDs in urban areas. Peer-reviewed and grey literature published between 2000 and 2016 was searched. We screened abstracts and full texts to select studies. Using an extraction grid, we retrieved general data, results, lessons learned and recommendations, future research avenues, and practice implications. We classified studies by VBD and country/continent and identified relevant knowledge gaps. Of 773 articles selected for full-text screening, 50 were included in the review: 23 based on research in the Americas, 15 in Asia, 10 in Africa, and one each in Europe and Australia. The largest body of evidence concerning VBD epidemiology in urban areas concerned dengue and malaria. Other arboviruses covered included chikungunya and West Nile virus, other parasitic diseases such as leishmaniasis and trypanosomiasis, and bacterial rickettsiosis and plague. Most articles retrieved in our review combined transmission dynamics and vectorial capacity; only two combined transmission dynamics and co-infection. The review identified significant knowledge gaps on the role of asymptomatic individuals, the effects of co-infection and other host factors, and the impacts of climatic, environmental, and socioeconomic factors on VBD transmission in urban areas. Limitations included the trade-off from narrowing the search strategy (missing out on classical modelling studies), a lack of studies on co-infections, most studies being only descriptive, and few offering concrete public health recommendations. More research is needed on transmission risk in homes and workplaces, given increasingly dynamic and mobile populations. The lack of studies on co-infection hampers monitoring of infections transmitted by the same vector.
CONCLUSIONS: Strengthening VBD surveillance and control, particularly in asymptomatic cases and mobile populations, as well as using early warning tools to predict increasing transmission, were key strategies identified for public health policy and practice.",1,0
31209084,Comparison of autoregressive integrated moving average model and generalised regression neural network model for prediction of haemorrhagic fever with renal syndrome in China: a time-series study,"Wang YW, Shen ZZ, Jiang Y.",BMJ Open. 2019 Jun 16;9(6):e025773. doi: 10.1136/bmjopen-2018-025773.,Wang YW,BMJ Open,2019,19-06-2019,PMC6589045,,10.1136/bmjopen-2018-025773,"OBJECTIVES: Haemorrhagic fever with renal syndrome (HFRS) is a serious threat to public health in China, accounting for almost 90% cases reported globally. Infectious disease prediction may help in disease prevention despite some uncontrollable influence factors. This study conducted a comparison between a hybrid model and two single models in forecasting the monthly incidence of HFRS in China.
DESIGN: Time-series study.
SETTING: The People's Republic of China.
METHODS: Autoregressive integrated moving average (ARIMA) model, generalised regression neural network (GRNN) model and hybrid ARIMA-GRNN model were constructed by R V.3.4.3 software. The monthly reported incidence of HFRS from January 2011 to May 2018 were adopted to evaluate models' performance. Root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) were adopted to evaluate these models' effectiveness. Spatial stratified heterogeneity of the time series was tested by month and another GRNN model was built with a new series.
RESULTS: The monthly incidence of HFRS in the past several years showed a slight downtrend and obvious seasonal variation. A total of four plausible ARIMA models were built and ARIMA(2,1,1) (2,1,1)<sub>12</sub> model was selected as the optimal model in HFRS fitting. The smooth factors of the basic GRNN model and the hybrid model were 0.027 and 0.043, respectively. The single ARIMA model was the best in fitting part (MAPE=9.1154, MAE=89.0302, RMSE=138.8356) while the hybrid model was the best in prediction (MAPE=17.8335, MAE=152.3013, RMSE=196.4682). GRNN model was revised by building model with new series and the forecasting performance of revised model (MAPE=17.6095, MAE=163.8000, RMSE=169.4751) was better than original GRNN model (MAPE=19.2029, MAE=177.0356, RMSE=202.1684).
CONCLUSIONS: The hybrid ARIMA-GRNN model was better than single ARIMA and basic GRNN model in forecasting monthly incidence of HFRS in China. It could be considered as a decision-making tool in HFRS prevention and control.","Comparison of autoregressive integrated moving average model and generalised regression neural network model for prediction of haemorrhagic fever with renal syndrome in China: a time-series study OBJECTIVES: Haemorrhagic fever with renal syndrome (HFRS) is a serious threat to public health in China, accounting for almost 90% cases reported globally. Infectious disease prediction may help in disease prevention despite some uncontrollable influence factors. This study conducted a comparison between a hybrid model and two single models in forecasting the monthly incidence of HFRS in China.
DESIGN: Time-series study.
SETTING: The People's Republic of China.
METHODS: Autoregressive integrated moving average (ARIMA) model, generalised regression neural network (GRNN) model and hybrid ARIMA-GRNN model were constructed by R V.3.4.3 software. The monthly reported incidence of HFRS from January 2011 to May 2018 were adopted to evaluate models' performance. Root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) were adopted to evaluate these models' effectiveness. Spatial stratified heterogeneity of the time series was tested by month and another GRNN model was built with a new series.
RESULTS: The monthly incidence of HFRS in the past several years showed a slight downtrend and obvious seasonal variation. A total of four plausible ARIMA models were built and ARIMA(2,1,1) (2,1,1)<sub>12</sub> model was selected as the optimal model in HFRS fitting. The smooth factors of the basic GRNN model and the hybrid model were 0.027 and 0.043, respectively. The single ARIMA model was the best in fitting part (MAPE=9.1154, MAE=89.0302, RMSE=138.8356) while the hybrid model was the best in prediction (MAPE=17.8335, MAE=152.3013, RMSE=196.4682). GRNN model was revised by building model with new series and the forecasting performance of revised model (MAPE=17.6095, MAE=163.8000, RMSE=169.4751) was better than original GRNN model (MAPE=19.2029, MAE=177.0356, RMSE=202.1684).
CONCLUSIONS: The hybrid ARIMA-GRNN model was better than single ARIMA and basic GRNN model in forecasting monthly incidence of HFRS in China. It could be considered as a decision-making tool in HFRS prevention and control.",1,1
32453658,Forecasting tuberculosis using diabetes-related google trends data,"Frauenfeld L, Nann D, Sulyok Z, Feng YS, Sulyok M.",Pathog Glob Health. 2020 Jul;114(5):236-241. doi: 10.1080/20477724.2020.1767854. Epub 2020 May 26.,Frauenfeld L,Pathog Glob Health,2020,27-05-2020,PMC7480530,,10.1080/20477724.2020.1767854,"Online activity-based data can be used to aid infectious disease forecasting. Our aim was to exploit the converging nature of the tuberculosis (TB) and diabetes epidemics to forecast TB case numbers. Thus, we extended TB prediction models based on traditional data with diabetes-related Google searches. We obtained data on the weekly case numbers of TB in Germany from June 8th, 2014, to May 5th, 2019. Internet search data were obtained from a Google Trends (GTD) search for 'diabetes' to the corresponding interval. A seasonal autoregressive moving average (SARIMA) model (0,1,1) (1,0,0) [52] was selected to describe the weekly TB case numbers with and without GTD as an external regressor. We cross-validated the SARIMA models to obtain the root mean squared errors (RMSE). We repeated this procedure with autoregressive feed-forward neural network (NNAR) models using 5-fold cross-validation. To simulate a data-poor surveillance setting, we also tested traditional and GTD-extended models against a hold-out dataset using a decreased 52-week-long period with missing values for training. Cross-validation resulted in an RMSE of 20.83 for the traditional model and 18.56 for the GTD-extended model. Cross-validation of the NNAR models showed a mean RMSE of 19.49 for the traditional model and 18.99 for the GTD-extended model. When we tested the models trained on a decreased dataset with missing values, the GTD-extended models achieved significantly better prediction than the traditional models (p &lt; 0.001). The GTD-extended models outperformed the traditional models in all assessed model evaluation parameters. Using online activity-based data regarding diabetes can improve TB forecasting, but further validation is warranted.","Forecasting tuberculosis using diabetes-related google trends data Online activity-based data can be used to aid infectious disease forecasting. Our aim was to exploit the converging nature of the tuberculosis (TB) and diabetes epidemics to forecast TB case numbers. Thus, we extended TB prediction models based on traditional data with diabetes-related Google searches. We obtained data on the weekly case numbers of TB in Germany from June 8th, 2014, to May 5th, 2019. Internet search data were obtained from a Google Trends (GTD) search for 'diabetes' to the corresponding interval. A seasonal autoregressive moving average (SARIMA) model (0,1,1) (1,0,0) [52] was selected to describe the weekly TB case numbers with and without GTD as an external regressor. We cross-validated the SARIMA models to obtain the root mean squared errors (RMSE). We repeated this procedure with autoregressive feed-forward neural network (NNAR) models using 5-fold cross-validation. To simulate a data-poor surveillance setting, we also tested traditional and GTD-extended models against a hold-out dataset using a decreased 52-week-long period with missing values for training. Cross-validation resulted in an RMSE of 20.83 for the traditional model and 18.56 for the GTD-extended model. Cross-validation of the NNAR models showed a mean RMSE of 19.49 for the traditional model and 18.99 for the GTD-extended model. When we tested the models trained on a decreased dataset with missing values, the GTD-extended models achieved significantly better prediction than the traditional models (p &lt; 0.001). The GTD-extended models outperformed the traditional models in all assessed model evaluation parameters. Using online activity-based data regarding diabetes can improve TB forecasting, but further validation is warranted.",1,1
35030203,Comparison of ARIMA and LSTM for prediction of hemorrhagic fever at different time scales in China,"Zhang R, Song H, Chen Q, Wang Y, Wang S, Li Y.",PLoS One. 2022 Jan 14;17(1):e0262009. doi: 10.1371/journal.pone.0262009. eCollection 2022.,Zhang R,PLoS One,2022,14-01-2022,PMC8759700,,10.1371/journal.pone.0262009,"OBJECTIVES: This study intends to build and compare two kinds of forecasting models at different time scales for hemorrhagic fever incidence in China.
METHODS: Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory Neural Network (LSTM) were adopted to fit monthly, weekly and daily incidence of hemorrhagic fever in China from 2013 to 2018. The two models, combined and uncombined with rolling forecasts, were used to predict the incidence in 2019 to examine their stability and applicability.
RESULTS: ARIMA (2, 1, 1) (0, 1, 1)12, ARIMA (1, 1, 3) (1, 1, 1)52 and ARIMA (5, 0, 1) were selected as the best fitting ARIMA model for monthly, weekly and daily incidence series, respectively. The LSTM model with 64 neurons and Stochastic Gradient Descent (SGDM) for monthly incidence, 8 neurons and Adaptive Moment Estimation (Adam) for weekly incidence, and 64 neurons and Root Mean Square Prop (RMSprop) for daily incidence were selected as the best fitting LSTM models. The values of root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of the models combined with rolling forecasts in 2019 were lower than those of the direct forecasting models for both ARIMA and LSTM. It was shown from the forecasting performance in 2019 that ARIMA was better than LSTM for monthly and weekly forecasting while the LSTM was better than ARIMA for daily forecasting in rolling forecasting models.
CONCLUSIONS: Both ARIMA and LSTM could be used to build a prediction model for the incidence of hemorrhagic fever. Different models might be more suitable for the incidence prediction at different time scales. The findings can provide a good reference for future selection of prediction models and establishments of early warning systems for hemorrhagic fever.","Comparison of ARIMA and LSTM for prediction of hemorrhagic fever at different time scales in China OBJECTIVES: This study intends to build and compare two kinds of forecasting models at different time scales for hemorrhagic fever incidence in China.
METHODS: Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory Neural Network (LSTM) were adopted to fit monthly, weekly and daily incidence of hemorrhagic fever in China from 2013 to 2018. The two models, combined and uncombined with rolling forecasts, were used to predict the incidence in 2019 to examine their stability and applicability.
RESULTS: ARIMA (2, 1, 1) (0, 1, 1)12, ARIMA (1, 1, 3) (1, 1, 1)52 and ARIMA (5, 0, 1) were selected as the best fitting ARIMA model for monthly, weekly and daily incidence series, respectively. The LSTM model with 64 neurons and Stochastic Gradient Descent (SGDM) for monthly incidence, 8 neurons and Adaptive Moment Estimation (Adam) for weekly incidence, and 64 neurons and Root Mean Square Prop (RMSprop) for daily incidence were selected as the best fitting LSTM models. The values of root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of the models combined with rolling forecasts in 2019 were lower than those of the direct forecasting models for both ARIMA and LSTM. It was shown from the forecasting performance in 2019 that ARIMA was better than LSTM for monthly and weekly forecasting while the LSTM was better than ARIMA for daily forecasting in rolling forecasting models.
CONCLUSIONS: Both ARIMA and LSTM could be used to build a prediction model for the incidence of hemorrhagic fever. Different models might be more suitable for the incidence prediction at different time scales. The findings can provide a good reference for future selection of prediction models and establishments of early warning systems for hemorrhagic fever.",1,1
37491597,Plasmapheresis to remove amyloid fibrin(ogen) particles for treating the post-COVID-19 condition,"Fox T, Hunt BJ, Ariens RA, Towers GJ, Lever R, Garner P, Kuehn R.",Cochrane Database Syst Rev. 2023 Jul 26;7(7):CD015775. doi: 10.1002/14651858.CD015775.,Fox T,Cochrane Database Syst Rev,2023,26-07-2023,PMC10368521,,10.1002/14651858.CD015775,"BACKGROUND: The post-COVID-19 condition (PCC) consists of a wide array of symptoms including fatigue and impaired daily living. People seek a wide variety of approaches to help them recover. A new belief, arising from a few laboratory studies, is that 'microclots' cause the symptoms of PCC. This belief has been extended outside these studies, suggesting that to recover people need plasmapheresis (an expensive process where blood is filtered outside the body). We appraised the laboratory studies, and it was clear that the term 'microclots' is incorrect to describe the phenomenon being described. The particles are amyloid and include fibrin(ogen); amyloid is not a part of a thrombus which is a mix of fibrin mesh and platelets. Initial acute COVID-19 infection is associated with clotting abnormalities; this review concerns amyloid fibrin(ogen) particles in PCC only. We have reported here our appraisal of laboratory studies investigating the presence of amyloid fibrin(ogen) particles in PCC, and of evidence that plasmapheresis may be an effective therapy to remove amyloid fibrin(ogen) particles for treating PCC.
OBJECTIVES: Laboratory studies review To summarize and appraise the research reports on amyloid fibrin(ogen) particles related to PCC. Randomized controlled trials review To assess the evidence of the safety and efficacy of plasmapheresis to remove amyloid fibrin(ogen) particles in individuals with PCC from randomized controlled trials.
SEARCH METHODS: Laboratory studies review We searched for all relevant laboratory studies up to 27 October 2022 using a comprehensive search strategy which included the search terms 'COVID', 'amyloid', 'fibrin', 'fibrinogen'. Randomized controlled trials review We searched the following databases on 21 October 2022: Cochrane COVID-19 Study Register; MEDLINE (Ovid); Embase (Ovid); and BIOSIS Previews (Web of Science). We also searched the WHO International Clinical Trials Registry Platform and ClinicalTrials.gov for trials in progress.
SELECTION CRITERIA: Laboratory studies review Laboratory studies that investigate the presence of amyloid fibrin(ogen) particles in plasma samples from patients with PCC were eligible. This included studies with or without controls. Randomized controlled trials review Studies were eligible if they were of randomized controlled design and investigated the effectiveness or safety of plasmapheresis for removing amyloid fibrin(ogen) particles for treating PCC.
DATA COLLECTION AND ANALYSIS: Two review authors applied study inclusion criteria to identify eligible studies and extracted data. Laboratory studies review We assessed the risk of bias of included studies using pre-developed methods for laboratory studies. We planned to perform synthesis without meta-analysis (SWiM) as described in our protocol. Randomized controlled trials review We planned that if we identified any eligible studies, we would assess risk of bias and report results with 95% confidence intervals. The primary outcome was recovery, measured using the Post-COVID-19 Functional Status Scale (absence of symptoms related to the illness, ability to do usual daily activities, and a return to a previous state of health and mind).
MAIN RESULTS: Laboratory studies review We identified five laboratory studies. Amyloid fibrin(ogen) particles were identified in participants across all studies, including those with PCC, healthy individuals, and those with diabetes. The results of three studies were based on visual images of amyloid fibrin(ogen) particles, which did not quantify the amount or size of the particles identified. Formal risk of bias assessment showed concerns in how the studies were conducted and reported. This means the results were insufficient to support the belief that amyloid fibrin(ogen) particles are associated with PCC, or to determine whether there is a difference in the amount or size of amyloid fibrin(ogen) particles in the plasma of people with PCC compared to healthy controls. Randomized controlled trials review We identified no trials meeting our inclusion criteria.
AUTHORS' CONCLUSIONS: In the absence of reliable research showing that amyloid fibrin(ogen) particles contribute to the pathophysiology of PCC, there is no rationale for plasmapheresis to remove amyloid fibrin(ogen) particles in PCC. Plasmapheresis for this indication should not be used outside the context of a well-conducted randomized controlled trial.","Plasmapheresis to remove amyloid fibrin(ogen) particles for treating the post-COVID-19 condition BACKGROUND: The post-COVID-19 condition (PCC) consists of a wide array of symptoms including fatigue and impaired daily living. People seek a wide variety of approaches to help them recover. A new belief, arising from a few laboratory studies, is that 'microclots' cause the symptoms of PCC. This belief has been extended outside these studies, suggesting that to recover people need plasmapheresis (an expensive process where blood is filtered outside the body). We appraised the laboratory studies, and it was clear that the term 'microclots' is incorrect to describe the phenomenon being described. The particles are amyloid and include fibrin(ogen); amyloid is not a part of a thrombus which is a mix of fibrin mesh and platelets. Initial acute COVID-19 infection is associated with clotting abnormalities; this review concerns amyloid fibrin(ogen) particles in PCC only. We have reported here our appraisal of laboratory studies investigating the presence of amyloid fibrin(ogen) particles in PCC, and of evidence that plasmapheresis may be an effective therapy to remove amyloid fibrin(ogen) particles for treating PCC.
OBJECTIVES: Laboratory studies review To summarize and appraise the research reports on amyloid fibrin(ogen) particles related to PCC. Randomized controlled trials review To assess the evidence of the safety and efficacy of plasmapheresis to remove amyloid fibrin(ogen) particles in individuals with PCC from randomized controlled trials.
SEARCH METHODS: Laboratory studies review We searched for all relevant laboratory studies up to 27 October 2022 using a comprehensive search strategy which included the search terms 'COVID', 'amyloid', 'fibrin', 'fibrinogen'. Randomized controlled trials review We searched the following databases on 21 October 2022: Cochrane COVID-19 Study Register; MEDLINE (Ovid); Embase (Ovid); and BIOSIS Previews (Web of Science). We also searched the WHO International Clinical Trials Registry Platform and ClinicalTrials.gov for trials in progress.
SELECTION CRITERIA: Laboratory studies review Laboratory studies that investigate the presence of amyloid fibrin(ogen) particles in plasma samples from patients with PCC were eligible. This included studies with or without controls. Randomized controlled trials review Studies were eligible if they were of randomized controlled design and investigated the effectiveness or safety of plasmapheresis for removing amyloid fibrin(ogen) particles for treating PCC.
DATA COLLECTION AND ANALYSIS: Two review authors applied study inclusion criteria to identify eligible studies and extracted data. Laboratory studies review We assessed the risk of bias of included studies using pre-developed methods for laboratory studies. We planned to perform synthesis without meta-analysis (SWiM) as described in our protocol. Randomized controlled trials review We planned that if we identified any eligible studies, we would assess risk of bias and report results with 95% confidence intervals. The primary outcome was recovery, measured using the Post-COVID-19 Functional Status Scale (absence of symptoms related to the illness, ability to do usual daily activities, and a return to a previous state of health and mind).
MAIN RESULTS: Laboratory studies review We identified five laboratory studies. Amyloid fibrin(ogen) particles were identified in participants across all studies, including those with PCC, healthy individuals, and those with diabetes. The results of three studies were based on visual images of amyloid fibrin(ogen) particles, which did not quantify the amount or size of the particles identified. Formal risk of bias assessment showed concerns in how the studies were conducted and reported. This means the results were insufficient to support the belief that amyloid fibrin(ogen) particles are associated with PCC, or to determine whether there is a difference in the amount or size of amyloid fibrin(ogen) particles in the plasma of people with PCC compared to healthy controls. Randomized controlled trials review We identified no trials meeting our inclusion criteria.
AUTHORS' CONCLUSIONS: In the absence of reliable research showing that amyloid fibrin(ogen) particles contribute to the pathophysiology of PCC, there is no rationale for plasmapheresis to remove amyloid fibrin(ogen) particles in PCC. Plasmapheresis for this indication should not be used outside the context of a well-conducted randomized controlled trial.",0,0
39123221,Comparative analysis of adverse events associated with CDK4/6 inhibitors based on FDA's adverse event reporting system: a case control pharmacovigilance study,"Lin W, Zeng Y, Weng L, Yang J, Zhuang W.",BMC Pharmacol Toxicol. 2024 Aug 9;25(1):47. doi: 10.1186/s40360-024-00770-6.,Lin W,BMC Pharmacol Toxicol,2024,09-08-2024,PMC11312934,,10.1186/s40360-024-00770-6,"BACKGROUND: Cyclin-dependent kinase 4/6 (CDK4/6) inhibitors marked a milestone in the breast cancer treatment. Due to the potential impact of adverse effects on treatment decisions and patient outcomes, careful consideration of the varying toxicities of CDK4/6 inhibitors is crucial, as three inhibitors-palbociclib, abemaciclib, and ribociclib-have been approved with differences in adverse event profiles. However, limitations in clinical trials call for urgent real-world safety studies to evaluate and compare the risk of adverse events (AEs) among these CDK4/6 inhibitors. Therefore, this study aimed to analyze AEs of CDK4/6 inhibitors and provide insights for clinical drug selection, using real world database.
METHODS: The AEs of CDK4/6 inhibitors in the FDA Adverse Event Reporting System (2015-2022) were analyzed. Four disproportionality methods were used to detect safety signals: reporting odds ratio (ROR), proportional reporting ratio, Bayesian Confidence Neural Network Propagation, and Multi-Item Gamma Poisson Shrinker. Venn analysis was used to compare and select common and specific AEs.
RESULTS: This study included 73,042 patients treated with palbociclib, 25,142 with ribociclib, and 7563 with abemaciclib. All three inhibitors had 27 common AEs. Palbociclib exhibited the highest ROR for hematologic toxicities, while ribociclib showed the highest ROR for macrocytosis, nail disorders, and hepatic lesions. Abemaciclib displayed the highest ROR for mucosal toxicity. Common signals for both palbociclib and ribociclib included hematologic toxicities, decreased immune responsiveness, and aphthous ulcers. Myelosuppression, oral pain, and pseudocirrhosis were common signals for palbociclib and abemaciclib. Anemia, hepatotoxicity, and pneumonitis were observed as common signals for ribociclib and abemaciclib. Furthermore, specific AEs associated with palbociclib included fatigue, alopecia, and stomatitis. For ribociclib, specific AEs included electrocardiogram QT prolongation, thrombocytopenia, and decreased hemoglobin. Abemaciclib was specifically linked to diarrhea, vomiting, and interstitial lung disease.
CONCLUSION: Our analysis revealed that palbociclib showed a higher risk of hematologic toxicity. Ribociclib showed higher risks of hepatotoxicity, nephrotoxicity, and QT prolongation. Abemaciclib showed higher risks of hepatotoxicity, gastrointestinal effects, interstitial lung disease, and thrombosis. These findings provide valuable insights for CDK4/6 inhibitor selection.","Comparative analysis of adverse events associated with CDK4/6 inhibitors based on FDA's adverse event reporting system: a case control pharmacovigilance study BACKGROUND: Cyclin-dependent kinase 4/6 (CDK4/6) inhibitors marked a milestone in the breast cancer treatment. Due to the potential impact of adverse effects on treatment decisions and patient outcomes, careful consideration of the varying toxicities of CDK4/6 inhibitors is crucial, as three inhibitors-palbociclib, abemaciclib, and ribociclib-have been approved with differences in adverse event profiles. However, limitations in clinical trials call for urgent real-world safety studies to evaluate and compare the risk of adverse events (AEs) among these CDK4/6 inhibitors. Therefore, this study aimed to analyze AEs of CDK4/6 inhibitors and provide insights for clinical drug selection, using real world database.
METHODS: The AEs of CDK4/6 inhibitors in the FDA Adverse Event Reporting System (2015-2022) were analyzed. Four disproportionality methods were used to detect safety signals: reporting odds ratio (ROR), proportional reporting ratio, Bayesian Confidence Neural Network Propagation, and Multi-Item Gamma Poisson Shrinker. Venn analysis was used to compare and select common and specific AEs.
RESULTS: This study included 73,042 patients treated with palbociclib, 25,142 with ribociclib, and 7563 with abemaciclib. All three inhibitors had 27 common AEs. Palbociclib exhibited the highest ROR for hematologic toxicities, while ribociclib showed the highest ROR for macrocytosis, nail disorders, and hepatic lesions. Abemaciclib displayed the highest ROR for mucosal toxicity. Common signals for both palbociclib and ribociclib included hematologic toxicities, decreased immune responsiveness, and aphthous ulcers. Myelosuppression, oral pain, and pseudocirrhosis were common signals for palbociclib and abemaciclib. Anemia, hepatotoxicity, and pneumonitis were observed as common signals for ribociclib and abemaciclib. Furthermore, specific AEs associated with palbociclib included fatigue, alopecia, and stomatitis. For ribociclib, specific AEs included electrocardiogram QT prolongation, thrombocytopenia, and decreased hemoglobin. Abemaciclib was specifically linked to diarrhea, vomiting, and interstitial lung disease.
CONCLUSION: Our analysis revealed that palbociclib showed a higher risk of hematologic toxicity. Ribociclib showed higher risks of hepatotoxicity, nephrotoxicity, and QT prolongation. Abemaciclib showed higher risks of hepatotoxicity, gastrointestinal effects, interstitial lung disease, and thrombosis. These findings provide valuable insights for CDK4/6 inhibitor selection.",0,0
31234938,Comparative evaluation of time series models for predicting influenza outbreaks: application of influenza-like illness data from sentinel sites of healthcare centers in Iran,"Tapak L, Hamidi O, Fathian M, Karami M.",BMC Res Notes. 2019 Jun 24;12(1):353. doi: 10.1186/s13104-019-4393-y.,Tapak L,BMC Res Notes,2019,26-06-2019,PMC6591835,,10.1186/s13104-019-4393-y,"OBJECTIVE: Forecasting the time of future outbreaks would minimize the impact of diseases by taking preventive steps including public health messaging and raising awareness of clinicians for timely treatment and diagnosis. The present study investigated the accuracy of support vector machine, artificial neural-network, and random-forest time series models in influenza like illness (ILI) modeling and outbreaks detection. The models were applied to a data set of weekly ILI frequencies in Iran. The root mean square errors (RMSE), mean absolute errors (MAE), and intra-class correlation coefficient (ICC) statistics were employed as evaluation criteria.
RESULTS: It was indicated that the random-forest time series model outperformed other three methods in modeling weekly ILI frequencies (RMSE = 22.78, MAE = 14.99 and ICC = 0.88 for the test set). In addition neural-network was better in outbreaks detection with total accuracy of 0.889 for the test set. The results showed that the used time series models had promising performances suggesting they could be effectively applied for predicting weekly ILI frequencies and outbreaks.","Comparative evaluation of time series models for predicting influenza outbreaks: application of influenza-like illness data from sentinel sites of healthcare centers in Iran OBJECTIVE: Forecasting the time of future outbreaks would minimize the impact of diseases by taking preventive steps including public health messaging and raising awareness of clinicians for timely treatment and diagnosis. The present study investigated the accuracy of support vector machine, artificial neural-network, and random-forest time series models in influenza like illness (ILI) modeling and outbreaks detection. The models were applied to a data set of weekly ILI frequencies in Iran. The root mean square errors (RMSE), mean absolute errors (MAE), and intra-class correlation coefficient (ICC) statistics were employed as evaluation criteria.
RESULTS: It was indicated that the random-forest time series model outperformed other three methods in modeling weekly ILI frequencies (RMSE = 22.78, MAE = 14.99 and ICC = 0.88 for the test set). In addition neural-network was better in outbreaks detection with total accuracy of 0.889 for the test set. The results showed that the used time series models had promising performances suggesting they could be effectively applied for predicting weekly ILI frequencies and outbreaks.",0,1
35174482,Community views on mass drug administration for filariasis: a qualitative evidence synthesis,"Taylor M, Thomas R, Oliver S, Garner P.",Cochrane Database Syst Rev. 2022 Feb 17;2(2):CD013638. doi: 10.1002/14651858.CD013638.pub2.,Taylor M,Cochrane Database Syst Rev,2022,17-02-2022,PMC8851040,,10.1002/14651858.CD013638.pub2,"BACKGROUND: The World Health Organization (WHO) recommends mass drug administration (MDA), giving a drug at regular intervals to a whole population, as part of the strategy for several disease control programmes in low- and middle-income countries. MDA is currently WHO policy for areas endemic with lymphatic filariasis, which is a parasitic disease that can result in swollen limbs and disability. The success depends on communities adhering to the drugs given, and this will be influenced by the perception of the drug, the programme, and those delivering it.  OBJECTIVES: To synthesize qualitative research evidence about community experience with, and understanding and perception of, MDA programmes for lymphatic filariasis. To explore whether programme design and delivery influence the community experience identified in the analysis.
SEARCH METHODS: We searched CENTRAL, MEDLINE, Embase, and seven other databases up to 8 April 2021, together with reference checking, citation searching, and contact with study authors to identify additional studies.
SELECTION CRITERIA: This review synthesized qualitative research and mixed-methods studies when it was possible to extract qualitative data. Eligible studies explored community experiences, perceptions, or attitudes towards MDA programmes for lymphatic filariasis in any country, conducted between 2000 and 2019.  DATA COLLECTION AND ANALYSIS: We extracted data on study design including: authors, aims, participants, methods, and qualitative data collection methods. We also described programme delivery factors including: country, urban or rural setting, endemicity, drug regimen, rounds of MDA received at the time of the study, who delivered the drugs, how the drugs were delivered, use of health education, and sensitization and adherence monitoring. We conducted a thematic analysis and developed codes inductively using ATLAS.ti software. We examined codes for underlying ideas, connections, and interpretations and, from this, generated analytical themes. We assessed the confidence in the findings using the GRADE-CERQual approach, and produced a conceptual model to display our findings.  MAIN RESULTS: From 902 results identified in the search, 29 studies met our inclusion criteria. The studies covered a broad range of countries in Africa, South-East Asia, and South America, and explored the views and experiences of community members and community drug distributors in low-income countries endemic for lymphatic filariasis. Four themes emerged. People weigh up benefits and harms before participating. People understand the potential benefits in terms of relief of suffering, stigma, and avoiding costs (high confidence); however, these theoretical benefits do not always mesh with their experiences (high confidence). In particular, adverse effects are frightening and unwelcome (high confidence); and these effects are amplified through rumour and social media (moderate confidence). Many people are suspicious of MDA programmes. When people lack a scientific explanation for the programme and their experiences of it, they often develop social explanations instead. These are largely shaped on the historical backdrop and level of trust people have in relevant authority figures (high confidence), although some have unwavering faith in their government and, by extension, the programme (moderate confidence). Programmes expect compliance, and this can become coercive and blaming. Health workers and community members stigmatize non-compliance, which can become coercive (moderate confidence), so communities may appear to comply publicly, but privately reject treatment (moderate confidence). Community distributors are often not respected or valued. They have little authority (moderate confidence), and the behaviour of some distributors damages the MDA programme's reputation (high confidence). Communities want information about programmes to help make decisions about participation, but drug distributors are not sufficiently informed, or skilled in this communication (high confidence). We intended to assess whether programme designs influenced communities' perceptions of the programme and decision to adhere but were unable to do so as few studies adequately reported the design and implementation of the local programme. We have moderate to high confidence in the evidence contributing to the review themes and subthemes.
AUTHORS' CONCLUSIONS: Adherence with MDA for filariasis is influenced by individual direct experience of benefit and harm; social influences in the community; political influences and their relationship to government; and historical influences. Fear of adverse effects was frequently described and this appears to be particularly important for communities. When views were negative, we were surprised by the strength of feeling expressed. Enthusiasm for these schemes as a strategy in global policy needs debate in the light of these findings.","Community views on mass drug administration for filariasis: a qualitative evidence synthesis BACKGROUND: The World Health Organization (WHO) recommends mass drug administration (MDA), giving a drug at regular intervals to a whole population, as part of the strategy for several disease control programmes in low- and middle-income countries. MDA is currently WHO policy for areas endemic with lymphatic filariasis, which is a parasitic disease that can result in swollen limbs and disability. The success depends on communities adhering to the drugs given, and this will be influenced by the perception of the drug, the programme, and those delivering it.  OBJECTIVES: To synthesize qualitative research evidence about community experience with, and understanding and perception of, MDA programmes for lymphatic filariasis. To explore whether programme design and delivery influence the community experience identified in the analysis.
SEARCH METHODS: We searched CENTRAL, MEDLINE, Embase, and seven other databases up to 8 April 2021, together with reference checking, citation searching, and contact with study authors to identify additional studies.
SELECTION CRITERIA: This review synthesized qualitative research and mixed-methods studies when it was possible to extract qualitative data. Eligible studies explored community experiences, perceptions, or attitudes towards MDA programmes for lymphatic filariasis in any country, conducted between 2000 and 2019.  DATA COLLECTION AND ANALYSIS: We extracted data on study design including: authors, aims, participants, methods, and qualitative data collection methods. We also described programme delivery factors including: country, urban or rural setting, endemicity, drug regimen, rounds of MDA received at the time of the study, who delivered the drugs, how the drugs were delivered, use of health education, and sensitization and adherence monitoring. We conducted a thematic analysis and developed codes inductively using ATLAS.ti software. We examined codes for underlying ideas, connections, and interpretations and, from this, generated analytical themes. We assessed the confidence in the findings using the GRADE-CERQual approach, and produced a conceptual model to display our findings.  MAIN RESULTS: From 902 results identified in the search, 29 studies met our inclusion criteria. The studies covered a broad range of countries in Africa, South-East Asia, and South America, and explored the views and experiences of community members and community drug distributors in low-income countries endemic for lymphatic filariasis. Four themes emerged. People weigh up benefits and harms before participating. People understand the potential benefits in terms of relief of suffering, stigma, and avoiding costs (high confidence); however, these theoretical benefits do not always mesh with their experiences (high confidence). In particular, adverse effects are frightening and unwelcome (high confidence); and these effects are amplified through rumour and social media (moderate confidence). Many people are suspicious of MDA programmes. When people lack a scientific explanation for the programme and their experiences of it, they often develop social explanations instead. These are largely shaped on the historical backdrop and level of trust people have in relevant authority figures (high confidence), although some have unwavering faith in their government and, by extension, the programme (moderate confidence). Programmes expect compliance, and this can become coercive and blaming. Health workers and community members stigmatize non-compliance, which can become coercive (moderate confidence), so communities may appear to comply publicly, but privately reject treatment (moderate confidence). Community distributors are often not respected or valued. They have little authority (moderate confidence), and the behaviour of some distributors damages the MDA programme's reputation (high confidence). Communities want information about programmes to help make decisions about participation, but drug distributors are not sufficiently informed, or skilled in this communication (high confidence). We intended to assess whether programme designs influenced communities' perceptions of the programme and decision to adhere but were unable to do so as few studies adequately reported the design and implementation of the local programme. We have moderate to high confidence in the evidence contributing to the review themes and subthemes.
AUTHORS' CONCLUSIONS: Adherence with MDA for filariasis is influenced by individual direct experience of benefit and harm; social influences in the community; political influences and their relationship to government; and historical influences. Fear of adverse effects was frequently described and this appears to be particularly important for communities. When views were negative, we were surprised by the strength of feeling expressed. Enthusiasm for these schemes as a strategy in global policy needs debate in the light of these findings.",0,0
31485259,Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay,"Mello-Román JD, Mello-Román JC, Gómez-Guerrero S, García-Torres M.",Comput Math Methods Med. 2019 Jul 29;2019:7307803. doi: 10.1155/2019/7307803. eCollection 2019.,Mello-Román JD,Comput Math Methods Med,2019,06-09-2019,PMC6702853,,10.1155/2019/7307803,"Early diagnosis of dengue continues to be a concern for public health in countries with a high incidence of this disease. In this work, we compared two machine learning techniques: artificial neural networks (ANN) and support vector machines (SVM) as assistance tools for medical diagnosis. The performance of classification models was evaluated in a real dataset of patients with a previous diagnosis of dengue extracted from the public health system of Paraguay during the period 2012-2016. The ANN multilayer perceptron achieved better results with an average of 96% accuracy, 96% sensitivity, and 97% specificity, with low variation in thirty different partitions of the dataset. In comparison, SVM polynomial obtained results above 90% for accuracy, sensitivity, and specificity.","Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay Early diagnosis of dengue continues to be a concern for public health in countries with a high incidence of this disease. In this work, we compared two machine learning techniques: artificial neural networks (ANN) and support vector machines (SVM) as assistance tools for medical diagnosis. The performance of classification models was evaluated in a real dataset of patients with a previous diagnosis of dengue extracted from the public health system of Paraguay during the period 2012-2016. The ANN multilayer perceptron achieved better results with an average of 96% accuracy, 96% sensitivity, and 97% specificity, with low variation in thirty different partitions of the dataset. In comparison, SVM polynomial obtained results above 90% for accuracy, sensitivity, and specificity.",1,1
36007846,"Evaluating the ability of the NLHA2 and artificial neural network models to predict COVID-19 severity, and comparing them with the four existing scoring systems","Dong Y, Wang K, Zou X, Tan X, Zang Y, Li X, Ren X, Xie D, Jie Z, Chen X, Zeng Y, Shi J.",Microb Pathog. 2022 Oct;171:105735. doi: 10.1016/j.micpath.2022.105735. Epub 2022 Aug 23.,Dong Y,Microb Pathog,2022,25-08-2022,PMC9395227,,10.1016/j.micpath.2022.105735,"To improve the identification and subsequent intervention of COVID-19 patients at risk for ICU admission, we constructed COVID-19 severity prediction models using logistic regression and artificial neural network (ANN) analysis and compared them with the four existing scoring systems (PSI, CURB-65, SMARTCOP, and MuLBSTA). In this prospective multi-center study, 296 patients with COVID-19 pneumonia were enrolled and split into the General-Ward-Care group (N = 238) and the ICU-Admission group (N = 58). The PSI model (AUC = 0.861) had the best results among the existing four scoring systems, followed by SMARTCOP (AUC = 0.770), motified-MuLBSTA (AUC = 0.761), and CURB-65 (AUC = 0.712). Data from 197 patients (training set) were analyzed for modeling. The beta coefficients from logistic regression were used to develop a severity prediction model and risk score calculator. The final model (NLHA2) included five covariates (consumes alcohol, neutrophil count, lymphocyte count, hemoglobin, and AKP). The NLHA2 model (training: AUC = 0.959; testing: AUC = 0.857) had similar results to the PSI model, but with fewer variable items. ANN analysis was used to build another complex model, which had higher accuracy (training: AUC = 1.000; testing: AUC = 0.907). Discrimination and calibration were further verified through bootstrapping (2000 replicates), Hosmer-Lemeshow goodness of fit testing, and Brier score calculation. In conclusion, the PSI model is the best existing system for predicting ICU admission among COVID-19 patients, while two newly-designed models (NLHA2 and ANN) performed better than PSI, and will provide a new approach for the development of prognostic evaluation system in a novel respiratory viral epidemic.","Evaluating the ability of the NLHA2 and artificial neural network models to predict COVID-19 severity, and comparing them with the four existing scoring systems To improve the identification and subsequent intervention of COVID-19 patients at risk for ICU admission, we constructed COVID-19 severity prediction models using logistic regression and artificial neural network (ANN) analysis and compared them with the four existing scoring systems (PSI, CURB-65, SMARTCOP, and MuLBSTA). In this prospective multi-center study, 296 patients with COVID-19 pneumonia were enrolled and split into the General-Ward-Care group (N = 238) and the ICU-Admission group (N = 58). The PSI model (AUC = 0.861) had the best results among the existing four scoring systems, followed by SMARTCOP (AUC = 0.770), motified-MuLBSTA (AUC = 0.761), and CURB-65 (AUC = 0.712). Data from 197 patients (training set) were analyzed for modeling. The beta coefficients from logistic regression were used to develop a severity prediction model and risk score calculator. The final model (NLHA2) included five covariates (consumes alcohol, neutrophil count, lymphocyte count, hemoglobin, and AKP). The NLHA2 model (training: AUC = 0.959; testing: AUC = 0.857) had similar results to the PSI model, but with fewer variable items. ANN analysis was used to build another complex model, which had higher accuracy (training: AUC = 1.000; testing: AUC = 0.907). Discrimination and calibration were further verified through bootstrapping (2000 replicates), Hosmer-Lemeshow goodness of fit testing, and Brier score calculation. In conclusion, the PSI model is the best existing system for predicting ICU admission among COVID-19 patients, while two newly-designed models (NLHA2 and ANN) performed better than PSI, and will provide a new approach for the development of prognostic evaluation system in a novel respiratory viral epidemic.",0,1
29526169,Factors associated with fatal outcome of children with enterovirus A71 infection: a case series,"Yang SD, Li PQ, Huang YG, Li W, Ma LZ, Wu L, Wang N, Lu JM, Chen WQ, Liu GM, Xiong YM, Chen YL, Zhang Y.",Epidemiol Infect. 2018 Apr;146(6):788-798. doi: 10.1017/S0950268818000468. Epub 2018 Mar 12.,Yang SD,Epidemiol Infect,2018,13-03-2018,PMC9134374,,10.1017/S0950268818000468,"Enterovirus A-71 (EV-A71) may be fatal, but the natural history, symptoms, and signs are poorly understood. This study aimed to examine the natural history of fatal EV-A71 infection and to identify the symptoms and signs of early warning of deterioration. This was a clinical observational study of fatal cases of EV-A71 infection treated at five Chinese hospitals between 1 January 2010 and 31 December 2012. We recorded and analysed 91 manifestations of EV-A71 infection in order to identify early prognosis indicators. There were 54 fatal cases. Median age was 21.5 months (Q1-Q3: 12-36). The median duration from onset to death was 78.5 h (range, 6 to 432). The multilayer perceptron analysis showed that ataxia respiratory, ultrahyperpyrexia, excessive tachycardia, refractory shock, absent pharyngeal reflex, irregular respiratory rhythm, hyperventilation, deep coma, pulmonary oedema and/or haemorrhage, excessive hypertension, tachycardia, somnolence, CRT extension, fatigue or sleepiness and age were associated with death. Autopsy findings (n = 2) showed neuronal necrosis, softening, perivascular cuffing, colloid and neuronophagia phenomenon in the brainstem. The fatal cases of enterovirus A71 had neurologic involvement, even at the early stage. Direct virus invasion through the neural pathway and subsequent brainstem damage might explain the rapid progression to death.","Factors associated with fatal outcome of children with enterovirus A71 infection: a case series Enterovirus A-71 (EV-A71) may be fatal, but the natural history, symptoms, and signs are poorly understood. This study aimed to examine the natural history of fatal EV-A71 infection and to identify the symptoms and signs of early warning of deterioration. This was a clinical observational study of fatal cases of EV-A71 infection treated at five Chinese hospitals between 1 January 2010 and 31 December 2012. We recorded and analysed 91 manifestations of EV-A71 infection in order to identify early prognosis indicators. There were 54 fatal cases. Median age was 21.5 months (Q1-Q3: 12-36). The median duration from onset to death was 78.5 h (range, 6 to 432). The multilayer perceptron analysis showed that ataxia respiratory, ultrahyperpyrexia, excessive tachycardia, refractory shock, absent pharyngeal reflex, irregular respiratory rhythm, hyperventilation, deep coma, pulmonary oedema and/or haemorrhage, excessive hypertension, tachycardia, somnolence, CRT extension, fatigue or sleepiness and age were associated with death. Autopsy findings (n = 2) showed neuronal necrosis, softening, perivascular cuffing, colloid and neuronophagia phenomenon in the brainstem. The fatal cases of enterovirus A71 had neurologic involvement, even at the early stage. Direct virus invasion through the neural pathway and subsequent brainstem damage might explain the rapid progression to death.",0,0
39234238,Post-marketing drug safety surveillance of enfortumab vedotin: an observational pharmacovigilance study based on a real-world database,"Yu M, Zhou L, Cao M, Ji C, Zheng Y.",Front Immunol. 2024 Aug 20;15:1397692. doi: 10.3389/fimmu.2024.1397692. eCollection 2024.,Yu M,Front Immunol,2024,05-09-2024,PMC11372787,,10.3389/fimmu.2024.1397692,"BACKGROUND: Enfortumab vedotin (EV) is an antibody-drug conjugate (ADC) that has been approved by the FDA for patients with locally advanced or metastatic urothelial carcinoma (UC). This study presents a comprehensive pharmacovigilance analysis of the post-marketing safety profile of EV in the real-world based on the US Food and Drug Administration Adverse Event Reporting System (FAERS).
METHODS: Adverse event (AE) reports regarding EV between January 2020 and December 2023 were obtained from the FAERS database. The standardized MedDRA query (SMQ) narrow search AEs on the preferred term (PT) level were used. Disproportionality analysis was performed to identify the AE signals for EV with the reporting odds ratio (ROR), proportional reporting ratio (PRR), multi-item gamma Poisson shrinker (MGPS), and Bayesian confidence propagation neural network (BCPNN).
RESULTS: A total of 2,216 reports regarding EV were included in the present study. SMQ analysis results indicated that a stronger strength signal was found in severe cutaneous adverse reactions, retroperitoneal fibrosis, and peripheral neuropathy. A total of 116 significant disproportionality PTs referring to 14 system organ classes (SOCs) were retained by disproportionality analysis, with 49 PTs not listed on the EV drug label. Frequently reported EV-related AEs included rash, peripheral neuropathy, decreased appetite, alopecia, and pruritus. The time to onset of the majority of EV-related AEs was within 30 days (66.05%), with only 0.73% events occurring after 1 year.
CONCLUSION: The disproportionality analysis highlights that dermatologic toxicity and peripheral neuropathy were the major AEs induced by EV. The potential AEs not listed on the drug label were mainly related to gastrointestinal, hepatic, and pulmonary events. Further research is needed to confirm and explore the EV-related AEs in clinical practice.","Post-marketing drug safety surveillance of enfortumab vedotin: an observational pharmacovigilance study based on a real-world database BACKGROUND: Enfortumab vedotin (EV) is an antibody-drug conjugate (ADC) that has been approved by the FDA for patients with locally advanced or metastatic urothelial carcinoma (UC). This study presents a comprehensive pharmacovigilance analysis of the post-marketing safety profile of EV in the real-world based on the US Food and Drug Administration Adverse Event Reporting System (FAERS).
METHODS: Adverse event (AE) reports regarding EV between January 2020 and December 2023 were obtained from the FAERS database. The standardized MedDRA query (SMQ) narrow search AEs on the preferred term (PT) level were used. Disproportionality analysis was performed to identify the AE signals for EV with the reporting odds ratio (ROR), proportional reporting ratio (PRR), multi-item gamma Poisson shrinker (MGPS), and Bayesian confidence propagation neural network (BCPNN).
RESULTS: A total of 2,216 reports regarding EV were included in the present study. SMQ analysis results indicated that a stronger strength signal was found in severe cutaneous adverse reactions, retroperitoneal fibrosis, and peripheral neuropathy. A total of 116 significant disproportionality PTs referring to 14 system organ classes (SOCs) were retained by disproportionality analysis, with 49 PTs not listed on the EV drug label. Frequently reported EV-related AEs included rash, peripheral neuropathy, decreased appetite, alopecia, and pruritus. The time to onset of the majority of EV-related AEs was within 30 days (66.05%), with only 0.73% events occurring after 1 year.
CONCLUSION: The disproportionality analysis highlights that dermatologic toxicity and peripheral neuropathy were the major AEs induced by EV. The potential AEs not listed on the drug label were mainly related to gastrointestinal, hepatic, and pulmonary events. Further research is needed to confirm and explore the EV-related AEs in clinical practice.",0,0
31608599,FluChip-8G Insight: HA and NA subtyping of potentially pandemic influenza A viruses in a single assay,"Toth E, Dawson ED, Taylor AW, Stoughton RS, Blair RH, Johnson JE Jr, Slinskey A, Fessler R, Smith CB, Talbot S, Rowlen K.",Influenza Other Respir Viruses. 2020 Jan;14(1):55-60. doi: 10.1111/irv.12683. Epub 2019 Oct 13.,Toth E,Influenza Other Respir Viruses,2020,15-10-2019,PMC6928037,,10.1111/irv.12683,"BACKGROUND: Global influenza surveillance in humans and animals is a critical component of pandemic preparedness. The FluChip-8G Insight assay was developed to subtype both seasonal and potentially pandemic influenza viruses in a single assay with a same day result. FluChip-8G Insight uses whole gene segment RT-PCR-based amplification to provide robustness against genetic drift and subsequent microarray detection with artificial neural network-based data interpretation.
OBJECTIVES: The objective of this study was to verify and validate the performance of the FluChip-8G Insight assay for the detection and positive identification of human and animal origin non-seasonal influenza A specimens.
METHODS: We evaluated the ability of the FluChip-8G Insight technology to type and HA and NA subtype a sample set consisting of 297 results from 180 unique non-seasonal influenza A strains (49 unique subtypes).
RESULTS: FluChip-8G Insight demonstrated a positive percent agreement ≥93% for 5 targeted HA and 5 targeted NA subtypes except for H9 (88%), and negative percent agreement exceeding 95% for all targeted subtypes.
CONCLUSIONS: The FluChip-8G Insight neural network-based algorithm used for virus identification performed well over a data set of 297 naïve sample results, and can be easily updated to improve performance on emerging strains without changing the underlying assay chemistry.","FluChip-8G Insight: HA and NA subtyping of potentially pandemic influenza A viruses in a single assay BACKGROUND: Global influenza surveillance in humans and animals is a critical component of pandemic preparedness. The FluChip-8G Insight assay was developed to subtype both seasonal and potentially pandemic influenza viruses in a single assay with a same day result. FluChip-8G Insight uses whole gene segment RT-PCR-based amplification to provide robustness against genetic drift and subsequent microarray detection with artificial neural network-based data interpretation.
OBJECTIVES: The objective of this study was to verify and validate the performance of the FluChip-8G Insight assay for the detection and positive identification of human and animal origin non-seasonal influenza A specimens.
METHODS: We evaluated the ability of the FluChip-8G Insight technology to type and HA and NA subtype a sample set consisting of 297 results from 180 unique non-seasonal influenza A strains (49 unique subtypes).
RESULTS: FluChip-8G Insight demonstrated a positive percent agreement ≥93% for 5 targeted HA and 5 targeted NA subtypes except for H9 (88%), and negative percent agreement exceeding 95% for all targeted subtypes.
CONCLUSIONS: The FluChip-8G Insight neural network-based algorithm used for virus identification performed well over a data set of 297 naïve sample results, and can be easily updated to improve performance on emerging strains without changing the underlying assay chemistry.",0,0
32309796,Early epidemiological analysis of the coronavirus disease 2019 outbreak based on crowdsourced data: a population-level observational study,"Sun K, Chen J, Viboud C.",Lancet Digit Health. 2020 Apr;2(4):e201-e208. doi: 10.1016/S2589-7500(20)30026-1. Epub 2020 Feb 20.,Sun K,Lancet Digit Health,2020,21-04-2020,PMC7158945,,10.1016/S2589-7500(20)30026-1,"BACKGROUND: As the outbreak of coronavirus disease 2019 (COVID-19) progresses, epidemiological data are needed to guide situational awareness and intervention strategies. Here we describe efforts to compile and disseminate epidemiological information on COVID-19 from news media and social networks.
METHODS: In this population-level observational study, we searched DXY.cn, a health-care-oriented social network that is currently streaming news reports on COVID-19 from local and national Chinese health agencies. We compiled a list of individual patients with COVID-19 and daily province-level case counts between Jan 13 and Jan 31, 2020, in China. We also compiled a list of internationally exported cases of COVID-19 from global news media sources (Kyodo News, The Straits Times, and CNN), national governments, and health authorities. We assessed trends in the epidemiology of COVID-19 and studied the outbreak progression across China, assessing delays between symptom onset, seeking care at a hospital or clinic, and reporting, before and after Jan 18, 2020, as awareness of the outbreak increased. All data were made publicly available in real time.
FINDINGS: We collected data for 507 patients with COVID-19 reported between Jan 13 and Jan 31, 2020, including 364 from mainland China and 143 from outside of China. 281 (55%) patients were male and the median age was 46 years (IQR 35-60). Few patients (13 [3%]) were younger than 15 years and the age profile of Chinese patients adjusted for baseline demographics confirmed a deficit of infections among children. Across the analysed period, delays between symptom onset and seeking care at a hospital or clinic were longer in Hubei province than in other provinces in mainland China and internationally. In mainland China, these delays decreased from 5 days before Jan 18, 2020, to 2 days thereafter until Jan 31, 2020 (p=0·0009). Although our sample captures only 507 (5·2%) of 9826 patients with COVID-19 reported by official sources during the analysed period, our data align with an official report published by Chinese authorities on Jan 28, 2020.
INTERPRETATION: News reports and social media can help reconstruct the progression of an outbreak and provide detailed patient-level data in the context of a health emergency. The availability of a central physician-oriented social network facilitated the compilation of publicly available COVID-19 data in China. As the outbreak progresses, social media and news reports will probably capture a diminishing fraction of COVID-19 cases globally due to reporting fatigue and overwhelmed health-care systems. In the early stages of an outbreak, availability of public datasets is important to encourage analytical efforts by independent teams and provide robust evidence to guide interventions.
FUNDING: Fogarty International Center, US National Institutes of Health.","Early epidemiological analysis of the coronavirus disease 2019 outbreak based on crowdsourced data: a population-level observational study BACKGROUND: As the outbreak of coronavirus disease 2019 (COVID-19) progresses, epidemiological data are needed to guide situational awareness and intervention strategies. Here we describe efforts to compile and disseminate epidemiological information on COVID-19 from news media and social networks.
METHODS: In this population-level observational study, we searched DXY.cn, a health-care-oriented social network that is currently streaming news reports on COVID-19 from local and national Chinese health agencies. We compiled a list of individual patients with COVID-19 and daily province-level case counts between Jan 13 and Jan 31, 2020, in China. We also compiled a list of internationally exported cases of COVID-19 from global news media sources (Kyodo News, The Straits Times, and CNN), national governments, and health authorities. We assessed trends in the epidemiology of COVID-19 and studied the outbreak progression across China, assessing delays between symptom onset, seeking care at a hospital or clinic, and reporting, before and after Jan 18, 2020, as awareness of the outbreak increased. All data were made publicly available in real time.
FINDINGS: We collected data for 507 patients with COVID-19 reported between Jan 13 and Jan 31, 2020, including 364 from mainland China and 143 from outside of China. 281 (55%) patients were male and the median age was 46 years (IQR 35-60). Few patients (13 [3%]) were younger than 15 years and the age profile of Chinese patients adjusted for baseline demographics confirmed a deficit of infections among children. Across the analysed period, delays between symptom onset and seeking care at a hospital or clinic were longer in Hubei province than in other provinces in mainland China and internationally. In mainland China, these delays decreased from 5 days before Jan 18, 2020, to 2 days thereafter until Jan 31, 2020 (p=0·0009). Although our sample captures only 507 (5·2%) of 9826 patients with COVID-19 reported by official sources during the analysed period, our data align with an official report published by Chinese authorities on Jan 28, 2020.
INTERPRETATION: News reports and social media can help reconstruct the progression of an outbreak and provide detailed patient-level data in the context of a health emergency. The availability of a central physician-oriented social network facilitated the compilation of publicly available COVID-19 data in China. As the outbreak progresses, social media and news reports will probably capture a diminishing fraction of COVID-19 cases globally due to reporting fatigue and overwhelmed health-care systems. In the early stages of an outbreak, availability of public datasets is important to encourage analytical efforts by independent teams and provide robust evidence to guide interventions.
FUNDING: Fogarty International Center, US National Institutes of Health.",0,0
34731188,Predicting increases in COVID-19 incidence to identify locations for targeted testing in West Virginia: A machine learning enhanced approach,"Price BS, Khodaverdi M, Halasz A, Hendricks B, Kimble W, Smith GS, Hodder SL.",PLoS One. 2021 Nov 3;16(11):e0259538. doi: 10.1371/journal.pone.0259538. eCollection 2021.,Price BS,PLoS One,2021,03-11-2021,PMC8565789,,10.1371/journal.pone.0259538,"During the COVID-19 pandemic, West Virginia developed an aggressive SARS-CoV-2 testing strategy which included utilizing pop-up mobile testing in locations anticipated to have near-term increases in SARS-CoV-2 infections. This study describes and compares two methods for predicting near-term SARS-CoV-2 incidence in West Virginia counties. The first method, Rt Only, is solely based on producing forecasts for each county using the daily instantaneous reproductive numbers, Rt. The second method, ML+Rt, is a machine learning approach that uses a Long Short-Term Memory network to predict the near-term number of cases for each county using epidemiological statistics such as Rt, county population information, and time series trends including information on major holidays, as well as leveraging statewide COVID-19 trends across counties and county population size. Both approaches used daily county-level SARS-CoV-2 incidence data provided by the West Virginia Department Health and Human Resources beginning April 2020. The methods are compared on the accuracy of near-term SARS-CoV-2 increases predictions by county over 17 weeks from January 1, 2021- April 30, 2021. Both methods performed well (correlation between forecasted number of cases and the actual number of cases week over week is 0.872 for the ML+Rt method and 0.867 for the Rt Only method) but differ in performance at various time points. Over the 17-week assessment period, the ML+Rt method outperforms the Rt Only method in identifying larger spikes. Results show that both methods perform adequately in both rural and non-rural predictions. Finally, a detailed discussion on practical issues regarding implementing forecasting models for public health action based on Rt is provided, and the potential for further development of machine learning methods that are enhanced by Rt.","Predicting increases in COVID-19 incidence to identify locations for targeted testing in West Virginia: A machine learning enhanced approach During the COVID-19 pandemic, West Virginia developed an aggressive SARS-CoV-2 testing strategy which included utilizing pop-up mobile testing in locations anticipated to have near-term increases in SARS-CoV-2 infections. This study describes and compares two methods for predicting near-term SARS-CoV-2 incidence in West Virginia counties. The first method, Rt Only, is solely based on producing forecasts for each county using the daily instantaneous reproductive numbers, Rt. The second method, ML+Rt, is a machine learning approach that uses a Long Short-Term Memory network to predict the near-term number of cases for each county using epidemiological statistics such as Rt, county population information, and time series trends including information on major holidays, as well as leveraging statewide COVID-19 trends across counties and county population size. Both approaches used daily county-level SARS-CoV-2 incidence data provided by the West Virginia Department Health and Human Resources beginning April 2020. The methods are compared on the accuracy of near-term SARS-CoV-2 increases predictions by county over 17 weeks from January 1, 2021- April 30, 2021. Both methods performed well (correlation between forecasted number of cases and the actual number of cases week over week is 0.872 for the ML+Rt method and 0.867 for the Rt Only method) but differ in performance at various time points. Over the 17-week assessment period, the ML+Rt method outperforms the Rt Only method in identifying larger spikes. Results show that both methods perform adequately in both rural and non-rural predictions. Finally, a detailed discussion on practical issues regarding implementing forecasting models for public health action based on Rt is provided, and the potential for further development of machine learning methods that are enhanced by Rt.",0,1
25621078,Predicting outcomes in patients with perforated gastroduodenal ulcers: artificial neural network modelling indicates a highly complex disease,"Søreide K, Thorsen K, Søreide JA.",Eur J Trauma Emerg Surg. 2015 Feb;41(1):91-8. doi: 10.1007/s00068-014-0417-4. Epub 2014 Jun 14.,Søreide K,Eur J Trauma Emerg Surg,2015,27-01-2015,PMC4298653,,10.1007/s00068-014-0417-4,"PURPOSE: Mortality prediction models for patients with perforated peptic ulcer (PPU) have not yielded consistent or highly accurate results. Given the complex nature of this disease, which has many non-linear associations with outcomes, we explored artificial neural networks (ANNs) to predict the complex interactions between the risk factors of PPU and death among patients with this condition.
METHODS: ANN modelling using a standard feed-forward, back-propagation neural network with three layers (i.e., an input layer, a hidden layer and an output layer) was used to predict the 30-day mortality of consecutive patients from a population-based cohort undergoing surgery for PPU. A receiver-operating characteristic (ROC) analysis was used to assess model accuracy.
RESULTS: Of the 172 patients, 168 had their data included in the model; the data of 117 (70%) were used for the training set, and the data of 51 (39%) were used for the test set. The accuracy, as evaluated by area under the ROC curve (AUC), was best for an inclusive, multifactorial ANN model (AUC 0.90, 95% CIs 0.85-0.95; p < 0.001). This model outperformed standard predictive scores, including Boey and PULP. The importance of each variable decreased as the number of factors included in the ANN model increased.
CONCLUSIONS: The prediction of death was most accurate when using an ANN model with several univariate influences on the outcome. This finding demonstrates that PPU is a highly complex disease for which clinical prognoses are likely difficult. The incorporation of computerised learning systems might enhance clinical judgments to improve decision making and outcome prediction.","Predicting outcomes in patients with perforated gastroduodenal ulcers: artificial neural network modelling indicates a highly complex disease PURPOSE: Mortality prediction models for patients with perforated peptic ulcer (PPU) have not yielded consistent or highly accurate results. Given the complex nature of this disease, which has many non-linear associations with outcomes, we explored artificial neural networks (ANNs) to predict the complex interactions between the risk factors of PPU and death among patients with this condition.
METHODS: ANN modelling using a standard feed-forward, back-propagation neural network with three layers (i.e., an input layer, a hidden layer and an output layer) was used to predict the 30-day mortality of consecutive patients from a population-based cohort undergoing surgery for PPU. A receiver-operating characteristic (ROC) analysis was used to assess model accuracy.
RESULTS: Of the 172 patients, 168 had their data included in the model; the data of 117 (70%) were used for the training set, and the data of 51 (39%) were used for the test set. The accuracy, as evaluated by area under the ROC curve (AUC), was best for an inclusive, multifactorial ANN model (AUC 0.90, 95% CIs 0.85-0.95; p < 0.001). This model outperformed standard predictive scores, including Boey and PULP. The importance of each variable decreased as the number of factors included in the ANN model increased.
CONCLUSIONS: The prediction of death was most accurate when using an ANN model with several univariate influences on the outcome. This finding demonstrates that PPU is a highly complex disease for which clinical prognoses are likely difficult. The incorporation of computerised learning systems might enhance clinical judgments to improve decision making and outcome prediction.",1,0
34642701,Predicting increases in COVID-19 incidence to identify locations for targeted testing in West Virginia: A machine learning enhanced approach,"Price BS, Khodaverdi M, Halasz A, Hendricks B, Kimble W, Smith GS, Hodder SL.",medRxiv [Preprint]. 2021 Oct 7:2021.10.06.21264569. doi: 10.1101/2021.10.06.21264569.,Price BS,medRxiv,2021,13-10-2021,PMC8509102,,10.1101/2021.10.06.21264569,"During the COVID-19 pandemic, West Virginia developed an aggressive SARS-CoV-2 testing strategy which included utilizing pop-up mobile testing in locations anticipated to have near-term increases in SARS-CXoV-2 infections. In this study, we describe and compare two methods for predicting near-term SARS-CoV-2 incidence in West Virginia counties. The first method, R <sub>t</sub> Only, is solely based on producing forecasts for each county using the daily instantaneous reproductive numbers, R <sub>t.</sub> The second method, ML+ R <sub>t</sub> , is a machine learning approach that uses a Long Short-Term Memory network to predict the near-term number of cases for each county using epidemiological statistics such as Rt, county population information, and time series trends including information on major holidays, as well as leveraging statewide COVID-19 trends across counties and county population size. Both approaches used daily county-level SARS-CoV-2 incidence data provided by the West Virginia Department Health and Human Resources beginning April 2020. The methods are compared on the accuracy of near-term SARS-CoV-2 increases predictions by county over 17 weeks from January 1, 2021-April 30, 2021. Both methods performed well (correlation between forecasted number of cases and the actual number of cases week over week is 0.872 for the ML+R <sub>t</sub> method and 0.867 for the R <sub>t</sub> Only method) but differ in performance at various time points. Over the 17-week assessment period, the ML+R <sub>t</sub> method outperforms the R <sub>t</sub> Only method in identifying larger spikes. We also find that both methods perform adequately in both rural and non-rural predictions. Finally, we provide a detailed discussion on practical issues regarding implementing forecasting models for public health action based on R <sub>t</sub> , and the potential for further development of machine learning methods that are enhanced by R <sub>t.</sub>","Predicting increases in COVID-19 incidence to identify locations for targeted testing in West Virginia: A machine learning enhanced approach During the COVID-19 pandemic, West Virginia developed an aggressive SARS-CoV-2 testing strategy which included utilizing pop-up mobile testing in locations anticipated to have near-term increases in SARS-CXoV-2 infections. In this study, we describe and compare two methods for predicting near-term SARS-CoV-2 incidence in West Virginia counties. The first method, R <sub>t</sub> Only, is solely based on producing forecasts for each county using the daily instantaneous reproductive numbers, R <sub>t.</sub> The second method, ML+ R <sub>t</sub> , is a machine learning approach that uses a Long Short-Term Memory network to predict the near-term number of cases for each county using epidemiological statistics such as Rt, county population information, and time series trends including information on major holidays, as well as leveraging statewide COVID-19 trends across counties and county population size. Both approaches used daily county-level SARS-CoV-2 incidence data provided by the West Virginia Department Health and Human Resources beginning April 2020. The methods are compared on the accuracy of near-term SARS-CoV-2 increases predictions by county over 17 weeks from January 1, 2021-April 30, 2021. Both methods performed well (correlation between forecasted number of cases and the actual number of cases week over week is 0.872 for the ML+R <sub>t</sub> method and 0.867 for the R <sub>t</sub> Only method) but differ in performance at various time points. Over the 17-week assessment period, the ML+R <sub>t</sub> method outperforms the R <sub>t</sub> Only method in identifying larger spikes. We also find that both methods perform adequately in both rural and non-rural predictions. Finally, we provide a detailed discussion on practical issues regarding implementing forecasting models for public health action based on R <sub>t</sub> , and the potential for further development of machine learning methods that are enhanced by R <sub>t.</sub>",0,1
39198754,Study on the impact of meteorological factors on influenza in different periods and prediction based on artificial intelligence RF-Bi-LSTM algorithm: to compare the COVID-19 period with the non-COVID-19 period,"Zhu H, Chen S, Qin W, Aynur J, Chen Y, Wang X, Chen K, Xie Z, Li L, Liu Y, Chen G, Ou J, Zheng K.",BMC Infect Dis. 2024 Aug 28;24(1):878. doi: 10.1186/s12879-024-09750-x.,Zhu H,BMC Infect Dis,2024,28-08-2024,PMC11360838,,10.1186/s12879-024-09750-x,"OBJECTIVE: At different times, public health faces various challenges and the degree of intervention measures varies. The research on the impact and prediction of meteorology factors on influenza is increasing gradually, however, there is currently no evidence on whether its research results are affected by different periods. This study aims to provide limited evidence to reveal this issue.
METHODS: Daily data on influencing factors and influenza in Xiamen were divided into three parts: overall period (phase AB), non-COVID-19 epidemic period (phase A), and COVID-19 epidemic period (phase B). The association between influencing factors and influenza was analysed using generalized additive models (GAMs). The excess risk (ER) was used to represent the percentage change in influenza as the interquartile interval (IQR) of meteorology factors increases. The 7-day average daily influenza cases were predicted using the combination of bi-directional long short memory (Bi-LSTM) and random forest (RF) through multi-step rolling input of the daily multifactor values of the previous 7-day.
RESULTS: In periods A and AB, air temperature below 22 °C was a risk factor for influenza. However, in phase B, temperature showed a U-shaped effect on it. Relative humidity had a more significant cumulative effect on influenza in phase AB than in phase A (peak: accumulate 14d, AB: ER = 281.54, 95% CI = 245.47 ~ 321.37; A: ER = 120.48, 95% CI = 100.37 ~ 142.60). Compared to other age groups, children aged 4-12 were more affected by pressure, precipitation, sunshine, and day light, while those aged ≥ 13 were more affected by the accumulation of humidity over multiple days. The accuracy of predicting influenza was highest in phase A and lowest in phase B.
CONCLUSIONS: The varying degrees of intervention measures adopted during different phases led to significant differences in the impact of meteorology factors on influenza and in the influenza prediction. In association studies of respiratory infectious diseases, especially influenza, and environmental factors, it is advisable to exclude periods with more external interventions to reduce interference with environmental factors and influenza related research, or to refine the model to accommodate the alterations brought about by intervention measures. In addition, the RF-Bi-LSTM model has good predictive performance for influenza.","Study on the impact of meteorological factors on influenza in different periods and prediction based on artificial intelligence RF-Bi-LSTM algorithm: to compare the COVID-19 period with the non-COVID-19 period OBJECTIVE: At different times, public health faces various challenges and the degree of intervention measures varies. The research on the impact and prediction of meteorology factors on influenza is increasing gradually, however, there is currently no evidence on whether its research results are affected by different periods. This study aims to provide limited evidence to reveal this issue.
METHODS: Daily data on influencing factors and influenza in Xiamen were divided into three parts: overall period (phase AB), non-COVID-19 epidemic period (phase A), and COVID-19 epidemic period (phase B). The association between influencing factors and influenza was analysed using generalized additive models (GAMs). The excess risk (ER) was used to represent the percentage change in influenza as the interquartile interval (IQR) of meteorology factors increases. The 7-day average daily influenza cases were predicted using the combination of bi-directional long short memory (Bi-LSTM) and random forest (RF) through multi-step rolling input of the daily multifactor values of the previous 7-day.
RESULTS: In periods A and AB, air temperature below 22 °C was a risk factor for influenza. However, in phase B, temperature showed a U-shaped effect on it. Relative humidity had a more significant cumulative effect on influenza in phase AB than in phase A (peak: accumulate 14d, AB: ER = 281.54, 95% CI = 245.47 ~ 321.37; A: ER = 120.48, 95% CI = 100.37 ~ 142.60). Compared to other age groups, children aged 4-12 were more affected by pressure, precipitation, sunshine, and day light, while those aged ≥ 13 were more affected by the accumulation of humidity over multiple days. The accuracy of predicting influenza was highest in phase A and lowest in phase B.
CONCLUSIONS: The varying degrees of intervention measures adopted during different phases led to significant differences in the impact of meteorology factors on influenza and in the influenza prediction. In association studies of respiratory infectious diseases, especially influenza, and environmental factors, it is advisable to exclude periods with more external interventions to reduce interference with environmental factors and influenza related research, or to refine the model to accommodate the alterations brought about by intervention measures. In addition, the RF-Bi-LSTM model has good predictive performance for influenza.",1,1
39570994,Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models,"Madden WG, Jin W, Lopman B, Zufle A, Dalziel B, E Metcalf CJ, Grenfell BT, Lau MSY.",PLoS Comput Biol. 2024 Nov 21;20(11):e1012616. doi: 10.1371/journal.pcbi.1012616. eCollection 2024 Nov.,Madden WG,PLoS Comput Biol,2024,21-11-2024,PMC11620694,,10.1371/journal.pcbi.1012616,"Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that while the TSIR model yields similarly performant short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, our neural network model (SFNN) consistently achieves lower root mean squared error (RMSE) across other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental models and neural networks. Our results show that the TSIR can facilitate the reconstruction of latent susceptible dynamics, thereby enhancing both forecasts in terms of mean absolute error (MAE) and parameter inference of measles dynamics within the PINN. In summary, our results show that appropriately designed neural network-based models can outperform traditional mechanistic models for short to long-term forecasts, while simultaneously providing mechanistic interpretability. Our work also provides valuable insights into more effectively integrating machine learning models with mechanistic models to enhance public health responses to measles and similar infectious disease systems.","Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that while the TSIR model yields similarly performant short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, our neural network model (SFNN) consistently achieves lower root mean squared error (RMSE) across other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental models and neural networks. Our results show that the TSIR can facilitate the reconstruction of latent susceptible dynamics, thereby enhancing both forecasts in terms of mean absolute error (MAE) and parameter inference of measles dynamics within the PINN. In summary, our results show that appropriately designed neural network-based models can outperform traditional mechanistic models for short to long-term forecasts, while simultaneously providing mechanistic interpretability. Our work also provides valuable insights into more effectively integrating machine learning models with mechanistic models to enhance public health responses to measles and similar infectious disease systems.",1,1
35564940,Predictive Models for Forecasting Public Health Scenarios: Practical Experiences Applied during the First Wave of the COVID-19 Pandemic,"Martin-Moreno JM, Alegre-Martinez A, Martin-Gorgojo V, Alfonso-Sanchez JL, Torres F, Pallares-Carratala V.",Int J Environ Res Public Health. 2022 May 3;19(9):5546. doi: 10.3390/ijerph19095546.,Martin-Moreno JM,Int J Environ Res Public Health,2022,14-05-2022,PMC9101183,,10.3390/ijerph19095546,"Background: Forecasting the behavior of epidemic outbreaks is vital in public health. This makes it possible to anticipate the planning and organization of the health system, as well as possible restrictive or preventive measures. During the COVID-19 pandemic, this need for prediction has been crucial. This paper attempts to characterize the alternative models that were applied in the first wave of this pandemic context, trying to shed light that could help to understand them for future practical applications. Methods: A systematic literature search was performed in standardized bibliographic repertoires, using keywords and Boolean operators to refine the findings, and selecting articles according to the main PRISMA 2020 statement recommendations. Results: After identifying models used throughout the first wave of this pandemic (between March and June 2020), we begin by examining standard data-driven epidemiological models, including studies applying models such as SIR (Susceptible-Infected-Recovered), SQUIDER, SEIR, time-dependent SIR, and other alternatives. For data-driven methods, we identify experiences using autoregressive integrated moving average (ARIMA), evolutionary genetic programming machine learning, short-term memory (LSTM), and global epidemic and mobility models. Conclusions: The COVID-19 pandemic has led to intensive and evolving use of alternative infectious disease prediction models. At this point it is not easy to decide which prediction method is the best in a generic way. Moreover, although models such as the LSTM emerge as remarkably versatile and useful, the practical applicability of the alternatives depends on the specific context of the underlying variable and on the information of the target to be prioritized. In addition, the robustness of the assessment is conditioned by heterogeneity in the quality of information sources and differences in the characteristics of disease control interventions. Further comprehensive comparison of the performance of models in comparable situations, assessing their predictive validity, is needed. This will help determine the most reliable and practical methods for application in future outbreaks and eventual pandemics.","Predictive Models for Forecasting Public Health Scenarios: Practical Experiences Applied during the First Wave of the COVID-19 Pandemic Background: Forecasting the behavior of epidemic outbreaks is vital in public health. This makes it possible to anticipate the planning and organization of the health system, as well as possible restrictive or preventive measures. During the COVID-19 pandemic, this need for prediction has been crucial. This paper attempts to characterize the alternative models that were applied in the first wave of this pandemic context, trying to shed light that could help to understand them for future practical applications. Methods: A systematic literature search was performed in standardized bibliographic repertoires, using keywords and Boolean operators to refine the findings, and selecting articles according to the main PRISMA 2020 statement recommendations. Results: After identifying models used throughout the first wave of this pandemic (between March and June 2020), we begin by examining standard data-driven epidemiological models, including studies applying models such as SIR (Susceptible-Infected-Recovered), SQUIDER, SEIR, time-dependent SIR, and other alternatives. For data-driven methods, we identify experiences using autoregressive integrated moving average (ARIMA), evolutionary genetic programming machine learning, short-term memory (LSTM), and global epidemic and mobility models. Conclusions: The COVID-19 pandemic has led to intensive and evolving use of alternative infectious disease prediction models. At this point it is not easy to decide which prediction method is the best in a generic way. Moreover, although models such as the LSTM emerge as remarkably versatile and useful, the practical applicability of the alternatives depends on the specific context of the underlying variable and on the information of the target to be prioritized. In addition, the robustness of the assessment is conditioned by heterogeneity in the quality of information sources and differences in the characteristics of disease control interventions. Further comprehensive comparison of the performance of models in comparable situations, assessing their predictive validity, is needed. This will help determine the most reliable and practical methods for application in future outbreaks and eventual pandemics.",1,1
38698304,Prediction of hospital-acquired influenza using machine learning algorithms: a comparative study,"Cho Y, Lee HK, Kim J, Yoo KB, Choi J, Lee Y, Choi M.",BMC Infect Dis. 2024 May 2;24(1):466. doi: 10.1186/s12879-024-09358-1.,Cho Y,BMC Infect Dis,2024,02-05-2024,PMC11067145,,10.1186/s12879-024-09358-1,"BACKGROUND: Hospital-acquired influenza (HAI) is under-recognized despite its high morbidity and poor health outcomes. The early detection of HAI is crucial for curbing its transmission in hospital settings.
AIM: This study aimed to investigate factors related to HAI, develop predictive models, and subsequently compare them to identify the best performing machine learning algorithm for predicting the occurrence of HAI.
METHODS: This retrospective observational study was conducted in 2022 and included 111 HAI and 73,748 non-HAI patients from the 2011-2012 and 2019-2020 influenza seasons. General characteristics, comorbidities, vital signs, laboratory and chest X-ray results, and room information within the electronic medical record were analysed. Logistic Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Network (ANN) techniques were used to construct the predictive models. Employing randomized allocation, 80% of the dataset constituted the training set, and the remaining 20% comprised the test set. The performance of the developed models was assessed using metrics such as the area under the receiver operating characteristic curve (AUC), the count of false negatives (FN), and the determination of feature importance.
RESULTS: Patients with HAI demonstrated notable differences in general characteristics, comorbidities, vital signs, laboratory findings, chest X-ray result, and room status compared to non-HAI patients. Among the developed models, the RF model demonstrated the best performance taking into account both the AUC (83.3%) and the occurrence of FN (four). The most influential factors for prediction were staying in double rooms, followed by vital signs and laboratory results.
CONCLUSION: This study revealed the characteristics of patients with HAI and emphasized the role of ventilation in reducing influenza incidence. These findings can aid hospitals in devising infection prevention strategies, and the application of machine learning-based predictive models especially RF can enable early intervention to mitigate the spread of influenza in healthcare settings.","Prediction of hospital-acquired influenza using machine learning algorithms: a comparative study BACKGROUND: Hospital-acquired influenza (HAI) is under-recognized despite its high morbidity and poor health outcomes. The early detection of HAI is crucial for curbing its transmission in hospital settings.
AIM: This study aimed to investigate factors related to HAI, develop predictive models, and subsequently compare them to identify the best performing machine learning algorithm for predicting the occurrence of HAI.
METHODS: This retrospective observational study was conducted in 2022 and included 111 HAI and 73,748 non-HAI patients from the 2011-2012 and 2019-2020 influenza seasons. General characteristics, comorbidities, vital signs, laboratory and chest X-ray results, and room information within the electronic medical record were analysed. Logistic Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Network (ANN) techniques were used to construct the predictive models. Employing randomized allocation, 80% of the dataset constituted the training set, and the remaining 20% comprised the test set. The performance of the developed models was assessed using metrics such as the area under the receiver operating characteristic curve (AUC), the count of false negatives (FN), and the determination of feature importance.
RESULTS: Patients with HAI demonstrated notable differences in general characteristics, comorbidities, vital signs, laboratory findings, chest X-ray result, and room status compared to non-HAI patients. Among the developed models, the RF model demonstrated the best performance taking into account both the AUC (83.3%) and the occurrence of FN (four). The most influential factors for prediction were staying in double rooms, followed by vital signs and laboratory results.
CONCLUSION: This study revealed the characteristics of patients with HAI and emphasized the role of ventilation in reducing influenza incidence. These findings can aid hospitals in devising infection prevention strategies, and the application of machine learning-based predictive models especially RF can enable early intervention to mitigate the spread of influenza in healthcare settings.",1,1
26270814,"Comparison of Two Hybrid Models for Forecasting the Incidence of Hemorrhagic Fever with Renal Syndrome in Jiangsu Province, China","Wu W, Guo J, An S, Guan P, Ren Y, Xia L, Zhou B.",PLoS One. 2015 Aug 13;10(8):e0135492. doi: 10.1371/journal.pone.0135492. eCollection 2015.,Wu W,PLoS One,2015,14-08-2015,PMC4536138,,10.1371/journal.pone.0135492,"BACKGROUND: Cases of hemorrhagic fever with renal syndrome (HFRS) are widely distributed in eastern Asia, especially in China, Russia, and Korea. It is proved to be a difficult task to eliminate HFRS completely because of the diverse animal reservoirs and effects of global warming. Reliable forecasting is useful for the prevention and control of HFRS.
METHODS: Two hybrid models, one composed of nonlinear autoregressive neural network (NARNN) and autoregressive integrated moving average (ARIMA) the other composed of generalized regression neural network (GRNN) and ARIMA were constructed to predict the incidence of HFRS in the future one year. Performances of the two hybrid models were compared with ARIMA model.
RESULTS: The ARIMA, ARIMA-NARNN ARIMA-GRNN model fitted and predicted the seasonal fluctuation well. Among the three models, the mean square error (MSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of ARIMA-NARNN hybrid model was the lowest both in modeling stage and forecasting stage. As for the ARIMA-GRNN hybrid model, the MSE, MAE and MAPE of modeling performance and the MSE and MAE of forecasting performance were less than the ARIMA model, but the MAPE of forecasting performance did not improve.
CONCLUSION: Developing and applying the ARIMA-NARNN hybrid model is an effective method to make us better understand the epidemic characteristics of HFRS and could be helpful to the prevention and control of HFRS.","Comparison of Two Hybrid Models for Forecasting the Incidence of Hemorrhagic Fever with Renal Syndrome in Jiangsu Province, China BACKGROUND: Cases of hemorrhagic fever with renal syndrome (HFRS) are widely distributed in eastern Asia, especially in China, Russia, and Korea. It is proved to be a difficult task to eliminate HFRS completely because of the diverse animal reservoirs and effects of global warming. Reliable forecasting is useful for the prevention and control of HFRS.
METHODS: Two hybrid models, one composed of nonlinear autoregressive neural network (NARNN) and autoregressive integrated moving average (ARIMA) the other composed of generalized regression neural network (GRNN) and ARIMA were constructed to predict the incidence of HFRS in the future one year. Performances of the two hybrid models were compared with ARIMA model.
RESULTS: The ARIMA, ARIMA-NARNN ARIMA-GRNN model fitted and predicted the seasonal fluctuation well. Among the three models, the mean square error (MSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of ARIMA-NARNN hybrid model was the lowest both in modeling stage and forecasting stage. As for the ARIMA-GRNN hybrid model, the MSE, MAE and MAPE of modeling performance and the MSE and MAE of forecasting performance were less than the ARIMA model, but the MAPE of forecasting performance did not improve.
CONCLUSION: Developing and applying the ARIMA-NARNN hybrid model is an effective method to make us better understand the epidemic characteristics of HFRS and could be helpful to the prevention and control of HFRS.",0,1
31775813,The external validation of a difficulty scoring system for predicting the risk of intraoperative complications during laparoscopic liver resection,"Ivanecz A, Plahuta I, Magdalenić T, Mencinger M, Peruš I, Potrč S, Krebs B.",BMC Surg. 2019 Nov 27;19(1):179. doi: 10.1186/s12893-019-0645-y.,Ivanecz A,BMC Surg,2019,29-11-2019,PMC6882247,,10.1186/s12893-019-0645-y,"BACKGROUND: This study aimed to externally validate and upgrade the recent difficulty scoring system (DSS) proposed by Halls et al. to predict intraoperative complications (IOC) during laparoscopic liver resection (LLR).
METHODS: The DSS was validated in a cohort of 128 consecutive patients undergoing pure LLRs between 2008 and 2019 at a single tertiary referral center. The validated DSS includes four difficulty levels based on five risk factors (neoadjuvant chemotherapy, previous open liver resection, lesion type, lesion size and classification of resection). As established by the validated DSS, IOC was defined as excessive blood loss (> 775 mL), conversion to an open approach and unintentional damage to surrounding structures. Additionally, intra- and postoperative outcomes were compared according to the difficulty levels with usual statistic methods. The same five risk factors were used for validation done by linear and advanced nonlinear (artificial neural network) models. The study was supported by mathematical computations to obtain a mean risk curve predicting the probability of IOC for every difficulty score.
RESULTS: The difficulty level of LLR was rated as low, moderate, high and extremely high in 36 (28.1%), 63 (49.2%), 27 (21.1%) and 2 (1.6%) patients, respectively. IOC was present in 23 (17.9%) patients. Blood loss of >775 mL occurred in 8 (6.2%) patients. Conversion to open approach was required in 18 (14.0%) patients. No patients suffered from unintentional damage to surrounding structures. Rates of IOC (0, 9.5, 55.5 and 100%) increased gradually with statistically significant value among difficulty levels (P < 0.001). The relations between the difficulty level, need for transfusion, operative time, hepatic pedicle clamping, and major postoperative morbidity were statistically significant (P < 0.05). Linear and nonlinear validation models showed a strong correlation (correlation coefficients 0.914 and 0.948, respectively) with the validated DSS. The Weibull cumulative distribution function was used for predicting the mean risk probability curve of IOC.
CONCLUSION: This external validation proved this DSS based on patient's, tumor and surgical factors enables us to estimate the risk of intra- and postoperative complications. A surgeon should be aware of an increased risk of complications before starting with more complex procedures.","The external validation of a difficulty scoring system for predicting the risk of intraoperative complications during laparoscopic liver resection BACKGROUND: This study aimed to externally validate and upgrade the recent difficulty scoring system (DSS) proposed by Halls et al. to predict intraoperative complications (IOC) during laparoscopic liver resection (LLR).
METHODS: The DSS was validated in a cohort of 128 consecutive patients undergoing pure LLRs between 2008 and 2019 at a single tertiary referral center. The validated DSS includes four difficulty levels based on five risk factors (neoadjuvant chemotherapy, previous open liver resection, lesion type, lesion size and classification of resection). As established by the validated DSS, IOC was defined as excessive blood loss (> 775 mL), conversion to an open approach and unintentional damage to surrounding structures. Additionally, intra- and postoperative outcomes were compared according to the difficulty levels with usual statistic methods. The same five risk factors were used for validation done by linear and advanced nonlinear (artificial neural network) models. The study was supported by mathematical computations to obtain a mean risk curve predicting the probability of IOC for every difficulty score.
RESULTS: The difficulty level of LLR was rated as low, moderate, high and extremely high in 36 (28.1%), 63 (49.2%), 27 (21.1%) and 2 (1.6%) patients, respectively. IOC was present in 23 (17.9%) patients. Blood loss of >775 mL occurred in 8 (6.2%) patients. Conversion to open approach was required in 18 (14.0%) patients. No patients suffered from unintentional damage to surrounding structures. Rates of IOC (0, 9.5, 55.5 and 100%) increased gradually with statistically significant value among difficulty levels (P < 0.001). The relations between the difficulty level, need for transfusion, operative time, hepatic pedicle clamping, and major postoperative morbidity were statistically significant (P < 0.05). Linear and nonlinear validation models showed a strong correlation (correlation coefficients 0.914 and 0.948, respectively) with the validated DSS. The Weibull cumulative distribution function was used for predicting the mean risk probability curve of IOC.
CONCLUSION: This external validation proved this DSS based on patient's, tumor and surgical factors enables us to estimate the risk of intra- and postoperative complications. A surgeon should be aware of an increased risk of complications before starting with more complex procedures.",0,0
38725544,Validation of a Thai artificial chatmate designed for cheering up the elderly during the COVID-19 pandemic,"Deepaisarn S, Imkome EU, Wongpatikaseree K, Yuenyong S, Lakanavisid P, Soonthornchaiva R, Yomaboot P, Angkoonsawaengsuk A, Munpansa N.",F1000Res. 2024 Feb 28;11:1411. doi: 10.12688/f1000research.127431.3. eCollection 2022.,Deepaisarn S,F1000Res,2024,10-05-2024,PMC11079584,,10.12688/f1000research.127431.3,"BACKGROUND: The COVID-19 pandemic severely affected populations of all age groups. The elderly are a high-risk group and are highly vulnerable to COVID-19. Assistive software chatbots can enhance the mental health status of the elderly by providing support and companionship. The objective of this study was to validate a Thai artificial chatmate for the elderly during the COVID-19 pandemic and floods.
METHODS: Chatbot design includes the establishment of a dataset and emotional word vectors in which data consisting of emotional sentences were converted into the word vector form using a pre-trained word2vec model. A word vector was then input into a convolutional neural network (CNN) and trained until the model converges using sentence embedding and similarity word segmentation. Sentence vectors were generated by averaging each word vector using an averaged vector method. For approximate similarity matching, the Annoy library was used to create the indices in tree sorting. Data were collected from 22 elderly and assessed by the Post-Study System Usability Questionnaire (PSSUQ).
RESULTS: The study revealed that 72.73% of the respondents found the chatbot easy to learn and use, 63.64% of the respondents found the chatbot can autonomously determine the next course of action, and 59.09% of the respondents believed that troubleshooting guidelines were provided for overcoming errors. The accuracy of the chatbot providing a reasonable response is 56.20±13.99%.
CONCLUSIONS: Most users were satisfied with the chatbot system. The proposed chatbot provided considerable essential insights into the development of assistance systems for the elderly during the coronavirus pandemic (COVID-19) and during the period of national disasters. The model can be expanded to other applications in the future.","Validation of a Thai artificial chatmate designed for cheering up the elderly during the COVID-19 pandemic BACKGROUND: The COVID-19 pandemic severely affected populations of all age groups. The elderly are a high-risk group and are highly vulnerable to COVID-19. Assistive software chatbots can enhance the mental health status of the elderly by providing support and companionship. The objective of this study was to validate a Thai artificial chatmate for the elderly during the COVID-19 pandemic and floods.
METHODS: Chatbot design includes the establishment of a dataset and emotional word vectors in which data consisting of emotional sentences were converted into the word vector form using a pre-trained word2vec model. A word vector was then input into a convolutional neural network (CNN) and trained until the model converges using sentence embedding and similarity word segmentation. Sentence vectors were generated by averaging each word vector using an averaged vector method. For approximate similarity matching, the Annoy library was used to create the indices in tree sorting. Data were collected from 22 elderly and assessed by the Post-Study System Usability Questionnaire (PSSUQ).
RESULTS: The study revealed that 72.73% of the respondents found the chatbot easy to learn and use, 63.64% of the respondents found the chatbot can autonomously determine the next course of action, and 59.09% of the respondents believed that troubleshooting guidelines were provided for overcoming errors. The accuracy of the chatbot providing a reasonable response is 56.20±13.99%.
CONCLUSIONS: Most users were satisfied with the chatbot system. The proposed chatbot provided considerable essential insights into the development of assistance systems for the elderly during the coronavirus pandemic (COVID-19) and during the period of national disasters. The model can be expanded to other applications in the future.",1,0
35618276,"Indoor microbiome, microbial and plant metabolites, chemical compounds, and asthma symptoms in junior high school students: a multicentre association study in Malaysia","Sun Y, Zhang M, Ou Z, Meng Y, Chen Y, Lin R, Hashim JH, Hashim Z, Wieslander G, Chen Q, Norbäck D, Fu X.",Eur Respir J. 2022 Nov 10;60(5):2200260. doi: 10.1183/13993003.00260-2022. Print 2022 Nov.,Sun Y,Eur Respir J,2022,26-05-2022,PMC9647074,,10.1183/13993003.00260-2022,"BACKGROUND: Indoor microbial exposure is associated with asthma, but the health effects of indoor metabolites and chemicals have not been comprehensively assessed.
METHODS: We collected classroom dust from 24 junior high schools in three geographically distanced areas in Malaysia (Johor Bahru, Terengganu and Penang), and conducted culture-independent high-throughput microbiome and untargeted metabolomics/chemical profiling.
RESULTS: 1290 students were surveyed for asthma symptoms (wheeze). In each centre, we found significant variation in the prevalence of wheeze among schools, which could be explained by personal characteristics and air pollutants. Large-scale microbial variations were observed between the three centres; the potential protective bacteria were mainly from phyla Actinobacteria in Johor Bahru, Cyanobacteria in Terengganu and Proteobacteria in Penang. In total, 2633 metabolites and chemicals were characterised. Many metabolites were enriched in low-wheeze schools, including plant secondary metabolites flavonoids/isoflavonoids (isoliquiritigenin, formononetin, astragalin), indole and derivatives (indole, serotonin, 1H-indole-3-carboxaldehyde), and others (biotin, chavicol). A neural network analysis showed that the indole derivatives were co-occurring with the potential protective microbial taxa, including Actinomycetospora, Fischerella and Truepera, suggesting these microorganisms may pose health effects by releasing indole metabolites. A few synthetic chemicals were enriched in high-wheeze schools, including pesticides (2(3H)-benzothiazolethione), fragrances (2-aminobenzoic acid, isovaleric acid), detergents and plastics (phthalic acid), and industrial materials (4,4-sulfonyldiphenol).
CONCLUSIONS: This is the first association study between high-throughput indoor chemical profiling and asthma symptoms. The consistent results from the three centres indicate that indoor metabolites/chemicals could be a better indicator than the indoor microbiome for environmental and health assessments, providing new insights for asthma prediction, prevention and control.","Indoor microbiome, microbial and plant metabolites, chemical compounds, and asthma symptoms in junior high school students: a multicentre association study in Malaysia BACKGROUND: Indoor microbial exposure is associated with asthma, but the health effects of indoor metabolites and chemicals have not been comprehensively assessed.
METHODS: We collected classroom dust from 24 junior high schools in three geographically distanced areas in Malaysia (Johor Bahru, Terengganu and Penang), and conducted culture-independent high-throughput microbiome and untargeted metabolomics/chemical profiling.
RESULTS: 1290 students were surveyed for asthma symptoms (wheeze). In each centre, we found significant variation in the prevalence of wheeze among schools, which could be explained by personal characteristics and air pollutants. Large-scale microbial variations were observed between the three centres; the potential protective bacteria were mainly from phyla Actinobacteria in Johor Bahru, Cyanobacteria in Terengganu and Proteobacteria in Penang. In total, 2633 metabolites and chemicals were characterised. Many metabolites were enriched in low-wheeze schools, including plant secondary metabolites flavonoids/isoflavonoids (isoliquiritigenin, formononetin, astragalin), indole and derivatives (indole, serotonin, 1H-indole-3-carboxaldehyde), and others (biotin, chavicol). A neural network analysis showed that the indole derivatives were co-occurring with the potential protective microbial taxa, including Actinomycetospora, Fischerella and Truepera, suggesting these microorganisms may pose health effects by releasing indole metabolites. A few synthetic chemicals were enriched in high-wheeze schools, including pesticides (2(3H)-benzothiazolethione), fragrances (2-aminobenzoic acid, isovaleric acid), detergents and plastics (phthalic acid), and industrial materials (4,4-sulfonyldiphenol).
CONCLUSIONS: This is the first association study between high-throughput indoor chemical profiling and asthma symptoms. The consistent results from the three centres indicate that indoor metabolites/chemicals could be a better indicator than the indoor microbiome for environmental and health assessments, providing new insights for asthma prediction, prevention and control.",0,0
32579598,"A comparative study of two methods to predict the incidence of hepatitis B in Guangxi, China","Zheng Y, Zhang L, Zhu X, Guo G.",PLoS One. 2020 Jun 24;15(6):e0234660. doi: 10.1371/journal.pone.0234660. eCollection 2020.,Zheng Y,PLoS One,2020,25-06-2020,PMC7314421,,10.1371/journal.pone.0234660,"In recent years, the incidence of hepatitis B (HB) in Guangxi is higher than that of the national level; it has been increasing, so it is urgent to do a good predictive research of HB incidence, which can help analyze the early warning of hepatitis B in Guangxi, China. In the study, the feasibility of predicting HB incidence in Guangxi by autoregressive integrated moving average (ARIMA) model method and Elman neural network (ElmanNN) method was discussed respectively, and the prediction accuracy of the two models was compared. Finally, we established the ARIMA (0, 1, 1) model and ElmanNN with 8 neurons. Both ARIMA (0, 1, 1) model and ElmanNN model had good performance, and their prediction accuracy were high. The fitting and prediction root-mean-square error (RMSE) and mean absolute error (MAE) of ElmanNN were smaller than those of ARIMA (0, 1, 1) model, which indicated that ElmanNN was superior to ARIMA (0, 1, 1) model in predicting the incidence of hepatitis B in Guangxi. Based on the ElmanNN, the HB incidence from September 2019 to December 2020 in Guangxi was predicted, the predicted results showed that the incidence of HB in 2020 was slightly higher than that in 2019 and the change trend was similar to that in 2019, for 2021 and beyond, the ElmanNN model could be used to continue the predictive analysis.","A comparative study of two methods to predict the incidence of hepatitis B in Guangxi, China In recent years, the incidence of hepatitis B (HB) in Guangxi is higher than that of the national level; it has been increasing, so it is urgent to do a good predictive research of HB incidence, which can help analyze the early warning of hepatitis B in Guangxi, China. In the study, the feasibility of predicting HB incidence in Guangxi by autoregressive integrated moving average (ARIMA) model method and Elman neural network (ElmanNN) method was discussed respectively, and the prediction accuracy of the two models was compared. Finally, we established the ARIMA (0, 1, 1) model and ElmanNN with 8 neurons. Both ARIMA (0, 1, 1) model and ElmanNN model had good performance, and their prediction accuracy were high. The fitting and prediction root-mean-square error (RMSE) and mean absolute error (MAE) of ElmanNN were smaller than those of ARIMA (0, 1, 1) model, which indicated that ElmanNN was superior to ARIMA (0, 1, 1) model in predicting the incidence of hepatitis B in Guangxi. Based on the ElmanNN, the HB incidence from September 2019 to December 2020 in Guangxi was predicted, the predicted results showed that the incidence of HB in 2020 was slightly higher than that in 2019 and the change trend was similar to that in 2019, for 2021 and beyond, the ElmanNN model could be used to continue the predictive analysis.",1,1
35641908,"Usability and acceptability of oral-based HCV self-testing among key populations: a mixed-methods evaluation in Tbilisi, Georgia","Fajardo E, Watson V, Kumwenda M, Usharidze D, Gogochashvili S, Kakhaberi D, Giguashvili A, Johnson CC, Jamil MS, Dacombe R, Stvilia K, Easterbrook P, Ivanova Reipold E.",BMC Infect Dis. 2022 May 31;22(1):510. doi: 10.1186/s12879-022-07484-2.,Fajardo E,BMC Infect Dis,2022,01-06-2022,PMC9154030,,10.1186/s12879-022-07484-2,"BACKGROUND: Hepatitis C virus self-testing (HCVST) is an additional approach that may expand access to HCV testing. We conducted a mixed-methods cross-sectional observational study to assess the usability and acceptability of HCVST among people who inject drugs (PWID), men who have sex with men (MSM) and transgender (TG) people in Tbilisi, Georgia.
METHODS: The study was conducted from December 2019 to June 2020 among PWID at one harm reduction site and among MSM/TG at one community-based organization. We used a convergent parallel mixed-methods design. Usability was assessed by observing errors made and difficulties faced by participants. Acceptability was assessed using an interviewer-administered semi-structured questionnaire. A subset of participants participated in cognitive and in-depth interviews.
RESULTS: A total of 90 PWID, 84 MSM and 6 TG were observed performing HCVST. PWID were older (median age 35 vs 24) and had a lower level of education compared to MSM/TG (27% vs 59%). The proportion of participants who completed all steps successfully without assistance was 60% among PWID and 80% among MSM/TG. The most common error was in sample collection and this was observed more often among PWID than MSM/TG (21% vs 6%; p = 0.002). More PWID requested assistance during HCVST compared to MSM/TG (22% vs 8%; p = 0.011). Acceptability was high in both groups (98% vs 96%; p = 0.407). Inter-reader agreement was 97% among PWID and 99% among MSM/TG. Qualitative data from cognitive (n = 20) and in-depth interviews (n = 20) was consistent with the quantitative data confirming a high usability and acceptability.
CONCLUSIONS: HCVST was highly acceptable among key populations in Georgia of relatively high educational level, and most participants performed HCVST correctly. A significant difference in usability was observed among PWID compared to MSM/TG, indicating that PWID may benefit from improved messaging and education as well as options to receive direct assistance when self-testing for HCV.","Usability and acceptability of oral-based HCV self-testing among key populations: a mixed-methods evaluation in Tbilisi, Georgia BACKGROUND: Hepatitis C virus self-testing (HCVST) is an additional approach that may expand access to HCV testing. We conducted a mixed-methods cross-sectional observational study to assess the usability and acceptability of HCVST among people who inject drugs (PWID), men who have sex with men (MSM) and transgender (TG) people in Tbilisi, Georgia.
METHODS: The study was conducted from December 2019 to June 2020 among PWID at one harm reduction site and among MSM/TG at one community-based organization. We used a convergent parallel mixed-methods design. Usability was assessed by observing errors made and difficulties faced by participants. Acceptability was assessed using an interviewer-administered semi-structured questionnaire. A subset of participants participated in cognitive and in-depth interviews.
RESULTS: A total of 90 PWID, 84 MSM and 6 TG were observed performing HCVST. PWID were older (median age 35 vs 24) and had a lower level of education compared to MSM/TG (27% vs 59%). The proportion of participants who completed all steps successfully without assistance was 60% among PWID and 80% among MSM/TG. The most common error was in sample collection and this was observed more often among PWID than MSM/TG (21% vs 6%; p = 0.002). More PWID requested assistance during HCVST compared to MSM/TG (22% vs 8%; p = 0.011). Acceptability was high in both groups (98% vs 96%; p = 0.407). Inter-reader agreement was 97% among PWID and 99% among MSM/TG. Qualitative data from cognitive (n = 20) and in-depth interviews (n = 20) was consistent with the quantitative data confirming a high usability and acceptability.
CONCLUSIONS: HCVST was highly acceptable among key populations in Georgia of relatively high educational level, and most participants performed HCVST correctly. A significant difference in usability was observed among PWID compared to MSM/TG, indicating that PWID may benefit from improved messaging and education as well as options to receive direct assistance when self-testing for HCV.",0,0
39072020,Identifying Importation and Asymptomatic Spreaders of Multi-drug Resistant Organisms in Hospital Settings,"Cui J, Heavey J, Klein E, Madden GR, Vullikanti A, Prakash BA.",medRxiv [Preprint]. 2024 Jul 15:2024.07.14.24310393. doi: 10.1101/2024.07.14.24310393.,Cui J,medRxiv,2024,29-07-2024,PMC11275683,,10.1101/2024.07.14.24310393,"Healthcare-associated infections (HAIs) due to multi-drug resistant organisms (MDROs) are a significant burden to the healthcare system. Patients are sometimes already infected at the time of admission to the hospital (referred to as ""importation""), and additional patients might get infected in the hospital through transmission (""nosocomial infection""). Since many of these importation and nosocomial infection cases may present no symptoms (i.e., ""asymptomatic""), rapidly identifying them is difficult since testing is limited and incurs significant delays. Although there has been a lot of work on examining the utility of both mathematical models of transmission and machine learning for identifying patients at risk of MDRO infections in recent years, these methods have limited performance and suffer from different drawbacks: Transmission modeling-based methods do not make full use of rich data contained in electronic health records (EHR), while machine learning-based methods typically lack information about mechanistic processes. In this work, we propose NEURABM, a new framework which integrates both neural networks and agent-based models (ABM) to combine the advantages of both modeling-based and machine learning-based methods. NEURABM simultaneously learns a neural network model for patient-level prediction of importation, as well as the ABM model which is used for identifying infections. Our results demonstrate that NEURABM identifies importation and nosocomial infection cases more accurately than existing methods.","Identifying Importation and Asymptomatic Spreaders of Multi-drug Resistant Organisms in Hospital Settings Healthcare-associated infections (HAIs) due to multi-drug resistant organisms (MDROs) are a significant burden to the healthcare system. Patients are sometimes already infected at the time of admission to the hospital (referred to as ""importation""), and additional patients might get infected in the hospital through transmission (""nosocomial infection""). Since many of these importation and nosocomial infection cases may present no symptoms (i.e., ""asymptomatic""), rapidly identifying them is difficult since testing is limited and incurs significant delays. Although there has been a lot of work on examining the utility of both mathematical models of transmission and machine learning for identifying patients at risk of MDRO infections in recent years, these methods have limited performance and suffer from different drawbacks: Transmission modeling-based methods do not make full use of rich data contained in electronic health records (EHR), while machine learning-based methods typically lack information about mechanistic processes. In this work, we propose NEURABM, a new framework which integrates both neural networks and agent-based models (ABM) to combine the advantages of both modeling-based and machine learning-based methods. NEURABM simultaneously learns a neural network model for patient-level prediction of importation, as well as the ABM model which is used for identifying infections. Our results demonstrate that NEURABM identifies importation and nosocomial infection cases more accurately than existing methods.",1,0
29540225,Community approval required for periconceptional adolescent adherence to weekly iron and/or folic acid supplementation: a qualitative study in rural Burkina Faso,"Compaoré A, Gies S, Brabin B, Tinto H, Brabin L.",Reprod Health. 2018 Mar 14;15(1):48. doi: 10.1186/s12978-018-0490-y.,Compaoré A,Reprod Health,2018,16-03-2018,PMC5852966,,10.1186/s12978-018-0490-y,"BACKGROUND: Iron deficiency remains a prevalent adolescent health problem in low income countries. Iron supplementation is recommended but improvement of iron status requires good adherence.
OBJECTIVES: We explored factors affecting adolescent adherence to weekly iron and/or folic acid supplements in a setting of low secondary school attendance.
METHODS: Taped in-depth interviews were conducted with participants in a randomised, controlled, periconceptional iron supplementation trial for young nulliparous women living in a rural, malaria endemic region of Burkina Faso. Participants with good, medium or poor adherence were selected. Interviews were transcribed and analysed thematically.
RESULTS: Thirty-nine interviews were conducted. The community initially thought supplements were contraceptives. The potential benefits of giving iron supplementation to unmarried ""girls"" ahead of pregnancy were not recognised. Trial participation, which required parental consent, remained high but was not openly admitted because iron supplements were thought to be contraceptives. Unmarried non-school attenders, being mobile, were often sent to provide domestic labour in varied locations. This interrupted adherence - as did movement of school girls during vacations and at marriage. Field workers tracked participants and trial provision of free treatment encouraged adherence. Most interviewees did not identify health benefits from taking supplements.
CONCLUSIONS: For success, communities must be convinced of the value of an adolescent intervention. During this safety trial, benefits not routinely available in iron supplementation programmes were important to this low income community, ensuring adolescent participation. Nevertheless, adolescents were obliged to fulfil cultural duties and roles that interfered with regular adherence to the iron supplementation regime.
TRIAL REGISTRATION: Trial Registration at clinicaltrials.gov : NCT01210040.","Community approval required for periconceptional adolescent adherence to weekly iron and/or folic acid supplementation: a qualitative study in rural Burkina Faso BACKGROUND: Iron deficiency remains a prevalent adolescent health problem in low income countries. Iron supplementation is recommended but improvement of iron status requires good adherence.
OBJECTIVES: We explored factors affecting adolescent adherence to weekly iron and/or folic acid supplements in a setting of low secondary school attendance.
METHODS: Taped in-depth interviews were conducted with participants in a randomised, controlled, periconceptional iron supplementation trial for young nulliparous women living in a rural, malaria endemic region of Burkina Faso. Participants with good, medium or poor adherence were selected. Interviews were transcribed and analysed thematically.
RESULTS: Thirty-nine interviews were conducted. The community initially thought supplements were contraceptives. The potential benefits of giving iron supplementation to unmarried ""girls"" ahead of pregnancy were not recognised. Trial participation, which required parental consent, remained high but was not openly admitted because iron supplements were thought to be contraceptives. Unmarried non-school attenders, being mobile, were often sent to provide domestic labour in varied locations. This interrupted adherence - as did movement of school girls during vacations and at marriage. Field workers tracked participants and trial provision of free treatment encouraged adherence. Most interviewees did not identify health benefits from taking supplements.
CONCLUSIONS: For success, communities must be convinced of the value of an adolescent intervention. During this safety trial, benefits not routinely available in iron supplementation programmes were important to this low income community, ensuring adolescent participation. Nevertheless, adolescents were obliged to fulfil cultural duties and roles that interfered with regular adherence to the iron supplementation regime.
TRIAL REGISTRATION: Trial Registration at clinicaltrials.gov : NCT01210040.",1,0
37212699,Multicenter Diagnostic Evaluation of OnSite COVID-19 Rapid Test (CTK Biotech) among Symptomatic Individuals in Brazil and the United Kingdom,"Thompson CR, Torres PM, Kontogianni K, Byrne RL; LSTM Diagnostic group; Noguera SV, Luna-Muschi A, Marchi AP, Andrade PS, Dos Santos Barboza A, Nishikawara M; CONDOR steering group; Body R, de Vos M, Escadafal C, Adams E, Figueiredo Costa S, Cubas-Atienzar AI.",Microbiol Spectr. 2023 Jun 15;11(3):e0504422. doi: 10.1128/spectrum.05044-22. Epub 2023 May 22.,Thompson CR,Microbiol Spectr,2023,22-05-2023,PMC10269675,,10.1128/spectrum.05044-22,"The COVID-19 pandemic has given rise to numerous commercially available antigen rapid diagnostic tests (Ag-RDTs). To generate and to share accurate and independent data with the global community requires multisite prospective diagnostic evaluations of Ag-RDTs. This report describes the clinical evaluation of the OnSite COVID-19 rapid test (CTK Biotech, CA, USA) in Brazil and the United Kingdom. A total of 496 paired nasopharyngeal (NP) swabs were collected from symptomatic health care workers at Hospital das Clínicas in São Paulo, Brazil, and 211 NP swabs were collected from symptomatic participants at a COVID-19 drive-through testing site in Liverpool, United Kingdom. Swabs were analyzed by Ag-RDT, and results were compared to quantitative reverse transcriptase PCR (RT-qPCR). The clinical sensitivity of the OnSite COVID-19 rapid test in Brazil was 90.3% (95% confidence interval [CI], 75.1 to 96.7%) and in the United Kingdom was 75.3% (95% CI, 64.6 to 83.6%). The clinical specificity in Brazil was 99.4% (95% CI, 98.1 to 99.8%) and in the United Kingdom was 95.5% (95% CI, 90.6 to 97.9%). Concurrently, analytical evaluation of the Ag-RDT was assessed using direct culture supernatant of SARS-CoV-2 strains from wild-type (WT), Alpha, Delta, Gamma, and Omicron lineages. This study provides comparative performance of an Ag-RDT across two different settings, geographical areas, and populations. Overall, the OnSite Ag-RDT demonstrated a lower clinical sensitivity than claimed by the manufacturer. The sensitivity and specificity from the Brazil study fulfilled the performance criteria determined by the World Health Organization, but the performance obtained from the UK study failed to do. Further evaluation of Ag-RDTs should include harmonized protocols between laboratories to facilitate comparison between settings. IMPORTANCE Evaluating rapid diagnostic tests in diverse populations is essential to improving diagnostic responses as it gives an indication of the accuracy in real-world scenarios. In the case of rapid diagnostic testing within this pandemic, lateral flow tests that meet the minimum requirements for sensitivity and specificity can play a key role in increasing testing capacity, allowing timely clinical management of those infected, and protecting health care systems. This is particularly valuable in settings where access to the test gold standard is often restricted.","Multicenter Diagnostic Evaluation of OnSite COVID-19 Rapid Test (CTK Biotech) among Symptomatic Individuals in Brazil and the United Kingdom The COVID-19 pandemic has given rise to numerous commercially available antigen rapid diagnostic tests (Ag-RDTs). To generate and to share accurate and independent data with the global community requires multisite prospective diagnostic evaluations of Ag-RDTs. This report describes the clinical evaluation of the OnSite COVID-19 rapid test (CTK Biotech, CA, USA) in Brazil and the United Kingdom. A total of 496 paired nasopharyngeal (NP) swabs were collected from symptomatic health care workers at Hospital das Clínicas in São Paulo, Brazil, and 211 NP swabs were collected from symptomatic participants at a COVID-19 drive-through testing site in Liverpool, United Kingdom. Swabs were analyzed by Ag-RDT, and results were compared to quantitative reverse transcriptase PCR (RT-qPCR). The clinical sensitivity of the OnSite COVID-19 rapid test in Brazil was 90.3% (95% confidence interval [CI], 75.1 to 96.7%) and in the United Kingdom was 75.3% (95% CI, 64.6 to 83.6%). The clinical specificity in Brazil was 99.4% (95% CI, 98.1 to 99.8%) and in the United Kingdom was 95.5% (95% CI, 90.6 to 97.9%). Concurrently, analytical evaluation of the Ag-RDT was assessed using direct culture supernatant of SARS-CoV-2 strains from wild-type (WT), Alpha, Delta, Gamma, and Omicron lineages. This study provides comparative performance of an Ag-RDT across two different settings, geographical areas, and populations. Overall, the OnSite Ag-RDT demonstrated a lower clinical sensitivity than claimed by the manufacturer. The sensitivity and specificity from the Brazil study fulfilled the performance criteria determined by the World Health Organization, but the performance obtained from the UK study failed to do. Further evaluation of Ag-RDTs should include harmonized protocols between laboratories to facilitate comparison between settings. IMPORTANCE Evaluating rapid diagnostic tests in diverse populations is essential to improving diagnostic responses as it gives an indication of the accuracy in real-world scenarios. In the case of rapid diagnostic testing within this pandemic, lateral flow tests that meet the minimum requirements for sensitivity and specificity can play a key role in increasing testing capacity, allowing timely clinical management of those infected, and protecting health care systems. This is particularly valuable in settings where access to the test gold standard is often restricted.",0,0
36670470,A new WHO bottle bioassay method to assess the susceptibility of mosquito vectors to public health insecticides: results from a WHO-coordinated multi-centre study,"Corbel V, Kont MD, Ahumada ML, Andréo L, Bayili B, Bayili K, Brooke B, Pinto Caballero JA, Lambert B, Churcher TS, Duchon S, Etang J, Flores AE, Gunasekaran K, Juntarajumnong W, Kirby M, Davies R, Lees RS, Lenhart A, Lima JBP, Martins AJ, Müller P, N'Guessan R, Ngufor C, Praulins G, Quinones M, Raghavendra K, Verma V, Rus AC, Samuel M, Ying KS, Sungvornyothin S, Uragayala S, Velayudhan R, Yadav RS.",Parasit Vectors. 2023 Jan 20;16(1):21. doi: 10.1186/s13071-022-05554-7.,Corbel V,Parasit Vectors,2023,20-01-2023,PMC9863080,,10.1186/s13071-022-05554-7,"BACKGROUND: The continued spread of insecticide resistance in mosquito vectors of malaria and arboviral diseases may lead to operational failure of insecticide-based interventions if resistance is not monitored and managed efficiently. This study aimed to develop and validate a new WHO glass bottle bioassay method as an alternative to the WHO standard insecticide tube test to monitor mosquito susceptibility to new public health insecticides with particular modes of action, physical properties or both.
METHODS: A multi-centre study involving 21 laboratories worldwide generated data on the susceptibility of seven mosquito species (Aedes aegypti, Aedes albopictus, Anopheles gambiae sensu stricto [An. gambiae s.s.], Anopheles funestus, Anopheles stephensi, Anopheles minimus and Anopheles albimanus) to seven public health insecticides in five classes, including pyrethroids (metofluthrin, prallethrin and transfluthrin), neonicotinoids (clothianidin), pyrroles (chlorfenapyr), juvenile hormone mimics (pyriproxyfen) and butenolides (flupyradifurone), in glass bottle assays. The data were analysed using a Bayesian binomial model to determine the concentration-response curves for each insecticide-species combination and to assess the within-bioassay variability in the susceptibility endpoints, namely the concentration that kills 50% and 99% of the test population (LC<sub>50</sub> and LC<sub>99</sub>, respectively) and the concentration that inhibits oviposition of the test population by 50% and 99% (OI<sub>50</sub> and OI<sub>99</sub>), to measure mortality and the sterilizing effect, respectively.
RESULTS: Overall, about 200,000 mosquitoes were tested with the new bottle bioassay, and LC<sub>50</sub>/LC<sub>99</sub> or OI<sub>50</sub>/OI<sub>99</sub> values were determined for all insecticides. Variation was seen between laboratories in estimates for some mosquito species-insecticide combinations, while other test results were consistent. The variation was generally greater with transfluthrin and flupyradifurone than with the other compounds tested, especially against Anopheles species. Overall, the mean within-bioassay variability in mortality and oviposition inhibition were &lt; 10% for most mosquito species-insecticide combinations.
CONCLUSION: Our findings, based on the largest susceptibility dataset ever produced on mosquitoes, showed that the new WHO bottle bioassay is adequate for evaluating mosquito susceptibility to new and promising public health insecticides currently deployed for vector control. The datasets presented in this study have been used recently by the WHO to establish 17 new insecticide discriminating concentrations (DCs) for either Aedes spp. or Anopheles spp. The bottle bioassay and DCs can now be widely used to monitor baseline insecticide susceptibility of wild populations of vectors of malaria and Aedes-borne diseases worldwide.","A new WHO bottle bioassay method to assess the susceptibility of mosquito vectors to public health insecticides: results from a WHO-coordinated multi-centre study BACKGROUND: The continued spread of insecticide resistance in mosquito vectors of malaria and arboviral diseases may lead to operational failure of insecticide-based interventions if resistance is not monitored and managed efficiently. This study aimed to develop and validate a new WHO glass bottle bioassay method as an alternative to the WHO standard insecticide tube test to monitor mosquito susceptibility to new public health insecticides with particular modes of action, physical properties or both.
METHODS: A multi-centre study involving 21 laboratories worldwide generated data on the susceptibility of seven mosquito species (Aedes aegypti, Aedes albopictus, Anopheles gambiae sensu stricto [An. gambiae s.s.], Anopheles funestus, Anopheles stephensi, Anopheles minimus and Anopheles albimanus) to seven public health insecticides in five classes, including pyrethroids (metofluthrin, prallethrin and transfluthrin), neonicotinoids (clothianidin), pyrroles (chlorfenapyr), juvenile hormone mimics (pyriproxyfen) and butenolides (flupyradifurone), in glass bottle assays. The data were analysed using a Bayesian binomial model to determine the concentration-response curves for each insecticide-species combination and to assess the within-bioassay variability in the susceptibility endpoints, namely the concentration that kills 50% and 99% of the test population (LC<sub>50</sub> and LC<sub>99</sub>, respectively) and the concentration that inhibits oviposition of the test population by 50% and 99% (OI<sub>50</sub> and OI<sub>99</sub>), to measure mortality and the sterilizing effect, respectively.
RESULTS: Overall, about 200,000 mosquitoes were tested with the new bottle bioassay, and LC<sub>50</sub>/LC<sub>99</sub> or OI<sub>50</sub>/OI<sub>99</sub> values were determined for all insecticides. Variation was seen between laboratories in estimates for some mosquito species-insecticide combinations, while other test results were consistent. The variation was generally greater with transfluthrin and flupyradifurone than with the other compounds tested, especially against Anopheles species. Overall, the mean within-bioassay variability in mortality and oviposition inhibition were &lt; 10% for most mosquito species-insecticide combinations.
CONCLUSION: Our findings, based on the largest susceptibility dataset ever produced on mosquitoes, showed that the new WHO bottle bioassay is adequate for evaluating mosquito susceptibility to new and promising public health insecticides currently deployed for vector control. The datasets presented in this study have been used recently by the WHO to establish 17 new insecticide discriminating concentrations (DCs) for either Aedes spp. or Anopheles spp. The bottle bioassay and DCs can now be widely used to monitor baseline insecticide susceptibility of wild populations of vectors of malaria and Aedes-borne diseases worldwide.",0,0
39237689,"A multicentre study to evaluate the diagnostic performance of a novel CAD software, DecXpert, for radiological diagnosis of tuberculosis in the northern Indian population","Nath A, Hashim Z, Shukla S, Poduvattil PA, Neyaz Z, Mishra R, Singh M, Misra N, Shukla A.",Sci Rep. 2024 Sep 5;14(1):20711. doi: 10.1038/s41598-024-71346-x.,Nath A,Sci Rep,2024,05-09-2024,PMC11377743,,10.1038/s41598-024-71346-x,"Tuberculosis (TB) is the leading cause of mortality among infectious diseases globally. Effectively managing TB requires early identification of individuals with TB disease. Resource-constrained settings often lack skilled professionals for interpreting chest X-rays (CXRs) used in TB diagnosis. To address this challenge, we developed ""DecXpert"" a novel Computer-Aided Detection (CAD) software solution based on deep neural networks for early TB diagnosis from CXRs, aiming to detect subtle abnormalities that may be overlooked by human interpretation alone. This study was conducted on the largest cohort size to date, where the performance of a CAD software (DecXpert version 1.4) was validated against the gold standard molecular diagnostic technique, GeneXpert MTB/RIF, analyzing data from 4363 individuals across 12 primary health care centers and one tertiary hospital in North India. DecXpert demonstrated 88% sensitivity (95% CI 0.85-0.93) and 85% specificity (95% CI 0.82-0.91) for active TB detection. Incorporating demographics, DecXpert achieved an area under the curve of 0.91 (95% CI 0.88-0.94), indicating robust diagnostic performance. Our findings establish DecXpert's potential as an accurate, efficient AI solution for early identification of active TB cases. Deployed as a screening tool in resource-limited settings, DecXpert could enable early identification of individuals with TB disease and facilitate effective TB management where skilled radiological interpretation is limited.","A multicentre study to evaluate the diagnostic performance of a novel CAD software, DecXpert, for radiological diagnosis of tuberculosis in the northern Indian population Tuberculosis (TB) is the leading cause of mortality among infectious diseases globally. Effectively managing TB requires early identification of individuals with TB disease. Resource-constrained settings often lack skilled professionals for interpreting chest X-rays (CXRs) used in TB diagnosis. To address this challenge, we developed ""DecXpert"" a novel Computer-Aided Detection (CAD) software solution based on deep neural networks for early TB diagnosis from CXRs, aiming to detect subtle abnormalities that may be overlooked by human interpretation alone. This study was conducted on the largest cohort size to date, where the performance of a CAD software (DecXpert version 1.4) was validated against the gold standard molecular diagnostic technique, GeneXpert MTB/RIF, analyzing data from 4363 individuals across 12 primary health care centers and one tertiary hospital in North India. DecXpert demonstrated 88% sensitivity (95% CI 0.85-0.93) and 85% specificity (95% CI 0.82-0.91) for active TB detection. Incorporating demographics, DecXpert achieved an area under the curve of 0.91 (95% CI 0.88-0.94), indicating robust diagnostic performance. Our findings establish DecXpert's potential as an accurate, efficient AI solution for early identification of active TB cases. Deployed as a screening tool in resource-limited settings, DecXpert could enable early identification of individuals with TB disease and facilitate effective TB management where skilled radiological interpretation is limited.",0,0
39610390,Comparative analysis of volatility forecasting for healthcare stock indices amid public health crises: a study based on the Bayes-CNN model,"Li Y, Gu R, Zhao D.",Front Public Health. 2024 Nov 14;12:1476196. doi: 10.3389/fpubh.2024.1476196. eCollection 2024.,Li Y,Front Public Health,2024,29-11-2024,PMC11602464,,10.3389/fpubh.2024.1476196,"In recent years, public health events have significantly impacted various aspects of human production and daily life, particularly in the domains of disease transmission and economic stability. While many scholars have primarily focused on the influence of public health events from the perspective of disease prevention and control, research examining their economic implications, especially regarding public health indices in the securities market, remains relatively scarce. Such studies are crucial for ensuring public health safety and stability. This paper employs the Bayesian Convolutional Neural Network (Bayes-CNN) model to predict financial market volatility influenced by public health events and conducts a comparative analysis. To validate the feasibility of this method, the model is used to analyze the impact of the COVID-19 pandemic on the CSI (China Securities Index) Medical Service Index. The results indicate significant differences in the volatility of the CSI Medical Service Index before and after the outbreak, particularly during the pandemic period. This study also enhances the validity and reliability of its conclusions by incorporating European data and employing the GARCH model. Relevant institutions and individual investors should adopt different regulatory and investment strategies based on the specifics of various public health events to prevent the outbreak of systemic financial risks that could affect social stability. This paper offers a new perspective and methodology for predicting financial market volatility under the influence of public health events, providing valuable insights for investors and decision-makers to better understand and respond to the potential impacts of such events on financial markets.","Comparative analysis of volatility forecasting for healthcare stock indices amid public health crises: a study based on the Bayes-CNN model In recent years, public health events have significantly impacted various aspects of human production and daily life, particularly in the domains of disease transmission and economic stability. While many scholars have primarily focused on the influence of public health events from the perspective of disease prevention and control, research examining their economic implications, especially regarding public health indices in the securities market, remains relatively scarce. Such studies are crucial for ensuring public health safety and stability. This paper employs the Bayesian Convolutional Neural Network (Bayes-CNN) model to predict financial market volatility influenced by public health events and conducts a comparative analysis. To validate the feasibility of this method, the model is used to analyze the impact of the COVID-19 pandemic on the CSI (China Securities Index) Medical Service Index. The results indicate significant differences in the volatility of the CSI Medical Service Index before and after the outbreak, particularly during the pandemic period. This study also enhances the validity and reliability of its conclusions by incorporating European data and employing the GARCH model. Relevant institutions and individual investors should adopt different regulatory and investment strategies based on the specifics of various public health events to prevent the outbreak of systemic financial risks that could affect social stability. This paper offers a new perspective and methodology for predicting financial market volatility under the influence of public health events, providing valuable insights for investors and decision-makers to better understand and respond to the potential impacts of such events on financial markets.",0,1
29784935,A causal mechanism for childhood acute lymphoblastic leukaemia,Greaves M.,Nat Rev Cancer. 2018 Aug;18(8):471-484. doi: 10.1038/s41568-018-0015-6.,Greaves M,Nat Rev Cancer,2018,23-05-2018,PMC6986894,EMS85528,10.1038/s41568-018-0015-6,"In this Review, I present evidence supporting a multifactorial causation of childhood acute lymphoblastic leukaemia (ALL), a major subtype of paediatric cancer. ALL evolves in two discrete steps. First, in utero initiation by fusion gene formation or hyperdiploidy generates a covert, pre-leukaemic clone. Second, in a small fraction of these cases, the postnatal acquisition of secondary genetic changes (primarily V(D)J recombination-activating protein (RAG) and activation-induced cytidine deaminase (AID)-driven copy number alterations in the case of ETS translocation variant 6 (ETV6)-runt-related transcription factor 1 (RUNX1)+ ALL) drives conversion to overt leukaemia. Epidemiological and modelling studies endorse a dual role for common infections. Microbial exposures earlier in life are protective but, in their absence, later infections trigger the critical secondary mutations. Risk is further modified by inherited genetics, chance and, probably, diet. Childhood ALL can be viewed as a paradoxical consequence of progress in modern societies, where behavioural changes have restrained early microbial exposure. This engenders an evolutionary mismatch between historical adaptations of the immune system and contemporary lifestyles. Childhood ALL may be a preventable cancer.","A causal mechanism for childhood acute lymphoblastic leukaemia In this Review, I present evidence supporting a multifactorial causation of childhood acute lymphoblastic leukaemia (ALL), a major subtype of paediatric cancer. ALL evolves in two discrete steps. First, in utero initiation by fusion gene formation or hyperdiploidy generates a covert, pre-leukaemic clone. Second, in a small fraction of these cases, the postnatal acquisition of secondary genetic changes (primarily V(D)J recombination-activating protein (RAG) and activation-induced cytidine deaminase (AID)-driven copy number alterations in the case of ETS translocation variant 6 (ETV6)-runt-related transcription factor 1 (RUNX1)+ ALL) drives conversion to overt leukaemia. Epidemiological and modelling studies endorse a dual role for common infections. Microbial exposures earlier in life are protective but, in their absence, later infections trigger the critical secondary mutations. Risk is further modified by inherited genetics, chance and, probably, diet. Childhood ALL can be viewed as a paradoxical consequence of progress in modern societies, where behavioural changes have restrained early microbial exposure. This engenders an evolutionary mismatch between historical adaptations of the immune system and contemporary lifestyles. Childhood ALL may be a preventable cancer.",0,0
33882225,Safety and Efficacy of Single-Dose Ad26.COV2.S Vaccine against Covid-19,"Sadoff J, Gray G, Vandebosch A, Cárdenas V, Shukarev G, Grinsztejn B, Goepfert PA, Truyers C, Fennema H, Spiessens B, Offergeld K, Scheper G, Taylor KL, Robb ML, Treanor J, Barouch DH, Stoddard J, Ryser MF, Marovich MA, Neuzil KM, Corey L, Cauwenberghs N, Tanner T, Hardt K, Ruiz-Guiñazú J, Le Gars M, Schuitemaker H, Van Hoof J, Struyf F, Douoguih M; ENSEMBLE Study Group.",N Engl J Med. 2021 Jun 10;384(23):2187-2201. doi: 10.1056/NEJMoa2101544. Epub 2021 Apr 21.,Sadoff J,N Engl J Med,2021,21-04-2021,PMC8220996,,10.1056/NEJMoa2101544,"BACKGROUND: The Ad26.COV2.S vaccine is a recombinant, replication-incompetent human adenovirus type 26 vector encoding full-length severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike protein in a prefusion-stabilized conformation.
METHODS: In an international, randomized, double-blind, placebo-controlled, phase 3 trial, we randomly assigned adult participants in a 1:1 ratio to receive a single dose of Ad26.COV2.S (5×1010 viral particles) or placebo. The primary end points were vaccine efficacy against moderate to severe-critical coronavirus disease 2019 (Covid-19) with an onset at least 14 days and at least 28 days after administration among participants in the per-protocol population who had tested negative for SARS-CoV-2. Safety was also assessed.
RESULTS: The per-protocol population included 19,630 SARS-CoV-2-negative participants who received Ad26.COV2.S and 19,691 who received placebo. Ad26.COV2.S protected against moderate to severe-critical Covid-19 with onset at least 14 days after administration (116 cases in the vaccine group vs. 348 in the placebo group; efficacy, 66.9%; adjusted 95% confidence interval [CI], 59.0 to 73.4) and at least 28 days after administration (66 vs. 193 cases; efficacy, 66.1%; adjusted 95% CI, 55.0 to 74.8). Vaccine efficacy was higher against severe-critical Covid-19 (76.7% [adjusted 95% CI, 54.6 to 89.1] for onset at ≥14 days and 85.4% [adjusted 95% CI, 54.2 to 96.9] for onset at ≥28 days). Despite 86 of 91 cases (94.5%) in South Africa with sequenced virus having the 20H/501Y.V2 variant, vaccine efficacy was 52.0% and 64.0% against moderate to severe-critical Covid-19 with onset at least 14 days and at least 28 days after administration, respectively, and efficacy against severe-critical Covid-19 was 73.1% and 81.7%, respectively. Reactogenicity was higher with Ad26.COV2.S than with placebo but was generally mild to moderate and transient. The incidence of serious adverse events was balanced between the two groups. Three deaths occurred in the vaccine group (none were Covid-19-related), and 16 in the placebo group (5 were Covid-19-related).
CONCLUSIONS: A single dose of Ad26.COV2.S protected against symptomatic Covid-19 and asymptomatic SARS-CoV-2 infection and was effective against severe-critical disease, including hospitalization and death. Safety appeared to be similar to that in other phase 3 trials of Covid-19 vaccines. (Funded by Janssen Research and Development and others; ENSEMBLE ClinicalTrials.gov number, NCT04505722.).","Safety and Efficacy of Single-Dose Ad26.COV2.S Vaccine against Covid-19 BACKGROUND: The Ad26.COV2.S vaccine is a recombinant, replication-incompetent human adenovirus type 26 vector encoding full-length severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike protein in a prefusion-stabilized conformation.
METHODS: In an international, randomized, double-blind, placebo-controlled, phase 3 trial, we randomly assigned adult participants in a 1:1 ratio to receive a single dose of Ad26.COV2.S (5×1010 viral particles) or placebo. The primary end points were vaccine efficacy against moderate to severe-critical coronavirus disease 2019 (Covid-19) with an onset at least 14 days and at least 28 days after administration among participants in the per-protocol population who had tested negative for SARS-CoV-2. Safety was also assessed.
RESULTS: The per-protocol population included 19,630 SARS-CoV-2-negative participants who received Ad26.COV2.S and 19,691 who received placebo. Ad26.COV2.S protected against moderate to severe-critical Covid-19 with onset at least 14 days after administration (116 cases in the vaccine group vs. 348 in the placebo group; efficacy, 66.9%; adjusted 95% confidence interval [CI], 59.0 to 73.4) and at least 28 days after administration (66 vs. 193 cases; efficacy, 66.1%; adjusted 95% CI, 55.0 to 74.8). Vaccine efficacy was higher against severe-critical Covid-19 (76.7% [adjusted 95% CI, 54.6 to 89.1] for onset at ≥14 days and 85.4% [adjusted 95% CI, 54.2 to 96.9] for onset at ≥28 days). Despite 86 of 91 cases (94.5%) in South Africa with sequenced virus having the 20H/501Y.V2 variant, vaccine efficacy was 52.0% and 64.0% against moderate to severe-critical Covid-19 with onset at least 14 days and at least 28 days after administration, respectively, and efficacy against severe-critical Covid-19 was 73.1% and 81.7%, respectively. Reactogenicity was higher with Ad26.COV2.S than with placebo but was generally mild to moderate and transient. The incidence of serious adverse events was balanced between the two groups. Three deaths occurred in the vaccine group (none were Covid-19-related), and 16 in the placebo group (5 were Covid-19-related).
CONCLUSIONS: A single dose of Ad26.COV2.S protected against symptomatic Covid-19 and asymptomatic SARS-CoV-2 infection and was effective against severe-critical disease, including hospitalization and death. Safety appeared to be similar to that in other phase 3 trials of Covid-19 vaccines. (Funded by Janssen Research and Development and others; ENSEMBLE ClinicalTrials.gov number, NCT04505722.).",0,0
38381160,Immune recovery uveitis: a focus review,"Rodrigues Alves N, Barão C, Mota C, Costa L, Proença RP.",Graefes Arch Clin Exp Ophthalmol. 2024 Aug;262(8):2703-2712. doi: 10.1007/s00417-024-06415-y. Epub 2024 Feb 21.,Rodrigues Alves N,Graefes Arch Clin Exp Ophthalmol,2024,21-02-2024,PMC11271330,,10.1007/s00417-024-06415-y,"Immune recovery uveitis (IRU) is an intraocular inflammation that typically occurs as part of immune reconstitution inflammatory syndrome (IRIS) in the eye. Typically, it affects human immunodeficiency virus (HIV)-infected patients with recognized or unrecognized cytomegalovirus (CMV) retinitis who are receiving highly active antiretroviral therapy (HAART). IRU is a common cause of new vision loss in these patients, and it manifests with a wide range of symptoms and an increased risk of inflammatory complications, such as macular edema. Recently, similar IRU-like responses have been observed in non-HIV individuals with immune reconstitution following immunosuppression of diverse etiologies, posing challenges in diagnosis and treatment. This review provides an updated overview of the current literature on the epidemiology, pathophysiology, biomarkers, clinical manifestations, diagnosis, differential diagnosis, and treatment strategies for IRU.","Immune recovery uveitis: a focus review Immune recovery uveitis (IRU) is an intraocular inflammation that typically occurs as part of immune reconstitution inflammatory syndrome (IRIS) in the eye. Typically, it affects human immunodeficiency virus (HIV)-infected patients with recognized or unrecognized cytomegalovirus (CMV) retinitis who are receiving highly active antiretroviral therapy (HAART). IRU is a common cause of new vision loss in these patients, and it manifests with a wide range of symptoms and an increased risk of inflammatory complications, such as macular edema. Recently, similar IRU-like responses have been observed in non-HIV individuals with immune reconstitution following immunosuppression of diverse etiologies, posing challenges in diagnosis and treatment. This review provides an updated overview of the current literature on the epidemiology, pathophysiology, biomarkers, clinical manifestations, diagnosis, differential diagnosis, and treatment strategies for IRU.",0,0
36173943,Review of the neglected tropical diseases programme implementation during 2012-2019 in the WHO-Eastern Mediterranean Region,"Warusavithana S, Atta H, Osman M, Hutin Y.",PLoS Negl Trop Dis. 2022 Sep 29;16(9):e0010665. doi: 10.1371/journal.pntd.0010665. eCollection 2022 Sep.,Warusavithana S,PLoS Negl Trop Dis,2022,29-09-2022,PMC9521802,,10.1371/journal.pntd.0010665,"INTRODUCTION: The 2012-2020 WHO NTD roadmap set targets for control, elimination, and eradication of neglected tropical diseases (NTDs). It recommends 5 strategies, out of which preventive chemotherapy (PC) and intensified disease management were key to achieve targets. WHO estimated that globally, between 2012 and 2019, the number of persons affected by NTDs decreased from nearly 2.1 to 1.7 billion people. We analysed the situation of NTDs in the WHO Eastern Mediterranean Region (EMR) in 2020 to assess the progress with the 2012-2020 roadmap and to identify gaps.
METHODS: We reviewed data repositories of national data sources for 2012 to 2019 including the Global Indicator Data Platform for Sustainable Development Goals, the Global Health Observatory data repository, the WHO PC databank, and the EMR data repository. We allocated countries a Red-Amber-Green (RAG) rating based on standardized criteria, on progress and current situation of each of 11 priority NTDs.
RESULTS: All 22 countries in EMR were affected by 1 or more autochthonous or imported NTDs. In 2019, WHO estimated that in EMR, 78 million people required interventions for NTDs, a 38% decline compared with 2012. Twelve of 22 countries needed priority public health action (i.e., red) for 1 or more NTD. Of these, Sudan needed priority public health action for 6 NTDs and Yemen for 5. Eleven countries also needed priority public health action for cutaneous leishmaniasis, and 5 countries for rabies and trachoma. Visceral leishmaniasis is on the increase in Afghanistan, Libya, Syria, and Yemen.
CONCLUSION: Since the first roadmap of NTDs in 2012, the EMR has made a substantial progress. Nevertheless, many challenges remain in the prevention and control of NTDs. EMR needs a regional approach to control NTDs in countries most affected and a coordinated strategy to stop the continuing increase of cutaneous leishmaniasis and a possible resurgence of visceral leishmaniasis.","Review of the neglected tropical diseases programme implementation during 2012-2019 in the WHO-Eastern Mediterranean Region INTRODUCTION: The 2012-2020 WHO NTD roadmap set targets for control, elimination, and eradication of neglected tropical diseases (NTDs). It recommends 5 strategies, out of which preventive chemotherapy (PC) and intensified disease management were key to achieve targets. WHO estimated that globally, between 2012 and 2019, the number of persons affected by NTDs decreased from nearly 2.1 to 1.7 billion people. We analysed the situation of NTDs in the WHO Eastern Mediterranean Region (EMR) in 2020 to assess the progress with the 2012-2020 roadmap and to identify gaps.
METHODS: We reviewed data repositories of national data sources for 2012 to 2019 including the Global Indicator Data Platform for Sustainable Development Goals, the Global Health Observatory data repository, the WHO PC databank, and the EMR data repository. We allocated countries a Red-Amber-Green (RAG) rating based on standardized criteria, on progress and current situation of each of 11 priority NTDs.
RESULTS: All 22 countries in EMR were affected by 1 or more autochthonous or imported NTDs. In 2019, WHO estimated that in EMR, 78 million people required interventions for NTDs, a 38% decline compared with 2012. Twelve of 22 countries needed priority public health action (i.e., red) for 1 or more NTD. Of these, Sudan needed priority public health action for 6 NTDs and Yemen for 5. Eleven countries also needed priority public health action for cutaneous leishmaniasis, and 5 countries for rabies and trachoma. Visceral leishmaniasis is on the increase in Afghanistan, Libya, Syria, and Yemen.
CONCLUSION: Since the first roadmap of NTDs in 2012, the EMR has made a substantial progress. Nevertheless, many challenges remain in the prevention and control of NTDs. EMR needs a regional approach to control NTDs in countries most affected and a coordinated strategy to stop the continuing increase of cutaneous leishmaniasis and a possible resurgence of visceral leishmaniasis.",0,0
30110939,Overview of Trends in the Application of Metagenomic Techniques in the Analysis of Human Enteric Viral Diversity in Africa's Environmental Regimes,"Osunmakinde CO, Selvarajan R, Sibanda T, Mamba BB, Msagati TAM.",Viruses. 2018 Aug 14;10(8):429. doi: 10.3390/v10080429.,Osunmakinde CO,Viruses,2018,17-08-2018,PMC6115975,,10.3390/v10080429,"There has been an increase in the quest for metagenomics as an approach for the identification and study of the diversity of human viruses found in aquatic systems, both for their role as waterborne pathogens and as water quality indicators. In the last few years, environmental viral metagenomics has grown significantly and has enabled the identification, diversity and entire genome sequencing of viruses in environmental and clinical samples extensively. Prior to the arrival of metagenomics, traditional molecular procedures such as the polymerase chain reaction (PCR) and sequencing, were mostly used to identify and classify enteric viral species in different environmental milieu. After the advent of metagenomics, more detailed reports have emerged about the important waterborne viruses identified in wastewater treatment plant effluents and surface water. This paper provides a review of methods that have been used for the concentration, detection and identification of viral species from different environmental matrices. The review also takes into consideration where metagenomics has been explored in different African countries, as well as the limitations and challenges facing the approach. Procedures including sample processing, experimental design, sequencing technology, and bioinformatics analysis are discussed. The review concludes by summarising the current thinking and practices in the field and lays bare key issues that those venturing into this field need to consider and address.","Overview of Trends in the Application of Metagenomic Techniques in the Analysis of Human Enteric Viral Diversity in Africa's Environmental Regimes There has been an increase in the quest for metagenomics as an approach for the identification and study of the diversity of human viruses found in aquatic systems, both for their role as waterborne pathogens and as water quality indicators. In the last few years, environmental viral metagenomics has grown significantly and has enabled the identification, diversity and entire genome sequencing of viruses in environmental and clinical samples extensively. Prior to the arrival of metagenomics, traditional molecular procedures such as the polymerase chain reaction (PCR) and sequencing, were mostly used to identify and classify enteric viral species in different environmental milieu. After the advent of metagenomics, more detailed reports have emerged about the important waterborne viruses identified in wastewater treatment plant effluents and surface water. This paper provides a review of methods that have been used for the concentration, detection and identification of viral species from different environmental matrices. The review also takes into consideration where metagenomics has been explored in different African countries, as well as the limitations and challenges facing the approach. Procedures including sample processing, experimental design, sequencing technology, and bioinformatics analysis are discussed. The review concludes by summarising the current thinking and practices in the field and lays bare key issues that those venturing into this field need to consider and address.",0,0
35139271,Final Analysis of Efficacy and Safety of Single-Dose Ad26.COV2.S,"Sadoff J, Gray G, Vandebosch A, Cárdenas V, Shukarev G, Grinsztejn B, Goepfert PA, Truyers C, Van Dromme I, Spiessens B, Vingerhoets J, Custers J, Scheper G, Robb ML, Treanor J, Ryser MF, Barouch DH, Swann E, Marovich MA, Neuzil KM, Corey L, Stoddard J, Hardt K, Ruiz-Guiñazú J, Le Gars M, Schuitemaker H, Van Hoof J, Struyf F, Douoguih M; ENSEMBLE Study Group.",N Engl J Med. 2022 Mar 3;386(9):847-860. doi: 10.1056/NEJMoa2117608. Epub 2022 Feb 9.,Sadoff J,N Engl J Med,2022,09-02-2022,PMC8849184,,10.1056/NEJMoa2117608,"BACKGROUND: The Ad26.COV2.S vaccine was highly effective against severe-critical coronavirus disease 2019 (Covid-19), hospitalization, and death in the primary phase 3 efficacy analysis.
METHODS: We conducted the final analysis in the double-blind phase of our multinational, randomized, placebo-controlled trial, in which adults were assigned in a 1:1 ratio to receive single-dose Ad26.COV2.S (5×1010 viral particles) or placebo. The primary end points were vaccine efficacy against moderate to severe-critical Covid-19 with onset at least 14 days after administration and at least 28 days after administration in the per-protocol population. Safety and key secondary and exploratory end points were also assessed.
RESULTS: Median follow-up in this analysis was 4 months; 8940 participants had at least 6 months of follow-up. In the per-protocol population (39,185 participants), vaccine efficacy against moderate to severe-critical Covid-19 at least 14 days after administration was 56.3% (95% confidence interval [CI], 51.3 to 60.8; 484 cases in the vaccine group vs. 1067 in the placebo group); at least 28 days after administration, vaccine efficacy was 52.9% (95% CI, 47.1 to 58.1; 433 cases in the vaccine group vs. 883 in the placebo group). Efficacy in the United States, primarily against the reference strain (B.1.D614G) and the B.1.1.7 (alpha) variant, was 69.7% (95% CI, 60.7 to 76.9); efficacy was reduced elsewhere against the P.1 (gamma), C.37 (lambda), and B.1.621 (mu) variants. Efficacy was 74.6% (95% CI, 64.7 to 82.1) against severe-critical Covid-19 (with only 4 severe-critical cases caused by the B.1.617.2 [delta] variant), 75.6% (95% CI, 54.3 to 88.0) against Covid-19 leading to medical intervention (including hospitalization), and 82.8% (95% CI, 40.5 to 96.8) against Covid-19-related death, with protection lasting 6 months or longer. Efficacy against any severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection was 41.7% (95% CI, 36.3 to 46.7). Ad26.COV2.S was associated with mainly mild-to-moderate adverse events, and no new safety concerns were identified.
CONCLUSIONS: A single dose of Ad26.COV2.S provided 52.9% protection against moderate to severe-critical Covid-19. Protection varied according to variant; higher protection was observed against severe Covid-19, medical intervention, and death than against other end points and lasted for 6 months or longer. (Funded by Janssen Research and Development and others; ENSEMBLE ClinicalTrials.gov number, NCT04505722.).","Final Analysis of Efficacy and Safety of Single-Dose Ad26.COV2.S BACKGROUND: The Ad26.COV2.S vaccine was highly effective against severe-critical coronavirus disease 2019 (Covid-19), hospitalization, and death in the primary phase 3 efficacy analysis.
METHODS: We conducted the final analysis in the double-blind phase of our multinational, randomized, placebo-controlled trial, in which adults were assigned in a 1:1 ratio to receive single-dose Ad26.COV2.S (5×1010 viral particles) or placebo. The primary end points were vaccine efficacy against moderate to severe-critical Covid-19 with onset at least 14 days after administration and at least 28 days after administration in the per-protocol population. Safety and key secondary and exploratory end points were also assessed.
RESULTS: Median follow-up in this analysis was 4 months; 8940 participants had at least 6 months of follow-up. In the per-protocol population (39,185 participants), vaccine efficacy against moderate to severe-critical Covid-19 at least 14 days after administration was 56.3% (95% confidence interval [CI], 51.3 to 60.8; 484 cases in the vaccine group vs. 1067 in the placebo group); at least 28 days after administration, vaccine efficacy was 52.9% (95% CI, 47.1 to 58.1; 433 cases in the vaccine group vs. 883 in the placebo group). Efficacy in the United States, primarily against the reference strain (B.1.D614G) and the B.1.1.7 (alpha) variant, was 69.7% (95% CI, 60.7 to 76.9); efficacy was reduced elsewhere against the P.1 (gamma), C.37 (lambda), and B.1.621 (mu) variants. Efficacy was 74.6% (95% CI, 64.7 to 82.1) against severe-critical Covid-19 (with only 4 severe-critical cases caused by the B.1.617.2 [delta] variant), 75.6% (95% CI, 54.3 to 88.0) against Covid-19 leading to medical intervention (including hospitalization), and 82.8% (95% CI, 40.5 to 96.8) against Covid-19-related death, with protection lasting 6 months or longer. Efficacy against any severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection was 41.7% (95% CI, 36.3 to 46.7). Ad26.COV2.S was associated with mainly mild-to-moderate adverse events, and no new safety concerns were identified.
CONCLUSIONS: A single dose of Ad26.COV2.S provided 52.9% protection against moderate to severe-critical Covid-19. Protection varied according to variant; higher protection was observed against severe Covid-19, medical intervention, and death than against other end points and lasted for 6 months or longer. (Funded by Janssen Research and Development and others; ENSEMBLE ClinicalTrials.gov number, NCT04505722.).",0,0
31702817,HIV‑1 integrase inhibitors targeting various DDE transposases: Retroviral integration versus RAG‑mediated recombination (Review),"Mușat MG, Nițulescu GM, Surleac M, Tsatsakis A, Spandidos DA, Margină D.",Mol Med Rep. 2019 Dec;20(6):4749-4762. doi: 10.3892/mmr.2019.10777. Epub 2019 Oct 30.,Mușat MG,Mol Med Rep,2019,09-11-2019,PMC6854553,,10.3892/mmr.2019.10777,"Transposases are ubiquitous mobile genetic elements responsible for genome development, driving rearrangements, such as insertions, deletions and translocations. Across species evolution, some transposases are tamed by their host and are made part of complex cellular systems. The proliferation of retroviruses is also dependent on transposase related enzymes termed integrases. Recombination‑activating gene protein (RAG)1 and metnase are just two examples of transposase domestication and together with retroviral integrases (INs), they belong to the DDE polynucleotidyl transferases superfamily. They share mechanistic and structural features linked to the RNase H‑like fold, harboring a DDE(D) metal dependent catalytic motif. Recent antiretroviral compounds target the catalytic domain of integrase, but they also have the potential of inhibiting other related enzymes. In this review, we report the activity of different classes of integrase inhibitors on various DDE transposases. Computational simulations are useful to predict the extent of off‑target activity and have been employed to study the interactions between RAG1 recombinase and compounds from three different pharmacologic classes. We demonstrate that strand‑transfer inhibitors display a higher affinity towards the RAG1 RNase H domain, as suggested by experimental data compared to allosteric inhibitors. While interference with RAG1 and 2 recombination is associated with a negative impact on immune function, the inhibition of metnase or HTLV‑1 integrase opens the way for the development of novel therapies for refractory cancers.","HIV‑1 integrase inhibitors targeting various DDE transposases: Retroviral integration versus RAG‑mediated recombination (Review) Transposases are ubiquitous mobile genetic elements responsible for genome development, driving rearrangements, such as insertions, deletions and translocations. Across species evolution, some transposases are tamed by their host and are made part of complex cellular systems. The proliferation of retroviruses is also dependent on transposase related enzymes termed integrases. Recombination‑activating gene protein (RAG)1 and metnase are just two examples of transposase domestication and together with retroviral integrases (INs), they belong to the DDE polynucleotidyl transferases superfamily. They share mechanistic and structural features linked to the RNase H‑like fold, harboring a DDE(D) metal dependent catalytic motif. Recent antiretroviral compounds target the catalytic domain of integrase, but they also have the potential of inhibiting other related enzymes. In this review, we report the activity of different classes of integrase inhibitors on various DDE transposases. Computational simulations are useful to predict the extent of off‑target activity and have been employed to study the interactions between RAG1 recombinase and compounds from three different pharmacologic classes. We demonstrate that strand‑transfer inhibitors display a higher affinity towards the RAG1 RNase H domain, as suggested by experimental data compared to allosteric inhibitors. While interference with RAG1 and 2 recombination is associated with a negative impact on immune function, the inhibition of metnase or HTLV‑1 integrase opens the way for the development of novel therapies for refractory cancers.",0,0
38318179,"Defining the ""Correlate(s) of Protection"" to tick-borne encephalitis vaccination and infection - key points and outstanding questions","Ackermann-Gäumann R, Lang P, Zens KD.",Front Immunol. 2024 Jan 22;15:1352720. doi: 10.3389/fimmu.2024.1352720. eCollection 2024.,Ackermann-Gäumann R,Front Immunol,2024,06-02-2024,PMC10840404,,10.3389/fimmu.2024.1352720,"Tick-borne Encephalitis (TBE) is a severe disease of the Central Nervous System (CNS) caused by the tick-borne encephalitis virus (TBEV). The generation of protective immunity after TBEV infection or TBE vaccination relies on the integrated responses of many distinct cell types at distinct physical locations. While long-lasting memory immune responses, in particular, form the basis for the correlates of protection against many diseases, these correlates of protection have not yet been clearly defined for TBE. This review addresses the immune control of TBEV infection and responses to TBE vaccination. Potential correlates of protection and the durability of protection against disease are discussed, along with outstanding questions in the field and possible areas for future research.","Defining the ""Correlate(s) of Protection"" to tick-borne encephalitis vaccination and infection - key points and outstanding questions Tick-borne Encephalitis (TBE) is a severe disease of the Central Nervous System (CNS) caused by the tick-borne encephalitis virus (TBEV). The generation of protective immunity after TBEV infection or TBE vaccination relies on the integrated responses of many distinct cell types at distinct physical locations. While long-lasting memory immune responses, in particular, form the basis for the correlates of protection against many diseases, these correlates of protection have not yet been clearly defined for TBE. This review addresses the immune control of TBEV infection and responses to TBE vaccination. Potential correlates of protection and the durability of protection against disease are discussed, along with outstanding questions in the field and possible areas for future research.",0,0
33193364,Vasculitis as a Major Morbidity Factor in Patients With Partial RAG Deficiency,"Geier CB, Farmer JR, Foldvari Z, Ujhazi B, Steininger J, Sleasman JW, Parikh S, Dilley MA, Pai SY, Henderson L, Hazen M, Neven B, Moshous D, Sharapova SO, Mihailova S, Yankova P, Naumova E, Özen S, Byram K, Fernandez J, Wolf HM, Eibl MM, Notarangelo LD, Calabrese LH, Walter JE.",Front Immunol. 2020 Oct 21;11:574738. doi: 10.3389/fimmu.2020.574738. eCollection 2020.,Geier CB,Front Immunol,2020,16-11-2020,PMC7609967,,10.3389/fimmu.2020.574738,"Vasculitis can be a life-threatening complication associated with high mortality and morbidity among patients with primary immunodeficiencies (PIDs), including variants of severe and combined immunodeficiencies ((S)CID). Our understanding of vasculitis in partial defects in recombination activating gene (RAG) deficiency, a prototype of (S)CIDs, is limited with no published systematic evaluation of diagnostic and therapeutic modalities. In this report, we sought to establish the clinical, laboratory features, and treatment outcome of patients with vasculitis due to partial RAG deficiency. Vasculitis was a major complication in eight (13%) of 62 patients in our cohort with partial RAG deficiency with features of infections and immune dysregulation. Vasculitis occurred early in life, often as first sign of disease (50%) and was complicated by significant end organ damage. Viral infections often preceded the onset of predominately non-granulomatous-small vessel vasculitis. Autoantibodies against cytokines (IFN-α, -ω, and IL-12) were detected in a large fraction of the cases tested (80%), whereas the majority of patients were anti-neutrophil cytoplasmic antibodies (ANCA) negative (>80%). Genetic diagnosis of RAG deficiency was delayed up to 2 years from the onset of vasculitis. Clinical cases with sole skin manifestation responded well to first-line steroid treatment, whereas systemic vasculitis with severe end-organ complications required second-line immunosuppression and/or hematopoietic stem cell transplantation (HSCT) for definitive management. In conclusion, our data suggest that vasculitis in partial RAG deficiency is prevalent among patients with partial RAG deficiency and is associated with high morbidity. Therefore, partial RAG deficiency should be included in the differential diagnosis of patients with early-onset systemic vasculitis. Diagnostic serology may be misleading with ANCA negative findings, and search for conventional autoantibodies should be extended to include those targeting cytokines.","Vasculitis as a Major Morbidity Factor in Patients With Partial RAG Deficiency Vasculitis can be a life-threatening complication associated with high mortality and morbidity among patients with primary immunodeficiencies (PIDs), including variants of severe and combined immunodeficiencies ((S)CID). Our understanding of vasculitis in partial defects in recombination activating gene (RAG) deficiency, a prototype of (S)CIDs, is limited with no published systematic evaluation of diagnostic and therapeutic modalities. In this report, we sought to establish the clinical, laboratory features, and treatment outcome of patients with vasculitis due to partial RAG deficiency. Vasculitis was a major complication in eight (13%) of 62 patients in our cohort with partial RAG deficiency with features of infections and immune dysregulation. Vasculitis occurred early in life, often as first sign of disease (50%) and was complicated by significant end organ damage. Viral infections often preceded the onset of predominately non-granulomatous-small vessel vasculitis. Autoantibodies against cytokines (IFN-α, -ω, and IL-12) were detected in a large fraction of the cases tested (80%), whereas the majority of patients were anti-neutrophil cytoplasmic antibodies (ANCA) negative (>80%). Genetic diagnosis of RAG deficiency was delayed up to 2 years from the onset of vasculitis. Clinical cases with sole skin manifestation responded well to first-line steroid treatment, whereas systemic vasculitis with severe end-organ complications required second-line immunosuppression and/or hematopoietic stem cell transplantation (HSCT) for definitive management. In conclusion, our data suggest that vasculitis in partial RAG deficiency is prevalent among patients with partial RAG deficiency and is associated with high morbidity. Therefore, partial RAG deficiency should be included in the differential diagnosis of patients with early-onset systemic vasculitis. Diagnostic serology may be misleading with ANCA negative findings, and search for conventional autoantibodies should be extended to include those targeting cytokines.",1,0
32880733,Multinational Association of Supportive Care in Cancer (MASCC) 2020 clinical practice recommendations for the management of immune-related adverse events: pulmonary toxicity,"Shannon VR, Anderson R, Blidner A, Choi J, Cooksley T, Dougan M, Glezerman I, Ginex P, Girotra M, Gupta D, Johnson DB, Suarez-Almazor ME, Rapoport BL.",Support Care Cancer. 2020 Dec;28(12):6145-6157. doi: 10.1007/s00520-020-05708-2. Epub 2020 Sep 3.,Shannon VR,Support Care Cancer,2020,04-09-2020,PMC7471521,,10.1007/s00520-020-05708-2,"The immune checkpoints associated with the CTLA-4 and PD-1 pathways are critical modulators of immune activation. These pathways dampen the immune response by providing brakes on activated T cells, thereby ensuring more uniform and controlled immune reactions and avoiding immune hyper-responsiveness and autoimmunity. Cancer cells often exploit these regulatory controls through a variety of immune subversion mechanisms, which facilitate immune escape and tumor survival. Immune checkpoint inhibitors (ICI) effectively block negative regulatory signals, thereby augmenting immune attack and tumor killing. This process is a double-edged sword in which release of regulatory controls is felt to be responsible for both the therapeutic efficacy of ICI therapy and the driver of immune-related adverse events (IrAEs). These adverse immune reactions are common, typically low-grade and may affect virtually every organ system. In the early clinical trials, lung IrAEs were rarely described. However, with ever-expanding clinical applications and more complex ICI-containing regimens, lung events, in particular, pneumonitis, have become increasingly recognized. ICI-related lung injury is clinically distinct from other types of lung toxicity and may lead to death in advanced stage disease. Thus, knowledge regarding the key characteristics and optimal treatment of lung-IrAEs is critical to good outcomes. This review provides an overview of lung-IrAEs, including risk factors and epidemiology, as well as clinical, radiologic, and histopathologic features of ICI-related lung injury. Management principles for ICI-related lung injury, including current consensus on steroid refractory pneumonitis and the use of other immune modulating agents in this setting are also highlighted.","Multinational Association of Supportive Care in Cancer (MASCC) 2020 clinical practice recommendations for the management of immune-related adverse events: pulmonary toxicity The immune checkpoints associated with the CTLA-4 and PD-1 pathways are critical modulators of immune activation. These pathways dampen the immune response by providing brakes on activated T cells, thereby ensuring more uniform and controlled immune reactions and avoiding immune hyper-responsiveness and autoimmunity. Cancer cells often exploit these regulatory controls through a variety of immune subversion mechanisms, which facilitate immune escape and tumor survival. Immune checkpoint inhibitors (ICI) effectively block negative regulatory signals, thereby augmenting immune attack and tumor killing. This process is a double-edged sword in which release of regulatory controls is felt to be responsible for both the therapeutic efficacy of ICI therapy and the driver of immune-related adverse events (IrAEs). These adverse immune reactions are common, typically low-grade and may affect virtually every organ system. In the early clinical trials, lung IrAEs were rarely described. However, with ever-expanding clinical applications and more complex ICI-containing regimens, lung events, in particular, pneumonitis, have become increasingly recognized. ICI-related lung injury is clinically distinct from other types of lung toxicity and may lead to death in advanced stage disease. Thus, knowledge regarding the key characteristics and optimal treatment of lung-IrAEs is critical to good outcomes. This review provides an overview of lung-IrAEs, including risk factors and epidemiology, as well as clinical, radiologic, and histopathologic features of ICI-related lung injury. Management principles for ICI-related lung injury, including current consensus on steroid refractory pneumonitis and the use of other immune modulating agents in this setting are also highlighted.",0,0
28590319,SURGICAL OUTCOMES OF 27-GAUGE VITRECTOMY FOR A CONSECUTIVE SERIES OF 163 EYES WITH VARIOUS VITREOUS DISEASES,"Yoneda K, Morikawa K, Oshima Y, Kinoshita S, Sotozono C; Japan Microincision Vitrectomy Surgery Study Group.",Retina. 2017 Nov;37(11):2130-2137. doi: 10.1097/IAE.0000000000001442.,Yoneda K,Retina,2017,08-06-2017,PMC5690303,,10.1097/IAE.0000000000001442,"PURPOSE: To evaluate the safety and efficacy of 27-gauge vitrectomy for various vitreoretinal disorders.
METHODS: In this retrospective comparative study, 163 consecutive eyes with various diseases that underwent 27-gauge pars plana vitrectomy with or without ultraspeed transformer by a single surgeon from June 2012 through December 2014 were analyzed in regard to best-corrected visual acuity, intraocular pressure, intraoperative and postoperative complications, and surgery time.
RESULTS: In 2 eyes (1.2%), peripheral retina breaks were encountered intraoperatively, yet no other complications were found in those eyes. No cases required larger-gauge vitrectomy. Mean best-corrected visual acuity improved from 20/58 (logarithm of the minimum angle of resolution, 0.46 ± 0.64) preoperatively to 20/32 (logarithm of the minimum angle of resolution, 0.20 ± 0.40) postoperatively (P < 0.001). Mean follow-up was 16.7 months (range, 6-33 months). Intraocular pressure remained stable throughout the postoperative course. Hypotony was seen in 15 eyes (9.2%) at 1-day postoperative, yet that spontaneously improved within 1 week. No case of retinal detachment or endophthalmitis was recorded. In macular surgeries, such as idiopathic epiretinal membrane and macular hole combined with cataract surgery, the mean surgery time was 32.1 ± 6.9 minutes with ultraspeed transformer (n = 38) and 37.1 ± 7.7 minutes without ultraspeed transformer (n = 40) (P = 0.004).
CONCLUSION: The 27-gauge pars plana vitrectomy was found to be safe and effective for treating various vitreoretinal disorders.","SURGICAL OUTCOMES OF 27-GAUGE VITRECTOMY FOR A CONSECUTIVE SERIES OF 163 EYES WITH VARIOUS VITREOUS DISEASES PURPOSE: To evaluate the safety and efficacy of 27-gauge vitrectomy for various vitreoretinal disorders.
METHODS: In this retrospective comparative study, 163 consecutive eyes with various diseases that underwent 27-gauge pars plana vitrectomy with or without ultraspeed transformer by a single surgeon from June 2012 through December 2014 were analyzed in regard to best-corrected visual acuity, intraocular pressure, intraoperative and postoperative complications, and surgery time.
RESULTS: In 2 eyes (1.2%), peripheral retina breaks were encountered intraoperatively, yet no other complications were found in those eyes. No cases required larger-gauge vitrectomy. Mean best-corrected visual acuity improved from 20/58 (logarithm of the minimum angle of resolution, 0.46 ± 0.64) preoperatively to 20/32 (logarithm of the minimum angle of resolution, 0.20 ± 0.40) postoperatively (P < 0.001). Mean follow-up was 16.7 months (range, 6-33 months). Intraocular pressure remained stable throughout the postoperative course. Hypotony was seen in 15 eyes (9.2%) at 1-day postoperative, yet that spontaneously improved within 1 week. No case of retinal detachment or endophthalmitis was recorded. In macular surgeries, such as idiopathic epiretinal membrane and macular hole combined with cataract surgery, the mean surgery time was 32.1 ± 6.9 minutes with ultraspeed transformer (n = 38) and 37.1 ± 7.7 minutes without ultraspeed transformer (n = 40) (P = 0.004).
CONCLUSION: The 27-gauge pars plana vitrectomy was found to be safe and effective for treating various vitreoretinal disorders.",1,0
39054430,"A randomized, open-label, phase 3 trial of pembrolizumab plus epacadostat versus sunitinib or pazopanib as first-line treatment for metastatic renal cell carcinoma (KEYNOTE-679/ECHO-302)","Lara PN Jr, Villanueva L, Ibanez C, Erman M, Lee JL, Heinrich D, Lipatov ON, Gedye C, Gokmen E, Acevedo A, Semenov A, Park SH, Gafanov RA, Kose F, Jones M, Du X, Munteanu M, Perini R, Choueiri TK, Motzer RJ.",BMC Cancer. 2024 Jul 25;23(Suppl 1):1253. doi: 10.1186/s12885-023-10971-7.,Lara PN Jr,BMC Cancer,2024,25-07-2024,PMC11270760,,10.1186/s12885-023-10971-7,"BACKGROUND: Immunotherapy-based combinations have emerged as standard therapies for patients with metastatic renal cell carcinoma (mRCC). Pembrolizumab, a PD-1 inhibitor, combined with epacadostat, an indoleamine 2,3-deoxygenase 1 selective inhibitor, demonstrated promising antitumor activity in a phase 1 study in advanced solid tumors, including mRCC.
METHODS: KEYNOTE-679/ECHO-302 was a randomized, open-label, parallel-group, multicenter, phase 3 study (NCT03260894) that compared pembrolizumab plus epacadostat with sunitinib or pazopanib as first-line treatment for mRCC. Eligible patients had histologically confirmed locally advanced or metastatic clear cell RCC and had not received systemic therapy. Patients were randomly assigned 1:1 to pembrolizumab 200 mg IV every 3 weeks plus epacadostat 100 mg orally twice daily versus sunitinib 50 mg orally once daily (4 weeks on treatment followed by 2 weeks off treatment) or pazopanib 800 mg orally once daily. Original dual primary end points were progression-free survival and overall survival. Enrollment was stopped when a phase 3 study in melanoma of pembrolizumab plus epacadostat compared with pembrolizumab monotherapy did not meet its primary end point. This protocol was amended, and primary end point was changed to investigator-assessed objective response rate (ORR) per RECIST 1.1.
RESULTS: One-hundred-twenty-nine patients were randomly assigned to receive pembrolizumab plus epacadostat (n = 64) or sunitinib/pazopanib (n = 65). Median (range) follow-up, defined as time from randomization to data cutoff, was 10.3 months (2.2-14.3) and 10.3 months (2.7-13.8) in the pembrolizumab plus epacadostat and sunitinib/pazopanib arms, respectively. ORRs were similar between pembrolizumab plus epacadostat (31.3% [95% CI 20.2-44.1] and sunitinib/pazopanib (29.2% [18.6-41.8]). Grade 3-5 treatment-related adverse events occurred in 34.4% and 42.9% of patients in the pembrolizumab plus epacadostat and sunitinib/pazopanib arms, respectively. One patient in the sunitinib/pazopanib arm died of septic shock (not treatment-related). Circulating kynurenine levels decreased in the pembrolizumab plus epacadostat arm, but not to levels observed in healthy subjects.
CONCLUSIONS: ORRs were similar between pembrolizumab plus epacadostat and sunitinib/pazopanib as first-line treatment in patients with mRCC. Safety and tolerability appeared similar between treatment arms; no new safety concerns were identified. Antitumor responses observed in patients with RCC receiving pembrolizumab plus epacadostat may be driven primarily by pembrolizumab.
CLINICAL TRIAL REGISTRATION: ClinicalTrials.gov; NCT03260894 .","A randomized, open-label, phase 3 trial of pembrolizumab plus epacadostat versus sunitinib or pazopanib as first-line treatment for metastatic renal cell carcinoma (KEYNOTE-679/ECHO-302) BACKGROUND: Immunotherapy-based combinations have emerged as standard therapies for patients with metastatic renal cell carcinoma (mRCC). Pembrolizumab, a PD-1 inhibitor, combined with epacadostat, an indoleamine 2,3-deoxygenase 1 selective inhibitor, demonstrated promising antitumor activity in a phase 1 study in advanced solid tumors, including mRCC.
METHODS: KEYNOTE-679/ECHO-302 was a randomized, open-label, parallel-group, multicenter, phase 3 study (NCT03260894) that compared pembrolizumab plus epacadostat with sunitinib or pazopanib as first-line treatment for mRCC. Eligible patients had histologically confirmed locally advanced or metastatic clear cell RCC and had not received systemic therapy. Patients were randomly assigned 1:1 to pembrolizumab 200 mg IV every 3 weeks plus epacadostat 100 mg orally twice daily versus sunitinib 50 mg orally once daily (4 weeks on treatment followed by 2 weeks off treatment) or pazopanib 800 mg orally once daily. Original dual primary end points were progression-free survival and overall survival. Enrollment was stopped when a phase 3 study in melanoma of pembrolizumab plus epacadostat compared with pembrolizumab monotherapy did not meet its primary end point. This protocol was amended, and primary end point was changed to investigator-assessed objective response rate (ORR) per RECIST 1.1.
RESULTS: One-hundred-twenty-nine patients were randomly assigned to receive pembrolizumab plus epacadostat (n = 64) or sunitinib/pazopanib (n = 65). Median (range) follow-up, defined as time from randomization to data cutoff, was 10.3 months (2.2-14.3) and 10.3 months (2.7-13.8) in the pembrolizumab plus epacadostat and sunitinib/pazopanib arms, respectively. ORRs were similar between pembrolizumab plus epacadostat (31.3% [95% CI 20.2-44.1] and sunitinib/pazopanib (29.2% [18.6-41.8]). Grade 3-5 treatment-related adverse events occurred in 34.4% and 42.9% of patients in the pembrolizumab plus epacadostat and sunitinib/pazopanib arms, respectively. One patient in the sunitinib/pazopanib arm died of septic shock (not treatment-related). Circulating kynurenine levels decreased in the pembrolizumab plus epacadostat arm, but not to levels observed in healthy subjects.
CONCLUSIONS: ORRs were similar between pembrolizumab plus epacadostat and sunitinib/pazopanib as first-line treatment in patients with mRCC. Safety and tolerability appeared similar between treatment arms; no new safety concerns were identified. Antitumor responses observed in patients with RCC receiving pembrolizumab plus epacadostat may be driven primarily by pembrolizumab.
CLINICAL TRIAL REGISTRATION: ClinicalTrials.gov; NCT03260894 .",0,0
38585719,Abolished frameshifting for predicted structure-stabilizing SARS-CoV-2 mutants: Implications to alternative conformations and their statistical structural analyses,"Dey A, Yan S, Schlick T, Laederach A.",bioRxiv [Preprint]. 2024 Mar 29:2024.03.28.586935. doi: 10.1101/2024.03.28.586935.,Dey A,bioRxiv,2024,08-04-2024,PMC10996636,,10.1101/2024.03.28.586935,"The SARS-CoV-2 frameshifting element (FSE) has been intensely studied and explored as a therapeutic target for coronavirus diseases including COVID-19. Besides the intriguing virology, this small RNA is known to adopt many length-dependent conformations, as verified by multiple experimental and computational approaches. However, the role these alternative conformations play in the frameshifting mechanism and how to quantify this structural abundance has been an ongoing challenge. Here, we show by DMS and dual-luciferase functional assays that previously predicted FSE mutants (using the RAG graph theory approach) suppress structural transitions and abolish frameshifting. Furthermore, correlated mutation analysis of DMS data by three programs (DREEM, DRACO, and DANCE-MaP) reveals important differences in their estimation of specific RNA conformations, suggesting caution in the interpretation of such complex conformational landscapes. Overall, the abolished frameshifting in three different mutants confirms that all alternative conformations play a role in the pathways of ribosomal transition.","Abolished frameshifting for predicted structure-stabilizing SARS-CoV-2 mutants: Implications to alternative conformations and their statistical structural analyses The SARS-CoV-2 frameshifting element (FSE) has been intensely studied and explored as a therapeutic target for coronavirus diseases including COVID-19. Besides the intriguing virology, this small RNA is known to adopt many length-dependent conformations, as verified by multiple experimental and computational approaches. However, the role these alternative conformations play in the frameshifting mechanism and how to quantify this structural abundance has been an ongoing challenge. Here, we show by DMS and dual-luciferase functional assays that previously predicted FSE mutants (using the RAG graph theory approach) suppress structural transitions and abolish frameshifting. Furthermore, correlated mutation analysis of DMS data by three programs (DREEM, DRACO, and DANCE-MaP) reveals important differences in their estimation of specific RNA conformations, suggesting caution in the interpretation of such complex conformational landscapes. Overall, the abolished frameshifting in three different mutants confirms that all alternative conformations play a role in the pathways of ribosomal transition.",0,0
37187529,Prediction of the spread of African swine fever through pig and carcass movements in Thailand using a network analysis and diffusion model,"Poolkhet C, Kasemsuwan S, Thongratsakul S, Warrasuth N, Pamaranon N, Nuanualsuwan S.",PeerJ. 2023 May 9;11:e15359. doi: 10.7717/peerj.15359. eCollection 2023.,Poolkhet C,PeerJ,2023,15-05-2023,PMC10178211,,10.7717/peerj.15359,"BACKGROUND: African swine fever (ASF) is a serious contagious viral disease of pigs that affects the pig industry. This study aimed to evaluate the possible African swine fever (ASF) distribution using network analysis and a diffusion model through live pig, carcass, and pig product movement data.
MATERIAL AND METHODS: Empirical movement data from Thailand for the year 2019 were used, and expert opinions were sought to evaluate network properties and the diffusion model. The networks were presented as live pig movement and carcass movement data at the provincial and district levels. For network analysis, a descriptive network analysis was performed using outdegree, indegree, betweenness, fragmentation, and power law distribution, and cutpoints were used to describe movement patterns. For the diffusion model, we simulated each network using spatially different infected locations, patterns, and initial infection sites. Based on expert opinions, the initial infection site, the probability of ASF occurrence, and the probability of the initial infected adopter were selected for the appropriated network. In this study, we also simulated networks under varying network parameters to predict the infection speed.
RESULTS AND CONCLUSIONS: The total number of movements recorded was 2,594,364. These were divided into 403,408 (403,408/2,594,364; 15.55%) for live pigs and 2,190,956 (2,190,956/2,594,364; 84.45%) for carcasses. We found that carcass movement at the provincial level showed the highest outdegree (mean = 342.554, standard deviation (SD) = 900.528) and indegree values (mean = 342.554, SD = 665.509). In addition, the outdegree and indegree presented similar mean values and the degree distributions of both district networks followed a power-law function. The network of live pigs at provincial level showed the highest value for betweenness (mean = 0.011, SD = 0.017), and the network of live pigs at provincial level showed the highest value for fragmentation (mean = 0.027, SD = 0.005). Our simulation data indicated that the disease occurred randomly due to live pig and carcass movements along the central and western regions of Thailand, causing the rapid spread of ASF. Without control measures, it could spread to all provinces within 5- and 3-time units and in all districts within 21- and 30-time units for the network of live pigs and carcasses, respectively. This study assists the authorities to plan control and preventive measures and limit economic losses caused by ASF.","Prediction of the spread of African swine fever through pig and carcass movements in Thailand using a network analysis and diffusion model BACKGROUND: African swine fever (ASF) is a serious contagious viral disease of pigs that affects the pig industry. This study aimed to evaluate the possible African swine fever (ASF) distribution using network analysis and a diffusion model through live pig, carcass, and pig product movement data.
MATERIAL AND METHODS: Empirical movement data from Thailand for the year 2019 were used, and expert opinions were sought to evaluate network properties and the diffusion model. The networks were presented as live pig movement and carcass movement data at the provincial and district levels. For network analysis, a descriptive network analysis was performed using outdegree, indegree, betweenness, fragmentation, and power law distribution, and cutpoints were used to describe movement patterns. For the diffusion model, we simulated each network using spatially different infected locations, patterns, and initial infection sites. Based on expert opinions, the initial infection site, the probability of ASF occurrence, and the probability of the initial infected adopter were selected for the appropriated network. In this study, we also simulated networks under varying network parameters to predict the infection speed.
RESULTS AND CONCLUSIONS: The total number of movements recorded was 2,594,364. These were divided into 403,408 (403,408/2,594,364; 15.55%) for live pigs and 2,190,956 (2,190,956/2,594,364; 84.45%) for carcasses. We found that carcass movement at the provincial level showed the highest outdegree (mean = 342.554, standard deviation (SD) = 900.528) and indegree values (mean = 342.554, SD = 665.509). In addition, the outdegree and indegree presented similar mean values and the degree distributions of both district networks followed a power-law function. The network of live pigs at provincial level showed the highest value for betweenness (mean = 0.011, SD = 0.017), and the network of live pigs at provincial level showed the highest value for fragmentation (mean = 0.027, SD = 0.005). Our simulation data indicated that the disease occurred randomly due to live pig and carcass movements along the central and western regions of Thailand, causing the rapid spread of ASF. Without control measures, it could spread to all provinces within 5- and 3-time units and in all districts within 21- and 30-time units for the network of live pigs and carcasses, respectively. This study assists the authorities to plan control and preventive measures and limit economic losses caused by ASF.",1,1
