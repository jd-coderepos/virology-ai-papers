Authors,Year of publication,Title of article,Name of Publication/Journal,Title,authors,category,date,Abstract,doi,source_file,Combined_Text,Is_infectious
"Jalal, H.; Burke, D. S.",2019,Hexamaps for Visualizing Age-Period-Cohort Data Trends,Epidemiology,Hexamaps for Visualizing Age-Period-Cohort Data Trends,"Jalal, H.; Burke, D. S.",Epidemiology,2019-11-29 00:00:00 UTC,"Age-period-cohort (APC) analyses often reveal important insights into patterns of disease incidence and mortality such as cancer. Both visual and analytical APC tools are available to reveal patterns by age, period and cohort. While developing new analytical methods of APC data is an active area of research, the choices of visual tools specific to APC data has been limited. In this study, we propose a ""hexamap"" as a new APC specific data visualization tool. This tool uses hexagons to address the unique challenge of APC data visualization, that is cohort= period - age. The approach is further illustrated using alcohol related mortality. Flexible Open-Source functions for implementation in R is also provided.",10.1101/19011700,virology-agentic-ai.xlsx,"Hexamaps for Visualizing Age-Period-Cohort Data Trends Age-period-cohort (APC) analyses often reveal important insights into patterns of disease incidence and mortality such as cancer. Both visual and analytical APC tools are available to reveal patterns by age, period and cohort. While developing new analytical methods of APC data is an active area of research, the choices of visual tools specific to APC data has been limited. In this study, we propose a ""hexamap"" as a new APC specific data visualization tool. This tool uses hexagons to address the unique challenge of APC data visualization, that is cohort= period - age. The approach is further illustrated using alcohol related mortality. Flexible Open-Source functions for implementation in R is also provided.",0
"Grossmann, G.; Backenkoehler, M.; Wolf, V.",2020,Importance of Interaction Structure and Stochasticity for Epidemic Spreading: A COVID-19 Case Study,Epidemiology,Importance of Interaction Structure and Stochasticity for Epidemic Spreading: A COVID-19 Case Study,"Grossmann, G.; Backenkoehler, M.; Wolf, V.",Epidemiology,2020-09-03 00:00:00 UTC,"In the recent COVID-19 pandemic, computer simulations are used to predict the evolution of the virus propagation and to evaluate the prospective effectiveness of non-pharmaceutical interventions. As such, the corresponding mathematical models and their simulations are central tools to guide political decision-making. Typically, ODE-based models are considered, in which fractions of infected and healthy individuals change deterministically and continuously over time.

In this work, we translate an ODE-based COVID-19 spreading model from literature to a stochastic multi-agent system and use a contact network to mimic complex interaction structures. We observe a large dependency of the epidemics dynamics on the structure of the underlying contact graph, which is not adequately captured by existing ODE-models. For instance, existence of super-spreaders leads to a higher infection peak but a lower death toll compared to interaction structures without super-spreaders. Overall, we observe that the interaction structure has a crucial impact on the spreading dynamics, which exceeds the effects of other parameters such as the basic reproduction number R0.

We conclude that deterministic models fitted to COVID-19 outbreak data have limited predictive power or may even lead to wrong conclusions while stochastic models taking interaction structure into account offer different and probably more realistic epidemiological insights.",10.1101/2020.05.05.20091736,virology-agentic-ai.xlsx,"Importance of Interaction Structure and Stochasticity for Epidemic Spreading: A COVID-19 Case Study In the recent COVID-19 pandemic, computer simulations are used to predict the evolution of the virus propagation and to evaluate the prospective effectiveness of non-pharmaceutical interventions. As such, the corresponding mathematical models and their simulations are central tools to guide political decision-making. Typically, ODE-based models are considered, in which fractions of infected and healthy individuals change deterministically and continuously over time.

In this work, we translate an ODE-based COVID-19 spreading model from literature to a stochastic multi-agent system and use a contact network to mimic complex interaction structures. We observe a large dependency of the epidemics dynamics on the structure of the underlying contact graph, which is not adequately captured by existing ODE-models. For instance, existence of super-spreaders leads to a higher infection peak but a lower death toll compared to interaction structures without super-spreaders. Overall, we observe that the interaction structure has a crucial impact on the spreading dynamics, which exceeds the effects of other parameters such as the basic reproduction number R0.

We conclude that deterministic models fitted to COVID-19 outbreak data have limited predictive power or may even lead to wrong conclusions while stochastic models taking interaction structure into account offer different and probably more realistic epidemiological insights.",1
"Nande, A.; Adlam, B.; Sheen, J.; Levy, M. Z.; Hill, A. L.",2021,Dynamics of COVID-19 under social distancing measures are driven by transmission network structure,Epidemiology,Dynamics of COVID-19 under social distancing measures are driven by transmission network structure,"Nande, A.; Adlam, B.; Sheen, J.; Levy, M. Z.; Hill, A. L.",Epidemiology,2021-01-15 00:00:00 UTC,"In the absence of pharmaceutical interventions, social distancing is being used worldwide to curb the spread of COVID-19. The impact of these measures has been inconsistent, with some regions rapidly nearing disease elimination and others seeing delayed peaks or nearly flat epidemic curves. Here we build a stochastic epidemic model to examine the effects of COVID-19 clinical progression and transmission network structure on the outcomes of social distancing interventions. Our simulations show that long delays between the adoption of control measures and observed declines in cases, hospitalizations, and deaths occur in many scenarios. We find that the strength of within-household transmission is a critical determinant of success, governing the timing and size of the epidemic peak, the rate of decline, individual risks of infection, and the success of partial relaxation measures. The structure of residual external connections, driven by workforce participation and essential businesses, interacts to determine outcomes. We suggest limited conditions under which the formation of household ""bubbles"" can be safe. These findings can improve future predictions of the timescale and efficacy of interventions needed to control second waves of COVID-19 as well as other similar outbreaks, and highlight the need for better quantification and control of household transmission.

Author SummarySocial distancing is the main tool used to control COVID-19, and involves reducing contacts that could potentially transmit infection with strategies like school closures, work-from-home policies, mask-wearing, or lockdowns. These measures have been applied around the world, but in situations where they have suppressed infections, the effect has not been immediate or consistent. In this study we use a mathematical model to simulate the spread and control of COVID-19, tracking the different settings of person-to-person contact (e.g. household, school, workplace) and the different clinical stages an infected individual may pass through before recovery or death. We find that there are often long delays between when strong social distancing policies are adopted and when cases, hospitalizations, and deaths peak and begin to decline. Moreover, we find that the amount of transmission that happens within versus outside the household is critical to determining when social distancing can be effective and the delay until the epidemic peak. We show how the interaction between unmitigated households spread and residual external connections due to essential activities impacts individual risk and population infection levels. These results can be used to better predict the impact of future interventions to control COVID-19 or similar outbreaks",10.1101/2020.06.04.20121673,virology-agentic-ai.xlsx,"Dynamics of COVID-19 under social distancing measures are driven by transmission network structure In the absence of pharmaceutical interventions, social distancing is being used worldwide to curb the spread of COVID-19. The impact of these measures has been inconsistent, with some regions rapidly nearing disease elimination and others seeing delayed peaks or nearly flat epidemic curves. Here we build a stochastic epidemic model to examine the effects of COVID-19 clinical progression and transmission network structure on the outcomes of social distancing interventions. Our simulations show that long delays between the adoption of control measures and observed declines in cases, hospitalizations, and deaths occur in many scenarios. We find that the strength of within-household transmission is a critical determinant of success, governing the timing and size of the epidemic peak, the rate of decline, individual risks of infection, and the success of partial relaxation measures. The structure of residual external connections, driven by workforce participation and essential businesses, interacts to determine outcomes. We suggest limited conditions under which the formation of household ""bubbles"" can be safe. These findings can improve future predictions of the timescale and efficacy of interventions needed to control second waves of COVID-19 as well as other similar outbreaks, and highlight the need for better quantification and control of household transmission.

Author SummarySocial distancing is the main tool used to control COVID-19, and involves reducing contacts that could potentially transmit infection with strategies like school closures, work-from-home policies, mask-wearing, or lockdowns. These measures have been applied around the world, but in situations where they have suppressed infections, the effect has not been immediate or consistent. In this study we use a mathematical model to simulate the spread and control of COVID-19, tracking the different settings of person-to-person contact (e.g. household, school, workplace) and the different clinical stages an infected individual may pass through before recovery or death. We find that there are often long delays between when strong social distancing policies are adopted and when cases, hospitalizations, and deaths peak and begin to decline. Moreover, we find that the amount of transmission that happens within versus outside the household is critical to determining when social distancing can be effective and the delay until the epidemic peak. We show how the interaction between unmitigated households spread and residual external connections due to essential activities impacts individual risk and population infection levels. These results can be used to better predict the impact of future interventions to control COVID-19 or similar outbreaks",1
"Grossmann, G.; Backenkoehler, M.; Wolf, V.",2021,Why ODE models for COVID-19 fail: Heterogeneity shapes epidemic dynamics,Epidemiology,Why ODE models for COVID-19 fail: Heterogeneity shapes epidemic dynamics,"Grossmann, G.; Backenkoehler, M.; Wolf, V.",Epidemiology,2021-03-26 00:00:00 UTC,"In the recent COVID-19 pandemic, mathematical modeling constitutes an important tool to evaluate the prospective effectiveness of non-pharmaceutical interventions (NPIs) and to guide policy-making. Most research is, however, centered around characterizing the epidemic based on point estimates like the average infectiousness or the average number of contacts.

In this work, we use stochastic simulations to investigate the consequences of a populations heterogeneity regarding connectivity and individual viral load levels.

Therefore, we translate a COVID-19 ODE model to a stochastic multi-agent system. We use contact networks to model complex interaction structures and a probabilistic infection rate to model individual viral load variation.

We observe a large dependency of the dispersion and dynamical evolution on the populations heterogeneity that is not adequately captured by point estimates, for instance, used in ODE models. In particular, models that assume the same clinical and transmission parameters may lead to different conclusions, depending on different types of heterogeneity in the population. For instance, the existence of hubs in the contact network leads to an initial increase of dispersion and the effective reproduction number, but to a lower herd immunity threshold (HIT) compared to homogeneous populations or a population where the heterogeneity stems solely from individual infectivity variations.

Author summaryComputational modeling can support decision-making in the face of pandemics like COVID-19. Models help to understand transmission data and predict important epidemiological properties (e.g., When will herd immunity be reached?). They can also examine the effectiveness of certain measures, and--to a limited extent--extrapolate the dynamics under specific assumptions. In all these cases, the heterogeneity of the population plays an important role. For instance, it is known that connectivity differences in (and among) age groups influence the dynamics of epidemic propagation. Here we focus on two types of differences among individuals: their social interactions and on how infectious they are. We show that only considering population averages (e.g., What is the average number of contacts of an individual?) may lead to misleading conclusions, because the individual differences (such as those related to the epidemic (over-)dispersion) play an important role in shaping the epidemic dynamics. Many commonly used model classes, such as SEIR-type ODE compartmental models, ignore differences within a population to a large extent. This omission bears the potential of misleading conclusions.",10.1101/2021.03.25.21254292,virology-agentic-ai.xlsx,"Why ODE models for COVID-19 fail: Heterogeneity shapes epidemic dynamics In the recent COVID-19 pandemic, mathematical modeling constitutes an important tool to evaluate the prospective effectiveness of non-pharmaceutical interventions (NPIs) and to guide policy-making. Most research is, however, centered around characterizing the epidemic based on point estimates like the average infectiousness or the average number of contacts.

In this work, we use stochastic simulations to investigate the consequences of a populations heterogeneity regarding connectivity and individual viral load levels.

Therefore, we translate a COVID-19 ODE model to a stochastic multi-agent system. We use contact networks to model complex interaction structures and a probabilistic infection rate to model individual viral load variation.

We observe a large dependency of the dispersion and dynamical evolution on the populations heterogeneity that is not adequately captured by point estimates, for instance, used in ODE models. In particular, models that assume the same clinical and transmission parameters may lead to different conclusions, depending on different types of heterogeneity in the population. For instance, the existence of hubs in the contact network leads to an initial increase of dispersion and the effective reproduction number, but to a lower herd immunity threshold (HIT) compared to homogeneous populations or a population where the heterogeneity stems solely from individual infectivity variations.

Author summaryComputational modeling can support decision-making in the face of pandemics like COVID-19. Models help to understand transmission data and predict important epidemiological properties (e.g., When will herd immunity be reached?). They can also examine the effectiveness of certain measures, and--to a limited extent--extrapolate the dynamics under specific assumptions. In all these cases, the heterogeneity of the population plays an important role. For instance, it is known that connectivity differences in (and among) age groups influence the dynamics of epidemic propagation. Here we focus on two types of differences among individuals: their social interactions and on how infectious they are. We show that only considering population averages (e.g., What is the average number of contacts of an individual?) may lead to misleading conclusions, because the individual differences (such as those related to the epidemic (over-)dispersion) play an important role in shaping the epidemic dynamics. Many commonly used model classes, such as SEIR-type ODE compartmental models, ignore differences within a population to a large extent. This omission bears the potential of misleading conclusions.",1
"Scott, A. M.; Forbes, C.; Clark, J.; Carter, M.; Glasziou, P.; Munn, Z.",2021,"Systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developers: tools used, abandoned, and desired",Epidemiology,"Systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developers: tools used, abandoned, and desired","Scott, A. M.; Forbes, C.; Clark, J.; Carter, M.; Glasziou, P.; Munn, Z.",Epidemiology,2021-04-30 00:00:00 UTC,"ObjectiveWe investigated the use of systematic review automation tools by systematic reviewers, health technology assessors and clinical guideline developers.

Study design and settingsAn online, 16-question survey was distributed across several evidence synthesis, health technology assessment and guideline development organisations internationally. We asked the respondents what tools they use and abandon, how often and when they use the tools, their perceived time savings and accuracy, and desired new tools. Descriptive statistics were used to report the results.

Results253 respondents completed the survey; 89% have used systematic review automation tools - most frequently whilst screening (79%). Respondents  top 3 tools include: Covidence (45%), RevMan (35%), Rayyan and GRADEPro (both 22%); most commonly abandoned were Rayyan (19%), Covidence (15%), DistillerSR (14%) and RevMan (13%). Majority thought tools saved time (80%) and increased accuracy (54%). Respondents taught themselves to how to use the tools (72%), and were most often prevented by lack of knowledge from their adoption (51%). Most new tool development was suggested for the searching and data extraction stages.

ConclusionAutomation tools are likely to take on an increasingly important role in high quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews.",10.1101/2021.04.26.21255833,virology-agentic-ai.xlsx,"Systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developers: tools used, abandoned, and desired ObjectiveWe investigated the use of systematic review automation tools by systematic reviewers, health technology assessors and clinical guideline developers.

Study design and settingsAn online, 16-question survey was distributed across several evidence synthesis, health technology assessment and guideline development organisations internationally. We asked the respondents what tools they use and abandon, how often and when they use the tools, their perceived time savings and accuracy, and desired new tools. Descriptive statistics were used to report the results.

Results253 respondents completed the survey; 89% have used systematic review automation tools - most frequently whilst screening (79%). Respondents  top 3 tools include: Covidence (45%), RevMan (35%), Rayyan and GRADEPro (both 22%); most commonly abandoned were Rayyan (19%), Covidence (15%), DistillerSR (14%) and RevMan (13%). Majority thought tools saved time (80%) and increased accuracy (54%). Respondents taught themselves to how to use the tools (72%), and were most often prevented by lack of knowledge from their adoption (51%). Most new tool development was suggested for the searching and data extraction stages.

ConclusionAutomation tools are likely to take on an increasingly important role in high quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews.",1
"Berger, D. O.; Pedersen, E. S. L.; Mallet, M. C.; De Jong, C. C. M.; Usemann, J.; Regamey, N.; Spycher, B.; Ardura-Garcia, C.; Kuehni, C. E.",2022,External Validation of the Predicting Asthma Risk in Children (PARC) tool in a clinical cohort,Epidemiology,External Validation of the Predicting Asthma Risk in Children (PARC) tool in a clinical cohort,"Berger, D. O.; Pedersen, E. S. L.; Mallet, M. C.; De Jong, C. C. M.; Usemann, J.; Regamey, N.; Spycher, B.; Ardura-Garcia, C.; Kuehni, C. E.",Epidemiology,2022-03-30 00:00:00 UTC,"RationaleThe Predicting Asthma Risk in Children (PARC) tool uses questionnaire-based respiratory symptoms collected from preschool children to predict their risk of asthma 5 years later. The tool was originally developed and externally validated in population-based settings and has not yet been validated in a clinical setting.

ObjectiveTo externally validate the PARC tool in children seen in paediatric pulmonology clinics.

MethodsThe Swiss Paediatric Airway Cohort (SPAC) is a prospective study of children seen in respiratory outpatient clinics across Switzerland. This analysis included children seen at ages 1-6 years for cough or wheeze at baseline and who completed the follow-up questionnaire 2 years later. The outcome was defined as current wheeze plus use of asthma medication. In sensitivity analyses, we explored effects of varied inclusion criteria and outcomes. We assessed performance by describing sensitivity, specificity, negative and positive predictive value (NPV, PPV), area under the curve (AUC), scaled Briers score and Nagelkerkes R2 scores and compared performance in SPAC to that achieved in the original population, the Leicester Respiratory Cohort (LRC).

ResultsAmong the 346 children included, 125 (36%) reported the outcome after 2 years. At a PARC score cut-off of 4, sensitivity was higher (95% vs 79%) but specificity lower (14% vs 57%) in SPAC compared to LRC. NPV was comparable (0.84 vs. 0.87) as was PPV (0.37 vs.0.42). Discrimination was lower in SPAC (AUC of 0.71 vs 0.78), as were Nagelkerkes R2 (0.18 vs 0.28) and scaled Briers scores (0.13 vs 0.22). When the outcome was changed to moderately severe asthma (>4 attacks plus use of asthma medication), there were improvements in AUC (0.74), sensitivity (0.97), specificity (0.22) and NPV (0.99), but some deterioration in PPV (0.13), R2 (0.15) and scaled Brier score (0.09).

ConclusionWhile the PARC tool performs well in a population-based setting and has some clinical utility, in particular for ruling out the development of asthma, this study highlights the need for new prognostic prediction tools to be developed specifically for the clinical setting.

FundingSNSF:320030_182628, SLA2019-03_641670",10.1101/2022.03.28.22273062,virology-agentic-ai.xlsx,"External Validation of the Predicting Asthma Risk in Children (PARC) tool in a clinical cohort RationaleThe Predicting Asthma Risk in Children (PARC) tool uses questionnaire-based respiratory symptoms collected from preschool children to predict their risk of asthma 5 years later. The tool was originally developed and externally validated in population-based settings and has not yet been validated in a clinical setting.

ObjectiveTo externally validate the PARC tool in children seen in paediatric pulmonology clinics.

MethodsThe Swiss Paediatric Airway Cohort (SPAC) is a prospective study of children seen in respiratory outpatient clinics across Switzerland. This analysis included children seen at ages 1-6 years for cough or wheeze at baseline and who completed the follow-up questionnaire 2 years later. The outcome was defined as current wheeze plus use of asthma medication. In sensitivity analyses, we explored effects of varied inclusion criteria and outcomes. We assessed performance by describing sensitivity, specificity, negative and positive predictive value (NPV, PPV), area under the curve (AUC), scaled Briers score and Nagelkerkes R2 scores and compared performance in SPAC to that achieved in the original population, the Leicester Respiratory Cohort (LRC).

ResultsAmong the 346 children included, 125 (36%) reported the outcome after 2 years. At a PARC score cut-off of 4, sensitivity was higher (95% vs 79%) but specificity lower (14% vs 57%) in SPAC compared to LRC. NPV was comparable (0.84 vs. 0.87) as was PPV (0.37 vs.0.42). Discrimination was lower in SPAC (AUC of 0.71 vs 0.78), as were Nagelkerkes R2 (0.18 vs 0.28) and scaled Briers scores (0.13 vs 0.22). When the outcome was changed to moderately severe asthma (>4 attacks plus use of asthma medication), there were improvements in AUC (0.74), sensitivity (0.97), specificity (0.22) and NPV (0.99), but some deterioration in PPV (0.13), R2 (0.15) and scaled Brier score (0.09).

ConclusionWhile the PARC tool performs well in a population-based setting and has some clinical utility, in particular for ruling out the development of asthma, this study highlights the need for new prognostic prediction tools to be developed specifically for the clinical setting.

FundingSNSF:320030_182628, SLA2019-03_641670",1
"Li, Y.; Chen, M.; George, J.; Liu, E. T.; Karuturi, R. K. M.",2022,Adaptive sentinel testing in workplace for COVID-19 pandemic,Epidemiology,Adaptive sentinel testing in workplace for COVID-19 pandemic,"Li, Y.; Chen, M.; George, J.; Liu, E. T.; Karuturi, R. K. M.",Epidemiology,2022-07-19 00:00:00 UTC,"Testing and isolation of infectious employees is one of the critical strategies to make the workplace safe during the pandemic for many organizations. Adaptive testing frequency reduces cost while keeping the pandemic under control at the workplace. However, most models aimed at estimating test frequencies were structured for municipalities or large organizations such as university campuses of highly mobile individuals. By contrast, the workplace exhibits distinct characteristics: employee positivity rate may be different from the local community because of rigorous protective measures at workplace, or self-selection of co-workers with common behavioral tendencies for adherence to pandemic mitigation guidelines. Moreover, dual exposure to COVID19 occurs at work and home that complicates transmission modelling, as does transmission tracing at the workplace. Hence, we developed bi-modal SEIR model and R-shiny tool that accounts for these differentiating factors to adaptively estimate the testing frequency for workplace. Our tool uses easily measurable parameters: community incidence rate, risks of acquiring infection from community and work-place, workforce size, and sensitivity of testing. Our model is best suited for moderate-sized organizations with low internal transmission rates, no-outward facing employees whose position demands frequent in-person interactions with the public, and low to medium population positivity rates. Simulations revealed that employee behavior in adherence to protective measures at work and in their community, and the onsite workforce size have large effects on testing frequency. Reducing workplace transmission rate through workplace mitigation protocols and higher sensitivity of the test deployed, though to a lesser extent. Furthermore, our simulations showed that sentinel testing leads to only marginal increase in the number of infections even for high community incidence rates, suggesting that this may be a cost-effective approach in future pandemics. We used our model to accurately guide testing regimen for three campuses of The Jackson Laboratory.",10.1101/2022.07.18.22277434,virology-agentic-ai.xlsx,"Adaptive sentinel testing in workplace for COVID-19 pandemic Testing and isolation of infectious employees is one of the critical strategies to make the workplace safe during the pandemic for many organizations. Adaptive testing frequency reduces cost while keeping the pandemic under control at the workplace. However, most models aimed at estimating test frequencies were structured for municipalities or large organizations such as university campuses of highly mobile individuals. By contrast, the workplace exhibits distinct characteristics: employee positivity rate may be different from the local community because of rigorous protective measures at workplace, or self-selection of co-workers with common behavioral tendencies for adherence to pandemic mitigation guidelines. Moreover, dual exposure to COVID19 occurs at work and home that complicates transmission modelling, as does transmission tracing at the workplace. Hence, we developed bi-modal SEIR model and R-shiny tool that accounts for these differentiating factors to adaptively estimate the testing frequency for workplace. Our tool uses easily measurable parameters: community incidence rate, risks of acquiring infection from community and work-place, workforce size, and sensitivity of testing. Our model is best suited for moderate-sized organizations with low internal transmission rates, no-outward facing employees whose position demands frequent in-person interactions with the public, and low to medium population positivity rates. Simulations revealed that employee behavior in adherence to protective measures at work and in their community, and the onsite workforce size have large effects on testing frequency. Reducing workplace transmission rate through workplace mitigation protocols and higher sensitivity of the test deployed, though to a lesser extent. Furthermore, our simulations showed that sentinel testing leads to only marginal increase in the number of infections even for high community incidence rates, suggesting that this may be a cost-effective approach in future pandemics. We used our model to accurately guide testing regimen for three campuses of The Jackson Laboratory.",1
"Chen, W.-M.; Fu, M.; Zhang, C.-J.; Xing, Q.-Q.; Zhou, F.; Lin, M.-J.; Dong, X.; Zheng, Q.-Z.; Hong, M.-Z.; Pan, J.-S.",2020,Deep Learning-Based Universal Expert-Level Recognizing Pathological Images of Hepatocellular Carcinoma and beyond,Pathology,Deep Learning-Based Universal Expert-Level Recognizing Pathological Images of Hepatocellular Carcinoma and beyond,"Chen, W.-M.; Fu, M.; Zhang, C.-J.; Xing, Q.-Q.; Zhou, F.; Lin, M.-J.; Dong, X.; Zheng, Q.-Z.; Hong, M.-Z.; Pan, J.-S.",Pathology,2020-04-05 00:00:00 UTC,"PurposeHuman-based medical-image interpretation always falls into the predicament between specialized practitioners and expanding medical imaging. We aim at developing a diagnostic tool for pathological-image classification by using transfer learning that can be applied to diverse tumor types.

Experimental DesignIn this study, images were retrospectively collected and prospectively analyzed using machine learning. Microscopic images of liver tissue that show or do not show hepatocellular carcinoma were used to train and validate a classification framework based on convolutional neural network. To evaluate the universal classification performance of the artificial-intelligence (AI) framework, histological images from colorectal tissue and breast were also collected. Training and validation set of images were collected from Xiamen Hospital of Traditional Chinese Medicine whereas test set of images were collected from Zhongshan Hospital Xiamen University.

ResultsAccuracy, sensitivity, and specificity were reported and compared to human image interpretation and other AI image classification systems such as AlexNet and GoogLeNet. For the test dataset, sensitivity, specificity, and area under the curve of the AI framework were 99.1%, 98.0%, and 0.960, respectively. In human-machine comparisons, the accuracy of the AI framework was 98.5%, while the accuracy of human experts fluctuated between 93.0% and 95.0%. Based on transfer learning, the AI framework accuracy for colorectal carcinoma, breast invasive ductal carcinoma, were 96.8%, and 96.0%, respectively.

ConclusionsThe performance of the proposed AI framework in classifying histological images with hepatocellular carcinoma is comparable to the classification by human experts. With limited training, the proposed AI framework has potential universality in histological image classification.

Study Highlights O_TEXTBOXWHAT IS KNOWN{checkmark} Accurate recognition of medical images is the basis for clinical decision-making.
{checkmark}Unresolved challenge exists between specialized practitioners and expanding medical imaging output.


WHAT IS NEW HERE{checkmark} Proposed AI framework has excellent performance in classifying hepatocellular carcinoma.
{checkmark}The AI framework has universal feature in classifying other types of histological images.
{checkmark}The AI framework may help to interpret emerging imaging technology.


C_TEXTBOX",10.1101/2020.03.22.20041178,virology-computer-vision.xlsx,"Deep Learning-Based Universal Expert-Level Recognizing Pathological Images of Hepatocellular Carcinoma and beyond PurposeHuman-based medical-image interpretation always falls into the predicament between specialized practitioners and expanding medical imaging. We aim at developing a diagnostic tool for pathological-image classification by using transfer learning that can be applied to diverse tumor types.

Experimental DesignIn this study, images were retrospectively collected and prospectively analyzed using machine learning. Microscopic images of liver tissue that show or do not show hepatocellular carcinoma were used to train and validate a classification framework based on convolutional neural network. To evaluate the universal classification performance of the artificial-intelligence (AI) framework, histological images from colorectal tissue and breast were also collected. Training and validation set of images were collected from Xiamen Hospital of Traditional Chinese Medicine whereas test set of images were collected from Zhongshan Hospital Xiamen University.

ResultsAccuracy, sensitivity, and specificity were reported and compared to human image interpretation and other AI image classification systems such as AlexNet and GoogLeNet. For the test dataset, sensitivity, specificity, and area under the curve of the AI framework were 99.1%, 98.0%, and 0.960, respectively. In human-machine comparisons, the accuracy of the AI framework was 98.5%, while the accuracy of human experts fluctuated between 93.0% and 95.0%. Based on transfer learning, the AI framework accuracy for colorectal carcinoma, breast invasive ductal carcinoma, were 96.8%, and 96.0%, respectively.

ConclusionsThe performance of the proposed AI framework in classifying histological images with hepatocellular carcinoma is comparable to the classification by human experts. With limited training, the proposed AI framework has potential universality in histological image classification.

Study Highlights O_TEXTBOXWHAT IS KNOWN{checkmark} Accurate recognition of medical images is the basis for clinical decision-making.
{checkmark}Unresolved challenge exists between specialized practitioners and expanding medical imaging output.


WHAT IS NEW HERE{checkmark} Proposed AI framework has excellent performance in classifying hepatocellular carcinoma.
{checkmark}The AI framework has universal feature in classifying other types of histological images.
{checkmark}The AI framework may help to interpret emerging imaging technology.


C_TEXTBOX",0
"Amyar, A.; Modzelewski, R.; Ruan, S.",2020,Multi-task Deep Learning Based CT Imaging Analysis For COVID-19: Classification and Segmentation,Epidemiology,Multi-task Deep Learning Based CT Imaging Analysis For COVID-19: Classification and Segmentation,"Amyar, A.; Modzelewski, R.; Ruan, S.",Epidemiology,2020-04-21 00:00:00 UTC,"The fast spreading of the novel coronavirus COVID-19 has aroused worldwide interest and concern, and caused more than one million and a half confirmed cases to date. To combat this spread, medical imaging such as computed tomography (CT) images can be used for diagnostic. An automatic detection tools is necessary for helping screening COVID-19 pneumonia using chest CT imaging. In this work, we propose a multitask deep learning model to jointly identify COVID-19 patient and segment COVID-19 lesion from chest CT images. Our motivation is to leverage useful information contained in multiple related tasks to help improve both segmentation and classification performances. Our architecture is composed by an encoder and two decoders for reconstruction and segmentation, and a multi-layer perceptron for classification. The proposed model is evaluated and compared with other image segmentation and classification techniques using a dataset of 1044 patients including 449 patients with COVID-19, 100 normal ones, 98 with lung cancer and 397 of different kinds of pathology. The obtained results show very encouraging performance of our method with a dice coefficient higher than 0.78 for the segmentation and an area under the ROC curve higher than 93% for the classification.",10.1101/2020.04.16.20064709,virology-computer-vision.xlsx,"Multi-task Deep Learning Based CT Imaging Analysis For COVID-19: Classification and Segmentation The fast spreading of the novel coronavirus COVID-19 has aroused worldwide interest and concern, and caused more than one million and a half confirmed cases to date. To combat this spread, medical imaging such as computed tomography (CT) images can be used for diagnostic. An automatic detection tools is necessary for helping screening COVID-19 pneumonia using chest CT imaging. In this work, we propose a multitask deep learning model to jointly identify COVID-19 patient and segment COVID-19 lesion from chest CT images. Our motivation is to leverage useful information contained in multiple related tasks to help improve both segmentation and classification performances. Our architecture is composed by an encoder and two decoders for reconstruction and segmentation, and a multi-layer perceptron for classification. The proposed model is evaluated and compared with other image segmentation and classification techniques using a dataset of 1044 patients including 449 patients with COVID-19, 100 normal ones, 98 with lung cancer and 397 of different kinds of pathology. The obtained results show very encouraging performance of our method with a dice coefficient higher than 0.78 for the segmentation and an area under the ROC curve higher than 93% for the classification.",1
"Karatzas, P.; Kiouvrekis, Y.; Sarimveis, H.; Stefaneas, P.",2020,An approach for predicting the effects of endocrine disrupting chemicals on human health using deep learning,Epidemiology,An approach for predicting the effects of endocrine disrupting chemicals on human health using deep learning,"Karatzas, P.; Kiouvrekis, Y.; Sarimveis, H.; Stefaneas, P.",Epidemiology,2020-08-16 00:00:00 UTC,"In recent years, deep neural networks, especially those exhibiting synergistic properties, have been at the cutting edge of image processing, producing very good results. So far, they have been able to successfully address issues of classification and recognition of objects depicted on images. In this paper, a novel idea is presented, where images of chemical structures are used as input information in deep learning neural network architectures aiming at the generation of Quantitative Structure Activity Relationship (QSAR) models, i.e. models that predict properties, activities or adverse effects of chemicals. The proposed method was applied to a case study of particular interest, which is the prediction of endocrine disrupting potential of chemicals. Two different deep learning architectures were applied. The produced ImageNet model proved successful, in terms of accuracy, performance and robustness on training and validation sets. The new approach is proposed to the community as an alternative or complementary method to current practices in QSAR modelling, which can automate and improve the creation of predictive models.",10.1101/2020.08.05.20168419,virology-computer-vision.xlsx,"An approach for predicting the effects of endocrine disrupting chemicals on human health using deep learning In recent years, deep neural networks, especially those exhibiting synergistic properties, have been at the cutting edge of image processing, producing very good results. So far, they have been able to successfully address issues of classification and recognition of objects depicted on images. In this paper, a novel idea is presented, where images of chemical structures are used as input information in deep learning neural network architectures aiming at the generation of Quantitative Structure Activity Relationship (QSAR) models, i.e. models that predict properties, activities or adverse effects of chemicals. The proposed method was applied to a case study of particular interest, which is the prediction of endocrine disrupting potential of chemicals. Two different deep learning architectures were applied. The produced ImageNet model proved successful, in terms of accuracy, performance and robustness on training and validation sets. The new approach is proposed to the community as an alternative or complementary method to current practices in QSAR modelling, which can automate and improve the creation of predictive models.",0
"Flotho, P.; Bhamborae, M.; Grun, T.; Trenado, C.; Thinnes, D.; Limbach, D.; Strauss, D. J.",2020,"Multimodal Data Acquisition at SARS-CoV-2 Drive Through Screening Centers: Setup Description and Experiences in Saarland, Germany",Epidemiology,"Multimodal Data Acquisition at SARS-CoV-2 Drive Through Screening Centers: Setup Description and Experiences in Saarland, Germany","Flotho, P.; Bhamborae, M.; Grun, T.; Trenado, C.; Thinnes, D.; Limbach, D.; Strauss, D. J.",Epidemiology,2020-12-11 00:00:00 UTC,"SARS-CoV-2 drive through screening centers (DTSC) have been implemented worldwide as a fast and secure way of mass screening. We use DTSCs as a platform for the acquisition of multimodal datasets that are needed for the development of remote screening methods. Our acquisition setup consists of an array of thermal, infrared and RGB cameras as well as microphones and we apply methods from computer vision and computer audition for the contactless estimation of physiological parameters. We have recorded a multimodal dataset of DTSC participants in Germany for the development of remote screening methods and symptom identification. Acquisition in the early stages of a pandemic and in regions with high infection rates can facilitate and speed up the identification of infection specific symptoms and large scale data acquisition at DTSC is possible without disturbing the flow of operation.",10.1101/2020.12.08.20240382,virology-computer-vision.xlsx,"Multimodal Data Acquisition at SARS-CoV-2 Drive Through Screening Centers: Setup Description and Experiences in Saarland, Germany SARS-CoV-2 drive through screening centers (DTSC) have been implemented worldwide as a fast and secure way of mass screening. We use DTSCs as a platform for the acquisition of multimodal datasets that are needed for the development of remote screening methods. Our acquisition setup consists of an array of thermal, infrared and RGB cameras as well as microphones and we apply methods from computer vision and computer audition for the contactless estimation of physiological parameters. We have recorded a multimodal dataset of DTSC participants in Germany for the development of remote screening methods and symptom identification. Acquisition in the early stages of a pandemic and in regions with high infection rates can facilitate and speed up the identification of infection specific symptoms and large scale data acquisition at DTSC is possible without disturbing the flow of operation.",1
"Simonson, P. D.; Ren, X.; Fromm, J. R.",2021,Creating virtual H&E images using samples imaged on a commercial CODEX platform,Pathology,Creating virtual H&E images using samples imaged on a commercial CODEX platform,"Simonson, P. D.; Ren, X.; Fromm, J. R.",Pathology,2021-02-08 00:00:00 UTC,"Multiparametric fluorescence imaging via CODEX allows the simultaneous imaging of many biomarkers in a single tissue section. While the digital fluorescence data thus obtained can provide highly specific characterizations of individual cells and microenvironments, the images obtained are different from those usually interpreted by pathologists (i.e., H&E slides and DAB-stained immunohistochemistry slides). Having the fluorescence data plus co-registered H&E or similar data could facilitate adoption of multiparametric imaging into regular workflows, as well as facilitate the transfer of algorithms and machine learning previous developed around H&E slides. Since commercial CODEX instruments do not produce H&E-like images by themselves, we developed a staining protocol and associated image processing to make ""virtual H&E"" images that can be incorporated into the CODEX workflow. While there are many ways to achieve virtual H&E images, including use of a fluorescent nuclear stain and tissue autofluorescence to simulate eosin staining, we opted to combine fluorescent nuclear staining (via DAPI) with actual eosin staining. We also output images derived from fluorescent nuclear staining and autofluorescence images for additional evaluation.",10.1101/2021.02.05.21249150,virology-computer-vision.xlsx,"Creating virtual H&E images using samples imaged on a commercial CODEX platform Multiparametric fluorescence imaging via CODEX allows the simultaneous imaging of many biomarkers in a single tissue section. While the digital fluorescence data thus obtained can provide highly specific characterizations of individual cells and microenvironments, the images obtained are different from those usually interpreted by pathologists (i.e., H&E slides and DAB-stained immunohistochemistry slides). Having the fluorescence data plus co-registered H&E or similar data could facilitate adoption of multiparametric imaging into regular workflows, as well as facilitate the transfer of algorithms and machine learning previous developed around H&E slides. Since commercial CODEX instruments do not produce H&E-like images by themselves, we developed a staining protocol and associated image processing to make ""virtual H&E"" images that can be incorporated into the CODEX workflow. While there are many ways to achieve virtual H&E images, including use of a fluorescent nuclear stain and tissue autofluorescence to simulate eosin staining, we opted to combine fluorescent nuclear staining (via DAPI) with actual eosin staining. We also output images derived from fluorescent nuclear staining and autofluorescence images for additional evaluation.",0
"Durant, T. J.; Dudgeon, S. N.; Mcpadden, J.; Simpson, A.; Price, N.; Schulz, W. L.; Torres, R.; Olson, E.",2021,Applications of Digital Microscopy and Densely Connected Convolutional Neural Networks for Automated Quantitation of Babesia-Infected Erythrocytes,Pathology,Applications of Digital Microscopy and Densely Connected Convolutional Neural Networks for Automated Quantitation of Babesia-Infected Erythrocytes,"Durant, T. J.; Dudgeon, S. N.; Mcpadden, J.; Simpson, A.; Price, N.; Schulz, W. L.; Torres, R.; Olson, E.",Pathology,2021-04-29 00:00:00 UTC,"BackgroundClinical babesiosis is diagnosed, and parasite burden is determined, by microscopic inspection of a thick or thin Giemsa-stained peripheral blood smear. However, quantitative analysis by manual microscopy is subject to observer bias, slide distribution errors, statistical sampling error, recording errors, and is inherently burdensome from time management and workflow efficiency standpoints. As such, methods for the automated measurement of percent parasitemia in digital microscopic images of peripheral blood smears could improve clinical accuracy, relative to the predicate method.

MethodsIndividual erythrocyte images (shape: 70x70x3) were manually labeled as ""parasite"" or ""normal"" and were used to train a model for binary image classification. The best model was then used to calculate percent parasitemia from a clinical validation dataset, and values were compared to a clinical reference value. Lastly, model interpretability was examined using an integrated gradient to identify pixels most likely to influence classification decisions.

ResultsThe precision and recall of the model during development testing were 0.92 and 1.00, respectively. In clinical validation, the model returned increasing positive signal with increasing mean reference value. However, there were two highly erroneous false positive values returned by the model. Lastly, the model incorrectly assessed three cases well above the clinical threshold of 10%. The integrated gradient suggested potential sources of false positives including rouleaux formations, cell boundaries, and precipitate as deterministic factors in negative erythrocyte images.

ConclusionsWhile the model demonstrated highly accurate single cell classification and correctly assessed most slides, several false positives were highly incorrect. This project highlights the need for integrated testing of ML-based models, even when models in the development phase perform well.",10.1101/2021.04.27.21256115,virology-computer-vision.xlsx,"Applications of Digital Microscopy and Densely Connected Convolutional Neural Networks for Automated Quantitation of Babesia-Infected Erythrocytes BackgroundClinical babesiosis is diagnosed, and parasite burden is determined, by microscopic inspection of a thick or thin Giemsa-stained peripheral blood smear. However, quantitative analysis by manual microscopy is subject to observer bias, slide distribution errors, statistical sampling error, recording errors, and is inherently burdensome from time management and workflow efficiency standpoints. As such, methods for the automated measurement of percent parasitemia in digital microscopic images of peripheral blood smears could improve clinical accuracy, relative to the predicate method.

MethodsIndividual erythrocyte images (shape: 70x70x3) were manually labeled as ""parasite"" or ""normal"" and were used to train a model for binary image classification. The best model was then used to calculate percent parasitemia from a clinical validation dataset, and values were compared to a clinical reference value. Lastly, model interpretability was examined using an integrated gradient to identify pixels most likely to influence classification decisions.

ResultsThe precision and recall of the model during development testing were 0.92 and 1.00, respectively. In clinical validation, the model returned increasing positive signal with increasing mean reference value. However, there were two highly erroneous false positive values returned by the model. Lastly, the model incorrectly assessed three cases well above the clinical threshold of 10%. The integrated gradient suggested potential sources of false positives including rouleaux formations, cell boundaries, and precipitate as deterministic factors in negative erythrocyte images.

ConclusionsWhile the model demonstrated highly accurate single cell classification and correctly assessed most slides, several false positives were highly incorrect. This project highlights the need for integrated testing of ML-based models, even when models in the development phase perform well.",1
"Kalia, R. K.; Sharma, A.; Amin, S. B.; Saha, M.; Thittamaranahalli, S. K.",2021,AI-DRIVEN QUANTIFICATION OF GROUND GLASS OPACITIES IN LUNGS OF COVID-19 PATIENTS USING 3D COMPUTED TOMOGRAPHY IMAGING,Epidemiology,AI-DRIVEN QUANTIFICATION OF GROUND GLASS OPACITIES IN LUNGS OF COVID-19 PATIENTS USING 3D COMPUTED TOMOGRAPHY IMAGING,"Kalia, R. K.; Sharma, A.; Amin, S. B.; Saha, M.; Thittamaranahalli, S. K.",Epidemiology,2021-07-08 00:00:00 UTC,"ObjectivesGround-glass opacity (GGO) -- a hazy, gray appearing density on computed tomography (CT) of lungs -- is one of the hallmark features of SARS-CoV-2 in COVID-19 patients. This AI-driven study is focused on segmentation, morphology, and distribution patterns of GGOs.

MethodWe use an AI-driven unsupervised machine learning approach called PointNet++ to detect and quantify GGOs in CT scans of COVID-19 patients and to assess the severity of the disease. We have conducted our study on the ""MosMedData"", which contains CT lung scans of 1110 patients with or without COVID-19 infections. We quantify the morphologies of GGOs using Minkowski tensors and compute the abnormality score of individual regions of segmented lung and GGOs.

ResultsPointNet++ detects GGOs with the highest evaluation accuracy (98%), average class accuracy (95%), and intersection over union (92%) using only a fraction of 3D data. On average, the shapes of GGOs in the COVID-19 datasets deviate from sphericity by 15% and anisotropies in GGOs are dominated by dipole and hexapole components. These anisotropies may help to quantitatively delineate GGOs of COVID-19 from other lung diseases.

ConclusionThe PointNet++ and the Minkowski tensor based morphological approach together with abnormality analysis will provide radiologists and clinicians with a valuable set of tools when interpreting CT lung scans of COVID-19 patients. Implementation would be particularly useful in countries severely devastated by COVID-19 such as India, where the number of cases has outstripped available resources creating delays or even breakdowns in patient care. This AI-driven approach synthesizes both the unique GGO distribution pattern and severity of the disease to allow for more efficient diagnosis, triaging and conservation of limited resources.

Key PointsOur approach to GGO analysis has four distinguishing features:

O_LIWe combine an unsupervised computer vision approach with convex hull and convex points algorithms to segment and preserve the actual structure of the lung.
C_LIO_LITo the best of our knowledge, we are the first group to use PointNet++ architecture for 3D visualization, segmentation, classification, and pattern analysis of GGOs.
C_LIO_LIWe make abnormality predictions using a deep network and Cox proportional hazards model using lung CT images of COVID-19 patients.
C_LIO_LIWe quantify the shapes and sizes of GGOs using Minkowski tensors to understand the morphological variations of GGOs within the COVID-19 cohort.
C_LI",10.1101/2021.07.06.21260109,virology-computer-vision.xlsx,"AI-DRIVEN QUANTIFICATION OF GROUND GLASS OPACITIES IN LUNGS OF COVID-19 PATIENTS USING 3D COMPUTED TOMOGRAPHY IMAGING ObjectivesGround-glass opacity (GGO) -- a hazy, gray appearing density on computed tomography (CT) of lungs -- is one of the hallmark features of SARS-CoV-2 in COVID-19 patients. This AI-driven study is focused on segmentation, morphology, and distribution patterns of GGOs.

MethodWe use an AI-driven unsupervised machine learning approach called PointNet++ to detect and quantify GGOs in CT scans of COVID-19 patients and to assess the severity of the disease. We have conducted our study on the ""MosMedData"", which contains CT lung scans of 1110 patients with or without COVID-19 infections. We quantify the morphologies of GGOs using Minkowski tensors and compute the abnormality score of individual regions of segmented lung and GGOs.

ResultsPointNet++ detects GGOs with the highest evaluation accuracy (98%), average class accuracy (95%), and intersection over union (92%) using only a fraction of 3D data. On average, the shapes of GGOs in the COVID-19 datasets deviate from sphericity by 15% and anisotropies in GGOs are dominated by dipole and hexapole components. These anisotropies may help to quantitatively delineate GGOs of COVID-19 from other lung diseases.

ConclusionThe PointNet++ and the Minkowski tensor based morphological approach together with abnormality analysis will provide radiologists and clinicians with a valuable set of tools when interpreting CT lung scans of COVID-19 patients. Implementation would be particularly useful in countries severely devastated by COVID-19 such as India, where the number of cases has outstripped available resources creating delays or even breakdowns in patient care. This AI-driven approach synthesizes both the unique GGO distribution pattern and severity of the disease to allow for more efficient diagnosis, triaging and conservation of limited resources.

Key PointsOur approach to GGO analysis has four distinguishing features:

O_LIWe combine an unsupervised computer vision approach with convex hull and convex points algorithms to segment and preserve the actual structure of the lung.
C_LIO_LITo the best of our knowledge, we are the first group to use PointNet++ architecture for 3D visualization, segmentation, classification, and pattern analysis of GGOs.
C_LIO_LIWe make abnormality predictions using a deep network and Cox proportional hazards model using lung CT images of COVID-19 patients.
C_LIO_LIWe quantify the shapes and sizes of GGOs using Minkowski tensors to understand the morphological variations of GGOs within the COVID-19 cohort.
C_LI",1
"Victoria Matias, A.; Cerentini, A.; Buschetto Macarini, L. A.; Atkinson Amorim, J. G.; Perozzo Daltoe, F.; Von Wangenheim, A.",2021,Comparison of Object Detection Approaches Applied to Field Images of Papanicolaou Stained Cytology Slides,Pathology,Comparison of Object Detection Approaches Applied to Field Images of Papanicolaou Stained Cytology Slides,"Victoria Matias, A.; Cerentini, A.; Buschetto Macarini, L. A.; Atkinson Amorim, J. G.; Perozzo Daltoe, F.; Von Wangenheim, A.",Pathology,2021-08-31 00:00:00 UTC,"Papanicolaou is an inexpensive and non-invasive method, generally applied to detect cervical cancer, that can also be useful to detect cancer on oral cavities. Although oral cancer is considered a global health issue with 350.000 people diagnosed over a year it can successfully be treated if diagnosed at early stages. The manual process of analyzing cells to detect abnormalities is time-consuming and subject to variations in perceptions from different professionals. To evaluate a possible solution to the automation of this process, in this paper we employ the object detection deep learning approach in the analysis of this type of image using 3 models: RetinaNet, Faster R-CNN, and Mask R-CNN. We trained and tested the models using images from 6 cytology slides (4 cancer cases and 2 healthy samples) and our results show that Mask R-CNN was the best model for localization and classification of nuclei with an IoU of 0.51 and recall of abnormal nuclei of 0.67.",10.1101/2021.08.25.21262605,virology-computer-vision.xlsx,"Comparison of Object Detection Approaches Applied to Field Images of Papanicolaou Stained Cytology Slides Papanicolaou is an inexpensive and non-invasive method, generally applied to detect cervical cancer, that can also be useful to detect cancer on oral cavities. Although oral cancer is considered a global health issue with 350.000 people diagnosed over a year it can successfully be treated if diagnosed at early stages. The manual process of analyzing cells to detect abnormalities is time-consuming and subject to variations in perceptions from different professionals. To evaluate a possible solution to the automation of this process, in this paper we employ the object detection deep learning approach in the analysis of this type of image using 3 models: RetinaNet, Faster R-CNN, and Mask R-CNN. We trained and tested the models using images from 6 cytology slides (4 cancer cases and 2 healthy samples) and our results show that Mask R-CNN was the best model for localization and classification of nuclei with an IoU of 0.51 and recall of abnormal nuclei of 0.67.",0
"Tomita, N.; Tafe, L. J.; Suriawinata, A. A.; Tsongalis, G. J.; Nasir-Moin, M.; Dragnev, K.; Hassanpour, S.",2022,Predicting Oncogene Mutations of Lung Cancer Using Deep Learning and Histopathologic Features on Whole-Slide Images,Pathology,Predicting Oncogene Mutations of Lung Cancer Using Deep Learning and Histopathologic Features on Whole-Slide Images,"Tomita, N.; Tafe, L. J.; Suriawinata, A. A.; Tsongalis, G. J.; Nasir-Moin, M.; Dragnev, K.; Hassanpour, S.",Pathology,2022-05-05 00:00:00 UTC,"Lung cancer is a leading cause of death in both men and women globally. The recent development of tumor molecular profiling has opened opportunities for targeted therapies for lung adenocarcinoma (LUAD) patients. However, the lack of access to molecular profiling or cost and turnaround time associated with it could hinder oncologists willingness to order frequent molecular tests, limiting potential benefits from precision medicine. In this study, we developed a weakly supervised deep learning model for predicting somatic mutations of LUAD patients based on formalin-fixed paraffin-embedded (FFPE) whole-slide images (WSIs) using LUAD subtypes-related histological features and recent advances in computer vision. Our study was performed on a total of 747 hematoxylin and eosin (H&E) stained FFPE LUAD WSIs and the genetic mutation data of 232 patients who were treated at Dartmouth-Hitchcock Medical Center (DHMC). We developed our convolutional neural network-based models on 172 training cases and tested on 60 independent cases to analyze whole slides and predict five major genetic mutations, i.e., BRAF, EGFR, KRAS, STK11, and TP53. We additionally used 111 cases from the LUAD dataset of the CPTAC-3 study for external validation. Our model achieved an AUROC of 0.799 (95% CI: 0.686-0.904) and 0.686 (95% CI: 0.620-0.752) for predicting EGFR genetic mutations on the DHMC and CPTAC-3 test sets, respectively. Predicting TP53 genetic mutations also showed promising outcomes. Our results demonstrated that H&E stained FFPE LUAD whole slides could be utilized to predict oncogene mutations, such as EGFR, indicating that somatic mutations could present subtle morphological characteristics in histology slides, where deep learning-based feature extractors can learn such latent information.",10.1101/2022.05.03.22274614,virology-computer-vision.xlsx,"Predicting Oncogene Mutations of Lung Cancer Using Deep Learning and Histopathologic Features on Whole-Slide Images Lung cancer is a leading cause of death in both men and women globally. The recent development of tumor molecular profiling has opened opportunities for targeted therapies for lung adenocarcinoma (LUAD) patients. However, the lack of access to molecular profiling or cost and turnaround time associated with it could hinder oncologists willingness to order frequent molecular tests, limiting potential benefits from precision medicine. In this study, we developed a weakly supervised deep learning model for predicting somatic mutations of LUAD patients based on formalin-fixed paraffin-embedded (FFPE) whole-slide images (WSIs) using LUAD subtypes-related histological features and recent advances in computer vision. Our study was performed on a total of 747 hematoxylin and eosin (H&E) stained FFPE LUAD WSIs and the genetic mutation data of 232 patients who were treated at Dartmouth-Hitchcock Medical Center (DHMC). We developed our convolutional neural network-based models on 172 training cases and tested on 60 independent cases to analyze whole slides and predict five major genetic mutations, i.e., BRAF, EGFR, KRAS, STK11, and TP53. We additionally used 111 cases from the LUAD dataset of the CPTAC-3 study for external validation. Our model achieved an AUROC of 0.799 (95% CI: 0.686-0.904) and 0.686 (95% CI: 0.620-0.752) for predicting EGFR genetic mutations on the DHMC and CPTAC-3 test sets, respectively. Predicting TP53 genetic mutations also showed promising outcomes. Our results demonstrated that H&E stained FFPE LUAD whole slides could be utilized to predict oncogene mutations, such as EGFR, indicating that somatic mutations could present subtle morphological characteristics in histology slides, where deep learning-based feature extractors can learn such latent information.",0
"Vilar, J.; Saiz, L.",2022,Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series,Epidemiology,Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series,"Vilar, J.; Saiz, L.",Epidemiology,2022-09-17 00:00:00 UTC,"Inferring the timing and amplitude of perturbations in epidemiological systems from their stochastically spread low-resolution outcomes is as relevant as challenging. It is a requirement for current approaches to overcome the need to know the details of the perturbations to proceed with the analyses. However, the general problem of connecting epidemiological curves with the underlying incidence lacks the highly effective methodology present in other inverse problems, such as super-resolution and dehazing from computer vision. Here, we develop an unsupervised physics-informed convolutional neural network approach in reverse to connect death records with incidence that allows the identification of regime changes at single-day resolution. Applied to COVID-19 data with proper regularization and model-selection criteria, the approach can identify the implementation and removal of lockdowns and other nonpharmaceutical interventions with 0.93-day accuracy over the time span of a year.",10.1101/2022.09.14.22279935,virology-computer-vision.xlsx,"Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series Inferring the timing and amplitude of perturbations in epidemiological systems from their stochastically spread low-resolution outcomes is as relevant as challenging. It is a requirement for current approaches to overcome the need to know the details of the perturbations to proceed with the analyses. However, the general problem of connecting epidemiological curves with the underlying incidence lacks the highly effective methodology present in other inverse problems, such as super-resolution and dehazing from computer vision. Here, we develop an unsupervised physics-informed convolutional neural network approach in reverse to connect death records with incidence that allows the identification of regime changes at single-day resolution. Applied to COVID-19 data with proper regularization and model-selection criteria, the approach can identify the implementation and removal of lockdowns and other nonpharmaceutical interventions with 0.93-day accuracy over the time span of a year.",1
"Ramachandra, V.",2023,Histopathology: Deep machine learning based semantic segmentation features predict patient survival,Pathology,Histopathology: Deep machine learning based semantic segmentation features predict patient survival,"Ramachandra, V.",Pathology,2023-01-14 00:00:00 UTC,"In this paper, we use deep learning techniques to segment different regions from breast cancer histopathology images, such as tumor nucleus, epithelium and stromal areas. Then, in the second stage, the deep segmentation features learned by the neural network are used to predict individual patient survival, using random forest based classification. We show that the deep segmentation network features can predict survival very well, and outperform classical computer vision based shape, texture and other feature descriptors used in earlier research for the same survival prediction task.",10.1101/2023.01.14.23284554,virology-computer-vision.xlsx,"Histopathology: Deep machine learning based semantic segmentation features predict patient survival In this paper, we use deep learning techniques to segment different regions from breast cancer histopathology images, such as tumor nucleus, epithelium and stromal areas. Then, in the second stage, the deep segmentation features learned by the neural network are used to predict individual patient survival, using random forest based classification. We show that the deep segmentation network features can predict survival very well, and outperform classical computer vision based shape, texture and other feature descriptors used in earlier research for the same survival prediction task.",0
"Gu, Q.; Prodduturi, N.; Hart, S. N.",2023,Deep Learning in Automating Breast Cancer Diagnosis from Microscopy Images,Pathology,Deep Learning in Automating Breast Cancer Diagnosis from Microscopy Images,"Gu, Q.; Prodduturi, N.; Hart, S. N.",Pathology,2023-06-16 00:00:00 UTC,"ContextBreast cancer is one of the most common cancers in women. With early diagnosis, some breast cancers are highly curable. However, the concordance rate of breast cancer diagnosis from histology slides by pathologists is unacceptably low. Classifying normal versus tumor breast tissues from microscopy images of breast histology is an ideal case to use for deep learning and could help to more reproducibly diagnose breast cancer. Since data preprocessing and hyperparameter configurations have impacts on breast cancer classification accuracies of deep learning models, training a deep learning classifier with appropriate data preprocessing approaches and optimized hyperparameter configurations could improve breast cancer classification accuracy.

Methods and MaterialUsing 12 combinations of deep learning model architectures (i.e., including 5 non-specialized and 7 digital pathology-specialized model architectures), image data preprocessing, and hyperparameter configurations, the validation accuracy of tumor versus normal classification were calculated using the BreAst Cancer Histology (BACH) dataset.

ResultsThe DenseNet201, a non-specialized model architecture, with transfer learning approach achieved 98.61% validation accuracy compared to only 64.00% for the digital pathology-specialized model architecture.

ConclusionsThe combination of image data preprocessing approaches and hyperparameter configurations have a profound impact on the performance of deep neural networks for image classification. To identify a well-performing deep neural network to classify tumor versus normal breast histology, researchers should not only focus on developing new models specifically for digital pathology, since hyperparameter tuning for existing deep neural networks in the computer vision field could also achieve a high (often better) prediction accuracy.",10.1101/2023.06.15.23291437,virology-computer-vision.xlsx,"Deep Learning in Automating Breast Cancer Diagnosis from Microscopy Images ContextBreast cancer is one of the most common cancers in women. With early diagnosis, some breast cancers are highly curable. However, the concordance rate of breast cancer diagnosis from histology slides by pathologists is unacceptably low. Classifying normal versus tumor breast tissues from microscopy images of breast histology is an ideal case to use for deep learning and could help to more reproducibly diagnose breast cancer. Since data preprocessing and hyperparameter configurations have impacts on breast cancer classification accuracies of deep learning models, training a deep learning classifier with appropriate data preprocessing approaches and optimized hyperparameter configurations could improve breast cancer classification accuracy.

Methods and MaterialUsing 12 combinations of deep learning model architectures (i.e., including 5 non-specialized and 7 digital pathology-specialized model architectures), image data preprocessing, and hyperparameter configurations, the validation accuracy of tumor versus normal classification were calculated using the BreAst Cancer Histology (BACH) dataset.

ResultsThe DenseNet201, a non-specialized model architecture, with transfer learning approach achieved 98.61% validation accuracy compared to only 64.00% for the digital pathology-specialized model architecture.

ConclusionsThe combination of image data preprocessing approaches and hyperparameter configurations have a profound impact on the performance of deep neural networks for image classification. To identify a well-performing deep neural network to classify tumor versus normal breast histology, researchers should not only focus on developing new models specifically for digital pathology, since hyperparameter tuning for existing deep neural networks in the computer vision field could also achieve a high (often better) prediction accuracy.",0
"Harikrishnan, K.; Tarcar, A. K.; Botelho, N.; Kenkre, A.; Rebelo, P.",2023,A novel approach to classification and segmentation of colon cancer imaging towards personalized medicine,Pathology,A novel approach to classification and segmentation of colon cancer imaging towards personalized medicine,"Harikrishnan, K.; Tarcar, A. K.; Botelho, N.; Kenkre, A.; Rebelo, P.",Pathology,2023-07-08 00:00:00 UTC,"Recent advances in the field of pathology coupled with the rapid evolution of machine learning based techniques have revolutionized healthcare practices. Colorectal cancer accounts for one of the top 5 cancers with high incidence (126,240 in 2020) with a high mortality worldwide [1] [2]. Tissue biopsy remains to be the gold standard procedure for accurate diagnosis, treatment planning and prognosis prediction [3]. As an image based modality, pathology has attracted a lot of attention for development of AI algorithms and there has been a steady increase in the number of filings for FDA authorized use of AI algorithms in clinical practice [4]. The SemiCOL Challenge aims to develop computational pathology methods for automatic segmentation and classification of tumor and other tissue classes using H&E stained images. In this paper, we present a novel machine learning framework addressing the SemiCOL Challenge, focusing on semantic segmentation, segmentation-based whole-slide image classification, and effective use of limited annotated data. Our approach leverages deep learning techniques and incorporates data augmentation to improve the accuracy and efficiency of tumor tissue detection and classification in CRC. The proposed method achieves an average Dice score of 0.2785 for segmentation and an AUC score of 0.71 for classification across 20 whole-slide images. This framework has the potential to revolutionize the field of computational pathology, contributing to more efficient and accurate diagnostic tools for colorectal cancer.",10.1101/2023.07.07.23292356,virology-computer-vision.xlsx,"A novel approach to classification and segmentation of colon cancer imaging towards personalized medicine Recent advances in the field of pathology coupled with the rapid evolution of machine learning based techniques have revolutionized healthcare practices. Colorectal cancer accounts for one of the top 5 cancers with high incidence (126,240 in 2020) with a high mortality worldwide [1] [2]. Tissue biopsy remains to be the gold standard procedure for accurate diagnosis, treatment planning and prognosis prediction [3]. As an image based modality, pathology has attracted a lot of attention for development of AI algorithms and there has been a steady increase in the number of filings for FDA authorized use of AI algorithms in clinical practice [4]. The SemiCOL Challenge aims to develop computational pathology methods for automatic segmentation and classification of tumor and other tissue classes using H&E stained images. In this paper, we present a novel machine learning framework addressing the SemiCOL Challenge, focusing on semantic segmentation, segmentation-based whole-slide image classification, and effective use of limited annotated data. Our approach leverages deep learning techniques and incorporates data augmentation to improve the accuracy and efficiency of tumor tissue detection and classification in CRC. The proposed method achieves an average Dice score of 0.2785 for segmentation and an AUC score of 0.71 for classification across 20 whole-slide images. This framework has the potential to revolutionize the field of computational pathology, contributing to more efficient and accurate diagnostic tools for colorectal cancer.",0
"Filiot, A.; Ghermi, R.; Olivier, A.; Jacob, P.; Fidon, L.; Camara, A.; Mac Kain, A.; Saillard, C.; Schiratti, J.-B.",2024,Scaling Self-Supervised Learning for Histopathology with Masked Image Modeling,Pathology,Scaling Self-Supervised Learning for Histopathology with Masked Image Modeling,"Filiot, A.; Ghermi, R.; Olivier, A.; Jacob, P.; Fidon, L.; Camara, A.; Mac Kain, A.; Saillard, C.; Schiratti, J.-B.",Pathology,2024-12-18 00:00:00 UTC,"Computational pathology is revolutionizing the field of pathology by integrating advanced computer vision and machine learning technologies into diagnostic workflows. It offers unprecedented opportunities for improved efficiency in treatment decisions by allowing pathologists to achieve higher precision and objectivity in disease classification, tumor microenvironment description and identification of new biomarkers. However, the potential of computational pathology in personalized medicine comes with significant challenges, particularly in annotating whole slide images (WSI), which is time-consuming, costly and subject to inter-observer variability. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising solution to learn representations from histology patches and leverage large volumes of unlabelled WSI. Recently, Masked Image Modeling (MIM) as a SSL framework has emerged and is now considered to outperform purely contrastive learning paradigms. In this work, we therefore explore the application of MIM to histology using iBOT, a self-supervised transformer-based framework. Through a wide range of 17 downstream tasks over seven cancer indications, both at the slide and patch levels, we provide recommendations on the pre-training of large models for histology data using MIM. First, we demonstrate that in-domain pre-training with iBOT outperforms both ImageNet pre-training and a model pre-trained with a purely contrastive learning objective, MoCo v2. Second, we show that Vision Transformers (ViT) models, when scaled appropriately, have the capability to learn pan-cancer representations that benefit a large variety of downstream tasks. Finally, our iBOT ViT-Base model (80 million parameters), pre-trained on more than 40 million histology images from 16 different cancer types, achieves state-of-the-art performance in most weakly-supervised WSI classification tasks compared to other SSL frameworks available in the literature. This paves the way for the development of a foundation model for histopathology. Our code, models and features are publicly available at https://github.com/owkin/HistoSSLscaling.",10.1101/2023.07.21.23292757,virology-computer-vision.xlsx,"Scaling Self-Supervised Learning for Histopathology with Masked Image Modeling Computational pathology is revolutionizing the field of pathology by integrating advanced computer vision and machine learning technologies into diagnostic workflows. It offers unprecedented opportunities for improved efficiency in treatment decisions by allowing pathologists to achieve higher precision and objectivity in disease classification, tumor microenvironment description and identification of new biomarkers. However, the potential of computational pathology in personalized medicine comes with significant challenges, particularly in annotating whole slide images (WSI), which is time-consuming, costly and subject to inter-observer variability. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising solution to learn representations from histology patches and leverage large volumes of unlabelled WSI. Recently, Masked Image Modeling (MIM) as a SSL framework has emerged and is now considered to outperform purely contrastive learning paradigms. In this work, we therefore explore the application of MIM to histology using iBOT, a self-supervised transformer-based framework. Through a wide range of 17 downstream tasks over seven cancer indications, both at the slide and patch levels, we provide recommendations on the pre-training of large models for histology data using MIM. First, we demonstrate that in-domain pre-training with iBOT outperforms both ImageNet pre-training and a model pre-trained with a purely contrastive learning objective, MoCo v2. Second, we show that Vision Transformers (ViT) models, when scaled appropriately, have the capability to learn pan-cancer representations that benefit a large variety of downstream tasks. Finally, our iBOT ViT-Base model (80 million parameters), pre-trained on more than 40 million histology images from 16 different cancer types, achieves state-of-the-art performance in most weakly-supervised WSI classification tasks compared to other SSL frameworks available in the literature. This paves the way for the development of a foundation model for histopathology. Our code, models and features are publicly available at https://github.com/owkin/HistoSSLscaling.",0
"Fatemi, M. Y.; Lu, Y.; Sharma, C.; Feng, E.; Azher, Z. L.; Diallo, A. B.; Srinivasan, G.; Rosner, G. M.; Pointer, K. B.; Christensen, B. C.; Salas, L. A.; Tsongalis, G. J.; Palisoul, S. M.; Perreard, L.; Kolling, F. W.; Vaickus, L. J.; Levy, J. J.",2023,Feasibility of Inferring Spatial Transcriptomics from Single-Cell Histological Patterns for Studying Colon Cancer Tumor Heterogeneity,Pathology,Feasibility of Inferring Spatial Transcriptomics from Single-Cell Histological Patterns for Studying Colon Cancer Tumor Heterogeneity,"Fatemi, M. Y.; Lu, Y.; Sharma, C.; Feng, E.; Azher, Z. L.; Diallo, A. B.; Srinivasan, G.; Rosner, G. M.; Pointer, K. B.; Christensen, B. C.; Salas, L. A.; Tsongalis, G. J.; Palisoul, S. M.; Perreard, L.; Kolling, F. W.; Vaickus, L. J.; Levy, J. J.",Pathology,2023-10-09 00:00:00 UTC,"BackgroundSpatial transcriptomics involves studying the spatial organization of gene expression within tissues, offering insights into the molecular diversity of tumors. While spatial gene expression is commonly amalgamated from 1-10 cells across 50-micron spots, recent methods have demonstrated the capability to disaggregate this information at subspot resolution by leveraging both expression and histological patterns. However, elucidating such information from histology alone presents a significant challenge but if solved can better permit spatial molecular analysis at cellular resolution for instances where Visium data is not available, reducing study costs. This study explores integrating single-cell histological and transcriptomic data to infer spatial mRNA expression patterns in whole slide images collected from a cohort of stage pT3 colorectal cancer patients. A cell graph neural network algorithm was developed to align histological information extracted from detected cells with single cell RNA patterns through optimal transport methods, facilitating the analysis of cellular groupings and gene relationships. This approach leveraged spot-level expression as an intermediary to co-map histological and transcriptomic information at the single-cell level.

ResultsOur study demonstrated that single-cell transcriptional heterogeneity within a spot could be predicted from histological markers extracted from cells detected within a spot. Furthermore, our model exhibited proficiency in delineating overarching gene expression patterns across whole-slide images. This approach compared favorably to traditional patch-based computer vision methods as well as other methods which did not incorporate single cell expression during the model fitting procedures. Topological nuances of single-cell expression within a Visium spot were preserved using the developed methodology.

ConclusionThis innovative approach augments the resolution of spatial molecular assays utilizing histology as a sole input through synergistic co-mapping of histological and transcriptomic datasets at the single-cell level, anchored by spatial transcriptomics. While initial results are promising, they warrant rigorous validation. This includes collaborating with pathologists for precise spatial identification of distinct cell types and utilizing sophisticated assays, such as Xenium, to attain deeper subcellular insights.",10.1101/2023.10.09.23296701,virology-computer-vision.xlsx,"Feasibility of Inferring Spatial Transcriptomics from Single-Cell Histological Patterns for Studying Colon Cancer Tumor Heterogeneity BackgroundSpatial transcriptomics involves studying the spatial organization of gene expression within tissues, offering insights into the molecular diversity of tumors. While spatial gene expression is commonly amalgamated from 1-10 cells across 50-micron spots, recent methods have demonstrated the capability to disaggregate this information at subspot resolution by leveraging both expression and histological patterns. However, elucidating such information from histology alone presents a significant challenge but if solved can better permit spatial molecular analysis at cellular resolution for instances where Visium data is not available, reducing study costs. This study explores integrating single-cell histological and transcriptomic data to infer spatial mRNA expression patterns in whole slide images collected from a cohort of stage pT3 colorectal cancer patients. A cell graph neural network algorithm was developed to align histological information extracted from detected cells with single cell RNA patterns through optimal transport methods, facilitating the analysis of cellular groupings and gene relationships. This approach leveraged spot-level expression as an intermediary to co-map histological and transcriptomic information at the single-cell level.

ResultsOur study demonstrated that single-cell transcriptional heterogeneity within a spot could be predicted from histological markers extracted from cells detected within a spot. Furthermore, our model exhibited proficiency in delineating overarching gene expression patterns across whole-slide images. This approach compared favorably to traditional patch-based computer vision methods as well as other methods which did not incorporate single cell expression during the model fitting procedures. Topological nuances of single-cell expression within a Visium spot were preserved using the developed methodology.

ConclusionThis innovative approach augments the resolution of spatial molecular assays utilizing histology as a sole input through synergistic co-mapping of histological and transcriptomic datasets at the single-cell level, anchored by spatial transcriptomics. While initial results are promising, they warrant rigorous validation. This includes collaborating with pathologists for precise spatial identification of distinct cell types and utilizing sophisticated assays, such as Xenium, to attain deeper subcellular insights.",0
"Gao, W.; Wang, D.; Huang, Y.",2023,Federated Learning-Driven Collaborative Diagnostic System for Metastatic Breast Cancer,Pathology,Federated Learning-Driven Collaborative Diagnostic System for Metastatic Breast Cancer,"Gao, W.; Wang, D.; Huang, Y.",Pathology,2023-10-21 00:00:00 UTC,"Metastatic breast cancer is one of the leading causes of cancer mortality. While there has been progress in developing deep learning-driven diagnostic system for metastatic breast cancer based on histopathological images, it faces a major challenge in real-world application, i.e., how to improve generalizability of the diagnostic models for diverse patient populations and variations in sample and image processing across different geographic regions. Multi-institutional collaborative learning, which trains a single model using data from multiple institutions, can address the challenges of data inadequacy, lack of data diversity, and data quality. However, the current practice of direct medical data transfer among institutions faces increasing restrictions including patient privacy, intellectual property, data ownership and legal obligations. To enable multi-institutional collaborative learning for cancer diagnosis, we developed a federated learning-driven collaborative diagnostic system for metastatic breast cancer. This system preserves patient privacy by decoupling model training from the need for direct medical data transfer between institutions. Further, this study has demonstrated that the federate learning-driven system can improve diagnostic model accuracy and generalizability by leveraging information derived from diverse data sources across multiple institutions. This study has also shown that this collaborative diagnostic system has a strong potential of improving local diagnosis performance on lower quality images at a resource constrained institution. Our research indicated that federated learning-driven diagnostic system is a feasible and robust framework for multi-institutional collaborative development of diagnostic models for metastatic breast cancer. In addition to the benefits of improving diagnostic model generalizability for diverse patient populations, the collaborative diagnostic system presents a new opportunity to enable under-resourced healthcare institutions to leverage external data resources to improve local diagnosis performance while preserving patient privacy.",10.1101/2023.10.20.23297323,virology-computer-vision.xlsx,"Federated Learning-Driven Collaborative Diagnostic System for Metastatic Breast Cancer Metastatic breast cancer is one of the leading causes of cancer mortality. While there has been progress in developing deep learning-driven diagnostic system for metastatic breast cancer based on histopathological images, it faces a major challenge in real-world application, i.e., how to improve generalizability of the diagnostic models for diverse patient populations and variations in sample and image processing across different geographic regions. Multi-institutional collaborative learning, which trains a single model using data from multiple institutions, can address the challenges of data inadequacy, lack of data diversity, and data quality. However, the current practice of direct medical data transfer among institutions faces increasing restrictions including patient privacy, intellectual property, data ownership and legal obligations. To enable multi-institutional collaborative learning for cancer diagnosis, we developed a federated learning-driven collaborative diagnostic system for metastatic breast cancer. This system preserves patient privacy by decoupling model training from the need for direct medical data transfer between institutions. Further, this study has demonstrated that the federate learning-driven system can improve diagnostic model accuracy and generalizability by leveraging information derived from diverse data sources across multiple institutions. This study has also shown that this collaborative diagnostic system has a strong potential of improving local diagnosis performance on lower quality images at a resource constrained institution. Our research indicated that federated learning-driven diagnostic system is a feasible and robust framework for multi-institutional collaborative development of diagnostic models for metastatic breast cancer. In addition to the benefits of improving diagnostic model generalizability for diverse patient populations, the collaborative diagnostic system presents a new opportunity to enable under-resourced healthcare institutions to leverage external data resources to improve local diagnosis performance while preserving patient privacy.",0
"Levy, J.; Salas, L. A.; Christensen, B. C.; Sriharan, A.; Vaickus, L. J.",2019,"PathFlowAI: A High-Throughput Workflow for Preprocessing, Deep Learning and Interpretation in Digital Pathology",Pathology,"PathFlowAI: A High-Throughput Workflow for Preprocessing, Deep Learning and Interpretation in Digital Pathology","Levy, J.; Salas, L. A.; Christensen, B. C.; Sriharan, A.; Vaickus, L. J.",Pathology,2019-10-25 00:00:00 UTC,"The diagnosis of disease often requires analysis of a biopsy. Many diagnoses depend not only on the presence of certain features but on their location within the tissue. Recently, a number of deep learning diagnostic aids have been developed to classify digitized biopsy slides. Clinical workflows often involve processing of more than 500 slides per day. But, clinical use of deep learning diagnostic aids would require a preprocessing workflow that is cost-effective, flexible, scalable, rapid, interpretable, and transparent. Here, we present such a workflow, optimized using Dask and mixed precision training via APEX, capable of handling any patch-level or slide level classification and prediction problem. The workflow uses a flexible and fast preprocessing and deep learning analytics pipeline, incorporates model interpretation and has a highly storage-efficient audit trail. We demonstrate the utility of this package on the analysis of a prototypical anatomic pathology specimen, liver biopsies for evaluation of hepatitis from a prospective cohort. The preliminary data indicate that PathFlowAI may become a cost-effective and time-efficient tool for clinical use of Artificial Intelligence (AI) algorithms.",10.1101/19003897,virology-deep-learning.xlsx,"PathFlowAI: A High-Throughput Workflow for Preprocessing, Deep Learning and Interpretation in Digital Pathology The diagnosis of disease often requires analysis of a biopsy. Many diagnoses depend not only on the presence of certain features but on their location within the tissue. Recently, a number of deep learning diagnostic aids have been developed to classify digitized biopsy slides. Clinical workflows often involve processing of more than 500 slides per day. But, clinical use of deep learning diagnostic aids would require a preprocessing workflow that is cost-effective, flexible, scalable, rapid, interpretable, and transparent. Here, we present such a workflow, optimized using Dask and mixed precision training via APEX, capable of handling any patch-level or slide level classification and prediction problem. The workflow uses a flexible and fast preprocessing and deep learning analytics pipeline, incorporates model interpretation and has a highly storage-efficient audit trail. We demonstrate the utility of this package on the analysis of a prototypical anatomic pathology specimen, liver biopsies for evaluation of hepatitis from a prospective cohort. The preliminary data indicate that PathFlowAI may become a cost-effective and time-efficient tool for clinical use of Artificial Intelligence (AI) algorithms.",1
"Joung, H.-A.; Ballard, Z. S.; Wu, J.; Tseng, D. K.; Teshome, H.; Zhang, L.; Horn, E. J.; Arnaboldi, P. M.; Dattwyler, R. J.; Garner, O. B.; Carlo, D. D.; Ozcan, A.",2019,Point-of-care serodiagnostic test for early-stage Lyme disease using a multiplexed paper-based immunoassay and machine learning,Pathology,Point-of-care serodiagnostic test for early-stage Lyme disease using a multiplexed paper-based immunoassay and machine learning,"Joung, H.-A.; Ballard, Z. S.; Wu, J.; Tseng, D. K.; Teshome, H.; Zhang, L.; Horn, E. J.; Arnaboldi, P. M.; Dattwyler, R. J.; Garner, O. B.; Carlo, D. D.; Ozcan, A.",Pathology,2019-10-22 00:00:00 UTC,"Caused by the tick-borne spirochete, Borrelia burgdorferi, Lyme disease (LD) is the most common vector-borne infectious disease in North America and Europe. Though timely diagnosis and treatment are effective in preventing disease progression, current tests are insensitive in early-stage LD, with a sensitivity <50%. Additionally, the serological testing currently recommended by the US Center for Disease Control has high costs (>$400/test) and extended sample-to-answer timelines (>24 hours). To address these challenges, we created a cost-effective and rapid point-of-care (POC) test for early-stage LD that assays for antibodies specific to seven Borrelia antigens and a synthetic peptide in a paper-based multiplexed vertical flow assay (xVFA). We trained a deep learning-based diagnostic algorithm to select an optimal subset of antigen/peptide targets, and then blindly-tested our xVFA using human samples (N(+) = 42, N(-)= 54), achieving an area-under-the-curve (AUC), sensitivity, and specificity of 0.950, 90.5%, and 87.0% respectively, outperforming previous LD POC tests. With batch-specific standardization and threshold tuning, the specificity of our blind-testing performance improved to 96.3%, with an AUC and sensitivity of 0.963 and 85.7%, respectively.",10.1101/19009423,virology-deep-learning.xlsx,"Point-of-care serodiagnostic test for early-stage Lyme disease using a multiplexed paper-based immunoassay and machine learning Caused by the tick-borne spirochete, Borrelia burgdorferi, Lyme disease (LD) is the most common vector-borne infectious disease in North America and Europe. Though timely diagnosis and treatment are effective in preventing disease progression, current tests are insensitive in early-stage LD, with a sensitivity <50%. Additionally, the serological testing currently recommended by the US Center for Disease Control has high costs (>$400/test) and extended sample-to-answer timelines (>24 hours). To address these challenges, we created a cost-effective and rapid point-of-care (POC) test for early-stage LD that assays for antibodies specific to seven Borrelia antigens and a synthetic peptide in a paper-based multiplexed vertical flow assay (xVFA). We trained a deep learning-based diagnostic algorithm to select an optimal subset of antigen/peptide targets, and then blindly-tested our xVFA using human samples (N(+) = 42, N(-)= 54), achieving an area-under-the-curve (AUC), sensitivity, and specificity of 0.950, 90.5%, and 87.0% respectively, outperforming previous LD POC tests. With batch-specific standardization and threshold tuning, the specificity of our blind-testing performance improved to 96.3%, with an AUC and sensitivity of 0.963 and 85.7%, respectively.",1
"Uchino, E.; Suzuki, K.; Sato, N.; Kojima, R.; Tamada, Y.; Hiragi, S.; Yokoi, H.; Yugami, N.; Minamiguchi, S.; Haga, H.; Yanagita, M.; Okuno, Y.",2020,Classification of glomerular pathological findings using deep learning and nephrologist-AI collective intelligence approach,Pathology,Classification of glomerular pathological findings using deep learning and nephrologist-AI collective intelligence approach,"Uchino, E.; Suzuki, K.; Sato, N.; Kojima, R.; Tamada, Y.; Hiragi, S.; Yokoi, H.; Yugami, N.; Minamiguchi, S.; Haga, H.; Yanagita, M.; Okuno, Y.",Pathology,2020-01-02 00:00:00 UTC,"BackgroundAutomated classification of glomerular pathological findings is potentially beneficial in establishing an efficient and objective diagnosis in renal pathology. While previous studies have verified the artificial intelligence (AI) models for the classification of global sclerosis and glomerular cell proliferation, there are several other glomerular pathological findings required for diagnosis, and the comprehensive models for the classification of these major findings have not yet been reported. Whether the cooperation between these AI models and clinicians improves diagnostic performance also remains unknown. Here, we developed AI models to classify glomerular images for major findings required for pathological diagnosis and investigated whether those models could improve the diagnostic performance of nephrologists.

MethodsWe used a dataset of 283 kidney biopsy cases comprising 15888 glomerular images that were annotated by a total of 25 nephrologists. AI models to classify seven pathological findings: global sclerosis, segmental sclerosis, endocapillary proliferation, mesangial matrix accumulation, mesangial cell proliferation, crescent, and basement membrane structural changes, were constructed using deep learning by fine-tuning of InceptionV3 convolutional neural network. Subsequently, we compared the agreement to truth labels between majority decision among nephrologists with or without the AI model as a voter.

ResultsOur model for global sclerosis showed high performance (area under the curve: periodic acid-Schiff, 0.986; periodic acid methenamine silver, 0.983); the models for the other findings also showed performance close to those of nephrologists. By adding the AI model output to majority decision among nephrologists, the sensitivity and specificity were significantly improved in 9 of 14 constructed models compared to those of nephrologists alone.

ConclusionOur study showed a proof-of-concept for the classification of multiple glomerular findings in a comprehensive method of deep learning and suggested its potential effectiveness in improving diagnostic accuracy of clinicians.",10.1101/2019.12.30.19016162,virology-deep-learning.xlsx,"Classification of glomerular pathological findings using deep learning and nephrologist-AI collective intelligence approach BackgroundAutomated classification of glomerular pathological findings is potentially beneficial in establishing an efficient and objective diagnosis in renal pathology. While previous studies have verified the artificial intelligence (AI) models for the classification of global sclerosis and glomerular cell proliferation, there are several other glomerular pathological findings required for diagnosis, and the comprehensive models for the classification of these major findings have not yet been reported. Whether the cooperation between these AI models and clinicians improves diagnostic performance also remains unknown. Here, we developed AI models to classify glomerular images for major findings required for pathological diagnosis and investigated whether those models could improve the diagnostic performance of nephrologists.

MethodsWe used a dataset of 283 kidney biopsy cases comprising 15888 glomerular images that were annotated by a total of 25 nephrologists. AI models to classify seven pathological findings: global sclerosis, segmental sclerosis, endocapillary proliferation, mesangial matrix accumulation, mesangial cell proliferation, crescent, and basement membrane structural changes, were constructed using deep learning by fine-tuning of InceptionV3 convolutional neural network. Subsequently, we compared the agreement to truth labels between majority decision among nephrologists with or without the AI model as a voter.

ResultsOur model for global sclerosis showed high performance (area under the curve: periodic acid-Schiff, 0.986; periodic acid methenamine silver, 0.983); the models for the other findings also showed performance close to those of nephrologists. By adding the AI model output to majority decision among nephrologists, the sensitivity and specificity were significantly improved in 9 of 14 constructed models compared to those of nephrologists alone.

ConclusionOur study showed a proof-of-concept for the classification of multiple glomerular findings in a comprehensive method of deep learning and suggested its potential effectiveness in improving diagnostic accuracy of clinicians.",0
"Schuhmacher, D.; Gerwert, K.; Mosig, A.",2020,A Generic Neural Network Approach to Infer Segmenting Classifiers for Disease-Associated Regions in Medical Image data,Pathology,A Generic Neural Network Approach to Infer Segmenting Classifiers for Disease-Associated Regions in Medical Image data,"Schuhmacher, D.; Gerwert, K.; Mosig, A.",Pathology,2020-02-29 00:00:00 UTC,"AO_SCPLOWBSTRACTC_SCPLOWIn many settings in digital pathology or radiology, it is of predominant importance to train classifiers that can segment disease-associated regions in medical images. While numerous deep learning approaches, most notably U-Nets, exist to learn segmentations, these approaches typically require reference segmentations as training data. As a consequence, obtaining pixel level annotations of histopathological samples has become a major bottleneck to establish segmentation learning approaches. Our contribution introduces a neural network approach to avoid the annotation bottleneck in the first place: our approach requires two-class labels such as cancer vs. healthy at the sample level only. Using these sample-labels, a meta-network is trained that infers a segmenting neural network which will segment the disease-associated region (e.g. tumor) that is present in the cancer samples, but not in the healthy samples. This process results in a network, e.g. a U-Net, that can segment tumor regions in arbitrary further samples of the same type.

We establish and validate our approach in the context of digital label-free pathology, where hyperspectral infrared microscopy is used to segment and characterize the disease status of histopathological samples. Trained on a data set comprising infrared microscopic images of 100 tissue microarray spots labelled as either cancerous or cancer-free, the approach yields a U-Net that reliably identifies tumor regions or the absence of tumor in an independent test set involving 40 samples.

While our present work is focused on training a U-Net for infrared microscopic images, the approach is generic in the sense that it can be adapted to other image modalities and essentially arbitrary segmenting network topologies.",10.1101/2020.02.27.20028845,virology-deep-learning.xlsx,"A Generic Neural Network Approach to Infer Segmenting Classifiers for Disease-Associated Regions in Medical Image data AO_SCPLOWBSTRACTC_SCPLOWIn many settings in digital pathology or radiology, it is of predominant importance to train classifiers that can segment disease-associated regions in medical images. While numerous deep learning approaches, most notably U-Nets, exist to learn segmentations, these approaches typically require reference segmentations as training data. As a consequence, obtaining pixel level annotations of histopathological samples has become a major bottleneck to establish segmentation learning approaches. Our contribution introduces a neural network approach to avoid the annotation bottleneck in the first place: our approach requires two-class labels such as cancer vs. healthy at the sample level only. Using these sample-labels, a meta-network is trained that infers a segmenting neural network which will segment the disease-associated region (e.g. tumor) that is present in the cancer samples, but not in the healthy samples. This process results in a network, e.g. a U-Net, that can segment tumor regions in arbitrary further samples of the same type.

We establish and validate our approach in the context of digital label-free pathology, where hyperspectral infrared microscopy is used to segment and characterize the disease status of histopathological samples. Trained on a data set comprising infrared microscopic images of 100 tissue microarray spots labelled as either cancerous or cancer-free, the approach yields a U-Net that reliably identifies tumor regions or the absence of tumor in an independent test set involving 40 samples.

While our present work is focused on training a U-Net for infrared microscopic images, the approach is generic in the sense that it can be adapted to other image modalities and essentially arbitrary segmenting network topologies.",0
"Zhou, M.; Chen, Y.; Wang, D.; Xu, Y.; Yao, W.; Huang, J.; Jin, X.; Pan, Z.; Tan, J.; Wang, L.; Xia, Y.; Zou, L.; Xu, X.; Wei, J.; Guan, M.; Feng, J.; Zhang, H.; Qu, J.",2020,Improved deep learning model for differentiating novel coronavirus pneumonia and influenza pneumonia,Respiratory Medicine,Improved deep learning model for differentiating novel coronavirus pneumonia and influenza pneumonia,"Zhou, M.; Chen, Y.; Wang, D.; Xu, Y.; Yao, W.; Huang, J.; Jin, X.; Pan, Z.; Tan, J.; Wang, L.; Xia, Y.; Zou, L.; Xu, X.; Wei, J.; Guan, M.; Feng, J.; Zhang, H.; Qu, J.",Respiratory Medicine,2020-03-30 00:00:00 UTC,"BackgroundChest CT had high sensitivity in diagnosing novel coronavirus pneumonia (NCP) at early stage, giving it an advantage over nucleic acid detection in time of crisis. Deep learning was reported to discover intricate structures from clinical images and achieve expert-level performance in medical image analysis. To develop and validate an integrated deep learning framework on chest CT images for auto-detection of NCP, particularly focusing on differentiating NCP from influenza pneumonia (IP).

Methods35 confirmed NCP cases were consecutively enrolled as training set from 1138 suspected patients in three NCP designated hospitals together with 361 confirmed viral pneumonia patients from center one including 156 IP patients, from May, 2015 to February, 2020. The external validation set enrolled 57 NCP patients and 50 IP patients from eight centers.

Results96.6% of NCP lesions were larger than 1 cm and 76.8% were with intensity below -500 Hu, indicating less consolidation than IP lesions which had nodules ranging 5-10 mm. The classification schemes accurately distinguished NCP and IP lesions with area under the receiver operating characteristic curve (AUC) above 0.93. The Trinary scheme was more device-independent and consistent with specialists than the Plain scheme, which achieved a F1 score of 0.847, higher than the Plain scheme (0.774), specialists (0.785) and residents (0.644).

ConclusionsOur study potentially provides an accurate early diagnosis tool on chest CT for NCP with high transferability, and shows high efficiency in differentiating NCP and IP, helping to reduce misdiagnosis and contain the pandemic transmission.",10.1101/2020.03.24.20043117,virology-deep-learning.xlsx,"Improved deep learning model for differentiating novel coronavirus pneumonia and influenza pneumonia BackgroundChest CT had high sensitivity in diagnosing novel coronavirus pneumonia (NCP) at early stage, giving it an advantage over nucleic acid detection in time of crisis. Deep learning was reported to discover intricate structures from clinical images and achieve expert-level performance in medical image analysis. To develop and validate an integrated deep learning framework on chest CT images for auto-detection of NCP, particularly focusing on differentiating NCP from influenza pneumonia (IP).

Methods35 confirmed NCP cases were consecutively enrolled as training set from 1138 suspected patients in three NCP designated hospitals together with 361 confirmed viral pneumonia patients from center one including 156 IP patients, from May, 2015 to February, 2020. The external validation set enrolled 57 NCP patients and 50 IP patients from eight centers.

Results96.6% of NCP lesions were larger than 1 cm and 76.8% were with intensity below -500 Hu, indicating less consolidation than IP lesions which had nodules ranging 5-10 mm. The classification schemes accurately distinguished NCP and IP lesions with area under the receiver operating characteristic curve (AUC) above 0.93. The Trinary scheme was more device-independent and consistent with specialists than the Plain scheme, which achieved a F1 score of 0.847, higher than the Plain scheme (0.774), specialists (0.785) and residents (0.644).

ConclusionsOur study potentially provides an accurate early diagnosis tool on chest CT for NCP with high transferability, and shows high efficiency in differentiating NCP and IP, helping to reduce misdiagnosis and contain the pandemic transmission.",1
"Jo, H.; Son, H.; Jung, S. Y.; Hwang, H. J.",2020,Analysis of COVID-19 spread in South Korea using the SIR model with time-dependent parameters and deep learning,Epidemiology,Analysis of COVID-19 spread in South Korea using the SIR model with time-dependent parameters and deep learning,"Jo, H.; Son, H.; Jung, S. Y.; Hwang, H. J.",Epidemiology,2020-04-17 00:00:00 UTC,"Mathematical modeling is a process aimed at finding a mathematical description of a system and translating it into a relational expression. When a system is continuously changing over time (e.g., infectious diseases) differential equations, which may include parameters, are used for modeling the system. The process of finding those parameters that best fit the given data from the system is called an inverse problem. This study aims at analyzing the novel coronavirus infection (COVID-19) spread in South Korea using the susceptible-infected-recovered (SIR) model. We collect the data from Korea Centers for Disease Control & Prevention (KCDC). We assume that each parameter in the SIR model is a function of time so that we can compute important parameters, such as the basic reproduction number (R0), more delicately. Using neural networks, we propose a method to find the best time-varying parameters and the solution for the model simultaneously. Moreover, using time-dependent parameters, we find that traditional numerical algorithms, such as the Runge-Kutta methods, can successfully approximate the SIR model while fitting the COVID-19 data, thus modeling the propagation patterns of COVID-19 more precisely.",10.1101/2020.04.13.20063412,virology-deep-learning.xlsx,"Analysis of COVID-19 spread in South Korea using the SIR model with time-dependent parameters and deep learning Mathematical modeling is a process aimed at finding a mathematical description of a system and translating it into a relational expression. When a system is continuously changing over time (e.g., infectious diseases) differential equations, which may include parameters, are used for modeling the system. The process of finding those parameters that best fit the given data from the system is called an inverse problem. This study aims at analyzing the novel coronavirus infection (COVID-19) spread in South Korea using the susceptible-infected-recovered (SIR) model. We collect the data from Korea Centers for Disease Control & Prevention (KCDC). We assume that each parameter in the SIR model is a function of time so that we can compute important parameters, such as the basic reproduction number (R0), more delicately. Using neural networks, we propose a method to find the best time-varying parameters and the solution for the model simultaneously. Moreover, using time-dependent parameters, we find that traditional numerical algorithms, such as the Runge-Kutta methods, can successfully approximate the SIR model while fitting the COVID-19 data, thus modeling the propagation patterns of COVID-19 more precisely.",1
"Deng, Q.",2020,Dynamics and Development of the COVID-19 Epidemics in the US: a Compartmental Model with Deep Learning Enhancement,Epidemiology,Dynamics and Development of the COVID-19 Epidemics in the US: a Compartmental Model with Deep Learning Enhancement,"Deng, Q.",Epidemiology,2020-06-06 00:00:00 UTC,"BackgroundCompartmental models dominate epidemic modeling. Estimations of transmission parameters between compartments are typically done through stochastic parameterization processes that depend upon detailed statistics on transmission characteristics, which are economically and resource-wide expensive to collect. We apply deep learning techniques as a lower data dependency alternative to estimate transmission parameters of a customized compartmental model, for the purposes of simulating the dynamics of the US COVID-19 epidemics and projecting its further development.

MethodsWe construct a compartmental model. We develop a multistep deep learning methodology to estimate the models transmission parameters. We then feed the estimated transmission parameters to the model to predict the development of the US COVID-19 epidemics for 35 and 42 days. Epidemics are considered suppressed when the basic reproduction number (R0) becomes less than one.

ResultsThe deep learning-enhanced compartmental model predicts that R0 will become less than one around June 19 to July 3, 2020, at which point the epidemics will effectively start to die out, and that the US ""Infected"" population will peak round June 18 to July 2, 2020 between 1{middle dot}34 million and 1{middle dot}41 million individual cases. The models also predict that the number of accumulative confirmed cases will cross the 2 million mark around June 10 to 11, 2020.

ConclusionsCurrent compartmental models require stochastic parameterization to estimate the transmission parameters. These models effectiveness depends upon detailed statistics on transmission characteristics. As an alternative, deep learning techniques are effective in estimating these stochastic parameters with greatly reduced dependency on data particularity.",10.1101/2020.05.31.20118414,virology-deep-learning.xlsx,"Dynamics and Development of the COVID-19 Epidemics in the US: a Compartmental Model with Deep Learning Enhancement BackgroundCompartmental models dominate epidemic modeling. Estimations of transmission parameters between compartments are typically done through stochastic parameterization processes that depend upon detailed statistics on transmission characteristics, which are economically and resource-wide expensive to collect. We apply deep learning techniques as a lower data dependency alternative to estimate transmission parameters of a customized compartmental model, for the purposes of simulating the dynamics of the US COVID-19 epidemics and projecting its further development.

MethodsWe construct a compartmental model. We develop a multistep deep learning methodology to estimate the models transmission parameters. We then feed the estimated transmission parameters to the model to predict the development of the US COVID-19 epidemics for 35 and 42 days. Epidemics are considered suppressed when the basic reproduction number (R0) becomes less than one.

ResultsThe deep learning-enhanced compartmental model predicts that R0 will become less than one around June 19 to July 3, 2020, at which point the epidemics will effectively start to die out, and that the US ""Infected"" population will peak round June 18 to July 2, 2020 between 1{middle dot}34 million and 1{middle dot}41 million individual cases. The models also predict that the number of accumulative confirmed cases will cross the 2 million mark around June 10 to 11, 2020.

ConclusionsCurrent compartmental models require stochastic parameterization to estimate the transmission parameters. These models effectiveness depends upon detailed statistics on transmission characteristics. As an alternative, deep learning techniques are effective in estimating these stochastic parameters with greatly reduced dependency on data particularity.",1
"He, X.; Wang, S.; Shi, S.; Chu, X.; Tang, J.; Liu, X.; Yan, C.; Zhang, J.; Ding, G.",2021,Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans,Epidemiology,Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans,"He, X.; Wang, S.; Shi, S.; Chu, X.; Tang, J.; Liu, X.; Yan, C.; Zhang, J.; Ding, G.",Epidemiology,2021-11-04 00:00:00 UTC,"COVID-19 pandemic has spread all over the world for months. As its transmissibility and high pathogenicity seriously threaten peoples lives, the accurate and fast detection of the COVID-19 infection is crucial. Although many recent studies have shown that deep learning based solutions can help detect COVID-19 based on chest CT scans, there lacks a consistent and systematic comparison and evaluation on these techniques. In this paper, we first build a clean and segmented CT dataset called Clean-CC-CCII by fixing the errors and removing some noises in a large CT scan dataset CC-CCII with three classes: novel coronavirus pneumonia (NCP), common pneumonia (CP), and normal controls (Normal). After cleaning, our dataset consists of a total of 340,190 slices of 3,993 scans from 2,698 patients. Then we benchmark and compare the performance of a series of state-of-the-art (SOTA) 3D and 2D convolutional neural networks (CNNs). The results show that 3D CNNs outperform 2D CNNs in general. With extensive effort of hyperparameter tuning, we find that the 3D CNN model DenseNet3D121 achieves the highest accuracy of 88.63% (F1-score is 88.14% and AUC is 0.940), and another 3D CNN model ResNet3D34 achieves the best AUC of 0.959 (accuracy is 87.83% and F1-score is 86.04%). We further demonstrate that the mixup data augmentation technique can largely improve the model performance. At last, we design an automated deep learning methodology to generate a lightweight deep learning model MNas3DNet41 that achieves an accuracy of 87.14%, F1-score of 87.25%, and AUC of 0.957, which are on par with the best models made by AI experts. The automated deep learning design is a promising methodology that can help health-care professionals develop effective deep learning models using their private data sets. Our Clean-CC-CCII dataset and source code are available at: https://github.com/HKBU-HPML/HKBU_HPML_COVID-19.",10.1101/2020.06.08.20125963,virology-deep-learning.xlsx,"Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans COVID-19 pandemic has spread all over the world for months. As its transmissibility and high pathogenicity seriously threaten peoples lives, the accurate and fast detection of the COVID-19 infection is crucial. Although many recent studies have shown that deep learning based solutions can help detect COVID-19 based on chest CT scans, there lacks a consistent and systematic comparison and evaluation on these techniques. In this paper, we first build a clean and segmented CT dataset called Clean-CC-CCII by fixing the errors and removing some noises in a large CT scan dataset CC-CCII with three classes: novel coronavirus pneumonia (NCP), common pneumonia (CP), and normal controls (Normal). After cleaning, our dataset consists of a total of 340,190 slices of 3,993 scans from 2,698 patients. Then we benchmark and compare the performance of a series of state-of-the-art (SOTA) 3D and 2D convolutional neural networks (CNNs). The results show that 3D CNNs outperform 2D CNNs in general. With extensive effort of hyperparameter tuning, we find that the 3D CNN model DenseNet3D121 achieves the highest accuracy of 88.63% (F1-score is 88.14% and AUC is 0.940), and another 3D CNN model ResNet3D34 achieves the best AUC of 0.959 (accuracy is 87.83% and F1-score is 86.04%). We further demonstrate that the mixup data augmentation technique can largely improve the model performance. At last, we design an automated deep learning methodology to generate a lightweight deep learning model MNas3DNet41 that achieves an accuracy of 87.14%, F1-score of 87.25%, and AUC of 0.957, which are on par with the best models made by AI experts. The automated deep learning design is a promising methodology that can help health-care professionals develop effective deep learning models using their private data sets. Our Clean-CC-CCII dataset and source code are available at: https://github.com/HKBU-HPML/HKBU_HPML_COVID-19.",1
"Lange, T.; Schwarzer, G.; Datzmann, T.; Binder, H.",2020,Machine learning for identifying relevant publications in updates of systematic reviews of diagnostic test studies,Epidemiology,Machine learning for identifying relevant publications in updates of systematic reviews of diagnostic test studies,"Lange, T.; Schwarzer, G.; Datzmann, T.; Binder, H.",Epidemiology,2020-06-19 00:00:00 UTC,"BackgroundUpdating systematic reviews is often a time-consuming process involving a lot of human effort and is therefore not carried out as often as it should be. Our aim was therefore to explore the potential of machine learning methods to reduce the human workload, and to particularly also gauge the performance of deep learning methods as compared to more established machine learning methods.

MethodsWe used three available reviews of diagnostic test studies as data basis. In order to identify relevant publications we used typical text pre-processing methods. The reference standard for the evaluation was the human-consensus based binary classification (inclusion, exclusion). For the evaluation of models various scenarios were generated using a grid of combinations of data preprocessing steps. Furthermore, we evaluated each machine learning approach with an approach-specific predefined grid of tuning parameters using the Brier score metric.

ResultsThe best performance was obtained with an ensemble method for two of the reviews, and by a deep learning approach for the other review. Yet, the final performance of approaches is seen to strongly depend on data preparation. Overall, machine learning methods provided reasonable classification.

ConclusionIt seems possible to reduce the human workload in updating systematic reviews by using machine learning methods. Yet, as the influence of data preprocessing on the final performance seems to be at least as important as choosing the specific machine learning approach, users should not blindly expect good performance just by using approaches from a popular class, such as deep learning.",10.1101/2020.06.16.20132670,virology-deep-learning.xlsx,"Machine learning for identifying relevant publications in updates of systematic reviews of diagnostic test studies BackgroundUpdating systematic reviews is often a time-consuming process involving a lot of human effort and is therefore not carried out as often as it should be. Our aim was therefore to explore the potential of machine learning methods to reduce the human workload, and to particularly also gauge the performance of deep learning methods as compared to more established machine learning methods.

MethodsWe used three available reviews of diagnostic test studies as data basis. In order to identify relevant publications we used typical text pre-processing methods. The reference standard for the evaluation was the human-consensus based binary classification (inclusion, exclusion). For the evaluation of models various scenarios were generated using a grid of combinations of data preprocessing steps. Furthermore, we evaluated each machine learning approach with an approach-specific predefined grid of tuning parameters using the Brier score metric.

ResultsThe best performance was obtained with an ensemble method for two of the reviews, and by a deep learning approach for the other review. Yet, the final performance of approaches is seen to strongly depend on data preparation. Overall, machine learning methods provided reasonable classification.

ConclusionIt seems possible to reduce the human workload in updating systematic reviews by using machine learning methods. Yet, as the influence of data preprocessing on the final performance seems to be at least as important as choosing the specific machine learning approach, users should not blindly expect good performance just by using approaches from a popular class, such as deep learning.",0
"El-Bana, S.; Al-Kabbany, A.; Sharkas, M.",2020,A Multi-Task Pipeline with Specialized Streams forClassification and Segmentation of InfectionManifestations in COVID-19 Scans,Epidemiology,A Multi-Task Pipeline with Specialized Streams forClassification and Segmentation of InfectionManifestations in COVID-19 Scans,"El-Bana, S.; Al-Kabbany, A.; Sharkas, M.",Epidemiology,2020-06-26 00:00:00 UTC,"We are concerned with the challenge of coronavirus disease (COVID-19) detection in chest X-ray and Computed Tomography (CT) scans, and the classification and segmentation of related infection manifestations. Even though it is arguably not an established diagnostic tool, using machine learning-based analysis of COVID-19 medical scans has shown the potential to provide a preliminary digital second opinion. This can help in managing the current pandemic, and thus has been attracting significant research attention. In this research, we propose a multi-task pipeline that takes advantage of the growing advances in deep neural network models. In the first stage, we fine-tuned an Inception-v3 deep model for COVID-19 recognition using multi-modal learning, i.e., using X-ray and CT scans. In addition to outperforming other deep models on the same task in the recent literature, with an attained accuracy of 99.4%, we also present comparative analysis for multi-modal learning against learning from X-ray scans alone. The second and the third stages of the proposed pipeline complement one another in dealing with different types of infection manifestations. The former features a convolutional neural network architecture for recognizing three types of manifestations, while the latter transfers learning from another knowledge domain, namely, pulmonary nodule segmentation in CT scans, to produce binary masks for segmenting the regions corresponding to these manifestations. Our proposed pipeline also features specialized streams in which multiple deep models are trained separately to segment specific types of infection manifestations, and we show the significant impact that this framework has on various performance metrics. We evaluate the proposed models on widely adopted datasets, and we demonstrate an increase of approximately 4% and 7% for dice coefficient and mean intersection-over-union (mIoU), respectively, while achieving 60% reduction in computational time, compared to the recent literature.",10.1101/2020.06.24.20139238,virology-deep-learning.xlsx,"A Multi-Task Pipeline with Specialized Streams forClassification and Segmentation of InfectionManifestations in COVID-19 Scans We are concerned with the challenge of coronavirus disease (COVID-19) detection in chest X-ray and Computed Tomography (CT) scans, and the classification and segmentation of related infection manifestations. Even though it is arguably not an established diagnostic tool, using machine learning-based analysis of COVID-19 medical scans has shown the potential to provide a preliminary digital second opinion. This can help in managing the current pandemic, and thus has been attracting significant research attention. In this research, we propose a multi-task pipeline that takes advantage of the growing advances in deep neural network models. In the first stage, we fine-tuned an Inception-v3 deep model for COVID-19 recognition using multi-modal learning, i.e., using X-ray and CT scans. In addition to outperforming other deep models on the same task in the recent literature, with an attained accuracy of 99.4%, we also present comparative analysis for multi-modal learning against learning from X-ray scans alone. The second and the third stages of the proposed pipeline complement one another in dealing with different types of infection manifestations. The former features a convolutional neural network architecture for recognizing three types of manifestations, while the latter transfers learning from another knowledge domain, namely, pulmonary nodule segmentation in CT scans, to produce binary masks for segmenting the regions corresponding to these manifestations. Our proposed pipeline also features specialized streams in which multiple deep models are trained separately to segment specific types of infection manifestations, and we show the significant impact that this framework has on various performance metrics. We evaluate the proposed models on widely adopted datasets, and we demonstrate an increase of approximately 4% and 7% for dice coefficient and mean intersection-over-union (mIoU), respectively, while achieving 60% reduction in computational time, compared to the recent literature.",1
"Bukhari, S. U. K.; Mehtab, U.; Hussain, S. S.; Syed, A.; Armaghan, S. U.; Shah, S. S. H.",2020,The assessment of Computer Vision Algorithms for the Diagnosis of Prostatic Adenocarcinoma in Surgical Specimens,Pathology,The assessment of Computer Vision Algorithms for the Diagnosis of Prostatic Adenocarcinoma in Surgical Specimens,"Bukhari, S. U. K.; Mehtab, U.; Hussain, S. S.; Syed, A.; Armaghan, S. U.; Shah, S. S. H.",Pathology,2020-07-17 00:00:00 UTC,"IntroductionProstatic malignancy is a major cause of morbidity and fatality among men around the globe. More than a million new cases of prostatic cancer are diagnoses annually. The incidence of prostatic malignancy is rising and it is expected that more than two million new cases of prostatic carcinoma will be diagnosed in 2040. The application of machine learning to assist the histopathologists could be a very valuable adjunct tool for the histological diagnosis of prostatic malignant tumors.

Aim & ObjectivesTo evaluate the effectiveness of artificial intelligence for the histopathological diagnosis of prostatic carcinoma by analyzing the digitized pathology slides.

Materials & MethodsEight hundred and two (802) images in total, were obtained from the anonymised slides stained with hematoxylin and eosin which included anonymised 337 images of prostatic adenocarcinoma and 465 anonymised images of nodular hyperplasia of prostate. Eighty percent (80%) of the total digital images were used for training and 20% for testing. Three ResNet architectures ResNet-18, ResNet-34, and ResNet-50 were employed for the analysis of these images.

ResultsThe evaluation of digital images by ResNet-18, ResNet-34, and ResNet-50 revealed the diagnostic accuracy of 97.1%, 98 % and 99.5 % respectively.

DiscussionThe application of artificial intelligence is being considered as a very useful tool which may improve the patient care by improving the diagnostic accuracy and reducing the cost. In radiology, the application of deep learning to interpret radiological images has revealed excellent results. In the present study, the analysis of pathology images by convolutional neural network architecture revealed the diagnostic accuracy of 97.1%, 98 % and 99.5 % with by ResNet-18, ResNet-34, and ResNet-50 respectively. The findings of the present study are in accordance with the other published series, which were carried out to determine the accuracy of machine learning for the diagnosis of cancers of lung, breast and prostate. The application of deep learning for the histological diagnosis of malignant tumors could be quite helpful in improving the patient care.

ConclusionThe findings of the present study suggest that intelligent vision system possibly a worthwhile tool for the histopathological evaluation of prostatic tissue to differentiate between the benign and malignant disorders.",10.1101/2020.07.14.20152116,virology-deep-learning.xlsx,"The assessment of Computer Vision Algorithms for the Diagnosis of Prostatic Adenocarcinoma in Surgical Specimens IntroductionProstatic malignancy is a major cause of morbidity and fatality among men around the globe. More than a million new cases of prostatic cancer are diagnoses annually. The incidence of prostatic malignancy is rising and it is expected that more than two million new cases of prostatic carcinoma will be diagnosed in 2040. The application of machine learning to assist the histopathologists could be a very valuable adjunct tool for the histological diagnosis of prostatic malignant tumors.

Aim & ObjectivesTo evaluate the effectiveness of artificial intelligence for the histopathological diagnosis of prostatic carcinoma by analyzing the digitized pathology slides.

Materials & MethodsEight hundred and two (802) images in total, were obtained from the anonymised slides stained with hematoxylin and eosin which included anonymised 337 images of prostatic adenocarcinoma and 465 anonymised images of nodular hyperplasia of prostate. Eighty percent (80%) of the total digital images were used for training and 20% for testing. Three ResNet architectures ResNet-18, ResNet-34, and ResNet-50 were employed for the analysis of these images.

ResultsThe evaluation of digital images by ResNet-18, ResNet-34, and ResNet-50 revealed the diagnostic accuracy of 97.1%, 98 % and 99.5 % respectively.

DiscussionThe application of artificial intelligence is being considered as a very useful tool which may improve the patient care by improving the diagnostic accuracy and reducing the cost. In radiology, the application of deep learning to interpret radiological images has revealed excellent results. In the present study, the analysis of pathology images by convolutional neural network architecture revealed the diagnostic accuracy of 97.1%, 98 % and 99.5 % with by ResNet-18, ResNet-34, and ResNet-50 respectively. The findings of the present study are in accordance with the other published series, which were carried out to determine the accuracy of machine learning for the diagnosis of cancers of lung, breast and prostate. The application of deep learning for the histological diagnosis of malignant tumors could be quite helpful in improving the patient care.

ConclusionThe findings of the present study suggest that intelligent vision system possibly a worthwhile tool for the histopathological evaluation of prostatic tissue to differentiate between the benign and malignant disorders.",0
"Sornapudi, S.; Addanki, R.; Stanley, J.; Stoecker, W. V.; Long, R.; Zuna, R.; Frazier, S. R.; Antani, S.",2020,Cervical Whole Slide Histology Image Analysis Toolbox,Pathology,Cervical Whole Slide Histology Image Analysis Toolbox,"Sornapudi, S.; Addanki, R.; Stanley, J.; Stoecker, W. V.; Long, R.; Zuna, R.; Frazier, S. R.; Antani, S.",Pathology,2020-07-24 00:00:00 UTC,"Cervical intraepithelial neoplasia (CIN) is regarded as a potential precancerous state of the uterine cervix. Timely and appropriate early treatment of CIN can help reduce cervical cancer mortality. Accurate estimation of CIN grade correlated with human papillomavirus (HPV) type, which is the primary cause of the disease, helps determine the patients risk for developing the disease. Colposcopy is used to select women for biopsy. Expert pathologists examine the biopsied cervical epithelial tissue under a microscope. The examination can take a long time and is prone to error and often results in high inter- and intra-observer variability in outcomes. We propose a novel image analysis toolbox that can automate CIN diagnosis using whole slide image (digitized biopsies) of cervical tissue samples. The toolbox is built as a four-step deep learning model that detects the epithelium regions, segments the detected epithelial portions, analyzes local vertical segment regions, and finally classifies each epithelium block with localized attention. We propose an epithelium detection network in this study and make use of our earlier research on epithelium segmentation and CIN classification to complete the design of the end-to-end CIN diagnosis toolbox. The results show that automated epithelium detection and segmentation for CIN classification yields comparable results to manually segmented epithelium CIN classification. This highlights the potential as a tool for automated digitized histology slide image analysis to assist expert pathologists.",10.1101/2020.07.22.20160366,virology-deep-learning.xlsx,"Cervical Whole Slide Histology Image Analysis Toolbox Cervical intraepithelial neoplasia (CIN) is regarded as a potential precancerous state of the uterine cervix. Timely and appropriate early treatment of CIN can help reduce cervical cancer mortality. Accurate estimation of CIN grade correlated with human papillomavirus (HPV) type, which is the primary cause of the disease, helps determine the patients risk for developing the disease. Colposcopy is used to select women for biopsy. Expert pathologists examine the biopsied cervical epithelial tissue under a microscope. The examination can take a long time and is prone to error and often results in high inter- and intra-observer variability in outcomes. We propose a novel image analysis toolbox that can automate CIN diagnosis using whole slide image (digitized biopsies) of cervical tissue samples. The toolbox is built as a four-step deep learning model that detects the epithelium regions, segments the detected epithelial portions, analyzes local vertical segment regions, and finally classifies each epithelium block with localized attention. We propose an epithelium detection network in this study and make use of our earlier research on epithelium segmentation and CIN classification to complete the design of the end-to-end CIN diagnosis toolbox. The results show that automated epithelium detection and segmentation for CIN classification yields comparable results to manually segmented epithelium CIN classification. This highlights the potential as a tool for automated digitized histology slide image analysis to assist expert pathologists.",1
"Bukhari, S. U. K.; Asmara, S.; Bokhari, S. K. A.; Hussain, S. S.; Armaghan, S. U.; Shah, S. S. H.",2020,The Histological Diagnosis of Colonic Adenocarcinoma by Applying Partial Self Supervised Learning,Pathology,The Histological Diagnosis of Colonic Adenocarcinoma by Applying Partial Self Supervised Learning,"Bukhari, S. U. K.; Asmara, S.; Bokhari, S. K. A.; Hussain, S. S.; Armaghan, S. U.; Shah, S. S. H.",Pathology,2020-08-17 00:00:00 UTC,"BackgroundThe cancer of colon is one of the important cause of morbidity and mortality in adults. For the management of colonic carcinoma, the definitive diagnosis depends on the histological examination of biopsy specimens. With the development of whole slide imaging, the convolutional neural networks are being applied to diagnose colonic carcinoma by digital image analysis.

AimThe main aim of the current study is to assess the application of deep learning for the histopathological diagnosis of colonic adenocarcinoma by analysing the digitized pathology images.

Materials & MethodsThe images of colonic adenocarcinoma and non neoplastic colonic tissue have been acquired from the two datasets. The first dataset contains ten thousand images which were used to train and validate the convolutional neural network (CNN) architecture. From the second dataset (Colorectal Adenocarcinoma Gland (CRAG) Dataset) 40% of the images were used as a train set while 60% of the images were used as test dataset. Two histopathologists also evaluated these images. In this study, three variants of CNN (ResNet-18, ResNet-34 and ResNet-50) have been employed to evaluate the images.

ResultsIn the present study, three CNN architectures(ResNet-18, ResNet-30, and ResNet-50) were applied for the classification of digitized images of colonic tissue. The accuracy (93.91%) of ResNet-50 was the highest which is followed by ResNet-30 and ResNet-18 with the accuracy of 93.04% each.

ConclusionBased on the findings of the present study and analysis of previously reported series, the development of computer aided technology to evaluate the surgical specimens for the diagnosis of malignant tumors could provide a significant assistance to pathologists.",10.1101/2020.08.15.20175760,virology-deep-learning.xlsx,"The Histological Diagnosis of Colonic Adenocarcinoma by Applying Partial Self Supervised Learning BackgroundThe cancer of colon is one of the important cause of morbidity and mortality in adults. For the management of colonic carcinoma, the definitive diagnosis depends on the histological examination of biopsy specimens. With the development of whole slide imaging, the convolutional neural networks are being applied to diagnose colonic carcinoma by digital image analysis.

AimThe main aim of the current study is to assess the application of deep learning for the histopathological diagnosis of colonic adenocarcinoma by analysing the digitized pathology images.

Materials & MethodsThe images of colonic adenocarcinoma and non neoplastic colonic tissue have been acquired from the two datasets. The first dataset contains ten thousand images which were used to train and validate the convolutional neural network (CNN) architecture. From the second dataset (Colorectal Adenocarcinoma Gland (CRAG) Dataset) 40% of the images were used as a train set while 60% of the images were used as test dataset. Two histopathologists also evaluated these images. In this study, three variants of CNN (ResNet-18, ResNet-34 and ResNet-50) have been employed to evaluate the images.

ResultsIn the present study, three CNN architectures(ResNet-18, ResNet-30, and ResNet-50) were applied for the classification of digitized images of colonic tissue. The accuracy (93.91%) of ResNet-50 was the highest which is followed by ResNet-30 and ResNet-18 with the accuracy of 93.04% each.

ConclusionBased on the findings of the present study and analysis of previously reported series, the development of computer aided technology to evaluate the surgical specimens for the diagnosis of malignant tumors could provide a significant assistance to pathologists.",0
"Yamashita, R.; Long, J.; Saleem, A.; Rubin, D. L.; Shen, J.",2020,Deep learning predicts post-surgical recurrence of hepatocellular carcinoma from digital whole-slide images,Pathology,Deep learning predicts post-surgical recurrence of hepatocellular carcinoma from digital whole-slide images,"Yamashita, R.; Long, J.; Saleem, A.; Rubin, D. L.; Shen, J.",Pathology,2020-08-25 00:00:00 UTC,"Recurrence risk stratification of patients undergoing primary surgical resection for hepatocellular carcinoma (HCC) is an area of active investigation, and several staging systems have been proposed to optimize treatment strategies. However, as many as 70% of patients still have tumor recurrence at 5 years post-surgery. Routine hematoxylin and eosin (H&E)-stained histopathology slides may contain morphologic features associated with tumor recurrence. In this study, we developed and independently validated a deep learning-based system (HCC-SurvNet) that provides risk scores for disease recurrence after primary surgical resection, directly from H&E-stained digital whole-slide images of formalin-fixed, paraffin embedded liver resections. Our model achieved a concordance index of 0.724 on a held-out internal test set of 53 patients, and 0.683 on an external test set of 198 patients, exceeding the performance of standard staging using the American Joint Committee on Cancer (AJCC)/International Union against Cancer (UICC) Tumor-Node-Metastasis (TNM) classification system, on both the internal and external test cohorts (p = 0.018 and 0.025, respectively). We observed statistically significant differences in the survival distributions between low- and high-risk subgroups, as stratified by the risk scores predicted by HCC-SurvNet on both the internal and external test sets (log-rank p-value: 0.0013 and < 0.0001, respectively). On multivariable Cox proportional hazards analysis, the risk score was an independent risk factor for post-surgical recurrence, on both the internal (hazard ratio (HR) = 7.44 (95% CI: 1.60, 34.6), p = 0.0105) and external (HR = 2.37 (95% CI: 1.27, 4.43), p = 0.0069) test sets. Our results suggest that deep learning-based models can provide recurrence risk scores which may augment current patient stratification methods, and help refine the clinical management of patients undergoing primary surgical resection for HCC.",10.1101/2020.08.22.20179952,virology-deep-learning.xlsx,"Deep learning predicts post-surgical recurrence of hepatocellular carcinoma from digital whole-slide images Recurrence risk stratification of patients undergoing primary surgical resection for hepatocellular carcinoma (HCC) is an area of active investigation, and several staging systems have been proposed to optimize treatment strategies. However, as many as 70% of patients still have tumor recurrence at 5 years post-surgery. Routine hematoxylin and eosin (H&E)-stained histopathology slides may contain morphologic features associated with tumor recurrence. In this study, we developed and independently validated a deep learning-based system (HCC-SurvNet) that provides risk scores for disease recurrence after primary surgical resection, directly from H&E-stained digital whole-slide images of formalin-fixed, paraffin embedded liver resections. Our model achieved a concordance index of 0.724 on a held-out internal test set of 53 patients, and 0.683 on an external test set of 198 patients, exceeding the performance of standard staging using the American Joint Committee on Cancer (AJCC)/International Union against Cancer (UICC) Tumor-Node-Metastasis (TNM) classification system, on both the internal and external test cohorts (p = 0.018 and 0.025, respectively). We observed statistically significant differences in the survival distributions between low- and high-risk subgroups, as stratified by the risk scores predicted by HCC-SurvNet on both the internal and external test sets (log-rank p-value: 0.0013 and < 0.0001, respectively). On multivariable Cox proportional hazards analysis, the risk score was an independent risk factor for post-surgical recurrence, on both the internal (hazard ratio (HR) = 7.44 (95% CI: 1.60, 34.6), p = 0.0105) and external (HR = 2.37 (95% CI: 1.27, 4.43), p = 0.0069) test sets. Our results suggest that deep learning-based models can provide recurrence risk scores which may augment current patient stratification methods, and help refine the clinical management of patients undergoing primary surgical resection for HCC.",0
"Tang, H.; Sun, N.; Shen, S.",2020,Improving generalization of deep learning models for diagnostic pathology by increasing variability in training data: experiments on osteosarcoma subtypes,Pathology,Improving generalization of deep learning models for diagnostic pathology by increasing variability in training data: experiments on osteosarcoma subtypes,"Tang, H.; Sun, N.; Shen, S.",Pathology,2020-09-18 00:00:00 UTC,"Artificial intelligence (AI) has an emerging progress in diagnostic pathology. A large number of studies of applying deep learning models to histopathological images have been published in recent years. While many studies claim high accuracies, they may fall into the pitfalls of overfitting and lack of generalization due to the high variability of the histopathological images. We use the example of Osteosarcoma to illustrate the pitfalls and how the addition of model input variability can help improve model performance. We use the publicly available osteosarcoma dataset to retrain a previously published classification model for osteosarcoma. We partition the same set of images into the training and testing datasets differently than the original study: the test dataset consists of images from one patient while the training dataset consists images of all other patients. The performance of the model on the test set using the new partition schema declines dramatically, indicating a lack of model generalization and overfitting. We also show the influence of training data variability on model performance by collecting a minimal dataset of 10 osteosarcoma subtypes as well as benign tissues and benign bone tumors of differentiation. We show the additions of more and more subtypes into the training data step by step under the same model schema yield a series of coherent models with increasing performances. In conclusion, we bring forward data preprocessing and collection tactics for histopathological images of high variability to avoid the pitfalls of overfitting and build deep learning models of higher generalization abilities.",10.1101/2020.09.10.20192294,virology-deep-learning.xlsx,"Improving generalization of deep learning models for diagnostic pathology by increasing variability in training data: experiments on osteosarcoma subtypes Artificial intelligence (AI) has an emerging progress in diagnostic pathology. A large number of studies of applying deep learning models to histopathological images have been published in recent years. While many studies claim high accuracies, they may fall into the pitfalls of overfitting and lack of generalization due to the high variability of the histopathological images. We use the example of Osteosarcoma to illustrate the pitfalls and how the addition of model input variability can help improve model performance. We use the publicly available osteosarcoma dataset to retrain a previously published classification model for osteosarcoma. We partition the same set of images into the training and testing datasets differently than the original study: the test dataset consists of images from one patient while the training dataset consists images of all other patients. The performance of the model on the test set using the new partition schema declines dramatically, indicating a lack of model generalization and overfitting. We also show the influence of training data variability on model performance by collecting a minimal dataset of 10 osteosarcoma subtypes as well as benign tissues and benign bone tumors of differentiation. We show the additions of more and more subtypes into the training data step by step under the same model schema yield a series of coherent models with increasing performances. In conclusion, we bring forward data preprocessing and collection tactics for histopathological images of high variability to avoid the pitfalls of overfitting and build deep learning models of higher generalization abilities.",0
"Bhouri, M. A.; Costabal, F. S.; Wang, H.; Linka, K.; Peirlinck, M.; Kuhl, E.; Perdikaris, P.",2020,COVID-19 dynamics across the US: A deep learning study of human mobility and social behavior,Epidemiology,COVID-19 dynamics across the US: A deep learning study of human mobility and social behavior,"Bhouri, M. A.; Costabal, F. S.; Wang, H.; Linka, K.; Peirlinck, M.; Kuhl, E.; Perdikaris, P.",Epidemiology,2020-09-23 00:00:00 UTC,"This paper presents a deep learning framework for epidemiology system identification from noisy and sparse observations with quantified uncertainty. The proposed approach employs an ensemble of deep neural networks to infer the time-dependent reproduction number of an infectious disease by formulating a tensor-based multi-step loss function that allows us to efficiently calibrate the model on multiple observed trajectories. The method is applied to a mobility and social behavior-based SEIR model of COVID-19 spread. The model is trained on Google and Unacast mobility data spanning a period of 66 days, and is able to yield accurate future forecasts of COVID-19 spread in 203 US counties within a time-window of 15 days. Strikingly, a sensitivity analysis that assesses the importance of different mobility and social behavior parameters reveals that attendance of close places, including workplaces, residential, and retail and recreational locations, has the largest impact on the basic reproduction number. The model enables us to rapidly probe and quantify the effects of government interventions, such as lock-down and re-opening strategies. Taken together, the proposed framework provides a robust workflow for data-driven epidemiology model discovery under uncertainty and produces probabilistic forecasts for the evolution of a pandemic that can judiciously inform policy and decision making. All codes and data accompanying this manuscript are available at https://github.com/PredictiveIntelligenceLab/DeepCOVID19.",10.1101/2020.09.20.20198432,virology-deep-learning.xlsx,"COVID-19 dynamics across the US: A deep learning study of human mobility and social behavior This paper presents a deep learning framework for epidemiology system identification from noisy and sparse observations with quantified uncertainty. The proposed approach employs an ensemble of deep neural networks to infer the time-dependent reproduction number of an infectious disease by formulating a tensor-based multi-step loss function that allows us to efficiently calibrate the model on multiple observed trajectories. The method is applied to a mobility and social behavior-based SEIR model of COVID-19 spread. The model is trained on Google and Unacast mobility data spanning a period of 66 days, and is able to yield accurate future forecasts of COVID-19 spread in 203 US counties within a time-window of 15 days. Strikingly, a sensitivity analysis that assesses the importance of different mobility and social behavior parameters reveals that attendance of close places, including workplaces, residential, and retail and recreational locations, has the largest impact on the basic reproduction number. The model enables us to rapidly probe and quantify the effects of government interventions, such as lock-down and re-opening strategies. Taken together, the proposed framework provides a robust workflow for data-driven epidemiology model discovery under uncertainty and produces probabilistic forecasts for the evolution of a pandemic that can judiciously inform policy and decision making. All codes and data accompanying this manuscript are available at https://github.com/PredictiveIntelligenceLab/DeepCOVID19.",1
"Rodriguez, A.; Tabassum, A.; Cui, J.; Xie, J.; Ho, J.; Agarwal, P.; Adhikari, B.; Prakash, B. A.",2021,DeepCOVID: An Operational Deep Learning-driven Framework for Explainable Real-time COVID-19 Forecasting,Epidemiology,DeepCOVID: An Operational Deep Learning-driven Framework for Explainable Real-time COVID-19 Forecasting,"Rodriguez, A.; Tabassum, A.; Cui, J.; Xie, J.; Ho, J.; Agarwal, P.; Adhikari, B.; Prakash, B. A.",Epidemiology,2021-03-21 00:00:00 UTC,"How do we forecast an emerging pandemic in real time in a purely data-driven manner? How to leverage rich heterogeneous data based on various signals such as mobility, testing, and/or disease exposure for forecasting? How to handle noisy data and generate uncertainties in the forecast? In this paper, we present DO_SCPLOWEEPC_SCPLOWCO_SCPLOWOVIDC_SCPLOW, an operational deep learning frame-work designed for real-time COVID-19 forecasting. DO_SCPLOWEEPC_SCPLOW-CO_SCPLOWOVIDC_SCPLOW works well with sparse data and can handle noisy heterogeneous data signals by propagating the uncertainty from the data in a principled manner resulting in meaningful uncertainties in the forecast. The deployed framework also consists of modules for both real-time and retrospective exploratory analysis to enable interpretation of the forecasts. Results from real-time predictions (featured on the CDC website and FiveThirtyEight.com) since April 2020 indicates that our approach is competitive among the methods in the COVID-19 Forecast Hub, especially for short-term predictions.",10.1101/2020.09.28.20203109,virology-deep-learning.xlsx,"DeepCOVID: An Operational Deep Learning-driven Framework for Explainable Real-time COVID-19 Forecasting How do we forecast an emerging pandemic in real time in a purely data-driven manner? How to leverage rich heterogeneous data based on various signals such as mobility, testing, and/or disease exposure for forecasting? How to handle noisy data and generate uncertainties in the forecast? In this paper, we present DO_SCPLOWEEPC_SCPLOWCO_SCPLOWOVIDC_SCPLOW, an operational deep learning frame-work designed for real-time COVID-19 forecasting. DO_SCPLOWEEPC_SCPLOW-CO_SCPLOWOVIDC_SCPLOW works well with sparse data and can handle noisy heterogeneous data signals by propagating the uncertainty from the data in a principled manner resulting in meaningful uncertainties in the forecast. The deployed framework also consists of modules for both real-time and retrospective exploratory analysis to enable interpretation of the forecasts. Results from real-time predictions (featured on the CDC website and FiveThirtyEight.com) since April 2020 indicates that our approach is competitive among the methods in the COVID-19 Forecast Hub, especially for short-term predictions.",1
"Arntfield, R.; Vanberlo, B.; Alaifan, T.; Phelps, N.; White, M.; Chaudhary, R.; Ho, J.; Wu, D.",2020,Development of a deep learning classifier to accurately distinguish COVID-19 from look-a-like pathology on lung ultrasound,Respiratory Medicine,Development of a deep learning classifier to accurately distinguish COVID-19 from look-a-like pathology on lung ultrasound,"Arntfield, R.; Vanberlo, B.; Alaifan, T.; Phelps, N.; White, M.; Chaudhary, R.; Ho, J.; Wu, D.",Respiratory Medicine,2020-10-22 00:00:00 UTC,"ObjectivesLung ultrasound (LUS) is a portable, low cost respiratory imaging tool but is challenged by user dependence and lack of diagnostic specificity. It is unknown whether the advantages of LUS implementation could be paired with deep learning techniques to match or exceed human-level, diagnostic specificity among similar appearing, pathological LUS images.

DesignA convolutional neural network was trained on LUS images with B lines of different etiologies. CNN diagnostic performance, as validated using a 10% data holdback set was compared to surveyed LUS-competent physicians.

SettingTwo tertiary Canadian hospitals.

Participants600 LUS videos (121,381 frames) of B lines from 243 distinct patients with either 1) COVID-19, Non-COVID acute respiratory distress syndrome (NCOVID) and 3) Hydrostatic pulmonary edema (HPE).

ResultsThe trained CNN performance on the independent dataset showed an ability to discriminate between COVID (AUC 1.0), NCOVID (AUC 0.934) and HPE (AUC 1.0) pathologies. This was significantly better than physician ability (AUCs of 0.697, 0.704, 0.967 for the COVID, NCOVID and HPE classes, respectively), p < 0.01.

ConclusionsA deep learning model can distinguish similar appearing LUS pathology, including COVID-19, that cannot be distinguished by humans. The performance gap between humans and the model suggests that subvisible biomarkers within ultrasound images could exist and multi-center research is merited.",10.1101/2020.10.13.20212258,virology-deep-learning.xlsx,"Development of a deep learning classifier to accurately distinguish COVID-19 from look-a-like pathology on lung ultrasound ObjectivesLung ultrasound (LUS) is a portable, low cost respiratory imaging tool but is challenged by user dependence and lack of diagnostic specificity. It is unknown whether the advantages of LUS implementation could be paired with deep learning techniques to match or exceed human-level, diagnostic specificity among similar appearing, pathological LUS images.

DesignA convolutional neural network was trained on LUS images with B lines of different etiologies. CNN diagnostic performance, as validated using a 10% data holdback set was compared to surveyed LUS-competent physicians.

SettingTwo tertiary Canadian hospitals.

Participants600 LUS videos (121,381 frames) of B lines from 243 distinct patients with either 1) COVID-19, Non-COVID acute respiratory distress syndrome (NCOVID) and 3) Hydrostatic pulmonary edema (HPE).

ResultsThe trained CNN performance on the independent dataset showed an ability to discriminate between COVID (AUC 1.0), NCOVID (AUC 0.934) and HPE (AUC 1.0) pathologies. This was significantly better than physician ability (AUCs of 0.697, 0.704, 0.967 for the COVID, NCOVID and HPE classes, respectively), p < 0.01.

ConclusionsA deep learning model can distinguish similar appearing LUS pathology, including COVID-19, that cannot be distinguished by humans. The performance gap between humans and the model suggests that subvisible biomarkers within ultrasound images could exist and multi-center research is merited.",1
"Nabi, K. N.",2021,Forecasting COVID-19 cases: A comparative analysis between Recurrent and Convolutional Neural Networks,Epidemiology,Forecasting COVID-19 cases: A comparative analysis between Recurrent and Convolutional Neural Networks,"Nabi, K. N.",Epidemiology,2021-02-20 00:00:00 UTC,"When the entire world is waiting restlessly for a safe and effective COVID-19 vaccine that could soon become a reality, numerous countries around the globe are grappling with unprecedented surges of new COVID-19 cases. As the number of new cases is skyrocketing, pandemic fatigue and public apathy towards different intervention strategies are posing new challenges to the government officials to combat the pandemic. Henceforth, it is indispensable for the government officials to understand the future dynamics of COVID-19 flawlessly in order to develop strategic preparedness and resilient response planning. In light of the above circumstances, probable future outbreak scenarios in Brazil, Russia and the United kingdom have been sketched in this study with the help of four deep learning models: long short term memory (LSTM), gated recurrent unit (GRU), convolutional neural network (CNN) and multivariate convolutional neural network (MCNN). In our analysis, CNN algorithm has outperformed other deep learning models in terms of validation accuracy and forecasting consistency. It has been unearthed in our study that CNN can provide robust long term forecasting results in time series analysis due to its capability of essential features learning, distortion invariance and temporal dependence learning. However, the prediction accuracy of LSTM algorithm has been found to be poor as it tries to discover seasonality and periodic intervals from any time series dataset, which were absent in our studied countries. Our study has highlighted the promising validation of using convolutional neural networks instead of recurrent neural networks when it comes to forecasting with very few features and less amount of historical data.",10.1101/2020.11.28.20240259,virology-deep-learning.xlsx,"Forecasting COVID-19 cases: A comparative analysis between Recurrent and Convolutional Neural Networks When the entire world is waiting restlessly for a safe and effective COVID-19 vaccine that could soon become a reality, numerous countries around the globe are grappling with unprecedented surges of new COVID-19 cases. As the number of new cases is skyrocketing, pandemic fatigue and public apathy towards different intervention strategies are posing new challenges to the government officials to combat the pandemic. Henceforth, it is indispensable for the government officials to understand the future dynamics of COVID-19 flawlessly in order to develop strategic preparedness and resilient response planning. In light of the above circumstances, probable future outbreak scenarios in Brazil, Russia and the United kingdom have been sketched in this study with the help of four deep learning models: long short term memory (LSTM), gated recurrent unit (GRU), convolutional neural network (CNN) and multivariate convolutional neural network (MCNN). In our analysis, CNN algorithm has outperformed other deep learning models in terms of validation accuracy and forecasting consistency. It has been unearthed in our study that CNN can provide robust long term forecasting results in time series analysis due to its capability of essential features learning, distortion invariance and temporal dependence learning. However, the prediction accuracy of LSTM algorithm has been found to be poor as it tries to discover seasonality and periodic intervals from any time series dataset, which were absent in our studied countries. Our study has highlighted the promising validation of using convolutional neural networks instead of recurrent neural networks when it comes to forecasting with very few features and less amount of historical data.",1
"Bilal, M.; Raza, S. E. A.; Azam, A.; Graham, S.; Ilyas, M.; Cree, I. A.; Snead, D.; Minhas, F.; Rajpoot, N. M.",2021,Novel deep learning algorithm predicts the status of molecular pathways and key mutations in colorectal cancer from routine histology images,Pathology,Novel deep learning algorithm predicts the status of molecular pathways and key mutations in colorectal cancer from routine histology images,"Bilal, M.; Raza, S. E. A.; Azam, A.; Graham, S.; Ilyas, M.; Cree, I. A.; Snead, D.; Minhas, F.; Rajpoot, N. M.",Pathology,2021-02-04 00:00:00 UTC,"BackgroundDetermining molecular pathways involved in the development of colorectal cancer (CRC) and knowing the status of key mutations are crucial for deciding optimal target therapy. The goal of this study is to explore machine learning to predict the status of the three main CRC molecular pathways - microsatellite instability (MSI), chromosomal instability (CIN), CpG island methylator phenotype (CIMP) - and to detect BRAF and TP53 mutations as well as to predict hypermutated (HM) CRC tumors from whole-slide images (WSIs) of colorectal cancer (CRC) slides stained with Hematoxylin and Eosin (H&E).

MethodsWe propose a novel iterative draw-and-rank sampling (IDaRS) algorithm to select representative sub-images or tiles from a WSI given a single WSI-level label, without needing any detailed annotations at the cell or region levels. IDaRS is used to train a deep convolutional network for predicting key molecular parameters in CRC (in particular, prediction of HM tumors and the status of three main CRC molecular pathways - MSI, CIN, CIMP - as well as the detection of two key mutations, BRAF and TP53) from digitized images of routine H&E stained tissue slides of CRC patients (n=497 for TCGA cohort and n=47 cases for the Pathology AI Platform or PAIP cohort). Visual fields most predictive of each pathway and HM tumors identified by IDaRS are analyzed for verification of known histological features for the first time to reveal novel histological features. This is achieved by systematic, data-driven analysis of the cellular composition of strongly predictive tiles.

FindingsIDaRS yields high prediction accuracy for prediction of the three main CRC genetic pathways and key mutations by deep learning based analysis of the WSIs of H&E stained slides. It achieves the state-of-the-art AUROC values of 0.90, 0.83, and 0.81 for prediction of the status of MSI, CIN, and HM tumors for the TCGA cohort, which is significantly higher than any other currently published methods on that cohort. We also report prediction of status of CIMP pathway (CIMP-High and CIMP-Low) from H&E slides, with an AUROC of 0.79. We analyzed key discriminative histological features associated with HM tumors and each molecular pathway in a data-driven manner, via an automated quantitative analysis of the cellular composition of tiles strongly predictive of the corresponding molecular status. A key feature of the proposed method is that it enables a systematic and data-driven analysis of the cellular composition of image tiles strongly predictive of the various molecular parameters. We found that relatively high proportion of tumor infiltrating lymphocytes and necrosis are found to be strongly associated with HM and MSI, and moderately associated with CIMP-H and genome-stable (GS) cases, whereas relatively high proportions of neoplastic epithelial type 2 (NEP2), mesenchymal and neoplastic epithelial type 1 (NEP1) cells are found to be associated with CIN cases.

InterpretationAutomated prediction of genetic pathways and key mutations from image analysis of simple H&E stained sections with a high accuracy can provide time and cost-effective decision support. This work shows that a deep learning algorithm can mine both visually recognizable as well as sub-visual histological patterns associated with molecular pathways and key mutations in CRC in a data-driven manner.

FundingThis study was funded by the UK Medical Research Council (award MR/P015476/1).",10.1101/2021.01.19.21250122,virology-deep-learning.xlsx,"Novel deep learning algorithm predicts the status of molecular pathways and key mutations in colorectal cancer from routine histology images BackgroundDetermining molecular pathways involved in the development of colorectal cancer (CRC) and knowing the status of key mutations are crucial for deciding optimal target therapy. The goal of this study is to explore machine learning to predict the status of the three main CRC molecular pathways - microsatellite instability (MSI), chromosomal instability (CIN), CpG island methylator phenotype (CIMP) - and to detect BRAF and TP53 mutations as well as to predict hypermutated (HM) CRC tumors from whole-slide images (WSIs) of colorectal cancer (CRC) slides stained with Hematoxylin and Eosin (H&E).

MethodsWe propose a novel iterative draw-and-rank sampling (IDaRS) algorithm to select representative sub-images or tiles from a WSI given a single WSI-level label, without needing any detailed annotations at the cell or region levels. IDaRS is used to train a deep convolutional network for predicting key molecular parameters in CRC (in particular, prediction of HM tumors and the status of three main CRC molecular pathways - MSI, CIN, CIMP - as well as the detection of two key mutations, BRAF and TP53) from digitized images of routine H&E stained tissue slides of CRC patients (n=497 for TCGA cohort and n=47 cases for the Pathology AI Platform or PAIP cohort). Visual fields most predictive of each pathway and HM tumors identified by IDaRS are analyzed for verification of known histological features for the first time to reveal novel histological features. This is achieved by systematic, data-driven analysis of the cellular composition of strongly predictive tiles.

FindingsIDaRS yields high prediction accuracy for prediction of the three main CRC genetic pathways and key mutations by deep learning based analysis of the WSIs of H&E stained slides. It achieves the state-of-the-art AUROC values of 0.90, 0.83, and 0.81 for prediction of the status of MSI, CIN, and HM tumors for the TCGA cohort, which is significantly higher than any other currently published methods on that cohort. We also report prediction of status of CIMP pathway (CIMP-High and CIMP-Low) from H&E slides, with an AUROC of 0.79. We analyzed key discriminative histological features associated with HM tumors and each molecular pathway in a data-driven manner, via an automated quantitative analysis of the cellular composition of tiles strongly predictive of the corresponding molecular status. A key feature of the proposed method is that it enables a systematic and data-driven analysis of the cellular composition of image tiles strongly predictive of the various molecular parameters. We found that relatively high proportion of tumor infiltrating lymphocytes and necrosis are found to be strongly associated with HM and MSI, and moderately associated with CIMP-H and genome-stable (GS) cases, whereas relatively high proportions of neoplastic epithelial type 2 (NEP2), mesenchymal and neoplastic epithelial type 1 (NEP1) cells are found to be associated with CIN cases.

InterpretationAutomated prediction of genetic pathways and key mutations from image analysis of simple H&E stained sections with a high accuracy can provide time and cost-effective decision support. This work shows that a deep learning algorithm can mine both visually recognizable as well as sub-visual histological patterns associated with molecular pathways and key mutations in CRC in a data-driven manner.

FundingThis study was funded by the UK Medical Research Council (award MR/P015476/1).",0
"Gialluisi, A.; Di Castelnuovo, A.; Costanzo, S.; Bonaccio, M.; Persichillo, M.; Magnacca, S.; De Curtis, A.; Cerletti, C.; Donati, M. B.; De Gaetano, G.; Capobianco, E.; Iacoviello, L.",2021,"Exploring domains, clinical implications and environmental associations of a deep learning marker of biological ageing",Epidemiology,"Exploring domains, clinical implications and environmental associations of a deep learning marker of biological ageing","Gialluisi, A.; Di Castelnuovo, A.; Costanzo, S.; Bonaccio, M.; Persichillo, M.; Magnacca, S.; De Curtis, A.; Cerletti, C.; Donati, M. B.; De Gaetano, G.; Capobianco, E.; Iacoviello, L.",Epidemiology,2021-01-26 00:00:00 UTC,"Deep Neural Networks (DNN) have been recently developed for the estimation of Biological Age (BA), the hypothetical underlying age of an organism, which can differ from its chronological age (CA). Although promising, these population-specific algorithms warrant further characterization and validation, since their biological, clinical and environmental correlates remain largely unexplored.

Here, an accurate DNN was trained to compute BA based on 36 circulating biomarkers in an Italian population (N=23,858; age[&ge;]35 years; 51.7% women). This estimate was heavily influenced by markers of metabolic, heart, kidney and liver function. The resulting {Delta}age (BA-CA) significantly predicted mortality and hospitalization risk for all and specific causes. Slowed biological aging ({Delta}age<0) was associated with higher physical and mental wellbeing, healthy lifestyles (e.g. adherence to Mediterranean diet) and higher socioeconomic status (educational attainment, household income and occupational status), while accelerated aging ({Delta}age>0) was associated with smoking and obesity. Together, lifestyles and socioeconomic variables explained {square}48% of the total variance in {Delta}age, potentially suggesting the existence of a genetic basis.

These findings validate blood-based biological aging as a marker of public health in adult Italians and provide a robust body of knowledge on its biological architecture, clinical implications and potential environmental influences.",10.1101/2021.01.22.21250338,virology-deep-learning.xlsx,"Exploring domains, clinical implications and environmental associations of a deep learning marker of biological ageing Deep Neural Networks (DNN) have been recently developed for the estimation of Biological Age (BA), the hypothetical underlying age of an organism, which can differ from its chronological age (CA). Although promising, these population-specific algorithms warrant further characterization and validation, since their biological, clinical and environmental correlates remain largely unexplored.

Here, an accurate DNN was trained to compute BA based on 36 circulating biomarkers in an Italian population (N=23,858; age[&ge;]35 years; 51.7% women). This estimate was heavily influenced by markers of metabolic, heart, kidney and liver function. The resulting {Delta}age (BA-CA) significantly predicted mortality and hospitalization risk for all and specific causes. Slowed biological aging ({Delta}age<0) was associated with higher physical and mental wellbeing, healthy lifestyles (e.g. adherence to Mediterranean diet) and higher socioeconomic status (educational attainment, household income and occupational status), while accelerated aging ({Delta}age>0) was associated with smoking and obesity. Together, lifestyles and socioeconomic variables explained {square}48% of the total variance in {Delta}age, potentially suggesting the existence of a genetic basis.

These findings validate blood-based biological aging as a marker of public health in adult Italians and provide a robust body of knowledge on its biological architecture, clinical implications and potential environmental influences.",0
"Paul, A.; Bhattacharjee, J. K.; Pal, A.; Chakraborty, S.",2021,Emergence of universality in the transmission dynamics of COVID-19,Epidemiology,Emergence of universality in the transmission dynamics of COVID-19,"Paul, A.; Bhattacharjee, J. K.; Pal, A.; Chakraborty, S.",Epidemiology,2021-02-03 00:00:00 UTC,"The complexities involved in modeling the transmission dynamics of COVID-19 has been a major roadblock in achieving predictability in the spread and containment of the disease. In addition to understanding the modes of transmission, the effectiveness of the mitigation methods also needs to be built into any effective model for making such predictions. We show that such complexities can be circumvented by appealing to scaling principles which lead to the emergence of universality in the transmission dynamics of the disease. The ensuing data collapse renders the transmission dynamics largely independent of geopolitical variations, the effectiveness of various mitigation strategies, population demographics, etc. We propose a simple two-parameter model--the Blue Sky model--and show that one class of transmission dynamics can be explained by a solution that lives at the edge of a blue sky bifurcation. In addition, the data collapse leads to an enhanced degree of predictability in the disease spread for several geographical scales which can also be realized in a model-independent manner as we show using a deep neural network. The methodology adopted in this work can potentially be applied to the transmission of other infectious diseases and new universality classes may be found. The predictability in transmission dynamics and the simplicity of our methodology can help in building policies for exit strategies and mitigation methods during a pandemic.",10.1101/2021.01.29.21250750,virology-deep-learning.xlsx,"Emergence of universality in the transmission dynamics of COVID-19 The complexities involved in modeling the transmission dynamics of COVID-19 has been a major roadblock in achieving predictability in the spread and containment of the disease. In addition to understanding the modes of transmission, the effectiveness of the mitigation methods also needs to be built into any effective model for making such predictions. We show that such complexities can be circumvented by appealing to scaling principles which lead to the emergence of universality in the transmission dynamics of the disease. The ensuing data collapse renders the transmission dynamics largely independent of geopolitical variations, the effectiveness of various mitigation strategies, population demographics, etc. We propose a simple two-parameter model--the Blue Sky model--and show that one class of transmission dynamics can be explained by a solution that lives at the edge of a blue sky bifurcation. In addition, the data collapse leads to an enhanced degree of predictability in the disease spread for several geographical scales which can also be realized in a model-independent manner as we show using a deep neural network. The methodology adopted in this work can potentially be applied to the transmission of other infectious diseases and new universality classes may be found. The predictability in transmission dynamics and the simplicity of our methodology can help in building policies for exit strategies and mitigation methods during a pandemic.",1
"Chatrian, A.; Colling, R.; Browning, L.; Alham, N. K.; Sirinukunwattana, K.; Malacrino, S.; Haghighat, M.; Aberdeen, A.; Monks, A.; Moxley-Wyles, B.; Rakha, E.; Snead, D. R.; Rittscher, J.; Verrill, C.",2021,Artificial Intelligence for Advance Requesting of Immunohistochemistry in Diagnostically Uncertain Prostate Biopsies,Pathology,Artificial Intelligence for Advance Requesting of Immunohistochemistry in Diagnostically Uncertain Prostate Biopsies,"Chatrian, A.; Colling, R.; Browning, L.; Alham, N. K.; Sirinukunwattana, K.; Malacrino, S.; Haghighat, M.; Aberdeen, A.; Monks, A.; Moxley-Wyles, B.; Rakha, E.; Snead, D. R.; Rittscher, J.; Verrill, C.",Pathology,2021-02-26 00:00:00 UTC,"The use of immunohistochemistry in the reporting of prostate biopsies is an important adjunct when the diagnosis is not definite on haematoxylin and eosin (H&E) morphology alone. The process is however inherently inefficient with delays while waiting for pathologist review to make the request and duplicated effort reviewing a case more than once. In this study, we aimed to capture the workflow implications of immunohistochemistry requests and demonstrate a novel artificial intelligence tool to identify cases in which immunohistochemistry (IHC) is required and generate an automated request.

We conducted audits of the workflow for prostate biopsies in order to understand the potential implications of automated immunohistochemistry requesting and collected prospective cases to train a deep neural network algorithm to detect tissue regions that presented ambiguous morphology on whole slide images. These ambiguous foci were selected on the basis of the pathologist requesting immunohistochemistry to aid diagnosis. A gradient boosted trees classifier was then used to make a slide level prediction based on the outputs of the neural network prediction. The algorithm was trained on annotations of 219 immunohistochemistry-requested and 80 control images, and tested by 3-fold cross-validation. Validation was conducted on a separate validation dataset of 212 images.

Non IHC-requested cases were diagnosed in 17.9 minutes on average, while IHC-requested cases took 33.4 minutes over multiple reporting sessions. We estimated 11 minutes could be saved on average per case by automated IHC requesting, by removing duplication of effort. The tool attained 99% accuracy and 0.99 Area Under the Curve (AUC) on the test data. In the validation, the average agreement with pathologists was 0.81, with a mean AUC of 0.80.

We demonstrate the proof-of-principle that an AI tool making automated immunohistochemistry requests could create a significantly leaner workflow and result in pathologist time savings.",10.1101/2021.02.20.21252126,virology-deep-learning.xlsx,"Artificial Intelligence for Advance Requesting of Immunohistochemistry in Diagnostically Uncertain Prostate Biopsies The use of immunohistochemistry in the reporting of prostate biopsies is an important adjunct when the diagnosis is not definite on haematoxylin and eosin (H&E) morphology alone. The process is however inherently inefficient with delays while waiting for pathologist review to make the request and duplicated effort reviewing a case more than once. In this study, we aimed to capture the workflow implications of immunohistochemistry requests and demonstrate a novel artificial intelligence tool to identify cases in which immunohistochemistry (IHC) is required and generate an automated request.

We conducted audits of the workflow for prostate biopsies in order to understand the potential implications of automated immunohistochemistry requesting and collected prospective cases to train a deep neural network algorithm to detect tissue regions that presented ambiguous morphology on whole slide images. These ambiguous foci were selected on the basis of the pathologist requesting immunohistochemistry to aid diagnosis. A gradient boosted trees classifier was then used to make a slide level prediction based on the outputs of the neural network prediction. The algorithm was trained on annotations of 219 immunohistochemistry-requested and 80 control images, and tested by 3-fold cross-validation. Validation was conducted on a separate validation dataset of 212 images.

Non IHC-requested cases were diagnosed in 17.9 minutes on average, while IHC-requested cases took 33.4 minutes over multiple reporting sessions. We estimated 11 minutes could be saved on average per case by automated IHC requesting, by removing duplication of effort. The tool attained 99% accuracy and 0.99 Area Under the Curve (AUC) on the test data. In the validation, the average agreement with pathologists was 0.81, with a mean AUC of 0.80.

We demonstrate the proof-of-principle that an AI tool making automated immunohistochemistry requests could create a significantly leaner workflow and result in pathologist time savings.",0
"Levy, J.; Vattikonda, N.; Haudenschild, C.; Christensen, B.; Vaickus, L.",2021,Comparison of Machine Learning Algorithms for the Prediction of Current Procedural Terminology (CPT) Codes from Pathology Reports,Pathology,Comparison of Machine Learning Algorithms for the Prediction of Current Procedural Terminology (CPT) Codes from Pathology Reports,"Levy, J.; Vattikonda, N.; Haudenschild, C.; Christensen, B.; Vaickus, L.",Pathology,2021-03-13 00:00:00 UTC,"BackgroundPathology reports serve as an auditable trail of a patients clinical narrative containing important free text pertaining to diagnosis, prognosis and specimen processing. Recent works have utilized sophisticated natural language processing (NLP) pipelines which include rule-based or machine learning analytics to uncover patterns from text to inform clinical endpoints and biomarker information. While deep learning methods have come to the forefront of NLP, there have been limited comparisons with the performance of other machine learning methods in extracting key insights for prediction of medical procedure information (Current Procedural Terminology; CPT codes), that informs insurance claims, medical research, and healthcare policy and utilization. Additionally, the utility of combining and ranking information from multiple report subfields as compared to exclusively using the diagnostic field for the prediction of CPT codes and signing pathologist remains unclear.

MethodsAfter passing pathology reports through a preprocessing pipeline, we utilized advanced topic modeling techniques such as UMAP and LDA to identify topics with diagnostic relevance in order to characterize a cohort of 93,039 pathology reports at the Dartmouth-Hitchcock Department of Pathology and Laboratory Medicine (DPLM). We separately compared XGBoost, SVM, and BERT methodologies for prediction of 38 different CPT codes using 5-fold cross validation, using both the diagnostic text only as well as text from all subfields. We performed similar analyses for characterizing text from a group of the twenty pathologists with the most pathology report sign-outs. Finally, we interpreted report and cohort level important words using TF-IDF, Shapley Additive Explanations (SHAP), attention, and integrated gradients.

ResultsWe identified 10 topics for both the diagnostic-only and all-fields text, which pertained to diagnostic and procedural information respectively. The topics were associated with select CPT codes, pathologists and report clusters. Operating on the diagnostic text alone, XGBoost performed similarly to BERT for prediction of CPT codes. When utilizing all report subfields, XGBoost outperformed BERT for prediction of CPT codes, though XGBoost and BERT performed similarly for prediction of signing pathologist. Both XGBoost and BERT outperformed SVM. Utilizing additional subfields of the pathology report increased prediction accuracy for the CPT code and pathologist classification tasks. Misclassification of pathologist was largely subspecialty related. We identified text that is CPT and pathologist specific.

ConclusionsOur approach generated CPT code predictions with an accuracy higher than that reported in previous literature. While diagnostic text is an important information source for NLP pipelines in pathology, additional insights may be extracted from other report subfields. Although deep learning approaches did not outperform XGBoost approaches, they may lend valuable information to pipelines that combine image, text and -omics information. Future resource-saving opportunities exist for utilizing pathology reports to help hospitals detect mis-billing and estimate productivity metrics that pertain to pathologist compensation (RVUs).",10.1101/2021.03.13.21253502,virology-deep-learning.xlsx,"Comparison of Machine Learning Algorithms for the Prediction of Current Procedural Terminology (CPT) Codes from Pathology Reports BackgroundPathology reports serve as an auditable trail of a patients clinical narrative containing important free text pertaining to diagnosis, prognosis and specimen processing. Recent works have utilized sophisticated natural language processing (NLP) pipelines which include rule-based or machine learning analytics to uncover patterns from text to inform clinical endpoints and biomarker information. While deep learning methods have come to the forefront of NLP, there have been limited comparisons with the performance of other machine learning methods in extracting key insights for prediction of medical procedure information (Current Procedural Terminology; CPT codes), that informs insurance claims, medical research, and healthcare policy and utilization. Additionally, the utility of combining and ranking information from multiple report subfields as compared to exclusively using the diagnostic field for the prediction of CPT codes and signing pathologist remains unclear.

MethodsAfter passing pathology reports through a preprocessing pipeline, we utilized advanced topic modeling techniques such as UMAP and LDA to identify topics with diagnostic relevance in order to characterize a cohort of 93,039 pathology reports at the Dartmouth-Hitchcock Department of Pathology and Laboratory Medicine (DPLM). We separately compared XGBoost, SVM, and BERT methodologies for prediction of 38 different CPT codes using 5-fold cross validation, using both the diagnostic text only as well as text from all subfields. We performed similar analyses for characterizing text from a group of the twenty pathologists with the most pathology report sign-outs. Finally, we interpreted report and cohort level important words using TF-IDF, Shapley Additive Explanations (SHAP), attention, and integrated gradients.

ResultsWe identified 10 topics for both the diagnostic-only and all-fields text, which pertained to diagnostic and procedural information respectively. The topics were associated with select CPT codes, pathologists and report clusters. Operating on the diagnostic text alone, XGBoost performed similarly to BERT for prediction of CPT codes. When utilizing all report subfields, XGBoost outperformed BERT for prediction of CPT codes, though XGBoost and BERT performed similarly for prediction of signing pathologist. Both XGBoost and BERT outperformed SVM. Utilizing additional subfields of the pathology report increased prediction accuracy for the CPT code and pathologist classification tasks. Misclassification of pathologist was largely subspecialty related. We identified text that is CPT and pathologist specific.

ConclusionsOur approach generated CPT code predictions with an accuracy higher than that reported in previous literature. While diagnostic text is an important information source for NLP pipelines in pathology, additional insights may be extracted from other report subfields. Although deep learning approaches did not outperform XGBoost approaches, they may lend valuable information to pipelines that combine image, text and -omics information. Future resource-saving opportunities exist for utilizing pathology reports to help hospitals detect mis-billing and estimate productivity metrics that pertain to pathologist compensation (RVUs).",0
"Al-Shawesh, R. A.; Chen, Y. X.",2021,Enhancing Histopathological Colorectal Cancer Image Classification by using Convolutional Neural Network,Pathology,Enhancing Histopathological Colorectal Cancer Image Classification by using Convolutional Neural Network,"Al-Shawesh, R. A.; Chen, Y. X.",Pathology,2021-03-24 00:00:00 UTC,"Colorectal cancer (CRC) also known as bowl cancer is one of the leading death causes worldwide. Early diagnosis has become vital for a successful treatment. Now days with the new advancements in Convolutional Neural networks (CNNs) its possible to classify different images of CRC into different classes. Today It is crucial for physician to take advantage of the new advancements in deep learning, since classification methods are becoming more and more accurate and efficient. In this study, we introduce a method to improve the classification accuracy from previous studies that used the National Center for Tumor diseases (NCT) data sets. We adapt the ResNet-50 model in our experiment to classify the CRC histopathological images. Furthermore, we utilize transfer learning and fine-tunning techniques to improve the accuracy. Our Experiment results show that ResNet_50 network is the best CNN architecture so far for classifying CRC histopathological images on the NCT Biobank open source dataset. In addition to that using transfer learning allow us to obtain 97.7% accuracy on the validation dataset, which is better than all previous results we found in literature.",10.1101/2021.03.17.21253390,virology-deep-learning.xlsx,"Enhancing Histopathological Colorectal Cancer Image Classification by using Convolutional Neural Network Colorectal cancer (CRC) also known as bowl cancer is one of the leading death causes worldwide. Early diagnosis has become vital for a successful treatment. Now days with the new advancements in Convolutional Neural networks (CNNs) its possible to classify different images of CRC into different classes. Today It is crucial for physician to take advantage of the new advancements in deep learning, since classification methods are becoming more and more accurate and efficient. In this study, we introduce a method to improve the classification accuracy from previous studies that used the National Center for Tumor diseases (NCT) data sets. We adapt the ResNet-50 model in our experiment to classify the CRC histopathological images. Furthermore, we utilize transfer learning and fine-tunning techniques to improve the accuracy. Our Experiment results show that ResNet_50 network is the best CNN architecture so far for classifying CRC histopathological images on the NCT Biobank open source dataset. In addition to that using transfer learning allow us to obtain 97.7% accuracy on the validation dataset, which is better than all previous results we found in literature.",0
"Berman, A. G.; Orchard, W. R.; Gehrung, M.; Markowetz, F.",2021,PathML: A unified framework for whole-slide image analysis with deep learning,Pathology,PathML: A unified framework for whole-slide image analysis with deep learning,"Berman, A. G.; Orchard, W. R.; Gehrung, M.; Markowetz, F.",Pathology,2021-07-13 00:00:00 UTC,"The inspection of stained tissue slides by pathologists is essential for the early detection, diagnosis and monitoring of disease. Recently, deep learning methods for the analysis of whole-slide images (WSIs) have shown excellent performance on these tasks, and have the potential to substantially reduce the workload of pathologists. However, successful implementation of deep learning for WSI analysis is complex and requires careful consideration of model hyperparameters, slide and image artefacts, and data augmentation. Here we introduce PathML, a Python library for performing preand post-processing of WSIs, which has been designed to interact with the most widely used deep learning libraries, PyTorch and TensorFlow, thus allowing seamless integration into deep learning workflows. We present the current best practices in deep learning for WSI analysis, and give a step-by-step guide using the PathML framework: from annotating and pre-processing of slides, to implementing neural network architectures, to training and post-processing. PathML provides a unified framework in which deep learning methods for WSI analysis can be developed and applied, thus increasing the accessibility of an important new application of deep learning.",10.1101/2021.07.07.21260138,virology-deep-learning.xlsx,"PathML: A unified framework for whole-slide image analysis with deep learning The inspection of stained tissue slides by pathologists is essential for the early detection, diagnosis and monitoring of disease. Recently, deep learning methods for the analysis of whole-slide images (WSIs) have shown excellent performance on these tasks, and have the potential to substantially reduce the workload of pathologists. However, successful implementation of deep learning for WSI analysis is complex and requires careful consideration of model hyperparameters, slide and image artefacts, and data augmentation. Here we introduce PathML, a Python library for performing preand post-processing of WSIs, which has been designed to interact with the most widely used deep learning libraries, PyTorch and TensorFlow, thus allowing seamless integration into deep learning workflows. We present the current best practices in deep learning for WSI analysis, and give a step-by-step guide using the PathML framework: from annotating and pre-processing of slides, to implementing neural network architectures, to training and post-processing. PathML provides a unified framework in which deep learning methods for WSI analysis can be developed and applied, thus increasing the accessibility of an important new application of deep learning.",0
"Uegami, W.; Bychkov, A.; Ozasa, M.; Uehara, K.; Kataoka, K.; Johkoh, T.; Kondo, Y.; Sakanashi, H.; Fukuoka, J.",2021,MIXTURE of human expertise and deep learning - Developing an explainable model for predicting pathological diagnosis and survival in patients with interstitial lung disease,Pathology,MIXTURE of human expertise and deep learning - Developing an explainable model for predicting pathological diagnosis and survival in patients with interstitial lung disease,"Uegami, W.; Bychkov, A.; Ozasa, M.; Uehara, K.; Kataoka, K.; Johkoh, T.; Kondo, Y.; Sakanashi, H.; Fukuoka, J.",Pathology,2021-07-23 00:00:00 UTC,"Interstitial pneumonia is a heterogeneous disease with a progressive course and poor prognosis, at times even worse than those in the main cancer types. Histopathological examination is crucial for its diagnosis and estimation of prognosis. However, the evaluation strongly depends on the experience of pathologists, and the reproducibility of diagnosis is low.

Herein, we propose MIXTURE (huMan-In-the-loop eXplainable artificial intelligence Through the Use of REcurrent training), a method to develop deep learning models for extracting pathologically significant findings based on an expert pathologists perspective with a small annotation effort. The procedure of MIXTURE consists of three steps as follows. First, we created feature extractors for tiles from whole slide images using self-supervised learning. The similar looking tiles were clustered based on the output features and then pathologists integrated the pathologically synonymous clusters. Using the integrated clusters as labeled data, deep learning models to classify the tiles into pathological findings were created by transfer-learning the feature extractors. We developed three models for different magnifications.

Using these extracted findings, our model was able to predict the diagnosis of usual interstitial pneumonia, a finding suggestive of progressive disease, with high accuracy (AUC 0.90). This high accuracy could not be achieved without the integration of findings by pathologists. The patients predicted as UIP had significantly poorer prognosis (five-year overall survival [OS]: 55.4%) than those predicted as non-UIP (OS: 95.2%). The Cox proportional hazards model for each microscopic finding and prognosis pointed out dense fibrosis, fibroblastic foci, elastosis, and lymphocyte aggregation as independent risk factors. We suggest that MIXTURE may serve as a model approach to different diseases evaluated by medical imaging, including pathology and radiology, and be the prototype for artificial intelligence that can collaborate with humans.",10.1101/2021.07.21.21260920,virology-deep-learning.xlsx,"MIXTURE of human expertise and deep learning - Developing an explainable model for predicting pathological diagnosis and survival in patients with interstitial lung disease Interstitial pneumonia is a heterogeneous disease with a progressive course and poor prognosis, at times even worse than those in the main cancer types. Histopathological examination is crucial for its diagnosis and estimation of prognosis. However, the evaluation strongly depends on the experience of pathologists, and the reproducibility of diagnosis is low.

Herein, we propose MIXTURE (huMan-In-the-loop eXplainable artificial intelligence Through the Use of REcurrent training), a method to develop deep learning models for extracting pathologically significant findings based on an expert pathologists perspective with a small annotation effort. The procedure of MIXTURE consists of three steps as follows. First, we created feature extractors for tiles from whole slide images using self-supervised learning. The similar looking tiles were clustered based on the output features and then pathologists integrated the pathologically synonymous clusters. Using the integrated clusters as labeled data, deep learning models to classify the tiles into pathological findings were created by transfer-learning the feature extractors. We developed three models for different magnifications.

Using these extracted findings, our model was able to predict the diagnosis of usual interstitial pneumonia, a finding suggestive of progressive disease, with high accuracy (AUC 0.90). This high accuracy could not be achieved without the integration of findings by pathologists. The patients predicted as UIP had significantly poorer prognosis (five-year overall survival [OS]: 55.4%) than those predicted as non-UIP (OS: 95.2%). The Cox proportional hazards model for each microscopic finding and prognosis pointed out dense fibrosis, fibroblastic foci, elastosis, and lymphocyte aggregation as independent risk factors. We suggest that MIXTURE may serve as a model approach to different diseases evaluated by medical imaging, including pathology and radiology, and be the prototype for artificial intelligence that can collaborate with humans.",1
"Almahfouz Nasser, S.; Cherian Kurian, N.; Sethi, A.",2021,Reducing Domain Shift For Mitosis Detection Using Preprocessing Homogenizers,Pathology,Reducing Domain Shift For Mitosis Detection Using Preprocessing Homogenizers,"Almahfouz Nasser, S.; Cherian Kurian, N.; Sethi, A.",Pathology,2021-09-10 00:00:00 UTC,"The detection of mitotic figures in histological tumor images plays a vital role in the decision-making of the appropriate therapy. However, tissue preparation and image acquisition methods degrade the performances of the deep learning-based approaches for mitotic figures detection. MItosis DOmain Generalization challenge addresses the domain-shift problem of this detection task. This work presents our approach based on preprocessing homogenizers to tackling this problem.",10.1101/2021.09.02.21263039,virology-deep-learning.xlsx,"Reducing Domain Shift For Mitosis Detection Using Preprocessing Homogenizers The detection of mitotic figures in histological tumor images plays a vital role in the decision-making of the appropriate therapy. However, tissue preparation and image acquisition methods degrade the performances of the deep learning-based approaches for mitotic figures detection. MItosis DOmain Generalization challenge addresses the domain-shift problem of this detection task. This work presents our approach based on preprocessing homogenizers to tackling this problem.",0
"Bukhari, S. U. K.; Syed, A.; Khalid, S. S.; Shah, S. S. H.",2021,The Histological Diagnosis of Breast Cancer by Employing scale invariant ResNet 18 With Spatial Supervised Technique,Pathology,The Histological Diagnosis of Breast Cancer by Employing scale invariant ResNet 18 With Spatial Supervised Technique,"Bukhari, S. U. K.; Syed, A.; Khalid, S. S.; Shah, S. S. H.",Pathology,2021-09-12 00:00:00 UTC,"BackgroundBreast cancer is one of the most prevalent cause of morbidity and mortality in women all over the world. Histopathological diagnosis is a vital component in the management of breast cancer. The application of artificial intelligence is yielding promising results for the better patient care.

AimThe main aim of the present research project is to explore the potential of spatial supervised technique to develop scale invariant system for the histological diagnosis of breast cancer.

Materials and MethodsThe anonymized images of hematoxylin and eosin stained section of the dataset, which has been acquired from the website. The slides were taken at different zoom (magnification) levels. Spatial supervised learning has been employed to make a scale invariant system. We used 400x and 40x to generate the results. For the 400x, we trained our network on a dataset of 200x,100x, and 40x images. The datasets were split into training and validation sets. The training set contained 80% digital slides of the respected dataset, and the validation set contained 20% digital slides of the respected dataset. The final result was generated by splitting the dataset of 400x into the training and test dataset. The training set contained 50% digital slides, and the test set also contained 50% digital slides. This unusual split is done to show how good spatial supervised learning works. Similarly, for 40x, we trained our networks on a dataset of 400x,200x, and 100x. The same steps were followed to obtain the 40x results.

ResultsThe result analysis revealed that the ResNet 18 with spatial supervised learning on dataset of 40x yielded the F-1 score of 1.0, while ResNet 18 with supervised learning only, on dataset of 40x yielded F-1 score of 0.9823. ResNet 18 with spatial supervised learning on dataset of 400x revealed F-1 score of 0.9957, and ResNet 18 with supervised learning only, on dataset of 400x showed the F-1 score of 0.9591. For supervised learning dataset is spited into training (80%) and testing (20% of dataset).

ConclusionThe analysis of digitized pathology images with the application of convolutional neural network Resnet -18 architecture with spatial supervised learning revealed excellent results, which is demonstrated by a very high F-1 score of 1.0.

The development of scale invariant system with application of spatial supervised technique solved the problem of images with variable magnifications. The finding would further pave the pathway for application of deep learning for the histological diagnosis of pathological lesions.",10.1101/2021.09.06.21263185,virology-deep-learning.xlsx,"The Histological Diagnosis of Breast Cancer by Employing scale invariant ResNet 18 With Spatial Supervised Technique BackgroundBreast cancer is one of the most prevalent cause of morbidity and mortality in women all over the world. Histopathological diagnosis is a vital component in the management of breast cancer. The application of artificial intelligence is yielding promising results for the better patient care.

AimThe main aim of the present research project is to explore the potential of spatial supervised technique to develop scale invariant system for the histological diagnosis of breast cancer.

Materials and MethodsThe anonymized images of hematoxylin and eosin stained section of the dataset, which has been acquired from the website. The slides were taken at different zoom (magnification) levels. Spatial supervised learning has been employed to make a scale invariant system. We used 400x and 40x to generate the results. For the 400x, we trained our network on a dataset of 200x,100x, and 40x images. The datasets were split into training and validation sets. The training set contained 80% digital slides of the respected dataset, and the validation set contained 20% digital slides of the respected dataset. The final result was generated by splitting the dataset of 400x into the training and test dataset. The training set contained 50% digital slides, and the test set also contained 50% digital slides. This unusual split is done to show how good spatial supervised learning works. Similarly, for 40x, we trained our networks on a dataset of 400x,200x, and 100x. The same steps were followed to obtain the 40x results.

ResultsThe result analysis revealed that the ResNet 18 with spatial supervised learning on dataset of 40x yielded the F-1 score of 1.0, while ResNet 18 with supervised learning only, on dataset of 40x yielded F-1 score of 0.9823. ResNet 18 with spatial supervised learning on dataset of 400x revealed F-1 score of 0.9957, and ResNet 18 with supervised learning only, on dataset of 400x showed the F-1 score of 0.9591. For supervised learning dataset is spited into training (80%) and testing (20% of dataset).

ConclusionThe analysis of digitized pathology images with the application of convolutional neural network Resnet -18 architecture with spatial supervised learning revealed excellent results, which is demonstrated by a very high F-1 score of 1.0.

The development of scale invariant system with application of spatial supervised technique solved the problem of images with variable magnifications. The finding would further pave the pathway for application of deep learning for the histological diagnosis of pathological lesions.",0
"Mehdiratta, G.",2021,Prediction of BAP1 mutations in uveal melanoma patients from histology images using weakly supervised deep learning-based whole slide image analysis,Pathology,Prediction of BAP1 mutations in uveal melanoma patients from histology images using weakly supervised deep learning-based whole slide image analysis,"Mehdiratta, G.",Pathology,2021-11-30 00:00:00 UTC,"While cases of uveal melanoma are relatively rare overall, it remains the most common intraocular cancer in adults and has a 10-year fatality rate of approximately 50% in metastatic patients with no effective treatment options. Mutations in BAP1, a tumor suppressor gene, have been previously found to be associated with the onset of metastasis in uveal melanoma patients. In this study, I utilize a weakly supervised deep learning-based pipeline in order to analyze whole slide images (WSIs) of uveal melanoma patients in conjunction with slide-level labels regarding the presence of BAP1 mutations. I demonstrate that there is a strong relationship between BAP1 mutations and physical tumor development in uveal melanoma and that my model is able to predict such relationships with an optimized mean test AUC of 0.86. My findings demonstrate that deep learning models are able to accurately predict patient-specific genotypic characteristics in uveal melanoma. Once integrated into and adapted to existing non-invasive ocular scanner technologies, my model would assist healthcare professionals in understanding the specific genetic profiles of their patients and provide more personalized treatment options in a safe, efficient manner, thus resulting in improved treatment outcomes.",10.1101/2021.09.16.21263694,virology-deep-learning.xlsx,"Prediction of BAP1 mutations in uveal melanoma patients from histology images using weakly supervised deep learning-based whole slide image analysis While cases of uveal melanoma are relatively rare overall, it remains the most common intraocular cancer in adults and has a 10-year fatality rate of approximately 50% in metastatic patients with no effective treatment options. Mutations in BAP1, a tumor suppressor gene, have been previously found to be associated with the onset of metastasis in uveal melanoma patients. In this study, I utilize a weakly supervised deep learning-based pipeline in order to analyze whole slide images (WSIs) of uveal melanoma patients in conjunction with slide-level labels regarding the presence of BAP1 mutations. I demonstrate that there is a strong relationship between BAP1 mutations and physical tumor development in uveal melanoma and that my model is able to predict such relationships with an optimized mean test AUC of 0.86. My findings demonstrate that deep learning models are able to accurately predict patient-specific genotypic characteristics in uveal melanoma. Once integrated into and adapted to existing non-invasive ocular scanner technologies, my model would assist healthcare professionals in understanding the specific genetic profiles of their patients and provide more personalized treatment options in a safe, efficient manner, thus resulting in improved treatment outcomes.",0
"Davis, R. C.; Li, X.; Xu, Y.; Wang, Z.; Souma, N.; Sotolongo, G.; Bell, J.; Ellis, M.; Howell, D.; Shen, X.; Lafata, K.; Barisoni, L.",2021,Deep Learning Segmentation of Glomeruli on Kidney Donor Frozen Sections,Pathology,Deep Learning Segmentation of Glomeruli on Kidney Donor Frozen Sections,"Davis, R. C.; Li, X.; Xu, Y.; Wang, Z.; Souma, N.; Sotolongo, G.; Bell, J.; Ellis, M.; Howell, D.; Shen, X.; Lafata, K.; Barisoni, L.",Pathology,2021-09-22 00:00:00 UTC,"PurposeRecent advances in computational image analysis offer the opportunity to develop automatic quantification of histologic parameters as aid tools for practicing pathologists. This work aims to develop deep learning (DL) models to quantify non-sclerotic and sclerotic glomeruli on frozen sections from donor kidney biopsies.

ApproachA total of 258 whole slide images (WSI) from cadaveric donor kidney biopsies performed at our institution (n=123) and at external institutions (n=135) were used in this study. WSIs from our institution were divided at the patient level into training and validation datasets (Ratio: 0.8:0.2) and external WSIs were used as an independent testing dataset. Non-sclerotic (n=22767) and sclerotic (n=1366) glomeruli were manually annotated by study pathologists on all WSIs. A 9-layer convolutional neural network based on the common U-Net architecture was developed and tested for the segmentation of non-sclerotic and sclerotic glomeruli. DL-derived, manual segmentation and reported glomerular count (standard of care) were compared.

ResultsThe average Dice Similarity Coefficient testing was 0.90 and 0.83. and the F1, Recall, and Precision scores were 0.93, 0.96, and 0.90, and 0.87, 0.93, and 0.81, for non-sclerotic and sclerotic glomeruli, respectively. DL-derived and manual segmentation derived glomerular counts were comparable, but statistically different from reported glomerular count.

ConclusionsDL segmentation is a feasible and robust approach for automatic quantification of glomeruli. This work represents the first step toward new protocols for the evaluation of donor kidney biopsies.",10.1101/2021.09.16.21263707,virology-deep-learning.xlsx,"Deep Learning Segmentation of Glomeruli on Kidney Donor Frozen Sections PurposeRecent advances in computational image analysis offer the opportunity to develop automatic quantification of histologic parameters as aid tools for practicing pathologists. This work aims to develop deep learning (DL) models to quantify non-sclerotic and sclerotic glomeruli on frozen sections from donor kidney biopsies.

ApproachA total of 258 whole slide images (WSI) from cadaveric donor kidney biopsies performed at our institution (n=123) and at external institutions (n=135) were used in this study. WSIs from our institution were divided at the patient level into training and validation datasets (Ratio: 0.8:0.2) and external WSIs were used as an independent testing dataset. Non-sclerotic (n=22767) and sclerotic (n=1366) glomeruli were manually annotated by study pathologists on all WSIs. A 9-layer convolutional neural network based on the common U-Net architecture was developed and tested for the segmentation of non-sclerotic and sclerotic glomeruli. DL-derived, manual segmentation and reported glomerular count (standard of care) were compared.

ResultsThe average Dice Similarity Coefficient testing was 0.90 and 0.83. and the F1, Recall, and Precision scores were 0.93, 0.96, and 0.90, and 0.87, 0.93, and 0.81, for non-sclerotic and sclerotic glomeruli, respectively. DL-derived and manual segmentation derived glomerular counts were comparable, but statistically different from reported glomerular count.

ConclusionsDL segmentation is a feasible and robust approach for automatic quantification of glomeruli. This work represents the first step toward new protocols for the evaluation of donor kidney biopsies.",0
"Haghighat, M.; Browning, L.; Sirinukunwattana, K.; Malacrino, S.; Alham, N. K.; Colling, R.; Cui, Y.; Rakha, E.; Hamdy, F.; Verrill, C.; Rittscher, J.",2021,"PathProfiler: Automated Quality Assessment of Retrospective Histopathology Whole-Slide Image Cohorts by Artificial Intelligence, A Case Study for Prostate Cancer Research",Pathology,"PathProfiler: Automated Quality Assessment of Retrospective Histopathology Whole-Slide Image Cohorts by Artificial Intelligence, A Case Study for Prostate Cancer Research","Haghighat, M.; Browning, L.; Sirinukunwattana, K.; Malacrino, S.; Alham, N. K.; Colling, R.; Cui, Y.; Rakha, E.; Hamdy, F.; Verrill, C.; Rittscher, J.",Pathology,2021-09-27 00:00:00 UTC,"Research using whole slide images (WSIs) of scanned histopathology slides for the development of artificial intelligence (AI) algorithms has increased exponentially over recent years. Glass slides from large retrospective cohorts with patient follow-up data are digitised for the development and validation of AI tools. Such resources, therefore, become very important, with the need to ensure that their quality is of the standard necessary for downstream AI development. However, manual quality control of such large cohorts of WSIs by visual assessment is unfeasible, and whilst quality control AI algorithms exist, these focus on bespoke aspects of image quality, e.g. focus, or use traditional machine-learning methods such as hand-crafted features, which are unable to classify the range of potential image artefacts that should be considered.

In this study, we have trained and validated a multi-task deep neural network to automate the process of quality control of a large retrospective cohort of prostate cases from which glass slides have been scanned several years after production, to determine both the usability of the images for research and the common image artefacts present.

Using a two-layer approach, quality overlays of WSIs were generated from a quality assessment undertaken at patch-level at 5X magnification. From these quality overlays the slide-level quality scores were predicted and then compared to those generated by three specialist urological pathologists, with a Pearson correlation of 0.89 for overall  usability (at a diagnostic level), and 0.87 and 0.82 for focus and H&E staining quality scores respectively. We subsequently applied our quality assessment pipeline to the TCGA prostate cancer cohort and to a colorectal cancer cohort, for comparison.

Our model, designated as PathProfiler, indicates comparable predicted usability of images from the cohorts assessed (86-90%), and perhaps more significantly is able to predicts WSIs that could benefit from re-scanning or re-staining for quality improvement.

We have shown in this study that AI can be used to automate the process of quality control of large retrospective cohorts to maximise research outputs and conclusions.",10.1101/2021.09.24.21263762,virology-deep-learning.xlsx,"PathProfiler: Automated Quality Assessment of Retrospective Histopathology Whole-Slide Image Cohorts by Artificial Intelligence, A Case Study for Prostate Cancer Research Research using whole slide images (WSIs) of scanned histopathology slides for the development of artificial intelligence (AI) algorithms has increased exponentially over recent years. Glass slides from large retrospective cohorts with patient follow-up data are digitised for the development and validation of AI tools. Such resources, therefore, become very important, with the need to ensure that their quality is of the standard necessary for downstream AI development. However, manual quality control of such large cohorts of WSIs by visual assessment is unfeasible, and whilst quality control AI algorithms exist, these focus on bespoke aspects of image quality, e.g. focus, or use traditional machine-learning methods such as hand-crafted features, which are unable to classify the range of potential image artefacts that should be considered.

In this study, we have trained and validated a multi-task deep neural network to automate the process of quality control of a large retrospective cohort of prostate cases from which glass slides have been scanned several years after production, to determine both the usability of the images for research and the common image artefacts present.

Using a two-layer approach, quality overlays of WSIs were generated from a quality assessment undertaken at patch-level at 5X magnification. From these quality overlays the slide-level quality scores were predicted and then compared to those generated by three specialist urological pathologists, with a Pearson correlation of 0.89 for overall  usability (at a diagnostic level), and 0.87 and 0.82 for focus and H&E staining quality scores respectively. We subsequently applied our quality assessment pipeline to the TCGA prostate cancer cohort and to a colorectal cancer cohort, for comparison.

Our model, designated as PathProfiler, indicates comparable predicted usability of images from the cohorts assessed (86-90%), and perhaps more significantly is able to predicts WSIs that could benefit from re-scanning or re-staining for quality improvement.

We have shown in this study that AI can be used to automate the process of quality control of large retrospective cohorts to maximise research outputs and conclusions.",0
"Oshinubi, K.; Rachdi, M.; Demongeot, J.",2021,Modelling of COVID-19 pandemic vis-a-vis some socioeconomic factors,Epidemiology,Modelling of COVID-19 pandemic vis-a-vis some socioeconomic factors,"Oshinubi, K.; Rachdi, M.; Demongeot, J.",Epidemiology,2021-10-01 00:00:00 UTC,"The impacts of COVID-19 outbreak on socio-economic status of countries across the globe cannot be overemphasized as we examine the role it played in various countries. A lot of people were out of jobs, many households were careful of their spending and a greater social fracture of the population in fourteen different countries has emerged. We considered periods of infection spread during the first and second wave in Organization for Economic Co-operation and Development (OECD) countries and countries in Africa, that is developed and developing countries alongside their social-economic data. We established a mathematical and statistical relationship between Theil and Gini index, then we studied the relationship between the data from epidemiology and socio-economic determinants using several machine learning and deep learning methods. High correlations were observed between some of the socio-economic and epidemiologic parameters and we predicted three of the socio-economic variables in order to validate our results. These result shows a sharp difference between the first and second wave of the pandemic confirming the real dynamics of the spread of the outbreak in several countries and ways by which it was mitigated.",10.1101/2021.09.30.21264356,virology-deep-learning.xlsx,"Modelling of COVID-19 pandemic vis-a-vis some socioeconomic factors The impacts of COVID-19 outbreak on socio-economic status of countries across the globe cannot be overemphasized as we examine the role it played in various countries. A lot of people were out of jobs, many households were careful of their spending and a greater social fracture of the population in fourteen different countries has emerged. We considered periods of infection spread during the first and second wave in Organization for Economic Co-operation and Development (OECD) countries and countries in Africa, that is developed and developing countries alongside their social-economic data. We established a mathematical and statistical relationship between Theil and Gini index, then we studied the relationship between the data from epidemiology and socio-economic determinants using several machine learning and deep learning methods. High correlations were observed between some of the socio-economic and epidemiologic parameters and we predicted three of the socio-economic variables in order to validate our results. These result shows a sharp difference between the first and second wave of the pandemic confirming the real dynamics of the spread of the outbreak in several countries and ways by which it was mitigated.",1
"Xu, F.; Zhu, C.; Tang, W.; Wang, Y.; Zhang, Y.; Li, J.; Jiang, H.; Shi, Z.; Liu, J.; Jin, M.",2021,Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides,Pathology,Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides,"Xu, F.; Zhu, C.; Tang, W.; Wang, Y.; Zhang, Y.; Li, J.; Jiang, H.; Shi, Z.; Liu, J.; Jin, M.",Pathology,2021-10-14 00:00:00 UTC,"ObjectivesTo develop and validate a deep learning (DL) based primary tumor biopsy signature for predicting axillary lymph node (ALN) metastasis preoperatively in early breast cancer (EBC) patients with clinically negative ALN.

MethodsA total of 1058 EBC patients with pathologically confirmed ALN status were enrolled from May 2010 to August 2020. A deep learning core-needle biopsy (DL-CNB) model was built on the attention based multiple instance learning (AMIL) framework to predict ALN status utilizing the deep learning features, which were extracted from the cancer areas of digitized whole-slide images (WSIs) of breast CNB specimens annotated by two pathologists. Accuracy, sensitivity, specificity, receiver operating characteristic (ROC) curves, and areas under the receiver operating characteristic curve (AUCs) were analyzed to evaluate our model.

ResultsThe best performing DL-CNB model with VGG16_BN as the feature extractor achieved an AUC of 0.816 (95% confidence interval (CI): 0.758, 0.865) in predicting positive ALN metastasis in the independent test cohort. Furthermore, our model incorporating the clinical data, which was called DL-CNB+C, yielded the best accuracy of 0.831 (95%CI: 0.775, 0.878), especially for patients younger than 50 years (AUC: 0.918, 95%CI: 0.825, 0.971). The interpretation of DL-CNB model showed that the top signatures most predictive of ALN metastasis were characterized by the nuclei features including density (p=0.015), circumference (p=0.009), circularity (p=0.010), and orientation (p=0.012).

ConclusionOur study provides a novel deep learning-based biomarker on primary tumor CNB slides to predict the metastatic status of ALN preoperatively for patients with early breast cancer.",10.1101/2021.10.10.21264721,virology-deep-learning.xlsx,"Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides ObjectivesTo develop and validate a deep learning (DL) based primary tumor biopsy signature for predicting axillary lymph node (ALN) metastasis preoperatively in early breast cancer (EBC) patients with clinically negative ALN.

MethodsA total of 1058 EBC patients with pathologically confirmed ALN status were enrolled from May 2010 to August 2020. A deep learning core-needle biopsy (DL-CNB) model was built on the attention based multiple instance learning (AMIL) framework to predict ALN status utilizing the deep learning features, which were extracted from the cancer areas of digitized whole-slide images (WSIs) of breast CNB specimens annotated by two pathologists. Accuracy, sensitivity, specificity, receiver operating characteristic (ROC) curves, and areas under the receiver operating characteristic curve (AUCs) were analyzed to evaluate our model.

ResultsThe best performing DL-CNB model with VGG16_BN as the feature extractor achieved an AUC of 0.816 (95% confidence interval (CI): 0.758, 0.865) in predicting positive ALN metastasis in the independent test cohort. Furthermore, our model incorporating the clinical data, which was called DL-CNB+C, yielded the best accuracy of 0.831 (95%CI: 0.775, 0.878), especially for patients younger than 50 years (AUC: 0.918, 95%CI: 0.825, 0.971). The interpretation of DL-CNB model showed that the top signatures most predictive of ALN metastasis were characterized by the nuclei features including density (p=0.015), circumference (p=0.009), circularity (p=0.010), and orientation (p=0.012).

ConclusionOur study provides a novel deep learning-based biomarker on primary tumor CNB slides to predict the metastatic status of ALN preoperatively for patients with early breast cancer.",0
"Yuan, Y.; Jahani, E.; Zhao, S.; Ahn, Y.-Y.; Pentland, A. S.",2022,Mobility network reveals the impact of spatial vaccination heterogeneity on COVID-19,Epidemiology,Mobility network reveals the impact of spatial vaccination heterogeneity on COVID-19,"Yuan, Y.; Jahani, E.; Zhao, S.; Ahn, Y.-Y.; Pentland, A. S.",Epidemiology,2022-05-31 00:00:00 UTC,"Mass vaccination is one of the most effective epidemic control measures. Because ones vaccination decision is shaped by social processes, the pattern of vaccine uptake tends to show strong social and spatial heterogeneity, such as urban-rural divide and clustering. Examining through network perspectives, we develop a framework for estimating the impact of spatial vaccination heterogeneity on epidemic outbreaks. Leveraging fine-grained mobility data and computational models, we investigate two network effects--the ""hub effect"" (vaccinating mobility hubs reduces transmission) and the ""homophily effect"" (stronger homophily in vaccination rates increases transmission). Applying Bayesian deep learning and fine-grained epidemic simulations, our study suggests a negative effect of homophily and a positive effect of highly vaccinated hubs on reducing case counts for both the synthetic network and the U.S. mobility network. Our framework enables us to evaluate outcomes from various hypothetical spatial vaccine distributions and to study a hypothetical vaccination campaign strategy that targets a small number of regions with the largest gain in protective power using the data from January 2022. Our simulation suggests that our strategy can potentially prevent about 2.5 times more cases than a uniform strategy with an additional 1% of the population vaccinated. Notably, our simulation also shows that this strategy could even better protect vulnerable or disadvantaged communities through network effects than strategies that directly target them. Our study suggests that we need to examine the interplay between vaccination patterns and mobility networks beyond the overall vaccination rate, and that understanding geographical pattern of vaccine uptake could be just as important as improving the overall vaccination rate.",10.1101/2021.10.26.21265488,virology-deep-learning.xlsx,"Mobility network reveals the impact of spatial vaccination heterogeneity on COVID-19 Mass vaccination is one of the most effective epidemic control measures. Because ones vaccination decision is shaped by social processes, the pattern of vaccine uptake tends to show strong social and spatial heterogeneity, such as urban-rural divide and clustering. Examining through network perspectives, we develop a framework for estimating the impact of spatial vaccination heterogeneity on epidemic outbreaks. Leveraging fine-grained mobility data and computational models, we investigate two network effects--the ""hub effect"" (vaccinating mobility hubs reduces transmission) and the ""homophily effect"" (stronger homophily in vaccination rates increases transmission). Applying Bayesian deep learning and fine-grained epidemic simulations, our study suggests a negative effect of homophily and a positive effect of highly vaccinated hubs on reducing case counts for both the synthetic network and the U.S. mobility network. Our framework enables us to evaluate outcomes from various hypothetical spatial vaccine distributions and to study a hypothetical vaccination campaign strategy that targets a small number of regions with the largest gain in protective power using the data from January 2022. Our simulation suggests that our strategy can potentially prevent about 2.5 times more cases than a uniform strategy with an additional 1% of the population vaccinated. Notably, our simulation also shows that this strategy could even better protect vulnerable or disadvantaged communities through network effects than strategies that directly target them. Our study suggests that we need to examine the interplay between vaccination patterns and mobility networks beyond the overall vaccination rate, and that understanding geographical pattern of vaccine uptake could be just as important as improving the overall vaccination rate.",1
"Lu, Y.; Aslani, S.; Emberton, M.; Alexander, D. C.; Jacob, J.",2022,Deep Learning Based Long Term Mortality Prediction in the National Lung Screening Trial,Respiratory Medicine,Deep Learning Based Long Term Mortality Prediction in the National Lung Screening Trial,"Lu, Y.; Aslani, S.; Emberton, M.; Alexander, D. C.; Jacob, J.",Respiratory Medicine,2022-01-13 00:00:00 UTC,"In this study, the long-term mortality in the National Lung Screening Trial (NLST) was investigated using a deep learning-based method. Binary classification of the non-lung-cancer mortality (i.e. cardiovascular and respiratory mortality) was performed using neural network models centered around a 3D-ResNet. The models were trained on a participant age, gender, and smoking history matched cohort. Utilising both the 3D CT scan and clinical information, the models can achieve an AUC of 0.73 which outperforms humans at cardiovascular mortality prediction. By interpreting the trained models with 3D saliency maps, we examined the features on the CT scans that correspond to the mortality signal. The saliency maps can potentially assist the clinicians and radiologists to identify regions of concern on the image that may indicate the need to adopt preventative healthcare management strategies to prolong the patients life expectancy.",10.1101/2022.01.12.22269152,virology-deep-learning.xlsx,"Deep Learning Based Long Term Mortality Prediction in the National Lung Screening Trial In this study, the long-term mortality in the National Lung Screening Trial (NLST) was investigated using a deep learning-based method. Binary classification of the non-lung-cancer mortality (i.e. cardiovascular and respiratory mortality) was performed using neural network models centered around a 3D-ResNet. The models were trained on a participant age, gender, and smoking history matched cohort. Utilising both the 3D CT scan and clinical information, the models can achieve an AUC of 0.73 which outperforms humans at cardiovascular mortality prediction. By interpreting the trained models with 3D saliency maps, we examined the features on the CT scans that correspond to the mortality signal. The saliency maps can potentially assist the clinicians and radiologists to identify regions of concern on the image that may indicate the need to adopt preventative healthcare management strategies to prolong the patients life expectancy.",0
"Kanavati, F.; Ichihara, S.; Tsuneki, M.",2022,A deep learning model for breast ductal carcinoma in situ classification in whole slide images,Pathology,A deep learning model for breast ductal carcinoma in situ classification in whole slide images,"Kanavati, F.; Ichihara, S.; Tsuneki, M.",Pathology,2022-01-15 00:00:00 UTC,"The pathological differential diagnosis between breast ductal carcinoma in situ (DCIS) and invasive ductal carcinoma (IDC) is of pivotal importance for determining optimum cancer treatment(s) and clinical outcomes. Since conventional diagnosis by pathologists using micro-scopes is limited in terms of human resources, it is necessary to develop new techniques that can rapidly and accurately diagnose large numbers of histopathological specimens. Computational pathology tools which can assist pathologists in detecting and classifying DCIS and IDC from whole slide images (WSIs) would be of great benefit for routine pathological diagnosis. In this paper, we trained deep learning models capable of classifying biopsy and surgical histopathological WSIs into DCIS, IDC, and benign. We evaluated the models on two independent test sets (n=1,382, n=548), achieving ROC areas under the curves (AUCs) up to 0.960 and 0.977 for DCIS and IDC, respectively.",10.1101/2022.01.14.22269329,virology-deep-learning.xlsx,"A deep learning model for breast ductal carcinoma in situ classification in whole slide images The pathological differential diagnosis between breast ductal carcinoma in situ (DCIS) and invasive ductal carcinoma (IDC) is of pivotal importance for determining optimum cancer treatment(s) and clinical outcomes. Since conventional diagnosis by pathologists using micro-scopes is limited in terms of human resources, it is necessary to develop new techniques that can rapidly and accurately diagnose large numbers of histopathological specimens. Computational pathology tools which can assist pathologists in detecting and classifying DCIS and IDC from whole slide images (WSIs) would be of great benefit for routine pathological diagnosis. In this paper, we trained deep learning models capable of classifying biopsy and surgical histopathological WSIs into DCIS, IDC, and benign. We evaluated the models on two independent test sets (n=1,382, n=548), achieving ROC areas under the curves (AUCs) up to 0.960 and 0.977 for DCIS and IDC, respectively.",0
"Zhang, J.; Fanous, M. J.; Sobh, N.; Popescu, G.",2022,Automatic colorectal cancer screening using deep-learning on spatial light interference microscopy data,Pathology,Automatic colorectal cancer screening using deep-learning on spatial light interference microscopy data,"Zhang, J.; Fanous, M. J.; Sobh, N.; Popescu, G.",Pathology,2022-01-18 00:00:00 UTC,"The surgical pathology workflow currently adopted in the clinic uses staining to reveal tissue architecture within thin sections. A trained pathologist then conducts a visual examination of these slices and, as the investigation is based on an empirical assessment, a certain amount of subjectivity is unavoidable. Furthermore, the reliance on such external contrast agents like hematoxylin and eosin (H&E), albeit a well-established method, makes it difficult to standardize color balance, staining strength, and imaging conditions, hindering automated computational analysis. In response to these challenges, we applied spatial light interference microscopy (SLIM), a label-free method that generates contrast based on the intrinsic tissue refractive index signatures. Thus, we reduce human bias and make the image data comparable across instruments and clinics. We applied a Mask R-CNN deep learning algorithm to the SLIM data to achieve an automated colorectal cancer screening procedure, i.e., classifying normal vs. cancer specimens. Our results obtained on a tissue microarray consisting of specimens from 132 patients, resulted in 91% accuracy for gland detection, 99.71% accuracy in gland-level classification, and 97% accuracy in core-level classification. A SLIM tissue scanner accompanied by an application-specific deep learning algorithm may become a valuable clinical tool, enabling faster and more accurate assessment by the pathologist.",10.1101/2022.01.16.22269381,virology-deep-learning.xlsx,"Automatic colorectal cancer screening using deep-learning on spatial light interference microscopy data The surgical pathology workflow currently adopted in the clinic uses staining to reveal tissue architecture within thin sections. A trained pathologist then conducts a visual examination of these slices and, as the investigation is based on an empirical assessment, a certain amount of subjectivity is unavoidable. Furthermore, the reliance on such external contrast agents like hematoxylin and eosin (H&E), albeit a well-established method, makes it difficult to standardize color balance, staining strength, and imaging conditions, hindering automated computational analysis. In response to these challenges, we applied spatial light interference microscopy (SLIM), a label-free method that generates contrast based on the intrinsic tissue refractive index signatures. Thus, we reduce human bias and make the image data comparable across instruments and clinics. We applied a Mask R-CNN deep learning algorithm to the SLIM data to achieve an automated colorectal cancer screening procedure, i.e., classifying normal vs. cancer specimens. Our results obtained on a tissue microarray consisting of specimens from 132 patients, resulted in 91% accuracy for gland detection, 99.71% accuracy in gland-level classification, and 97% accuracy in core-level classification. A SLIM tissue scanner accompanied by an application-specific deep learning algorithm may become a valuable clinical tool, enabling faster and more accurate assessment by the pathologist.",0
"Wu, W.; Liu, X.; Hamilton, R.; Suriawinata, A.; Hassanpour, S.",2022,Graph Convolutional Neural Networks for Histological Classification of Pancreatic Cancer,Pathology,Graph Convolutional Neural Networks for Histological Classification of Pancreatic Cancer,"Wu, W.; Liu, X.; Hamilton, R.; Suriawinata, A.; Hassanpour, S.",Pathology,2022-01-28 00:00:00 UTC,"Pancreatic ductal adenocarcinoma has some of the worst prognostic outcomes among various cancer types. Detection of histologic patterns of pancreatic tumors is essential to predict prognosis and decide about the treatment for patients. This histologic classification can have a large degree of variability even among expert pathologists. This study proposes a graph convolutional network-based deep learning model to detect aggressive adenocarcinoma and less aggressive pancreatic tumors from benign cases. Our model uses a convolutional neural network to extract detailed information from every small region in a whole-slide image. Then, we use a graph architecture to aggregate the extracted features from these regions and their positional information to capture the whole-slide level structure and make the final prediction. We evaluated our model on an independent test set and achieved an F1 score of 0.85 for detecting neoplastic cells and ductal adenocarcinoma, significantly outperforming other baseline methods. If validated in prospective studies, this approach has a great potential to assist pathologists in identifying adenocarcinoma and other types of pancreatic tumors in clinical settings.",10.1101/2022.01.26.22269832,virology-deep-learning.xlsx,"Graph Convolutional Neural Networks for Histological Classification of Pancreatic Cancer Pancreatic ductal adenocarcinoma has some of the worst prognostic outcomes among various cancer types. Detection of histologic patterns of pancreatic tumors is essential to predict prognosis and decide about the treatment for patients. This histologic classification can have a large degree of variability even among expert pathologists. This study proposes a graph convolutional network-based deep learning model to detect aggressive adenocarcinoma and less aggressive pancreatic tumors from benign cases. Our model uses a convolutional neural network to extract detailed information from every small region in a whole-slide image. Then, we use a graph architecture to aggregate the extracted features from these regions and their positional information to capture the whole-slide level structure and make the final prediction. We evaluated our model on an independent test set and achieved an F1 score of 0.85 for detecting neoplastic cells and ductal adenocarcinoma, significantly outperforming other baseline methods. If validated in prospective studies, this approach has a great potential to assist pathologists in identifying adenocarcinoma and other types of pancreatic tumors in clinical settings.",0
"Bilal, M.; Tsang, Y. W.; Ali, M.; Graham, S.; Hero, E.; Wahab, N.; Dodd, K.; Sahota, H.; Lu, W.; Jahanifar, M.; Robinson, A.; Azam, A.; Benes, K.; Nimir, M.; Bhalerao, A.; Eldaly, H.; Raza, S. E. A.; Gopalakrishnan, K.; Minhas, F.; Snead, D.; Rajpoot, N.",2022,AI based pre-screening of large bowel cancer via weakly supervised learning of colorectal biopsy histology images,Pathology,AI based pre-screening of large bowel cancer via weakly supervised learning of colorectal biopsy histology images,"Bilal, M.; Tsang, Y. W.; Ali, M.; Graham, S.; Hero, E.; Wahab, N.; Dodd, K.; Sahota, H.; Lu, W.; Jahanifar, M.; Robinson, A.; Azam, A.; Benes, K.; Nimir, M.; Bhalerao, A.; Eldaly, H.; Raza, S. E. A.; Gopalakrishnan, K.; Minhas, F.; Snead, D.; Rajpoot, N.",Pathology,2022-02-28 00:00:00 UTC,"Histopathological examination is a pivotal step in the diagnosis and treatment planning of many major diseases. To facilitate the diagnostic decision-making and reduce the workload of pathologists, we present an AI-based pre-screening tool capable of identifying normal and neoplastic colon biopsies. To learn the differential histological patterns from whole slides images (WSIs) stained with hematoxylin and eosin (H&E), our proposed weakly supervised deep learning method requires only slide-level labels and no detailed cell or region-level annotations. The proposed method was developed and validated on an internal cohort of biopsy slides (n=4 292) from two hospitals labeled with corresponding diagnostic categories assigned by pathologists after reviewing case reports. Performance of the proposed colon cancer pre-screening tool was evaluated in a cross-validation setting using the internal cohort (n=4 292) and also by an external validation on The Cancer Genome Atlas (TCGA) cohort (n=731). With overall cross-validated classification accuracy (AUROC = 0.9895) and external validation accuracy (AUROC = 0.9746), the proposed tool promises high accuracy to assist with the pre-screening of colorectal biopsies in clinical practice. Analysis of saliency maps confirms the representation of disease heterogeneity in model predictions and their association with relevant pathological features. The proposed AI tool correctly reported some slides as neoplastic while clinical reports suggested they were normal. Additionally, we analyzed genetic mutations and gene enrichment analysis of AI-generated neoplastic scores to gain further insight into the model predictions and explore the association between neoplastic histology and genetic heterogeneity through representative genes and signaling pathways.",10.1101/2022.02.28.22271565,virology-deep-learning.xlsx,"AI based pre-screening of large bowel cancer via weakly supervised learning of colorectal biopsy histology images Histopathological examination is a pivotal step in the diagnosis and treatment planning of many major diseases. To facilitate the diagnostic decision-making and reduce the workload of pathologists, we present an AI-based pre-screening tool capable of identifying normal and neoplastic colon biopsies. To learn the differential histological patterns from whole slides images (WSIs) stained with hematoxylin and eosin (H&E), our proposed weakly supervised deep learning method requires only slide-level labels and no detailed cell or region-level annotations. The proposed method was developed and validated on an internal cohort of biopsy slides (n=4 292) from two hospitals labeled with corresponding diagnostic categories assigned by pathologists after reviewing case reports. Performance of the proposed colon cancer pre-screening tool was evaluated in a cross-validation setting using the internal cohort (n=4 292) and also by an external validation on The Cancer Genome Atlas (TCGA) cohort (n=731). With overall cross-validated classification accuracy (AUROC = 0.9895) and external validation accuracy (AUROC = 0.9746), the proposed tool promises high accuracy to assist with the pre-screening of colorectal biopsies in clinical practice. Analysis of saliency maps confirms the representation of disease heterogeneity in model predictions and their association with relevant pathological features. The proposed AI tool correctly reported some slides as neoplastic while clinical reports suggested they were normal. Additionally, we analyzed genetic mutations and gene enrichment analysis of AI-generated neoplastic scores to gain further insight into the model predictions and explore the association between neoplastic histology and genetic heterogeneity through representative genes and signaling pathways.",0
"Singh, A.; Bajpai, M. K.",2023,A compartmental Mathematical model of COVID-19 intervention scenarios for Mumbai,Epidemiology,A compartmental Mathematical model of COVID-19 intervention scenarios for Mumbai,"Singh, A.; Bajpai, M. K.",Epidemiology,2023-04-18 00:00:00 UTC,"A new mathematical method with an outstanding potential to predict the incidence of COVID-19 diseases has been proposed. The model proposed is an improvement to the SEIR model. In order to improve the basic understanding of disease spread and outcomes, four compartments included presymptomatic, asymptomatic, quarantine hospitalized and hospitalized. We have studied COVID-19 cases in the city of Mumbai. We first gather clinical details and fit it on death cases using the Lavenberg-Marquardt model to approximate the various parameters. The model uses logistic regression to calculate the basic reproduction number over time and the case fatality rate based on the age-category scenario of the city of Mumbai. Two types of case fatality rate are calculated by the model: one is CFR daily, and the other is total CFR. The total case fatality rate is 4.2, which is almost the same as the actual scenario. The proposed model predicts the approximate time when the disease is at its worst and the approximate time when death cases barely arise and determines how many hospital beds in the peak days of infection would be expected. The proposed model outperforms the classic ARX, SARIMAX and the ARIMA model. And It also outperforms the deep learning models LSTM and Seq2Seq model. To validate results, RMSE, MAPE and R squared matrices are used and are represented using Taylor diagrams graphically.",10.1101/2022.02.28.22271624,virology-deep-learning.xlsx,"A compartmental Mathematical model of COVID-19 intervention scenarios for Mumbai A new mathematical method with an outstanding potential to predict the incidence of COVID-19 diseases has been proposed. The model proposed is an improvement to the SEIR model. In order to improve the basic understanding of disease spread and outcomes, four compartments included presymptomatic, asymptomatic, quarantine hospitalized and hospitalized. We have studied COVID-19 cases in the city of Mumbai. We first gather clinical details and fit it on death cases using the Lavenberg-Marquardt model to approximate the various parameters. The model uses logistic regression to calculate the basic reproduction number over time and the case fatality rate based on the age-category scenario of the city of Mumbai. Two types of case fatality rate are calculated by the model: one is CFR daily, and the other is total CFR. The total case fatality rate is 4.2, which is almost the same as the actual scenario. The proposed model predicts the approximate time when the disease is at its worst and the approximate time when death cases barely arise and determines how many hospital beds in the peak days of infection would be expected. The proposed model outperforms the classic ARX, SARIMAX and the ARIMA model. And It also outperforms the deep learning models LSTM and Seq2Seq model. To validate results, RMSE, MAPE and R squared matrices are used and are represented using Taylor diagrams graphically.",1
"Belgaid, A.",2022,Deep Sequence Modeling for Pressure Controlled Mechanical Ventilation,Respiratory Medicine,Deep Sequence Modeling for Pressure Controlled Mechanical Ventilation,"Belgaid, A.",Respiratory Medicine,2022-03-04 00:00:00 UTC,"This paper presents a deep neural network approach to simulate the pressure of a mechanical ventilator. The traditional mechanical ventilator has a control pressure monitored by a medical practitioner, which could behave inaccurately by missing the proper pressure. This paper exploits recent studies and provides a simulator based on a deep sequence model to predict the airway pressure in the respiratory circuit during the inspiratory phase of a breath given a time series of control parameters and lung attributes. This approach demonstrates the effectiveness of neural network-based controllers in tracking pressure waveforms significantly better than the current industry standard and provides insights to build effective and robust pressure-controlled mechanical ventilators.",10.1101/2022.03.02.22271790,virology-deep-learning.xlsx,"Deep Sequence Modeling for Pressure Controlled Mechanical Ventilation This paper presents a deep neural network approach to simulate the pressure of a mechanical ventilator. The traditional mechanical ventilator has a control pressure monitored by a medical practitioner, which could behave inaccurately by missing the proper pressure. This paper exploits recent studies and provides a simulator based on a deep sequence model to predict the airway pressure in the respiratory circuit during the inspiratory phase of a breath given a time series of control parameters and lung attributes. This approach demonstrates the effectiveness of neural network-based controllers in tracking pressure waveforms significantly better than the current industry standard and provides insights to build effective and robust pressure-controlled mechanical ventilators.",0
"Barrios, W.; Abdollahi, B.; Goyal, M.; Song, Q.; Suriawinata, M.; Richards, R.; Ren, B.; Schned, A.; Seigne, J.; Karagas, M.; Hassanpour, S.",2022,Bladder Cancer Prognosis Using Deep Neural Networks and Histopathology Images,Pathology,Bladder Cancer Prognosis Using Deep Neural Networks and Histopathology Images,"Barrios, W.; Abdollahi, B.; Goyal, M.; Song, Q.; Suriawinata, M.; Richards, R.; Ren, B.; Schned, A.; Seigne, J.; Karagas, M.; Hassanpour, S.",Pathology,2022-03-07 00:00:00 UTC,"Recent studies indicate bladder cancer is among the top 10 most common cancer in the world [1]. Bladder cancer frequently reoccurs, and prognostic judgments may vary among clinicians. Classification of histopathology slides is essential for accurate prognosis and effective treatment of bladder cancer patients, as a favorable prognosis might help to inform less aggressive treatment plans. Developing automated and accurate histopathology image analysis methods can help pathologists in determining the prognosis of bladder cancer. In this study, we introduced Bladder4Net, a deep learning pipeline to classify whole-slide histopathology images of bladder cancer into two classes: low-risk (combination of PUNLMP and low-grade tumors) and high-risk (combination of high-grade and invasive tumors). This pipeline consists of 4 convolutional neural network (CNN) based classifiers to address the difficulties of identifying PUNLMP and invasive classes. We evaluated our pipeline on 182 independent whole-slide images from the New Hampshire Bladder Cancer Study (NHBCS) [22] [23] [24] collected from 1994 to 2004 and 378 external digitized slides from The Cancer Genome Atlas (TCGA) database [26]. The weighted average F1-score of our approach was 0.91 (95% confidence interval (CI): 0.86-0.94) on the NHBCS dataset and 0.99 (95% CI: 0.97-1.00) on the TCGA dataset. Additionally, we computed Kaplan-Meier survival curves for patients predicted as high-risk versus those predicted as low-risk. For the NHBCS test set, patients predicted as high-risk had worse overall survival than those predicted as low-risk, with a Log-rank P-value of 0.004. If validated through prospective trials, our model could be used in clinical settings to improve patient care.",10.1101/2022.03.04.22271918,virology-deep-learning.xlsx,"Bladder Cancer Prognosis Using Deep Neural Networks and Histopathology Images Recent studies indicate bladder cancer is among the top 10 most common cancer in the world [1]. Bladder cancer frequently reoccurs, and prognostic judgments may vary among clinicians. Classification of histopathology slides is essential for accurate prognosis and effective treatment of bladder cancer patients, as a favorable prognosis might help to inform less aggressive treatment plans. Developing automated and accurate histopathology image analysis methods can help pathologists in determining the prognosis of bladder cancer. In this study, we introduced Bladder4Net, a deep learning pipeline to classify whole-slide histopathology images of bladder cancer into two classes: low-risk (combination of PUNLMP and low-grade tumors) and high-risk (combination of high-grade and invasive tumors). This pipeline consists of 4 convolutional neural network (CNN) based classifiers to address the difficulties of identifying PUNLMP and invasive classes. We evaluated our pipeline on 182 independent whole-slide images from the New Hampshire Bladder Cancer Study (NHBCS) [22] [23] [24] collected from 1994 to 2004 and 378 external digitized slides from The Cancer Genome Atlas (TCGA) database [26]. The weighted average F1-score of our approach was 0.91 (95% confidence interval (CI): 0.86-0.94) on the NHBCS dataset and 0.99 (95% CI: 0.97-1.00) on the TCGA dataset. Additionally, we computed Kaplan-Meier survival curves for patients predicted as high-risk versus those predicted as low-risk. For the NHBCS test set, patients predicted as high-risk had worse overall survival than those predicted as low-risk, with a Log-rank P-value of 0.004. If validated through prospective trials, our model could be used in clinical settings to improve patient care.",0
"Tsuneki, M.; Kanavati, F.",2022,Weakly supervised learning for multi-organ adenocarcinoma classification in whole slide images,Pathology,Weakly supervised learning for multi-organ adenocarcinoma classification in whole slide images,"Tsuneki, M.; Kanavati, F.",Pathology,2022-03-31 00:00:00 UTC,"The primary screening by automated computational pathology algorithms of the presence or absence of adenocarcinoma in biopsy specimens (e.g., endoscopic biopsy, transbronchial lung biopsy, and needle biopsy) of possible primary organs (e.g., stomach, colon, lung, and breast) and radical lymph node dissection specimen is very useful and should be a powerful tool to assist surgical pathologists in routine histopathological diagnostic workflow. In this paper, we trained multi-organ deep learning models to classify adenocarcinoma in biopsy and radical lymph node dissection specimens whole slide images (WSIs). We evaluated the models on seven independent test sets (stomach, colon, lung, breast, lymph nodes) to demonstrate the feasibility in multiorgan and lymph nodes specimens from different medical institutions and international public datasets, achieving receiver operating characteristic areas under the curves (ROC-AUCs) in the range of 0.91-0.99.",10.1101/2022.03.28.22273054,virology-deep-learning.xlsx,"Weakly supervised learning for multi-organ adenocarcinoma classification in whole slide images The primary screening by automated computational pathology algorithms of the presence or absence of adenocarcinoma in biopsy specimens (e.g., endoscopic biopsy, transbronchial lung biopsy, and needle biopsy) of possible primary organs (e.g., stomach, colon, lung, and breast) and radical lymph node dissection specimen is very useful and should be a powerful tool to assist surgical pathologists in routine histopathological diagnostic workflow. In this paper, we trained multi-organ deep learning models to classify adenocarcinoma in biopsy and radical lymph node dissection specimens whole slide images (WSIs). We evaluated the models on seven independent test sets (stomach, colon, lung, breast, lymph nodes) to demonstrate the feasibility in multiorgan and lymph nodes specimens from different medical institutions and international public datasets, achieving receiver operating characteristic areas under the curves (ROC-AUCs) in the range of 0.91-0.99.",0
"Latacz, E.; Hoppener, D.; Bohlok, A.; Leduc, S.; Tabaries, S.; Moro, C. F.; Lugassy, C.; Nystrom, H.; Bozoky, B.; Floris, G.; Geyer, N.; Brodt, P.; Llado, L.; Van Mileghem, L.; De Schepper, M.; Majeed, A. W.; Lazaris, A.; Dirix, P.; Zhang, Q.; Petrillo, S. K.; Vankerckhove, S.; Joye, I.; Meyer, Y.; Gregorieff, A.; Roig, N. R.; Vidal-Vanaclocha, F.; Denis, L.; Oliveira, R. C.; Metrakos, P.; Grunhagen, D. J.; Nagtegaal, I. D.; Mollevi, D. G.; Jarnagin, W. R.; D Angelica, M. I.; Reynolds, A. R.; Doukas, M.; Desmedt, C.; Dirix, L.; Donckier, V.; Siegel, P. M.; Barnhill, R.; Gerling, M.; Verhoef, C",2022,"Histopathological growth patterns of liver metastasis: updated consensus guidelines for pattern scoring, perspectives, and recent mechanistic insights.",Pathology,"Histopathological growth patterns of liver metastasis: updated consensus guidelines for pattern scoring, perspectives, and recent mechanistic insights.","Latacz, E.; Hoppener, D.; Bohlok, A.; Leduc, S.; Tabaries, S.; Moro, C. F.; Lugassy, C.; Nystrom, H.; Bozoky, B.; Floris, G.; Geyer, N.; Brodt, P.; Llado, L.; Van Mileghem, L.; De Schepper, M.; Majeed, A. W.; Lazaris, A.; Dirix, P.; Zhang, Q.; Petrillo, S. K.; Vankerckhove, S.; Joye, I.; Meyer, Y.; Gregorieff, A.; Roig, N. R.; Vidal-Vanaclocha, F.; Denis, L.; Oliveira, R. C.; Metrakos, P.; Grunhagen, D. J.; Nagtegaal, I. D.; Mollevi, D. G.; Jarnagin, W. R.; D Angelica, M. I.; Reynolds, A. R.; Doukas, M.; Desmedt, C.; Dirix, L.; Donckier, V.; Siegel, P. M.; Barnhill, R.; Gerling, M.; Verhoef, C",Pathology,2022-04-10 00:00:00 UTC,"The first consensus guidelines for scoring the histopathological growth patterns (HGPs) of liver metastases were established in 2017. Since then, numerous studies have applied these guidelines, have further substantiated the potential clinical value of the HGPs in patients with liver metastases from various tumour types and are starting to shed light on the biology of the distinct HGPs. In the present guidelines, we give an overview of these studies, discuss novel strategies for predicting the HGPs of liver metastases, such as deep learning algorithms for whole slide histopathology images and medical imaging, and highlight liver metastasis animal models that exhibit features of the different HGPs. Based on a pooled analysis of large cohorts of patients with liver-metastatic colorectal cancer, we propose a new cut-off to categorize patients according to the HGPs. An up-to-date standard method for HGP assessment within liver metastases is also presented with the aim of incorporating HGPs into the decision-making processes surrounding the treatment of patients with liver metastatic cancer. Finally, we propose hypotheses on the cellular and molecular mechanisms that drive the biology of the different HGPs, opening some exciting pre-clinical and clinical research perspectives.",10.1101/2022.04.07.22273504,virology-deep-learning.xlsx,"Histopathological growth patterns of liver metastasis: updated consensus guidelines for pattern scoring, perspectives, and recent mechanistic insights. The first consensus guidelines for scoring the histopathological growth patterns (HGPs) of liver metastases were established in 2017. Since then, numerous studies have applied these guidelines, have further substantiated the potential clinical value of the HGPs in patients with liver metastases from various tumour types and are starting to shed light on the biology of the distinct HGPs. In the present guidelines, we give an overview of these studies, discuss novel strategies for predicting the HGPs of liver metastases, such as deep learning algorithms for whole slide histopathology images and medical imaging, and highlight liver metastasis animal models that exhibit features of the different HGPs. Based on a pooled analysis of large cohorts of patients with liver-metastatic colorectal cancer, we propose a new cut-off to categorize patients according to the HGPs. An up-to-date standard method for HGP assessment within liver metastases is also presented with the aim of incorporating HGPs into the decision-making processes surrounding the treatment of patients with liver metastatic cancer. Finally, we propose hypotheses on the cellular and molecular mechanisms that drive the biology of the different HGPs, opening some exciting pre-clinical and clinical research perspectives.",0
"Tsuneki, M.; Abe, M.; Kanavati, F.",2022,Weakly supervised and transfer learning for adenocarcinoma classification in transurethral resection of the prostate whole slide images,Pathology,Weakly supervised and transfer learning for adenocarcinoma classification in transurethral resection of the prostate whole slide images,"Tsuneki, M.; Abe, M.; Kanavati, F.",Pathology,2022-04-21 00:00:00 UTC,"The transurethral resection of the prostate (TUR-P) is generally considered an option for benign prostatic diseases especially nodular hyperplasia patients who have moderate to severe urinary problems that have not responded to medication. Importantly, incidental prostate cancer are diagnosed at the time of TUR-P for benign prostatic disease. Since diagnosing a large number of cases containing TUR-P specimens which are characterized by a very large volume of tissue fragments by pathologists using a conventional microscope is time-consuming and limited in terms of human resources. Thus, it is necessary to develop new techniques which can rapidly and accurately screen large numbers of TUR-P specimens. Computational pathology applications which can assist pathologists in detecting prostate adenocarcinoma from TUR-P whole slide images (WSIs) would be of great benefit for routine histopathological workflow. In this study, we trained deep learning models to classify TUR-P WSIs into prostate adenocarcinoma and benign (non-neoplastic) lesions using transfer and weakly supervised learning. We evaluated the models on TUR-P, needle biopsy, and The Cancer Genome Atlas (TCGA) public dataset test sets, achieving an ROC-AUC up to 0.984 in TUR-P test sets for adenocarcinoma. The results demonstrate the high promising potential of deployment in a practical TUR-P histopathological diagnostic workflow system.",10.1101/2022.04.20.22274062,virology-deep-learning.xlsx,"Weakly supervised and transfer learning for adenocarcinoma classification in transurethral resection of the prostate whole slide images The transurethral resection of the prostate (TUR-P) is generally considered an option for benign prostatic diseases especially nodular hyperplasia patients who have moderate to severe urinary problems that have not responded to medication. Importantly, incidental prostate cancer are diagnosed at the time of TUR-P for benign prostatic disease. Since diagnosing a large number of cases containing TUR-P specimens which are characterized by a very large volume of tissue fragments by pathologists using a conventional microscope is time-consuming and limited in terms of human resources. Thus, it is necessary to develop new techniques which can rapidly and accurately screen large numbers of TUR-P specimens. Computational pathology applications which can assist pathologists in detecting prostate adenocarcinoma from TUR-P whole slide images (WSIs) would be of great benefit for routine histopathological workflow. In this study, we trained deep learning models to classify TUR-P WSIs into prostate adenocarcinoma and benign (non-neoplastic) lesions using transfer and weakly supervised learning. We evaluated the models on TUR-P, needle biopsy, and The Cancer Genome Atlas (TCGA) public dataset test sets, achieving an ROC-AUC up to 0.984 in TUR-P test sets for adenocarcinoma. The results demonstrate the high promising potential of deployment in a practical TUR-P histopathological diagnostic workflow system.",0
"Wagner, S. J.; Matek, C.; Boushehri, S. S.; Boxberg, M.; Lamm, L.; Sadafi, A.; Waibel, D. J. E.; Marr, C.; Peng, T.",2022,Built to last? Reproducibility and Reusability of Deep Learning Algorithms in Computational Pathology,Pathology,Built to last? Reproducibility and Reusability of Deep Learning Algorithms in Computational Pathology,"Wagner, S. J.; Matek, C.; Boushehri, S. S.; Boxberg, M.; Lamm, L.; Sadafi, A.; Waibel, D. J. E.; Marr, C.; Peng, T.",Pathology,2022-05-31 00:00:00 UTC,"Recent progress in computational pathology has been driven by deep learning. While code and data availability are essential to reproduce findings from preceding publications, ensuring a deep learning models reusability is more challenging. For that, the codebase should be well-documented and easy to integrate in existing workflows, and models should be robust towards noise and generalizable towards data from different sources. Strikingly, only a few computational pathology algorithms have been reused by other researchers so far, let alone employed in a clinical setting.

To assess the current state of reproducibility and reusability of computational pathology algorithms, we evaluated peer-reviewed articles available in Pubmed, published between January 2019 and March 2021, in five use cases: stain normalization, tissue type segmentation, evaluation of cell-level features, genetic alteration prediction, and direct extraction of grading, staging, and prognostic information. We compiled criteria for data and code availability, and for statistical result analysis and assessed them in 161 publications. We found that only one quarter (42 out of 161 publications) made code publicly available and thus fulfilled our minimum requirement for reproducibility and reusability. Among these 42 papers, three quarters (30 out of 42) analyzed their results statistically, less than half (20 out of 42) have released their trained model weights, and only about a third (16 out of 42) used an independent cohort for evaluation.

This review highlights candidates for reproducible and reusable algorithms in computational pathology. It is intended for both pathologists interested in deep learning, and researchers applying deep learning algorithms to computational pathology challenges. We provide a list of reusable data handling tools and a detailed overview of the publications together with our criteria for reproducibility and reusability.",10.1101/2022.05.15.22275108,virology-deep-learning.xlsx,"Built to last? Reproducibility and Reusability of Deep Learning Algorithms in Computational Pathology Recent progress in computational pathology has been driven by deep learning. While code and data availability are essential to reproduce findings from preceding publications, ensuring a deep learning models reusability is more challenging. For that, the codebase should be well-documented and easy to integrate in existing workflows, and models should be robust towards noise and generalizable towards data from different sources. Strikingly, only a few computational pathology algorithms have been reused by other researchers so far, let alone employed in a clinical setting.

To assess the current state of reproducibility and reusability of computational pathology algorithms, we evaluated peer-reviewed articles available in Pubmed, published between January 2019 and March 2021, in five use cases: stain normalization, tissue type segmentation, evaluation of cell-level features, genetic alteration prediction, and direct extraction of grading, staging, and prognostic information. We compiled criteria for data and code availability, and for statistical result analysis and assessed them in 161 publications. We found that only one quarter (42 out of 161 publications) made code publicly available and thus fulfilled our minimum requirement for reproducibility and reusability. Among these 42 papers, three quarters (30 out of 42) analyzed their results statistically, less than half (20 out of 42) have released their trained model weights, and only about a third (16 out of 42) used an independent cohort for evaluation.

This review highlights candidates for reproducible and reusable algorithms in computational pathology. It is intended for both pathologists interested in deep learning, and researchers applying deep learning algorithms to computational pathology challenges. We provide a list of reusable data handling tools and a detailed overview of the publications together with our criteria for reproducibility and reusability.",0
"Medvedev, K. E.; Acosta, P. H.; Jia, L.; Grishin, N. V.",2023,Deep learning for subtypes identification of pure seminoma of the testis,Pathology,Deep learning for subtypes identification of pure seminoma of the testis,"Medvedev, K. E.; Acosta, P. H.; Jia, L.; Grishin, N. V.",Pathology,2023-11-05 00:00:00 UTC,"The most critical step in the clinical diagnosis workflow is the pathological evaluation of each tumor sample. Deep learning is a powerful approach that is widely used to enhance diagnostic accuracy and streamline the diagnosis process. In our previous study using omics data, we identified two distinct subtypes of pure seminoma. Seminoma is the most common histological type of testicular germ cell tumors (TGCTs). Here we developed a deep learning decision making tool for the identification of seminoma subtypes using histopathological slides. We used all available slides for pure seminoma samples from The Cancer Genome Atlas (TCGA). The developed model showed an area under the ROC curve of 0.896. Our model not only confirms the presence of two distinct subtypes within pure seminoma but also unveils the presence of morphological differences between them that are imperceptible to the human eye.",10.1101/2022.05.16.22275153,virology-deep-learning.xlsx,"Deep learning for subtypes identification of pure seminoma of the testis The most critical step in the clinical diagnosis workflow is the pathological evaluation of each tumor sample. Deep learning is a powerful approach that is widely used to enhance diagnostic accuracy and streamline the diagnosis process. In our previous study using omics data, we identified two distinct subtypes of pure seminoma. Seminoma is the most common histological type of testicular germ cell tumors (TGCTs). Here we developed a deep learning decision making tool for the identification of seminoma subtypes using histopathological slides. We used all available slides for pure seminoma samples from The Cancer Genome Atlas (TCGA). The developed model showed an area under the ROC curve of 0.896. Our model not only confirms the presence of two distinct subtypes within pure seminoma but also unveils the presence of morphological differences between them that are imperceptible to the human eye.",0
"Jin, D.; Rosenthal, J. H.; Thompson, E. E.; Dunnmon, J.; Olson, N. H.",2022,Independent assessment of a deep learning system for lymph node metastasis detection on the Augmented Reality Microscope,Pathology,Independent assessment of a deep learning system for lymph node metastasis detection on the Augmented Reality Microscope,"Jin, D.; Rosenthal, J. H.; Thompson, E. E.; Dunnmon, J.; Olson, N. H.",Pathology,2022-05-27 00:00:00 UTC,"Several machine learning algorithms have demonstrated high predictive capability in the identification of cancer within digitized pathology slides. The Augmented Reality Microscope (ARM) has allowed these algorithms to be seamlessly integrated within the current pathology workflow by overlaying their inferences onto its microscopic field of view in real time. In this paper, we present an independent assessment of the LYmph Node Assistant (LYNA) models, state-of-the-art algorithms for the identification of breast cancer metastases in lymph node biopsies which have been optimized for usage at different ARM magnifications. We assessed the models on a set of 40 whole slide images at the commonly used objective magnifications of 10x, 20x, and 40x. We analyzed the performance of the models across clinically relevant subclasses of tissue, including metastatic breast cancer, lymphocytes, histiocytes, veins, and fat. We also analyzed the models performance on potential types of contaminant tissue such as endometrial carcinoma and papillary thyroid cancer. Each model obtained overall AUC values of approximately 0.98, accuracy values of approximately 0.94, and sensitivity values above 0.88 at classifying small regions of a field of view as benign or cancerous. Across tissue subclasses, the models performed most accurately on fat and blood, and least accurately on histiocytes, germinal centers, and sinus. The models also struggled with the identification of isolated tumor cells, especially at lower magnifications. After testing, we manually reviewed the discrepancies between model predictions and ground truth in order to understand the causes of error. We introduce a distinction between proper and improper ground truth to allow for analysis in cases of uncertain annotations or on tasks with low inter-rater reliability. Taken together, these methods comprise a novel approach for exploratory model analysis over complex anatomic pathology data in which precise ground truth is difficult to establish.",10.1101/2022.05.24.22275431,virology-deep-learning.xlsx,"Independent assessment of a deep learning system for lymph node metastasis detection on the Augmented Reality Microscope Several machine learning algorithms have demonstrated high predictive capability in the identification of cancer within digitized pathology slides. The Augmented Reality Microscope (ARM) has allowed these algorithms to be seamlessly integrated within the current pathology workflow by overlaying their inferences onto its microscopic field of view in real time. In this paper, we present an independent assessment of the LYmph Node Assistant (LYNA) models, state-of-the-art algorithms for the identification of breast cancer metastases in lymph node biopsies which have been optimized for usage at different ARM magnifications. We assessed the models on a set of 40 whole slide images at the commonly used objective magnifications of 10x, 20x, and 40x. We analyzed the performance of the models across clinically relevant subclasses of tissue, including metastatic breast cancer, lymphocytes, histiocytes, veins, and fat. We also analyzed the models performance on potential types of contaminant tissue such as endometrial carcinoma and papillary thyroid cancer. Each model obtained overall AUC values of approximately 0.98, accuracy values of approximately 0.94, and sensitivity values above 0.88 at classifying small regions of a field of view as benign or cancerous. Across tissue subclasses, the models performed most accurately on fat and blood, and least accurately on histiocytes, germinal centers, and sinus. The models also struggled with the identification of isolated tumor cells, especially at lower magnifications. After testing, we manually reviewed the discrepancies between model predictions and ground truth in order to understand the causes of error. We introduce a distinction between proper and improper ground truth to allow for analysis in cases of uncertain annotations or on tasks with low inter-rater reliability. Taken together, these methods comprise a novel approach for exploratory model analysis over complex anatomic pathology data in which precise ground truth is difficult to establish.",0
"Tsuneki, M.; Kanavati, F.",2022,Weakly supervised learning for poorly differentiated adenocarcinoma classification in gastric endoscopic submucosal dissection whole slide images,Pathology,Weakly supervised learning for poorly differentiated adenocarcinoma classification in gastric endoscopic submucosal dissection whole slide images,"Tsuneki, M.; Kanavati, F.",Pathology,2022-11-10 00:00:00 UTC,"The endoscopic submucosal dissection (ESD) is the preferred technique for treating early gastric cancers including poorly differentiated adenocarcinoma without ulcerative findings. The histopathological classification of poorly differentiated adenocarcinoma including signet ring cell carcinoma is of pivotal importance for determining further optimum cancer treatment(s) and clinical outcomes. Because conventional diagnosis by pathologists using microscopes is time-consuming and limited in terms of human resources, it is very important to develop computer-aided techniques that can rapidly and accurately inspect large numbers of histopathological specimen whole-slide images (WSIs). Computational pathology applications which can assist pathologists in detecting and classifying gastric poorly differentiated adenocarcinoma from ESD WSIs would be of great benefit for routine histopathological diagnostic workflow. In this study, we trained the deep learning model to classify poorly differentiated adenocarcinoma in ESD WSIs by transfer and weakly supervised learning approaches. We evaluated the model on ESD, endoscopic biopsy, and surgical specimen WSI test sets, achieving and ROC-AUC up to 0.975 in gastric ESD test sets for poorly differentiated adenocarcinoma. The deep learning model developed in this study demonstrates the high promising potential of deployment in a routine practical gastric ESD histopathological diagnostic workflow as a computer-aided diagnosis system.",10.1101/2022.05.28.22275729,virology-deep-learning.xlsx,"Weakly supervised learning for poorly differentiated adenocarcinoma classification in gastric endoscopic submucosal dissection whole slide images The endoscopic submucosal dissection (ESD) is the preferred technique for treating early gastric cancers including poorly differentiated adenocarcinoma without ulcerative findings. The histopathological classification of poorly differentiated adenocarcinoma including signet ring cell carcinoma is of pivotal importance for determining further optimum cancer treatment(s) and clinical outcomes. Because conventional diagnosis by pathologists using microscopes is time-consuming and limited in terms of human resources, it is very important to develop computer-aided techniques that can rapidly and accurately inspect large numbers of histopathological specimen whole-slide images (WSIs). Computational pathology applications which can assist pathologists in detecting and classifying gastric poorly differentiated adenocarcinoma from ESD WSIs would be of great benefit for routine histopathological diagnostic workflow. In this study, we trained the deep learning model to classify poorly differentiated adenocarcinoma in ESD WSIs by transfer and weakly supervised learning approaches. We evaluated the model on ESD, endoscopic biopsy, and surgical specimen WSI test sets, achieving and ROC-AUC up to 0.975 in gastric ESD test sets for poorly differentiated adenocarcinoma. The deep learning model developed in this study demonstrates the high promising potential of deployment in a routine practical gastric ESD histopathological diagnostic workflow as a computer-aided diagnosis system.",0
"Deng, Q.",2024,A Deep Learning Enhanced Compartmental Model and its Application in Modeling Omicron Dynamics and Development in China,Epidemiology,A Deep Learning Enhanced Compartmental Model and its Application in Modeling Omicron Dynamics and Development in China,"Deng, Q.",Epidemiology,2024-04-03 00:00:00 UTC,"The mainstream compartmental models require stochastic parameterization to estimate the transmission parameters between compartments, which depends upon detailed statistics on epidemiological characteristics that are economically and resource-wide expensive to collect. As an alternative, deep learning techniques are effective in estimating these stochastic parameters with greatly reduced dependency on data particularity. We apply deep learning to estimate transmission parameters of a customized compartmental model, then feed the estimated transmission parameters to the compartmental model to predict the development of the Omicron epidemics in China for 28 days. The average levels of predication accuracy of the model are 98% and 92% for number of infections and deaths, respectively.",10.1101/2022.06.05.22276023,virology-deep-learning.xlsx,"A Deep Learning Enhanced Compartmental Model and its Application in Modeling Omicron Dynamics and Development in China The mainstream compartmental models require stochastic parameterization to estimate the transmission parameters between compartments, which depends upon detailed statistics on epidemiological characteristics that are economically and resource-wide expensive to collect. As an alternative, deep learning techniques are effective in estimating these stochastic parameters with greatly reduced dependency on data particularity. We apply deep learning to estimate transmission parameters of a customized compartmental model, then feed the estimated transmission parameters to the compartmental model to predict the development of the Omicron epidemics in China for 28 days. The average levels of predication accuracy of the model are 98% and 92% for number of infections and deaths, respectively.",0
"Cao, L.; Liu, Q.",2022,COVID-19 Modeling: A Review,Epidemiology,COVID-19 Modeling: A Review,"Cao, L.; Liu, Q.",Epidemiology,2022-09-26 00:00:00 UTC,"The unprecedented and overwhelming SARS-CoV-2 virus and COVID-19 disease significantly challenged our way of life, society and the economy. Many questions emerge, a critical one being how to quantify the challenges, realities, intervention effect and influence of the pandemic. With the massive effort that has been in relation to modeling COVID-19, what COVID-19 issues have been modeled? What and how well have epidemiology, AI, data science, machine learning, deep learning, mathematics and social science characterized the COVID-19 epidemic? what are the gaps and opportunities of quantifying the pandemic? Such questions involve a wide body of knowledge and literature, which are unclear but important for present and future health crisis quantification. Here, we provide a comprehensive review of the challenges, tasks, methods, progress, gaps and opportunities in relation to modeling COVID-19 processes, data, mitigation and impact. With a research landscape of COVID-19 modeling, we further categorize, summarize, compare and discuss the related methods and the progress which has been made in modeling COVID-19 epidemic transmission processes and dynamics, case identification and tracing, infection diagnosis and medical treatments, non-pharmaceutical interventions and their effects, drug and vaccine development, psychological, economic and social influence and impact, and misinformation, etc. The review shows how modeling methods such as mathematical and statistical models, domain-driven modeling by epidemiological compartmental models, medical and biomedical analysis, AI and data science, in particular shallow and deep machine learning, simulation modeling, social science methods and hybrid modeling have addressed the COVID-19 challenges, what gaps exist and what research directions can be followed for a better future.",10.1101/2022.08.22.22279022,virology-deep-learning.xlsx,"COVID-19 Modeling: A Review The unprecedented and overwhelming SARS-CoV-2 virus and COVID-19 disease significantly challenged our way of life, society and the economy. Many questions emerge, a critical one being how to quantify the challenges, realities, intervention effect and influence of the pandemic. With the massive effort that has been in relation to modeling COVID-19, what COVID-19 issues have been modeled? What and how well have epidemiology, AI, data science, machine learning, deep learning, mathematics and social science characterized the COVID-19 epidemic? what are the gaps and opportunities of quantifying the pandemic? Such questions involve a wide body of knowledge and literature, which are unclear but important for present and future health crisis quantification. Here, we provide a comprehensive review of the challenges, tasks, methods, progress, gaps and opportunities in relation to modeling COVID-19 processes, data, mitigation and impact. With a research landscape of COVID-19 modeling, we further categorize, summarize, compare and discuss the related methods and the progress which has been made in modeling COVID-19 epidemic transmission processes and dynamics, case identification and tracing, infection diagnosis and medical treatments, non-pharmaceutical interventions and their effects, drug and vaccine development, psychological, economic and social influence and impact, and misinformation, etc. The review shows how modeling methods such as mathematical and statistical models, domain-driven modeling by epidemiological compartmental models, medical and biomedical analysis, AI and data science, in particular shallow and deep machine learning, simulation modeling, social science methods and hybrid modeling have addressed the COVID-19 challenges, what gaps exist and what research directions can be followed for a better future.",1
"Du, H.; Dong, E.; Badr, H. S.; Petrone, M.; Grubaugh, N.; Gardner, L. M.",2022,A Deep Learning Approach to Forecast Short-Term COVID-19 Cases and Deaths in the US,Epidemiology,A Deep Learning Approach to Forecast Short-Term COVID-19 Cases and Deaths in the US,"Du, H.; Dong, E.; Badr, H. S.; Petrone, M.; Grubaugh, N.; Gardner, L. M.",Epidemiology,2022-08-24 00:00:00 UTC,"Since the US reported its first COVID-19 case on January 21, 2020, the science community has been applying various techniques to forecast incident cases and deaths. To date, providing an accurate and robust forecast at a high spatial resolution has proved challenging, even in the short term. Here we present a novel multi-stage deep learning model to forecast the number of COVID-19 cases and deaths for each US state at a weekly level for a forecast horizon of 1 to 4 weeks. The model is heavily data driven, and relies on epidemiological, mobility, survey, climate, and demographic. We further present results from a case study that incorporates SARS-CoV-2 genomic data (i.e. variant cases) to demonstrate the value of incorporating variant cases data into model forecast tools. We implement a rigorous and robust evaluation of our model - specifically we report on weekly performance over a one-year period based on multiple error metrics, and explicitly assess how our model performance varies over space, chronological time, and different outbreak phases. The proposed model is shown to consistently outperform the CDC ensemble model for all evaluation metrics in multiple spatiotemporal settings, especially for the longer-term (3 and 4 weeks ahead) forecast horizon. Our case study also highlights the potential value of virus genomic data for use in short-term forecasting to identify forthcoming surges driven by new variants. Based on our findings, the proposed forecasting framework improves upon the available forecasting tools currently used to support public health decision making with respect to COVID-19 risk.

Research in contextO_ST_ABSEvidence before this studyC_ST_ABSA systematic review of the COVID-19 forecasting and the EPIFORGE 2020 guidelines reveal the lack of consistency, reproducibility, comparability, and quality in the current COVID-19 forecasting literature. To provide an updated survey of the literature, we carried out our literature search on Google Scholar, PubMed, and medRxi, using the terms ""Covid-19,"" ""SARS-CoV-2,"" ""coronavirus,"" ""short-term,"" ""forecasting,"" and ""genomic surveillance."" Although the literature includes a significant number of papers, it remains lacking with respect to rigorous model evaluation, interpretability and translation. Furthermore, while SARS-CoV-2 genomic surveillance is emerging as a vital necessity to fight COVID-19 (i.e. wastewater sampling and airport screening), to our knowledge, no published forecasting model has illustrated the value of virus genomic data for informing future outbreaks.

Added value of this studyWe propose a multi-stage deep learning model to forecast COVID-19 cases and deaths with a horizon window of four weeks. The data driven model relies on a comprehensive set of input features, including epidemiological, mobility, behavioral survey, climate, and demographic. We present a robust evaluation framework to systematically assess the model performance over a one-year time span, and using multiple error metrics. This rigorous evaluation framework reveals how the predictive accuracy varies over chronological time, space, and outbreak phase. Further, a comparative analysis against the CDC ensemble, the best performing model in the COVID-19 ForecastHub, shows the model to consistently outperform the CDC ensemble for all evaluation metrics in multiple spatiotemporal settings, especially for the longer forecasting windows. We also conduct a feature analysis, and show that the role of explanatory features changes over time. Specifically, we note a changing role of climate variables on model performance in the latter half of the study period. Lastly, we present a case study that reveals how incorporating SARS-CoV-2 genomic surveillance data may improve forecasting accuracy compared to a model without variant cases data.

Implications of all the available evidenceResults from the robust evaluation analysis highlight extreme model performance variability over time and space, and suggest that forecasting models should be accompanied with specifications on the conditions under which they perform best (and worst), in order to maximize their value and utility in aiding public health decision making. The feature analysis reveals the complex and changing role of factors contributing to COVID-19 transmission over time, and suggests a possible seasonality effect of climate on COVID-19 spread, but only after August 2021. Finally, the case study highlights the added value of using genomic surveillance data in short-term epidemiological forecasting models, especially during the early stage of new variant introductions.",10.1101/2022.08.23.22279132,virology-deep-learning.xlsx,"A Deep Learning Approach to Forecast Short-Term COVID-19 Cases and Deaths in the US Since the US reported its first COVID-19 case on January 21, 2020, the science community has been applying various techniques to forecast incident cases and deaths. To date, providing an accurate and robust forecast at a high spatial resolution has proved challenging, even in the short term. Here we present a novel multi-stage deep learning model to forecast the number of COVID-19 cases and deaths for each US state at a weekly level for a forecast horizon of 1 to 4 weeks. The model is heavily data driven, and relies on epidemiological, mobility, survey, climate, and demographic. We further present results from a case study that incorporates SARS-CoV-2 genomic data (i.e. variant cases) to demonstrate the value of incorporating variant cases data into model forecast tools. We implement a rigorous and robust evaluation of our model - specifically we report on weekly performance over a one-year period based on multiple error metrics, and explicitly assess how our model performance varies over space, chronological time, and different outbreak phases. The proposed model is shown to consistently outperform the CDC ensemble model for all evaluation metrics in multiple spatiotemporal settings, especially for the longer-term (3 and 4 weeks ahead) forecast horizon. Our case study also highlights the potential value of virus genomic data for use in short-term forecasting to identify forthcoming surges driven by new variants. Based on our findings, the proposed forecasting framework improves upon the available forecasting tools currently used to support public health decision making with respect to COVID-19 risk.

Research in contextO_ST_ABSEvidence before this studyC_ST_ABSA systematic review of the COVID-19 forecasting and the EPIFORGE 2020 guidelines reveal the lack of consistency, reproducibility, comparability, and quality in the current COVID-19 forecasting literature. To provide an updated survey of the literature, we carried out our literature search on Google Scholar, PubMed, and medRxi, using the terms ""Covid-19,"" ""SARS-CoV-2,"" ""coronavirus,"" ""short-term,"" ""forecasting,"" and ""genomic surveillance."" Although the literature includes a significant number of papers, it remains lacking with respect to rigorous model evaluation, interpretability and translation. Furthermore, while SARS-CoV-2 genomic surveillance is emerging as a vital necessity to fight COVID-19 (i.e. wastewater sampling and airport screening), to our knowledge, no published forecasting model has illustrated the value of virus genomic data for informing future outbreaks.

Added value of this studyWe propose a multi-stage deep learning model to forecast COVID-19 cases and deaths with a horizon window of four weeks. The data driven model relies on a comprehensive set of input features, including epidemiological, mobility, behavioral survey, climate, and demographic. We present a robust evaluation framework to systematically assess the model performance over a one-year time span, and using multiple error metrics. This rigorous evaluation framework reveals how the predictive accuracy varies over chronological time, space, and outbreak phase. Further, a comparative analysis against the CDC ensemble, the best performing model in the COVID-19 ForecastHub, shows the model to consistently outperform the CDC ensemble for all evaluation metrics in multiple spatiotemporal settings, especially for the longer forecasting windows. We also conduct a feature analysis, and show that the role of explanatory features changes over time. Specifically, we note a changing role of climate variables on model performance in the latter half of the study period. Lastly, we present a case study that reveals how incorporating SARS-CoV-2 genomic surveillance data may improve forecasting accuracy compared to a model without variant cases data.

Implications of all the available evidenceResults from the robust evaluation analysis highlight extreme model performance variability over time and space, and suggest that forecasting models should be accompanied with specifications on the conditions under which they perform best (and worst), in order to maximize their value and utility in aiding public health decision making. The feature analysis reveals the complex and changing role of factors contributing to COVID-19 transmission over time, and suggests a possible seasonality effect of climate on COVID-19 spread, but only after August 2021. Finally, the case study highlights the added value of using genomic surveillance data in short-term epidemiological forecasting models, especially during the early stage of new variant introductions.",1
"Song, Y.; Cisternino, F.; Mekke, J. M.; De Borst, G. J.; De Kleijn, D. P. V.; Pasterkamp, G.; Vink, A.; Glastonbury, C. A.; Van Der Laan, S. W.; Miller, C. L.",2022,An automatic entropy method to efficiently mask histology whole-slide images,Pathology,An automatic entropy method to efficiently mask histology whole-slide images,"Song, Y.; Cisternino, F.; Mekke, J. M.; De Borst, G. J.; De Kleijn, D. P. V.; Pasterkamp, G.; Vink, A.; Glastonbury, C. A.; Van Der Laan, S. W.; Miller, C. L.",Pathology,2022-09-02 00:00:00 UTC,"BackgroundTissue segmentation of histology whole-slide images (WSI) remains a critical task in automated digital pathology workflows for both accurate disease diagnosis and deep phenotyping for research purposes. This is especially challenging when the tissue structure of biospecimens is relatively porous and heterogeneous, such as for atherosclerotic plaques.

MethodsIn this study, we developed a unique approach called EntropyMasker based on image entropy to tackle the fore- and background segmentation (masking) task in histology WSI. We evaluated our method on 97 high-resolution WSI of human carotid atherosclerotic plaques in the Athero-Express Biobank Study, constituting hematoxylin and eosin (H&E) and 8 other staining types.

Results and ConclusionUsing multiple benchmarking metrics, we compared our method with four widely used segmentation methods: Otsus method, Adaptive mean, Adaptive Gaussian and slideMask and observed that our method had the highest sensitivity and Jaccard similarity index. We envision EntropyMasker to fill an important gap in WSI preprocessing and deep learning image analysis pipelines and enable disease phenotyping beyond the field of atherosclerosis.",10.1101/2022.09.01.22279487,virology-deep-learning.xlsx,"An automatic entropy method to efficiently mask histology whole-slide images BackgroundTissue segmentation of histology whole-slide images (WSI) remains a critical task in automated digital pathology workflows for both accurate disease diagnosis and deep phenotyping for research purposes. This is especially challenging when the tissue structure of biospecimens is relatively porous and heterogeneous, such as for atherosclerotic plaques.

MethodsIn this study, we developed a unique approach called EntropyMasker based on image entropy to tackle the fore- and background segmentation (masking) task in histology WSI. We evaluated our method on 97 high-resolution WSI of human carotid atherosclerotic plaques in the Athero-Express Biobank Study, constituting hematoxylin and eosin (H&E) and 8 other staining types.

Results and ConclusionUsing multiple benchmarking metrics, we compared our method with four widely used segmentation methods: Otsus method, Adaptive mean, Adaptive Gaussian and slideMask and observed that our method had the highest sensitivity and Jaccard similarity index. We envision EntropyMasker to fill an important gap in WSI preprocessing and deep learning image analysis pipelines and enable disease phenotyping beyond the field of atherosclerosis.",0
"Tsuneki, M.; Abe, M.; Ichihara, S.; Kanavati, F.",2022,Inference of core needle biopsy whole slide images requiring definitive therapy for prostate cancer,Pathology,Inference of core needle biopsy whole slide images requiring definitive therapy for prostate cancer,"Tsuneki, M.; Abe, M.; Ichihara, S.; Kanavati, F.",Pathology,2022-09-06 00:00:00 UTC,"Prostate cancer is often a slowly progressive indolent disease. Unnecessary treatments from overdiagnosis are a significant concern, particularly low-grade disease. Active surveillance has being considered as a risk management strategy to avoid potential side effects by unnecessary radical treatment. In 2016, American Society of Clinical Oncology (ASCO) endorsed the Cancer Care Ontario (CCO) Clinical Practice Guideline on active surveillance for the management of localized prostate cancer. Based on this guideline, we developed a deep learning model to classify prostate adenocarcinoma into indolent (applicable for active surveillance) and aggressive (necessary for definitive therapy) on core needle biopsy whole slide images (WSIs). In this study, we trained deep learning models using a combination of transfer, weakly supervised, and fully supervised learning approaches using a dataset of core needle biopsy WSIs (n=1300). We evaluated the models on a test set (n=645), achieving ROC-AUCs 0.846 (indolent) and 0.980 (aggressive). The results demonstrate the promising potential of deployment in a practical prostate adenocarcinoma histopathological diagnostic workflow system.",10.1101/2022.09.06.22279630,virology-deep-learning.xlsx,"Inference of core needle biopsy whole slide images requiring definitive therapy for prostate cancer Prostate cancer is often a slowly progressive indolent disease. Unnecessary treatments from overdiagnosis are a significant concern, particularly low-grade disease. Active surveillance has being considered as a risk management strategy to avoid potential side effects by unnecessary radical treatment. In 2016, American Society of Clinical Oncology (ASCO) endorsed the Cancer Care Ontario (CCO) Clinical Practice Guideline on active surveillance for the management of localized prostate cancer. Based on this guideline, we developed a deep learning model to classify prostate adenocarcinoma into indolent (applicable for active surveillance) and aggressive (necessary for definitive therapy) on core needle biopsy whole slide images (WSIs). In this study, we trained deep learning models using a combination of transfer, weakly supervised, and fully supervised learning approaches using a dataset of core needle biopsy WSIs (n=1300). We evaluated the models on a test set (n=645), achieving ROC-AUCs 0.846 (indolent) and 0.980 (aggressive). The results demonstrate the promising potential of deployment in a practical prostate adenocarcinoma histopathological diagnostic workflow system.",0
"Kim, J.; Tomita, N.; Suriawinata, A. A.; Hassanpour, S.",2022,Detection of Colorectal Adenocarcinoma and Grading Dysplasia on Histopathologic Slides Using Deep Learning,Pathology,Detection of Colorectal Adenocarcinoma and Grading Dysplasia on Histopathologic Slides Using Deep Learning,"Kim, J.; Tomita, N.; Suriawinata, A. A.; Hassanpour, S.",Pathology,2022-09-22 00:00:00 UTC,"Colorectal cancer is one of the most common types of cancer among men and women. The grading of dysplasia and the detection of adenocarcinoma are important clinical tasks in the diagnosis of colorectal cancer and shape the patients follow-up plans. This study evaluates the feasibility of deep learning models for the classification of colorectal lesions into four classes: benign, low-grade dysplasia, high-grade dysplasia, and adenocarcinoma. To this end, we develop a deep neural network on a training set of 655 whole-slide images of digitized colorectal resection slides from a tertiary medical institution and evaluate it on an internal test set of 234 slides, as well as on an external test set of 606 adenocarcinoma slides from The Cancer Genome Atlas database. Our model achieves an overall accuracy, sensitivity, and specificity of 95.5%, 91.0%, and 97.1% on the internal test set and an accuracy and sensitivity of 98.5% for adenocarcinoma detection task on the external test set. Our results suggest that such deep learning models can potentially assist pathologists in grading colorectal dysplasia, detecting adenocarcinoma, prescreening, and prioritizing the reviewing of suspicious cases to improve the turnaround time for patients with a high risk of colorectal cancer. Furthermore, the high sensitivity on the external test set suggests our models generalizability in detecting colorectal adenocarcinoma on whole slide images across different institutions.",10.1101/2022.09.19.22280112,virology-deep-learning.xlsx,"Detection of Colorectal Adenocarcinoma and Grading Dysplasia on Histopathologic Slides Using Deep Learning Colorectal cancer is one of the most common types of cancer among men and women. The grading of dysplasia and the detection of adenocarcinoma are important clinical tasks in the diagnosis of colorectal cancer and shape the patients follow-up plans. This study evaluates the feasibility of deep learning models for the classification of colorectal lesions into four classes: benign, low-grade dysplasia, high-grade dysplasia, and adenocarcinoma. To this end, we develop a deep neural network on a training set of 655 whole-slide images of digitized colorectal resection slides from a tertiary medical institution and evaluate it on an internal test set of 234 slides, as well as on an external test set of 606 adenocarcinoma slides from The Cancer Genome Atlas database. Our model achieves an overall accuracy, sensitivity, and specificity of 95.5%, 91.0%, and 97.1% on the internal test set and an accuracy and sensitivity of 98.5% for adenocarcinoma detection task on the external test set. Our results suggest that such deep learning models can potentially assist pathologists in grading colorectal dysplasia, detecting adenocarcinoma, prescreening, and prioritizing the reviewing of suspicious cases to improve the turnaround time for patients with a high risk of colorectal cancer. Furthermore, the high sensitivity on the external test set suggests our models generalizability in detecting colorectal adenocarcinoma on whole slide images across different institutions.",0
"Chen, J.; Xu, Z.; Sun, L.; Yu, K.; Hersh, C. P.; Boueiz, A.; Hokanson, J.; Sciurba, F. C.; Silverman, E. K.; Castaldi, P. J.; Batmanghelich, K.",2022,Deep Learning Integration of Chest CT Imaging and Gene Expression Identifies Novel Aspects of COPD,Respiratory Medicine,Deep Learning Integration of Chest CT Imaging and Gene Expression Identifies Novel Aspects of COPD,"Chen, J.; Xu, Z.; Sun, L.; Yu, K.; Hersh, C. P.; Boueiz, A.; Hokanson, J.; Sciurba, F. C.; Silverman, E. K.; Castaldi, P. J.; Batmanghelich, K.",Respiratory Medicine,2022-10-14 00:00:00 UTC,"RationaleChronic obstructive pulmonary disease (COPD) is characterized by pathologic changes in the airways, lung parenchyma, and persistent inflammation, but the links between lung structural changes and patterns of systemic inflammation have not been fully described.

ObjectivesTo identify novel relationships between lung structural changes measured by chest computed tomography (CT) and systemic inflammation measured by blood RNA sequencing.

MethodsCT scan images and blood RNA-seq gene expression from 1,223 subjects in the COPDGene study were jointly analyzed using deep learning to identify shared aspects of inflammation and lung structural changes that we refer to as Image-Expression Axes (IEAs). We related IEAs to COPD-related measurements and prospective health outcomes through regression and Cox proportional hazards models and tested them for biological pathway enrichment.

Measurements and Main ResultsWe identified two distinct IEAs: IEAemph captures an emphysema-predominant process with a strong positive correlation to CT emphysema and a negative correlation to FEV1 and Body Mass Index (BMI); IEAairway captures an airway-predominant process with a positive correlation to BMI and airway wall thickness and a negative correlation to emphysema. Pathway enrichment analysis identified 29 and 13 pathways significantly associated with IEAemph and IEAairway, respectively (adjusted p<0.001).

ConclusionsIntegration of CT scans and gene expression data identified two IEAs that capture distinct inflammatory processes associated with emphysema and airway-predominant COPD.

At a Glance CommentaryO_ST_ABSScientific Knowledge on the SubjectC_ST_ABSChronic obstructive pulmonary disease (COPD) is characterized by lung structural changes and has a prominent systemic inflammatory component, but the links between lung structural changes and patterns of systemic inflammation in COPD have not been fully described.

What This Study Adds to the FieldWe identified novel relationships between lung structural changes and systemic inflammation by simultaneously analyzing CT scans and blood RNA-sequencing gene expression using deep learning models. We identified two distinct Image-Expression Axes (IEAs) that characterize different inflammatory processes associated with emphysema and airway predominant COPD.

This article has an online data supplement, which is accessible from this issues table of content online at www.atsjournals.org.",10.1101/2022.09.26.22280242,virology-deep-learning.xlsx,"Deep Learning Integration of Chest CT Imaging and Gene Expression Identifies Novel Aspects of COPD RationaleChronic obstructive pulmonary disease (COPD) is characterized by pathologic changes in the airways, lung parenchyma, and persistent inflammation, but the links between lung structural changes and patterns of systemic inflammation have not been fully described.

ObjectivesTo identify novel relationships between lung structural changes measured by chest computed tomography (CT) and systemic inflammation measured by blood RNA sequencing.

MethodsCT scan images and blood RNA-seq gene expression from 1,223 subjects in the COPDGene study were jointly analyzed using deep learning to identify shared aspects of inflammation and lung structural changes that we refer to as Image-Expression Axes (IEAs). We related IEAs to COPD-related measurements and prospective health outcomes through regression and Cox proportional hazards models and tested them for biological pathway enrichment.

Measurements and Main ResultsWe identified two distinct IEAs: IEAemph captures an emphysema-predominant process with a strong positive correlation to CT emphysema and a negative correlation to FEV1 and Body Mass Index (BMI); IEAairway captures an airway-predominant process with a positive correlation to BMI and airway wall thickness and a negative correlation to emphysema. Pathway enrichment analysis identified 29 and 13 pathways significantly associated with IEAemph and IEAairway, respectively (adjusted p<0.001).

ConclusionsIntegration of CT scans and gene expression data identified two IEAs that capture distinct inflammatory processes associated with emphysema and airway-predominant COPD.

At a Glance CommentaryO_ST_ABSScientific Knowledge on the SubjectC_ST_ABSChronic obstructive pulmonary disease (COPD) is characterized by lung structural changes and has a prominent systemic inflammatory component, but the links between lung structural changes and patterns of systemic inflammation in COPD have not been fully described.

What This Study Adds to the FieldWe identified novel relationships between lung structural changes and systemic inflammation by simultaneously analyzing CT scans and blood RNA-sequencing gene expression using deep learning models. We identified two distinct Image-Expression Axes (IEAs) that characterize different inflammatory processes associated with emphysema and airway predominant COPD.

This article has an online data supplement, which is accessible from this issues table of content online at www.atsjournals.org.",0
"Aswolinskiy, W.; Munari, E.; Horlings, H. M.; Mulder, L.; Bogina, G.; Sanders, J.; Liu, Y.-H.; Van Den Belt-Dusebout, A. W.; Tessier, L.; Balkenhol, M.; Hoven, J.; Wesseling, J.; Van Der Laak, J.; Lips, E. H.; Ciompi, F.",2022,Predicting pathological complete response to neoadjuvant chemotherapy in breast cancer from routine diagnostic histopathology biopsies,Pathology,Predicting pathological complete response to neoadjuvant chemotherapy in breast cancer from routine diagnostic histopathology biopsies,"Aswolinskiy, W.; Munari, E.; Horlings, H. M.; Mulder, L.; Bogina, G.; Sanders, J.; Liu, Y.-H.; Van Den Belt-Dusebout, A. W.; Tessier, L.; Balkenhol, M.; Hoven, J.; Wesseling, J.; Van Der Laak, J.; Lips, E. H.; Ciompi, F.",Pathology,2022-12-08 00:00:00 UTC,"PurposeInvasive breast cancer patients are increasingly being treated with neoadjuvant chemotherapy, however, only a fraction of the patients respond to it completely. To prevent over-treating patients with a toxic drug, there is an urgent need for biomarkers capable of predicting treatment response before administering the therapy. In this retrospective study, we developed interpretable, deep-learning based biomarkers to predict the pathological complete response (pCR, i.e. the absence of tumor cells in the surgical resection specimens) to neoadjuvant chemotherapy from digital pathology H&E images of pre-treatment breast biopsies.

Experimental DesignOur approach consists of two steps: In the first step, using deep learning, mitoses are detected and the tissue segmented into several morphology compartments including tumor, lymphocytes and stroma. In the second step, computational biomarkers are derived from the segmentation and detection output to encode slide-level relationships between the morphological structures with focus on tumor infiltrating lymphocytes (TILs). We developed and evaluated our method on slides from N=721 patients from three European medical centers with triple-negative and Luminal B breast cancers.

ResultsThe investigated biomarkers yield statistically significant prediction performance for pCR with areas under the receiver operating characteristic curve between 0.66 and 0.88 depending on the cancer subtype and center.

ConclusionThe proposed computational biomarkers predict pathological complete response, but will require more evaluation and finetuning for clinical application. The results further corroborate the potential role of deep learning to automate TILs quantification, and their predictive value in breast cancer neoadjuvant treatment planning.",10.1101/2022.11.11.22282205,virology-deep-learning.xlsx,"Predicting pathological complete response to neoadjuvant chemotherapy in breast cancer from routine diagnostic histopathology biopsies PurposeInvasive breast cancer patients are increasingly being treated with neoadjuvant chemotherapy, however, only a fraction of the patients respond to it completely. To prevent over-treating patients with a toxic drug, there is an urgent need for biomarkers capable of predicting treatment response before administering the therapy. In this retrospective study, we developed interpretable, deep-learning based biomarkers to predict the pathological complete response (pCR, i.e. the absence of tumor cells in the surgical resection specimens) to neoadjuvant chemotherapy from digital pathology H&E images of pre-treatment breast biopsies.

Experimental DesignOur approach consists of two steps: In the first step, using deep learning, mitoses are detected and the tissue segmented into several morphology compartments including tumor, lymphocytes and stroma. In the second step, computational biomarkers are derived from the segmentation and detection output to encode slide-level relationships between the morphological structures with focus on tumor infiltrating lymphocytes (TILs). We developed and evaluated our method on slides from N=721 patients from three European medical centers with triple-negative and Luminal B breast cancers.

ResultsThe investigated biomarkers yield statistically significant prediction performance for pCR with areas under the receiver operating characteristic curve between 0.66 and 0.88 depending on the cancer subtype and center.

ConclusionThe proposed computational biomarkers predict pathological complete response, but will require more evaluation and finetuning for clinical application. The results further corroborate the potential role of deep learning to automate TILs quantification, and their predictive value in breast cancer neoadjuvant treatment planning.",0
"Melbye, H.; Ravn, J.; Pabiszczak, M.; Bongo, L. A.; Aviles Solis, J. C.",2023,Validity of a deep learning algorithm for detecting wheezes and crackles from lung sound recordings in adults,Respiratory Medicine,Validity of a deep learning algorithm for detecting wheezes and crackles from lung sound recordings in adults,"Melbye, H.; Ravn, J.; Pabiszczak, M.; Bongo, L. A.; Aviles Solis, J. C.",Respiratory Medicine,2023-01-27 00:00:00 UTC,"We validated our state-of-the-art deep learning algorithm for detection of wheezes and crackles in sound files by comparing the classification of our algorithm with those of human experts. We had two validation sets classified by experienced raters that were not used to train the algorithm with 615 (A) and 120 (B) sound files, respectively. We calculated Area Under Curve (AUC) of the algorithms probability scores for wheezes and crackles. We dichotomized the scores and calculated sensitivity and specificity as well as kappa agreement. In set A, the AUC was 0.88 (95% CI 0.84 - 0.92) for wheezes and 0.88 (95% CI 0.84 - 0.92) for crackles. The sensitivities and specificities of the labels were 81% and 89% for wheezes and 67% and 96% for crackles. In set B, the kappa agreement between the algorithm and the validation set was 0.78 (95% CI 0.58 - 0.99) for wheezes and 0.75 (95% CI 0.59 - 0.92) for crackles. The 24 observers who had rated the same 120 sound files agreed less with the reference classification with a mean kappa of 0.68 for wheezes and 0.55 for crackles. We found the algorithm to be superior to doctors in detecting wheezes and crackles in lung sound files.",10.1101/2022.11.18.22282442,virology-deep-learning.xlsx,"Validity of a deep learning algorithm for detecting wheezes and crackles from lung sound recordings in adults We validated our state-of-the-art deep learning algorithm for detection of wheezes and crackles in sound files by comparing the classification of our algorithm with those of human experts. We had two validation sets classified by experienced raters that were not used to train the algorithm with 615 (A) and 120 (B) sound files, respectively. We calculated Area Under Curve (AUC) of the algorithms probability scores for wheezes and crackles. We dichotomized the scores and calculated sensitivity and specificity as well as kappa agreement. In set A, the AUC was 0.88 (95% CI 0.84 - 0.92) for wheezes and 0.88 (95% CI 0.84 - 0.92) for crackles. The sensitivities and specificities of the labels were 81% and 89% for wheezes and 67% and 96% for crackles. In set B, the kappa agreement between the algorithm and the validation set was 0.78 (95% CI 0.58 - 0.99) for wheezes and 0.75 (95% CI 0.59 - 0.92) for crackles. The 24 observers who had rated the same 120 sound files agreed less with the reference classification with a mean kappa of 0.68 for wheezes and 0.55 for crackles. We found the algorithm to be superior to doctors in detecting wheezes and crackles in lung sound files.",0
"Bilal, M.; Tsang, Y. W.; Ali, M.; Graham, S.; Hero, E.; Wahab, N.; Dodd, K.; Sahota, H.; Wu, S.; Lu, W.; Jahanifar, M.; Robinson, A.; Azam, A.; Benes, K.; Nimir, M.; Hewitt, K.; Bhalerao, A.; Eldaly, H.; Raza, S. E. A.; Gopalakrishnan, K.; Minhas, F.; Snead, D.; Rajpoot, N.",2022,Development and validation of AI-based pre-screening of large bowel biopsies,Pathology,Development and validation of AI-based pre-screening of large bowel biopsies,"Bilal, M.; Tsang, Y. W.; Ali, M.; Graham, S.; Hero, E.; Wahab, N.; Dodd, K.; Sahota, H.; Wu, S.; Lu, W.; Jahanifar, M.; Robinson, A.; Azam, A.; Benes, K.; Nimir, M.; Hewitt, K.; Bhalerao, A.; Eldaly, H.; Raza, S. E. A.; Gopalakrishnan, K.; Minhas, F.; Snead, D.; Rajpoot, N.",Pathology,2022-12-01 00:00:00 UTC,"BackgroundHistopathological examination is a pivotal step in the diagnosis and treatment planning of many major diseases. With the aims of facilitating diagnostic decision-making and improving the use of pathologists time, we developed an AI-based pre-screening tool that analyses whole slide images (WSIs) of large bowel biopsies to identify normal, inflammatory, and neoplastic biopsies.

MethodsTo learn the differential histological patterns from digitised WSIs of large bowel biopsy slides stained with Haematoxylin and Eosin (H&E), our proposed weakly supervised deep learning method uses only slide-level diagnostic labels and no detailed cell or region-level annotations. The proposed method was developed on an internal cohort of biopsy slides (n=5054) from a single laboratory labelled with corresponding diagnostic categories assigned by pathologists. Performance of the tool was evaluated on the internal development cohort (n=5054) in a cross-validation setting, and three external unseen cohorts (n=1536) for independent validation.

FindingsThe proposed tool demonstrates high degree of accuracy to assist with the pre-screening of large bowel biopsies, being able to identify neoplastic biopsies (AUROC = 0{middle dot}993), inflammatory biopsies (AUROC = 0{middle dot}966) and all abnormal biopsies (AUROC = 0{middle dot}979). On the three independent validation cohorts, it achieves AUROC values of 0{middle dot}943, 0{middle dot}958 and 0{middle dot}964 for the detection of abnormal biopsies. Analysis of saliency maps confirms the representation of disease heterogeneity in model predictions and their association with relevant histological features. Interestingly, after examining diagnostic discrepancies between the proposed AI tool and original diagnostic labels, a panel of pathologists found that the proposed tool correctly identified a number of abnormal slides that had been initially reported as normal.

InterpretationsThe proposed tool with its high sensitivity of detecting abnormal colorectal biopsies promises significant improvements in clinical workflow efficiency and assistance in diagnostic decision-making through pre-screening of normal biopsies.

FundingInnovate UK on behalf of UK Research and Innovation.",10.1101/2022.11.30.22282859,virology-deep-learning.xlsx,"Development and validation of AI-based pre-screening of large bowel biopsies BackgroundHistopathological examination is a pivotal step in the diagnosis and treatment planning of many major diseases. With the aims of facilitating diagnostic decision-making and improving the use of pathologists time, we developed an AI-based pre-screening tool that analyses whole slide images (WSIs) of large bowel biopsies to identify normal, inflammatory, and neoplastic biopsies.

MethodsTo learn the differential histological patterns from digitised WSIs of large bowel biopsy slides stained with Haematoxylin and Eosin (H&E), our proposed weakly supervised deep learning method uses only slide-level diagnostic labels and no detailed cell or region-level annotations. The proposed method was developed on an internal cohort of biopsy slides (n=5054) from a single laboratory labelled with corresponding diagnostic categories assigned by pathologists. Performance of the tool was evaluated on the internal development cohort (n=5054) in a cross-validation setting, and three external unseen cohorts (n=1536) for independent validation.

FindingsThe proposed tool demonstrates high degree of accuracy to assist with the pre-screening of large bowel biopsies, being able to identify neoplastic biopsies (AUROC = 0{middle dot}993), inflammatory biopsies (AUROC = 0{middle dot}966) and all abnormal biopsies (AUROC = 0{middle dot}979). On the three independent validation cohorts, it achieves AUROC values of 0{middle dot}943, 0{middle dot}958 and 0{middle dot}964 for the detection of abnormal biopsies. Analysis of saliency maps confirms the representation of disease heterogeneity in model predictions and their association with relevant histological features. Interestingly, after examining diagnostic discrepancies between the proposed AI tool and original diagnostic labels, a panel of pathologists found that the proposed tool correctly identified a number of abnormal slides that had been initially reported as normal.

InterpretationsThe proposed tool with its high sensitivity of detecting abnormal colorectal biopsies promises significant improvements in clinical workflow efficiency and assistance in diagnostic decision-making through pre-screening of normal biopsies.

FundingInnovate UK on behalf of UK Research and Innovation.",0
"Singh, A.; Wan, M.; Harrison, L.; Breggia, A.; Christman, R.; Winslow, R. L.; Amal, S.",2022,Visualizing Decisions and Analytics of Artificial Intelligence based Cancer Diagnosis and Grading of Specimen Digitized Biopsy: Case Study for Prostate Cancer,Pathology,Visualizing Decisions and Analytics of Artificial Intelligence based Cancer Diagnosis and Grading of Specimen Digitized Biopsy: Case Study for Prostate Cancer,"Singh, A.; Wan, M.; Harrison, L.; Breggia, A.; Christman, R.; Winslow, R. L.; Amal, S.",Pathology,2022-12-23 00:00:00 UTC,"1The rise in Artificial Intelligence (AI) and deep learning research has shown great promise in diagnosing prostate cancer from whole slide image biopsies. Intelligent application interface for diagnosis is a progressive way to communicate AI results in the medical domain for practical use. This paper aims to suggest a way to integrate state-of-the-art deep learning algorithms into a web application for visualizations of decisions and analytics of an AI based algorithms applied on cancer digitized specimen biopsies together with visualizing evidence and explanation of the decision using both image from the biopsy and textual data from Electronic Health Records (EHR). By creating smart visualizations of tissue biopsy images, from magnified regions to augmented sharper images along with image masks that highlight cancerous regions of tissue in addition to intelligent analytics and distribution charts related to cancer prediction, we aim to communicate these easily interpretable results to assist pathologists and concerned medical team to make better decisions for prostate cancer diagnosis as case study.",10.1101/2022.12.21.22283754,virology-deep-learning.xlsx,"Visualizing Decisions and Analytics of Artificial Intelligence based Cancer Diagnosis and Grading of Specimen Digitized Biopsy: Case Study for Prostate Cancer 1The rise in Artificial Intelligence (AI) and deep learning research has shown great promise in diagnosing prostate cancer from whole slide image biopsies. Intelligent application interface for diagnosis is a progressive way to communicate AI results in the medical domain for practical use. This paper aims to suggest a way to integrate state-of-the-art deep learning algorithms into a web application for visualizations of decisions and analytics of an AI based algorithms applied on cancer digitized specimen biopsies together with visualizing evidence and explanation of the decision using both image from the biopsy and textual data from Electronic Health Records (EHR). By creating smart visualizations of tissue biopsy images, from magnified regions to augmented sharper images along with image masks that highlight cancerous regions of tissue in addition to intelligent analytics and distribution charts related to cancer prediction, we aim to communicate these easily interpretable results to assist pathologists and concerned medical team to make better decisions for prostate cancer diagnosis as case study.",0
"Dent, A.; Faust, K.; Lam, K. H. B.; Ahangari, N.; Leon, A.; Tsang, Q.; Kamil, Z. S.; Gao, A.; Pal, P.; Lheureux, S.; Oza, A.; Diamandis, P.",2023,HAVOC: Small-scale histomic mapping of biodiversity across entire tumor specimens using deep neural networks,Pathology,HAVOC: Small-scale histomic mapping of biodiversity across entire tumor specimens using deep neural networks,"Dent, A.; Faust, K.; Lam, K. H. B.; Ahangari, N.; Leon, A.; Tsang, Q.; Kamil, Z. S.; Gao, A.; Pal, P.; Lheureux, S.; Oza, A.; Diamandis, P.",Pathology,2023-01-14 00:00:00 UTC,"SummaryIntra-tumoral heterogeneity can wreak havoc on current precision medicine strategies due to challenges in sufficient sampling of geographically separated areas of biodiversity distributed across centimeter-scale tumor distances. In particular, modern tissue profiling approaches are still largely designed to only interrogate small tumor fragments; which may constitute a minute and non-representative fraction of the overall neoplasm. To address this gap, we developed a pipeline that leverages deep learning to define topographic histomorphologic fingerprints of tissue and create Histomic Atlases of Variation Of Cancers (HAVOC). Importantly, using a number of spatially-resolved readouts, including mass-spectrometry-based proteomics and immunohistochemisy, we demonstrate that these personalized atlases of histomic variation can define regional cancer boundaries with distinct biological programs. Using larger tumor specimens, we show that HAVOC can map spatial organization of cancer biodiversity spanning tissue coordinates separated by multiple centimeters. By applying this tool to guide profiling of 19 distinct geographic partitions from 6 high-grade gliomas, HAVOC revealed that distinct states of differentiation can often co-exist and be regionally distributed across individual tumors. Finally, to highlight generalizability, we further benchmark HAVOC on additional tumor types and experimental models of heterogeneity. Together, we establish HAVOC as a versatile and accessible tool to generate small-scale maps of tissue heterogeneity and guide regional deployment of molecular resources to relevant and biodiverse tumor niches.",10.1101/2023.01.11.22283903,virology-deep-learning.xlsx,"HAVOC: Small-scale histomic mapping of biodiversity across entire tumor specimens using deep neural networks SummaryIntra-tumoral heterogeneity can wreak havoc on current precision medicine strategies due to challenges in sufficient sampling of geographically separated areas of biodiversity distributed across centimeter-scale tumor distances. In particular, modern tissue profiling approaches are still largely designed to only interrogate small tumor fragments; which may constitute a minute and non-representative fraction of the overall neoplasm. To address this gap, we developed a pipeline that leverages deep learning to define topographic histomorphologic fingerprints of tissue and create Histomic Atlases of Variation Of Cancers (HAVOC). Importantly, using a number of spatially-resolved readouts, including mass-spectrometry-based proteomics and immunohistochemisy, we demonstrate that these personalized atlases of histomic variation can define regional cancer boundaries with distinct biological programs. Using larger tumor specimens, we show that HAVOC can map spatial organization of cancer biodiversity spanning tissue coordinates separated by multiple centimeters. By applying this tool to guide profiling of 19 distinct geographic partitions from 6 high-grade gliomas, HAVOC revealed that distinct states of differentiation can often co-exist and be regionally distributed across individual tumors. Finally, to highlight generalizability, we further benchmark HAVOC on additional tumor types and experimental models of heterogeneity. Together, we establish HAVOC as a versatile and accessible tool to generate small-scale maps of tissue heterogeneity and guide regional deployment of molecular resources to relevant and biodiverse tumor niches.",0
"Sharmin, M.; Manivannan, M.; Woo, D.; Sorel, O.; Auclair, J.; Gandhi, M.; Mujawar, I.",2023,Cross-sectional Ct distributions from qPCR tests can provide an early warning signal for the spread of COVID-19 in communities,Epidemiology,Cross-sectional Ct distributions from qPCR tests can provide an early warning signal for the spread of COVID-19 in communities,"Sharmin, M.; Manivannan, M.; Woo, D.; Sorel, O.; Auclair, J.; Gandhi, M.; Mujawar, I.",Epidemiology,2023-01-14 00:00:00 UTC,"BackgroundSARS-CoV-2 PCR testing data has been widely used for COVID-19 surveillance. Existing COVID-19 forecasting models mainly rely on case counts, even though the binary PCR results provide a limited picture of the pandemic trajectory. Most forecasting models have failed to accurately predict the COVID-19 waves before they occur. Recently a model utilizing cross-sectional population cycle threshold (Ct) values obtained from PCR tests (Ct-based model) was developed to overcome the limitations of using only binary PCR results. In this study, we aimed to improve on COVID-19 forecasting models using features derived from the Ct-based model, to detect epidemic waves earlier than case-based trajectories.

MethodsPCR data was collected weekly at Northeastern University (NU) between August 2020 and January 2022. The NU campus epidemic trajectories were generated from the campus incidence rates. In addition, epidemic trajectories were generated for Suffolk County, where NU is located, based on publicly available case-counts. A novel forecasting approach was developed by enhancing a recent deep learning model with Ct-based features, along with the models default features. For this, cross-sectional Ct values from PCR data were used to generate Ct-based epidemic trajectories, including effective reproductive rate (Rt) and incidence. The improvement in forecasting performance was compared using absolute errors and residual squared errors with respect to actual observed cases at the 7-day and 14-day forecasting horizons. The model was also tested prospectively over the period January 2022 to April 2022.

ResultsRt estimates from the Ct-based model preceded NU campus and Suffolk County cases by 12 and 14 days respectively, with a three-way synched Spearman correlation of 0.57. Enhancing the forecasting models with Ct-based information significantly decreased absolute error and residual squared error compared to the original model without Ct features (p-value <0.001 for both 7 and 14-days forecasting horizons).

ConclusionCt-based epidemic trajectories can herald an earlier signal for impending epidemic waves in the community and forecast transmission peaks. Moreover, COVID-19 forecasting models can be enhanced using these Ct features to improve their forecasting accuracy.

Policy implicationsWe make the case that public health agencies should publish Ct values along with the binary positive/negative PCR results. Early and accurate forecasting of epidemic waves can inform public health policies and countermeasures which can mitigate spread.",10.1101/2023.01.12.23284489,virology-deep-learning.xlsx,"Cross-sectional Ct distributions from qPCR tests can provide an early warning signal for the spread of COVID-19 in communities BackgroundSARS-CoV-2 PCR testing data has been widely used for COVID-19 surveillance. Existing COVID-19 forecasting models mainly rely on case counts, even though the binary PCR results provide a limited picture of the pandemic trajectory. Most forecasting models have failed to accurately predict the COVID-19 waves before they occur. Recently a model utilizing cross-sectional population cycle threshold (Ct) values obtained from PCR tests (Ct-based model) was developed to overcome the limitations of using only binary PCR results. In this study, we aimed to improve on COVID-19 forecasting models using features derived from the Ct-based model, to detect epidemic waves earlier than case-based trajectories.

MethodsPCR data was collected weekly at Northeastern University (NU) between August 2020 and January 2022. The NU campus epidemic trajectories were generated from the campus incidence rates. In addition, epidemic trajectories were generated for Suffolk County, where NU is located, based on publicly available case-counts. A novel forecasting approach was developed by enhancing a recent deep learning model with Ct-based features, along with the models default features. For this, cross-sectional Ct values from PCR data were used to generate Ct-based epidemic trajectories, including effective reproductive rate (Rt) and incidence. The improvement in forecasting performance was compared using absolute errors and residual squared errors with respect to actual observed cases at the 7-day and 14-day forecasting horizons. The model was also tested prospectively over the period January 2022 to April 2022.

ResultsRt estimates from the Ct-based model preceded NU campus and Suffolk County cases by 12 and 14 days respectively, with a three-way synched Spearman correlation of 0.57. Enhancing the forecasting models with Ct-based information significantly decreased absolute error and residual squared error compared to the original model without Ct features (p-value <0.001 for both 7 and 14-days forecasting horizons).

ConclusionCt-based epidemic trajectories can herald an earlier signal for impending epidemic waves in the community and forecast transmission peaks. Moreover, COVID-19 forecasting models can be enhanced using these Ct features to improve their forecasting accuracy.

Policy implicationsWe make the case that public health agencies should publish Ct values along with the binary positive/negative PCR results. Early and accurate forecasting of epidemic waves can inform public health policies and countermeasures which can mitigate spread.",1
"Bashir, R. M. S.; Shephard, A.; Mahmood, H.; Azarmehr, N.; Raza, S. E. A.; Khurram, A.; Rajpoot, N.",2023,A digital score of peri-epithelial lymphocytic activity predicts malignant transformation in oral epithelial dysplasia,Pathology,A digital score of peri-epithelial lymphocytic activity predicts malignant transformation in oral epithelial dysplasia,"Bashir, R. M. S.; Shephard, A.; Mahmood, H.; Azarmehr, N.; Raza, S. E. A.; Khurram, A.; Rajpoot, N.",Pathology,2023-02-22 00:00:00 UTC,"Oral squamous cell carcinoma (OSCC) is amongst the most common cancers worldwide, with more than 377,000 new cases worldwide each year. OSCC prognosis remains poor, related to cancer presentation at a late stage indicating the need for early detection to improve patient prognosis. OSCC is often preceded by a premalignant state known as oral epithelial dysplasia (OED), which is diagnosed and graded using subjective histological criteria leading to variability and prognostic unreliability. In this work, we propose a deep learning approach for the development of prognostic models for malignant transformation and their association with clinical outcomes in histology whole slide images (WSIs) of OED tissue sections. We train a weakly supervised method on OED (n= 137) cases with transformation (n= 50) status and mean malignant transformation time of 6.51 years ({+/-}5.35 SD). Performing stratified 5-fold cross-validation achieves an average AUROC of [~]0.78 for predicting malignant transformations in OED. Hotspot analysis reveals various features from nuclei in the epithelium and peri-epithelial tissue to be significant prognostic factors for malignant transformation, including the count of peri-epithelial lymphocytes (PELs) (p < 0.05), epithelial layer nuclei count (NC) (p < 0.05) and basal layer NC (p < 0.05). Progression free survival using the Epithelial layer NC (p < 0.05, C-index = 0.73), Basal layer NC (p < 0.05, C-index = 0.70) and PEL count (p < 0.05, C-index = 0.73) shown association of these features with a high risk of malignant transformation. Our work shows the application of deep learning for prognostication and progression free survival (PFS) prediction of OED for the first time and has a significant potential to aid patient management. Further evaluation and testing on multi-centric data is required for validation and translation to clinical practice.",10.1101/2023.02.14.23285872,virology-deep-learning.xlsx,"A digital score of peri-epithelial lymphocytic activity predicts malignant transformation in oral epithelial dysplasia Oral squamous cell carcinoma (OSCC) is amongst the most common cancers worldwide, with more than 377,000 new cases worldwide each year. OSCC prognosis remains poor, related to cancer presentation at a late stage indicating the need for early detection to improve patient prognosis. OSCC is often preceded by a premalignant state known as oral epithelial dysplasia (OED), which is diagnosed and graded using subjective histological criteria leading to variability and prognostic unreliability. In this work, we propose a deep learning approach for the development of prognostic models for malignant transformation and their association with clinical outcomes in histology whole slide images (WSIs) of OED tissue sections. We train a weakly supervised method on OED (n= 137) cases with transformation (n= 50) status and mean malignant transformation time of 6.51 years ({+/-}5.35 SD). Performing stratified 5-fold cross-validation achieves an average AUROC of [~]0.78 for predicting malignant transformations in OED. Hotspot analysis reveals various features from nuclei in the epithelium and peri-epithelial tissue to be significant prognostic factors for malignant transformation, including the count of peri-epithelial lymphocytes (PELs) (p < 0.05), epithelial layer nuclei count (NC) (p < 0.05) and basal layer NC (p < 0.05). Progression free survival using the Epithelial layer NC (p < 0.05, C-index = 0.73), Basal layer NC (p < 0.05, C-index = 0.70) and PEL count (p < 0.05, C-index = 0.73) shown association of these features with a high risk of malignant transformation. Our work shows the application of deep learning for prognostication and progression free survival (PFS) prediction of OED for the first time and has a significant potential to aid patient management. Further evaluation and testing on multi-centric data is required for validation and translation to clinical practice.",0
"Sharma, A.; Weitz, P.; Wang, Y.; Liu, B.; Hartman, J.; Rantalainen, M.",2023,Development and prognostic validation of a three-level NHG-like deep learning-based model for histological grading of breast cancer,Pathology,Development and prognostic validation of a three-level NHG-like deep learning-based model for histological grading of breast cancer,"Sharma, A.; Weitz, P.; Wang, Y.; Liu, B.; Hartman, J.; Rantalainen, M.",Pathology,2023-02-15 00:00:00 UTC,"Histological Grade is a well-known prognostic factor that is routinely assessed in breast tumours. However, manual assessment of Nottingham Histological Grade (NHG) has high inter-assessor and inter-lab variability, causing uncertainty in grade assignments. To address this challenge, we developed and validated a three-level NHG-like deep learning-based histological grade model. The primary performance evaluation focuses on prognostic performance.

This observational study is based on two patient cohorts (SoS-BC-4, N=2421 (training and internal test); SCAN-B-Lund, N=1262 (test)) that include routine histological whole slide images together with patient outcomes. A Deep Convolutional Neural Network (CNN) model with an attention mechanism was optimised for the classification of the three-level histological grading (NHG) from hematoxylin and eosin-stained WSIs. The prognostic performance was evaluated by time-to-event analysis of Recurrence-free survival (RFS) and compared to clinical NHG grade assignments in the internal test set as well as in the fully independent external test cohort. We observed effect sizes (Hazard Ratio) for grade 3 vs 1, for the conventional NHG method (HR=2.60 (1.18-5.70 95%CI, p-value = 0.017)) and the deep learning model (HR = 2.27, 95%CI: 1.07-4.82, p-value = 0.033) on the internal test set after adjusting for established clinicopathological risk factors. In the external test set, the unadjusted HR for NHG 1 vs 2 was estimated to be 2.59 (p-value = 0.004) and NHG 1 vs 3 was estimated to be 3.58 (p-value < 0.001). For predGrade, the unadjusted HR for grade 1 vs 2 HR=2.52 (p-value = 0.030), and 4.07 (p-value = 0.001) for grade 1 vs 3. In multivariable analysis, HR estimates for neither NHG nor predGrade were found to be significant (p-value >0.05). We tested for differences in HR estimates between NHG and predGrade in the independent test set, and found no significant difference between the two classification models (p-value > 0.05), confirming similar prognostic performance between conventional NHG and predGrade.

Routine histopathology assessment of NHG has a high degree of inter-assessor variability, motivating the development of model-based decision support to improve reproducibility in histological grading. We found that the proposed model provides similar prognostic performance as NHG. The results indicate that deep CNN-based models can be applied for breast cancer histological grading.",10.1101/2023.02.15.23285956,virology-deep-learning.xlsx,"Development and prognostic validation of a three-level NHG-like deep learning-based model for histological grading of breast cancer Histological Grade is a well-known prognostic factor that is routinely assessed in breast tumours. However, manual assessment of Nottingham Histological Grade (NHG) has high inter-assessor and inter-lab variability, causing uncertainty in grade assignments. To address this challenge, we developed and validated a three-level NHG-like deep learning-based histological grade model. The primary performance evaluation focuses on prognostic performance.

This observational study is based on two patient cohorts (SoS-BC-4, N=2421 (training and internal test); SCAN-B-Lund, N=1262 (test)) that include routine histological whole slide images together with patient outcomes. A Deep Convolutional Neural Network (CNN) model with an attention mechanism was optimised for the classification of the three-level histological grading (NHG) from hematoxylin and eosin-stained WSIs. The prognostic performance was evaluated by time-to-event analysis of Recurrence-free survival (RFS) and compared to clinical NHG grade assignments in the internal test set as well as in the fully independent external test cohort. We observed effect sizes (Hazard Ratio) for grade 3 vs 1, for the conventional NHG method (HR=2.60 (1.18-5.70 95%CI, p-value = 0.017)) and the deep learning model (HR = 2.27, 95%CI: 1.07-4.82, p-value = 0.033) on the internal test set after adjusting for established clinicopathological risk factors. In the external test set, the unadjusted HR for NHG 1 vs 2 was estimated to be 2.59 (p-value = 0.004) and NHG 1 vs 3 was estimated to be 3.58 (p-value < 0.001). For predGrade, the unadjusted HR for grade 1 vs 2 HR=2.52 (p-value = 0.030), and 4.07 (p-value = 0.001) for grade 1 vs 3. In multivariable analysis, HR estimates for neither NHG nor predGrade were found to be significant (p-value >0.05). We tested for differences in HR estimates between NHG and predGrade in the independent test set, and found no significant difference between the two classification models (p-value > 0.05), confirming similar prognostic performance between conventional NHG and predGrade.

Routine histopathology assessment of NHG has a high degree of inter-assessor variability, motivating the development of model-based decision support to improve reproducibility in histological grading. We found that the proposed model provides similar prognostic performance as NHG. The results indicate that deep CNN-based models can be applied for breast cancer histological grading.",0
"Retamales, G.; Gavidia, M.; Bausch, B.; Montanari, A.; Husch, A.; Goncalves, J.",2024,Towards automatic home-based sleep apnea estimation using deep learning,Respiratory Medicine,Towards automatic home-based sleep apnea estimation using deep learning,"Retamales, G.; Gavidia, M.; Bausch, B.; Montanari, A.; Husch, A.; Goncalves, J.",Respiratory Medicine,2024-03-29 00:00:00 UTC,"Apnea and hypopnea are common sleep disorders characterized by complete or partial obstructions of the airways, respectively. A sleep study, also known as polysomnography (PSG), is typically used to compute the Apnea-Hypopnea Index (AHI), the number of times a person has apnea or certain types of hypopnea per hour of sleep. AHI is then used to diagnose the severity of the sleep disorder. Early detection and treatment of apnea can significantly reduce morbidity and mortality. However, continuous PSG monitoring is unfeasible as it is costly and uncomfortable for patients. To circumvent these issues, we propose a method, named DRIVEN, to estimate AHI at home from wearable devices and assist physicians in diagnosing the severity of apneas. DRIVEN also detects when apnea, hypopnea, periods of wakefulness occur throughout the night, facilitating easy inspection by physicians. Patients can wear a single sensor or a combination of sensors that can be easily measured at home: abdominal movement, thoracic movement, or pulse oximetry. For example, using only two sensors, DRIVEN correctly classifies 72.4% of all test patients into one of the four AHI classes, with 99.3% either correctly classified or placed one class away from the true one. This is a reasonable trade-off between the models performance and patients comfort. We use data from three sleep studies from the National Sleep Research Resource (NSRR), the largest public repository, consisting of 14,370 recordings. DRIVEN is based on a combination of deep convolutional neural networks and a light-gradient-boost machine for classification. Since DRIVEN is simple and computationally efficient, it can be implemented for automatic estimation of AHI in unsupervised long-term home monitoring systems, reducing costs to healthcare systems and improving patient care.",10.1101/2023.02.15.23285988,virology-deep-learning.xlsx,"Towards automatic home-based sleep apnea estimation using deep learning Apnea and hypopnea are common sleep disorders characterized by complete or partial obstructions of the airways, respectively. A sleep study, also known as polysomnography (PSG), is typically used to compute the Apnea-Hypopnea Index (AHI), the number of times a person has apnea or certain types of hypopnea per hour of sleep. AHI is then used to diagnose the severity of the sleep disorder. Early detection and treatment of apnea can significantly reduce morbidity and mortality. However, continuous PSG monitoring is unfeasible as it is costly and uncomfortable for patients. To circumvent these issues, we propose a method, named DRIVEN, to estimate AHI at home from wearable devices and assist physicians in diagnosing the severity of apneas. DRIVEN also detects when apnea, hypopnea, periods of wakefulness occur throughout the night, facilitating easy inspection by physicians. Patients can wear a single sensor or a combination of sensors that can be easily measured at home: abdominal movement, thoracic movement, or pulse oximetry. For example, using only two sensors, DRIVEN correctly classifies 72.4% of all test patients into one of the four AHI classes, with 99.3% either correctly classified or placed one class away from the true one. This is a reasonable trade-off between the models performance and patients comfort. We use data from three sleep studies from the National Sleep Research Resource (NSRR), the largest public repository, consisting of 14,370 recordings. DRIVEN is based on a combination of deep convolutional neural networks and a light-gradient-boost machine for classification. Since DRIVEN is simple and computationally efficient, it can be implemented for automatic estimation of AHI in unsupervised long-term home monitoring systems, reducing costs to healthcare systems and improving patient care.",0
"Saldarriaga, O. A.; Krishnan, S.; Wanninger, T. G.; Oneka, M.; Rao, A.; Bao, D. Z.; Arroyave, E.; Gosnell, J.; Kueht, M.; Moghe, A.; Millian, D.; Jiao, J.; Sanchez, J.; Spratt, H.; Beretta, L.; Stevenson, H. L.",2023,Patients with fibrosis from non-alcoholic steatohepatitis have heterogeneous intrahepatic macrophages and therapeutic targets,Pathology,Patients with fibrosis from non-alcoholic steatohepatitis have heterogeneous intrahepatic macrophages and therapeutic targets,"Saldarriaga, O. A.; Krishnan, S.; Wanninger, T. G.; Oneka, M.; Rao, A.; Bao, D. Z.; Arroyave, E.; Gosnell, J.; Kueht, M.; Moghe, A.; Millian, D.; Jiao, J.; Sanchez, J.; Spratt, H.; Beretta, L.; Stevenson, H. L.",Pathology,2023-02-23 00:00:00 UTC,"Background and AimsIn clinical trials for reducing fibrosis in NASH patients, therapeutics that target macrophages have had variable results. We evaluated intrahepatic macrophages in patients with non-alcoholic steatohepatitis to determine if fibrosis influenced phenotypes and expression of CCR2 and Galectin-3.

Approach & ResultsWe used nCounter to analyze liver biopsies from well-matched patients with minimal (n=12) or advanced (n=12) fibrosis to determine which macrophage-related genes would be significantly different. Known therapy targets (e.g., CCR2 and Galectin-3) were significantly increased in patients with cirrhosis.

However, several genes (e.g., CD68, CD16, and CD14) did not show significant differences, and CD163, a marker of pro-fibrotic macrophages was significantly decreased with cirrhosis. Next, we analyzed patients with minimal (n=6) or advanced fibrosis (n=5) using approaches that preserved hepatic architecture by multiplex-staining with anti-CD68, Mac387, CD163, CD14, and CD16. Spectral data were analyzed using deep learning/artificial intelligence to determine percentages and spatial relationships. This approach showed patients with advanced fibrosis had increased CD68+, CD16+, Mac387+, CD163+, and CD16+CD163+ populations. Interaction of CD68+ and Mac387+ populations was significantly increased in patients with cirrhosis and enrichment of these same phenotypes in individuals with minimal fibrosis correlated with poor outcomes. Evaluation of a final set of patients (n=4) also showed heterogenous expression of CD163, CCR2, Galectin-3, and Mac387, and significant differences were not dependent on fibrosis stage or NAFLD activity.

ConclusionsApproaches that leave hepatic architecture intact, like multispectral imaging, may be paramount to developing effective treatments for NASH. In addition, understanding individual differences in patients may be required for optimal responses to macrophage-targeting therapies.",10.1101/2023.02.16.23285924,virology-deep-learning.xlsx,"Patients with fibrosis from non-alcoholic steatohepatitis have heterogeneous intrahepatic macrophages and therapeutic targets Background and AimsIn clinical trials for reducing fibrosis in NASH patients, therapeutics that target macrophages have had variable results. We evaluated intrahepatic macrophages in patients with non-alcoholic steatohepatitis to determine if fibrosis influenced phenotypes and expression of CCR2 and Galectin-3.

Approach & ResultsWe used nCounter to analyze liver biopsies from well-matched patients with minimal (n=12) or advanced (n=12) fibrosis to determine which macrophage-related genes would be significantly different. Known therapy targets (e.g., CCR2 and Galectin-3) were significantly increased in patients with cirrhosis.

However, several genes (e.g., CD68, CD16, and CD14) did not show significant differences, and CD163, a marker of pro-fibrotic macrophages was significantly decreased with cirrhosis. Next, we analyzed patients with minimal (n=6) or advanced fibrosis (n=5) using approaches that preserved hepatic architecture by multiplex-staining with anti-CD68, Mac387, CD163, CD14, and CD16. Spectral data were analyzed using deep learning/artificial intelligence to determine percentages and spatial relationships. This approach showed patients with advanced fibrosis had increased CD68+, CD16+, Mac387+, CD163+, and CD16+CD163+ populations. Interaction of CD68+ and Mac387+ populations was significantly increased in patients with cirrhosis and enrichment of these same phenotypes in individuals with minimal fibrosis correlated with poor outcomes. Evaluation of a final set of patients (n=4) also showed heterogenous expression of CD163, CCR2, Galectin-3, and Mac387, and significant differences were not dependent on fibrosis stage or NAFLD activity.

ConclusionsApproaches that leave hepatic architecture intact, like multispectral imaging, may be paramount to developing effective treatments for NASH. In addition, understanding individual differences in patients may be required for optimal responses to macrophage-targeting therapies.",0
"Ghose, S.; Cho, S.; Ginty, F.; Mcdonough, E.; Davis, C.; Zhang, Z.; Mitra, J.; Harris, A.; Thike, A. A.; Tan, P. H.; Gokmen-Polar, Y.; Badve, S.",2023,Predicting Breast Cancer Events in Ductal Carcinoma In Situ (DCIS) using Generative Adversarial Network Augmented Deep Learning Model,Pathology,Predicting Breast Cancer Events in Ductal Carcinoma In Situ (DCIS) using Generative Adversarial Network Augmented Deep Learning Model,"Ghose, S.; Cho, S.; Ginty, F.; Mcdonough, E.; Davis, C.; Zhang, Z.; Mitra, J.; Harris, A.; Thike, A. A.; Tan, P. H.; Gokmen-Polar, Y.; Badve, S.",Pathology,2023-02-26 00:00:00 UTC,"Standard clinicopathological parameters (age, growth pattern, tumor size, margin status and grade) have been shown to have limited value in predicting recurrence in ductal carcinoma in situ (DCIS) patients. Early and accurate recurrence prediction would facilitate a more aggressive treatment policy for high-risk patients (mastectomy or adjuvant radiation therapy), and simultaneously reduce over-treatment of low-risk patients. Generative adversarial networks (GAN) are a class of DL models in which two adversarial neural networks, generator and discriminator, compete with each other to generate high quality images. In this work, we have developed a deep learning (DL) classification network that predicts breast cancer events (BCEs) in DCIS patients using hematoxylin and eosin (H&E) images. The DL classification model was trained on 67 patients using image patches from the actual DCIS cores and GAN generated image patches to predict breast cancer events (BCEs). The hold-out validation dataset (n= 66) had an AUC of 0.82. Bayesian analysis further confirmed the independence of the model from classical clinico-pathological parameters. DL models of H&E images may be used as a risk stratification strategy for DCIS patients to personalize therapy.

Simple SummaryDuctal carcinoma in situ (DCIS) patients have an excellent overall survival rate and over-treatment is always a cause for concern due to potential side-effects. Standard clinicopathological parameters have limited value in predicting breast cancer events (BCEs) and stratification of high and low risk patients. Herein, we have developed a deep learning (DL) classification framework to predict BCEs in DCIS patients. A generative adversarial network (GAN) augmented deep learning (DL) classification of histological features associated with aggressive disease was trained on hematoxylin and eosin (H&E) tissue microarray (TMA) images of DCIS to predict BCEs. The area under the curve (AUC) for BCEs in the validation set was 0.82. Early and accurate prediction of DCIS BCEs would facilitate a personalized approach to therapy.",10.1101/2023.02.23.23286367,virology-deep-learning.xlsx,"Predicting Breast Cancer Events in Ductal Carcinoma In Situ (DCIS) using Generative Adversarial Network Augmented Deep Learning Model Standard clinicopathological parameters (age, growth pattern, tumor size, margin status and grade) have been shown to have limited value in predicting recurrence in ductal carcinoma in situ (DCIS) patients. Early and accurate recurrence prediction would facilitate a more aggressive treatment policy for high-risk patients (mastectomy or adjuvant radiation therapy), and simultaneously reduce over-treatment of low-risk patients. Generative adversarial networks (GAN) are a class of DL models in which two adversarial neural networks, generator and discriminator, compete with each other to generate high quality images. In this work, we have developed a deep learning (DL) classification network that predicts breast cancer events (BCEs) in DCIS patients using hematoxylin and eosin (H&E) images. The DL classification model was trained on 67 patients using image patches from the actual DCIS cores and GAN generated image patches to predict breast cancer events (BCEs). The hold-out validation dataset (n= 66) had an AUC of 0.82. Bayesian analysis further confirmed the independence of the model from classical clinico-pathological parameters. DL models of H&E images may be used as a risk stratification strategy for DCIS patients to personalize therapy.

Simple SummaryDuctal carcinoma in situ (DCIS) patients have an excellent overall survival rate and over-treatment is always a cause for concern due to potential side-effects. Standard clinicopathological parameters have limited value in predicting breast cancer events (BCEs) and stratification of high and low risk patients. Herein, we have developed a deep learning (DL) classification framework to predict BCEs in DCIS patients. A generative adversarial network (GAN) augmented deep learning (DL) classification of histological features associated with aggressive disease was trained on hematoxylin and eosin (H&E) tissue microarray (TMA) images of DCIS to predict BCEs. The area under the curve (AUC) for BCEs in the validation set was 0.82. Early and accurate prediction of DCIS BCEs would facilitate a personalized approach to therapy.",0
"Levy, J.; Chan, N.; Marotti, J.; Kerr, D.; Gutmann, E.; Glass, R.; Dodge, C.; Suriawinata, A.; Christensen, B.; Liu, X.; Vaickus, L.",2023,Large-Scale Validation Study of an Improved Semi-Autonomous Urine Cytology Assessment Tool: AutoParis-X,Pathology,Large-Scale Validation Study of an Improved Semi-Autonomous Urine Cytology Assessment Tool: AutoParis-X,"Levy, J.; Chan, N.; Marotti, J.; Kerr, D.; Gutmann, E.; Glass, R.; Dodge, C.; Suriawinata, A.; Christensen, B.; Liu, X.; Vaickus, L.",Pathology,2023-03-02 00:00:00 UTC,"Adopting a computational approach for the assessment of urine cytology specimens has the potential to improve the efficiency, accuracy and reliability of bladder cancer screening, which has heretofore relied on semi-subjective manual assessment methods. As rigorous, quantitative criteria and guidelines have been introduced for improving screening practices, e.g., The Paris System for Reporting Urinary Cytology (TPS), algorithms to emulate semi-autonomous diagnostic decision-making have lagged behind, in part due to the complex and nuanced nature of urine cytology reporting. In this study, we report on a deep learning tool, AutoParis-X, which can facilitate rapid semi-autonomous examination of urine cytology specimens. Through a large-scale retrospective validation study, results indicate that AutoParis-X can accurately determine urothelial cell atypia and aggregate a wide-variety of cell and cluster-related information across a slide to yield an Atypia Burden Score (ABS) that correlates closely with overall specimen atypia, predictive of TPS diagnostic categories. Importantly, this approach accounts for challenges associated with assessment of overlapping cell cluster borders, which improved the ability to predict specimen atypia and accurately estimate the nuclear-to-cytoplasm (NC) ratio for cells in these clusters. We developed an interactive web application that is publicly available and open-source, which features a simple, easy-to-use display for examining urine cytology whole-slide images (WSI) and determining the atypia level of specific cells, flagging the most abnormal cells for pathologist review. The accuracy of AutoParis-X (and other semi-automated digital pathology systems) indicates that these technologies are approaching clinical readiness and necessitates full evaluation of these algorithms via head-to-head clinical trials.",10.1101/2023.03.01.23286639,virology-deep-learning.xlsx,"Large-Scale Validation Study of an Improved Semi-Autonomous Urine Cytology Assessment Tool: AutoParis-X Adopting a computational approach for the assessment of urine cytology specimens has the potential to improve the efficiency, accuracy and reliability of bladder cancer screening, which has heretofore relied on semi-subjective manual assessment methods. As rigorous, quantitative criteria and guidelines have been introduced for improving screening practices, e.g., The Paris System for Reporting Urinary Cytology (TPS), algorithms to emulate semi-autonomous diagnostic decision-making have lagged behind, in part due to the complex and nuanced nature of urine cytology reporting. In this study, we report on a deep learning tool, AutoParis-X, which can facilitate rapid semi-autonomous examination of urine cytology specimens. Through a large-scale retrospective validation study, results indicate that AutoParis-X can accurately determine urothelial cell atypia and aggregate a wide-variety of cell and cluster-related information across a slide to yield an Atypia Burden Score (ABS) that correlates closely with overall specimen atypia, predictive of TPS diagnostic categories. Importantly, this approach accounts for challenges associated with assessment of overlapping cell cluster borders, which improved the ability to predict specimen atypia and accurately estimate the nuclear-to-cytoplasm (NC) ratio for cells in these clusters. We developed an interactive web application that is publicly available and open-source, which features a simple, easy-to-use display for examining urine cytology whole-slide images (WSI) and determining the atypia level of specific cells, flagging the most abnormal cells for pathologist review. The accuracy of AutoParis-X (and other semi-automated digital pathology systems) indicates that these technologies are approaching clinical readiness and necessitates full evaluation of these algorithms via head-to-head clinical trials.",0
"Tsuneki, M.; Abe, M.; Kanavati, F.",2023,Comparison of the classification of HER2 from whole-slide images between pathologists and a deep learning model,Pathology,Comparison of the classification of HER2 from whole-slide images between pathologists and a deep learning model,"Tsuneki, M.; Abe, M.; Kanavati, F.",Pathology,2023-03-29 00:00:00 UTC,"HER2 (human epidermal growth factor receptor 2) is a protein that is found on the surface of some cells, including breast cells. HER2 plays a role in cell growth, division, and repair, and when it is overexpressed, it can contribute to the development of certain types of cancer, particularly breast cancer. HER2 overexpression occurs in approximately 20% of cases, and it is associated with more aggressive tumor phenotypes and poorer prognosis. This makes its status an important factor in determining treatment options for breast cancer. While HER2 expression is typically diagnosed through a combination of immunohistochemistry (IHC) and/or fluorescence in situ hybridization (FISH) testing on breast cancer tissue samples, we sought to determine to what extent it is possible to diagnose from H&E-stained specimens. To this effect we trained a deep learning model to classify HER2-positive image patches using a dataset of 10 whole-slide images (5 HER2-positive, 5 HER2-negative). We evaluated the model on a different test set consisting of patches extracted from 10 WSIs (5 HER2-positive, 5 HER2-negative), and we compared the performance against two pathologists on 100 512x512 patches (50 HER2-positive, 50 HER2-negative). Overall, the model achieved an accuracy of 73% while the pathologists achieved 58% and 47%, respectively.",10.1101/2023.03.29.23287897,virology-deep-learning.xlsx,"Comparison of the classification of HER2 from whole-slide images between pathologists and a deep learning model HER2 (human epidermal growth factor receptor 2) is a protein that is found on the surface of some cells, including breast cells. HER2 plays a role in cell growth, division, and repair, and when it is overexpressed, it can contribute to the development of certain types of cancer, particularly breast cancer. HER2 overexpression occurs in approximately 20% of cases, and it is associated with more aggressive tumor phenotypes and poorer prognosis. This makes its status an important factor in determining treatment options for breast cancer. While HER2 expression is typically diagnosed through a combination of immunohistochemistry (IHC) and/or fluorescence in situ hybridization (FISH) testing on breast cancer tissue samples, we sought to determine to what extent it is possible to diagnose from H&E-stained specimens. To this effect we trained a deep learning model to classify HER2-positive image patches using a dataset of 10 whole-slide images (5 HER2-positive, 5 HER2-negative). We evaluated the model on a different test set consisting of patches extracted from 10 WSIs (5 HER2-positive, 5 HER2-negative), and we compared the performance against two pathologists on 100 512x512 patches (50 HER2-positive, 50 HER2-negative). Overall, the model achieved an accuracy of 73% while the pathologists achieved 58% and 47%, respectively.",0
"Mcneil, C.; Wong, P. F.; Sridhar, N.; Wang, Y.; Santori, C.; Wu, C.-H.; Homyk, A.; Gutierrez, M.; Behrooz, A.; Tiniakos, D.; Burt, A.; Pai, R. K.; Tekiela, K.; Chen, P.-H. C.; Fischer, L.; Martins, E. B.; Seyedkazemi, S.; Freedman, D.; Kim, C.; Cimermancic, P.",2023,An end-to-end platform for digital pathology using hyperspectral autofluorescence microscopy and deep learning based virtual histology,Pathology,An end-to-end platform for digital pathology using hyperspectral autofluorescence microscopy and deep learning based virtual histology,"Mcneil, C.; Wong, P. F.; Sridhar, N.; Wang, Y.; Santori, C.; Wu, C.-H.; Homyk, A.; Gutierrez, M.; Behrooz, A.; Tiniakos, D.; Burt, A.; Pai, R. K.; Tekiela, K.; Chen, P.-H. C.; Fischer, L.; Martins, E. B.; Seyedkazemi, S.; Freedman, D.; Kim, C.; Cimermancic, P.",Pathology,2023-04-20 00:00:00 UTC,"Conventional histopathology involves expensive and labor intensive processes that often consume tissue samples, rendering them unavailable for other analysis. We present a novel end-to-end workflow for pathology powered by hyperspectral microscopy and deep learning. First, we developed a custom hyperspectral microscope to non-destructively image the autofluorescence of unstained tissue sections. We then train a deep learning model to use the autofluorescence to generate virtual histological stains, which avoids the cost and variability of chemical staining procedures and conserves tissue samples. We showed that the virtual images reproduce the histological features present in the real stained images using a randomized nonalcoholic steatohepatitis (NASH) scoring comparison study where both real and virtual stains are scored by pathologists. The test showed moderate to good concordance between pathologists scoring on corresponding real and virtual stains. Finally, we developed deep learning-based models for automated NASH clinical research network (NASH CRN) score prediction. We showed that the end-to-end automated pathology platform is comparable to pathologists for NASH CRN scoring when evaluated against the expert pathologist consensus scores. This study provides proof of concept for this virtual staining strategy, which could improve cost, efficiency, and reliability in pathology, and enable novel approaches to spatial biology research.",10.1101/2023.04.10.23288259,virology-deep-learning.xlsx,"An end-to-end platform for digital pathology using hyperspectral autofluorescence microscopy and deep learning based virtual histology Conventional histopathology involves expensive and labor intensive processes that often consume tissue samples, rendering them unavailable for other analysis. We present a novel end-to-end workflow for pathology powered by hyperspectral microscopy and deep learning. First, we developed a custom hyperspectral microscope to non-destructively image the autofluorescence of unstained tissue sections. We then train a deep learning model to use the autofluorescence to generate virtual histological stains, which avoids the cost and variability of chemical staining procedures and conserves tissue samples. We showed that the virtual images reproduce the histological features present in the real stained images using a randomized nonalcoholic steatohepatitis (NASH) scoring comparison study where both real and virtual stains are scored by pathologists. The test showed moderate to good concordance between pathologists scoring on corresponding real and virtual stains. Finally, we developed deep learning-based models for automated NASH clinical research network (NASH CRN) score prediction. We showed that the end-to-end automated pathology platform is comparable to pathologists for NASH CRN scoring when evaluated against the expert pathologist consensus scores. This study provides proof of concept for this virtual staining strategy, which could improve cost, efficiency, and reliability in pathology, and enable novel approaches to spatial biology research.",0
"Song, Q.; Muller, K. E.; Hondelink, L. M.; Diflorio-Alexander, R. M.; .Karagas, M. R.; Hassanpour, S.",2023,Non-Metastatic Axillary Lymph Nodes Have Distinct Morphology and Immunophenotype in Obese Breast Cancer patients at Risk for Metastasis,Pathology,Non-Metastatic Axillary Lymph Nodes Have Distinct Morphology and Immunophenotype in Obese Breast Cancer patients at Risk for Metastasis,"Song, Q.; Muller, K. E.; Hondelink, L. M.; Diflorio-Alexander, R. M.; .Karagas, M. R.; Hassanpour, S.",Pathology,2023-04-17 00:00:00 UTC,"Obese patients have worse breast cancer outcomes than normal weight women including a 50% to 80% increased rate of axillary nodal metastasis. Recent studies have shown a potential link between increased lymph node adipose tissue and breast cancer nodal metastasis. Further investigation into potential mechanisms underlying this link may reveal potential prognostic utility of fat-enlarged lymph nodes in breast cancer patients. In this study, a deep learning framework was developed to identify morphological differences of non-metastatic axillary nodes between node-positive and node-negative obese breast cancer patients. Pathology review of the model-selected patches found an increase in the average size of adipocytes (p-value=0.004), an increased amount of white space between lymphocytes (p-value<0.0001), and an increased amount of red blood cells (p-value<0.001) in non-metastatic lymph nodes of node-positive breast cancer patients. Our downstream immunohistology (IHC) analysis showed a decrease of CD3 expression and increase of leptin expression in fat-replaced axillary lymph nodes in obese node-positive patients. In summary, our findings suggest a novel direction to further investigate the crosstalk between lymph node adiposity, lymphatic dysfunction, and breast cancer nodal metastases.",10.1101/2023.04.14.23288545,virology-deep-learning.xlsx,"Non-Metastatic Axillary Lymph Nodes Have Distinct Morphology and Immunophenotype in Obese Breast Cancer patients at Risk for Metastasis Obese patients have worse breast cancer outcomes than normal weight women including a 50% to 80% increased rate of axillary nodal metastasis. Recent studies have shown a potential link between increased lymph node adipose tissue and breast cancer nodal metastasis. Further investigation into potential mechanisms underlying this link may reveal potential prognostic utility of fat-enlarged lymph nodes in breast cancer patients. In this study, a deep learning framework was developed to identify morphological differences of non-metastatic axillary nodes between node-positive and node-negative obese breast cancer patients. Pathology review of the model-selected patches found an increase in the average size of adipocytes (p-value=0.004), an increased amount of white space between lymphocytes (p-value<0.0001), and an increased amount of red blood cells (p-value<0.001) in non-metastatic lymph nodes of node-positive breast cancer patients. Our downstream immunohistology (IHC) analysis showed a decrease of CD3 expression and increase of leptin expression in fat-replaced axillary lymph nodes in obese node-positive patients. In summary, our findings suggest a novel direction to further investigate the crosstalk between lymph node adiposity, lymphatic dysfunction, and breast cancer nodal metastases.",0
"Iwagami, M.; Inokuchi, R.; Kawakami, E.; Yamada, T.; Goto, A.; Kuno, T.; Hashimoto, Y.; Michihata, N.; Goto, T.; Shinozaki, T.; Sun, Y.; Taniguchi, Y.; Komiyama, J.; Uda, K.; Abe, T.; Tamiya, N.",2023,Comparison of machine-learning and logistic regression models to predict 30-day unplanned readmission: a development and validation study,Epidemiology,Comparison of machine-learning and logistic regression models to predict 30-day unplanned readmission: a development and validation study,"Iwagami, M.; Inokuchi, R.; Kawakami, E.; Yamada, T.; Goto, A.; Kuno, T.; Hashimoto, Y.; Michihata, N.; Goto, T.; Shinozaki, T.; Sun, Y.; Taniguchi, Y.; Komiyama, J.; Uda, K.; Abe, T.; Tamiya, N.",Epidemiology,2023-05-11 00:00:00 UTC,"We compared the predictive performance of gradient-boosted decision tree (GBDT), random forest (RF), deep neural network (DNN), and logistic regression (LR) with the least absolute shrinkage and selection operator (LASSO) for 30-day unplanned readmission, according to the number of predictor variables and presence/absence of blood-test results. We used electronic health records of patients discharged alive from 38 hospitals in 2015-2017 for derivation (n=339,513) and in 2018 for validation (n=118,074), including basic characteristics (age, sex, admission diagnosis category, number of hospitalizations in the past year, discharge location), diagnosis, surgery, procedure, and drug codes, and blood-test results. We created six patterns of datasets having different numbers of binary variables (that [&ge;]5% or [&ge;]1% of patients or [&ge;]10 patients had) with and without blood-test results. For the dataset with the smallest number of variables (102), the c-statistic was highest for GBDT (0.740), followed by RF (0.734), LR-LASSO (0.720), and DNN (0.664). For the dataset with the largest number of variables (1543), the c-statistic was highest for GBDT (0.764), followed by LR-LASSO (0.755), RF (0.751), and DNN (0.720). We found that GBDT generally outperformed LR-LASSO, but the difference became smaller when the number of variables was increased and blood-test results were used.",10.1101/2023.05.06.23289569,virology-deep-learning.xlsx,"Comparison of machine-learning and logistic regression models to predict 30-day unplanned readmission: a development and validation study We compared the predictive performance of gradient-boosted decision tree (GBDT), random forest (RF), deep neural network (DNN), and logistic regression (LR) with the least absolute shrinkage and selection operator (LASSO) for 30-day unplanned readmission, according to the number of predictor variables and presence/absence of blood-test results. We used electronic health records of patients discharged alive from 38 hospitals in 2015-2017 for derivation (n=339,513) and in 2018 for validation (n=118,074), including basic characteristics (age, sex, admission diagnosis category, number of hospitalizations in the past year, discharge location), diagnosis, surgery, procedure, and drug codes, and blood-test results. We created six patterns of datasets having different numbers of binary variables (that [&ge;]5% or [&ge;]1% of patients or [&ge;]10 patients had) with and without blood-test results. For the dataset with the smallest number of variables (102), the c-statistic was highest for GBDT (0.740), followed by RF (0.734), LR-LASSO (0.720), and DNN (0.664). For the dataset with the largest number of variables (1543), the c-statistic was highest for GBDT (0.764), followed by LR-LASSO (0.755), RF (0.751), and DNN (0.720). We found that GBDT generally outperformed LR-LASSO, but the difference became smaller when the number of variables was increased and blood-test results were used.",0
"Ramachandra, V.",2023,Hospital length of stay and discharge type prediction using deep learning,Epidemiology,Hospital length of stay and discharge type prediction using deep learning,"Ramachandra, V.",Epidemiology,2023-07-25 00:00:00 UTC,"The length of hospital stay (LOS) and the type of discharge are important indicators of how well care is provided at a hospital. The purpose of this study is to leverage in-patient data collected at the hospital to help determine the factors that influence the length of hospital stay and type of discharge. Our research focuses on estimating if the person survived or not after they were admitted to the hospital, as well as the type of discharge. The study uses a retrospective design and examines information from hospital discharged patients medical records. Demographic information, diagnosis, treatment, and discharge status were included in the data. We have used the PEDALFAST dataset which stands for PEDiatric Validation of Variables in Trauma. A survey of patients to find out how they feel about the quality of care they received while they were in the hospital was also a part of the study dataset. The findings of this study will shed light on the ways in which various factors influence the LOS in the hospital and the type of discharge, assisting in the formulation of strategies to enhance the quality and effectiveness of health care delivery.",10.1101/2023.07.24.23293092,virology-deep-learning.xlsx,"Hospital length of stay and discharge type prediction using deep learning The length of hospital stay (LOS) and the type of discharge are important indicators of how well care is provided at a hospital. The purpose of this study is to leverage in-patient data collected at the hospital to help determine the factors that influence the length of hospital stay and type of discharge. Our research focuses on estimating if the person survived or not after they were admitted to the hospital, as well as the type of discharge. The study uses a retrospective design and examines information from hospital discharged patients medical records. Demographic information, diagnosis, treatment, and discharge status were included in the data. We have used the PEDALFAST dataset which stands for PEDiatric Validation of Variables in Trauma. A survey of patients to find out how they feel about the quality of care they received while they were in the hospital was also a part of the study dataset. The findings of this study will shed light on the ways in which various factors influence the LOS in the hospital and the type of discharge, assisting in the formulation of strategies to enhance the quality and effectiveness of health care delivery.",0
"Nan, L.; Xin, W.; Boqian, W.; Renjie, M.; Yunxiang, Z.; Zili, C.; Yuan, J.; Junjie, Y.; Mingda, H.; Wei, C.; Hongguang, R.",2023,Flu-CNN: predicting host tropism of influenza A viruses via character-level convolutional networks,Epidemiology,Flu-CNN: predicting host tropism of influenza A viruses via character-level convolutional networks,"Nan, L.; Xin, W.; Boqian, W.; Renjie, M.; Yunxiang, Z.; Zili, C.; Yuan, J.; Junjie, Y.; Mingda, H.; Wei, C.; Hongguang, R.",Epidemiology,2023-08-31 00:00:00 UTC,"Throughout history, Influenza A viruses (IAVs) have caused significant harm and catastrophic pandemics. The presence of host barriers results in viral host tropism, where infected hosts are subject to strict restrictions due to the hindered spread of viruses across hosts. Therefore, the identification of host tropism of IAVs, particularly in humans, is crucial to preventing the cross-host transmission of avian viruses and their outbreaks in humans. Nevertheless, efficiently and effectively identifying host tropism, especially for early host susceptibility warnings based on viral genome sequences during outbreak onset, remains challenging. To address this challenge, we propose Flu-CNN, a deep neural network model based on classical character-level convolutional networks. By analyzing the genomic segments of IAVs, Flu-CNN can accurately identify the host tropism, with a particular focus on avian influenza viruses that may infect humans. According to our experimental evaluations, Flu-CNN achieved an accuracy of 99% in identifying virus hosts via only a single genomic segment, even for subtypes with a relatively small number of viral strains such as H5N1, H7N9, and H9N2. The superiority of Flu-CNN demonstrates its effectiveness in screening for critical amino acid mutations, which is important to host adaptation, and zoonotic risk prediction of viral strains. Flu-CNN is a valuable tool for identifying evolutionary characterization, monitoring potential outbreaks, and preventing epidemical spreads of IAVs, which contribute to the effective surveillance of influenza A viruses.",10.1101/2023.08.28.23294703,virology-deep-learning.xlsx,"Flu-CNN: predicting host tropism of influenza A viruses via character-level convolutional networks Throughout history, Influenza A viruses (IAVs) have caused significant harm and catastrophic pandemics. The presence of host barriers results in viral host tropism, where infected hosts are subject to strict restrictions due to the hindered spread of viruses across hosts. Therefore, the identification of host tropism of IAVs, particularly in humans, is crucial to preventing the cross-host transmission of avian viruses and their outbreaks in humans. Nevertheless, efficiently and effectively identifying host tropism, especially for early host susceptibility warnings based on viral genome sequences during outbreak onset, remains challenging. To address this challenge, we propose Flu-CNN, a deep neural network model based on classical character-level convolutional networks. By analyzing the genomic segments of IAVs, Flu-CNN can accurately identify the host tropism, with a particular focus on avian influenza viruses that may infect humans. According to our experimental evaluations, Flu-CNN achieved an accuracy of 99% in identifying virus hosts via only a single genomic segment, even for subtypes with a relatively small number of viral strains such as H5N1, H7N9, and H9N2. The superiority of Flu-CNN demonstrates its effectiveness in screening for critical amino acid mutations, which is important to host adaptation, and zoonotic risk prediction of viral strains. Flu-CNN is a valuable tool for identifying evolutionary characterization, monitoring potential outbreaks, and preventing epidemical spreads of IAVs, which contribute to the effective surveillance of influenza A viruses.",1
"De Sanjose, S.; Perkins, R. B.; Campos, N. G.; Inturrisi, F.; Egemen, D.; Befano, B.; Rodriguez, A. C.; Jeronimo, J.; Cheung, L. C.; Desai, K. T.; Han, P.; Novetsky, A. P.; Ukwuani, A.; Marcus, J.; Ahmed, S. R.; Wentzensen, N.; Kalpathy-Cramer, J.; Schiffman, M.; The Pave Study Group,",2023,Design of the HPV-Automated Visual Evaluation (PAVE) Study: Validating a Novel Cervical Screening,Epidemiology,Design of the HPV-Automated Visual Evaluation (PAVE) Study: Validating a Novel Cervical Screening,"De Sanjose, S.; Perkins, R. B.; Campos, N. G.; Inturrisi, F.; Egemen, D.; Befano, B.; Rodriguez, A. C.; Jeronimo, J.; Cheung, L. C.; Desai, K. T.; Han, P.; Novetsky, A. P.; Ukwuani, A.; Marcus, J.; Ahmed, S. R.; Wentzensen, N.; Kalpathy-Cramer, J.; Schiffman, M.; The Pave Study Group,",Epidemiology,2023-10-23 00:00:00 UTC,"ObjectiveTo describe the HPV-Automated Visual Evaluation (PAVE) Study, an international, multi-centric study designed to evaluate a novel cervical screen-triage-treat strategy for resource-limited settings as part of a global strategy to reduce cervical cancer burden. The PAVE strategy involves: 1) screening with self-sampled HPV testing; 2) triage of HPV-positive participants with a combination of extended genotyping and visual evaluation of the cervix assisted by deep-learning-based automated visual evaluation (AVE); and 3) treatment with thermal ablation or excision (Large Loop Excision of the Transformation Zone). The PAVE study has two phases: efficacy (2023-2024) and effectiveness (planned to begin in 2024-2025). The efficacy phase aims to refine and validate the screen-triage portion of the protocol. The effectiveness phase will examine acceptability and feasibility of the PAVE strategy into clinical practice, cost-effectiveness, and health communication within the PAVE sites.

Study designPhase 1 Efficacy: Around 100,000 nonpregnant women, aged 25-49 years, without prior hysterectomy, and irrespective of HIV status, are being screened at nine study sites in resource-limited settings. Eligible and consenting participants perform self-collection of vaginal specimens for HPV testing using a FLOQSwab (Copan). Swabs are transported dry and undergo testing for HPV using a newly-redesigned isothermal DNA amplification HPV test (ScreenFire HPV RS), which has been designed to provide HPV genotyping by hierarchical risk groups: HPV16, else HPV18/45, else HPV31/33/35/52/58, else HPV39/51/56/59/68. HPV-negative individuals are considered negative for precancer/cancer and do not undergo further testing. HPV-positive individuals undergo pelvic examination with collection of cervical images and targeted biopsies of all acetowhite areas or endocervical sampling in the absence of visible lesions. Accuracy of histology diagnosis is evaluated across all sites. Cervical images are used to refine a deep learning AVE algorithm that classifies images as normal, indeterminate, or precancer+. AVE classifications are validated against the histologic endpoint of high-grade precancer determined by biopsy. The combination of HPV genotype and AVE classification is used to generate a risk score that corresponds to the risk of precancer (lower, medium, high, highest). During the efficacy phase, clinicians and patients within the PAVE sites will receive HPV testing results but not AVE results or risk scores. Treatment during the efficacy phase will be performed per local standard of care: positive Visual Inspection with Acetic Acid impression, high-grade colposcopic impression or CIN2+ on colposcopic biopsy, HPV positivity, or HPV 16,18/45 positivity. Follow up of triage negative patients and post treatment will follow standard of care protocols. The sensitivity of the PAVE strategy for detection of precancer will be compared to current SOC at a given level of specificity.

Phase 2 Effectiveness: The AVE software will be downloaded to the new dedicated image analysis and thermal ablation devices (Liger Iris) into which the HPV genotype information can be entered to provide risk HPV-AVE risk scores for precancer to clinicians in real time. The effectiveness phase will examine clinician use of the PAVE strategy in practice, including feasibility and acceptability for clinicians and patients, cost-effectiveness, and health communication within the PAVE sites.

ConclusionThe goal of the PAVE study is to validate a screen-triage-treat protocol using novel biomarkers to provide an accurate, feasible, cost-effective strategy for cervical cancer prevention in resource-limited settings. If validated, implementation of PAVE at larger scale can be encouraged.

FundingThe consortial sites are responsible for their own study costs. Research equipment and supplies, and the NCI-affiliated staff are funded by the National Cancer Institute Intramural Research Program including supplemental funding from the Cancer Cures Moonshot Initiative. No commercial support was obtained. Brian Befano was supported by NCI/NIH under Grant T32CA09168.

Date of protocol latest review: September 24th 2023",10.1101/2023.08.30.23294826,virology-deep-learning.xlsx,"Design of the HPV-Automated Visual Evaluation (PAVE) Study: Validating a Novel Cervical Screening ObjectiveTo describe the HPV-Automated Visual Evaluation (PAVE) Study, an international, multi-centric study designed to evaluate a novel cervical screen-triage-treat strategy for resource-limited settings as part of a global strategy to reduce cervical cancer burden. The PAVE strategy involves: 1) screening with self-sampled HPV testing; 2) triage of HPV-positive participants with a combination of extended genotyping and visual evaluation of the cervix assisted by deep-learning-based automated visual evaluation (AVE); and 3) treatment with thermal ablation or excision (Large Loop Excision of the Transformation Zone). The PAVE study has two phases: efficacy (2023-2024) and effectiveness (planned to begin in 2024-2025). The efficacy phase aims to refine and validate the screen-triage portion of the protocol. The effectiveness phase will examine acceptability and feasibility of the PAVE strategy into clinical practice, cost-effectiveness, and health communication within the PAVE sites.

Study designPhase 1 Efficacy: Around 100,000 nonpregnant women, aged 25-49 years, without prior hysterectomy, and irrespective of HIV status, are being screened at nine study sites in resource-limited settings. Eligible and consenting participants perform self-collection of vaginal specimens for HPV testing using a FLOQSwab (Copan). Swabs are transported dry and undergo testing for HPV using a newly-redesigned isothermal DNA amplification HPV test (ScreenFire HPV RS), which has been designed to provide HPV genotyping by hierarchical risk groups: HPV16, else HPV18/45, else HPV31/33/35/52/58, else HPV39/51/56/59/68. HPV-negative individuals are considered negative for precancer/cancer and do not undergo further testing. HPV-positive individuals undergo pelvic examination with collection of cervical images and targeted biopsies of all acetowhite areas or endocervical sampling in the absence of visible lesions. Accuracy of histology diagnosis is evaluated across all sites. Cervical images are used to refine a deep learning AVE algorithm that classifies images as normal, indeterminate, or precancer+. AVE classifications are validated against the histologic endpoint of high-grade precancer determined by biopsy. The combination of HPV genotype and AVE classification is used to generate a risk score that corresponds to the risk of precancer (lower, medium, high, highest). During the efficacy phase, clinicians and patients within the PAVE sites will receive HPV testing results but not AVE results or risk scores. Treatment during the efficacy phase will be performed per local standard of care: positive Visual Inspection with Acetic Acid impression, high-grade colposcopic impression or CIN2+ on colposcopic biopsy, HPV positivity, or HPV 16,18/45 positivity. Follow up of triage negative patients and post treatment will follow standard of care protocols. The sensitivity of the PAVE strategy for detection of precancer will be compared to current SOC at a given level of specificity.

Phase 2 Effectiveness: The AVE software will be downloaded to the new dedicated image analysis and thermal ablation devices (Liger Iris) into which the HPV genotype information can be entered to provide risk HPV-AVE risk scores for precancer to clinicians in real time. The effectiveness phase will examine clinician use of the PAVE strategy in practice, including feasibility and acceptability for clinicians and patients, cost-effectiveness, and health communication within the PAVE sites.

ConclusionThe goal of the PAVE study is to validate a screen-triage-treat protocol using novel biomarkers to provide an accurate, feasible, cost-effective strategy for cervical cancer prevention in resource-limited settings. If validated, implementation of PAVE at larger scale can be encouraged.

FundingThe consortial sites are responsible for their own study costs. Research equipment and supplies, and the NCI-affiliated staff are funded by the National Cancer Institute Intramural Research Program including supplemental funding from the Cancer Cures Moonshot Initiative. No commercial support was obtained. Brian Befano was supported by NCI/NIH under Grant T32CA09168.

Date of protocol latest review: September 24th 2023",1
"Wang, Y.; Sun, W.; Karlsson, E.; Kang Lovgren, S.; Acs, B.; Rantalainen, M.; Robertson, S.; Hartman, J.",2023,Clinical evaluation of deep learning-based risk profiling in breast cancer histopathology and comparison to an established multigene assay,Pathology,Clinical evaluation of deep learning-based risk profiling in breast cancer histopathology and comparison to an established multigene assay,"Wang, Y.; Sun, W.; Karlsson, E.; Kang Lovgren, S.; Acs, B.; Rantalainen, M.; Robertson, S.; Hartman, J.",Pathology,2023-12-17 00:00:00 UTC,"A significant proportion of oestrogen receptor (ER)-positive and human epidermal growth factor receptor 2 (HER2)-negative early breast cancer patients are categorised as intermediate risk based on classic clinicopathological variables, thus providing limited information to guide treatment decisions. The Prosigna assay is one of the established prognostic multigene assays in clinical practice for risk profiling. Stratipath Breast is a novel deep learning-based image analysis tool that utilises haematoxylin and eosin (HE)-stained histopathological images for risk profiling. In this study, we aimed to evaluate the Stratipath Breast tool for image-based risk profiling and compare it with the Prosigna assay. In a real-world breast cancer case series comprising 234 invasive tumours from patients with early ER+/HER2-breast cancer, clinically intermediate risk and eligible for chemotherapy, clinicopathological data including Prosigna results and corresponding HE-stained tissue slides were retrieved. The digitised HE slides were analysed by Stratipath Breast. Our findings showed that the Stratipath Breast analysis identified 49.6% of the clinically intermediate tumours as low risk and 50.4% as high risk. The Prosigna assay classified 32.5%, 47.0% and 20.5% tumours as low, intermediate and high risk, respectively. Among Prosigna intermediate-risk tumours, 47.3% were stratified as Stratipath low risk and 52.7% as high risk. In addition, 89.7% of Stratipath low-risk cases were classified as Prosigna low/intermediate risk. The overall agreement between the two tests for low-risk and high-risk groups was 71.0%, with a Cohens kappa of 0.42. For both risk profiling tests, grade and Ki67 differed significantly between risk groups. In conclusion, for the first time, we here present the results from a clinical evaluation of image-based risk stratification and show a considerable agreement to an established gene expression assay in routine breast pathology. The findings demonstrate that image-based risk profiling may aid in the identification of low-risk patients who could potentially be spared adjuvant chemotherapy.",10.1101/2023.08.31.23294882,virology-deep-learning.xlsx,"Clinical evaluation of deep learning-based risk profiling in breast cancer histopathology and comparison to an established multigene assay A significant proportion of oestrogen receptor (ER)-positive and human epidermal growth factor receptor 2 (HER2)-negative early breast cancer patients are categorised as intermediate risk based on classic clinicopathological variables, thus providing limited information to guide treatment decisions. The Prosigna assay is one of the established prognostic multigene assays in clinical practice for risk profiling. Stratipath Breast is a novel deep learning-based image analysis tool that utilises haematoxylin and eosin (HE)-stained histopathological images for risk profiling. In this study, we aimed to evaluate the Stratipath Breast tool for image-based risk profiling and compare it with the Prosigna assay. In a real-world breast cancer case series comprising 234 invasive tumours from patients with early ER+/HER2-breast cancer, clinically intermediate risk and eligible for chemotherapy, clinicopathological data including Prosigna results and corresponding HE-stained tissue slides were retrieved. The digitised HE slides were analysed by Stratipath Breast. Our findings showed that the Stratipath Breast analysis identified 49.6% of the clinically intermediate tumours as low risk and 50.4% as high risk. The Prosigna assay classified 32.5%, 47.0% and 20.5% tumours as low, intermediate and high risk, respectively. Among Prosigna intermediate-risk tumours, 47.3% were stratified as Stratipath low risk and 52.7% as high risk. In addition, 89.7% of Stratipath low-risk cases were classified as Prosigna low/intermediate risk. The overall agreement between the two tests for low-risk and high-risk groups was 71.0%, with a Cohens kappa of 0.42. For both risk profiling tests, grade and Ki67 differed significantly between risk groups. In conclusion, for the first time, we here present the results from a clinical evaluation of image-based risk stratification and show a considerable agreement to an established gene expression assay in routine breast pathology. The findings demonstrate that image-based risk profiling may aid in the identification of low-risk patients who could potentially be spared adjuvant chemotherapy.",0
"Lu, Y.; Srinivasan, G.; Preum, S.; Pettus, J.; Davis, M.; Greenburg, J.; Vaickus, L.; Levy, J.",2023,Assessing the Impact of Pretraining Domain Relevance on Large Language Models Across Various Pathology Reporting Tasks,Pathology,Assessing the Impact of Pretraining Domain Relevance on Large Language Models Across Various Pathology Reporting Tasks,"Lu, Y.; Srinivasan, G.; Preum, S.; Pettus, J.; Davis, M.; Greenburg, J.; Vaickus, L.; Levy, J.",Pathology,2023-09-11 00:00:00 UTC,"Deep learning (DL) algorithms continue to develop at a rapid pace, providing researchers access to a set of tools capable of solving a wide array of biomedical challenges. While this progress is promising, it also leads to confusion regarding task-specific model choices, where deeper investigation is necessary to determine the optimal model configuration. Natural language processing (NLP) has the unique ability to accurately and efficiently capture a patients narrative, which can improve the operational efficiency of modern pathology laboratories through advanced computational solutions that can facilitate rapid access to and reporting of histological and molecular findings. In this study, we use pathology reports from a large academic medical system to assess the generalizability and potential real-world applicability of various deep learning-based NLP models on reports with highly specialized vocabulary and complex reporting structures. The performance of each NLP model examined was compared across four distinct tasks: 1) current procedural terminology (CPT) code classification, 2) pathologist classification, 3) report sign-out time regression, and 4) report text generation, under the hypothesis that models initialized on domain-relevant medical text would perform better than models not attuned to this prior knowledge. Our study highlights that the performance of deep learning-based NLP models can vary meaningfully across pathology-related tasks. Models pretrained on medical data outperform other models where medical domain knowledge is crucial, e.g., current procedural terminology (CPT) code classification. However, where interpretation is more subjective (i.e., teasing apart pathologist-specific lexicon and variable sign-out times), models with medical pretraining do not consistently outperform the other approaches. Instead, fine-tuning models pretrained on general or unrelated text sources achieved comparable or better results. Overall, our findings underscore the importance of considering the nature of the task at hand when selecting a pretraining strategy for NLP models in pathology. The optimal approach may vary depending on the specific requirements and nuances of the task, and related text sources can offer valuable insights and improve performance in certain cases, contradicting established notions about domain adaptation. This research contributes to our understanding of pretraining strategies for large language models and further informs the development and deployment of these models in pathology-related applications.",10.1101/2023.09.10.23295318,virology-deep-learning.xlsx,"Assessing the Impact of Pretraining Domain Relevance on Large Language Models Across Various Pathology Reporting Tasks Deep learning (DL) algorithms continue to develop at a rapid pace, providing researchers access to a set of tools capable of solving a wide array of biomedical challenges. While this progress is promising, it also leads to confusion regarding task-specific model choices, where deeper investigation is necessary to determine the optimal model configuration. Natural language processing (NLP) has the unique ability to accurately and efficiently capture a patients narrative, which can improve the operational efficiency of modern pathology laboratories through advanced computational solutions that can facilitate rapid access to and reporting of histological and molecular findings. In this study, we use pathology reports from a large academic medical system to assess the generalizability and potential real-world applicability of various deep learning-based NLP models on reports with highly specialized vocabulary and complex reporting structures. The performance of each NLP model examined was compared across four distinct tasks: 1) current procedural terminology (CPT) code classification, 2) pathologist classification, 3) report sign-out time regression, and 4) report text generation, under the hypothesis that models initialized on domain-relevant medical text would perform better than models not attuned to this prior knowledge. Our study highlights that the performance of deep learning-based NLP models can vary meaningfully across pathology-related tasks. Models pretrained on medical data outperform other models where medical domain knowledge is crucial, e.g., current procedural terminology (CPT) code classification. However, where interpretation is more subjective (i.e., teasing apart pathologist-specific lexicon and variable sign-out times), models with medical pretraining do not consistently outperform the other approaches. Instead, fine-tuning models pretrained on general or unrelated text sources achieved comparable or better results. Overall, our findings underscore the importance of considering the nature of the task at hand when selecting a pretraining strategy for NLP models in pathology. The optimal approach may vary depending on the specific requirements and nuances of the task, and related text sources can offer valuable insights and improve performance in certain cases, contradicting established notions about domain adaptation. This research contributes to our understanding of pretraining strategies for large language models and further informs the development and deployment of these models in pathology-related applications.",0
"Vabalas, A.; Hartonen, T.; Vartiainen, P.; Jukarainen, S.; Viippola, E.; Rodosthenous, R.; Liu, A.; Hagg, S.; Perola, M.; Ganna, A.",2023,Deep learning-based prediction of one-year mortality in the entire Finnish population is an accurate but unfair digital marker of aging,Epidemiology,Deep learning-based prediction of one-year mortality in the entire Finnish population is an accurate but unfair digital marker of aging,"Vabalas, A.; Hartonen, T.; Vartiainen, P.; Jukarainen, S.; Viippola, E.; Rodosthenous, R.; Liu, A.; Hagg, S.; Perola, M.; Ganna, A.",Epidemiology,2023-09-18 00:00:00 UTC,"BackgroundAccurately predicting short-term mortality is important for optimizing healthcare resource allocation, developing risk-reducing interventions, and improving end-of-life care. Moreover, short-term mortality risk reflects individual frailty and can serve as digital aging marker. Previous studies have focused on specific, high-risk populations. Predicting all-cause mortality in an unselected population incorporating both health and socioeconomic factors has direct public health relevance but requires careful fairness considerations.

MethodsWe developed a deep learning model to predict 1-year mortality using nationwide longitudinal data from the Finnish population (N = 5.4 million), including >8,000 features and spanning back up to 50 years. We used the area under the receiver operating characteristic curve (AUC) as a primary metric to assess model performance and fairness.

FindingsThe model achieved an AUC of 0.944 with strong calibration, outperforming a baseline model that only included age and sex (AUC = 0.897). The model generalized well to different causes of death (AUC > 0.800 for 45 out of 50 causes), including COVID-19 which was not present in the training data. The model performed best among young females and worst in older males (AUC = 0.910 vs. AUC = 0.718). Extensive fairness analyses revealed that individuals belonging to multiple disadvantaged groups had the worst model performance, not explained by age and sex differences, reduced healthcare contact, or smaller training set sizes within these groups.

ConclusionA deep learning model based on nationwide longitudinal multi-modal data accurately identified short-term mortality risk holding the potential for developing a population-wide in-silico aging marker. Unfairness in model predictions represents a major challenge to the equitable integration of these approaches in public health interventions.",10.1101/2023.09.18.23295726,virology-deep-learning.xlsx,"Deep learning-based prediction of one-year mortality in the entire Finnish population is an accurate but unfair digital marker of aging BackgroundAccurately predicting short-term mortality is important for optimizing healthcare resource allocation, developing risk-reducing interventions, and improving end-of-life care. Moreover, short-term mortality risk reflects individual frailty and can serve as digital aging marker. Previous studies have focused on specific, high-risk populations. Predicting all-cause mortality in an unselected population incorporating both health and socioeconomic factors has direct public health relevance but requires careful fairness considerations.

MethodsWe developed a deep learning model to predict 1-year mortality using nationwide longitudinal data from the Finnish population (N = 5.4 million), including >8,000 features and spanning back up to 50 years. We used the area under the receiver operating characteristic curve (AUC) as a primary metric to assess model performance and fairness.

FindingsThe model achieved an AUC of 0.944 with strong calibration, outperforming a baseline model that only included age and sex (AUC = 0.897). The model generalized well to different causes of death (AUC > 0.800 for 45 out of 50 causes), including COVID-19 which was not present in the training data. The model performed best among young females and worst in older males (AUC = 0.910 vs. AUC = 0.718). Extensive fairness analyses revealed that individuals belonging to multiple disadvantaged groups had the worst model performance, not explained by age and sex differences, reduced healthcare contact, or smaller training set sizes within these groups.

ConclusionA deep learning model based on nationwide longitudinal multi-modal data accurately identified short-term mortality risk holding the potential for developing a population-wide in-silico aging marker. Unfairness in model predictions represents a major challenge to the equitable integration of these approaches in public health interventions.",1
"Fatemi, M. Y.; Lu, Y.; Diallo, A. B.; Srinivasan, G.; Azher, Z. L.; Christensen, B. C.; Salas, L. A.; Tsongalis, G. J.; Palisoul, S. M.; Perreard, L.; Kolling, F. W.; Vaickus, L. J.; Levy, J. J.",2023,The Overlooked Role of Specimen Preparation in Bolstering Deep Learning-Enhanced Spatial Transcriptomics Workflows,Pathology,The Overlooked Role of Specimen Preparation in Bolstering Deep Learning-Enhanced Spatial Transcriptomics Workflows,"Fatemi, M. Y.; Lu, Y.; Diallo, A. B.; Srinivasan, G.; Azher, Z. L.; Christensen, B. C.; Salas, L. A.; Tsongalis, G. J.; Palisoul, S. M.; Perreard, L.; Kolling, F. W.; Vaickus, L. J.; Levy, J. J.",Pathology,2023-10-09 00:00:00 UTC,"The application of deep learning methods to spatial transcriptomics has shown promise in unraveling the complex relationships between gene expression patterns and tissue architecture as they pertain to various pathological conditions. Deep learning methods that can infer gene expression patterns directly from tissue histomorphology can expand the capability to discern spatial molecular markers within tissue slides. However, current methods utilizing these techniques are plagued by substantial variability in tissue preparation and characteristics, which can hinder the broader adoption of these tools. Furthermore, training deep learning models using spatial transcriptomics on small study cohorts remains a costly endeavor. Necessitating novel tissue preparation processes enhance assay reliability, resolution, and scalability. This study investigated the impact of an enhanced specimen processing workflow for facilitating a deep learning-based spatial transcriptomics assessment. The enhanced workflow leveraged the flexibility of the Visium CytAssist assay to permit automated H&E staining (e.g., Leica Bond) of tissue slides, whole-slide imaging at 40x-resolution, and multiplexing of tissue sections from multiple patients within individual capture areas for spatial transcriptomics profiling. Using a cohort of thirteen pT3 stage colorectal cancer (CRC) patients, we compared the efficacy of deep learning models trained on slide prepared using an enhanced workflow as compared to the traditional workflow which leverages manual tissue staining and standard imaging of tissue slides. Leveraging Inceptionv3 neural networks, we aimed to predict gene expression patterns across matched serial tissue sections, each stemming from a distinct workflow but aligned based on persistent histological structures. Findings indicate that the enhanced workflow considerably outperformed the traditional spatial transcriptomics workflow. Gene expression profiles predicted from enhanced tissue slides also yielded expression patterns more topologically consistent with the ground truth. This led to enhanced statistical precision in pinpointing biomarkers associated with distinct spatial structures. These insights can potentially elevate diagnostic and prognostic biomarker detection by broadening the range of spatial molecular markers linked to metastasis and recurrence. Future endeavors will further explore these findings to enrich our comprehension of various diseases and uncover molecular pathways with greater nuance. Combining deep learning with spatial transcriptomics provides a compelling avenue to enrich our understanding of tumor biology and improve clinical outcomes. For results of the highest fidelity, however, effective specimen processing is crucial, and fostering collaboration between histotechnicians, pathologists, and genomics specialists is essential to herald this new era in spatial transcriptomics-driven cancer research.",10.1101/2023.10.09.23296700,virology-deep-learning.xlsx,"The Overlooked Role of Specimen Preparation in Bolstering Deep Learning-Enhanced Spatial Transcriptomics Workflows The application of deep learning methods to spatial transcriptomics has shown promise in unraveling the complex relationships between gene expression patterns and tissue architecture as they pertain to various pathological conditions. Deep learning methods that can infer gene expression patterns directly from tissue histomorphology can expand the capability to discern spatial molecular markers within tissue slides. However, current methods utilizing these techniques are plagued by substantial variability in tissue preparation and characteristics, which can hinder the broader adoption of these tools. Furthermore, training deep learning models using spatial transcriptomics on small study cohorts remains a costly endeavor. Necessitating novel tissue preparation processes enhance assay reliability, resolution, and scalability. This study investigated the impact of an enhanced specimen processing workflow for facilitating a deep learning-based spatial transcriptomics assessment. The enhanced workflow leveraged the flexibility of the Visium CytAssist assay to permit automated H&E staining (e.g., Leica Bond) of tissue slides, whole-slide imaging at 40x-resolution, and multiplexing of tissue sections from multiple patients within individual capture areas for spatial transcriptomics profiling. Using a cohort of thirteen pT3 stage colorectal cancer (CRC) patients, we compared the efficacy of deep learning models trained on slide prepared using an enhanced workflow as compared to the traditional workflow which leverages manual tissue staining and standard imaging of tissue slides. Leveraging Inceptionv3 neural networks, we aimed to predict gene expression patterns across matched serial tissue sections, each stemming from a distinct workflow but aligned based on persistent histological structures. Findings indicate that the enhanced workflow considerably outperformed the traditional spatial transcriptomics workflow. Gene expression profiles predicted from enhanced tissue slides also yielded expression patterns more topologically consistent with the ground truth. This led to enhanced statistical precision in pinpointing biomarkers associated with distinct spatial structures. These insights can potentially elevate diagnostic and prognostic biomarker detection by broadening the range of spatial molecular markers linked to metastasis and recurrence. Future endeavors will further explore these findings to enrich our comprehension of various diseases and uncover molecular pathways with greater nuance. Combining deep learning with spatial transcriptomics provides a compelling avenue to enrich our understanding of tumor biology and improve clinical outcomes. For results of the highest fidelity, however, effective specimen processing is crucial, and fostering collaboration between histotechnicians, pathologists, and genomics specialists is essential to herald this new era in spatial transcriptomics-driven cancer research.",0
"Lafarge, M. W.; Domingo, E.; Sirinukunwattana, K.; Wood, R.; Samuel, L.; Murray, G.; Richman, S. D.; Blake, A.; Sebag-Montefiore, D.; Gollins, S.; Klieser, E.; Neureiter, D.; Huemer, F.; Greil, R.; Dunne, P.; Quirke, P.; Weiss, L.; Rittscher, J.; Maughan, T.; Koelzer, V. H.",2024,Image-Based Consensus Molecular Subtyping in Rectal Cancer Biopsies and Response to Neoadjuvant Chemoradiotherapy,Pathology,Image-Based Consensus Molecular Subtyping in Rectal Cancer Biopsies and Response to Neoadjuvant Chemoradiotherapy,"Lafarge, M. W.; Domingo, E.; Sirinukunwattana, K.; Wood, R.; Samuel, L.; Murray, G.; Richman, S. D.; Blake, A.; Sebag-Montefiore, D.; Gollins, S.; Klieser, E.; Neureiter, D.; Huemer, F.; Greil, R.; Dunne, P.; Quirke, P.; Weiss, L.; Rittscher, J.; Maughan, T.; Koelzer, V. H.",Pathology,2024-02-09 00:00:00 UTC,"The development of deep learning (DL) models to predict the consensus molecular subtypes (CMS) from histopathology images (imCMS) is a promising and cost-effective strategy to support patient stratification. Here, we investigate whether imCMS calls generated from whole slide histopathology images (WSIs) of rectal cancer (RC) pre-treatment biopsies are associated with pathological complete response (pCR) to neoadjuvant long course chemoradiotherapy (LCRT) with single agent fluoropyrimidine.

DL models were trained to classify WSIs of colorectal cancers stained with hematoxylin and eosin into one of the four CMS classes using a multi-centric dataset of resection and biopsy specimens (n=1057 WSIs) with paired transcriptional data. Classifiers were tested on a held out RC biopsy cohort (ARISTOTLE) and correlated with pCR to LCRT in an independent dataset merging two RC cohorts (ARISTOTLE, n=114 and SALZBURG, n=55 patients).

DL models predicted CMS with high classification performance in multiple comparative analyses. In the independent cohorts (ARISTOTLE, SALZBURG), cases with WSIs classified as imCMS1 had a significantly higher likelihood of achieving pCR (OR=2.69, 95%CI 1.01-7.17, p=0.048). Conversely, imCMS4 was associated with lack of pCR (OR=0.25, 95%CI 0.07-0.88, p=0.031). Classification maps demonstrated pathologist-interpretable associations with high stromal content in imCMS4 cases, associated with poor outcome. No significant association was found in imCMS2 or imCMS3.

imCMS classification of pre-treatment biopsies is a fast and inexpensive solution to identify patient groups that could benefit from neoadjuvant LCRT. The significant associations between imCMS1/imCMS4 with pCR suggest the existence of predictive morphological features that could enhance standard pathological assessment.",10.1101/2023.10.26.23297521,virology-deep-learning.xlsx,"Image-Based Consensus Molecular Subtyping in Rectal Cancer Biopsies and Response to Neoadjuvant Chemoradiotherapy The development of deep learning (DL) models to predict the consensus molecular subtypes (CMS) from histopathology images (imCMS) is a promising and cost-effective strategy to support patient stratification. Here, we investigate whether imCMS calls generated from whole slide histopathology images (WSIs) of rectal cancer (RC) pre-treatment biopsies are associated with pathological complete response (pCR) to neoadjuvant long course chemoradiotherapy (LCRT) with single agent fluoropyrimidine.

DL models were trained to classify WSIs of colorectal cancers stained with hematoxylin and eosin into one of the four CMS classes using a multi-centric dataset of resection and biopsy specimens (n=1057 WSIs) with paired transcriptional data. Classifiers were tested on a held out RC biopsy cohort (ARISTOTLE) and correlated with pCR to LCRT in an independent dataset merging two RC cohorts (ARISTOTLE, n=114 and SALZBURG, n=55 patients).

DL models predicted CMS with high classification performance in multiple comparative analyses. In the independent cohorts (ARISTOTLE, SALZBURG), cases with WSIs classified as imCMS1 had a significantly higher likelihood of achieving pCR (OR=2.69, 95%CI 1.01-7.17, p=0.048). Conversely, imCMS4 was associated with lack of pCR (OR=0.25, 95%CI 0.07-0.88, p=0.031). Classification maps demonstrated pathologist-interpretable associations with high stromal content in imCMS4 cases, associated with poor outcome. No significant association was found in imCMS2 or imCMS3.

imCMS classification of pre-treatment biopsies is a fast and inexpensive solution to identify patient groups that could benefit from neoadjuvant LCRT. The significant associations between imCMS1/imCMS4 with pCR suggest the existence of predictive morphological features that could enhance standard pathological assessment.",0
"Heilbroner, S. P.; Carter, C.; Vidmar, D. M.; Mueller, E. T.; Stumpe, M. C.; Miotto, R.",2023,LIFE: A Deep Learning Framework for Laboratory Data Imputation in Electronic Health Records,Epidemiology,LIFE: A Deep Learning Framework for Laboratory Data Imputation in Electronic Health Records,"Heilbroner, S. P.; Carter, C.; Vidmar, D. M.; Mueller, E. T.; Stumpe, M. C.; Miotto, R.",Epidemiology,2023-11-02 00:00:00 UTC,"Laboratory data in electronic health records (EHRs) is an effective source of information to characterize patient populations, inform accurate diagnostics and treatment decisions, and fuel research studies. However, despite their value, laboratory values are underutilized due to high levels of missingness. Existing imputation methods fall short, as they do not fully leverage patient clinical histories and are commonly not scalable to the large number of tests available in real-world data (RWD). To address these shortcomings, we present Laboratory Imputation Framework using EHRs (LIFE), a deep learning framework based on multi-head attention that is trained to impute any laboratory test value at any point in time in the patients journey using their complete EHRs. This architecture (1) eliminates the need to train a different model for each laboratory test by jointly modeling all laboratory data of interest; and (2) better clinically contextualizes the predictions by leveraging additional EHR variables, such as diagnosis, medications, and discrete laboratory results. We validate our framework using a large-scale, real-world dataset encompassing over 1 million oncology patients. Our results demonstrate that LIFE obtains superior or equivalent results compared to state-of-the-art baselines in 23 out of 25 evaluated laboratory tests and better enhances a downstream adverse event detection task in 7 out of 9 cases, showcasing its potential in efficiently estimating missing laboratory values and, consequently, in transforming the utilization of RWD in healthcare.",10.1101/2023.10.31.23297843,virology-deep-learning.xlsx,"LIFE: A Deep Learning Framework for Laboratory Data Imputation in Electronic Health Records Laboratory data in electronic health records (EHRs) is an effective source of information to characterize patient populations, inform accurate diagnostics and treatment decisions, and fuel research studies. However, despite their value, laboratory values are underutilized due to high levels of missingness. Existing imputation methods fall short, as they do not fully leverage patient clinical histories and are commonly not scalable to the large number of tests available in real-world data (RWD). To address these shortcomings, we present Laboratory Imputation Framework using EHRs (LIFE), a deep learning framework based on multi-head attention that is trained to impute any laboratory test value at any point in time in the patients journey using their complete EHRs. This architecture (1) eliminates the need to train a different model for each laboratory test by jointly modeling all laboratory data of interest; and (2) better clinically contextualizes the predictions by leveraging additional EHR variables, such as diagnosis, medications, and discrete laboratory results. We validate our framework using a large-scale, real-world dataset encompassing over 1 million oncology patients. Our results demonstrate that LIFE obtains superior or equivalent results compared to state-of-the-art baselines in 23 out of 25 evaluated laboratory tests and better enhances a downstream adverse event detection task in 7 out of 9 cases, showcasing its potential in efficiently estimating missing laboratory values and, consequently, in transforming the utilization of RWD in healthcare.",0
"Pozzi, M.; Noei, S.; Robbi, E.; Cima, L.; Moroni, M.; Munari, E.; Torresani, E.; Jurman, G.",2023,Generating synthetic data in digital pathology through diffusion models: a multifaceted approach to evaluation,Pathology,Generating synthetic data in digital pathology through diffusion models: a multifaceted approach to evaluation,"Pozzi, M.; Noei, S.; Robbi, E.; Cima, L.; Moroni, M.; Munari, E.; Torresani, E.; Jurman, G.",Pathology,2023-11-22 00:00:00 UTC,"Synthetic data has recently risen as a new precious item in the computational pathologists toolbox, supporting several tasks such as helping with data scarcity or augmenting training set in deep learning. Nonetheless, the use of such novel resources requires a carefully planned construction and evaluation, to avoid pitfalls such as the generation of clinically meaningless artifacts.

As the major outcome described in the current manuscript, a novel full stack pipeline is introduced for the generation and evaluation of synthetic pathology data powered by a diffusion model. The workflow features, as characterizing elements, a new multifaceted evaluation strategy with an embedded explainability procedure effectively tackling two critical aspects of the use of synthetic data in health-related domains.

An ensemble-like strategy is adopted for the evaluation of the produced data, with the threefold aim of assessing the similarity of real and synthetic data through a set of well-established metrics, evaluating the practical usability of the generated images in deep learning models complemented by explainable AI methods, and validating their histopathological realism through a dedicated questionnaire answered by three professional pathologists.

The pipeline is demonstrated on the public GTEx dataset of 650 WSIs, including five different tissues, conditioning the training step of the underlying diffusion model. An equal number of tiles from each of these five tissues are then generated. Finally, the reliability of the generated data is assessed using the proposed evaluation pipeline, with encouraging results. We show that each of these evaluation steps are necessary as they provide complementary information on the generated datas quality.

Overall, all the aforementioned features characterize the proposed workflow as a fully-fledged solution for generative AI in digital pathology representing a potentially useful tool for the digital pathology community in their transition towards digitalization and data-driven modeling.",10.1101/2023.11.21.23298808,virology-deep-learning.xlsx,"Generating synthetic data in digital pathology through diffusion models: a multifaceted approach to evaluation Synthetic data has recently risen as a new precious item in the computational pathologists toolbox, supporting several tasks such as helping with data scarcity or augmenting training set in deep learning. Nonetheless, the use of such novel resources requires a carefully planned construction and evaluation, to avoid pitfalls such as the generation of clinically meaningless artifacts.

As the major outcome described in the current manuscript, a novel full stack pipeline is introduced for the generation and evaluation of synthetic pathology data powered by a diffusion model. The workflow features, as characterizing elements, a new multifaceted evaluation strategy with an embedded explainability procedure effectively tackling two critical aspects of the use of synthetic data in health-related domains.

An ensemble-like strategy is adopted for the evaluation of the produced data, with the threefold aim of assessing the similarity of real and synthetic data through a set of well-established metrics, evaluating the practical usability of the generated images in deep learning models complemented by explainable AI methods, and validating their histopathological realism through a dedicated questionnaire answered by three professional pathologists.

The pipeline is demonstrated on the public GTEx dataset of 650 WSIs, including five different tissues, conditioning the training step of the underlying diffusion model. An equal number of tiles from each of these five tissues are then generated. Finally, the reliability of the generated data is assessed using the proposed evaluation pipeline, with encouraging results. We show that each of these evaluation steps are necessary as they provide complementary information on the generated datas quality.

Overall, all the aforementioned features characterize the proposed workflow as a fully-fledged solution for generative AI in digital pathology representing a potentially useful tool for the digital pathology community in their transition towards digitalization and data-driven modeling.",0
"Gkertsou, C.; Parameshwarappa, A. K.; Shiyanbola, A.; Balkhiyarova, Z.; Kouchaki, S.; Prokopenko, I.; Lagou, V.; Demirkan, A.",2023,Genetic loci discovery for Alzheimer's disease using explainable deep neural networks,Epidemiology,Genetic loci discovery for Alzheimer's disease using explainable deep neural networks,"Gkertsou, C.; Parameshwarappa, A. K.; Shiyanbola, A.; Balkhiyarova, Z.; Kouchaki, S.; Prokopenko, I.; Lagou, V.; Demirkan, A.",Epidemiology,2023-12-13 00:00:00 UTC,"BackgroundGenome-wide association studies (GWAS) have shed light on various complex diseases and traits, by detecting more than 400,000 associated genetic loci. This number is expected to drastically increase because of the use of novel artificial intelligence methods offering new ways to study the effects of variants. Deep learning using artificial neural networks (ANN) is a sub-field of artificial intelligence, which simulates how the human brain learns. We aimed at assessing the potential of deep learning in human genetic studies of Alzheimers Disease (AD) and how these compare to the traditional statistical methods used in GWAS, by simultaneously testing the two approaches on the same dataset, while discovering new genetic loci associated to AD.

MethodsTo address this aim, phenotypic and genome-wide SNP data from the UK Biobank was analysed on a binary outcome, AD diagnosis, in two different data balance options, of one-to-one and one-to-two case-control datasets, using 2,764 cases vs 2,764 controls and 5,528 controls respectively matched on gender, age, ethnicity, PC1-20 and genotyping array. Genetic data handling and GWAS were performed using PLINK, whereas neural networks were trained using GenNet, a new ANN tool, with the same datasets, separated into training (60%), validation (20%) and test (20%) sets. Neural network layers were determined using biological knowledge, by annotating SNPs to genes and genes to AD related pathways, using ANNOVAR annotations followed by GeneSCF and KEGG.

ResultsSignificant associations were detected between four SNPs linked to two different genes and AD for the 1 to 1 case-control study design and six SNPs linked to four different genes for the 1 to 2 case-control study design by using PLINK. All identified regions have been previously associated to AD. GenNet identified twelve SNPs on seven genes to be associated with AD, all with biological plausibility, achieving an AUC of 0.80 when using three biologically determined layers and 0.73 when using two layers at the neural networks. No common top SNPs were identified between the machine learning and GWAS models.

ConclusionThis is one of the first studies attempting to compare the traditional GWAS to more sophisticated state-of-art methods for understanding the genetic architecture of complex phenotypes using the same dataset. More systematic comparisons with such approaches on real data are needed to enable best practises for machine learning in the analysis of genome-wide genetic data.",10.1101/2023.12.11.23299839,virology-deep-learning.xlsx,"Genetic loci discovery for Alzheimer's disease using explainable deep neural networks BackgroundGenome-wide association studies (GWAS) have shed light on various complex diseases and traits, by detecting more than 400,000 associated genetic loci. This number is expected to drastically increase because of the use of novel artificial intelligence methods offering new ways to study the effects of variants. Deep learning using artificial neural networks (ANN) is a sub-field of artificial intelligence, which simulates how the human brain learns. We aimed at assessing the potential of deep learning in human genetic studies of Alzheimers Disease (AD) and how these compare to the traditional statistical methods used in GWAS, by simultaneously testing the two approaches on the same dataset, while discovering new genetic loci associated to AD.

MethodsTo address this aim, phenotypic and genome-wide SNP data from the UK Biobank was analysed on a binary outcome, AD diagnosis, in two different data balance options, of one-to-one and one-to-two case-control datasets, using 2,764 cases vs 2,764 controls and 5,528 controls respectively matched on gender, age, ethnicity, PC1-20 and genotyping array. Genetic data handling and GWAS were performed using PLINK, whereas neural networks were trained using GenNet, a new ANN tool, with the same datasets, separated into training (60%), validation (20%) and test (20%) sets. Neural network layers were determined using biological knowledge, by annotating SNPs to genes and genes to AD related pathways, using ANNOVAR annotations followed by GeneSCF and KEGG.

ResultsSignificant associations were detected between four SNPs linked to two different genes and AD for the 1 to 1 case-control study design and six SNPs linked to four different genes for the 1 to 2 case-control study design by using PLINK. All identified regions have been previously associated to AD. GenNet identified twelve SNPs on seven genes to be associated with AD, all with biological plausibility, achieving an AUC of 0.80 when using three biologically determined layers and 0.73 when using two layers at the neural networks. No common top SNPs were identified between the machine learning and GWAS models.

ConclusionThis is one of the first studies attempting to compare the traditional GWAS to more sophisticated state-of-art methods for understanding the genetic architecture of complex phenotypes using the same dataset. More systematic comparisons with such approaches on real data are needed to enable best practises for machine learning in the analysis of genome-wide genetic data.",0
"Song, T.-H.; Clemente, L.; Pan, X.; Jang, J.; Santillana, M.; Lee, K.",2024,Fine-Grained Forecasting of COVID-19 Trends at the County Level in the United States,Epidemiology,Fine-Grained Forecasting of COVID-19 Trends at the County Level in the United States,"Song, T.-H.; Clemente, L.; Pan, X.; Jang, J.; Santillana, M.; Lee, K.",Epidemiology,2024-03-25 00:00:00 UTC,"The novel coronavirus (COVID-19) pandemic, first identified in Wuhan China in December 2019, has profoundly impacted various aspects of daily life, society, healthcare systems, and global health policies. There have been more than half a billion human infections and more than 6 million deaths globally attributable to COVID-19. Although treatments and vaccines to protect against COVID-19 are now available, people continue being hospitalized and dying due to COVID-19 infections. Real-time surveillance of population-level infections, hospitalizations, and deaths has helped public health officials better allocate healthcare resources and deploy mitigation strategies. However, producing reliable, real-time, short-term disease activity forecasts (one or two weeks into the future) remains a practical challenge. The recent emergence of robust time-series forecasting methodologies based on deep learning approaches has led to clear improvements in multiple research fields. We propose a recurrent neural network model named Fine-Grained Infection Forecast Network (FIGI-Net), which utilizes a stacked bidirectional LSTM structure designed to leverage fine-grained county-level data, to produce daily forecasts of COVID-19 infection trends up to two weeks in advance. We show that FIGI-Net improves existing COVID-19 forecasting approaches and delivers accurate county-level COVID-19 disease estimates. Specifically, FIGI-Net is capable of anticipating upcoming sudden changes in disease trends such as the onset of a new outbreak or the peak of an ongoing outbreak, a skill that multiple existing state-of-the-art models fail to achieve. This improved performance is observed across locations and periods. Our enhanced forecasting methodologies may help protect human populations against future disease outbreaks.",10.1101/2024.01.13.24301248,virology-deep-learning.xlsx,"Fine-Grained Forecasting of COVID-19 Trends at the County Level in the United States The novel coronavirus (COVID-19) pandemic, first identified in Wuhan China in December 2019, has profoundly impacted various aspects of daily life, society, healthcare systems, and global health policies. There have been more than half a billion human infections and more than 6 million deaths globally attributable to COVID-19. Although treatments and vaccines to protect against COVID-19 are now available, people continue being hospitalized and dying due to COVID-19 infections. Real-time surveillance of population-level infections, hospitalizations, and deaths has helped public health officials better allocate healthcare resources and deploy mitigation strategies. However, producing reliable, real-time, short-term disease activity forecasts (one or two weeks into the future) remains a practical challenge. The recent emergence of robust time-series forecasting methodologies based on deep learning approaches has led to clear improvements in multiple research fields. We propose a recurrent neural network model named Fine-Grained Infection Forecast Network (FIGI-Net), which utilizes a stacked bidirectional LSTM structure designed to leverage fine-grained county-level data, to produce daily forecasts of COVID-19 infection trends up to two weeks in advance. We show that FIGI-Net improves existing COVID-19 forecasting approaches and delivers accurate county-level COVID-19 disease estimates. Specifically, FIGI-Net is capable of anticipating upcoming sudden changes in disease trends such as the onset of a new outbreak or the peak of an ongoing outbreak, a skill that multiple existing state-of-the-art models fail to achieve. This improved performance is observed across locations and periods. Our enhanced forecasting methodologies may help protect human populations against future disease outbreaks.",1
"Fang, T.; Chen, X.; Wu, Z.; Tan, L.; Li, Z.; Ji, J.; Fan, Y.; Li, Z.; Yue, S.",2024,Label-free virtual peritoneal lavage cytology via deep-learning-assisted single-color stimulated Raman scattering microscopy,Pathology,Label-free virtual peritoneal lavage cytology via deep-learning-assisted single-color stimulated Raman scattering microscopy,"Fang, T.; Chen, X.; Wu, Z.; Tan, L.; Li, Z.; Ji, J.; Fan, Y.; Li, Z.; Yue, S.",Pathology,2024-01-17 00:00:00 UTC,"Clinical guidelines for gastric cancer treatment recommend intraoperative peritoneal lavage cytology to detect free cancer cells. Patients with positive cytology require neoadjuvant chemotherapy instead of instant resection and conversion to negative cytology results in improved survival. However, the accuracy of cytological diagnosis by pathologists or artificial intelligence is disturbed by manually-produced, unstandardized slides. In addition, the elaborate infrastructure makes cytology accessible to a limited number of medical institutes. Here, we developed CellGAN, a deep learning method that enables label-free virtual peritoneal lavage cytology by producing virtual hematoxylin-eosin-stained images with single-color stimulated Raman scattering microscopy. A structural similarity loss was introduced to overcome the challenge of existing unsupervised virtual pathology techniques unable to present cellular structures accurately. This method achieved a structural similarity of 0.820{+/-}0.041 and a nucleus area consistency of 0.698{+/-}0.102, indicating the staining fidelity outperforming the state-of-the-art method. Diagnosis using virtually stained cells reached 93.8% accuracy and substantial consistency with conventional staining. Single-cell detection and classification on virtual slides achieved a mean average precision of 0.924 and an area under the receiver operating characteristic curve of 0.906, respectively. Collectively, this method achieves standardized and accurate virtual peritoneal lavage cytology and holds great potential for clinical translation.",10.1101/2024.01.17.24301416,virology-deep-learning.xlsx,"Label-free virtual peritoneal lavage cytology via deep-learning-assisted single-color stimulated Raman scattering microscopy Clinical guidelines for gastric cancer treatment recommend intraoperative peritoneal lavage cytology to detect free cancer cells. Patients with positive cytology require neoadjuvant chemotherapy instead of instant resection and conversion to negative cytology results in improved survival. However, the accuracy of cytological diagnosis by pathologists or artificial intelligence is disturbed by manually-produced, unstandardized slides. In addition, the elaborate infrastructure makes cytology accessible to a limited number of medical institutes. Here, we developed CellGAN, a deep learning method that enables label-free virtual peritoneal lavage cytology by producing virtual hematoxylin-eosin-stained images with single-color stimulated Raman scattering microscopy. A structural similarity loss was introduced to overcome the challenge of existing unsupervised virtual pathology techniques unable to present cellular structures accurately. This method achieved a structural similarity of 0.820{+/-}0.041 and a nucleus area consistency of 0.698{+/-}0.102, indicating the staining fidelity outperforming the state-of-the-art method. Diagnosis using virtually stained cells reached 93.8% accuracy and substantial consistency with conventional staining. Single-cell detection and classification on virtual slides achieved a mean average precision of 0.924 and an area under the receiver operating characteristic curve of 0.906, respectively. Collectively, this method achieves standardized and accurate virtual peritoneal lavage cytology and holds great potential for clinical translation.",0
"Andani, S.; Chen, B.; Ficek-Pascual, J.; Heinke, S.; Casanova, R.; Hild, B.; Sobottka, B.; Bodenmiller, B.; The Tumor Profiler Consortium,  ; Ko?lzer, V. H.; Ra?tsch, G.",2024,HistoPlexer: Histopathology-based Protein Multiplex Generation using Deep Learning,Pathology,HistoPlexer: Histopathology-based Protein Multiplex Generation using Deep Learning,"Andani, S.; Chen, B.; Ficek-Pascual, J.; Heinke, S.; Casanova, R.; Hild, B.; Sobottka, B.; Bodenmiller, B.; The Tumor Profiler Consortium,  ; Ko?lzer, V. H.; Ra?tsch, G.",Pathology,2024-12-07 00:00:00 UTC,"Multiplexed imaging technologies provide crucial insights into interactions between tumors and their surrounding tumor microenvironment (TME), but their widespread adoption is limited by cost, time, and tissue availability. We introduce HistoPlexer, a deep learning (DL) framework that generates spatially-resolved protein multiplexes directly from histopathology images. HistoPlexer employs the conditional generative adversarial networks with custom loss functions that mitigate slice-to-slice variations and preserve spatial protein correlations. In a comprehensive evaluation on metastatic melanoma samples, HistoPlexer consistently outperforms existing approaches, achieving superior Multiscale Structural Similarity Index and Peak Signal-to-Noise Ratio. Qualitative evaluation by domain experts demonstrates that the generated protein multiplexes closely resemble the real ones, evidenced by Human Eye Perceptual Evaluation error rates exceeding the 50% threshold for perceived realism. Importantly, HistoPlexer preserves crucial biological relationships, accurately capturing spatial co-localization patterns among proteins. In addition, the spatial distribution of cell types derived from HistoPlexer-generated protein multiplex enables effective stratification of tumors into immune hot versus cold subtypes. When applied to an independent cohort, incorporating additional features from HistoPlexergenerated multiplexes enhances the performance of the DL model for survival prediction and immune subtyping, outperforming the model reliant solely on Hematoxylin & Eosin (H&E) image features. By enabling the generation of whole-slide protein multiplex from the H&E image, HistoPlexer offers a cost- and time-effective approach to understanding the TME, and holds promise for advancing precision oncology.",10.1101/2024.01.26.24301803,virology-deep-learning.xlsx,"HistoPlexer: Histopathology-based Protein Multiplex Generation using Deep Learning Multiplexed imaging technologies provide crucial insights into interactions between tumors and their surrounding tumor microenvironment (TME), but their widespread adoption is limited by cost, time, and tissue availability. We introduce HistoPlexer, a deep learning (DL) framework that generates spatially-resolved protein multiplexes directly from histopathology images. HistoPlexer employs the conditional generative adversarial networks with custom loss functions that mitigate slice-to-slice variations and preserve spatial protein correlations. In a comprehensive evaluation on metastatic melanoma samples, HistoPlexer consistently outperforms existing approaches, achieving superior Multiscale Structural Similarity Index and Peak Signal-to-Noise Ratio. Qualitative evaluation by domain experts demonstrates that the generated protein multiplexes closely resemble the real ones, evidenced by Human Eye Perceptual Evaluation error rates exceeding the 50% threshold for perceived realism. Importantly, HistoPlexer preserves crucial biological relationships, accurately capturing spatial co-localization patterns among proteins. In addition, the spatial distribution of cell types derived from HistoPlexer-generated protein multiplex enables effective stratification of tumors into immune hot versus cold subtypes. When applied to an independent cohort, incorporating additional features from HistoPlexergenerated multiplexes enhances the performance of the DL model for survival prediction and immune subtyping, outperforming the model reliant solely on Hematoxylin & Eosin (H&E) image features. By enabling the generation of whole-slide protein multiplex from the H&E image, HistoPlexer offers a cost- and time-effective approach to understanding the TME, and holds promise for advancing precision oncology.",0
"Kozinski, M.; Oner, D.; Gwizdala, J.; Beigelman, C.; Fua, P.; Koutsokera, A.; Casutt, A.; De Palma, M.; Aubert, J.-D.; Bischof, H.; Von Garnier, C.; Rahi, S.; Urschler, M.; Mansouri, N.",2024,Harnessing Deep Learning to Detect Bronchiolitis Obliterans Syndrome from Chest CT,Respiratory Medicine,Harnessing Deep Learning to Detect Bronchiolitis Obliterans Syndrome from Chest CT,"Kozinski, M.; Oner, D.; Gwizdala, J.; Beigelman, C.; Fua, P.; Koutsokera, A.; Casutt, A.; De Palma, M.; Aubert, J.-D.; Bischof, H.; Von Garnier, C.; Rahi, S.; Urschler, M.; Mansouri, N.",Respiratory Medicine,2024-02-08 00:00:00 UTC,"Bronchiolitis Obliterans Syndrome (BOS), a fibrotic airway disease following lung transplantation, conventionally relies on pulmonary function tests (PFTs) for diagnosis due to limitations of CT images. Thus far, deep neural networks (DNNs) have not been used for BOS detection. We optimized a DNN for detection of BOS solely using CT scans by integrating an innovative co-training method for enhanced performance in low-data scenarios. The novel auxiliary task is to predict the temporal precedence of CT scans of BOS patients. We tested our method using CT scans at various stages of inspiration from 75 post-transplant patients, including 26 with BOS. The method achieved a ROC-AUC of 0.90 (95% CI: 0.840-0.953) in distinguishing BOS from non-BOS CT scans. Performance correlated with disease progression, reaching 0.88 ROC-AUC for stage I, 0.91 for stage II, and an outstanding 0.94 for stage III BOS. Importantly, performance parity existed between standard and high-resolution scans. Particularly noteworthy is the DNNs ability to predict BOS in at-risk patients (FEV1 between 80% and 90% of best FEV1) with a robust 0.87 ROC-AUC (CI: 0.735-0.974). Using techniques for visually interpreting the results of deep neural networks, we reveal that our method is especially sensitive to hyperlucent areas compatible with air-trapping or bronchiectasis. Our approach shows the potential to improve BOS diagnosis, enabling early detection and management. Detecting BOS from low-resolution scans reduces radiation exposure and using scans at any stage of respiration makes our method more accessible. Additionally, we demonstrate that techniques that limit overfitting are essential to unlocking the power of DNNs in scenarios with scarce training data. Our method may enable clinicians to use DNNs in studies where only a modest number of patients is available.",10.1101/2024.02.07.24302414,virology-deep-learning.xlsx,"Harnessing Deep Learning to Detect Bronchiolitis Obliterans Syndrome from Chest CT Bronchiolitis Obliterans Syndrome (BOS), a fibrotic airway disease following lung transplantation, conventionally relies on pulmonary function tests (PFTs) for diagnosis due to limitations of CT images. Thus far, deep neural networks (DNNs) have not been used for BOS detection. We optimized a DNN for detection of BOS solely using CT scans by integrating an innovative co-training method for enhanced performance in low-data scenarios. The novel auxiliary task is to predict the temporal precedence of CT scans of BOS patients. We tested our method using CT scans at various stages of inspiration from 75 post-transplant patients, including 26 with BOS. The method achieved a ROC-AUC of 0.90 (95% CI: 0.840-0.953) in distinguishing BOS from non-BOS CT scans. Performance correlated with disease progression, reaching 0.88 ROC-AUC for stage I, 0.91 for stage II, and an outstanding 0.94 for stage III BOS. Importantly, performance parity existed between standard and high-resolution scans. Particularly noteworthy is the DNNs ability to predict BOS in at-risk patients (FEV1 between 80% and 90% of best FEV1) with a robust 0.87 ROC-AUC (CI: 0.735-0.974). Using techniques for visually interpreting the results of deep neural networks, we reveal that our method is especially sensitive to hyperlucent areas compatible with air-trapping or bronchiectasis. Our approach shows the potential to improve BOS diagnosis, enabling early detection and management. Detecting BOS from low-resolution scans reduces radiation exposure and using scans at any stage of respiration makes our method more accessible. Additionally, we demonstrate that techniques that limit overfitting are essential to unlocking the power of DNNs in scenarios with scarce training data. Our method may enable clinicians to use DNNs in studies where only a modest number of patients is available.",0
"Williams, D. K. A.; Graifman, G.; Hussain, N.; Amiel, M.; Priscilla, T.; Reddy, A.; Haider, A.; Kavitesh, B. K.; Li, A.; Alishahian, L.; Perera, N.; Efros, C.; Babu, M.; Tharakan, M.; Etienne, M.; Babu, B.",2024,"Digital Pathology, Deep Learning, and Cancer: A Narrative Review",Pathology,"Digital Pathology, Deep Learning, and Cancer: A Narrative Review","Williams, D. K. A.; Graifman, G.; Hussain, N.; Amiel, M.; Priscilla, T.; Reddy, A.; Haider, A.; Kavitesh, B. K.; Li, A.; Alishahian, L.; Perera, N.; Efros, C.; Babu, M.; Tharakan, M.; Etienne, M.; Babu, B.",Pathology,2024-03-15 00:00:00 UTC,"Background and ObjectiveCancer is a leading cause of morbidity and mortality worldwide. The emergence of digital pathology and deep learning technologies signifies a transformative era in healthcare. These technologies can enhance cancer detection, streamline operations, and bolster patient care. A substantial gap exists between the development phase of deep learning models in controlled laboratory environments and their translations into clinical practice. This narrative review evaluates the current landscape of deep learning and digital pathology, analyzing the factors influencing model development and implementation into clinical practice.

MethodsWe searched multiple databases, including Web of Science, Arxiv, MedRxiv, BioRxiv, Embase, PubMed, DBLP, Google Scholar, IEEE Xplore, and Cochrane, targeting articles on whole slide imaging and deep learning published from 2014 and 2023. Out of 776 articles identified based on inclusion criteria, we selected 36 papers for the analysis.

Key Content and FindingsMost articles in this review focus on the in-laboratory phase of deep learning model development, a critical stage in the deep learning lifecycle. Challenges arise during model development and their integration into clinical practice. Notably, lab performance metrics may not always match real-world clinical outcomes. As technology advances and regulations evolve, we expect more clinical trials to bridge this performance gap and validate deep learning models effectiveness in clinical care. High clinical accuracy is vital for informed decision-making throughout a patients cancer care.

ConclusionsDeep learning technology can enhance cancer detection, clinical workflows, and patient care. Challenges may arise during model development. The deep learning lifecycle involves data preprocessing, model development, and clinical implementation. Achieving health equity requires including diverse patient groups and eliminating bias during implementation. While model development is integral, most articles focus on the pre-deployment phase. Future longitudinal studies are crucial for validating models in real-world settings post-deployment. A collaborative approach among computational pathologists, technologists, industry, and healthcare providers is essential for driving adoption in clinical settings.",10.1101/2024.03.14.24304308,virology-deep-learning.xlsx,"Digital Pathology, Deep Learning, and Cancer: A Narrative Review Background and ObjectiveCancer is a leading cause of morbidity and mortality worldwide. The emergence of digital pathology and deep learning technologies signifies a transformative era in healthcare. These technologies can enhance cancer detection, streamline operations, and bolster patient care. A substantial gap exists between the development phase of deep learning models in controlled laboratory environments and their translations into clinical practice. This narrative review evaluates the current landscape of deep learning and digital pathology, analyzing the factors influencing model development and implementation into clinical practice.

MethodsWe searched multiple databases, including Web of Science, Arxiv, MedRxiv, BioRxiv, Embase, PubMed, DBLP, Google Scholar, IEEE Xplore, and Cochrane, targeting articles on whole slide imaging and deep learning published from 2014 and 2023. Out of 776 articles identified based on inclusion criteria, we selected 36 papers for the analysis.

Key Content and FindingsMost articles in this review focus on the in-laboratory phase of deep learning model development, a critical stage in the deep learning lifecycle. Challenges arise during model development and their integration into clinical practice. Notably, lab performance metrics may not always match real-world clinical outcomes. As technology advances and regulations evolve, we expect more clinical trials to bridge this performance gap and validate deep learning models effectiveness in clinical care. High clinical accuracy is vital for informed decision-making throughout a patients cancer care.

ConclusionsDeep learning technology can enhance cancer detection, clinical workflows, and patient care. Challenges may arise during model development. The deep learning lifecycle involves data preprocessing, model development, and clinical implementation. Achieving health equity requires including diverse patient groups and eliminating bias during implementation. While model development is integral, most articles focus on the pre-deployment phase. Future longitudinal studies are crucial for validating models in real-world settings post-deployment. A collaborative approach among computational pathologists, technologists, industry, and healthcare providers is essential for driving adoption in clinical settings.",0
"Liu, J.; Richmond, R.; Bowden, J.; Barry, C.; Dashti, H. S.; Daghlas, I. S.; Lane, J. M.; Jones, S. E.; Wood, A. R.; Frayling, T. M.; Wright, A. K.; Carr, M. J.; Anderson, S. G.; Emsley, R.; Ray, D.; Weedon, M. N.; Saxena, R.; Lawlor, D. A.; Rutter, M.",2021,Assessing the causal role of sleep traits on glycated haemoglobin: a Mendelian randomization study,Epidemiology,Assessing the causal role of sleep traits on glycated haemoglobin: a Mendelian randomization study,"Liu, J.; Richmond, R.; Bowden, J.; Barry, C.; Dashti, H. S.; Daghlas, I. S.; Lane, J. M.; Jones, S. E.; Wood, A. R.; Frayling, T. M.; Wright, A. K.; Carr, M. J.; Anderson, S. G.; Emsley, R.; Ray, D.; Weedon, M. N.; Saxena, R.; Lawlor, D. A.; Rutter, M.",Epidemiology,2021-01-06 00:00:00 UTC,"ObjectiveTo examine the effects of sleep traits on glycated haemoglobin (HbA1c).

DesignObservational multivariable regression (MVR), one-sample Mendelian randomization (1SMR), and two-sample summary data Mendelian randomization (2SMR).

SettingUK Biobank (UKB) prospective cohort study and genome-wide association studies from the Meta-Analyses of Glucose and Insulin-related traits Consortium (MAGIC).

ParticipantsIn MVR and 1SMR, participants were adults (mean (SD) age 57 (8) years; 54% female) from the UKB (n=336,999); in 2SMR, participants were adults (53 (11) years; 52% female) from MAGIC (n=46,368). All participants were adults of European ancestry.

ExposuresSelf-reported insomnia frequency (usually vs sometimes or rarely/never); sleep duration: 24-hour sleep duration (hours/day); short sleep ([&le;]6 hours vs 7-8 hours) and long sleep ([&ge;]9 hours vs 7-8 hours); daytime sleepiness and daytime napping (each consisting of 3 categories: never/rarely, sometimes, usually); chronotype (5 categories from definite morning to definite evening preference).

Main outcome measureHbA1c in standard deviation (SD) units.

ResultsAcross MV, 1SMR, 2SMR, and their sensitivity analyses we found a higher frequency of insomnia (usually vs sometimes or rarely/never) was associated with higher HbA1c (MVR: 0.053 SD units, 95% confidence interval (0.046 to 0.061), 1SMR: 0.52, (0.42 to 0.63), 2SMR: 0.22, (0.10 to 0.35)). Results remained significant but point estimates were somewhat attenuated after excluding people with diagnosed diabetes. For other sleep traits, there was less consistency with significant associations when using some, but not all methods.

ConclusionsThis study suggests that insomnia increases HbA1c levels. These findings could have important implications for developing and evaluating strategies that improve sleep habits to reduce hyperglycaemia and prevent diabetes.

SUMMARY BOXO_ST_ABSWhat is already known on this topicC_ST_ABSO_LIIn observational data, insomnia, short sleep duration, and evening preference are associated with higher risk for type 2 diabetes.
C_LIO_LIMendelian randomization (MR) studies have not found evidence of a causal effect of short sleep on type 2 diabetes or glycaemic traits but have indicated an effect of insomnia on type 2 diabetes. It is unclear whether insomnia influences HbA1c levels, a marker of long-term hyperglycaemia, in the general population.
C_LIO_LIRecently identified genetic variants robustly associated with insomnia, sleep duration, daytime sleepiness, napping, and chronotype can be used in MR studies to explore causal effects of these sleep traits on HbA1c levels.
C_LI

What this study addsO_LIThis study suggests that a higher frequency of insomnia increases HbA1c levels in the general population and after excluding people with diabetes.
C_LIO_LIWe found no robust evidence for causal effects of other sleep traits on HbA1c levels.
C_LIO_LIThese findings improve our understanding of the impact of sleep traits on HbA1c levels and have important implications for developing and evaluating strategies that improve sleep habits to reduce hyperglycaemia and prevent diabetes.
C_LI",10.1101/2020.12.18.20224733,virology-generative-AI.xlsx,"Assessing the causal role of sleep traits on glycated haemoglobin: a Mendelian randomization study ObjectiveTo examine the effects of sleep traits on glycated haemoglobin (HbA1c).

DesignObservational multivariable regression (MVR), one-sample Mendelian randomization (1SMR), and two-sample summary data Mendelian randomization (2SMR).

SettingUK Biobank (UKB) prospective cohort study and genome-wide association studies from the Meta-Analyses of Glucose and Insulin-related traits Consortium (MAGIC).

ParticipantsIn MVR and 1SMR, participants were adults (mean (SD) age 57 (8) years; 54% female) from the UKB (n=336,999); in 2SMR, participants were adults (53 (11) years; 52% female) from MAGIC (n=46,368). All participants were adults of European ancestry.

ExposuresSelf-reported insomnia frequency (usually vs sometimes or rarely/never); sleep duration: 24-hour sleep duration (hours/day); short sleep ([&le;]6 hours vs 7-8 hours) and long sleep ([&ge;]9 hours vs 7-8 hours); daytime sleepiness and daytime napping (each consisting of 3 categories: never/rarely, sometimes, usually); chronotype (5 categories from definite morning to definite evening preference).

Main outcome measureHbA1c in standard deviation (SD) units.

ResultsAcross MV, 1SMR, 2SMR, and their sensitivity analyses we found a higher frequency of insomnia (usually vs sometimes or rarely/never) was associated with higher HbA1c (MVR: 0.053 SD units, 95% confidence interval (0.046 to 0.061), 1SMR: 0.52, (0.42 to 0.63), 2SMR: 0.22, (0.10 to 0.35)). Results remained significant but point estimates were somewhat attenuated after excluding people with diagnosed diabetes. For other sleep traits, there was less consistency with significant associations when using some, but not all methods.

ConclusionsThis study suggests that insomnia increases HbA1c levels. These findings could have important implications for developing and evaluating strategies that improve sleep habits to reduce hyperglycaemia and prevent diabetes.

SUMMARY BOXO_ST_ABSWhat is already known on this topicC_ST_ABSO_LIIn observational data, insomnia, short sleep duration, and evening preference are associated with higher risk for type 2 diabetes.
C_LIO_LIMendelian randomization (MR) studies have not found evidence of a causal effect of short sleep on type 2 diabetes or glycaemic traits but have indicated an effect of insomnia on type 2 diabetes. It is unclear whether insomnia influences HbA1c levels, a marker of long-term hyperglycaemia, in the general population.
C_LIO_LIRecently identified genetic variants robustly associated with insomnia, sleep duration, daytime sleepiness, napping, and chronotype can be used in MR studies to explore causal effects of these sleep traits on HbA1c levels.
C_LI

What this study addsO_LIThis study suggests that a higher frequency of insomnia increases HbA1c levels in the general population and after excluding people with diabetes.
C_LIO_LIWe found no robust evidence for causal effects of other sleep traits on HbA1c levels.
C_LIO_LIThese findings improve our understanding of the impact of sleep traits on HbA1c levels and have important implications for developing and evaluating strategies that improve sleep habits to reduce hyperglycaemia and prevent diabetes.
C_LI",0
"Menezes, S. M.; Braz, M.; Llorens-Rico, V.; Wauters, J.; Van Weyenbergh, J.",2021,Endogenous interferon-beta but not interferon-alpha or interferon-lambda levels in upper respiratory tract predict clinical outcome in critical COVID-19 patients independent of viral load,Respiratory Medicine,Endogenous interferon-beta but not interferon-alpha or interferon-lambda levels in upper respiratory tract predict clinical outcome in critical COVID-19 patients independent of viral load,"Menezes, S. M.; Braz, M.; Llorens-Rico, V.; Wauters, J.; Van Weyenbergh, J.",Respiratory Medicine,2021-03-26 00:00:00 UTC,"Although the subject of intensive preclinical and clinical research, controversy on the protective vs. deleterious effect of interferon (IFN) in COVID-19 remains. Some apparently conflicting results are likely due to the intricacy of IFN subtypes (type I: IFN-alpha/beta, type III: IFN-lambda), timing and mode of administration (nebulized/subcutaneous) and clinical groups targeted (asymptomatic/mild, moderate, severe/critical COVID-19). Within the COntAGIouS (COvid-19 Advanced Genetic and Immunologic Sampling) clinical trial, we investigated endogenous type I and type III IFNs in nasal mucosa as possible predictors of clinical outcome in critical patients, as well as their correlation to SARS-CoV-2 viral load, using nCounter technology. We found that endogenous IFN-beta expression in the nasal mucosa predicts clinical outcome, independent of viral replication or Apache II score, and should be considered as a prognostic tool in a precision medicine approach of IFN therapy in COVID-19 clinical management.",10.1101/2021.03.23.21253748,virology-generative-AI.xlsx,"Endogenous interferon-beta but not interferon-alpha or interferon-lambda levels in upper respiratory tract predict clinical outcome in critical COVID-19 patients independent of viral load Although the subject of intensive preclinical and clinical research, controversy on the protective vs. deleterious effect of interferon (IFN) in COVID-19 remains. Some apparently conflicting results are likely due to the intricacy of IFN subtypes (type I: IFN-alpha/beta, type III: IFN-lambda), timing and mode of administration (nebulized/subcutaneous) and clinical groups targeted (asymptomatic/mild, moderate, severe/critical COVID-19). Within the COntAGIouS (COvid-19 Advanced Genetic and Immunologic Sampling) clinical trial, we investigated endogenous type I and type III IFNs in nasal mucosa as possible predictors of clinical outcome in critical patients, as well as their correlation to SARS-CoV-2 viral load, using nCounter technology. We found that endogenous IFN-beta expression in the nasal mucosa predicts clinical outcome, independent of viral replication or Apache II score, and should be considered as a prognostic tool in a precision medicine approach of IFN therapy in COVID-19 clinical management.",1
"Duclos, T. G.; Reichert, T. A.",2021,CHARACTERIZING AND MANAGING AN EPIDEMIC: A FIRST PRINCIPLES MODEL AND A CLOSED FORM SOLUTION TO THE KERMACK AND MCKENDRICK EQUATIONS,Epidemiology,CHARACTERIZING AND MANAGING AN EPIDEMIC: A FIRST PRINCIPLES MODEL AND A CLOSED FORM SOLUTION TO THE KERMACK AND MCKENDRICK EQUATIONS,"Duclos, T. G.; Reichert, T. A.",Epidemiology,2021-09-14 00:00:00 UTC,"We derived a closed-form solution to the original epidemic equations formulated by Kermack and McKendrick in 1927 (1). The complete solution is validated using independently measured mobility data and accurate predictions of COVID-19 case dynamics in multiple countries. It replicates the observed phenomenology, quantitates pandemic dynamics, and provides simple analytical tools for policy makers. Of particular note, it projects that increased social containment measures shorten an epidemic and reduce the ultimate number of cases and deaths. In contrast, the widely used Susceptible-Infectious-Recovered (SIR) models, based on an approximation to Kermack and McKendricks original equations, project that strong containment measures delay the peak in daily infections, causing a longer epidemic. These projections contradict both the complete solution and the observed phenomenology in COVID-19 pandemic data. The closed-form solution elucidates that the two parameters classically used as constants in approximate SIR models cannot, in fact, be reasonably assumed to be constant in real epidemics. This prima facie failure forces the conclusion that the approximate SIR models should not be used to characterize or manage epidemics. As a replacement to the SIR models, the closed-form solution and the expressions derived from the solution form a complete set of analytical tools that can accurately diagnose the state of an epidemic and provide proper guidance for public health decision makers.",10.1101/2021.09.09.21263355,virology-generative-AI.xlsx,"CHARACTERIZING AND MANAGING AN EPIDEMIC: A FIRST PRINCIPLES MODEL AND A CLOSED FORM SOLUTION TO THE KERMACK AND MCKENDRICK EQUATIONS We derived a closed-form solution to the original epidemic equations formulated by Kermack and McKendrick in 1927 (1). The complete solution is validated using independently measured mobility data and accurate predictions of COVID-19 case dynamics in multiple countries. It replicates the observed phenomenology, quantitates pandemic dynamics, and provides simple analytical tools for policy makers. Of particular note, it projects that increased social containment measures shorten an epidemic and reduce the ultimate number of cases and deaths. In contrast, the widely used Susceptible-Infectious-Recovered (SIR) models, based on an approximation to Kermack and McKendricks original equations, project that strong containment measures delay the peak in daily infections, causing a longer epidemic. These projections contradict both the complete solution and the observed phenomenology in COVID-19 pandemic data. The closed-form solution elucidates that the two parameters classically used as constants in approximate SIR models cannot, in fact, be reasonably assumed to be constant in real epidemics. This prima facie failure forces the conclusion that the approximate SIR models should not be used to characterize or manage epidemics. As a replacement to the SIR models, the closed-form solution and the expressions derived from the solution form a complete set of analytical tools that can accurately diagnose the state of an epidemic and provide proper guidance for public health decision makers.",1
"Liu, J.; Richmond, R. C.; Anderson, E. L.; Bowden, J.; Barry, C.-J. S.; Dashti, H. S.; Daghlas, I. S.; Lane, J. M.; Kyle, S. D.; Vetter, C.; Morrison, C. L.; Jones, S. E.; Wood, A. R.; Frayling, T. R.; Wright, A. K.; Carr, M. J.; Anderson, S. G.; Emsley, R. A.; Ray, D. W.; Weedon, M. N.; Saxena, R.; Rutter, M. K.; Lawlor, D. A.",2023,The role of accelerometer-derived sleep traits on glycated haemoglobin and glucose levels: a Mendelian randomization study,Epidemiology,The role of accelerometer-derived sleep traits on glycated haemoglobin and glucose levels: a Mendelian randomization study,"Liu, J.; Richmond, R. C.; Anderson, E. L.; Bowden, J.; Barry, C.-J. S.; Dashti, H. S.; Daghlas, I. S.; Lane, J. M.; Kyle, S. D.; Vetter, C.; Morrison, C. L.; Jones, S. E.; Wood, A. R.; Frayling, T. R.; Wright, A. K.; Carr, M. J.; Anderson, S. G.; Emsley, R. A.; Ray, D. W.; Weedon, M. N.; Saxena, R.; Rutter, M. K.; Lawlor, D. A.",Epidemiology,2023-06-28 00:00:00 UTC,"Study ObjectivesSelf-reported shorter/longer sleep duration, insomnia, and evening preference are associated with hyperglycaemia in observational analyses, with similar results observed in small studies using accelerometer-derived sleep traits. Mendelian randomization (MR) studies support an effect of self-reported insomnia, but not other sleep traits, on glycated haemoglobin (HbA1c). Our aims were a) to explore potential effects of accelerometer-derived sleep traits on HbA1c and glucose levels and b) to determine genetic correlations across accelerometer-derived and self-reported sleep traits.

MethodsWe used MR methods to explore effects of accelerometer-derived sleep traits (duration, mid-point least active 5-hours, mid-point most active 10-hours, sleep fragmentation, and efficiency) on HbA1c in European adults from the UK Biobank (UKB) (n = 73,797) and the MAGIC consortium (n = 149,054). Cross-trait linkage disequilibrium score regression was also applied to determine genetic correlations across all accelerometer-derived and self-reported sleep traits and HbA1c/glucose.

ResultsMain and sensitivity MR analyses showed no causal effect of any accelerometer-derived sleep trait on HbA1c or glucose. Similar MR results for self-reported sleep traits in the UKB sub-sample with accelerometer-derived measures suggested our results were not explained by selection bias. Genetic correlation analyses suggested complex relationships between self-reported and accelerometer-derived traits indicating that they may reflect different types of exposure.

ConclusionsTaken together, these findings suggested accelerometer-derived sleep traits do not causally affect HbA1c levels, and accelerometer-derived measures of sleep duration and sleep quality might not simply be  objective measures of self-reported sleep duration and insomnia, but rather captured different underlying sleep characteristics.

Statement of SignificanceSelf-reported and accelerometer-derived sleep disturbance is associated with increased risk of hyperglycaemia and type 2 diabetes in observational analyses. Mendelian randomization (MR) studies support an effect of self-reported insomnia, but not other self-reported sleep traits, on glycated haemoglobin (HbA1c). This MR study showed little evidence supporting an effect of any accelerometer-derived sleep trait on HbA1c or glucose, but a potential non-linear (e.g., U-shaped) effect cannot be ruled out. The genetic correlation suggested complex relationships between self-reported and accelerometer-derived traits indicating that they may reflect different exposures.",10.1101/2022.10.11.22280427,virology-generative-AI.xlsx,"The role of accelerometer-derived sleep traits on glycated haemoglobin and glucose levels: a Mendelian randomization study Study ObjectivesSelf-reported shorter/longer sleep duration, insomnia, and evening preference are associated with hyperglycaemia in observational analyses, with similar results observed in small studies using accelerometer-derived sleep traits. Mendelian randomization (MR) studies support an effect of self-reported insomnia, but not other sleep traits, on glycated haemoglobin (HbA1c). Our aims were a) to explore potential effects of accelerometer-derived sleep traits on HbA1c and glucose levels and b) to determine genetic correlations across accelerometer-derived and self-reported sleep traits.

MethodsWe used MR methods to explore effects of accelerometer-derived sleep traits (duration, mid-point least active 5-hours, mid-point most active 10-hours, sleep fragmentation, and efficiency) on HbA1c in European adults from the UK Biobank (UKB) (n = 73,797) and the MAGIC consortium (n = 149,054). Cross-trait linkage disequilibrium score regression was also applied to determine genetic correlations across all accelerometer-derived and self-reported sleep traits and HbA1c/glucose.

ResultsMain and sensitivity MR analyses showed no causal effect of any accelerometer-derived sleep trait on HbA1c or glucose. Similar MR results for self-reported sleep traits in the UKB sub-sample with accelerometer-derived measures suggested our results were not explained by selection bias. Genetic correlation analyses suggested complex relationships between self-reported and accelerometer-derived traits indicating that they may reflect different types of exposure.

ConclusionsTaken together, these findings suggested accelerometer-derived sleep traits do not causally affect HbA1c levels, and accelerometer-derived measures of sleep duration and sleep quality might not simply be  objective measures of self-reported sleep duration and insomnia, but rather captured different underlying sleep characteristics.

Statement of SignificanceSelf-reported and accelerometer-derived sleep disturbance is associated with increased risk of hyperglycaemia and type 2 diabetes in observational analyses. Mendelian randomization (MR) studies support an effect of self-reported insomnia, but not other self-reported sleep traits, on glycated haemoglobin (HbA1c). This MR study showed little evidence supporting an effect of any accelerometer-derived sleep trait on HbA1c or glucose, but a potential non-linear (e.g., U-shaped) effect cannot be ruled out. The genetic correlation suggested complex relationships between self-reported and accelerometer-derived traits indicating that they may reflect different exposures.",0
"Mo, J.; He, B.; Wong, T.; Liang, Y.; Luo, S.; Lo, K.; Louie, J.; Au Yeung, S. L.",2023,Evaluating the role of amino acids in type 2 diabetes risk: a Mendelian randomization study,Epidemiology,Evaluating the role of amino acids in type 2 diabetes risk: a Mendelian randomization study,"Mo, J.; He, B.; Wong, T.; Liang, Y.; Luo, S.; Lo, K.; Louie, J.; Au Yeung, S. L.",Epidemiology,2023-08-28 00:00:00 UTC,"BackgroundPrevious observational and Mendelian randomization studies suggested different amino acids associated with type 2 diabetes (T2D). However, these studies may suffer from confounding or the use of invalid instruments, respectively.

MethodsWe extracted strong (p < 5x10-8), independent (r2 < 0.001) genetic variants associated with nine amino acids (alanine, glutamine, glycine, histidine, phenylalanine, tyrosine, isoleucine, leucine, and valine) from summary statistics of UK Biobank (N [&le;] 115,075), with exclusion of potentially pleiotropic variants. We then applied them to T2D summary statistics from DIAMANTE Consortium (without UK Biobank participants) (N = 455,313) and FinnGen study (N = 365,950), and glycemic traits (MAGIC consortium, N [&le;] 209,605). Inverse variance weighed (IVW) method was the main analysis, with multiple sensitivity analyses to assess robustness of findings.

ResultsAlanine was associated with higher T2D risk, correcting for multiple testing (Odds Ratio (OR) 1.50 per SD; 95% CI 1.16 to 1.95). At nominal significance, isoleucine was associated with higher T2D risk (OR 1.13; 95% CI 1.00 to 1.27) and tyrosine was associated with lower T2D risk (OR 0.89; 95% CI 0.80 to 0.99). Alanine was also associated with lower insulin, higher glycated hemoglobin and glucose whereas isoleucine and leucine were associated with lower insulin. These associations were consistent in most sensitivity analyses.

ConclusionAlaine likely contributed to higher T2D risk whilst the associations for isoleucine and tyrosine requires further verification. Whether these findings explain health effects of sources of amino acids, such as diet, should be further explored.",10.1101/2023.08.27.23294702,virology-generative-AI.xlsx,"Evaluating the role of amino acids in type 2 diabetes risk: a Mendelian randomization study BackgroundPrevious observational and Mendelian randomization studies suggested different amino acids associated with type 2 diabetes (T2D). However, these studies may suffer from confounding or the use of invalid instruments, respectively.

MethodsWe extracted strong (p < 5x10-8), independent (r2 < 0.001) genetic variants associated with nine amino acids (alanine, glutamine, glycine, histidine, phenylalanine, tyrosine, isoleucine, leucine, and valine) from summary statistics of UK Biobank (N [&le;] 115,075), with exclusion of potentially pleiotropic variants. We then applied them to T2D summary statistics from DIAMANTE Consortium (without UK Biobank participants) (N = 455,313) and FinnGen study (N = 365,950), and glycemic traits (MAGIC consortium, N [&le;] 209,605). Inverse variance weighed (IVW) method was the main analysis, with multiple sensitivity analyses to assess robustness of findings.

ResultsAlanine was associated with higher T2D risk, correcting for multiple testing (Odds Ratio (OR) 1.50 per SD; 95% CI 1.16 to 1.95). At nominal significance, isoleucine was associated with higher T2D risk (OR 1.13; 95% CI 1.00 to 1.27) and tyrosine was associated with lower T2D risk (OR 0.89; 95% CI 0.80 to 0.99). Alanine was also associated with lower insulin, higher glycated hemoglobin and glucose whereas isoleucine and leucine were associated with lower insulin. These associations were consistent in most sensitivity analyses.

ConclusionAlaine likely contributed to higher T2D risk whilst the associations for isoleucine and tyrosine requires further verification. Whether these findings explain health effects of sources of amino acids, such as diet, should be further explored.",0
"Haley, B. M.; Sun, Y.; Jagai, J. S.; Leibler, J. H.; Fulweiler, R.; Ashmore, J.; Wellenius, G. A.; Heiger-Bernays, W.",2023,"Association between combined sewer overflow events and gastrointestinal illness in Massachusetts municipalities with and without river-sourced drinking water, 2014-2019",Epidemiology,"Association between combined sewer overflow events and gastrointestinal illness in Massachusetts municipalities with and without river-sourced drinking water, 2014-2019","Haley, B. M.; Sun, Y.; Jagai, J. S.; Leibler, J. H.; Fulweiler, R.; Ashmore, J.; Wellenius, G. A.; Heiger-Bernays, W.",Epidemiology,2023-10-26 00:00:00 UTC,"BackgroundCombined sewer overflow (CSO) events release untreated wastewater into surface waterbodies during heavy precipitation or snowmelt. Combined sewer systems serve approximately 40 million people in the United States, primarily in urban and suburban municipalities in the Midwest and Northeast. Predicted increases in heavy precipitation events driven by climate change underscore the importance of quantifying potential health risks associated with CSO events.

ObjectivesThe aims of this study were: to 1) estimate the association between CSO events (2014-2019) and emergency department (ED) visits for acute gastrointestinal illness (AGI) among Massachusetts municipalities that border a CSO-impacted river, and 2) determine if associations differ by municipal drinking water source.

MethodsA case time series design was used to estimate the association between daily cumulative upstream CSO discharge in the prior four days and ED visits for AGI, adjusting for temporal trends, temperature, and precipitation. Associations between CSO events and AGI were also compared by municipal drinking water source (CSO-impacted river vs. other sources).

ResultsExtreme upstream CSO discharge events (>95th percentile by cumulative volume) were associated with a cumulative risk ratio (CRR) of AGI of 1.22 (95% CI: 1.05, 1.42) over the next four days for all municipalities, and the association was robust after adjusting for precipitation (1.17 [0.98, 1.39]). In municipalities with CSO-impacted drinking water sources, the adjusted association was somewhat less pronounced following 95th percentile CSO events (1.05 [0.82, 1.33]). The adjusted CRR of AGI was 1.62 in all municipalities following 99th percentile CSO events (95% CI: 1.04, 2.51) and not meaningfully different across strata defined by drinking water source.

DiscussionIn municipalities bordering a CSO-impacted river in Massachusetts, extreme CSO events are associated with higher risk of AGI within four days. The largest CSO events are associated with increased risk of AGI regardless of drinking water source.",10.1101/2023.10.25.23297573,virology-generative-AI.xlsx,"Association between combined sewer overflow events and gastrointestinal illness in Massachusetts municipalities with and without river-sourced drinking water, 2014-2019 BackgroundCombined sewer overflow (CSO) events release untreated wastewater into surface waterbodies during heavy precipitation or snowmelt. Combined sewer systems serve approximately 40 million people in the United States, primarily in urban and suburban municipalities in the Midwest and Northeast. Predicted increases in heavy precipitation events driven by climate change underscore the importance of quantifying potential health risks associated with CSO events.

ObjectivesThe aims of this study were: to 1) estimate the association between CSO events (2014-2019) and emergency department (ED) visits for acute gastrointestinal illness (AGI) among Massachusetts municipalities that border a CSO-impacted river, and 2) determine if associations differ by municipal drinking water source.

MethodsA case time series design was used to estimate the association between daily cumulative upstream CSO discharge in the prior four days and ED visits for AGI, adjusting for temporal trends, temperature, and precipitation. Associations between CSO events and AGI were also compared by municipal drinking water source (CSO-impacted river vs. other sources).

ResultsExtreme upstream CSO discharge events (>95th percentile by cumulative volume) were associated with a cumulative risk ratio (CRR) of AGI of 1.22 (95% CI: 1.05, 1.42) over the next four days for all municipalities, and the association was robust after adjusting for precipitation (1.17 [0.98, 1.39]). In municipalities with CSO-impacted drinking water sources, the adjusted association was somewhat less pronounced following 95th percentile CSO events (1.05 [0.82, 1.33]). The adjusted CRR of AGI was 1.62 in all municipalities following 99th percentile CSO events (95% CI: 1.04, 2.51) and not meaningfully different across strata defined by drinking water source.

DiscussionIn municipalities bordering a CSO-impacted river in Massachusetts, extreme CSO events are associated with higher risk of AGI within four days. The largest CSO events are associated with increased risk of AGI regardless of drinking water source.",0
"Hegde, S.; Eisenberg, J. N.; Beesley, L. J.; Mukherjee, B.",2024,A two-step penalization and shrinkage approach for binary response data that is jointly separated and correlated: The effects of social networks on diarrheal disease,Epidemiology,A two-step penalization and shrinkage approach for binary response data that is jointly separated and correlated: The effects of social networks on diarrheal disease,"Hegde, S.; Eisenberg, J. N.; Beesley, L. J.; Mukherjee, B.",Epidemiology,2024-03-18 00:00:00 UTC,"Epidemiologic data often violate common modeling assumptions of independence between subjects due to study design. Statistical separation is also common, particularly in the study of rare binary outcomes. Statistical separation for binary outcomes occurs when regions of the covariate space have no variation in the outcome, and separation can negatively impact the validity of logistic regression model parameters. When data are correlated, we generally use multi-level modeling for parameter estimation, and statistical approached have also been developed for handling statistical separation. Approaches for analyzing data with both separation and complex correlation, however, are not well-known. Extending prior work, we demonstrate a two-stage Bayesian modeling approach to account for both separated and highly correlated data through a motivating example examining the effect of social ties on Acute Gastrointestinal Illness (AGI) in rural Ecuador. The two-stage approach involves fitting a Bayesian hierarchical model to account for correlation using priors derived from parameter estimates from a Firth-corrected logistic regression model to account for separation. We compare estimates from the two-stage approach to standard regression methods that only account for either separation or correlation. Our results demonstrate that correctly accounting for separation and correlation when both are present can potentially provide better inference.",10.1101/2024.03.13.24304191,virology-generative-AI.xlsx,"A two-step penalization and shrinkage approach for binary response data that is jointly separated and correlated: The effects of social networks on diarrheal disease Epidemiologic data often violate common modeling assumptions of independence between subjects due to study design. Statistical separation is also common, particularly in the study of rare binary outcomes. Statistical separation for binary outcomes occurs when regions of the covariate space have no variation in the outcome, and separation can negatively impact the validity of logistic regression model parameters. When data are correlated, we generally use multi-level modeling for parameter estimation, and statistical approached have also been developed for handling statistical separation. Approaches for analyzing data with both separation and complex correlation, however, are not well-known. Extending prior work, we demonstrate a two-stage Bayesian modeling approach to account for both separated and highly correlated data through a motivating example examining the effect of social ties on Acute Gastrointestinal Illness (AGI) in rural Ecuador. The two-stage approach involves fitting a Bayesian hierarchical model to account for correlation using priors derived from parameter estimates from a Firth-corrected logistic regression model to account for separation. We compare estimates from the two-stage approach to standard regression methods that only account for either separation or correlation. Our results demonstrate that correctly accounting for separation and correlation when both are present can potentially provide better inference.",0
"Kopotsa, K.; Mbelle, N. M.; Osei Sekyere, J.",2020,"Epigenomics, Genomics, Resistome, Mobilome, Virulome and Evolutionary Phylogenomics of Carbapenem-resistant Klebsiella pneumoniae clinical strains",Epidemiology,"Epigenomics, Genomics, Resistome, Mobilome, Virulome and Evolutionary Phylogenomics of Carbapenem-resistant Klebsiella pneumoniae clinical strains","Kopotsa, K.; Mbelle, N. M.; Osei Sekyere, J.",Epidemiology,2020-06-23 00:00:00 UTC,"BackgroundCarbapenem-resistant Klebsiella pneumoniae (CRKP) remains a major clinical pathogen and public health threat with few therapeutic options. The mobilome, resistome, methylome, virulome and phylogeography of CRKP were characterised.

MethodsCRKP collected in 2018 were subjected to antimicrobial susceptibility testing, screening by multiplex-PCR, genotyping by Repetitive Element Palindromic-Polymerase Chain Reaction (REP-PCR), plasmid size, number, incompatibility, and mobility analyses, and PacBios SMRT sequencing (n=6).

Results & conclusionThere were 56 multidrug-resistant CRKP, having blaOXA-48-like and blaNDM-1/7 carbapenemases on self-transmissible IncF, A/C, IncL/M and IncX3 plasmids endowed with prophages, traT, resistance islands and type I and II restriction modification systems (RMS). These plasmids were of close evolutionary relationship to several plasmids globally whilst the strains also clustered with several global clades, evincing transboundary horizontal and vertical dissemination. Reduced susceptibility to colistin occurred in 23 strains. Common clones included ST307, ST607, ST17, ST39, and ST3559. IncFIIk virulent plasmid replicon was present in 56 strains. The six strains contained at least 41 virulence genes and four different K- and O-loci types: KL2, KL25, KL27, KL102, O1, O2, O4 and O5. Types I, II, and III RMS, conferring m6A (GATC, GATGNNNNNNTTG, CAANNNNNNCATC motifs) and m4C (CCWGG) modifications on chromosomes and plasmids, were found.

There is plasmid-mediated, clonal, and multiclonal dissemination of blaOXA-48-like and blaNDM-1 in South Africa, mirroring international epidemiology of similar clones and plasmids. Plasmid-mediated transmission of RMS, virulome and prophages influence bacterial evolution, epidemiology, pathogenicity, and resistance, threatening infection treatment. RMS influence on antimicrobial and bacteriophage therapy needs urgent investigation.

Highlights/ImportanceK. pneumoniae is a major pathogen implicated in numerous nosocomial infections. Worryingly, we show that K. pneumoniae isolates from South Africa, Africa and globally are endowed with rich resistomes and mobilomes that make them almost pandrug resistant. The isolates in this study contained rich virulomes and prophages on both chromosomes and plasmids, with close evolutionary kith or kin to other plasmids identified worldwide. There was a rich diversity of restriction modification systems that regulate virulence, transcription, and plasmid mobility in bacteria, facilitating the epidemiology, resistance, pathogenicity and genomic evolution of the strains, and threatening antimicrobial and bacteriophage therapy.",10.1101/2020.06.20.20135632,virology-graph-neural-network.xlsx,"Epigenomics, Genomics, Resistome, Mobilome, Virulome and Evolutionary Phylogenomics of Carbapenem-resistant Klebsiella pneumoniae clinical strains BackgroundCarbapenem-resistant Klebsiella pneumoniae (CRKP) remains a major clinical pathogen and public health threat with few therapeutic options. The mobilome, resistome, methylome, virulome and phylogeography of CRKP were characterised.

MethodsCRKP collected in 2018 were subjected to antimicrobial susceptibility testing, screening by multiplex-PCR, genotyping by Repetitive Element Palindromic-Polymerase Chain Reaction (REP-PCR), plasmid size, number, incompatibility, and mobility analyses, and PacBios SMRT sequencing (n=6).

Results & conclusionThere were 56 multidrug-resistant CRKP, having blaOXA-48-like and blaNDM-1/7 carbapenemases on self-transmissible IncF, A/C, IncL/M and IncX3 plasmids endowed with prophages, traT, resistance islands and type I and II restriction modification systems (RMS). These plasmids were of close evolutionary relationship to several plasmids globally whilst the strains also clustered with several global clades, evincing transboundary horizontal and vertical dissemination. Reduced susceptibility to colistin occurred in 23 strains. Common clones included ST307, ST607, ST17, ST39, and ST3559. IncFIIk virulent plasmid replicon was present in 56 strains. The six strains contained at least 41 virulence genes and four different K- and O-loci types: KL2, KL25, KL27, KL102, O1, O2, O4 and O5. Types I, II, and III RMS, conferring m6A (GATC, GATGNNNNNNTTG, CAANNNNNNCATC motifs) and m4C (CCWGG) modifications on chromosomes and plasmids, were found.

There is plasmid-mediated, clonal, and multiclonal dissemination of blaOXA-48-like and blaNDM-1 in South Africa, mirroring international epidemiology of similar clones and plasmids. Plasmid-mediated transmission of RMS, virulome and prophages influence bacterial evolution, epidemiology, pathogenicity, and resistance, threatening infection treatment. RMS influence on antimicrobial and bacteriophage therapy needs urgent investigation.

Highlights/ImportanceK. pneumoniae is a major pathogen implicated in numerous nosocomial infections. Worryingly, we show that K. pneumoniae isolates from South Africa, Africa and globally are endowed with rich resistomes and mobilomes that make them almost pandrug resistant. The isolates in this study contained rich virulomes and prophages on both chromosomes and plasmids, with close evolutionary kith or kin to other plasmids identified worldwide. There was a rich diversity of restriction modification systems that regulate virulence, transcription, and plasmid mobility in bacteria, facilitating the epidemiology, resistance, pathogenicity and genomic evolution of the strains, and threatening antimicrobial and bacteriophage therapy.",1
"Martin-Gonzalez, P.; Crispin-Ortuzar, M.; Markowetz, F.",2021,Predictive modelling of highly multiplexed tumour tissue images by graph neural networks,Pathology,Predictive modelling of highly multiplexed tumour tissue images by graph neural networks,"Martin-Gonzalez, P.; Crispin-Ortuzar, M.; Markowetz, F.",Pathology,2021-07-30 00:00:00 UTC,"The progression and treatment response of cancer largely depends on the complex tissue structure that surrounds cancer cells in a tumour, known as the tumour microenvironment (TME). Recent technical advances have led to the development of highly multiplexed imaging techniques such as Imaging Mass Cytometry (IMC), which capture the complexity of the TME by producing spatial tissue maps of dozens of proteins. Combining these multidimensional cell phenotypes with their spatial organization to predict clinically relevant information is a challenging computational task and so far no method has addressed it directly. Here, we propose and evaluate MULTIPLAI, a novel framework to predict clinical biomarkers from IMC data. The method relies on attention-based graph neural networks (GNNs) that integrate both the phenotypic and spatial dimensions of IMC images. In this proof-of- concept study we used MULTIPLAI to predict oestrogen receptor (ER) status, a key clinical variable for breast cancer patients. We trained different architectures of our framework on 240 samples and benchmarked against graph learning via graph kernels. Propagation Attribute graph kernels achieved a class-balanced accuracy of 66.18% in the development set (N=104) while GNNs achieved a class-balanced accuracy of 90.00% on the same set when using the best combination of graph convolution and pooling layers. We further validated this architecture in internal (N=112) and external test sets from different institutions (N=281 and N=350), demonstrating the generalizability of the method. Our results suggest that MULTIPLAI captures important TME features with clinical importance. This is the first application of GNNs to this type of data and opens up new opportunities for predictive modelling of highly multiplexed images.",10.1101/2021.07.28.21261179,virology-graph-neural-network.xlsx,"Predictive modelling of highly multiplexed tumour tissue images by graph neural networks The progression and treatment response of cancer largely depends on the complex tissue structure that surrounds cancer cells in a tumour, known as the tumour microenvironment (TME). Recent technical advances have led to the development of highly multiplexed imaging techniques such as Imaging Mass Cytometry (IMC), which capture the complexity of the TME by producing spatial tissue maps of dozens of proteins. Combining these multidimensional cell phenotypes with their spatial organization to predict clinically relevant information is a challenging computational task and so far no method has addressed it directly. Here, we propose and evaluate MULTIPLAI, a novel framework to predict clinical biomarkers from IMC data. The method relies on attention-based graph neural networks (GNNs) that integrate both the phenotypic and spatial dimensions of IMC images. In this proof-of- concept study we used MULTIPLAI to predict oestrogen receptor (ER) status, a key clinical variable for breast cancer patients. We trained different architectures of our framework on 240 samples and benchmarked against graph learning via graph kernels. Propagation Attribute graph kernels achieved a class-balanced accuracy of 66.18% in the development set (N=104) while GNNs achieved a class-balanced accuracy of 90.00% on the same set when using the best combination of graph convolution and pooling layers. We further validated this architecture in internal (N=112) and external test sets from different institutions (N=281 and N=350), demonstrating the generalizability of the method. Our results suggest that MULTIPLAI captures important TME features with clinical importance. This is the first application of GNNs to this type of data and opens up new opportunities for predictive modelling of highly multiplexed images.",0
"Graham, S.; Minhas, F.; Bilal, M.; Ali, M.; Tsang, Y. W.; Eastwood, M.; Wahab, N.; Jahanifar, M.; Hero, E.; Dodd, K.; Sahota, H.; Wu, S.; Lu, W.; Azam, A.; Benes, K.; Nimir, M.; Hewitt, K.; Bhalerao, A.; Robinson, A.; Eldaly, H.; E Ahmed Raza, S.; Gopalakrishnan, K.; Snead, D.; Rajpoot, N.",2022,Screening of normal endoscopic large bowel biopsies with artificial intelligence: a retrospective study,Pathology,Screening of normal endoscopic large bowel biopsies with artificial intelligence: a retrospective study,"Graham, S.; Minhas, F.; Bilal, M.; Ali, M.; Tsang, Y. W.; Eastwood, M.; Wahab, N.; Jahanifar, M.; Hero, E.; Dodd, K.; Sahota, H.; Wu, S.; Lu, W.; Azam, A.; Benes, K.; Nimir, M.; Hewitt, K.; Bhalerao, A.; Robinson, A.; Eldaly, H.; E Ahmed Raza, S.; Gopalakrishnan, K.; Snead, D.; Rajpoot, N.",Pathology,2022-10-24 00:00:00 UTC,"ObjectivesDevelop an interpretable AI algorithm to rule out normal large bowel endoscopic biopsies saving pathologist resources.

DesignRetrospective study.

SettingOne UK NHS site was used for model training and internal validation. External validation conducted on data from two other NHS sites and one site in Portugal.

Participants6,591 whole-slides images of endoscopic large bowel biopsies from 3,291 patients (54% Female, 46% Male).

Main outcome measuresArea under the receiver operating characteristic and precision recall curves (AUC-ROC and AUC-PR), measuring agreement between consensus pathologist diagnosis and AI generated classification of normal versus abnormal biopsies.

ResultsA graph neural network was developed incorporating pathologist domain knowledge to classify the biopsies as normal or abnormal using clinically driven interpretable features. Model training and internal validation were performed on 5,054 whole slide images of 2,080 patients from a single NHS site resulting in an AUC-ROC of 0.98 (SD=0.004) and AUC-PR of 0.98 (SD=0.003). The predictive performance of the model was consistent in testing over 1,537 whole slide images of 1,211 patients from three independent external datasets with mean AUC-ROC = 0.97 (SD=0.007) and AUC-PR = 0.97 (SD=0.005). Our analysis shows that at a high sensitivity threshold of 99%, the proposed model can, on average, reduce the number of normal slides to be reviewed by a pathologist by 55%. A key advantage of IGUANA is its ability to provide an explainable output highlighting potential abnormalities in a whole slide image as a heatmap overlay in addition to numerical values associating model prediction with various histological features. Example results with can be viewed online at https://iguana.dcs.warwick.ac.uk/.

ConclusionsAn interpretable AI model was developed to screen abnormal cases for review by pathologists. The model achieved consistently high predictive accuracy on independent cohorts showing its potential in optimising increasingly scarce pathologist resources and for achieving faster time to diagnosis. Explainable predictions of IGUANA can guide pathologists in their diagnostic decision making and help boost their confidence in the algorithm, paving the way for future clinical adoption.

What is already known on this topicO_LIIncreasing screening rates for early detection of colon cancer are placing significant pressure on already understaffed and overloaded histopathology resources worldwide and especially in the United Kingdom1.
C_LIO_LIApproximately a third of endoscopic colon biopsies are reported as normal and therefore require minimal intervention, yet the biopsy results can take up to 2-3 weeks2.
C_LIO_LIAI models hold great promise for reducing the burden of diagnostics for cancer screening but require incorporation of pathologist domain knowledge and explainability.
C_LI

What this study addsO_LIThis study presents the first AI algorithm for rule out of normal from abnormal large bowel endoscopic biopsies with high accuracy across different patient populations.
C_LIO_LIFor colon biopsies predicted as abnormal, the model can highlight diagnostically important biopsy regions and provide a list of clinically meaningful features of those regions such as glandular architecture, inflammatory cell density and spatial relationships between inflammatory cells, glandular structures and the epithelium.
C_LIO_LIThe proposed tool can both screen out normal biopsies and act as a decision support tool for abnormal biopsies, therefore offering a significant reduction in the pathologist workload and faster turnaround times.
C_LI",10.1101/2022.10.17.22279804,virology-graph-neural-network.xlsx,"Screening of normal endoscopic large bowel biopsies with artificial intelligence: a retrospective study ObjectivesDevelop an interpretable AI algorithm to rule out normal large bowel endoscopic biopsies saving pathologist resources.

DesignRetrospective study.

SettingOne UK NHS site was used for model training and internal validation. External validation conducted on data from two other NHS sites and one site in Portugal.

Participants6,591 whole-slides images of endoscopic large bowel biopsies from 3,291 patients (54% Female, 46% Male).

Main outcome measuresArea under the receiver operating characteristic and precision recall curves (AUC-ROC and AUC-PR), measuring agreement between consensus pathologist diagnosis and AI generated classification of normal versus abnormal biopsies.

ResultsA graph neural network was developed incorporating pathologist domain knowledge to classify the biopsies as normal or abnormal using clinically driven interpretable features. Model training and internal validation were performed on 5,054 whole slide images of 2,080 patients from a single NHS site resulting in an AUC-ROC of 0.98 (SD=0.004) and AUC-PR of 0.98 (SD=0.003). The predictive performance of the model was consistent in testing over 1,537 whole slide images of 1,211 patients from three independent external datasets with mean AUC-ROC = 0.97 (SD=0.007) and AUC-PR = 0.97 (SD=0.005). Our analysis shows that at a high sensitivity threshold of 99%, the proposed model can, on average, reduce the number of normal slides to be reviewed by a pathologist by 55%. A key advantage of IGUANA is its ability to provide an explainable output highlighting potential abnormalities in a whole slide image as a heatmap overlay in addition to numerical values associating model prediction with various histological features. Example results with can be viewed online at https://iguana.dcs.warwick.ac.uk/.

ConclusionsAn interpretable AI model was developed to screen abnormal cases for review by pathologists. The model achieved consistently high predictive accuracy on independent cohorts showing its potential in optimising increasingly scarce pathologist resources and for achieving faster time to diagnosis. Explainable predictions of IGUANA can guide pathologists in their diagnostic decision making and help boost their confidence in the algorithm, paving the way for future clinical adoption.

What is already known on this topicO_LIIncreasing screening rates for early detection of colon cancer are placing significant pressure on already understaffed and overloaded histopathology resources worldwide and especially in the United Kingdom1.
C_LIO_LIApproximately a third of endoscopic colon biopsies are reported as normal and therefore require minimal intervention, yet the biopsy results can take up to 2-3 weeks2.
C_LIO_LIAI models hold great promise for reducing the burden of diagnostics for cancer screening but require incorporation of pathologist domain knowledge and explainability.
C_LI

What this study addsO_LIThis study presents the first AI algorithm for rule out of normal from abnormal large bowel endoscopic biopsies with high accuracy across different patient populations.
C_LIO_LIFor colon biopsies predicted as abnormal, the model can highlight diagnostically important biopsy regions and provide a list of clinically meaningful features of those regions such as glandular architecture, inflammatory cell density and spatial relationships between inflammatory cells, glandular structures and the epithelium.
C_LIO_LIThe proposed tool can both screen out normal biopsies and act as a decision support tool for abnormal biopsies, therefore offering a significant reduction in the pathologist workload and faster turnaround times.
C_LI",1
"Song, Q.; Liu, X.; Li, Z.; Zhang, P.; Eadon, M.; Su, J.",2023,DEPOT: graph learning delineates the roles of cancers in the progression trajectories of chronic kidney disease using electronic medical records,Epidemiology,DEPOT: graph learning delineates the roles of cancers in the progression trajectories of chronic kidney disease using electronic medical records,"Song, Q.; Liu, X.; Li, Z.; Zhang, P.; Eadon, M.; Su, J.",Epidemiology,2023-08-16 00:00:00 UTC,"Chronic kidney disease (CKD) is a common, complex, and heterogeneous disease impacting aging populations. Determining the landscape of disease progression trajectories from midlife to senior age in a real-world context allows us to better understand the progression of CKD, the heterogeneity of progression patterns among the risk population, and the interactions with other clinical conditions like cancers. In this study, we use electronic health records (EHRs) to outline the CKD progression trajectory roadmap for the Wake Forest Baptist Medical Center (WFBMC) patient population. We establish an EHR cohort (n = 79,434) with patients health status identified by 18 Essential Clinical Indices across 508,732 clinical encounters. We develop the DisEase PrOgression Trajectory (DEPOT) approach to model CKD progression trajectories and individualize clinical decision support. The DEPOT is an evidence-driven, graph-based clinical informatics approach that addresses the unique challenges in longitudinal EHR data by systematically using the graph artificial intelligence (graph-AI) model for representation learning and reverse graph embedding for trajectory reconstruction. Moreover, DEPOT includes a prediction model to assign new patients along the progression trajectory. We successfully establish the EHR-based CKD progression trajectories with DEPOT in the WFUBMC cohort. We annotate the trajectories with clinical features, including kidney function, age, and other indices, including cancer. This CKD progression trajectory roadmap reveals diverse kidney failure pathways associated with different clinical conditions. Specifically, we have identified one high-risk trajectory and two low-risk trajectories. Switching pathways from low-risk trajectories to the high-risk one is associated with accelerated decline in kidney function. On this roadmap, high-risk patients are enriched in the skin and GU cancers, which differs from low-risk patients, suggesting fundamentally different disease progression mechanisms. Overall, the CKD progression trajectory roadmap reveals novel diverse renal failure pathways in type 2 diabetes mellitus and highlights disease progression patterns associated with cancer phenotypes.",10.1101/2023.08.13.23293968,virology-graph-neural-network.xlsx,"DEPOT: graph learning delineates the roles of cancers in the progression trajectories of chronic kidney disease using electronic medical records Chronic kidney disease (CKD) is a common, complex, and heterogeneous disease impacting aging populations. Determining the landscape of disease progression trajectories from midlife to senior age in a real-world context allows us to better understand the progression of CKD, the heterogeneity of progression patterns among the risk population, and the interactions with other clinical conditions like cancers. In this study, we use electronic health records (EHRs) to outline the CKD progression trajectory roadmap for the Wake Forest Baptist Medical Center (WFBMC) patient population. We establish an EHR cohort (n = 79,434) with patients health status identified by 18 Essential Clinical Indices across 508,732 clinical encounters. We develop the DisEase PrOgression Trajectory (DEPOT) approach to model CKD progression trajectories and individualize clinical decision support. The DEPOT is an evidence-driven, graph-based clinical informatics approach that addresses the unique challenges in longitudinal EHR data by systematically using the graph artificial intelligence (graph-AI) model for representation learning and reverse graph embedding for trajectory reconstruction. Moreover, DEPOT includes a prediction model to assign new patients along the progression trajectory. We successfully establish the EHR-based CKD progression trajectories with DEPOT in the WFUBMC cohort. We annotate the trajectories with clinical features, including kidney function, age, and other indices, including cancer. This CKD progression trajectory roadmap reveals diverse kidney failure pathways associated with different clinical conditions. Specifically, we have identified one high-risk trajectory and two low-risk trajectories. Switching pathways from low-risk trajectories to the high-risk one is associated with accelerated decline in kidney function. On this roadmap, high-risk patients are enriched in the skin and GU cancers, which differs from low-risk patients, suggesting fundamentally different disease progression mechanisms. Overall, the CKD progression trajectory roadmap reveals novel diverse renal failure pathways in type 2 diabetes mellitus and highlights disease progression patterns associated with cancer phenotypes.",0
"Ahn, J.; Won, S.; Park, J.-H.; Shimbo, D.; Lee, H.-Y.",2023,The Medical Impact of Emergent Banning of N-nitrosodimethylamine (NDMA)- contaminated Antihypertensive Drug: A nationwide longitudinal cohort study,Epidemiology,The Medical Impact of Emergent Banning of N-nitrosodimethylamine (NDMA)- contaminated Antihypertensive Drug: A nationwide longitudinal cohort study,"Ahn, J.; Won, S.; Park, J.-H.; Shimbo, D.; Lee, H.-Y.",Epidemiology,2023-11-04 00:00:00 UTC,"OBJECTIVETo study the association of NDMA-contaminated generic valsartan with cancer incidence.

DESIGNNationwide longitudinal observational cohort study.

SETTINGClaims data from the National Health Insurance Service of South Korea was analyzed using 1:1:1 pairwise propensity score matching (PSM) of NDMA-uncontaminated original, NDMA-contaminated generic, and initially-suspended-but-finally confirmed as NDMA-uncontaminated generic valsartan user-groups. Time-dependent Cox models and dose- response evaluation were used to evaluate carcinogenicity.

PARTICIPANTSA total of 3,231,212 participants with satisfactory minimal adherence, followed up from January 1, 2013 until December 31, 2020.

INTERVENTIONSAt least one tablet of valsartan.

MAIN OUTCOME MEASURESThe primary outcome was primary cancer incidence and secondary outcome was 12 prevalent organ-specific cancer incidences. All-cause and cardiovascular mortality risks were estimated before and after valsartan withdrawal.

RESULTSAmong participants (mean [standard deviation] age 59.5 [13.1] years; male, 53.5%), new users had adjusted hazard ratios and 95% confidence intervals (CI) of 1.069 (1.054 to 1.085) and 1.142 (1.100 to 1.186) for any cancer in the NDMA-exposed period (versus NDMA-unexposed) before and after 1:1:1 PSM, respectively. Regardless of PSM, lung and prostate cancer risks increased significantly during the NDMA-exposed period whereas, post-PSM, cancer risk did not increase in the eventually-NDMA-uncontaminated group, even in new users. All-cause and cardiovascular mortality did not differ significantly with NDMA exposure before and after emergent banning.

CONCLUSIONSNDMA-contaminated valsartan increased cancer risk, especially of lung and prostate cancers. All-cause and cardiovascular mortality did not evidently increase following banning. This supports emergent health-policy action against potentially carcinogenic drugs.",10.1101/2023.11.01.23297897,virology-graph-neural-network.xlsx,"The Medical Impact of Emergent Banning of N-nitrosodimethylamine (NDMA)- contaminated Antihypertensive Drug: A nationwide longitudinal cohort study OBJECTIVETo study the association of NDMA-contaminated generic valsartan with cancer incidence.

DESIGNNationwide longitudinal observational cohort study.

SETTINGClaims data from the National Health Insurance Service of South Korea was analyzed using 1:1:1 pairwise propensity score matching (PSM) of NDMA-uncontaminated original, NDMA-contaminated generic, and initially-suspended-but-finally confirmed as NDMA-uncontaminated generic valsartan user-groups. Time-dependent Cox models and dose- response evaluation were used to evaluate carcinogenicity.

PARTICIPANTSA total of 3,231,212 participants with satisfactory minimal adherence, followed up from January 1, 2013 until December 31, 2020.

INTERVENTIONSAt least one tablet of valsartan.

MAIN OUTCOME MEASURESThe primary outcome was primary cancer incidence and secondary outcome was 12 prevalent organ-specific cancer incidences. All-cause and cardiovascular mortality risks were estimated before and after valsartan withdrawal.

RESULTSAmong participants (mean [standard deviation] age 59.5 [13.1] years; male, 53.5%), new users had adjusted hazard ratios and 95% confidence intervals (CI) of 1.069 (1.054 to 1.085) and 1.142 (1.100 to 1.186) for any cancer in the NDMA-exposed period (versus NDMA-unexposed) before and after 1:1:1 PSM, respectively. Regardless of PSM, lung and prostate cancer risks increased significantly during the NDMA-exposed period whereas, post-PSM, cancer risk did not increase in the eventually-NDMA-uncontaminated group, even in new users. All-cause and cardiovascular mortality did not differ significantly with NDMA exposure before and after emergent banning.

CONCLUSIONSNDMA-contaminated valsartan increased cancer risk, especially of lung and prostate cancers. All-cause and cardiovascular mortality did not evidently increase following banning. This supports emergent health-policy action against potentially carcinogenic drugs.",0
"Tang, C. Y.; Woldu, H. G.; Sheets, L. R.",2021,The Paradox of Female Obesity in Low and Lower-Middle Income Countries,Epidemiology,The Paradox of Female Obesity in Low and Lower-Middle Income Countries,"Tang, C. Y.; Woldu, H. G.; Sheets, L. R.",Epidemiology,2021-02-27 00:00:00 UTC,"SettingObesity, once considered an epidemic of the developed world, is now becoming an even more prominent problem than underweight in low and lower middle income countries (LLMICs). Ample literature has shown that as a countrys income increases, the burden of obesity shifts from the rich to the poor. This is known as the ""Reversal Hypothesis."" Many studies have explored the effects of various social determinants of health on obesity, but few have studied education as an independent variable on female obesity across LLMICs.

ObjectiveGlobally, adult females have a higher prevalence of obesity and the obesity shift occurs more quickly for women than for men. We aim to address this disparity and contribute towards the reversal hypothesis by exploring the association of education and obesity in women in LLMICs.

DesignIn this cross-sectional study, we used a multi-national and multi-year database from the publicly available Demographic and Health Surveys program with data from 34 LLMICs. Education levels are standardized across countries during survey collection.

ResultsOur age-adjusted prevalence ratio (AA-PR) analysis shows that women in LLMICs with higher education have a significantly greater prevalence of obesity than women with no education. We analyzed this phenomenon by individual nations, continents, and income classifications. Educated women living in low income countries are 5.12 times more obese than uneducated women (AA-PR, 95% CI=4.75, 5.53) and 3.42 times more obese in lower middle income countries (AA-PR, 95% CI=3.31, 3.54).

ConclusionThese findings highlight a need for more studies and policy attention focusing on female education levels, among other factors, to understand, predict, and prevent obesity in LLMICs.

ARTICLE SUMMARY

Strengths and limitations of this studyO_LIA rigorous sample size of 943,947 adult females in 34 LLMIC countries was utilized to study the association between adult female obesity and education level.
C_LIO_LIAge-adjusted and age-and-wealth-adjusted prevalence ratios of obesity were analyzed based on 34 individual nations, three continents, and two major income categories.
C_LIO_LIThis study includes the most recent data available through the Demographic and Health Surveys program, which standardizes education levels during data collection, allowing for comparison between all surveyed countries.
C_LIO_LIThis study is limited by the relatively small number of countries for which data is available through the DHS dataset, and thus, further research will be needed to show whether these results are generalizable to other LLMICs.
C_LI",10.1101/19003004,virology-llm.xlsx,"The Paradox of Female Obesity in Low and Lower-Middle Income Countries SettingObesity, once considered an epidemic of the developed world, is now becoming an even more prominent problem than underweight in low and lower middle income countries (LLMICs). Ample literature has shown that as a countrys income increases, the burden of obesity shifts from the rich to the poor. This is known as the ""Reversal Hypothesis."" Many studies have explored the effects of various social determinants of health on obesity, but few have studied education as an independent variable on female obesity across LLMICs.

ObjectiveGlobally, adult females have a higher prevalence of obesity and the obesity shift occurs more quickly for women than for men. We aim to address this disparity and contribute towards the reversal hypothesis by exploring the association of education and obesity in women in LLMICs.

DesignIn this cross-sectional study, we used a multi-national and multi-year database from the publicly available Demographic and Health Surveys program with data from 34 LLMICs. Education levels are standardized across countries during survey collection.

ResultsOur age-adjusted prevalence ratio (AA-PR) analysis shows that women in LLMICs with higher education have a significantly greater prevalence of obesity than women with no education. We analyzed this phenomenon by individual nations, continents, and income classifications. Educated women living in low income countries are 5.12 times more obese than uneducated women (AA-PR, 95% CI=4.75, 5.53) and 3.42 times more obese in lower middle income countries (AA-PR, 95% CI=3.31, 3.54).

ConclusionThese findings highlight a need for more studies and policy attention focusing on female education levels, among other factors, to understand, predict, and prevent obesity in LLMICs.

ARTICLE SUMMARY

Strengths and limitations of this studyO_LIA rigorous sample size of 943,947 adult females in 34 LLMIC countries was utilized to study the association between adult female obesity and education level.
C_LIO_LIAge-adjusted and age-and-wealth-adjusted prevalence ratios of obesity were analyzed based on 34 individual nations, three continents, and two major income categories.
C_LIO_LIThis study includes the most recent data available through the Demographic and Health Surveys program, which standardizes education levels during data collection, allowing for comparison between all surveyed countries.
C_LIO_LIThis study is limited by the relatively small number of countries for which data is available through the DHS dataset, and thus, further research will be needed to show whether these results are generalizable to other LLMICs.
C_LI",0
"Zhu, Y.; Teng, Z.; Yang, L.; Xu, S.; Liu, J.; Teng, Y.; Hao, Q.; Zhao, D.; Li, X.; Lu, S.; Zeng, Y.",2020,"Efficacy and Safety of Remdesivir for COVID-19 Treatment: An Analysis of Randomized, Double-Blind, Placebo-Controlled Trials",Epidemiology,"Efficacy and Safety of Remdesivir for COVID-19 Treatment: An Analysis of Randomized, Double-Blind, Placebo-Controlled Trials","Zhu, Y.; Teng, Z.; Yang, L.; Xu, S.; Liu, J.; Teng, Y.; Hao, Q.; Zhao, D.; Li, X.; Lu, S.; Zeng, Y.",Epidemiology,2020-06-29 00:00:00 UTC,"BACKGROUNDRemdesivir, an inhibitor of viral RNA-dependent RNA polymerases, has been identified as a candidate for COVID-19 treatment. However, the therapeutic effect of remdesivir is controversial.

METHODSWe searched PubMed, Embase, and the Cochrane Central Register of Controlled Trials, from inception to June 11, 2020 for randomized controlled trials on the clinical efficacy of remdesivir. The main outcomes were discharge rate, mortality, and adverse events. This study is registered at INPLASY (INPLASY202060046).

RESULTSData of 1075 subjects showed that remdesivir significantly increased the discharge rate of patients with COVID-19 compared with the placebo (50.4% vs. 45.29%; relative risk [RR] 1.19 [95% confidence interval [CI], 1.05-1.34], I2 = 0.0%, P = 0.754). It also significantly decreased mortality (8.18% vs. 12.70%; RR 0.64 [95% CI, 0.44-0.92], I2 = 45.7%, P = 0.175) compared to the placebo. Data of 1296 subjects showed that remdesivir significantly decreased the occurrence of serious adverse events (RR 0.77 [95% CI, 0.63-0.94], I2 = 0.0%, P = 0.716).

CONCLUSIONRemdesivir is efficacious and safe for the treatment of COVID-19.

TRIAL REGISTRATION NUMBERThis study is registered at the International Platform of Registered Systematic Review and Meta-analysis Protocols (INPLASY202060046).",10.1101/2020.06.22.20136531,virology-llm.xlsx,"Efficacy and Safety of Remdesivir for COVID-19 Treatment: An Analysis of Randomized, Double-Blind, Placebo-Controlled Trials BACKGROUNDRemdesivir, an inhibitor of viral RNA-dependent RNA polymerases, has been identified as a candidate for COVID-19 treatment. However, the therapeutic effect of remdesivir is controversial.

METHODSWe searched PubMed, Embase, and the Cochrane Central Register of Controlled Trials, from inception to June 11, 2020 for randomized controlled trials on the clinical efficacy of remdesivir. The main outcomes were discharge rate, mortality, and adverse events. This study is registered at INPLASY (INPLASY202060046).

RESULTSData of 1075 subjects showed that remdesivir significantly increased the discharge rate of patients with COVID-19 compared with the placebo (50.4% vs. 45.29%; relative risk [RR] 1.19 [95% confidence interval [CI], 1.05-1.34], I2 = 0.0%, P = 0.754). It also significantly decreased mortality (8.18% vs. 12.70%; RR 0.64 [95% CI, 0.44-0.92], I2 = 45.7%, P = 0.175) compared to the placebo. Data of 1296 subjects showed that remdesivir significantly decreased the occurrence of serious adverse events (RR 0.77 [95% CI, 0.63-0.94], I2 = 0.0%, P = 0.716).

CONCLUSIONRemdesivir is efficacious and safe for the treatment of COVID-19.

TRIAL REGISTRATION NUMBERThis study is registered at the International Platform of Registered Systematic Review and Meta-analysis Protocols (INPLASY202060046).",1
"Mannan, A.; Mehedi, H. M. H.; Chy, N. H.; Qayum, M. O.; Akter, F.; Rob, A.; Biswas, P.; Hossain, S.; Ayub, M. I.",2020,"A multi-centric, cross-sectional study on COVID-19 in Bangladesh: Clinical epidemiology and short-term outcomes in recovered individuals",Epidemiology,"A multi-centric, cross-sectional study on COVID-19 in Bangladesh: Clinical epidemiology and short-term outcomes in recovered individuals","Mannan, A.; Mehedi, H. M. H.; Chy, N. H.; Qayum, M. O.; Akter, F.; Rob, A.; Biswas, P.; Hossain, S.; Ayub, M. I.",Epidemiology,2020-10-12 00:00:00 UTC,"ObjectivesTo investigate SARS-CoV-2 associated epidemiology and clinical outcomes in Bangladesh to understand the course of COVID-19 pandemic and suggest prevention measures.

MethodsA cross-sectional retrospective study was conducted among 1,021 RT-PCR confirmed but recovered COVID-19 cases from six participating hospitals in Bangladesh.

ResultsOf the total sample, 111 (10.9%) cases were asymptomatic while the number of symptomatic cases were 910 (89.1%). Higher prevalence of COVID-19 persisted in the male population (75%) and for the 31-40 age group. More than 85% of the samples reported BCG vaccination mark. Common symptoms observed in our study samples were fever (72.4%), cough (55.9%), loss of taste (40.7%) and body ache (40%); whereas for the biochemical parameters, Neutrophil (46.4%), D-dimer (46.1%), Ferritin (37.9%) and SGPT (36.8%) levels were found elevated. Post-COVID complications including pain (31.8%), loss of concentration (24.4%) and anxiety or depression (23.1%) were found significantly prevalent.

ConclusionOur study has shown that adult males aged between 31-40 in Bangladesh are more vulnerable to being infected with COVID-19. With an indication for the rising trend of the asymptomatic cases, deployment of interventions to curb further community spread is necessary to avoid the grave outcomes of COVID-19 in Bangladesh.",10.1101/2020.09.09.20191114,virology-llm.xlsx,"A multi-centric, cross-sectional study on COVID-19 in Bangladesh: Clinical epidemiology and short-term outcomes in recovered individuals ObjectivesTo investigate SARS-CoV-2 associated epidemiology and clinical outcomes in Bangladesh to understand the course of COVID-19 pandemic and suggest prevention measures.

MethodsA cross-sectional retrospective study was conducted among 1,021 RT-PCR confirmed but recovered COVID-19 cases from six participating hospitals in Bangladesh.

ResultsOf the total sample, 111 (10.9%) cases were asymptomatic while the number of symptomatic cases were 910 (89.1%). Higher prevalence of COVID-19 persisted in the male population (75%) and for the 31-40 age group. More than 85% of the samples reported BCG vaccination mark. Common symptoms observed in our study samples were fever (72.4%), cough (55.9%), loss of taste (40.7%) and body ache (40%); whereas for the biochemical parameters, Neutrophil (46.4%), D-dimer (46.1%), Ferritin (37.9%) and SGPT (36.8%) levels were found elevated. Post-COVID complications including pain (31.8%), loss of concentration (24.4%) and anxiety or depression (23.1%) were found significantly prevalent.

ConclusionOur study has shown that adult males aged between 31-40 in Bangladesh are more vulnerable to being infected with COVID-19. With an indication for the rising trend of the asymptomatic cases, deployment of interventions to curb further community spread is necessary to avoid the grave outcomes of COVID-19 in Bangladesh.",1
"Jarynowski, A.; Semenov, A.; Kaminski, M.; Belik, V.",2021,Mild Adverse Events of Sputnik V Vaccine Extracted from Russian Language Telegram Posts via BERT Deep Learning Model,Epidemiology,Mild Adverse Events of Sputnik V Vaccine Extracted from Russian Language Telegram Posts via BERT Deep Learning Model,"Jarynowski, A.; Semenov, A.; Kaminski, M.; Belik, V.",Epidemiology,2021-06-22 00:00:00 UTC,"BackgroundThere is a limited amount of data on the COVID-19 vector vaccine Gam-COVID-Vac (Sputnik V) safety profile. Previous infodemiology studies showed that social media discourse could be analyzed to assess the most concerning adverse events (AE) caused by drugs.

ObjectiveWe aimed to investigate mild AEs of Sputnik V based on a participatory trial conducted on Telegram in the Russian language. We compared AEs extracted from Telegram with other limited databases on Sputnik V and other COVID-19 vaccines. We explored symptom co-occurrence patterns and determined how counts of administered doses, age, gender, and sequence of shots could confound the reporting of AEs.

Materials and MethodsWe collected a unique dataset consisting of 11,515 self-reported Sputnik V vaccine AEs posted on the Telegram group, and we utilized natural language processing methods to extract AEs. Specifically, we performed multi-label classifications using the deep neural language model BERT ""DeepPavlov"", which we pre-trained on a Russian language corpus and applied to the Telegram messages. The resulting AUC score was 0.991. We chose symptom classes that represented the following AEs: fever, pain, chills, fatigue, nausea/vomiting, headache, insomnia, lymph node enlargement, erythema, pruritus, swelling, and diarrhea.

ResultsThe results of the retrospective analysis showed that females reported more AEs than males (1.2-fold, P<.001). In addition, there were more AEs from the first dose than from the second dose (1.13-fold, P<.001), and the number of AEs decreased with age ({beta} = .05 per year, P<.001). The results also showed that Sputnik V AEs were more similar to other vector vaccines (132 units) compared with mRNA ones (241 units) according to the average Euclidean distance between the vectors of AE frequencies. Elderly Telegram users reported significantly more (5.6-fold on average) systemic AEs than their peers, according to the results of the phase III clinical trials published in The Lancet. However, the AEs reported in Telegram posts were consistent (Pearson correlation r=.94, P=.02) with those reported in the Argentinian post-marketing AE registry.

ConclusionAfter receiving the Sputnik V vaccination, Telegram users complained about pain (47%), fever (47%), fatigue (34%), and headache (25%). The results showed that the AE profile of Sputnik V was comparable with other COVID-19 vaccines. Examining the sentinel properties of participatory trials (which is subject to self-reporting biases) could still provide meaningful information about pharmaceutics, especially if only a limited amount of information on AEs is provided by producers.",10.1101/2021.06.14.21258875,virology-llm.xlsx,"Mild Adverse Events of Sputnik V Vaccine Extracted from Russian Language Telegram Posts via BERT Deep Learning Model BackgroundThere is a limited amount of data on the COVID-19 vector vaccine Gam-COVID-Vac (Sputnik V) safety profile. Previous infodemiology studies showed that social media discourse could be analyzed to assess the most concerning adverse events (AE) caused by drugs.

ObjectiveWe aimed to investigate mild AEs of Sputnik V based on a participatory trial conducted on Telegram in the Russian language. We compared AEs extracted from Telegram with other limited databases on Sputnik V and other COVID-19 vaccines. We explored symptom co-occurrence patterns and determined how counts of administered doses, age, gender, and sequence of shots could confound the reporting of AEs.

Materials and MethodsWe collected a unique dataset consisting of 11,515 self-reported Sputnik V vaccine AEs posted on the Telegram group, and we utilized natural language processing methods to extract AEs. Specifically, we performed multi-label classifications using the deep neural language model BERT ""DeepPavlov"", which we pre-trained on a Russian language corpus and applied to the Telegram messages. The resulting AUC score was 0.991. We chose symptom classes that represented the following AEs: fever, pain, chills, fatigue, nausea/vomiting, headache, insomnia, lymph node enlargement, erythema, pruritus, swelling, and diarrhea.

ResultsThe results of the retrospective analysis showed that females reported more AEs than males (1.2-fold, P<.001). In addition, there were more AEs from the first dose than from the second dose (1.13-fold, P<.001), and the number of AEs decreased with age ({beta} = .05 per year, P<.001). The results also showed that Sputnik V AEs were more similar to other vector vaccines (132 units) compared with mRNA ones (241 units) according to the average Euclidean distance between the vectors of AE frequencies. Elderly Telegram users reported significantly more (5.6-fold on average) systemic AEs than their peers, according to the results of the phase III clinical trials published in The Lancet. However, the AEs reported in Telegram posts were consistent (Pearson correlation r=.94, P=.02) with those reported in the Argentinian post-marketing AE registry.

ConclusionAfter receiving the Sputnik V vaccination, Telegram users complained about pain (47%), fever (47%), fatigue (34%), and headache (25%). The results showed that the AE profile of Sputnik V was comparable with other COVID-19 vaccines. Examining the sentinel properties of participatory trials (which is subject to self-reporting biases) could still provide meaningful information about pharmaceutics, especially if only a limited amount of information on AEs is provided by producers.",1
"Van Ijzendoorn, D. G. P.; Habets, P. C.; Vinkers, C. H.; Otte, W. M.",2022,"Clinical study type classification, validation, and PubMed filter comparison with natural language processing and active learning",Epidemiology,"Clinical study type classification, validation, and PubMed filter comparison with natural language processing and active learning","Van Ijzendoorn, D. G. P.; Habets, P. C.; Vinkers, C. H.; Otte, W. M.",Epidemiology,2022-11-03 00:00:00 UTC,"Each day, many thousands of new studies are published. Identifying specific study types with high sensitivity and specificity may improve searchability and accelerate updating systematic reviews and meta-analyses. Machine learning transformer models could facilitate this identification process if sufficient training data is available.

We used an active learning strategy to construct a large training set (n=50,000) and fine-tuned the PubMedBERT language model to classify PubMed abstracts as randomized controlled trials, human studies, systematic reviews with and without meta-analyses, protocols, and rodent studies. In an external dataset (n=5,000), the average sensitivity and specificity across study types were 0.94 and 0.96, respectively. PubMeds internal filters had a low sensitivity for both systematic reviews with meta-analysis (0.175, CI: 0.057-0.293) and randomized controlled trials (0.256, CI: 0.119-0.393). We applied this labeling to all 34 million PubMed abstracts currently available and provide the results within an online meta-information platform (EvidenceHunt).

In conclusion, we show that study type classification in PubMed is opportune, given the available language models. The high accuracy in this study invites extending these models to more elaborate and hierarchical identification schemes.",10.1101/2022.11.01.22281685,virology-llm.xlsx,"Clinical study type classification, validation, and PubMed filter comparison with natural language processing and active learning Each day, many thousands of new studies are published. Identifying specific study types with high sensitivity and specificity may improve searchability and accelerate updating systematic reviews and meta-analyses. Machine learning transformer models could facilitate this identification process if sufficient training data is available.

We used an active learning strategy to construct a large training set (n=50,000) and fine-tuned the PubMedBERT language model to classify PubMed abstracts as randomized controlled trials, human studies, systematic reviews with and without meta-analyses, protocols, and rodent studies. In an external dataset (n=5,000), the average sensitivity and specificity across study types were 0.94 and 0.96, respectively. PubMeds internal filters had a low sensitivity for both systematic reviews with meta-analysis (0.175, CI: 0.057-0.293) and randomized controlled trials (0.256, CI: 0.119-0.393). We applied this labeling to all 34 million PubMed abstracts currently available and provide the results within an online meta-information platform (EvidenceHunt).

In conclusion, we show that study type classification in PubMed is opportune, given the available language models. The high accuracy in this study invites extending these models to more elaborate and hierarchical identification schemes.",0
"Sanmarchi, F.; Golinelli, D.; Bucci, A.",2023,A step-by-step Researcher's Guide to the use of an AI-based transformer in epidemiology: an exploratory analysis of ChatGPT using the STROBE checklist for observational studies,Epidemiology,A step-by-step Researcher's Guide to the use of an AI-based transformer in epidemiology: an exploratory analysis of ChatGPT using the STROBE checklist for observational studies,"Sanmarchi, F.; Golinelli, D.; Bucci, A.",Epidemiology,2023-02-08 00:00:00 UTC,"ObjectivesThis study aims at investigating how early-stage AI-based transformers can support researchers in designing and conducting an epidemiological study. To accomplish this, we used ChatGPT to reformulate the STROBE recommendations into a list of questions to be answered by the transformer itself. We then qualitatively evaluated the coherence and relevance of the transformers outputs.

Study designDescriptive study.

MethodsWe first chose a study to be used as a basis for the simulation. We then used ChatGPT to transform each STROBE checklists item into specific prompts. Each answer to the respective prompt was evaluated by independent researchers in terms of coherence and relevance.

ResultsThe mean scores assigned to each prompt were heterogeneous. On average, for the coherence domain, the overall mean score was 3.6 out of 5.0, and for relevance it was 3.3 out of 5.0. The lowest scores were assigned to items belonging to the Methods section of the checklist.

ConclusionsChatGPT can be considered as a valuable support for researchers in conducting an epidemiological study, following internationally recognized guidelines and standards. It is crucial for the users to have knowledge on the subject and a critical mindset when evaluating the outputs. The potential benefits of AI in scientific research and publishing are undeniable, but it is crucial to address the risks, and the ethical and legal consequences associated with its use.",10.1101/2023.02.06.23285514,virology-llm.xlsx,"A step-by-step Researcher's Guide to the use of an AI-based transformer in epidemiology: an exploratory analysis of ChatGPT using the STROBE checklist for observational studies ObjectivesThis study aims at investigating how early-stage AI-based transformers can support researchers in designing and conducting an epidemiological study. To accomplish this, we used ChatGPT to reformulate the STROBE recommendations into a list of questions to be answered by the transformer itself. We then qualitatively evaluated the coherence and relevance of the transformers outputs.

Study designDescriptive study.

MethodsWe first chose a study to be used as a basis for the simulation. We then used ChatGPT to transform each STROBE checklists item into specific prompts. Each answer to the respective prompt was evaluated by independent researchers in terms of coherence and relevance.

ResultsThe mean scores assigned to each prompt were heterogeneous. On average, for the coherence domain, the overall mean score was 3.6 out of 5.0, and for relevance it was 3.3 out of 5.0. The lowest scores were assigned to items belonging to the Methods section of the checklist.

ConclusionsChatGPT can be considered as a valuable support for researchers in conducting an epidemiological study, following internationally recognized guidelines and standards. It is crucial for the users to have knowledge on the subject and a critical mindset when evaluating the outputs. The potential benefits of AI in scientific research and publishing are undeniable, but it is crucial to address the risks, and the ethical and legal consequences associated with its use.",0
"Koga, S.",2023,Exploring the Pitfalls of Large Language Models: Inconsistency and Inaccuracy in Answering Pathology Board Examination-Style Questions,Pathology,Exploring the Pitfalls of Large Language Models: Inconsistency and Inaccuracy in Answering Pathology Board Examination-Style Questions,"Koga, S.",Pathology,2023-08-28 00:00:00 UTC,"In the rapidly advancing field of artificial intelligence, large language models (LLMs) such as ChatGPT and Google Bard are making significant progress, with applications extending across various fields, including medicine. This study explores their potential utility and pitfalls by assessing the performance of these LLMs in answering 150 multiple-choice questions, encompassing 15 subspecialties in pathology, sourced from the PathologyOutlines.com Question Bank, a resource for pathology examination preparation. Overall, ChatGPT outperformed Google Bard, scoring 122 out of 150, while Google Bard achieved a score of 70. Additionally, we explored the consistency of these LLMs by applying a test-retest approach over a two-week interval. ChatGPT showed a consistency rate of 85%, while Google Bard exhibited a consistency rate of 61%. In-depth analysis of incorrect responses identified potential factual inaccuracies and interpretive errors. While LLMs have potential to enhance medical education and assist clinical decision-making, their current limitations underscore the need for continued development and the critical role of human expertise in the application of such models.",10.1101/2023.08.03.23293401,virology-llm.xlsx,"Exploring the Pitfalls of Large Language Models: Inconsistency and Inaccuracy in Answering Pathology Board Examination-Style Questions In the rapidly advancing field of artificial intelligence, large language models (LLMs) such as ChatGPT and Google Bard are making significant progress, with applications extending across various fields, including medicine. This study explores their potential utility and pitfalls by assessing the performance of these LLMs in answering 150 multiple-choice questions, encompassing 15 subspecialties in pathology, sourced from the PathologyOutlines.com Question Bank, a resource for pathology examination preparation. Overall, ChatGPT outperformed Google Bard, scoring 122 out of 150, while Google Bard achieved a score of 70. Additionally, we explored the consistency of these LLMs by applying a test-retest approach over a two-week interval. ChatGPT showed a consistency rate of 85%, while Google Bard exhibited a consistency rate of 61%. In-depth analysis of incorrect responses identified potential factual inaccuracies and interpretive errors. While LLMs have potential to enhance medical education and assist clinical decision-making, their current limitations underscore the need for continued development and the critical role of human expertise in the application of such models.",0
"Cai, X.; Geng, Y.; Du, Y.; Westerman, B.; Wang, D.; Ma, C.; Vallejo, J. J. G.",2025,Utilizing ChatGPT to select literature for meta-analysis shows workload reduction while maintaining a similar recall level as manual curation,Epidemiology,Utilizing ChatGPT to select literature for meta-analysis shows workload reduction while maintaining a similar recall level as manual curation,"Cai, X.; Geng, Y.; Du, Y.; Westerman, B.; Wang, D.; Ma, C.; Vallejo, J. J. G.",Epidemiology,2025-01-09 00:00:00 UTC,"BackgroundLarge language models (LLMs) like ChatGPT showed great potential in aiding medical research. A heavy workload in filtering records is needed during the research process of evidence-based medicine, especially meta-analysis. However, no study tried to use LLMs to help screen records in meta-analysis.

ObjectiveIn this research, we aimed to explore the possibility of incorporating ChatGPT to facilitate the screening step based on the title and abstract of records during meta-analysis.

MethodsTo assess our strategy, we selected three meta-analyses from the literature, together with a glioma meta-analysis embedded in the study, as additional validation. For the automatic selection of records from curated meta-analyses, a four-step strategy called LARS-GPT was developed, consisting of (1) criteria selection and single-prompt (prompt with one criterion) creation, (2) best combination identification, (3) combined-prompt (prompt with one or more criteria) creation, and (4) request sending and answer summary. Recall, workload reduction, precision, and F1 score were calculated to assess the performance of LARS-GPT.

ResultsA variable performance was found between different single-prompts with a mean recall of 0.841. Based on these single-prompts, we were able to find combinations with performance better than the pre-set threshold. Finally, with a best combination of criteria identified, LARS-GPT showed a 39.5% workload reduction on average with a recall greater than 0.9.

ConclusionsWe show here the groundbreaking finding that automatic selection of literature for meta-analysis is possible with ChatGPT. We provide it here as a pipeline, LARS-GPT, which showed a great workload reduction while maintaining a pre-set recall.",10.1101/2023.09.06.23295072,virology-llm.xlsx,"Utilizing ChatGPT to select literature for meta-analysis shows workload reduction while maintaining a similar recall level as manual curation BackgroundLarge language models (LLMs) like ChatGPT showed great potential in aiding medical research. A heavy workload in filtering records is needed during the research process of evidence-based medicine, especially meta-analysis. However, no study tried to use LLMs to help screen records in meta-analysis.

ObjectiveIn this research, we aimed to explore the possibility of incorporating ChatGPT to facilitate the screening step based on the title and abstract of records during meta-analysis.

MethodsTo assess our strategy, we selected three meta-analyses from the literature, together with a glioma meta-analysis embedded in the study, as additional validation. For the automatic selection of records from curated meta-analyses, a four-step strategy called LARS-GPT was developed, consisting of (1) criteria selection and single-prompt (prompt with one criterion) creation, (2) best combination identification, (3) combined-prompt (prompt with one or more criteria) creation, and (4) request sending and answer summary. Recall, workload reduction, precision, and F1 score were calculated to assess the performance of LARS-GPT.

ResultsA variable performance was found between different single-prompts with a mean recall of 0.841. Based on these single-prompts, we were able to find combinations with performance better than the pre-set threshold. Finally, with a best combination of criteria identified, LARS-GPT showed a 39.5% workload reduction on average with a recall greater than 0.9.

ConclusionsWe show here the groundbreaking finding that automatic selection of literature for meta-analysis is possible with ChatGPT. We provide it here as a pipeline, LARS-GPT, which showed a great workload reduction while maintaining a pre-set recall.",0
"Geetha, S. D.; Khan, A.; Khan, A.; Kannadath, B. S.; Vitkovski, T.",2023,Evaluation of ChatGPT's Pathology Knowledge using Board-Style Questions,Pathology,Evaluation of ChatGPT's Pathology Knowledge using Board-Style Questions,"Geetha, S. D.; Khan, A.; Khan, A.; Kannadath, B. S.; Vitkovski, T.",Pathology,2023-10-03 00:00:00 UTC,"ObjectivesChatGPT is an artificial intelligence (AI) chatbot developed by OpenAI. Its extensive knowledge and unique interactive capabilities enable it to be utilized in various innovative ways in the medical field such as writing clinical notes, simplifying radiology reports. Through this study we aim to analyze its pathology knowledge to advocate its role in transforming pathology education.

MethodsAmerican Society for Clinical Pathology (ASCP) Resident Question bank (RQB) 2022 was used to test ChatGPT v4. Practice tests were created in each sub-category and were answered based on the input provided by ChatGPT. Questions that required interpretation of images were excluded. ChatGPTs performance was analyzed and compared with the average peer performance.

ResultsThe overall performance of ChatGPT was 56.98%, lower than that of the average peer performance of 62.81%. ChatGPT performed better on clinical pathology (60.42%) than anatomic pathology (54.94%). Furthermore, its performance was better on easy questions (68.47%) compared to intermediate (52.88%) and difficult questions (37.21%).

ConclusionsChatGPT has the potential to be a valuable resource in pathology education if trained on a larger, specialized medical dataset. Relying on it solely for the purpose of pathology training should be with caution, in its current form.

Key pointsO_LIChatGPT is an AI chatbot, that has gained tremendous popularity in multiple industries, including healthcare. We aim to understand its role in revolutionizing pathology education.
C_LIO_LIWe found that ChatGPTs overall performance in Pathology Practice Tests were lower than that expected from an AI tool, furthermore its performance was subpar compared to pathology residents in training.
C_LIO_LIIn its current form ChatGPT is not a reliable tool for pathology education, but with further refinement and training it has the potential of being a learning asset.
C_LI",10.1101/2023.10.01.23296400,virology-llm.xlsx,"Evaluation of ChatGPT's Pathology Knowledge using Board-Style Questions ObjectivesChatGPT is an artificial intelligence (AI) chatbot developed by OpenAI. Its extensive knowledge and unique interactive capabilities enable it to be utilized in various innovative ways in the medical field such as writing clinical notes, simplifying radiology reports. Through this study we aim to analyze its pathology knowledge to advocate its role in transforming pathology education.

MethodsAmerican Society for Clinical Pathology (ASCP) Resident Question bank (RQB) 2022 was used to test ChatGPT v4. Practice tests were created in each sub-category and were answered based on the input provided by ChatGPT. Questions that required interpretation of images were excluded. ChatGPTs performance was analyzed and compared with the average peer performance.

ResultsThe overall performance of ChatGPT was 56.98%, lower than that of the average peer performance of 62.81%. ChatGPT performed better on clinical pathology (60.42%) than anatomic pathology (54.94%). Furthermore, its performance was better on easy questions (68.47%) compared to intermediate (52.88%) and difficult questions (37.21%).

ConclusionsChatGPT has the potential to be a valuable resource in pathology education if trained on a larger, specialized medical dataset. Relying on it solely for the purpose of pathology training should be with caution, in its current form.

Key pointsO_LIChatGPT is an AI chatbot, that has gained tremendous popularity in multiple industries, including healthcare. We aim to understand its role in revolutionizing pathology education.
C_LIO_LIWe found that ChatGPTs overall performance in Pathology Practice Tests were lower than that expected from an AI tool, furthermore its performance was subpar compared to pathology residents in training.
C_LIO_LIIn its current form ChatGPT is not a reliable tool for pathology education, but with further refinement and training it has the potential of being a learning asset.
C_LI",0
"Gartlehner, G.; Kahwati, L.; Hilscher, R.; Thomas, I.; Kugley, S.; Crotty, K.; Viswanathan, M.; Nussbaumer-Streit, B.; Booth, G.; Erskine, N.; Konet, A.; Chew, R.",2023,Data Extraction for Evidence Synthesis Using a Large Language Model: A Proof-of-Concept Study,Epidemiology,Data Extraction for Evidence Synthesis Using a Large Language Model: A Proof-of-Concept Study,"Gartlehner, G.; Kahwati, L.; Hilscher, R.; Thomas, I.; Kugley, S.; Crotty, K.; Viswanathan, M.; Nussbaumer-Streit, B.; Booth, G.; Erskine, N.; Konet, A.; Chew, R.",Epidemiology,2023-10-03 00:00:00 UTC,"Data extraction is a crucial, yet labor-intensive and error-prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the advent of Large Language Models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof-of-concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English-language, open-access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test-retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors (n=4) were missed data items. Importantly, Claude 2s ease of use was high; it required no technical expertise or training data for effective operation. Based on findings of our proof-of-concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.",10.1101/2023.10.02.23296415,virology-llm.xlsx,"Data Extraction for Evidence Synthesis Using a Large Language Model: A Proof-of-Concept Study Data extraction is a crucial, yet labor-intensive and error-prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the advent of Large Language Models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof-of-concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English-language, open-access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test-retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors (n=4) were missed data items. Importantly, Claude 2s ease of use was high; it required no technical expertise or training data for effective operation. Based on findings of our proof-of-concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.",0
"Pitre, T.; Jassal, T.; Talukdar, J. R.; Shahab, M.; Ling, M.; Zeraatkar, D.",2024,ChatGPT for assessing risk of bias of randomized trials using the RoB 2.0 tool: A methods study,Epidemiology,ChatGPT for assessing risk of bias of randomized trials using the RoB 2.0 tool: A methods study,"Pitre, T.; Jassal, T.; Talukdar, J. R.; Shahab, M.; Ling, M.; Zeraatkar, D.",Epidemiology,2024-01-29 00:00:00 UTC,"BackgroundInternationally accepted standards for systematic reviews necessitate assessment of the risk of bias of primary studies. Assessing risk of bias, however, can be time- and resource-intensive. AI-based solutions may increase efficiency and reduce burden.

ObjectiveTo evaluate the reliability of ChatGPT for performing risk of bias assessments of randomized trials using the revised risk of bias tool for randomized trials (RoB 2.0).

MethodsWe sampled recently published Cochrane systematic reviews of medical interventions (up to October 2023) that included randomized controlled trials and assessed risk of bias using the Cochrane-endorsed revised risk of bias tool for randomized trials (RoB 2.0). From each eligible review, we collected data on the risk of bias assessments for the first three reported outcomes. Using ChatGPT-4, we assessed the risk of bias for the same outcomes using three different prompts: a minimal prompt including limited instructions, a maximal prompt with extensive instructions, and an optimized prompt that was designed to yield the best risk of bias judgements. The agreement between ChatGPTs assessments and those of Cochrane systematic reviewers was quantified using weighted kappa statistics.

ResultsWe included 34 systematic reviews with 157 unique trials. We found the agreement between ChatGPT and systematic review authors for assessment of overall risk of bias to be 0.16 (95% CI: 0.01 to 0.3) for the maximal ChatGPT prompt, 0.17 (95% CI: 0.02 to 0.32) for the optimized prompt, and 0.11 (95% CI: -0.04 to 0.27) for the minimal prompt. For the optimized prompt, agreement ranged between 0.11 (95% CI: -0.11 to 0.33) to 0.29 (95% CI: 0.14 to 0.44) across risk of bias domains, with the lowest agreement for the deviations from the intended intervention domain and the highest agreement for the missing outcome data domain.

ConclusionOur results suggest that ChatGPT and systematic reviewers only have ""slight"" to ""fair"" agreement in risk of bias judgements for randomized trials. ChatGPT is currently unable to reliably assess risk of bias of randomized trials. We advise against using ChatGPT to perform risk of bias assessments. There may be opportunities to use ChatGPT to streamline other aspects of systematic reviews, such as screening of search records or collection of data.",10.1101/2023.11.19.23298727,virology-llm.xlsx,"ChatGPT for assessing risk of bias of randomized trials using the RoB 2.0 tool: A methods study BackgroundInternationally accepted standards for systematic reviews necessitate assessment of the risk of bias of primary studies. Assessing risk of bias, however, can be time- and resource-intensive. AI-based solutions may increase efficiency and reduce burden.

ObjectiveTo evaluate the reliability of ChatGPT for performing risk of bias assessments of randomized trials using the revised risk of bias tool for randomized trials (RoB 2.0).

MethodsWe sampled recently published Cochrane systematic reviews of medical interventions (up to October 2023) that included randomized controlled trials and assessed risk of bias using the Cochrane-endorsed revised risk of bias tool for randomized trials (RoB 2.0). From each eligible review, we collected data on the risk of bias assessments for the first three reported outcomes. Using ChatGPT-4, we assessed the risk of bias for the same outcomes using three different prompts: a minimal prompt including limited instructions, a maximal prompt with extensive instructions, and an optimized prompt that was designed to yield the best risk of bias judgements. The agreement between ChatGPTs assessments and those of Cochrane systematic reviewers was quantified using weighted kappa statistics.

ResultsWe included 34 systematic reviews with 157 unique trials. We found the agreement between ChatGPT and systematic review authors for assessment of overall risk of bias to be 0.16 (95% CI: 0.01 to 0.3) for the maximal ChatGPT prompt, 0.17 (95% CI: 0.02 to 0.32) for the optimized prompt, and 0.11 (95% CI: -0.04 to 0.27) for the minimal prompt. For the optimized prompt, agreement ranged between 0.11 (95% CI: -0.11 to 0.33) to 0.29 (95% CI: 0.14 to 0.44) across risk of bias domains, with the lowest agreement for the deviations from the intended intervention domain and the highest agreement for the missing outcome data domain.

ConclusionOur results suggest that ChatGPT and systematic reviewers only have ""slight"" to ""fair"" agreement in risk of bias judgements for randomized trials. ChatGPT is currently unable to reliably assess risk of bias of randomized trials. We advise against using ChatGPT to perform risk of bias assessments. There may be opportunities to use ChatGPT to streamline other aspects of systematic reviews, such as screening of search records or collection of data.",0
"Tran, V.-T.; Gartlehner, G.; Yaacoub, S.; Boutron, I.; Schwingshackl, L.; Stadelmaier, J.; Sommer, I.; Aboulayeh, F.; Afach, S.; Meerpohl, J.; Ravaud, P.",2023,"Sensitivity, specificity and avoidable workload of using a large language models for title and abstract screening in systematic reviews and meta-analyses",Epidemiology,"Sensitivity, specificity and avoidable workload of using a large language models for title and abstract screening in systematic reviews and meta-analyses","Tran, V.-T.; Gartlehner, G.; Yaacoub, S.; Boutron, I.; Schwingshackl, L.; Stadelmaier, J.; Sommer, I.; Aboulayeh, F.; Afach, S.; Meerpohl, J.; Ravaud, P.",Epidemiology,2023-12-17 00:00:00 UTC,"ImportanceSystematic reviews are time-consuming and are still performed predominately manually by researchers despite the exponential growth of scientific literature.

ObjectiveTo investigate the sensitivity, specificity and estimate the avoidable workload when using an AI-based large language model (LLM) (Generative Pre-trained Transformer [GPT] version 3.5-Turbo from OpenAI) to perform title and abstract screening in systematic reviews.

Data SourcesUnannotated bibliographic databases from five systematic reviews conducted by researchers from Cochrane Austria, Germany and France, all published after January 2022 and hence not in the training data set from GPT 3.5-Turbo.

DesignWe developed a set of prompts for GPT models aimed at mimicking the process of title and abstract screening by human researchers. We compared recommendations from LLM to rule out citations based on title and abstract with decisions from authors, with a systematic reappraisal of all discrepancies between LLM and their original decisions. We used bivariate models for meta-analyses of diagnostic accuracy to estimate pooled estimates of sensitivity and specificity. We performed a simulation to assess the avoidable workload from limiting human screening on title and abstract to citations which were not ""ruled out"" by the LLM in a random sample of 100 systematic reviews published between 01/07/2022 and 31/12/2022. We extrapolated estimates of avoidable workload for health-related systematic reviews assessing therapeutic interventions in humans published per year.

ResultsPerformance of GPT models was tested across 22,666 citations. Pooled estimates of sensitivity and specificity were 97.1% (95%CI 89.6% to 99.2%) and 37.7%, (95%CI 18.4% to 61.9%), respectively. In 2022, we estimated the workload of title and abstract screening for systematic reviews to range from 211,013 to 422,025 person-hours. Limiting human screening to citations which were not ""ruled out"" by GPT models could reduce workload by 65% and save up from 106,268 to 276,053-person work hours (i.e.,66 to 172-person years of work), every year.

Conclusions and RelevanceAI systems based on large language models provide highly sensitive and moderately specific recommendations to rule out citations during title and abstract screening in systematic reviews. Their use to ""triage"" citations before human assessment could reduce the workload of evidence synthesis.",10.1101/2023.12.15.23300018,virology-llm.xlsx,"Sensitivity, specificity and avoidable workload of using a large language models for title and abstract screening in systematic reviews and meta-analyses ImportanceSystematic reviews are time-consuming and are still performed predominately manually by researchers despite the exponential growth of scientific literature.

ObjectiveTo investigate the sensitivity, specificity and estimate the avoidable workload when using an AI-based large language model (LLM) (Generative Pre-trained Transformer [GPT] version 3.5-Turbo from OpenAI) to perform title and abstract screening in systematic reviews.

Data SourcesUnannotated bibliographic databases from five systematic reviews conducted by researchers from Cochrane Austria, Germany and France, all published after January 2022 and hence not in the training data set from GPT 3.5-Turbo.

DesignWe developed a set of prompts for GPT models aimed at mimicking the process of title and abstract screening by human researchers. We compared recommendations from LLM to rule out citations based on title and abstract with decisions from authors, with a systematic reappraisal of all discrepancies between LLM and their original decisions. We used bivariate models for meta-analyses of diagnostic accuracy to estimate pooled estimates of sensitivity and specificity. We performed a simulation to assess the avoidable workload from limiting human screening on title and abstract to citations which were not ""ruled out"" by the LLM in a random sample of 100 systematic reviews published between 01/07/2022 and 31/12/2022. We extrapolated estimates of avoidable workload for health-related systematic reviews assessing therapeutic interventions in humans published per year.

ResultsPerformance of GPT models was tested across 22,666 citations. Pooled estimates of sensitivity and specificity were 97.1% (95%CI 89.6% to 99.2%) and 37.7%, (95%CI 18.4% to 61.9%), respectively. In 2022, we estimated the workload of title and abstract screening for systematic reviews to range from 211,013 to 422,025 person-hours. Limiting human screening to citations which were not ""ruled out"" by GPT models could reduce workload by 65% and save up from 106,268 to 276,053-person work hours (i.e.,66 to 172-person years of work), every year.

Conclusions and RelevanceAI systems based on large language models provide highly sensitive and moderately specific recommendations to rule out citations during title and abstract screening in systematic reviews. Their use to ""triage"" citations before human assessment could reduce the workload of evidence synthesis.",0
"Oami, T.; Okada, Y.; Nakada, T.-A.",2023,Citation screening using large language models for creating clinical practice guidelines: A protocol for a prospective study,Epidemiology,Citation screening using large language models for creating clinical practice guidelines: A protocol for a prospective study,"Oami, T.; Okada, Y.; Nakada, T.-A.",Epidemiology,2023-12-31 00:00:00 UTC,"BackgroundThe development of clinical practice guidelines requires a meticulous literature search and screening process. This study aims to explore the potential of large language models in the development of the Japanese Clinical Practice Guidelines for Management of Sepsis and Septic Shock (J-SSCG), focusing on enhancing literature search quality and reducing the citation screening workload.

MethodsA prospective study will be conducted to compare the efficiency and accuracy of literature citation screening between the conventional method and a novel approach using large language models. We will use the large language model, namely GPT-4, to conduct literature searches for predefined clinical questions. We will objectively measure the time required for citation screening and compare it to the time taken using the conventional method. Following the screening, we will calculate and compare the sensitivity and specificity of the results obtained from the conventional method and the large language models-assisted process. The total time spent using both approaches will also be compared to assess workload reduction.

Trial registrationThis research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000053091].

Conflicts of interestAll authors declare no conflicts of interest to have.

FundingNone",10.1101/2023.12.29.23300652,virology-llm.xlsx,"Citation screening using large language models for creating clinical practice guidelines: A protocol for a prospective study BackgroundThe development of clinical practice guidelines requires a meticulous literature search and screening process. This study aims to explore the potential of large language models in the development of the Japanese Clinical Practice Guidelines for Management of Sepsis and Septic Shock (J-SSCG), focusing on enhancing literature search quality and reducing the citation screening workload.

MethodsA prospective study will be conducted to compare the efficiency and accuracy of literature citation screening between the conventional method and a novel approach using large language models. We will use the large language model, namely GPT-4, to conduct literature searches for predefined clinical questions. We will objectively measure the time required for citation screening and compare it to the time taken using the conventional method. Following the screening, we will calculate and compare the sensitivity and specificity of the results obtained from the conventional method and the large language models-assisted process. The total time spent using both approaches will also be compared to assess workload reduction.

Trial registrationThis research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000053091].

Conflicts of interestAll authors declare no conflicts of interest to have.

FundingNone",0
"Espinosa, L.; Salathe, M.",2024,Use of large language models as a scalable approach to understanding public health discourse,Epidemiology,Use of large language models as a scalable approach to understanding public health discourse,"Espinosa, L.; Salathe, M.",Epidemiology,2024-08-22 00:00:00 UTC,"Online public health discourse is becoming more and more important in shaping public health dynamics. Large Language Models (LLMs) offer a scalable solution for analysing the vast amounts of unstructured text found on online platforms. Here, we explore the effectiveness of Large Language Models (LLMs), including GPT models and open-source alternatives, for extracting public stances towards vaccination from social media posts. Using an expert-annotated dataset of social media posts related to vaccination, we applied various LLMs and a rule-based sentiment analysis tool to classify the stance towards vaccination. We assessed the accuracy of these methods through comparisons with expert annotations and annotations obtained through crowdsourcing. Our results demonstrate that few-shot prompting of best-in-class LLMs are the best performing methods, and that all alternatives have significant risks of substantial misclassification. The study highlights the potential of LLMs as a scalable tool for public health professionals to quickly gauge public opinion on health policies and interventions, offering an efficient alternative to traditional data analysis methods. With the continuous advancement in LLM development, the integration of these models into public health surveillance systems could substantially improve our ability to monitor and respond to changing public health attitudes.

Authors summaryWe examined how Large Language Models (LLMs), including GPT models and open-source versions, can analyse online discussions about vaccination from social media. Using a dataset with expert-checked posts, we tested various LLMs and a sentiment analysis tool to identify public stance towards vaccination. Our findings suggest that using LLMs, and prompting them with labelled examples, is the most effective approach. The results show that LLMs are a valuable resource for public health experts to quickly understand the dynamics of public attitudes towards health policies and interventions, providing a faster and efficient option compared to traditional methods. As LLMs continue to improve, incorporating these models into digital public health monitoring could greatly improve how we observe and react to dynamics in public health discussions.",10.1101/2024.02.06.24302383,virology-llm.xlsx,"Use of large language models as a scalable approach to understanding public health discourse Online public health discourse is becoming more and more important in shaping public health dynamics. Large Language Models (LLMs) offer a scalable solution for analysing the vast amounts of unstructured text found on online platforms. Here, we explore the effectiveness of Large Language Models (LLMs), including GPT models and open-source alternatives, for extracting public stances towards vaccination from social media posts. Using an expert-annotated dataset of social media posts related to vaccination, we applied various LLMs and a rule-based sentiment analysis tool to classify the stance towards vaccination. We assessed the accuracy of these methods through comparisons with expert annotations and annotations obtained through crowdsourcing. Our results demonstrate that few-shot prompting of best-in-class LLMs are the best performing methods, and that all alternatives have significant risks of substantial misclassification. The study highlights the potential of LLMs as a scalable tool for public health professionals to quickly gauge public opinion on health policies and interventions, offering an efficient alternative to traditional data analysis methods. With the continuous advancement in LLM development, the integration of these models into public health surveillance systems could substantially improve our ability to monitor and respond to changing public health attitudes.

Authors summaryWe examined how Large Language Models (LLMs), including GPT models and open-source versions, can analyse online discussions about vaccination from social media. Using a dataset with expert-checked posts, we tested various LLMs and a sentiment analysis tool to identify public stance towards vaccination. Our findings suggest that using LLMs, and prompting them with labelled examples, is the most effective approach. The results show that LLMs are a valuable resource for public health experts to quickly understand the dynamics of public attitudes towards health policies and interventions, providing a faster and efficient option compared to traditional methods. As LLMs continue to improve, incorporating these models into digital public health monitoring could greatly improve how we observe and react to dynamics in public health discussions.",0
"Guastafierro, V.; Corbitt, D. N.; Bressan, A.; Fernandes, B.; Mintemur, O.; Magnoli, F.; Ronchi, S.; La Rosa, S.; Uccella, S.; Renne, S. L.",2024,Evaluation of ChatGPT's Usefulness and Accuracy in Diagnostic Surgical Pathology.,Pathology,Evaluation of ChatGPT's Usefulness and Accuracy in Diagnostic Surgical Pathology.,"Guastafierro, V.; Corbitt, D. N.; Bressan, A.; Fernandes, B.; Mintemur, O.; Magnoli, F.; Ronchi, S.; La Rosa, S.; Uccella, S.; Renne, S. L.",Pathology,2024-03-13 00:00:00 UTC,"ChatGPT is an artificial intelligence capable of processing and generating human-like language. ChatGPTs role within clinical patient care and medical education has been explored; however, assessment of its potential in supporting histopathological diagnosis is lacking. In this study, we assessed ChatGPTs reliability in addressing pathology-related diagnostic questions across 10 subspecialties, as well as its ability to provide scientific references. We created five clinico-pathological scenarios for each subspecialty, posed to ChatGPT as open-ended or multiple-choice questions. Each question either asked for scientific references or not. Outputs were assessed by six pathologists according to: 1) usefulness in supporting the diagnosis and 2) absolute number of errors. All references were manually verified. We used directed acyclic graphs and structural causal models to determine the effect of each scenario type, field, question modality and pathologist evaluation. Overall, we yielded 894 evaluations. ChatGPT provided useful answers in 62.2% of cases. 32.1% of outputs contained no errors, while the remaining contained at least one error (maximum 18). ChatGPT provided 214 bibliographic references: 70.1% were correct, 12.1% were inaccurate and 17.8% did not correspond to a publication. Scenario variability had the greatest impact on ratings, followed by prompting strategy. Finally, latent knowledge across the fields showed minimal variation. In conclusion, ChatGPT provided useful responses in one-third of cases, but the number of errors and variability highlight that it is not yet adequate for everyday diagnostic practice and should be used with discretion as a support tool. The lack of thoroughness in providing references also suggests caution should be employed even when used as a self-learning tool. It is essential to recognize the irreplaceable role of human experts in synthesizing images, clinical data and experience for the intricate task of histopathological diagnosis.",10.1101/2024.03.12.24304153,virology-llm.xlsx,"Evaluation of ChatGPT's Usefulness and Accuracy in Diagnostic Surgical Pathology. ChatGPT is an artificial intelligence capable of processing and generating human-like language. ChatGPTs role within clinical patient care and medical education has been explored; however, assessment of its potential in supporting histopathological diagnosis is lacking. In this study, we assessed ChatGPTs reliability in addressing pathology-related diagnostic questions across 10 subspecialties, as well as its ability to provide scientific references. We created five clinico-pathological scenarios for each subspecialty, posed to ChatGPT as open-ended or multiple-choice questions. Each question either asked for scientific references or not. Outputs were assessed by six pathologists according to: 1) usefulness in supporting the diagnosis and 2) absolute number of errors. All references were manually verified. We used directed acyclic graphs and structural causal models to determine the effect of each scenario type, field, question modality and pathologist evaluation. Overall, we yielded 894 evaluations. ChatGPT provided useful answers in 62.2% of cases. 32.1% of outputs contained no errors, while the remaining contained at least one error (maximum 18). ChatGPT provided 214 bibliographic references: 70.1% were correct, 12.1% were inaccurate and 17.8% did not correspond to a publication. Scenario variability had the greatest impact on ratings, followed by prompting strategy. Finally, latent knowledge across the fields showed minimal variation. In conclusion, ChatGPT provided useful responses in one-third of cases, but the number of errors and variability highlight that it is not yet adequate for everyday diagnostic practice and should be used with discretion as a support tool. The lack of thoroughness in providing references also suggests caution should be employed even when used as a self-learning tool. It is essential to recognize the irreplaceable role of human experts in synthesizing images, clinical data and experience for the intricate task of histopathological diagnosis.",0
"Tran, M.; Schmidle, P.; Wagner, S. J.; Koch, V.; Novotny, B.; Lupperger, V.; Feuchtinger, A.; Boehner, A.; Kaczmarczyk, R.; Biedermann, T.; Comfere, N. I.; Guo, R.; Wang, C.; Eyerich, K.; Braun, S. A.; Peng, T.; Marr, C.",2024,Generating clinical-grade pathology reports from gigapixel whole slide images with HistoGPT,Pathology,Generating clinical-grade pathology reports from gigapixel whole slide images with HistoGPT,"Tran, M.; Schmidle, P.; Wagner, S. J.; Koch, V.; Novotny, B.; Lupperger, V.; Feuchtinger, A.; Boehner, A.; Kaczmarczyk, R.; Biedermann, T.; Comfere, N. I.; Guo, R.; Wang, C.; Eyerich, K.; Braun, S. A.; Peng, T.; Marr, C.",Pathology,2024-06-19 00:00:00 UTC,"Histopathology is considered the reference standard for diagnosing the presence and nature of many malignancies, including cancer. However, analyzing tissue samples and writing pathology reports is time-consuming, labor-intensive, and non-standardized. To address this problem, we present HistoGPT, the first vision language model that simultaneously generates reports from multiple pathology images. It was trained on more than 15,000 whole slide images from over 6,000 dermatology patients with corresponding pathology reports. The generated reports match the quality of human-written reports, as confirmed by a variety of natural language processing metrics and domain expert evaluations. We show that HistoGPT generalizes to six geographically diverse cohorts and can predict tumor subtypes and tumor thickness in a zero-shot fashion. Our model demonstrates the potential of an AI assistant that supports pathologists in evaluating, reporting, and understanding routine dermatopathology cases.",10.1101/2024.03.15.24304211,virology-llm.xlsx,"Generating clinical-grade pathology reports from gigapixel whole slide images with HistoGPT Histopathology is considered the reference standard for diagnosing the presence and nature of many malignancies, including cancer. However, analyzing tissue samples and writing pathology reports is time-consuming, labor-intensive, and non-standardized. To address this problem, we present HistoGPT, the first vision language model that simultaneously generates reports from multiple pathology images. It was trained on more than 15,000 whole slide images from over 6,000 dermatology patients with corresponding pathology reports. The generated reports match the quality of human-written reports, as confirmed by a variety of natural language processing metrics and domain expert evaluations. We show that HistoGPT generalizes to six geographically diverse cohorts and can predict tumor subtypes and tumor thickness in a zero-shot fashion. Our model demonstrates the potential of an AI assistant that supports pathologists in evaluating, reporting, and understanding routine dermatopathology cases.",0
"Jarynowski, A.; Wojta-Kempa, M.; Belik, V.",2020,Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish Internet,Epidemiology,Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish Internet,"Jarynowski, A.; Wojta-Kempa, M.; Belik, V.",Epidemiology,2020-04-07 00:00:00 UTC,"ProblemDue to the spread of SARS CoV-2 virus infection and COVID-2019 disease, there is an urgent need to analyze COVID-2019 epidemic perception in Poland. This would enable authorities for preparation of specific actions minimizing public health and economic risks.

MethodsWe study the perception of COVID-2019 epidemic in Polish society using quantitative analysis of its digital footprints on the Internet (on Twitter, Google, YouTube, Wikipedia and electronic media represented by Event Registry) from January 2020 to 12.03.2020 (before and after official introduction to Poland on 04.03.2020). To this end we utilize data mining, social network analysis, natural language processing techniques. Each examined internet platform was analyzed for representativeness and composition of the target group.

ResultsWe identified three temporal major cluster of the interest before disease introduction on the topic COVID-2019: China- and Italy-related peaks on all platforms, as well as a peak on social media related to the recent special law on combating COVID-2019. Besides, there was a peak in interest on the day of officially confirmed introduction as well as an exponential increase of interest when the Polish government ""declared war against disease"" with a massive mitigation program. From sociolingistic perspective, we found that concepts and issues of threat, fear and prevention prevailed before introduction. After introduction, practical concepts about disease and epidemic dominate. We have found out that Twitter reflected the structural division of the Polish political sphere. We were able to identify clear communities of governing party, mainstream oppostition and a protestant group and potential sources of disinformation. We have also detected bluring boundaries between comminities after disease introduction.

ConclusionsTraditional and social media do not only reflect reality, but also create it. Due to filter ""bubbles"" observed on Twitter, public information campaigns might have less impact on society than expected. For greater penetration, it might be necessary to diversify information channels to reach as many people as possible which might already be happening. Moreover, it might be necessary to prevent the spread of disinformation, which is now possible in Poland due to the special law on combating COVID-2019.",10.1101/2020.03.29.20046789,virology-natural-language-processing.xlsx,"Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish Internet ProblemDue to the spread of SARS CoV-2 virus infection and COVID-2019 disease, there is an urgent need to analyze COVID-2019 epidemic perception in Poland. This would enable authorities for preparation of specific actions minimizing public health and economic risks.

MethodsWe study the perception of COVID-2019 epidemic in Polish society using quantitative analysis of its digital footprints on the Internet (on Twitter, Google, YouTube, Wikipedia and electronic media represented by Event Registry) from January 2020 to 12.03.2020 (before and after official introduction to Poland on 04.03.2020). To this end we utilize data mining, social network analysis, natural language processing techniques. Each examined internet platform was analyzed for representativeness and composition of the target group.

ResultsWe identified three temporal major cluster of the interest before disease introduction on the topic COVID-2019: China- and Italy-related peaks on all platforms, as well as a peak on social media related to the recent special law on combating COVID-2019. Besides, there was a peak in interest on the day of officially confirmed introduction as well as an exponential increase of interest when the Polish government ""declared war against disease"" with a massive mitigation program. From sociolingistic perspective, we found that concepts and issues of threat, fear and prevention prevailed before introduction. After introduction, practical concepts about disease and epidemic dominate. We have found out that Twitter reflected the structural division of the Polish political sphere. We were able to identify clear communities of governing party, mainstream oppostition and a protestant group and potential sources of disinformation. We have also detected bluring boundaries between comminities after disease introduction.

ConclusionsTraditional and social media do not only reflect reality, but also create it. Due to filter ""bubbles"" observed on Twitter, public information campaigns might have less impact on society than expected. For greater penetration, it might be necessary to diversify information channels to reach as many people as possible which might already be happening. Moreover, it might be necessary to prevent the spread of disinformation, which is now possible in Poland due to the special law on combating COVID-2019.",1
"Izquierdo, J. L.; Ancochea, J.; Savana Covid-19 Research Group,  ; Soriano, J. B.",2020,CLINICAL CHARACTERISTICS AND PROGNOSTIC FACTORS FOR ICU ADMISSION OF PATIENTS WITH COVID-19 USING MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING,Respiratory Medicine,CLINICAL CHARACTERISTICS AND PROGNOSTIC FACTORS FOR ICU ADMISSION OF PATIENTS WITH COVID-19 USING MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING,"Izquierdo, J. L.; Ancochea, J.; Savana Covid-19 Research Group,  ; Soriano, J. B.",Respiratory Medicine,2020-05-26 00:00:00 UTC,"There remain many unknowns regarding the onset and clinical course of the ongoing COVID-19 pandemic. We used a combination of classic epidemiological methods, natural language processing (NLP), and machine learning (for predictive modeling), to analyse the electronic health records (EHRs) of patients with COVID-19.

We explored the unstructured free text in the EHRs within the SESCAM Healthcare Network (Castilla La-Mancha, Spain) from the entire population with available EHRs (1,364,924 patients) from January 1st to March 29th, 2020. We extracted related clinical information upon diagnosis, progression and outcome for all COVID-19 cases, focusing in those requiring ICU admission.

A total of 10,504 patients with a clinical or PCR-confirmed diagnosis of COVID-19 were identified, 52.5% males, with age of 58.2{+/-}19.7 years. Upon admission, the most common symptoms were cough, fever, and dyspnoea, but all in less than half of cases. Overall, 6% of hospitalized patients required ICU admission. Using a machine-learning, data-driven algorithm we identified that a combination of age, fever, and tachypnoea was the most parsimonious predictor of ICU admission: those younger than 56 years, without tachypnoea, and temperature <39{degrees}C, (or >39{degrees}C without respiratory crackles), were free of ICU admission. On the contrary, COVID-19 patients aged 40 to 79 years were likely to be admitted to the ICU if they had tachypnoea and delayed their visit to the ER after being seen in primary care.

Our results show that a combination of easily obtainable clinical variables (age, fever, and tachypnoea with/without respiratory crackles) predicts which COVID-19 patients require ICU admission.",10.1101/2020.05.22.20109959,virology-natural-language-processing.xlsx,"CLINICAL CHARACTERISTICS AND PROGNOSTIC FACTORS FOR ICU ADMISSION OF PATIENTS WITH COVID-19 USING MACHINE LEARNING AND NATURAL LANGUAGE PROCESSING There remain many unknowns regarding the onset and clinical course of the ongoing COVID-19 pandemic. We used a combination of classic epidemiological methods, natural language processing (NLP), and machine learning (for predictive modeling), to analyse the electronic health records (EHRs) of patients with COVID-19.

We explored the unstructured free text in the EHRs within the SESCAM Healthcare Network (Castilla La-Mancha, Spain) from the entire population with available EHRs (1,364,924 patients) from January 1st to March 29th, 2020. We extracted related clinical information upon diagnosis, progression and outcome for all COVID-19 cases, focusing in those requiring ICU admission.

A total of 10,504 patients with a clinical or PCR-confirmed diagnosis of COVID-19 were identified, 52.5% males, with age of 58.2{+/-}19.7 years. Upon admission, the most common symptoms were cough, fever, and dyspnoea, but all in less than half of cases. Overall, 6% of hospitalized patients required ICU admission. Using a machine-learning, data-driven algorithm we identified that a combination of age, fever, and tachypnoea was the most parsimonious predictor of ICU admission: those younger than 56 years, without tachypnoea, and temperature <39{degrees}C, (or >39{degrees}C without respiratory crackles), were free of ICU admission. On the contrary, COVID-19 patients aged 40 to 79 years were likely to be admitted to the ICU if they had tachypnoea and delayed their visit to the ER after being seen in primary care.

Our results show that a combination of easily obtainable clinical variables (age, fever, and tachypnoea with/without respiratory crackles) predicts which COVID-19 patients require ICU admission.",1
"Gupta, M.; Bansal, A.; Jain, B.; Rochelle, J.; Oak, A.; Jalali, M. S.",2020,Whether the Weather Will Help Us Weather the COVID-19 Pandemic: Using Machine Learning to Measure Twitter Users' Perceptions,Epidemiology,Whether the Weather Will Help Us Weather the COVID-19 Pandemic: Using Machine Learning to Measure Twitter Users' Perceptions,"Gupta, M.; Bansal, A.; Jain, B.; Rochelle, J.; Oak, A.; Jalali, M. S.",Epidemiology,2020-08-01 00:00:00 UTC,"ObjectiveThe potential ability for weather to affect SARS-CoV-2 transmission has been an area of controversial discussion during the COVID-19 pandemic. Individuals perceptions of the impact of weather can inform their adherence to public health guidelines; however, there is no measure of their perceptions. We quantified Twitter users perceptions of the effect of weather and analyzed how they evolved with respect to real-world events and time.

Materials and MethodsWe collected 166,005 tweets posted between January 23 and June 22, 2020 and employed machine learning/natural language processing techniques to filter for relevant tweets, classify them by the type of effect they claimed, and identify topics of discussion.

ResultsWe identified 28,555 relevant tweets and estimate that 40.4% indicate uncertainty about weathers impact, 33.5% indicate no effect, and 26.1% indicate some effect. We tracked changes in these proportions over time. Topic modeling revealed major latent areas of discussion.

DiscussionThere is no consensus among the public for weathers potential impact. Earlier months were characterized by tweets that were uncertain of weathers effect or claimed no effect; later, the portion of tweets claiming some effect of weather increased. Tweets claiming no effect of weather comprised the largest class by June. Major topics of discussion included comparisons to influenzas seasonality, President Trumps comments on weathers effect, and social distancing.

ConclusionThere is a major gap between scientific evidence and public opinion of weathers impacts on COVID-19. We provide evidence of publics misconceptions and topics of discussion, which can inform public health communications.",10.1101/2020.07.29.20164814,virology-natural-language-processing.xlsx,"Whether the Weather Will Help Us Weather the COVID-19 Pandemic: Using Machine Learning to Measure Twitter Users' Perceptions ObjectiveThe potential ability for weather to affect SARS-CoV-2 transmission has been an area of controversial discussion during the COVID-19 pandemic. Individuals perceptions of the impact of weather can inform their adherence to public health guidelines; however, there is no measure of their perceptions. We quantified Twitter users perceptions of the effect of weather and analyzed how they evolved with respect to real-world events and time.

Materials and MethodsWe collected 166,005 tweets posted between January 23 and June 22, 2020 and employed machine learning/natural language processing techniques to filter for relevant tweets, classify them by the type of effect they claimed, and identify topics of discussion.

ResultsWe identified 28,555 relevant tweets and estimate that 40.4% indicate uncertainty about weathers impact, 33.5% indicate no effect, and 26.1% indicate some effect. We tracked changes in these proportions over time. Topic modeling revealed major latent areas of discussion.

DiscussionThere is no consensus among the public for weathers potential impact. Earlier months were characterized by tweets that were uncertain of weathers effect or claimed no effect; later, the portion of tweets claiming some effect of weather increased. Tweets claiming no effect of weather comprised the largest class by June. Major topics of discussion included comparisons to influenzas seasonality, President Trumps comments on weathers effect, and social distancing.

ConclusionThere is a major gap between scientific evidence and public opinion of weathers impacts on COVID-19. We provide evidence of publics misconceptions and topics of discussion, which can inform public health communications.",1
"Dhokotera, T. G.; Bohlius, J.; Egger, M.; Spoerri, A.; Ncayiyana, J.; Naidu, G.; Olago, V.; Zwahlen, M.; Singh, E.; Muchengeti, M.",2020,Cancer in HIV-positive and HIV-negative adolescents and young adults in South Africa: a cross-sectional study,Epidemiology,Cancer in HIV-positive and HIV-negative adolescents and young adults in South Africa: a cross-sectional study,"Dhokotera, T. G.; Bohlius, J.; Egger, M.; Spoerri, A.; Ncayiyana, J.; Naidu, G.; Olago, V.; Zwahlen, M.; Singh, E.; Muchengeti, M.",Epidemiology,2020-08-21 00:00:00 UTC,"ObjectiveTo determine the spectrum of cancers in AYAs living with HIV in South Africa compared to their HIV negative peers.

DesignCross sectional study with cancer data provided by the National Cancer Registry and HIV data from the National Health Laboratory Service.

Setting and participantsThe NHLS is the largest provider of pathology services in the South African public sector with an estimated coverage of 80%. The NCR is a division of the NHLS. We included AYAs (aged 10-24 years) diagnosed with cancer by public health sector laboratories between 2004 and 2014 (n=8 479). We included 3 672 in the complete case analysis.

Primary and secondary outcomesWe used linked NCR and NHLS data to determine the spectrum of cancers by HIV status in AYAs. We also used multivariable logistic regression to describe the association of cancer in AYAs with HIV, adjusting for age, sex (as appropriate), ethnicity, and calendar period. Due to the large proportion of unknown HIV status we also imputed (post-hoc) the missing HIV status.

ResultsFrom 2004-2014, 8 479 AYAs were diagnosed with cancer, HIV status was known for only 45% (n=3812); of those whose status was known, about half were HIV positive (n=1853). AYAs living with HIV were more likely to have Kaposis sarcoma (adjusted odds ratio (aOR) 218, 95% CI 89.9-530), cervical cancer (aOR 2.18, 95% CI 1.23-3.89), non-Hodgkins lymphoma (aOR 2.12, 95% CI 1.69-2.66), and anogenital cancers other than cervix (aOR 2.73, 95% CI 1.27-5.86). About 44% (n=1 062) of AYAs with HIV related cancers had not been tested for HIV, though they were very likely to have the disease.

ConclusionsCancer burden in AYAs living with HIV in South Africa could be reduced by screening young women for cervical cancer and vaccinating them against human papilloma virus (HPV) infection.

Strength and limitationsO_LIThis is the first nationwide study in South Africa to compare the distribution of cancers in adolescents and young adults (AYAs) by HIV status.
C_LIO_LIThe record linkage and the additional results determined from the text mining process ensured that we extracted the maximum available HIV results.
C_LIO_LIWe assumed a CD4 count test indicates being HIV positive but CD4 testing maybe performed for other reasons
C_LIO_LISince this was a population of only AYAs diagnosed with cancer, the odds ratios could be overestimated or underestimated depending on the frequency of the cancer
C_LI",10.1101/2020.08.18.20176289,virology-natural-language-processing.xlsx,"Cancer in HIV-positive and HIV-negative adolescents and young adults in South Africa: a cross-sectional study ObjectiveTo determine the spectrum of cancers in AYAs living with HIV in South Africa compared to their HIV negative peers.

DesignCross sectional study with cancer data provided by the National Cancer Registry and HIV data from the National Health Laboratory Service.

Setting and participantsThe NHLS is the largest provider of pathology services in the South African public sector with an estimated coverage of 80%. The NCR is a division of the NHLS. We included AYAs (aged 10-24 years) diagnosed with cancer by public health sector laboratories between 2004 and 2014 (n=8 479). We included 3 672 in the complete case analysis.

Primary and secondary outcomesWe used linked NCR and NHLS data to determine the spectrum of cancers by HIV status in AYAs. We also used multivariable logistic regression to describe the association of cancer in AYAs with HIV, adjusting for age, sex (as appropriate), ethnicity, and calendar period. Due to the large proportion of unknown HIV status we also imputed (post-hoc) the missing HIV status.

ResultsFrom 2004-2014, 8 479 AYAs were diagnosed with cancer, HIV status was known for only 45% (n=3812); of those whose status was known, about half were HIV positive (n=1853). AYAs living with HIV were more likely to have Kaposis sarcoma (adjusted odds ratio (aOR) 218, 95% CI 89.9-530), cervical cancer (aOR 2.18, 95% CI 1.23-3.89), non-Hodgkins lymphoma (aOR 2.12, 95% CI 1.69-2.66), and anogenital cancers other than cervix (aOR 2.73, 95% CI 1.27-5.86). About 44% (n=1 062) of AYAs with HIV related cancers had not been tested for HIV, though they were very likely to have the disease.

ConclusionsCancer burden in AYAs living with HIV in South Africa could be reduced by screening young women for cervical cancer and vaccinating them against human papilloma virus (HPV) infection.

Strength and limitationsO_LIThis is the first nationwide study in South Africa to compare the distribution of cancers in adolescents and young adults (AYAs) by HIV status.
C_LIO_LIThe record linkage and the additional results determined from the text mining process ensured that we extracted the maximum available HIV results.
C_LIO_LIWe assumed a CD4 count test indicates being HIV positive but CD4 testing maybe performed for other reasons
C_LIO_LISince this was a population of only AYAs diagnosed with cancer, the odds ratios could be overestimated or underestimated depending on the frequency of the cancer
C_LI",1
"Landsman, D.; Abdelbasit, A.; Wang, C.; Guerzhoy, M.; Joshi, U.; Mathew, S.; Pou-Prom, C.; Dai, D.; Pequegnat, V.; Murray, J.; Chokar, K.; Banning, M.; Mamdani, M.; Mishra, S.; Batt, J.",2020,"Cohort profile: St. Michael's Hospital Tuberculosis Database (SMH-TB), a retrospective cohort of electronic health record data and variables extracted using natural language processing",Epidemiology,"Cohort profile: St. Michael's Hospital Tuberculosis Database (SMH-TB), a retrospective cohort of electronic health record data and variables extracted using natural language processing","Landsman, D.; Abdelbasit, A.; Wang, C.; Guerzhoy, M.; Joshi, U.; Mathew, S.; Pou-Prom, C.; Dai, D.; Pequegnat, V.; Murray, J.; Chokar, K.; Banning, M.; Mamdani, M.; Mishra, S.; Batt, J.",Epidemiology,2020-09-13 00:00:00 UTC,"Background Tuberculosis (TB) is a major cause of death worldwide. TB research draws heavily on clinical cohorts which can be generated using electronic health records (EHR), but granular information extracted from unstructured EHR data is limited. The St. Michael's Hospital TB database (SMH-TB) was established to address gaps in EHR-derived TB clinical cohorts and provide researchers and clinicians with detailed, granular data related to TB management and treatment. Methods We collected and validated multiple layers of EHR data from the TB outpatient clinic at St. Michael's Hospital, Toronto, Ontario, Canada to generate the SMH-TB database. SMH-TB contains structured data directly from the EHR, and variables generated using natural language processing (NLP) by extracting relevant information from free-text within clinic, radiology, and other notes. NLP performance was assessed using recall, precision and F1 score averaged across variable labels. We present characteristics of the cohort population using binomial proportions and 95% confidence intervals (CI), with and without adjusting for NLP misclassification errors. Results SMH-TB currently contains retrospective patient data spanning 2011 to 2018, for a total of 3298 patients (N=3237 with at least 1 associated dictation). Performance of TB diagnosis and medication NLP rulesets surpasses 93% in recall, precision and F1 metrics, indicating good generalizability. We estimated 20% (95% CI: 18.4-21.2%) were diagnosed with active TB and 46% (95% CI: 43.8-47.2%) were diagnosed with latent TB. After adjusting for potential misclassification, the proportion of patients diagnosed with active and latent TB was 18% (95% CI: 16.8-19.7%) and 40% (95% CI: 37.8-41.6%) respectively Conclusion SMH-TB is a unique database that includes a breadth of structured data derived from structured and unstructured EHR data. The data are available for a variety of research applications, such as clinical epidemiology, quality improvement and mathematical modelling studies.",10.1101/2020.09.11.20192419,virology-natural-language-processing.xlsx,"Cohort profile: St. Michael's Hospital Tuberculosis Database (SMH-TB), a retrospective cohort of electronic health record data and variables extracted using natural language processing Background Tuberculosis (TB) is a major cause of death worldwide. TB research draws heavily on clinical cohorts which can be generated using electronic health records (EHR), but granular information extracted from unstructured EHR data is limited. The St. Michael's Hospital TB database (SMH-TB) was established to address gaps in EHR-derived TB clinical cohorts and provide researchers and clinicians with detailed, granular data related to TB management and treatment. Methods We collected and validated multiple layers of EHR data from the TB outpatient clinic at St. Michael's Hospital, Toronto, Ontario, Canada to generate the SMH-TB database. SMH-TB contains structured data directly from the EHR, and variables generated using natural language processing (NLP) by extracting relevant information from free-text within clinic, radiology, and other notes. NLP performance was assessed using recall, precision and F1 score averaged across variable labels. We present characteristics of the cohort population using binomial proportions and 95% confidence intervals (CI), with and without adjusting for NLP misclassification errors. Results SMH-TB currently contains retrospective patient data spanning 2011 to 2018, for a total of 3298 patients (N=3237 with at least 1 associated dictation). Performance of TB diagnosis and medication NLP rulesets surpasses 93% in recall, precision and F1 metrics, indicating good generalizability. We estimated 20% (95% CI: 18.4-21.2%) were diagnosed with active TB and 46% (95% CI: 43.8-47.2%) were diagnosed with latent TB. After adjusting for potential misclassification, the proportion of patients diagnosed with active and latent TB was 18% (95% CI: 16.8-19.7%) and 40% (95% CI: 37.8-41.6%) respectively Conclusion SMH-TB is a unique database that includes a breadth of structured data derived from structured and unstructured EHR data. The data are available for a variety of research applications, such as clinical epidemiology, quality improvement and mathematical modelling studies.",1
"Afshin-Pour, B.; Qiu, M.; Hosseini, S.; Stewart, M.; Horsky, J.; Aviv, R.; Zhang, N.; Narasimhan, M.; Chelico, J.; Musso, G.; Hajizadeh, N.",2021,High-fidelity discrimination of ARDS versus other causes of respiratory failure using natural language processing and iterative machine learning,Respiratory Medicine,High-fidelity discrimination of ARDS versus other causes of respiratory failure using natural language processing and iterative machine learning,"Afshin-Pour, B.; Qiu, M.; Hosseini, S.; Stewart, M.; Horsky, J.; Aviv, R.; Zhang, N.; Narasimhan, M.; Chelico, J.; Musso, G.; Hajizadeh, N.",Respiratory Medicine,2021-01-28 00:00:00 UTC,"Despite the high morbidity and mortality associated with Acute Respiratory Distress Syndrome (ARDS), discrimination of ARDS from other causes of acute respiratory failure remains challenging, particularly in the first 24 hours of mechanical ventilation. Delay in ARDS identification prevents lung protective strategies from being initiated and delays clinical trial enrolment and quality improvement interventions. Medical records from 1,263 ICU-admitted, mechanically ventilated patients at Northwell Health were retrospectively examined by a clinical team who assigned each patient a diagnosis of ""ARDS"" or ""non-ARDS"" (e.g., pulmonary edema). We then applied an iterative pre-processing and machine learning framework to construct a model that would discriminate ARDS versus non-ARDS, and examined features informative in the patient classification process. Data made available to the model included patient demographics, laboratory test results from before the initiation of mechanical ventilation, and features extracted by natural language processing of radiology reports. The resulting model discriminated well between ARDS and non-ARDS causes of respiratory failure (AUC=0.85, 89% precision at 20% recall), and highlighted features unique among ARDS patients, and among and the subset of ARDS patients who would not recover. Importantly, models built using both clinical notes and laboratory test results out-performed models built using either data source alone, akin to the retrospective clinician-based diagnostic process. This work demonstrates the feasibility of using readily available EHR data to discriminate ARDS patients prospectively in a real-world setting at a critical time in their care and highlights novel patient characteristics indicative of ARDS.",10.1101/2021.01.26.21250316,virology-natural-language-processing.xlsx,"High-fidelity discrimination of ARDS versus other causes of respiratory failure using natural language processing and iterative machine learning Despite the high morbidity and mortality associated with Acute Respiratory Distress Syndrome (ARDS), discrimination of ARDS from other causes of acute respiratory failure remains challenging, particularly in the first 24 hours of mechanical ventilation. Delay in ARDS identification prevents lung protective strategies from being initiated and delays clinical trial enrolment and quality improvement interventions. Medical records from 1,263 ICU-admitted, mechanically ventilated patients at Northwell Health were retrospectively examined by a clinical team who assigned each patient a diagnosis of ""ARDS"" or ""non-ARDS"" (e.g., pulmonary edema). We then applied an iterative pre-processing and machine learning framework to construct a model that would discriminate ARDS versus non-ARDS, and examined features informative in the patient classification process. Data made available to the model included patient demographics, laboratory test results from before the initiation of mechanical ventilation, and features extracted by natural language processing of radiology reports. The resulting model discriminated well between ARDS and non-ARDS causes of respiratory failure (AUC=0.85, 89% precision at 20% recall), and highlighted features unique among ARDS patients, and among and the subset of ARDS patients who would not recover. Importantly, models built using both clinical notes and laboratory test results out-performed models built using either data source alone, akin to the retrospective clinician-based diagnostic process. This work demonstrates the feasibility of using readily available EHR data to discriminate ARDS patients prospectively in a real-world setting at a critical time in their care and highlights novel patient characteristics indicative of ARDS.",0
"Lavertu, A.; Hamamsy, T. C.; Altman, R. B.; Eichstaedt, J.; Smith, D.",2024,Monitoring the opioid epidemic via social media discussions,Epidemiology,Monitoring the opioid epidemic via social media discussions,"Lavertu, A.; Hamamsy, T. C.; Altman, R. B.; Eichstaedt, J.; Smith, D.",Epidemiology,2024-11-20 00:00:00 UTC,"Opioid-involved overdose deaths have risen significantly since 1999 with over 80,000 deaths annually since 2021, primarily driven by synthetic opioids, like fentanyl. Responding to the rapidly changing opioid crisis requires reliable and timely information. One possible source of such data is the social media platforms with billions of user-generated posts, a fraction of which are about drug use. We therefore assessed the utility of Reddit data for surveillance of the opioid epidemic, covering prescription, heroin, and synthetic drugs (as of September 2024, up-to-date Reddit data was still accessible on the open web). Specifically, we built a natural language processing pipeline to identify opioid-related comments and created a cohort of 1,689,039 geo-located Reddit users, each assigned to a state. We followed these users from 2010 through 2022, measured their opioid-related posting activity over time, and compared this posting activity against CDC overdose and National Forensic Laboratory Information System (NFLIS) drug report rates. To simulate the real-world prediction of synthetic drug overdose rates, we added near real-time Reddit data to a model relying on CDC mortality data with a typical 6-month reporting lag and found that Reddit data significantly improved prediction accuracy. We observed drastic, largely unpredictable changes in both Reddit and overdose patterns during the COVID-19 pandemic. Reddit discussions covered a wide variety of drug types that are currently missed by official reporting. This work suggests that social media can help identify and monitor known and emerging drug epidemics and that this data is a public health ""common good"" to which researchers should continue to have access.

Significance statementThe opioid epidemic persists in the United States with over 80,000 deaths annually since 2021, primarily driven by synthetic opioids like fentanyl. As the geographic and demographic patterns of the opioid epidemic are rapidly changing, accurate and timely monitoring is needed. In this paper, we used social media data from Reddit to conduct public health surveillance of the opioid epidemic, following 1.5+ million geo-located users over 10+ years. We also found that near real-time Reddit data can improve our ability to predict future overdose death rates compared to models only using CDC data with typical half-year reporting delays. Our work suggests that social media can be a useful component for public health surveillance of the opioid epidemic.",10.1101/2021.04.01.21254815,virology-natural-language-processing.xlsx,"Monitoring the opioid epidemic via social media discussions Opioid-involved overdose deaths have risen significantly since 1999 with over 80,000 deaths annually since 2021, primarily driven by synthetic opioids, like fentanyl. Responding to the rapidly changing opioid crisis requires reliable and timely information. One possible source of such data is the social media platforms with billions of user-generated posts, a fraction of which are about drug use. We therefore assessed the utility of Reddit data for surveillance of the opioid epidemic, covering prescription, heroin, and synthetic drugs (as of September 2024, up-to-date Reddit data was still accessible on the open web). Specifically, we built a natural language processing pipeline to identify opioid-related comments and created a cohort of 1,689,039 geo-located Reddit users, each assigned to a state. We followed these users from 2010 through 2022, measured their opioid-related posting activity over time, and compared this posting activity against CDC overdose and National Forensic Laboratory Information System (NFLIS) drug report rates. To simulate the real-world prediction of synthetic drug overdose rates, we added near real-time Reddit data to a model relying on CDC mortality data with a typical 6-month reporting lag and found that Reddit data significantly improved prediction accuracy. We observed drastic, largely unpredictable changes in both Reddit and overdose patterns during the COVID-19 pandemic. Reddit discussions covered a wide variety of drug types that are currently missed by official reporting. This work suggests that social media can help identify and monitor known and emerging drug epidemics and that this data is a public health ""common good"" to which researchers should continue to have access.

Significance statementThe opioid epidemic persists in the United States with over 80,000 deaths annually since 2021, primarily driven by synthetic opioids like fentanyl. As the geographic and demographic patterns of the opioid epidemic are rapidly changing, accurate and timely monitoring is needed. In this paper, we used social media data from Reddit to conduct public health surveillance of the opioid epidemic, following 1.5+ million geo-located users over 10+ years. We also found that near real-time Reddit data can improve our ability to predict future overdose death rates compared to models only using CDC data with typical half-year reporting delays. Our work suggests that social media can be a useful component for public health surveillance of the opioid epidemic.",1
"Sun, X.; Guan, T.; Xue, T.; Fan, C.; Yang, M.; Meng, Y.; Zhang, T.; Jiangtulu, B.; Wu, F.; Li, J.",2021,Analysis on Action Tracking Reports of COVID-19 Informs Control Strategies and Vaccine Delivery in Post-Pandemic Era,Epidemiology,Analysis on Action Tracking Reports of COVID-19 Informs Control Strategies and Vaccine Delivery in Post-Pandemic Era,"Sun, X.; Guan, T.; Xue, T.; Fan, C.; Yang, M.; Meng, Y.; Zhang, T.; Jiangtulu, B.; Wu, F.; Li, J.",Epidemiology,2021-04-25 00:00:00 UTC,"Understanding the spread of SARS-CoV-2 provides important insights for control policies such as social-distancing interventions and vaccine delivery in the post-pandemic era. In this work, we take the advantage of action tracking reports of confirmed COVID-19 patients, which contain the mobility trajectory of patients. We analyzed reports of patients from April 2020 to January 2021 in China, a country where the residents are well-prepared for the ""new normal"" world following COVID-19 spread. We developed natural language processing (NLP) tools to transform the unstructured text of action-tracking reports to a structured network of social contacts. An epidemiology model was built on top of the network. Our analysis provides important insights for the development of control policies. Under the ""new normal"" conditions, we find that restaurants, locations less protected by mask-wearing, have a greater risk than any other location categories, including locations where people are present at higher densities (e.g., flight). We find that discouraging railway transports is crucial to avoid another wave of breakout during the Chunyun season (a period of travel in China with extremely high traffic load around the Chinese New Year). By formalizing the challenge of finding the optimal vaccine delivery among various different population groups as an optimization problem, our analysis helps to maximize the efficiency of vaccine delivery under the general situation of vaccine supply shortage. We are able to reduce the numbers of infections and deaths by 7.4% and 10.5% respectively with vaccine supply for only 1% of the population. Furthermore, with 10% vaccination rate, the numbers of infections and deaths further decrease by 52.6% and 78.1% respectively. Our work will be helpful in the design of effective policies regarding interventions, reopening, contact tracing and vaccine delivery in the ""new normal"" world following COVID-19 spread.",10.1101/2021.04.08.21254953,virology-natural-language-processing.xlsx,"Analysis on Action Tracking Reports of COVID-19 Informs Control Strategies and Vaccine Delivery in Post-Pandemic Era Understanding the spread of SARS-CoV-2 provides important insights for control policies such as social-distancing interventions and vaccine delivery in the post-pandemic era. In this work, we take the advantage of action tracking reports of confirmed COVID-19 patients, which contain the mobility trajectory of patients. We analyzed reports of patients from April 2020 to January 2021 in China, a country where the residents are well-prepared for the ""new normal"" world following COVID-19 spread. We developed natural language processing (NLP) tools to transform the unstructured text of action-tracking reports to a structured network of social contacts. An epidemiology model was built on top of the network. Our analysis provides important insights for the development of control policies. Under the ""new normal"" conditions, we find that restaurants, locations less protected by mask-wearing, have a greater risk than any other location categories, including locations where people are present at higher densities (e.g., flight). We find that discouraging railway transports is crucial to avoid another wave of breakout during the Chunyun season (a period of travel in China with extremely high traffic load around the Chinese New Year). By formalizing the challenge of finding the optimal vaccine delivery among various different population groups as an optimization problem, our analysis helps to maximize the efficiency of vaccine delivery under the general situation of vaccine supply shortage. We are able to reduce the numbers of infections and deaths by 7.4% and 10.5% respectively with vaccine supply for only 1% of the population. Furthermore, with 10% vaccination rate, the numbers of infections and deaths further decrease by 52.6% and 78.1% respectively. Our work will be helpful in the design of effective policies regarding interventions, reopening, contact tracing and vaccine delivery in the ""new normal"" world following COVID-19 spread.",1
"Krauer, F.; Schmid, B. V.",2022,Mapping the plague through natural language processing,Epidemiology,Mapping the plague through natural language processing,"Krauer, F.; Schmid, B. V.",Epidemiology,2022-07-20 00:00:00 UTC,"Pandemic diseases such as plague have produced a vast amount of literature providing information about the spatiotemporal extent of past epidemics, circumstances of transmission, symptoms, or countermeasures. However, the manual extraction of such information from running text is a tedious process, and much of this information has therefore remained locked into a narrative format. Natural Language processing (NLP) is a promising tool for the automated extraction of epidemiological data from texts, and can facilitate the establishment of datasets. In this paper, we explore the utility of NLP to assist in the creation of a plague outbreak dataset. We first produced a gold standard list of toponyms by manual annotation of a German plague treatise published by Sticker in 1908. We then investigated the performance of five pre-trained NLP libraries (Google NLP, Stanford CoreNLP, spaCy, germaNER and Geoparser.io) for the automated extraction of location data from a compared to the gold standard. Of all tested algorithms, spaCy performed best (sensitivity 0.92, F1 score 0.83), followed closely by Stanford CoreNLP (sensitivity 0.81, F1 score 0.87). Google NLP had a slightly lower performance (F1 score 0.72, sensitivity 0.78). Geoparser and germaNER had a poor sensitivity (0.41 and 0.61) From the gold standard list we produced a plague dataset by linking dates and outbreak places with GIS coordinates. We then evaluated how well automated geocoding services such as Google geocoding, Geonames and Geoparser located these outbreaks correctly. All geocoding services performed poorly and returned the correct GIS information only in 60.4%, 52.7% and 33.8% of all cases. The rate of correct matches was particularly low when it came to historical regions and places. Finally, we compared our newly digitized plague dataset to a re-digitized version of the plague treatise by Biraben and provide an update of the spatio-temporal extent of the second pandemic plague outbreaks. We conclude that NLP tools have their limitations, but they are potentially useful to accelerate the collection of data and the generation of a global plague outbreak database.",10.1101/2021.04.27.21256212,virology-natural-language-processing.xlsx,"Mapping the plague through natural language processing Pandemic diseases such as plague have produced a vast amount of literature providing information about the spatiotemporal extent of past epidemics, circumstances of transmission, symptoms, or countermeasures. However, the manual extraction of such information from running text is a tedious process, and much of this information has therefore remained locked into a narrative format. Natural Language processing (NLP) is a promising tool for the automated extraction of epidemiological data from texts, and can facilitate the establishment of datasets. In this paper, we explore the utility of NLP to assist in the creation of a plague outbreak dataset. We first produced a gold standard list of toponyms by manual annotation of a German plague treatise published by Sticker in 1908. We then investigated the performance of five pre-trained NLP libraries (Google NLP, Stanford CoreNLP, spaCy, germaNER and Geoparser.io) for the automated extraction of location data from a compared to the gold standard. Of all tested algorithms, spaCy performed best (sensitivity 0.92, F1 score 0.83), followed closely by Stanford CoreNLP (sensitivity 0.81, F1 score 0.87). Google NLP had a slightly lower performance (F1 score 0.72, sensitivity 0.78). Geoparser and germaNER had a poor sensitivity (0.41 and 0.61) From the gold standard list we produced a plague dataset by linking dates and outbreak places with GIS coordinates. We then evaluated how well automated geocoding services such as Google geocoding, Geonames and Geoparser located these outbreaks correctly. All geocoding services performed poorly and returned the correct GIS information only in 60.4%, 52.7% and 33.8% of all cases. The rate of correct matches was particularly low when it came to historical regions and places. Finally, we compared our newly digitized plague dataset to a re-digitized version of the plague treatise by Biraben and provide an update of the spatio-temporal extent of the second pandemic plague outbreaks. We conclude that NLP tools have their limitations, but they are potentially useful to accelerate the collection of data and the generation of a global plague outbreak database.",1
"Khurshid, S.; Reeder, C.; Harrington, L. X.; Singh, P.; Sarma, G.; Friedman, S. F.; Di Achille, P.; Diamant, N.; Cunningham, J. W.; Turner, A. C.; Lau, E. S.; Haimovich, J. S.; Al-Alusi, M. A.; Wang, X.; Klarqvist, M. D. R.; Ashburner, J. M.; Diedrich, C.; Ghadessi, M.; Mielke, J.; Eilken, H. M.; Mcelhinney, A.; Derix, A.; Atlas, S. J.; Ellinor, P. T.; Philippakis, A. A.; Anderson, C. D.; Ho, J. E.; Batra, P.; Lubitz, S.",2021,Cohort Design and Natural Language Processing to Reduce Bias in Electronic Health Records Research: The Community Care Cohort Project,Epidemiology,Cohort Design and Natural Language Processing to Reduce Bias in Electronic Health Records Research: The Community Care Cohort Project,"Khurshid, S.; Reeder, C.; Harrington, L. X.; Singh, P.; Sarma, G.; Friedman, S. F.; Di Achille, P.; Diamant, N.; Cunningham, J. W.; Turner, A. C.; Lau, E. S.; Haimovich, J. S.; Al-Alusi, M. A.; Wang, X.; Klarqvist, M. D. R.; Ashburner, J. M.; Diedrich, C.; Ghadessi, M.; Mielke, J.; Eilken, H. M.; Mcelhinney, A.; Derix, A.; Atlas, S. J.; Ellinor, P. T.; Philippakis, A. A.; Anderson, C. D.; Ho, J. E.; Batra, P.; Lubitz, S.",Epidemiology,2021-05-30 00:00:00 UTC,"BackgroundElectronic health records (EHRs) promise to enable broad-ranging discovery with power exceeding that of conventional research cohort studies. However, research using EHR datasets may be subject to selection bias, which can be compounded by missing data, limiting the generalizability of derived insights.

MethodsMass General Brigham (MGB) is a large New England-based healthcare network comprising seven tertiary care and community hospitals with associated outpatient practices. Within an MGB-based EHR warehouse of >3.5 million individuals with at least one ambulatory care visit, we approximated a community-based cohort study by selectively sampling individuals longitudinally attending primary care practices between 2001-2018 (n=520,868), which we named the Community Care Cohort Project (C3PO). We also utilized pre-trained deep natural language processing (NLP) models to recover vital signs (i.e., height, weight, and blood pressure) from unstructured notes in the EHR. We assessed the validity of C3PO by deploying established risk models including the Pooled Cohort Equations (PCE) and the Cohorts for Aging and Genomic Epidemiology Atrial Fibrillation (CHARGE-AF) score, and compared model performance in C3PO to that observed within typical EHR Convenience Samples which included all individuals from the same parent EHR with sufficient data to calculate each score but without a requirement for longitudinal primary care. All analyses were facilitated by the JEDI Extractive Data Infrastructure pipeline which we designed to efficiently aggregate EHR data within a unified framework conducive to regular updates.

ResultsC3PO includes 520,868 individuals (mean age 48 years, 61% women, median follow-up 7.2 years, median primary care visits per individual 13). Estimated using reports, C3PO contains over 2.9 million electrocardiograms, 450,000 echocardiograms, 12,000 cardiac magnetic resonance images, and 75 million narrative notes. Using tabular data alone, 286,009 individuals (54.9%) had all vital signs available at baseline, which increased to 358,411 (68.8%) after NLP recovery (31% reduction in missingness). Among individuals with both NLP and tabular data available, NLP-extracted and tabular vital signs obtained on the same day were highly correlated (e.g., Pearson r range 0.95-0.99, p<0.01 for all). Both the PCE models (c-index range 0.724-0.770) and CHARGE-AF (c-index 0.782, 95% 0.777-0.787) demonstrated good discrimination. As compared to the Convenience Samples, AF and MI/stroke incidence rates in C3PO were lower and calibration error was smaller for both PCE (integrated calibration index range 0.012-0.030 vs. 0.028-0.046) and CHARGE-AF (0.028 vs. 0.036).

ConclusionsIntentional sampling of individuals receiving regular ambulatory care and use of NLP to recover missing data have the potential to reduce bias in EHR research and maximize generalizability of insights.",10.1101/2021.05.26.21257872,virology-natural-language-processing.xlsx,"Cohort Design and Natural Language Processing to Reduce Bias in Electronic Health Records Research: The Community Care Cohort Project BackgroundElectronic health records (EHRs) promise to enable broad-ranging discovery with power exceeding that of conventional research cohort studies. However, research using EHR datasets may be subject to selection bias, which can be compounded by missing data, limiting the generalizability of derived insights.

MethodsMass General Brigham (MGB) is a large New England-based healthcare network comprising seven tertiary care and community hospitals with associated outpatient practices. Within an MGB-based EHR warehouse of >3.5 million individuals with at least one ambulatory care visit, we approximated a community-based cohort study by selectively sampling individuals longitudinally attending primary care practices between 2001-2018 (n=520,868), which we named the Community Care Cohort Project (C3PO). We also utilized pre-trained deep natural language processing (NLP) models to recover vital signs (i.e., height, weight, and blood pressure) from unstructured notes in the EHR. We assessed the validity of C3PO by deploying established risk models including the Pooled Cohort Equations (PCE) and the Cohorts for Aging and Genomic Epidemiology Atrial Fibrillation (CHARGE-AF) score, and compared model performance in C3PO to that observed within typical EHR Convenience Samples which included all individuals from the same parent EHR with sufficient data to calculate each score but without a requirement for longitudinal primary care. All analyses were facilitated by the JEDI Extractive Data Infrastructure pipeline which we designed to efficiently aggregate EHR data within a unified framework conducive to regular updates.

ResultsC3PO includes 520,868 individuals (mean age 48 years, 61% women, median follow-up 7.2 years, median primary care visits per individual 13). Estimated using reports, C3PO contains over 2.9 million electrocardiograms, 450,000 echocardiograms, 12,000 cardiac magnetic resonance images, and 75 million narrative notes. Using tabular data alone, 286,009 individuals (54.9%) had all vital signs available at baseline, which increased to 358,411 (68.8%) after NLP recovery (31% reduction in missingness). Among individuals with both NLP and tabular data available, NLP-extracted and tabular vital signs obtained on the same day were highly correlated (e.g., Pearson r range 0.95-0.99, p<0.01 for all). Both the PCE models (c-index range 0.724-0.770) and CHARGE-AF (c-index 0.782, 95% 0.777-0.787) demonstrated good discrimination. As compared to the Convenience Samples, AF and MI/stroke incidence rates in C3PO were lower and calibration error was smaller for both PCE (integrated calibration index range 0.012-0.030 vs. 0.028-0.046) and CHARGE-AF (0.028 vs. 0.036).

ConclusionsIntentional sampling of individuals receiving regular ambulatory care and use of NLP to recover missing data have the potential to reduce bias in EHR research and maximize generalizability of insights.",0
"Wright, L.; Paul, E.; Steptoe, A.; Fancourt, D.",2021,"Facilitators and Barriers to Compliance with COVID-19 Guidelines: A Structural Topic Modelling Analysis of Free-Text Data from 17,500 UK Adults",Epidemiology,"Facilitators and Barriers to Compliance with COVID-19 Guidelines: A Structural Topic Modelling Analysis of Free-Text Data from 17,500 UK Adults","Wright, L.; Paul, E.; Steptoe, A.; Fancourt, D.",Epidemiology,2021-07-04 00:00:00 UTC,"BackgroundDuring the COVID-19 pandemic, the UK government has implemented a series of guidelines, rules, and restrictions to change citizens behaviour to tackle the spread of the virus, such as the promotion of face-masks and the imposition of lockdown stay-at-home orders. The success of these measures requires active co-operation on the part of citizens, but compliance has not been complete. Detailed data is required on the factors aiding or hindering compliance with these measures.

MethodsTo understand the facilitators and barriers to compliance with COVID-19 guidelines, we used structural topic modelling, a text mining technique, to extract themes from over 26,000 free-text survey responses from 17,500 UK adults, collected between 17 November and 23 December 2020.

ResultsThe main factors facilitating compliance were desires to reduce risk to ones self and ones family and friends and to, a lesser extent, the general public. Also of importance were a desire to return to normality, the availability of activities and technological means to contact family and friends, and the ability to work from home. Identified barriers were difficulties maintaining social distancing in public (due to the actions of other people or environmental constraints), the need to provide or receive support from family and friends, social isolation, missing loved one, and mental health impacts, perceiving the risks as low, social pressure to not comply, and difficulties understanding and keep abreast of changing rules. Several of the barriers and facilitators raised were related to participant characteristics. Notably, women were more likely to discuss needing to provide or receive mental health support from friends and family.

ConclusionThe results demonstrate an array of factors contribute to compliance with guidelines. Of particular policy importance, the results suggest that government communications that emphasizes the potential risks of COVID-19 and provides simple, consistent guidance on how to reduce the spread of the virus would improve compliance with preventive behaviours.",10.1101/2021.06.28.21259621,virology-natural-language-processing.xlsx,"Facilitators and Barriers to Compliance with COVID-19 Guidelines: A Structural Topic Modelling Analysis of Free-Text Data from 17,500 UK Adults BackgroundDuring the COVID-19 pandemic, the UK government has implemented a series of guidelines, rules, and restrictions to change citizens behaviour to tackle the spread of the virus, such as the promotion of face-masks and the imposition of lockdown stay-at-home orders. The success of these measures requires active co-operation on the part of citizens, but compliance has not been complete. Detailed data is required on the factors aiding or hindering compliance with these measures.

MethodsTo understand the facilitators and barriers to compliance with COVID-19 guidelines, we used structural topic modelling, a text mining technique, to extract themes from over 26,000 free-text survey responses from 17,500 UK adults, collected between 17 November and 23 December 2020.

ResultsThe main factors facilitating compliance were desires to reduce risk to ones self and ones family and friends and to, a lesser extent, the general public. Also of importance were a desire to return to normality, the availability of activities and technological means to contact family and friends, and the ability to work from home. Identified barriers were difficulties maintaining social distancing in public (due to the actions of other people or environmental constraints), the need to provide or receive support from family and friends, social isolation, missing loved one, and mental health impacts, perceiving the risks as low, social pressure to not comply, and difficulties understanding and keep abreast of changing rules. Several of the barriers and facilitators raised were related to participant characteristics. Notably, women were more likely to discuss needing to provide or receive mental health support from friends and family.

ConclusionThe results demonstrate an array of factors contribute to compliance with guidelines. Of particular policy importance, the results suggest that government communications that emphasizes the potential risks of COVID-19 and provides simple, consistent guidance on how to reduce the spread of the virus would improve compliance with preventive behaviours.",1
"Wright, L.; Fluharty, M. E.; Steptoe, A.; Fancourt, D.",2022,"How did people cope during the COVID-19 pandemic? A Structural Topic Modelling Analysis of Free-Text Data from 11,000 UK Adults",Epidemiology,"How did people cope during the COVID-19 pandemic? A Structural Topic Modelling Analysis of Free-Text Data from 11,000 UK Adults","Wright, L.; Fluharty, M. E.; Steptoe, A.; Fancourt, D.",Epidemiology,2022-01-11 00:00:00 UTC,"BackgroundThe COVID-19 pandemic has had substantial impacts on lives across the globe. Job losses have been widespread, and individuals have experienced significant restrictions on their usual activities, including extended isolation from family and friends. While studies suggest population mental health worsened from before the pandemic, not all individuals appear to have experienced poorer mental health. This raises the question of how people managed to cope during the pandemic.

MethodsTo understand the coping strategies individuals employed during the COVID-19 pandemic, we used structural topic modelling, a text mining technique, to extract themes from free-text data on coping from over 11,000 UK adults, collected between 14 October and 26 November 2020.

ResultsWe identified 16 topics. The most discussed coping strategy was  thinking positively and involved themes of gratefulness and positivity. Other strategies included engaging in activities and hobbies (such as doing DIY, exercising, walking and spending time in nature), keeping routines, and focusing on one day at a time. Some participants reported more avoidant coping strategies, such as drinking alcohol and binge eating. Coping strategies varied by respondent characteristics including age, personality traits and sociodemographic characteristics and some coping strategies, such as engaging in creative activities, were associated with more positive lockdown experiences.

ConclusionA variety of coping strategies were employed by individuals during the COVID-19 pandemic. The coping strategy an individual adopted was related to their overall lockdown experiences. This may be useful for helping individuals prepare for future lockdowns or other events resulting in self-isolation.

CorrectionDue to an error in the analytical syntax, in an earlier version of this manuscript (posted August 13, 2021), topic labels in Figure 2 were mixed up. This - and the resulting discussion - have now been corrected.

O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=140 SRC=""FIGDIR/small/21262002v2_fig2.gif"" ALT=""Figure 2"">
View larger version (52K):
org.highwire.dtl.DTLVardef@62f742org.highwire.dtl.DTLVardef@15748b9org.highwire.dtl.DTLVardef@1678a2borg.highwire.dtl.DTLVardef@a04c58_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOFigure 2:C_FLOATNO Association between document topic proportion and participants age (+ 95% confidence intervals). Derived from OLS regression models including adjustment for gender, ethnicity, age, education level, living arrangement, psychiatric diagnosis, long-term physical health conditions, self-isolation status, Big-5 personality traits and keyworker status.

C_FIG",10.1101/2021.08.13.21262002,virology-natural-language-processing.xlsx,"How did people cope during the COVID-19 pandemic? A Structural Topic Modelling Analysis of Free-Text Data from 11,000 UK Adults BackgroundThe COVID-19 pandemic has had substantial impacts on lives across the globe. Job losses have been widespread, and individuals have experienced significant restrictions on their usual activities, including extended isolation from family and friends. While studies suggest population mental health worsened from before the pandemic, not all individuals appear to have experienced poorer mental health. This raises the question of how people managed to cope during the pandemic.

MethodsTo understand the coping strategies individuals employed during the COVID-19 pandemic, we used structural topic modelling, a text mining technique, to extract themes from free-text data on coping from over 11,000 UK adults, collected between 14 October and 26 November 2020.

ResultsWe identified 16 topics. The most discussed coping strategy was  thinking positively and involved themes of gratefulness and positivity. Other strategies included engaging in activities and hobbies (such as doing DIY, exercising, walking and spending time in nature), keeping routines, and focusing on one day at a time. Some participants reported more avoidant coping strategies, such as drinking alcohol and binge eating. Coping strategies varied by respondent characteristics including age, personality traits and sociodemographic characteristics and some coping strategies, such as engaging in creative activities, were associated with more positive lockdown experiences.

ConclusionA variety of coping strategies were employed by individuals during the COVID-19 pandemic. The coping strategy an individual adopted was related to their overall lockdown experiences. This may be useful for helping individuals prepare for future lockdowns or other events resulting in self-isolation.

CorrectionDue to an error in the analytical syntax, in an earlier version of this manuscript (posted August 13, 2021), topic labels in Figure 2 were mixed up. This - and the resulting discussion - have now been corrected.

O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=140 SRC=""FIGDIR/small/21262002v2_fig2.gif"" ALT=""Figure 2"">
View larger version (52K):
org.highwire.dtl.DTLVardef@62f742org.highwire.dtl.DTLVardef@15748b9org.highwire.dtl.DTLVardef@1678a2borg.highwire.dtl.DTLVardef@a04c58_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOFigure 2:C_FLOATNO Association between document topic proportion and participants age (+ 95% confidence intervals). Derived from OLS regression models including adjustment for gender, ethnicity, age, education level, living arrangement, psychiatric diagnosis, long-term physical health conditions, self-isolation status, Big-5 personality traits and keyworker status.

C_FIG",1
"Perlman-Arrow, S.; Loo, N.; Bobrovitz, N.; Yan, T.; Arora, R. K.",2022,A real-world evaluation of the implementation of NLP technology in abstract screening of a systematic review,Epidemiology,A real-world evaluation of the implementation of NLP technology in abstract screening of a systematic review,"Perlman-Arrow, S.; Loo, N.; Bobrovitz, N.; Yan, T.; Arora, R. K.",Epidemiology,2022-02-25 00:00:00 UTC,"The laborious and time-consuming nature of systematic review production hinders the dissemination of up-to-date evidence synthesis. Well-performing natural language processing (NLP) tools for systematic reviews have been developed, showing promise to improve efficiency. However, the feasibility and value of these technologies have not been comprehensively demonstrated in a real-world review. We developed an NLP-assisted abstract screening tool that provides text inclusion recommendations, keyword highlights, and visual context cues. We evaluated this tool in a living systematic review on SARS-CoV-2 seroprevalence, conducting a quality improvement assessment of screening with and without the tool. We evaluated changes to abstract screening speed, screening accuracy, characteristics of included texts, and user satisfaction. The tool improved efficiency, reducing screening time per abstract by 45.9% and decreasing inter-reviewer conflict rates. The tool conserved precision of article inclusion (positive predictive value; 0.92 with tool vs 0.88 without) and recall (sensitivity; 0.90 vs 0.81). The summary statistics of included studies were similar with and without the tool. Users were satisfied with the tool (mean satisfaction score of 4.2/5). We evaluated an abstract screening process where one human reviewer was replaced with the tools votes, finding that this maintained recall (0.92 one-person, one-tool vs 0.90 two tool-assisted humans) and precision (0.91 vs 0.92) while reducing screening time by 70%. Implementing an NLP tool in this living systematic review improved efficiency, maintained accuracy, and was well-received by researchers, demonstrating the real-world effectiveness of NLP in expediting evidence synthesis.",10.1101/2022.02.24.22268947,virology-natural-language-processing.xlsx,"A real-world evaluation of the implementation of NLP technology in abstract screening of a systematic review The laborious and time-consuming nature of systematic review production hinders the dissemination of up-to-date evidence synthesis. Well-performing natural language processing (NLP) tools for systematic reviews have been developed, showing promise to improve efficiency. However, the feasibility and value of these technologies have not been comprehensively demonstrated in a real-world review. We developed an NLP-assisted abstract screening tool that provides text inclusion recommendations, keyword highlights, and visual context cues. We evaluated this tool in a living systematic review on SARS-CoV-2 seroprevalence, conducting a quality improvement assessment of screening with and without the tool. We evaluated changes to abstract screening speed, screening accuracy, characteristics of included texts, and user satisfaction. The tool improved efficiency, reducing screening time per abstract by 45.9% and decreasing inter-reviewer conflict rates. The tool conserved precision of article inclusion (positive predictive value; 0.92 with tool vs 0.88 without) and recall (sensitivity; 0.90 vs 0.81). The summary statistics of included studies were similar with and without the tool. Users were satisfied with the tool (mean satisfaction score of 4.2/5). We evaluated an abstract screening process where one human reviewer was replaced with the tools votes, finding that this maintained recall (0.92 one-person, one-tool vs 0.90 two tool-assisted humans) and precision (0.91 vs 0.92) while reducing screening time by 70%. Implementing an NLP tool in this living systematic review improved efficiency, maintained accuracy, and was well-received by researchers, demonstrating the real-world effectiveness of NLP in expediting evidence synthesis.",1
"Bejan, C. A.; Ripperger, M.; Wilimitis, D.; Ahmed, R.; Kang, J.; Robinson, K.; Morley, T. J.; Ruderfer, D. M.; Walsh, C. G.",2022,Improving ascertainment of suicidal ideation and suicide attempt with natural language processing,Epidemiology,Improving ascertainment of suicidal ideation and suicide attempt with natural language processing,"Bejan, C. A.; Ripperger, M.; Wilimitis, D.; Ahmed, R.; Kang, J.; Robinson, K.; Morley, T. J.; Ruderfer, D. M.; Walsh, C. G.",Epidemiology,2022-02-27 00:00:00 UTC,"Methods relying on diagnostic codes to identify suicidal ideation and suicide attempt in Electronic Health Records (EHRs) at scale are suboptimal because these phenotypes are heavily under-coded. We propose to improve the ascertainment of suicide phenotypes using natural language processing (NLP). We developed information retrieval methodologies to search over 200 million notes from the Vanderbilt EHR. Suicide query terms were extracted using word2vec. A weakly supervised approach was designed to label cases of suicidal outcomes. The NLP validation of the top 200 retrieved patients showed high performance for suicidal ideation (area under the receiver operator curve [AUROC]: 98.6, 95% confidence interval [CI]: 97.1-99.5) and suicide attempt (AUROC: 97.3, 95% CI: 95.2-98.7). Case extraction produced the best performance when combining NLP and diagnostic codes and when accounting for negated suicide expressions in notes. Overall, we demonstrated that scalable and accurate NLP methods can be developed to identify suicide phenotypes in EHRs to enhance prevention efforts, predictive models, and precision medicine.",10.1101/2022.02.25.22271532,virology-natural-language-processing.xlsx,"Improving ascertainment of suicidal ideation and suicide attempt with natural language processing Methods relying on diagnostic codes to identify suicidal ideation and suicide attempt in Electronic Health Records (EHRs) at scale are suboptimal because these phenotypes are heavily under-coded. We propose to improve the ascertainment of suicide phenotypes using natural language processing (NLP). We developed information retrieval methodologies to search over 200 million notes from the Vanderbilt EHR. Suicide query terms were extracted using word2vec. A weakly supervised approach was designed to label cases of suicidal outcomes. The NLP validation of the top 200 retrieved patients showed high performance for suicidal ideation (area under the receiver operator curve [AUROC]: 98.6, 95% confidence interval [CI]: 97.1-99.5) and suicide attempt (AUROC: 97.3, 95% CI: 95.2-98.7). Case extraction produced the best performance when combining NLP and diagnostic codes and when accounting for negated suicide expressions in notes. Overall, we demonstrated that scalable and accurate NLP methods can be developed to identify suicide phenotypes in EHRs to enhance prevention efforts, predictive models, and precision medicine.",0
"Zavalis, E. A.; Ioannidis, J.",2022,A meta-epidemiological assessment of transparency indicators of infectious disease models,Epidemiology,A meta-epidemiological assessment of transparency indicators of infectious disease models,"Zavalis, E. A.; Ioannidis, J.",Epidemiology,2022-04-16 00:00:00 UTC,"Mathematical models have become very influential, especially during the COVID-19 pandemic. Data and code sharing are indispensable for reproducing them, protocol registration may be useful sometimes, and declarations of conflicts of interest (COIs) and of funding are quintessential for transparency. Here, we evaluated these features in publications of infectious disease-related models and assessed whether there were differences before and during the COVID-19 pandemic and for COVID-19 models versus models for other diseases. We analysed all PubMed Central open access publications of infectious disease models published in 2019 and 2021 using previously validated text mining algorithms of transparency indicators. We evaluated 1338 articles: 216 from 2019 and 1122 from 2021 (of which 818 were on COVID-19); almost a six-fold increase in publications within the field. 511 (39.2%) were compartmental models, 337 (25.2%) were time series, 279 (20.9%) were spatiotemporal, 186 (13.9%) were agent-based and 25 (1.9%) contained multiple model types. 288 (21.5%) articles shared code, 332 (24.8%) shared data, 6 (0.4%) were registered, and 1197 (89.5%) and 1109 (82.9%) contained COI and funding statements, respectively. There was no major changes in transparency indicators between 2019 and 2021. COVID-19 articles were less likely to have funding statements and more likely to share code. Manual assessment of 10% of the articles that were identified by the text mining algorithms as fulfilling transparency indicators showed that 24/29 (82.8%) actually shared code, 29/33 (87.9%) actually shared data; and all had COI and funding statements, but 95.8% disclosed no conflict and 11.7% reported no funding. On manual assessment, 5/6 articles identified as registered had indeed been registered. Transparency in infectious disease modelling is relatively low, especially for data and code sharing. This is concerning, considering the nature of this research and the heightened influence it has acquired.",10.1101/2022.04.11.22273744,virology-natural-language-processing.xlsx,"A meta-epidemiological assessment of transparency indicators of infectious disease models Mathematical models have become very influential, especially during the COVID-19 pandemic. Data and code sharing are indispensable for reproducing them, protocol registration may be useful sometimes, and declarations of conflicts of interest (COIs) and of funding are quintessential for transparency. Here, we evaluated these features in publications of infectious disease-related models and assessed whether there were differences before and during the COVID-19 pandemic and for COVID-19 models versus models for other diseases. We analysed all PubMed Central open access publications of infectious disease models published in 2019 and 2021 using previously validated text mining algorithms of transparency indicators. We evaluated 1338 articles: 216 from 2019 and 1122 from 2021 (of which 818 were on COVID-19); almost a six-fold increase in publications within the field. 511 (39.2%) were compartmental models, 337 (25.2%) were time series, 279 (20.9%) were spatiotemporal, 186 (13.9%) were agent-based and 25 (1.9%) contained multiple model types. 288 (21.5%) articles shared code, 332 (24.8%) shared data, 6 (0.4%) were registered, and 1197 (89.5%) and 1109 (82.9%) contained COI and funding statements, respectively. There was no major changes in transparency indicators between 2019 and 2021. COVID-19 articles were less likely to have funding statements and more likely to share code. Manual assessment of 10% of the articles that were identified by the text mining algorithms as fulfilling transparency indicators showed that 24/29 (82.8%) actually shared code, 29/33 (87.9%) actually shared data; and all had COI and funding statements, but 95.8% disclosed no conflict and 11.7% reported no funding. On manual assessment, 5/6 articles identified as registered had indeed been registered. Transparency in infectious disease modelling is relatively low, especially for data and code sharing. This is concerning, considering the nature of this research and the heightened influence it has acquired.",1
"Shah, A. D.; Subramanian, A. D.; Lewis, J.; Dhalla, S.; Ford, E.; Haroon, S.; Kuan, V.; Nirantharakumar, K.",2023,Long Covid symptoms and diagnosis in primary care: a cohort study using structured and unstructured data in The Health Improvement Network primary care database,Epidemiology,Long Covid symptoms and diagnosis in primary care: a cohort study using structured and unstructured data in The Health Improvement Network primary care database,"Shah, A. D.; Subramanian, A. D.; Lewis, J.; Dhalla, S.; Ford, E.; Haroon, S.; Kuan, V.; Nirantharakumar, K.",Epidemiology,2023-01-09 00:00:00 UTC,"BACKGROUNDLong Covid is a widely recognised consequence of COVID-19 infection, but little is known about the burden of symptoms that patients present with in primary care, as these are typically recorded only in free text clinical notes. Our objectives were to compare symptoms in patients with and without a history of COVID-19, and investigate symptoms associated with a Long Covid diagnosis.

METHODSWe used primary care electronic health record data from The Health Improvement Network (THIN), a Cegedim database. We included adults registered with participating practices in England, Scotland or Wales. We extracted information about 89 symptoms and  Long Covid diagnoses from free text using natural language processing. We calculated hazard ratios (adjusted for age, sex, baseline medical conditions and prior symptoms) for each symptom from 12 weeks after the COVID-19 diagnosis.

FINDINGSWe compared 11,015 patients with confirmed COVID-19 and 18,098 unexposed controls. Only 20% of symptom records were coded, with 80% in free text. A wide range of symptoms were associated with COVID-19 at least 12 weeks post-infection, with strongest associations for fatigue (adjusted hazard ratio (aHR) 3.99, 95% confidence interval (CI) 3.59, 4.44), shortness of breath (aHR 3.14, 95% CI 2.88, 3.42), palpitations (aHR 2.75, 95% CI 2.28, 3.32), and phlegm (aHR 2.88, 95% CI 2.30, 3.61). However, a limited subset of symptoms were recorded within 7 days prior to a Long Covid diagnosis in more than 20% of cases: shortness of breath, chest pain, pain, fatigue, cough, and anxiety / depression.

CONCLUSIONNumerous symptoms are reported to primary care at least 12 weeks after COVID-19 infection, but only a subset are commonly associated with a GP diagnosis of Long Covid.",10.1101/2023.01.06.23284202,virology-natural-language-processing.xlsx,"Long Covid symptoms and diagnosis in primary care: a cohort study using structured and unstructured data in The Health Improvement Network primary care database BACKGROUNDLong Covid is a widely recognised consequence of COVID-19 infection, but little is known about the burden of symptoms that patients present with in primary care, as these are typically recorded only in free text clinical notes. Our objectives were to compare symptoms in patients with and without a history of COVID-19, and investigate symptoms associated with a Long Covid diagnosis.

METHODSWe used primary care electronic health record data from The Health Improvement Network (THIN), a Cegedim database. We included adults registered with participating practices in England, Scotland or Wales. We extracted information about 89 symptoms and  Long Covid diagnoses from free text using natural language processing. We calculated hazard ratios (adjusted for age, sex, baseline medical conditions and prior symptoms) for each symptom from 12 weeks after the COVID-19 diagnosis.

FINDINGSWe compared 11,015 patients with confirmed COVID-19 and 18,098 unexposed controls. Only 20% of symptom records were coded, with 80% in free text. A wide range of symptoms were associated with COVID-19 at least 12 weeks post-infection, with strongest associations for fatigue (adjusted hazard ratio (aHR) 3.99, 95% confidence interval (CI) 3.59, 4.44), shortness of breath (aHR 3.14, 95% CI 2.88, 3.42), palpitations (aHR 2.75, 95% CI 2.28, 3.32), and phlegm (aHR 2.88, 95% CI 2.30, 3.61). However, a limited subset of symptoms were recorded within 7 days prior to a Long Covid diagnosis in more than 20% of cases: shortness of breath, chest pain, pain, fatigue, cough, and anxiety / depression.

CONCLUSIONNumerous symptoms are reported to primary care at least 12 weeks after COVID-19 infection, but only a subset are commonly associated with a GP diagnosis of Long Covid.",1
"Davidson, E. M.; Casey, A.; Grover, C.; Alex, B.; Wu, H.; Campbell, A.; Chalmers, F.; Adams, M.; Iveson, M.; Mcintosh, A.; Ball, E.; Rannikmae, K.; Whalley, H.; Whiteley, W. N.",2023,The epidemiological characteristics of stroke phenotypes defined with ICD-10 and free-text in a linked cohort study,Epidemiology,The epidemiological characteristics of stroke phenotypes defined with ICD-10 and free-text in a linked cohort study,"Davidson, E. M.; Casey, A.; Grover, C.; Alex, B.; Wu, H.; Campbell, A.; Chalmers, F.; Adams, M.; Iveson, M.; Mcintosh, A.; Ball, E.; Rannikmae, K.; Whalley, H.; Whiteley, W. N.",Epidemiology,2023-04-04 00:00:00 UTC,"BackgroundCoded healthcare data may not capture all stroke cases and has limited accuracy for stroke subtypes. We sought to determine the incremental value of adding natural language processing (NLP) of free-text radiology reports to international classification of disease (ICD-10) codes to phenotype stroke, and stroke subtypes, in routinely collected healthcare datasets.

MethodsWe linked participants in a community-based prospective cohort study, Generation Scotland, to clinical brain imaging reports (2008-2020) from five Scottish health boards. We used five combinations of NLP outputs and ICD-10 codes to define stroke phenotypes. With these phenotype models we measured the: stroke incidence standardised to a European Standardised Population; adjusted hazard ratio (aHR) of baseline hypertension for later stroke; and proportion of participants allocated stroke subtypes.

ResultsOf 19,026 participants, over a mean follow-up of 10.2 years, 1938 had 3493 brain scans. Any stroke was identified in 534 participants: 319 with NLP alone, 59 with ICD-10 codes alone and 156 with both ICD-10 codes and an NLP report consistent with stroke. The stroke aHR for baseline hypertension was 1.47 (95%CI: 1.12-1.92) for NLP-defined stroke only; 1.57 (95%CI: 1.18-2.10) for ICD-10 defined stroke only; and 1.81 (95%CI: 1.20-2.72) for cases with ICD 10 stroke codes and NLP stroke phenotypes. The age-standardised incidence of stroke for these phenotype models was 1.35, 1.34, and 0.65 per 1000 person years, respectively. The proportion of strokes not subtyped was 26% (57/215) using only ICD-10, 9% (42/467) using only NLP, and 12% (65/534) using both NLP and ICD-10.

ConclusionsAddition of NLP derived phenotypes to ICD-10 stroke codes identified approximately 2.5 times more stroke cases and greatly increased the proportion with subtyping. The phenotype model using ICD 10 stroke codes and NLP stroke phenotypes had the strongest association with baseline hypertension. This information is relevant to large cohort studies and clinical trials that use routine electronic health records for outcome ascertainment.",10.1101/2023.04.03.23288096,virology-natural-language-processing.xlsx,"The epidemiological characteristics of stroke phenotypes defined with ICD-10 and free-text in a linked cohort study BackgroundCoded healthcare data may not capture all stroke cases and has limited accuracy for stroke subtypes. We sought to determine the incremental value of adding natural language processing (NLP) of free-text radiology reports to international classification of disease (ICD-10) codes to phenotype stroke, and stroke subtypes, in routinely collected healthcare datasets.

MethodsWe linked participants in a community-based prospective cohort study, Generation Scotland, to clinical brain imaging reports (2008-2020) from five Scottish health boards. We used five combinations of NLP outputs and ICD-10 codes to define stroke phenotypes. With these phenotype models we measured the: stroke incidence standardised to a European Standardised Population; adjusted hazard ratio (aHR) of baseline hypertension for later stroke; and proportion of participants allocated stroke subtypes.

ResultsOf 19,026 participants, over a mean follow-up of 10.2 years, 1938 had 3493 brain scans. Any stroke was identified in 534 participants: 319 with NLP alone, 59 with ICD-10 codes alone and 156 with both ICD-10 codes and an NLP report consistent with stroke. The stroke aHR for baseline hypertension was 1.47 (95%CI: 1.12-1.92) for NLP-defined stroke only; 1.57 (95%CI: 1.18-2.10) for ICD-10 defined stroke only; and 1.81 (95%CI: 1.20-2.72) for cases with ICD 10 stroke codes and NLP stroke phenotypes. The age-standardised incidence of stroke for these phenotype models was 1.35, 1.34, and 0.65 per 1000 person years, respectively. The proportion of strokes not subtyped was 26% (57/215) using only ICD-10, 9% (42/467) using only NLP, and 12% (65/534) using both NLP and ICD-10.

ConclusionsAddition of NLP derived phenotypes to ICD-10 stroke codes identified approximately 2.5 times more stroke cases and greatly increased the proportion with subtyping. The phenotype model using ICD 10 stroke codes and NLP stroke phenotypes had the strongest association with baseline hypertension. This information is relevant to large cohort studies and clinical trials that use routine electronic health records for outcome ascertainment.",0
"Aronis, J. M.; Ye, Y.; Espino, J.; Hochheiser, H.; Michaels, M. G.; Cooper, G. F.",2023,A Bayesian System to Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases,Epidemiology,A Bayesian System to Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases,"Aronis, J. M.; Ye, Y.; Espino, J.; Hochheiser, H.; Michaels, M. G.; Cooper, G. F.",Epidemiology,2023-05-16 00:00:00 UTC,"It would be highly desirable to have a tool that detects the outbreak of a new influenza-like illness, such as COVID-19, accurately and early. This paper describes the ILI Tracker algorithm that first models the daily occurrence of a set of known influenza-like illnesses in a hospital emergency department using findings extracted from patient-care reports using natural language processing. We include results based on modeling the diseases influenza, respiratory syncytial virus, human metapneumovirus, and parainfluenza for five emergency departments in Allegheny County Pennsylvania from June 1, 2010 through May 31, 2015. We then show how the algorithm can be extended to detect the presence of an unmodeled disease which may represent a novel disease outbreak. We also include results for detecting an outbreak of an unmodeled disease during the mentioned time period, which in retrospect was very likely an outbreak of Enterovirus D68.",10.1101/2023.05.10.23289799,virology-natural-language-processing.xlsx,"A Bayesian System to Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases It would be highly desirable to have a tool that detects the outbreak of a new influenza-like illness, such as COVID-19, accurately and early. This paper describes the ILI Tracker algorithm that first models the daily occurrence of a set of known influenza-like illnesses in a hospital emergency department using findings extracted from patient-care reports using natural language processing. We include results based on modeling the diseases influenza, respiratory syncytial virus, human metapneumovirus, and parainfluenza for five emergency departments in Allegheny County Pennsylvania from June 1, 2010 through May 31, 2015. We then show how the algorithm can be extended to detect the presence of an unmodeled disease which may represent a novel disease outbreak. We also include results for detecting an outbreak of an unmodeled disease during the mentioned time period, which in retrospect was very likely an outbreak of Enterovirus D68.",1
"Beaney, T.; Clarke, J.; Salman, D.; Woodcock, T.; Majeed, A.; Aylin, P.; Barahona, M.",2023,Identifying multi-resolution clusters of diseases in ten million patients with multimorbidity in primary care in England,Epidemiology,Identifying multi-resolution clusters of diseases in ten million patients with multimorbidity in primary care in England,"Beaney, T.; Clarke, J.; Salman, D.; Woodcock, T.; Majeed, A.; Aylin, P.; Barahona, M.",Epidemiology,2023-06-30 00:00:00 UTC,"Identifying clusters of co-occurring diseases can aid understanding of shared aetiology, management of co-morbidities, and the discovery of new disease associations. Here, we use data from a population of over ten million people with multimorbidity registered to primary care in England to identify disease clusters through a two-stage process. First, we extract data-driven representations of 212 diseases from patient records employing i) co-occurrence-based methods and ii) sequence-based natural language processing methods. Second, we apply multiscale graph-based clustering to identify clusters based on disease similarity at multiple resolutions, which outperforms k-means and hierarchical clustering in explaining known disease associations. We find that diseases display an almost-hierarchical structure across resolutions from closely to more loosely similar co-occurrence patterns and identify interpretable clusters corresponding to both established and novel patterns. Our method provides a tool for clustering diseases at different levels of resolution from co-occurrence patterns in high-dimensional electronic healthcare record data.",10.1101/2023.06.30.23292080,virology-natural-language-processing.xlsx,"Identifying multi-resolution clusters of diseases in ten million patients with multimorbidity in primary care in England Identifying clusters of co-occurring diseases can aid understanding of shared aetiology, management of co-morbidities, and the discovery of new disease associations. Here, we use data from a population of over ten million people with multimorbidity registered to primary care in England to identify disease clusters through a two-stage process. First, we extract data-driven representations of 212 diseases from patient records employing i) co-occurrence-based methods and ii) sequence-based natural language processing methods. Second, we apply multiscale graph-based clustering to identify clusters based on disease similarity at multiple resolutions, which outperforms k-means and hierarchical clustering in explaining known disease associations. We find that diseases display an almost-hierarchical structure across resolutions from closely to more loosely similar co-occurrence patterns and identify interpretable clusters corresponding to both established and novel patterns. Our method provides a tool for clustering diseases at different levels of resolution from co-occurrence patterns in high-dimensional electronic healthcare record data.",0
"Weissenbacher, D.; O'connor, K.; Klein, A.; Golder, S.; Flores Amaro, I.; Elyaderani, A.; Scotch, M.; Gonzalez-Hernandez, G.",2023,Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,Epidemiology,Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,"Weissenbacher, D.; O'connor, K.; Klein, A.; Golder, S.; Flores Amaro, I.; Elyaderani, A.; Scotch, M.; Gonzalez-Hernandez, G.",Epidemiology,2023-08-04 00:00:00 UTC,"There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GI-SAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.",10.1101/2023.07.29.23293370,virology-natural-language-processing.xlsx,"Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GI-SAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.",1
"Maiorino, E.; De Marzio, M.; Xu, Z.; Yun, J.; Chase, R.; Hersh, C. P.; Weiss, S.; Silverman, E.; Castaldi, P.; Glass, K.",2024,JOINT CLINICAL AND MOLECULAR SUBTYPING OF COPD WITH VARIATIONAL AUTOENCODERS,Respiratory Medicine,JOINT CLINICAL AND MOLECULAR SUBTYPING OF COPD WITH VARIATIONAL AUTOENCODERS,"Maiorino, E.; De Marzio, M.; Xu, Z.; Yun, J.; Chase, R.; Hersh, C. P.; Weiss, S.; Silverman, E.; Castaldi, P.; Glass, K.",Respiratory Medicine,2024-01-10 00:00:00 UTC,"Chronic Obstructive Pulmonary Disease (COPD) is a complex, heterogeneous disease. Traditional subtyping methods generally focus on either the clinical manifestations or the molecular endotypes of the disease, resulting in classifications that do not fully capture the diseases complexity. Here, we bridge this gap by introducing a subtyping pipeline that integrates clinical and gene expression data with variational autoencoders. We apply this methodology to the COPDGene study, a large study of current and former smoking individuals with and without COPD. Our approach generates a set of vector embeddings, called Personalized Integrated Profiles (PIPs), that recapitulate the joint clinical and molecular state of the subjects in the study. Prediction experiments show that the PIPs have a predictive accuracy comparable to or better than other embedding approaches. Using trajectory learning approaches, we analyze the main trajectories of variation in the PIP space and identify five well-separated subtypes with distinct clinical phenotypes, expression signatures, and disease outcomes. Notably, these subtypes are more robust to data resampling compared to those identified using traditional clustering approaches. Overall, our findings provide new avenues to establish fine-grained associations between the clinical characteristics, molecular processes, and disease outcomes of COPD.",10.1101/2023.08.19.23294298,virology-natural-language-processing.xlsx,"JOINT CLINICAL AND MOLECULAR SUBTYPING OF COPD WITH VARIATIONAL AUTOENCODERS Chronic Obstructive Pulmonary Disease (COPD) is a complex, heterogeneous disease. Traditional subtyping methods generally focus on either the clinical manifestations or the molecular endotypes of the disease, resulting in classifications that do not fully capture the diseases complexity. Here, we bridge this gap by introducing a subtyping pipeline that integrates clinical and gene expression data with variational autoencoders. We apply this methodology to the COPDGene study, a large study of current and former smoking individuals with and without COPD. Our approach generates a set of vector embeddings, called Personalized Integrated Profiles (PIPs), that recapitulate the joint clinical and molecular state of the subjects in the study. Prediction experiments show that the PIPs have a predictive accuracy comparable to or better than other embedding approaches. Using trajectory learning approaches, we analyze the main trajectories of variation in the PIP space and identify five well-separated subtypes with distinct clinical phenotypes, expression signatures, and disease outcomes. Notably, these subtypes are more robust to data resampling compared to those identified using traditional clustering approaches. Overall, our findings provide new avenues to establish fine-grained associations between the clinical characteristics, molecular processes, and disease outcomes of COPD.",0
"Otte, W. M.; Van Ijzendoorn, D. G.; Habets, P. C.; Vinkers, C. H.",2024,Fast clinical trial identification using fuzzy-search elastic searches: retrospective validation with high-quality Cochrane benchmark,Epidemiology,Fast clinical trial identification using fuzzy-search elastic searches: retrospective validation with high-quality Cochrane benchmark,"Otte, W. M.; Van Ijzendoorn, D. G.; Habets, P. C.; Vinkers, C. H.",Epidemiology,2024-12-21 00:00:00 UTC,"The synthesis of treatment effects relies on systematic reviews of intervention trials. This process is often laborious due to the need for precise search queries and manual study identification. Recent advancements in database architecture and natural language processing (NLP) offer a potential solution by enabling faster, more flexible searches and automated extraction of information from unstructured texts.

Our study assesses the effectiveness of NLP-based literature searches within a novel database structure in comparison to the Cochrane Database of Systematic Reviews. We created a user-friendly elastic search database containing 36 million PubMed-indexed entries. We developed reliable filters for identifying randomized clinical trials and clinical intervention studies, as well as extracting relevant subtext related to population and intervention.

Our results indicate a high precision of 0.74, recall of 0.81, and F1-score of 0.77 for population subtext, and a precision of 0.70, recall of 0.71, and an F1-score of 0.70 for intervention subtext. Our approach efficiently identified included studies in 90% of systematic reviews, missing no more than two trials compared to Cochrane. Furthermore, it produced fewer total hits than a comparable PubMed keyword search, demonstrating the potential of the new database structure to enhance the efficiency and effectiveness of aggregating clinical evidence.",10.1101/2023.09.06.23295135,virology-natural-language-processing.xlsx,"Fast clinical trial identification using fuzzy-search elastic searches: retrospective validation with high-quality Cochrane benchmark The synthesis of treatment effects relies on systematic reviews of intervention trials. This process is often laborious due to the need for precise search queries and manual study identification. Recent advancements in database architecture and natural language processing (NLP) offer a potential solution by enabling faster, more flexible searches and automated extraction of information from unstructured texts.

Our study assesses the effectiveness of NLP-based literature searches within a novel database structure in comparison to the Cochrane Database of Systematic Reviews. We created a user-friendly elastic search database containing 36 million PubMed-indexed entries. We developed reliable filters for identifying randomized clinical trials and clinical intervention studies, as well as extracting relevant subtext related to population and intervention.

Our results indicate a high precision of 0.74, recall of 0.81, and F1-score of 0.77 for population subtext, and a precision of 0.70, recall of 0.71, and an F1-score of 0.70 for intervention subtext. Our approach efficiently identified included studies in 90% of systematic reviews, missing no more than two trials compared to Cochrane. Furthermore, it produced fewer total hits than a comparable PubMed keyword search, demonstrating the potential of the new database structure to enhance the efficiency and effectiveness of aggregating clinical evidence.",0
"Lu, Y.; Hamilton, R.; Greenburg, J.; Srinivasan, G.; Shah, P.; Preum, S.; Pettus, J.; Vaickus, L.; Levy, J.",2023,"Dendrite: A Structured, Accessible, and Queryable Pathology Search Database for Streamlined Experiment Planning",Pathology,"Dendrite: A Structured, Accessible, and Queryable Pathology Search Database for Streamlined Experiment Planning","Lu, Y.; Hamilton, R.; Greenburg, J.; Srinivasan, G.; Shah, P.; Preum, S.; Pettus, J.; Vaickus, L.; Levy, J.",Pathology,2023-09-10 00:00:00 UTC,"Pathology reports contain vital information, yet a significant portion of this data remains underutilized in electronic medical record systems due to the unstructured and varied nature of reporting. Although synoptic reporting has introduced reporting standards, the majority of pathology text remains free-form, necessitating additional processing to enable accessibility for research and clinical applications. This paper presents Dendrite, a web application designed to enhance pathology research by providing intelligent search capabilities and streamlining the creation of study cohorts. Leveraging expert knowledge and natural language processing algorithms, Dendrite converts free-form pathology reports into structured formats, facilitating easier querying and analysis. Using a custom Python script, Dendrite organizes pathology report data, enabling record linkages, text searches, and structured drop-down menus for information filtering and integration. A companion web application enables data exploration and export, showcasing its potential for further analysis and research. Dendrite, derived from existing laboratory information systems, outperforms existing implementations in terms of speed, responsiveness, and flexibility. With its efficient search functionality and support for clinical research and quality improvement efforts in the pathology field, Dendrite proves to be a valuable tool for pathologists. Future enhancements encompass user management integration, integration of natural language processing and machine learning to enhance structured reporting capabilities and seamless integration of Dendrite with the vast repository of genomics and imaging data.",10.1101/2023.09.09.23295302,virology-natural-language-processing.xlsx,"Dendrite: A Structured, Accessible, and Queryable Pathology Search Database for Streamlined Experiment Planning Pathology reports contain vital information, yet a significant portion of this data remains underutilized in electronic medical record systems due to the unstructured and varied nature of reporting. Although synoptic reporting has introduced reporting standards, the majority of pathology text remains free-form, necessitating additional processing to enable accessibility for research and clinical applications. This paper presents Dendrite, a web application designed to enhance pathology research by providing intelligent search capabilities and streamlining the creation of study cohorts. Leveraging expert knowledge and natural language processing algorithms, Dendrite converts free-form pathology reports into structured formats, facilitating easier querying and analysis. Using a custom Python script, Dendrite organizes pathology report data, enabling record linkages, text searches, and structured drop-down menus for information filtering and integration. A companion web application enables data exploration and export, showcasing its potential for further analysis and research. Dendrite, derived from existing laboratory information systems, outperforms existing implementations in terms of speed, responsiveness, and flexibility. With its efficient search functionality and support for clinical research and quality improvement efforts in the pathology field, Dendrite proves to be a valuable tool for pathologists. Future enhancements encompass user management integration, integration of natural language processing and machine learning to enhance structured reporting capabilities and seamless integration of Dendrite with the vast repository of genomics and imaging data.",0
"Klein, A. Z.; Kunatharaju, S.; Golder, S.; Levine, L. D.; Figueiredo, J. C.; Gonzalez-Hernandez, G.",2023,Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data,Epidemiology,Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data,"Klein, A. Z.; Kunatharaju, S.; Golder, S.; Levine, L. D.; Figueiredo, J. C.; Gonzalez-Hernandez, G.",Epidemiology,2023-11-21 00:00:00 UTC,"BackgroundPreterm birth, defined as birth at <37 weeks of gestation, is the leading cause of neonatal death globally and, together with low birthweight, the second leading cause of infant mortality in the United States. There is mounting evidence that COVID-19 infection during pregnancy is associated with an increased risk of preterm birth; however, data remain limited by trimester of infection. The ability to study COVID-19 infection during the earlier stages of pregnancy has been limited by available sources of data. The objective of this study was to use self-reports in large-scale, longitudinal social media data to assess the association between trimester of COVID-19 infection and preterm birth.

MethodsIn this retrospective cohort study, we used natural language processing and machine learning, followed by manual validation, to identify pregnant Twitter users and to search their longitudinal collection of publicly available tweets for reports of COVID-19 infection during pregnancy and, subsequently, a preterm birth or term birth (i.e., a gestational age [&ge;]37 weeks) outcome. Among the users who reported their pregnancy on Twitter, we also identified a 1:1 age-matched control group, consisting of users with a due date prior to January 1, 2020--that is, without COVID-19 infection during pregnancy. We calculated the odds ratios (ORs) with 95% confidence intervals (CIs) to compare the overall rates of preterm birth for pregnancies with and without COVID-19 infection and by timing of infection: first trimester (weeks 1-13), second trimester (weeks 14-27), or third trimester (weeks 28-36).

ResultsThrough August 2022, we identified 298 Twitter users who reported COVID-19 infection during pregnancy, a preterm birth or term birth outcome, and maternal age: 94 (31.5%) with first-trimester infection, 110 (36.9%) second-trimester infection, and 95 (31.9%) third-trimester infection. In total, 26 (8.8%) of these 298 users reported preterm birth: 8 (8.5%) were infected during the first trimester, 7 (6.4%) were infected during the second trimester, and 12 (12.6%) were infected during the third trimester. In the 1:1 age-matched control group, 13 (4.4%) of the 298 users reported preterm birth. Overall, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection compared to those without (OR 2.1, 95% CI 1.06-4.16). In particular, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection during the third trimester (OR 3.17, CI 1.39-7.21).

ConclusionThe results of our study suggest that COVID-19 infection particularly during the third trimester is associated with an increased risk of preterm birth.",10.1101/2023.11.17.23298696,virology-natural-language-processing.xlsx,"Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data BackgroundPreterm birth, defined as birth at <37 weeks of gestation, is the leading cause of neonatal death globally and, together with low birthweight, the second leading cause of infant mortality in the United States. There is mounting evidence that COVID-19 infection during pregnancy is associated with an increased risk of preterm birth; however, data remain limited by trimester of infection. The ability to study COVID-19 infection during the earlier stages of pregnancy has been limited by available sources of data. The objective of this study was to use self-reports in large-scale, longitudinal social media data to assess the association between trimester of COVID-19 infection and preterm birth.

MethodsIn this retrospective cohort study, we used natural language processing and machine learning, followed by manual validation, to identify pregnant Twitter users and to search their longitudinal collection of publicly available tweets for reports of COVID-19 infection during pregnancy and, subsequently, a preterm birth or term birth (i.e., a gestational age [&ge;]37 weeks) outcome. Among the users who reported their pregnancy on Twitter, we also identified a 1:1 age-matched control group, consisting of users with a due date prior to January 1, 2020--that is, without COVID-19 infection during pregnancy. We calculated the odds ratios (ORs) with 95% confidence intervals (CIs) to compare the overall rates of preterm birth for pregnancies with and without COVID-19 infection and by timing of infection: first trimester (weeks 1-13), second trimester (weeks 14-27), or third trimester (weeks 28-36).

ResultsThrough August 2022, we identified 298 Twitter users who reported COVID-19 infection during pregnancy, a preterm birth or term birth outcome, and maternal age: 94 (31.5%) with first-trimester infection, 110 (36.9%) second-trimester infection, and 95 (31.9%) third-trimester infection. In total, 26 (8.8%) of these 298 users reported preterm birth: 8 (8.5%) were infected during the first trimester, 7 (6.4%) were infected during the second trimester, and 12 (12.6%) were infected during the third trimester. In the 1:1 age-matched control group, 13 (4.4%) of the 298 users reported preterm birth. Overall, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection compared to those without (OR 2.1, 95% CI 1.06-4.16). In particular, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection during the third trimester (OR 3.17, CI 1.39-7.21).

ConclusionThe results of our study suggest that COVID-19 infection particularly during the third trimester is associated with an increased risk of preterm birth.",1
"Bellomo, R. K.; Ioannidis, J.; Zavalis, E. A.",2023,Assessment of transparency indicators in Space Medicine,Epidemiology,Assessment of transparency indicators in Space Medicine,"Bellomo, R. K.; Ioannidis, J.; Zavalis, E. A.",Epidemiology,2023-12-01 00:00:00 UTC,"Space medicine is a vital discipline with often time-intensive and costly projects and constrained opportunities for studying various elements such as space missions, astronauts, and simulated environments. Moreover, private interests gain increasing influence in this discipline. In scientific disciplines with these features, transparent and rigorous methods are essential. Here, we undertook an evaluation of transparency indicators in publications within the field of space medicine. A meta-epidemiological assessment of PubMed Central Open Access (PMC OA) eligible articles within the field of space medicine was performed for prevalence of code sharing, data sharing, pre-registration, conflicts of interest, and funding. Text mining was performed with the rtransparent text mining algorithms with manual validation of 200 random articles to obtain corrected estimates. Across 1215 included articles, 39 (3%) shared code, 258 (21%) shared data, 10 (1%) were registered, 110 (90%) contained a conflict-of-interest statement, and 1141 (93%) included a funding statement. After manual validation, the corrected estimates for code sharing, data sharing, and registration were 5%, 27%, and 1%, respectively. Data sharing was 32% when limited to original articles and highest in space/parabolic flights (46%). Overall, across space medicine we observed modest rates of data sharing, rare sharing of code and almost non-existent protocol registration. Enhancing transparency in space medicine research is imperative for safeguarding its scientific rigor and reproducibility.",10.1101/2023.12.01.23299278,virology-natural-language-processing.xlsx,"Assessment of transparency indicators in Space Medicine Space medicine is a vital discipline with often time-intensive and costly projects and constrained opportunities for studying various elements such as space missions, astronauts, and simulated environments. Moreover, private interests gain increasing influence in this discipline. In scientific disciplines with these features, transparent and rigorous methods are essential. Here, we undertook an evaluation of transparency indicators in publications within the field of space medicine. A meta-epidemiological assessment of PubMed Central Open Access (PMC OA) eligible articles within the field of space medicine was performed for prevalence of code sharing, data sharing, pre-registration, conflicts of interest, and funding. Text mining was performed with the rtransparent text mining algorithms with manual validation of 200 random articles to obtain corrected estimates. Across 1215 included articles, 39 (3%) shared code, 258 (21%) shared data, 10 (1%) were registered, 110 (90%) contained a conflict-of-interest statement, and 1141 (93%) included a funding statement. After manual validation, the corrected estimates for code sharing, data sharing, and registration were 5%, 27%, and 1%, respectively. Data sharing was 32% when limited to original articles and highest in space/parabolic flights (46%). Overall, across space medicine we observed modest rates of data sharing, rare sharing of code and almost non-existent protocol registration. Enhancing transparency in space medicine research is imperative for safeguarding its scientific rigor and reproducibility.",0
"Lituiev, D. S.; Cha, S. J.; Chin, A.; Glicksberg, B. S.; Bishara, A.; Dobi, D.; Cheng, R.; Sohn, J. H.; Laszik, Z.; Hadley, D.",2019,Automated Localization and Segmentation of Mononuclear Cell Aggregates in Kidney Histological Images Using Deep Learning,Pathology,Automated Localization and Segmentation of Mononuclear Cell Aggregates in Kidney Histological Images Using Deep Learning,"Lituiev, D. S.; Cha, S. J.; Chin, A.; Glicksberg, B. S.; Bishara, A.; Dobi, D.; Cheng, R.; Sohn, J. H.; Laszik, Z.; Hadley, D.",Pathology,2019-07-20 00:00:00 UTC,"Allograft rejection is a major concern in kidney transplantation. Inflammatory processes in patients with kidney allografts involve various patterns of immune cell recruitment and distributions. Lymphoid aggregates (LAs) are commonly observed in patients with kidney allografts and their presence and localization may correlate with severity of acute rejection. Alongside with other markers of inflammation, LAs assessment is currently performed by pathologists manually in a qualitative way, which is both time consuming and far from precise. Here we present the first automated method of identifying LAs and measuring their densities in whole slide images of transplant kidney biopsies. We trained a deep convolutional neural network based on U-Net on 44 core needle kidney biopsy slides, monitoring loss on a validation set (n=7 slides). The model was subsequently tested on a hold-out set (n=10 slides). We found that the coarse pattern of LAs localization agrees between the annotations and predictions, which is reflected by high correlation between the annotated and predicted fraction of LAs area per slide (Pearson R of 0.9756). Furthermore, the network achieves an auROC of 97.78 {+/-} 0.93% and an IoU score of 69.72 {+/-} 6.24 % per LA-containing slide in the test set. Our study demonstrates that a deep convolutional neural network can accurately identify lymphoid aggregates in digitized histological slides of kidney. This study presents a first automatic DL-based approach for quantifying inflammation marks in allograft kidney, which can greatly improve precision and speed of assessment of allograft kidney biopsies when implemented as a part of computer-aided diagnosis system.",10.1101/19002634,virology-neural-networks.xlsx,"Automated Localization and Segmentation of Mononuclear Cell Aggregates in Kidney Histological Images Using Deep Learning Allograft rejection is a major concern in kidney transplantation. Inflammatory processes in patients with kidney allografts involve various patterns of immune cell recruitment and distributions. Lymphoid aggregates (LAs) are commonly observed in patients with kidney allografts and their presence and localization may correlate with severity of acute rejection. Alongside with other markers of inflammation, LAs assessment is currently performed by pathologists manually in a qualitative way, which is both time consuming and far from precise. Here we present the first automated method of identifying LAs and measuring their densities in whole slide images of transplant kidney biopsies. We trained a deep convolutional neural network based on U-Net on 44 core needle kidney biopsy slides, monitoring loss on a validation set (n=7 slides). The model was subsequently tested on a hold-out set (n=10 slides). We found that the coarse pattern of LAs localization agrees between the annotations and predictions, which is reflected by high correlation between the annotated and predicted fraction of LAs area per slide (Pearson R of 0.9756). Furthermore, the network achieves an auROC of 97.78 {+/-} 0.93% and an IoU score of 69.72 {+/-} 6.24 % per LA-containing slide in the test set. Our study demonstrates that a deep convolutional neural network can accurately identify lymphoid aggregates in digitized histological slides of kidney. This study presents a first automatic DL-based approach for quantifying inflammation marks in allograft kidney, which can greatly improve precision and speed of assessment of allograft kidney biopsies when implemented as a part of computer-aided diagnosis system.",0
"Dandekar, R.; Barbastathis, G.",2020,Quantifying the effect of quarantine control in Covid-19 infectious spread using machine learning,Epidemiology,Quantifying the effect of quarantine control in Covid-19 infectious spread using machine learning,"Dandekar, R.; Barbastathis, G.",Epidemiology,2020-04-06 00:00:00 UTC,"Since the first recording of what we now call Covid-19 infection in Wuhan, Hubei province, China on Dec 31, 2019 (CHP 2020), the disease has spread worldwide and met with a wide variety of social distancing and quarantine policies. The effectiveness of these responses is notoriously difficult to quantify as individuals travel, violate policies deliberately or inadvertently, and infect others without themselves being detected (Li et al. 2020a; Wu & Leung 2020; Wang et al. 2020; Chinazzi et al. 2020; Ferguson et al. 2020; Kraemer et al. 2020). Moreover, the publicly available data on infection rates are themselves unreliable due to limited testing and even possibly under-reporting (Li et al. 2020b). In this paper, we attempt to interpret and extrapolate from publicly available data using a mixed first-principles epidemiological equations and data-driven neural network model. Leveraging our neural network augmented model, we focus our analysis on four locales: Wuhan, Italy, South Korea and the United States of America, and compare the role played by the quarantine and isolation measures in each of these countries in controlling the effective reproduction number Rt of the virus. Our results unequivocally indicate that the countries in which rapid government interventions and strict public health measures for quarantine and isolation were implemented were successful in halting the spread of infection and prevent it from exploding exponentially. In the case of Wuhan especially, where the available data were earliest available, we have been able to test the predicting ability of our model by training it from data in the January 24th till March 3rd window, and then matching the predictions up to April 1st. Even for Italy and South Korea, we have a buffer window of one week (25 March - 1 April) to validate the predictions of our model. In the case of the US, our model captures well the current infected curve growth and predicts a halting of infection spread by 20 April 2020. We further demonstrate that relaxing or reversing quarantine measures right now will lead to an exponential explosion in the infected case count, thus nullifying the role played by all measures implemented in the US since mid March 2020.",10.1101/2020.04.03.20052084,virology-neural-networks.xlsx,"Quantifying the effect of quarantine control in Covid-19 infectious spread using machine learning Since the first recording of what we now call Covid-19 infection in Wuhan, Hubei province, China on Dec 31, 2019 (CHP 2020), the disease has spread worldwide and met with a wide variety of social distancing and quarantine policies. The effectiveness of these responses is notoriously difficult to quantify as individuals travel, violate policies deliberately or inadvertently, and infect others without themselves being detected (Li et al. 2020a; Wu & Leung 2020; Wang et al. 2020; Chinazzi et al. 2020; Ferguson et al. 2020; Kraemer et al. 2020). Moreover, the publicly available data on infection rates are themselves unreliable due to limited testing and even possibly under-reporting (Li et al. 2020b). In this paper, we attempt to interpret and extrapolate from publicly available data using a mixed first-principles epidemiological equations and data-driven neural network model. Leveraging our neural network augmented model, we focus our analysis on four locales: Wuhan, Italy, South Korea and the United States of America, and compare the role played by the quarantine and isolation measures in each of these countries in controlling the effective reproduction number Rt of the virus. Our results unequivocally indicate that the countries in which rapid government interventions and strict public health measures for quarantine and isolation were implemented were successful in halting the spread of infection and prevent it from exploding exponentially. In the case of Wuhan especially, where the available data were earliest available, we have been able to test the predicting ability of our model by training it from data in the January 24th till March 3rd window, and then matching the predictions up to April 1st. Even for Italy and South Korea, we have a buffer window of one week (25 March - 1 April) to validate the predictions of our model. In the case of the US, our model captures well the current infected curve growth and predicts a halting of infection spread by 20 April 2020. We further demonstrate that relaxing or reversing quarantine measures right now will lead to an exponential explosion in the infected case count, thus nullifying the role played by all measures implemented in the US since mid March 2020.",1
"Batista, A. F. D. M.; Miraglia, J. L.; Donato, T. H. R.; Chiavegatto Filho, A. D. P.",2020,COVID-19 diagnosis prediction in emergency care patients: a machine learning approach,Epidemiology,COVID-19 diagnosis prediction in emergency care patients: a machine learning approach,"Batista, A. F. D. M.; Miraglia, J. L.; Donato, T. H. R.; Chiavegatto Filho, A. D. P.",Epidemiology,2020-04-14 00:00:00 UTC,"The coronavirus disease (COVID-19) pandemic has increased the necessity of immediate clinical decisions and effective usage of healthcare resources. Currently, the most validated diagnosis test for COVID-19 (RT-PCR) is in shortage in most developing countries, which may increase infection rates and delay important preventive measures. The objective of this study was to predict the risk of positive COVID-19 diagnosis with machine learning, using as predictors only results from emergency care admission exams. We collected data from 235 adult patients from the Hospital Israelita Albert Einstein in Sao Paulo, Brazil, from 17 to 30 of March, 2020, of which 102 (43%) received a positive diagnosis of COVID-19 from RT-PCR tests. Five machine learning algorithms (neural networks, random forests, gradient boosting trees, logistic regression and support vector machines) were trained on a random sample of 70% of the patients, and performance was tested on new unseen data (30%). The best predictive performance was obtained by the support vector machines algorithm (AUC: 0.85; Sensitivity: 0.68; Specificity: 0.85; Brier Score: 0.16). The three most important variables for the predictive performance of the algorithm were the number of lymphocytes, leukocytes and eosinophils, respectively. In conclusion, we found that targeted decisions for receiving COVID-19 tests using only routinely-collected data is a promising new area with the use of machine learning algorithms.",10.1101/2020.04.04.20052092,virology-neural-networks.xlsx,"COVID-19 diagnosis prediction in emergency care patients: a machine learning approach The coronavirus disease (COVID-19) pandemic has increased the necessity of immediate clinical decisions and effective usage of healthcare resources. Currently, the most validated diagnosis test for COVID-19 (RT-PCR) is in shortage in most developing countries, which may increase infection rates and delay important preventive measures. The objective of this study was to predict the risk of positive COVID-19 diagnosis with machine learning, using as predictors only results from emergency care admission exams. We collected data from 235 adult patients from the Hospital Israelita Albert Einstein in Sao Paulo, Brazil, from 17 to 30 of March, 2020, of which 102 (43%) received a positive diagnosis of COVID-19 from RT-PCR tests. Five machine learning algorithms (neural networks, random forests, gradient boosting trees, logistic regression and support vector machines) were trained on a random sample of 70% of the patients, and performance was tested on new unseen data (30%). The best predictive performance was obtained by the support vector machines algorithm (AUC: 0.85; Sensitivity: 0.68; Specificity: 0.85; Brier Score: 0.16). The three most important variables for the predictive performance of the algorithm were the number of lymphocytes, leukocytes and eosinophils, respectively. In conclusion, we found that targeted decisions for receiving COVID-19 tests using only routinely-collected data is a promising new area with the use of machine learning algorithms.",1
"Distante, C.; Gadelha Pereira, I.; Garcia Goncalves, L. M.; Piscitelli, P.; Miani, A.",2020,Forecasting Covid-19 Outbreak Progression in Italian Regions: A model based on neural network training from Chinese data,Epidemiology,Forecasting Covid-19 Outbreak Progression in Italian Regions: A model based on neural network training from Chinese data,"Distante, C.; Gadelha Pereira, I.; Garcia Goncalves, L. M.; Piscitelli, P.; Miani, A.",Epidemiology,2020-04-14 00:00:00 UTC,"BackgroundEpidemiological figures of Covid-19 epidemic in Italy are worse than those observed in China.

MethodsWe modeled the Covid-19 outbreak in Italian Regions vs. Lombardy to assess the epidemics progression and predict peaks of new daily infections and total cases by learning from the entire Chinese epidemiological dynamics. We trained an artificial neural network model, a modified auto-encoder with Covid-19 Chinese data, to forecast epidemic curve of the different Italian regions, and use the susceptible-exposed-infected-removed (SEIR) compartment model to predict the spreading and peaks. We have estimated the basic reproduction number (R0) - which represents the average number of people that can be infected by a person who has already acquired the infection - both by fitting the exponential growth rate of the infection across a 1-month period, and also by using a day by day assessment, based on single observations.

ResultsThe expected peak of SEIR model for new daily cases was at the end of March at national level. The peak of overall positive cases is expected by April 11th in Southern Italian Regions, a couple of days after that of Lombardy and Northern regions. According to our model, total confirmed cases in all Italy regions could reach 160,000 cases by April 30th and stabilize at a plateau.

ConclusionsTraining neural networks on Chinese data and use the knowledge to forecast Italian spreading of Covid-19 has resulted in a good fit, measured with the mean average precision between official Italian data and the forecast.",10.1101/2020.04.09.20059055,virology-neural-networks.xlsx,"Forecasting Covid-19 Outbreak Progression in Italian Regions: A model based on neural network training from Chinese data BackgroundEpidemiological figures of Covid-19 epidemic in Italy are worse than those observed in China.

MethodsWe modeled the Covid-19 outbreak in Italian Regions vs. Lombardy to assess the epidemics progression and predict peaks of new daily infections and total cases by learning from the entire Chinese epidemiological dynamics. We trained an artificial neural network model, a modified auto-encoder with Covid-19 Chinese data, to forecast epidemic curve of the different Italian regions, and use the susceptible-exposed-infected-removed (SEIR) compartment model to predict the spreading and peaks. We have estimated the basic reproduction number (R0) - which represents the average number of people that can be infected by a person who has already acquired the infection - both by fitting the exponential growth rate of the infection across a 1-month period, and also by using a day by day assessment, based on single observations.

ResultsThe expected peak of SEIR model for new daily cases was at the end of March at national level. The peak of overall positive cases is expected by April 11th in Southern Italian Regions, a couple of days after that of Lombardy and Northern regions. According to our model, total confirmed cases in all Italy regions could reach 160,000 cases by April 30th and stabilize at a plateau.

ConclusionsTraining neural networks on Chinese data and use the knowledge to forecast Italian spreading of Covid-19 has resulted in a good fit, measured with the mean average precision between official Italian data and the forecast.",1
"Uhlig, S.; Nichani, K.; Uhlig, C.; Simon, K.",2020,"Modeling projections for COVID-19 pandemic by combining epidemiological, statistical, and neural network approaches",Epidemiology,"Modeling projections for COVID-19 pandemic by combining epidemiological, statistical, and neural network approaches","Uhlig, S.; Nichani, K.; Uhlig, C.; Simon, K.",Epidemiology,2020-04-22 00:00:00 UTC,"As the number of people affected by COVID-19 disease caused by the novel coronavirus SARS-CoV-2 ebbs and flows in different national and sub-national regions across the world, it is evident that our lifestyle and socio-economic trajectories will have to be adapted and adjusted to the changing scenarios. Novel forecasting tools and frameworks provide an arguable advantage to facilitate this adapting and adjusting process, by promoting efficient resource management at individual and institutional levels. Based on deterministic compartment models we propose an empirical top-down modeling approach to provide epidemic forecasts and risk calculations for (local) outbreaks. We use neural networks to develop leading indicators based on available data for different regions. These indicators are not only used to assess the risk of a (new) outbreak or to determine the effectiveness of a measure at an early stage, but also in parametric models to determine an effective forecast, along with the associated uncertainty. Based on initial results, we show the performance of such an approach and its robustness against inherent disturbances in epidemiological surveillance data. We foresee such a statistical framework to drive web-based automatic platforms to democratize the dissemination of prognosis results.",10.1101/2020.04.17.20059535,virology-neural-networks.xlsx,"Modeling projections for COVID-19 pandemic by combining epidemiological, statistical, and neural network approaches As the number of people affected by COVID-19 disease caused by the novel coronavirus SARS-CoV-2 ebbs and flows in different national and sub-national regions across the world, it is evident that our lifestyle and socio-economic trajectories will have to be adapted and adjusted to the changing scenarios. Novel forecasting tools and frameworks provide an arguable advantage to facilitate this adapting and adjusting process, by promoting efficient resource management at individual and institutional levels. Based on deterministic compartment models we propose an empirical top-down modeling approach to provide epidemic forecasts and risk calculations for (local) outbreaks. We use neural networks to develop leading indicators based on available data for different regions. These indicators are not only used to assess the risk of a (new) outbreak or to determine the effectiveness of a measure at an early stage, but also in parametric models to determine an effective forecast, along with the associated uncertainty. Based on initial results, we show the performance of such an approach and its robustness against inherent disturbances in epidemiological surveillance data. We foresee such a statistical framework to drive web-based automatic platforms to democratize the dissemination of prognosis results.",1
"Kolozsvari, L. R.; Berczes, T.; Hajdu, A.; Gesztelyi, R.; Tiba, A.; Varga, I.; Al-Tammemi, A. B.; Szollosi, G. J.; Harsanyi, S.; Garboczy, S.; Zsuga, J.",2021,Predicting the epidemic curve of the coronavirus (SARS-CoV-2) disease (COVID-19) using artificial intelligence,Epidemiology,Predicting the epidemic curve of the coronavirus (SARS-CoV-2) disease (COVID-19) using artificial intelligence,"Kolozsvari, L. R.; Berczes, T.; Hajdu, A.; Gesztelyi, R.; Tiba, A.; Varga, I.; Al-Tammemi, A. B.; Szollosi, G. J.; Harsanyi, S.; Garboczy, S.; Zsuga, J.",Epidemiology,2021-01-27 00:00:00 UTC,"The aim of our study was to predict the epidemic curves (daily new cases) of COVID-19 pandemic using Artificial Intelligence (AI)-based Recurrent Neural Networks (RNNs), then to compare and validate the predicted models with the observed data. We used the publicly available datasets from the World Health Organization and Johns Hopkins University to create a training dataset, then we used RNNs with gated recurring units (Long Short-Term Memory) to create two prediction models. Information collected in the first t time-steps were aggregated with a fully connected (dense) neural network layer and a consequent regression output layer to determine the next predicted value. We also used Root Mean Squared Logarithmic Errors (RMSLE) to compare the predicted models with the observed data. The result of our study underscores that the COVID-19 pandemic is a propagated source epidemic, therefore repeated peaks on the epidemic curve are to be anticipated. Besides, the errors between the predicted and validated data and trends seems to be low. The influence of this pandemic is significant worldwide and has already impacted our daily life. Decision makers must be aware, that even if strict public health measures are executed and sustained, future peaks of infections are possible.",10.1101/2020.04.17.20069666,virology-neural-networks.xlsx,"Predicting the epidemic curve of the coronavirus (SARS-CoV-2) disease (COVID-19) using artificial intelligence The aim of our study was to predict the epidemic curves (daily new cases) of COVID-19 pandemic using Artificial Intelligence (AI)-based Recurrent Neural Networks (RNNs), then to compare and validate the predicted models with the observed data. We used the publicly available datasets from the World Health Organization and Johns Hopkins University to create a training dataset, then we used RNNs with gated recurring units (Long Short-Term Memory) to create two prediction models. Information collected in the first t time-steps were aggregated with a fully connected (dense) neural network layer and a consequent regression output layer to determine the next predicted value. We also used Root Mean Squared Logarithmic Errors (RMSLE) to compare the predicted models with the observed data. The result of our study underscores that the COVID-19 pandemic is a propagated source epidemic, therefore repeated peaks on the epidemic curve are to be anticipated. Besides, the errors between the predicted and validated data and trends seems to be low. The influence of this pandemic is significant worldwide and has already impacted our daily life. Decision makers must be aware, that even if strict public health measures are executed and sustained, future peaks of infections are possible.",1
"Paul, S. K.; Jana, S.; Bhaumik, P.",2020,A multivariate spatiotemporal spread model of COVID-19 using ensemble of ConvLSTM networks,Epidemiology,A multivariate spatiotemporal spread model of COVID-19 using ensemble of ConvLSTM networks,"Paul, S. K.; Jana, S.; Bhaumik, P.",Epidemiology,2020-04-29 00:00:00 UTC,The high R-naught factor of SARS-CoV-2 has created a race against time for mankind and it necessitates rapid containment actions to control the spread. In such scenario short term accurate spatiotemporal predictions can help understanding the dynamics of the spread in a geographic region and identify hotspots. However due to the novelty of the disease there is very little disease specific data generated yet. This poses a difficult problem for machine learning methods to learn a model of the epidemic spread from data. A proposed ensemble of convolutional LSTM based spatiotemporal model can forecast the spread of the epidemic with high resolution and accuracy in a large geographic region. A data preparation method is proposed to convert available spatial causal features into set of 2D images with or without temporal component. The model has been trained with available data for USA and Italy. It achieved 5.57% and 0.3% mean absolute percent error for total number of predicted infection cases in a 5day prediction period for USA and Italy respectively.,10.1101/2020.04.17.20069898,virology-neural-networks.xlsx,A multivariate spatiotemporal spread model of COVID-19 using ensemble of ConvLSTM networks The high R-naught factor of SARS-CoV-2 has created a race against time for mankind and it necessitates rapid containment actions to control the spread. In such scenario short term accurate spatiotemporal predictions can help understanding the dynamics of the spread in a geographic region and identify hotspots. However due to the novelty of the disease there is very little disease specific data generated yet. This poses a difficult problem for machine learning methods to learn a model of the epidemic spread from data. A proposed ensemble of convolutional LSTM based spatiotemporal model can forecast the spread of the epidemic with high resolution and accuracy in a large geographic region. A data preparation method is proposed to convert available spatial causal features into set of 2D images with or without temporal component. The model has been trained with available data for USA and Italy. It achieved 5.57% and 0.3% mean absolute percent error for total number of predicted infection cases in a 5day prediction period for USA and Italy respectively.,1
"Yu, Y.; Liu, Y.-R.; Luo, F.-M.; Tu, W.-W.; Zhan, D.-C.; Yu, G.; Zhou, Z.-H.",2020,COVID-19 Asymptomatic Infection Estimation,Epidemiology,COVID-19 Asymptomatic Infection Estimation,"Yu, Y.; Liu, Y.-R.; Luo, F.-M.; Tu, W.-W.; Zhan, D.-C.; Yu, G.; Zhou, Z.-H.",Epidemiology,2020-04-23 00:00:00 UTC,"BackgroundMounting evidence suggests that there is an undetected pool of COVID-19 asymptomatic but infectious cases. Estimating the number of asymptomatic infections has been crucial to understand the virus and contain its spread, which is, however, hard to be accurately counted.

MethodsWe propose an approach of machine learning based fine-grained simulator (ML-Sim), which integrates multiple practical factors including disease progress in the incubation period, cross-region population movement, undetected asymptomatic patients, and prevention and containment strength. The interactions among these factors are modeled by virtual transmission dynamics with several undetermined parameters, which are determined from epidemic data by machine learning techniques. When MLSim learns to match the real data closely, it also models the number of asymptomatic patients. MLSim is learned from the open Chinese global epidemic data.

FindingsMLSim showed better forecast accuracy than the SEIR and LSTM-based prediction models. The MLSim learned from the data of Chinas mainland reveals that there could have been 150,408 (142,178-157,417) asymptomatic and had self-healed patients, which is 65% (64% - 65%) of the inferred total infections including undetected ones. The numbers of asymptomatic but infectious patients on April 15, 2020, were inferred as, Italy: 41,387 (29,037 - 57,151), Germany: 21,118 (11,484 - 41,646), USA: 354,657 (277,641 - 495,128), France: 40,379 (10,807 - 186,878), and UK: 144,424 (127,215 - 171,930). To control the virus transmission, the containment measures taken by the government were crucial. The learned MLSim also reveals that if the date of containment measures in Chinas mainland was postponed for 1, 3, 5, and 7 days later than Jan. 23, there would be 109,039 (129%), 183,930 (218%), 313,342 (371%), 537,555 (637%) confirmed cases on June 12.

ConclusionsMachine learning based fine-grained simulators can better model the complex real-world disease transmission process, and thus can help decision-making of balanced containment measures. The simulator also revealed the potential great number of undetected asymptomatic infections, which poses a great risk to the virus containment.

FundingNational Natural Science Foundation of China.",10.1101/2020.04.19.20068072,virology-neural-networks.xlsx,"COVID-19 Asymptomatic Infection Estimation BackgroundMounting evidence suggests that there is an undetected pool of COVID-19 asymptomatic but infectious cases. Estimating the number of asymptomatic infections has been crucial to understand the virus and contain its spread, which is, however, hard to be accurately counted.

MethodsWe propose an approach of machine learning based fine-grained simulator (ML-Sim), which integrates multiple practical factors including disease progress in the incubation period, cross-region population movement, undetected asymptomatic patients, and prevention and containment strength. The interactions among these factors are modeled by virtual transmission dynamics with several undetermined parameters, which are determined from epidemic data by machine learning techniques. When MLSim learns to match the real data closely, it also models the number of asymptomatic patients. MLSim is learned from the open Chinese global epidemic data.

FindingsMLSim showed better forecast accuracy than the SEIR and LSTM-based prediction models. The MLSim learned from the data of Chinas mainland reveals that there could have been 150,408 (142,178-157,417) asymptomatic and had self-healed patients, which is 65% (64% - 65%) of the inferred total infections including undetected ones. The numbers of asymptomatic but infectious patients on April 15, 2020, were inferred as, Italy: 41,387 (29,037 - 57,151), Germany: 21,118 (11,484 - 41,646), USA: 354,657 (277,641 - 495,128), France: 40,379 (10,807 - 186,878), and UK: 144,424 (127,215 - 171,930). To control the virus transmission, the containment measures taken by the government were crucial. The learned MLSim also reveals that if the date of containment measures in Chinas mainland was postponed for 1, 3, 5, and 7 days later than Jan. 23, there would be 109,039 (129%), 183,930 (218%), 313,342 (371%), 537,555 (637%) confirmed cases on June 12.

ConclusionsMachine learning based fine-grained simulators can better model the complex real-world disease transmission process, and thus can help decision-making of balanced containment measures. The simulator also revealed the potential great number of undetected asymptomatic infections, which poses a great risk to the virus containment.

FundingNational Natural Science Foundation of China.",1
"Abbas, M. A.; Bukhari, S. U. K.; Syed, A.; Shah, S. S. H.",2020,The Histopathological Diagnosis of Adenocarcinoma & Squamous Cells Carcinoma of Lungs by Artificial intelligence: A comparative study of convolutional neural networks,Pathology,The Histopathological Diagnosis of Adenocarcinoma & Squamous Cells Carcinoma of Lungs by Artificial intelligence: A comparative study of convolutional neural networks,"Abbas, M. A.; Bukhari, S. U. K.; Syed, A.; Shah, S. S. H.",Pathology,2020-05-06 00:00:00 UTC,"IntroductionMalignant tumors of the lung are the most important cause of morbidity and mortality due to cancer all over the world. A rising trend in the incidence of lung cancer has been observed. Histopathological diagnosis of lung cancer is a vital component of patient care. The use of artificial intelligence in the histopathological diagnosis of lung cancer may be a very useful technology in the near future.

AimThe aim of the present research project is to determine the effectiveness of convolutional neural networks for the diagnosis of squamous cell carcinoma and adenocarcinoma of the lung by evaluating the digital pathology images of these cancers.

Materials & MethodsA total of 15000 digital images of histopathological slides were acquired from the LC2500 dataset. The digital pathology images from lungs are comprised of three classes; class I contains 5000 images of benign lung tissue, class II contains 5,000 images of squamous cell carcinoma of lungs while Class III contains 5,000 images of adenocarcinoma of lungs. Six state of the art off the shelf convolutional neural network architectures, VGG-19, Alex Net, ResNet: ResNet-18, ResNet-34, ResNet-50, and ResNet-101, are used to assess the data, in this comparison study. The dataset was divided into a train set, 55% of the entire data, validation set 20%, and 25% into the test data set.

ResultsA number of off the shelf pre-trained (on ImageNet data set) convolutional neural networks are used to classify the histopathological slides into three classes, benign lung tissue, squamous cell carcinoma-lung and adenocarcinoma - lung. The F-1 scores of AlexNet, VGG-19, ResNet-18, ResNet-34, ResNet-50 and ResNet-101, on the test dataset show the result of 0.973, 0.997, 0.986, 0.992, 0.999 and 0.999 respectively.

DiscussionThe diagnostic accuracy of more 97% has been achieved for the diagnosis of squamous cell carcinoma and adenocarcinoma of the lungs in the present study. A similar finding has been reported in other studies for the diagnosis of metastasis of breast carcinoma in lymph nodes, basal cell carcinoma, and prostatic cancer.

ConclusionThe development of algorithms for the recognition of a specific pattern of the particular malignant tumor by analyzing the digital images will reduce the chance of human errors and improve the efficiency of the laboratory for the rapid and accurate diagnosis of cancer.",10.1101/2020.05.02.20044602,virology-neural-networks.xlsx,"The Histopathological Diagnosis of Adenocarcinoma & Squamous Cells Carcinoma of Lungs by Artificial intelligence: A comparative study of convolutional neural networks IntroductionMalignant tumors of the lung are the most important cause of morbidity and mortality due to cancer all over the world. A rising trend in the incidence of lung cancer has been observed. Histopathological diagnosis of lung cancer is a vital component of patient care. The use of artificial intelligence in the histopathological diagnosis of lung cancer may be a very useful technology in the near future.

AimThe aim of the present research project is to determine the effectiveness of convolutional neural networks for the diagnosis of squamous cell carcinoma and adenocarcinoma of the lung by evaluating the digital pathology images of these cancers.

Materials & MethodsA total of 15000 digital images of histopathological slides were acquired from the LC2500 dataset. The digital pathology images from lungs are comprised of three classes; class I contains 5000 images of benign lung tissue, class II contains 5,000 images of squamous cell carcinoma of lungs while Class III contains 5,000 images of adenocarcinoma of lungs. Six state of the art off the shelf convolutional neural network architectures, VGG-19, Alex Net, ResNet: ResNet-18, ResNet-34, ResNet-50, and ResNet-101, are used to assess the data, in this comparison study. The dataset was divided into a train set, 55% of the entire data, validation set 20%, and 25% into the test data set.

ResultsA number of off the shelf pre-trained (on ImageNet data set) convolutional neural networks are used to classify the histopathological slides into three classes, benign lung tissue, squamous cell carcinoma-lung and adenocarcinoma - lung. The F-1 scores of AlexNet, VGG-19, ResNet-18, ResNet-34, ResNet-50 and ResNet-101, on the test dataset show the result of 0.973, 0.997, 0.986, 0.992, 0.999 and 0.999 respectively.

DiscussionThe diagnostic accuracy of more 97% has been achieved for the diagnosis of squamous cell carcinoma and adenocarcinoma of the lungs in the present study. A similar finding has been reported in other studies for the diagnosis of metastasis of breast carcinoma in lymph nodes, basal cell carcinoma, and prostatic cancer.

ConclusionThe development of algorithms for the recognition of a specific pattern of the particular malignant tumor by analyzing the digital images will reduce the chance of human errors and improve the efficiency of the laboratory for the rapid and accurate diagnosis of cancer.",0
"Abhijit Dandekar, R.; Henderson, S. G.; Jansen, M.; Moka, S.; Nazarathy, Y.; Rackauckas, C.; Taylor, P. G.; Vuorinen, A.",2020,Safe Blues: A Method for Estimation and Control in the Fight Against COVID-19,Epidemiology,Safe Blues: A Method for Estimation and Control in the Fight Against COVID-19,"Abhijit Dandekar, R.; Henderson, S. G.; Jansen, M.; Moka, S.; Nazarathy, Y.; Rackauckas, C.; Taylor, P. G.; Vuorinen, A.",Epidemiology,2020-05-08 00:00:00 UTC,"How do fine modifications to social distancing measures really affect COVID-19 spread? A major problem for health authorities is that we do not know.

In an imaginary world, we might develop a harmless biological virus that spreads just like COVID-19, but is traceable via a cheap and reliable diagnosis. By introducing such an imaginary virus into the population and observing how it spreads, we would have a way of learning about COVID-19 because the benign virus would respond to population behaviour and social distancing measures in a similar manner. Such a benign biological virus does not exist. Instead, we propose a safe and privacy-preserving digital alternative.

Our solution is to mimic the benign virus by passing virtual tokens between electronic devices when they move into close proximity. As Bluetooth transmission is the most likely method used for such inter-device communication, and as our suggested ""virtual viruses"" do not harm individuals software or intrude on privacy, we call these Safe Blues.

In contrast to many app-based methods that inform individuals or governments about actual COVID-19 patients or hazards, Safe Blues does not provide information about individuals locations or contacts. Hence the privacy concerns associated with Safe Blues are much lower than other methods. However, from the point of view of data collection, Safe Blues has two major advantages:

O_LIData about the spread of Safe Blues is uploaded to a central server in real time, which can give authorities a more up-to-date picture in comparison to actual COVID-19 data, which is only available retrospectively.
C_LIO_LISampling of Safe Blues data is not biased by being applied only to people who have shown symptoms or who have come into contact with known positive cases.
C_LI

These features mean that there would be real statistical value in introducing Safe Blues. In the medium term and end game of COVID-19, information from Safe Blues could aid health authorities to make informed decisions with respect to social distancing and other measures.

In this paper we outline the general principles of Safe Blues and we illustrate how Safe Blues data together with neural networks may be used to infer characteristics of the progress of the COVID-19 pandemic in real time. Further information is on the Safe Blues website: https://safeblues.org/.",10.1101/2020.05.04.20090258,virology-neural-networks.xlsx,"Safe Blues: A Method for Estimation and Control in the Fight Against COVID-19 How do fine modifications to social distancing measures really affect COVID-19 spread? A major problem for health authorities is that we do not know.

In an imaginary world, we might develop a harmless biological virus that spreads just like COVID-19, but is traceable via a cheap and reliable diagnosis. By introducing such an imaginary virus into the population and observing how it spreads, we would have a way of learning about COVID-19 because the benign virus would respond to population behaviour and social distancing measures in a similar manner. Such a benign biological virus does not exist. Instead, we propose a safe and privacy-preserving digital alternative.

Our solution is to mimic the benign virus by passing virtual tokens between electronic devices when they move into close proximity. As Bluetooth transmission is the most likely method used for such inter-device communication, and as our suggested ""virtual viruses"" do not harm individuals software or intrude on privacy, we call these Safe Blues.

In contrast to many app-based methods that inform individuals or governments about actual COVID-19 patients or hazards, Safe Blues does not provide information about individuals locations or contacts. Hence the privacy concerns associated with Safe Blues are much lower than other methods. However, from the point of view of data collection, Safe Blues has two major advantages:

O_LIData about the spread of Safe Blues is uploaded to a central server in real time, which can give authorities a more up-to-date picture in comparison to actual COVID-19 data, which is only available retrospectively.
C_LIO_LISampling of Safe Blues data is not biased by being applied only to people who have shown symptoms or who have come into contact with known positive cases.
C_LI

These features mean that there would be real statistical value in introducing Safe Blues. In the medium term and end game of COVID-19, information from Safe Blues could aid health authorities to make informed decisions with respect to social distancing and other measures.

In this paper we outline the general principles of Safe Blues and we illustrate how Safe Blues data together with neural networks may be used to infer characteristics of the progress of the COVID-19 pandemic in real time. Further information is on the Safe Blues website: https://safeblues.org/.",1
"Ge, Q.; Hu, Z.; Li, S.; Lin, W.; Jin, L.; Xiong, M.",2020,A Novel Intervention Recurrent autoencoder for real time forecasting and non-pharmaceutical intervention selection to curb the spread of Covid-19 in the world,Epidemiology,A Novel Intervention Recurrent autoencoder for real time forecasting and non-pharmaceutical intervention selection to curb the spread of Covid-19 in the world,"Ge, Q.; Hu, Z.; Li, S.; Lin, W.; Jin, L.; Xiong, M.",Epidemiology,2020-07-31 00:00:00 UTC,"As the Covid-19 pandemic soars around the world, there is urgent need to forecast the number of cases worldwide at its peak, the length of the pandemic before receding and implement public health interventions to significantly stop the spread of Covid-19. Widely used statistical and computer methods for modeling and forecasting the trajectory of Covid-19 are epidemiological models. Although these epidemiological models are useful for estimating the dynamics of transmission od epidemics, their prediction accuracies are quite low. To overcome this limitation, we formulated the real-time forecasting and evaluating multiple public health intervention problem into forecasting treatment response problem and developed recurrent neural network (RNN) for modeling the transmission dynamics of the epidemics and Counterfactual-RNN (CRNN) for evaluating and exploring public health intervention strategies to slow down the spread of Covid-19 worldwide. We applied the developed methods to the real data collected from January 22, 2020 to May 8, 2020 for real-time forecasting the confirmed cases of Covid-19 across the world.",10.1101/2020.05.05.20091827,virology-neural-networks.xlsx,"A Novel Intervention Recurrent autoencoder for real time forecasting and non-pharmaceutical intervention selection to curb the spread of Covid-19 in the world As the Covid-19 pandemic soars around the world, there is urgent need to forecast the number of cases worldwide at its peak, the length of the pandemic before receding and implement public health interventions to significantly stop the spread of Covid-19. Widely used statistical and computer methods for modeling and forecasting the trajectory of Covid-19 are epidemiological models. Although these epidemiological models are useful for estimating the dynamics of transmission od epidemics, their prediction accuracies are quite low. To overcome this limitation, we formulated the real-time forecasting and evaluating multiple public health intervention problem into forecasting treatment response problem and developed recurrent neural network (RNN) for modeling the transmission dynamics of the epidemics and Counterfactual-RNN (CRNN) for evaluating and exploring public health intervention strategies to slow down the spread of Covid-19 worldwide. We applied the developed methods to the real data collected from January 22, 2020 to May 8, 2020 for real-time forecasting the confirmed cases of Covid-19 across the world.",1
"Azarafza, M.; Azarafza, M.; Tanha, J.",2020,COVID-19 Infection Forecasting based on Deep Learning in Iran,Epidemiology,COVID-19 Infection Forecasting based on Deep Learning in Iran,"Azarafza, M.; Azarafza, M.; Tanha, J.",Epidemiology,2020-05-24 00:00:00 UTC,"Since December 2019 coronavirus disease (COVID-19) is outbreak from China and infected more than 4,666,000 people and caused thousands of deaths. Unfortunately, the infection numbers and deaths are still increasing rapidly which has put the world on the catastrophic abyss edge. Application of artificial intelligence and spatiotemporal distribution techniques can play a key role to infection forecasting in national and province levels in many countries. As methodology, the presented study employs long short-term memory-based deep for time series forecasting, the confirmed cases in both national and province levels, in Iran. The data were collected from February 19, to March 22, 2020 in provincial level and from February 19, to May 13, 2020 in national level by nationally recognised sources. For justification, we use the recurrent neural network, seasonal autoregressive integrated moving average, Holt winters exponential smoothing, and moving averages approaches. Furthermore, the mean absolute error, mean squared error, and mean absolute percentage error metrics are used as evaluation factors with associate the trend analysis. The results of our experiments show that the LSTM model is performed better than the other methods on the collected COVID-19 dataset in Iran.",10.1101/2020.05.16.20104182,virology-neural-networks.xlsx,"COVID-19 Infection Forecasting based on Deep Learning in Iran Since December 2019 coronavirus disease (COVID-19) is outbreak from China and infected more than 4,666,000 people and caused thousands of deaths. Unfortunately, the infection numbers and deaths are still increasing rapidly which has put the world on the catastrophic abyss edge. Application of artificial intelligence and spatiotemporal distribution techniques can play a key role to infection forecasting in national and province levels in many countries. As methodology, the presented study employs long short-term memory-based deep for time series forecasting, the confirmed cases in both national and province levels, in Iran. The data were collected from February 19, to March 22, 2020 in provincial level and from February 19, to May 13, 2020 in national level by nationally recognised sources. For justification, we use the recurrent neural network, seasonal autoregressive integrated moving average, Holt winters exponential smoothing, and moving averages approaches. Furthermore, the mean absolute error, mean squared error, and mean absolute percentage error metrics are used as evaluation factors with associate the trend analysis. The results of our experiments show that the LSTM model is performed better than the other methods on the collected COVID-19 dataset in Iran.",1
"Dolgikh, S.",2020,Identifying Explosive Cases with Unsupervised Machine Learning,Epidemiology,Identifying Explosive Cases with Unsupervised Machine Learning,"Dolgikh, S.",Epidemiology,2020-10-19 00:00:00 UTC,"An analysis of a combined dataset of Wave 1 and 2 cases, aligned at approximately Local Time Zero + 2 months with unsupervised machine learning methods such as PCA and deep autoencoder dimensionality reduction allows to clearly separate milder background cases from those with more rapid and aggressive onset of the epidemics. The analysis and findings of the study can be used in evaluation of possible epidemiological scenarios and as an effective modeling tool to design corrective and preventative measures to avoid developments with potentially heavy impact",10.1101/2020.05.17.20104661,virology-neural-networks.xlsx,"Identifying Explosive Cases with Unsupervised Machine Learning An analysis of a combined dataset of Wave 1 and 2 cases, aligned at approximately Local Time Zero + 2 months with unsupervised machine learning methods such as PCA and deep autoencoder dimensionality reduction allows to clearly separate milder background cases from those with more rapid and aggressive onset of the epidemics. The analysis and findings of the study can be used in evaluation of possible epidemiological scenarios and as an effective modeling tool to design corrective and preventative measures to avoid developments with potentially heavy impact",0
"Heili-Frades, S.; Minguez, P.; Mahillo-Fernandez, I.; Prieto-Rumeau, T.; Herrero Gonzalez, A.; De La Fuente, L.; Rodriguez Nieto, M. J.; Peces-Barba Romero, G.; Peces-Barba, M.; Carballosa De Miguel, M. D. P.; Fernandez Ormaechea, I.; Naya Prieto, A.; Ezzine De Blas, F.; Jimenez Hiscock, L.; Perez Calvo, C.; Santos, A.; Munoz Alameda, L. E.; Romero Bueno, F.; Hernandez-Mora, M. G.; Cabello Ubeda, A.; Alvarez Alvarez, B.; Petkova, E.; Carrasco, N.; Martin Rios, D.; Gonzalez Mangado, N.; Sanchez Pernaute, O.",2020,COVID-19 Outcomes in 4712 consecutively confirmed SARS-CoV2 cases in the city of Madrid.,Respiratory Medicine,COVID-19 Outcomes in 4712 consecutively confirmed SARS-CoV2 cases in the city of Madrid.,"Heili-Frades, S.; Minguez, P.; Mahillo-Fernandez, I.; Prieto-Rumeau, T.; Herrero Gonzalez, A.; De La Fuente, L.; Rodriguez Nieto, M. J.; Peces-Barba Romero, G.; Peces-Barba, M.; Carballosa De Miguel, M. D. P.; Fernandez Ormaechea, I.; Naya Prieto, A.; Ezzine De Blas, F.; Jimenez Hiscock, L.; Perez Calvo, C.; Santos, A.; Munoz Alameda, L. E.; Romero Bueno, F.; Hernandez-Mora, M. G.; Cabello Ubeda, A.; Alvarez Alvarez, B.; Petkova, E.; Carrasco, N.; Martin Rios, D.; Gonzalez Mangado, N.; Sanchez Pernaute, O.",Respiratory Medicine,2020-05-29 00:00:00 UTC,"There is limited information describing features and outcomes of patients requiring hospitalization for COVID19 disease and still no treatments have clearly demonstrated efficacy. Demographics and clinical variables on admission, as well as laboratory markers and therapeutic interventions were extracted from electronic Clinical Records (eCR) in 4712 SARS-CoV2 infected patients attending 4 public Hospitals in Madrid. Patients were stratified according to age and stage of severity. Using multivariate logistic regression analysis, cut-off points that best discriminated mortality were obtained for each of the studied variables. Principal components analysis and a neural network (NN) algorithm were applied.

A high mortality incidence associated to age >70, comorbidities (hypertension, neurological disorders and diabetes), altered vitals such as fever, heart rhythm disturbances or elevated systolic blood pressure, and alterations in several laboratory tests. Remarkably, analysis of therapeutic options either taken individually or in combination drew a universal relationship between the use of Cyclosporine A and better outcomes as also a benefit of tocilizumab and/or corticosteroids in critically ill patients.

We present a large Spanish population-based study addressing factors influencing survival in current SARS CoV2 pandemic, with particular emphasis on the effectivity of treatments. In addition, we have generated an NN capable of identifying severity predictors of SARS CoV2. A rapid extraction and management of data protocol from eCR and artificial intelligence in-house implementations allowed us to perform almost real time monitoring of the outbreak evolution.",10.1101/2020.05.22.20109850,virology-neural-networks.xlsx,"COVID-19 Outcomes in 4712 consecutively confirmed SARS-CoV2 cases in the city of Madrid. There is limited information describing features and outcomes of patients requiring hospitalization for COVID19 disease and still no treatments have clearly demonstrated efficacy. Demographics and clinical variables on admission, as well as laboratory markers and therapeutic interventions were extracted from electronic Clinical Records (eCR) in 4712 SARS-CoV2 infected patients attending 4 public Hospitals in Madrid. Patients were stratified according to age and stage of severity. Using multivariate logistic regression analysis, cut-off points that best discriminated mortality were obtained for each of the studied variables. Principal components analysis and a neural network (NN) algorithm were applied.

A high mortality incidence associated to age >70, comorbidities (hypertension, neurological disorders and diabetes), altered vitals such as fever, heart rhythm disturbances or elevated systolic blood pressure, and alterations in several laboratory tests. Remarkably, analysis of therapeutic options either taken individually or in combination drew a universal relationship between the use of Cyclosporine A and better outcomes as also a benefit of tocilizumab and/or corticosteroids in critically ill patients.

We present a large Spanish population-based study addressing factors influencing survival in current SARS CoV2 pandemic, with particular emphasis on the effectivity of treatments. In addition, we have generated an NN capable of identifying severity predictors of SARS CoV2. A rapid extraction and management of data protocol from eCR and artificial intelligence in-house implementations allowed us to perform almost real time monitoring of the outbreak evolution.",1
"Gemmar, P.",2020,An interpretable mortality prediction model for COVID-19 patients - alternative approach,Epidemiology,An interpretable mortality prediction model for COVID-19 patients - alternative approach,"Gemmar, P.",Epidemiology,2020-06-22 00:00:00 UTC,"The pandemic spread of coronavirus leads to increased burden on healthcare services worldwide. Experience shows that required medical treatment can reach limits at local clinics and fast and secure clinical assessment of the disease severity becomes vital. In [1] a model is presented for predicting the mortality of COVID-19 patients from their biomarkers. Three biomarkers have been selected by ranking with a supervised Multi-tree XGBoost classifier. The prediction model is built up as a binary decision tree with depth three and achieves AUC scores of up to 97.84{+/-}0.37 and 95.06{+/-} 2.21 for training and external test data sets, resp.

In human assessment and decision making influencing parameters usually arent considered as sharp numbers but rather as Fuzzy terms [2], and inferencing primarily yields Fuzzy terms or continuous grades rather than binary decisions. Therefore, I examined a Sugenotype Fuzzy classifier [3] for disease assessment and decision support. In addition, I used an artificial neural network (SOM, [4]) for selecting the biomarkers. Modelling and validation was done with the identical data base provided by [1]. With the complete training and test data sets, the Fuzzy prediction model achieves improved AUC scores of up to 98.59 or 95.12 The improvements with the Fuzzy classifier obviously become clear as physicians can interpret output grades to belong to positive or negative class more or less strongly. An extension of the Fuzzy model, which takes into account the trend in key features over time, provides excellent results with the training data, which, however, could not be finally verified due to the lack of suitable test data. The generation and training of the Fuzzy models was fully automatic and without additional adjustment with the help of ANFIS from Matlab(C).",10.1101/2020.06.14.20130732,virology-neural-networks.xlsx,"An interpretable mortality prediction model for COVID-19 patients - alternative approach The pandemic spread of coronavirus leads to increased burden on healthcare services worldwide. Experience shows that required medical treatment can reach limits at local clinics and fast and secure clinical assessment of the disease severity becomes vital. In [1] a model is presented for predicting the mortality of COVID-19 patients from their biomarkers. Three biomarkers have been selected by ranking with a supervised Multi-tree XGBoost classifier. The prediction model is built up as a binary decision tree with depth three and achieves AUC scores of up to 97.84{+/-}0.37 and 95.06{+/-} 2.21 for training and external test data sets, resp.

In human assessment and decision making influencing parameters usually arent considered as sharp numbers but rather as Fuzzy terms [2], and inferencing primarily yields Fuzzy terms or continuous grades rather than binary decisions. Therefore, I examined a Sugenotype Fuzzy classifier [3] for disease assessment and decision support. In addition, I used an artificial neural network (SOM, [4]) for selecting the biomarkers. Modelling and validation was done with the identical data base provided by [1]. With the complete training and test data sets, the Fuzzy prediction model achieves improved AUC scores of up to 98.59 or 95.12 The improvements with the Fuzzy classifier obviously become clear as physicians can interpret output grades to belong to positive or negative class more or less strongly. An extension of the Fuzzy model, which takes into account the trend in key features over time, provides excellent results with the training data, which, however, could not be finally verified due to the lack of suitable test data. The generation and training of the Fuzzy models was fully automatic and without additional adjustment with the help of ANFIS from Matlab(C).",1
"Tuli, S.; Tuli, S.; Verma, R.; Tuli, R.",2020,Modelling for prediction of the spread and severity of COVID-19 and its association with socioeconomic factors and virus types,Epidemiology,Modelling for prediction of the spread and severity of COVID-19 and its association with socioeconomic factors and virus types,"Tuli, S.; Tuli, S.; Verma, R.; Tuli, R.",Epidemiology,2020-06-20 00:00:00 UTC,"We report the development of a Weibull based Long-Short-Term-Memory approach (W-LSTM) for the prediction of COVID-19 disease. The W-LSTM model developed in this study, performs better in terms of MSE, R2 and MAPE, as compared to the previously published models, including ARIMA, LSTM and their variations. Using W-LSTM model, we have predicted the beginning and end of the current cycle of COVID-19 in several countries. Performance of the model was validated as satisfactory in 82% of the 50 test countries, while asking for prediction for 10 days beyond the period of training. Accuracy of the above prediction with days beyond training was assessed in comparison with the MAPE that the model gave with cumulative global data. The model was applied to study correlation between the growth of infection and deaths, and a number of effectors that may influence the epidemic. The model identified age groups, trade with China, air traffic, country temperature and CoV-2 virus types as the likely effectors of infection and virulence leading to deaths. The predictors likely to promote or suppress the epidemic were identified. Some of the predictors had significant effect on the shape parameters of Weibull distribution. The model can function on cloud, take inputs in real time and handle large data country wise, at low costs to make predictions dynamically. Such predictions are highly valuable in guiding policy makers, administration and health. Interactive curves generated from the W-LSTM model can be seen at http://collaboration.coraltele.com/covid2/.",10.1101/2020.06.18.20134874,virology-neural-networks.xlsx,"Modelling for prediction of the spread and severity of COVID-19 and its association with socioeconomic factors and virus types We report the development of a Weibull based Long-Short-Term-Memory approach (W-LSTM) for the prediction of COVID-19 disease. The W-LSTM model developed in this study, performs better in terms of MSE, R2 and MAPE, as compared to the previously published models, including ARIMA, LSTM and their variations. Using W-LSTM model, we have predicted the beginning and end of the current cycle of COVID-19 in several countries. Performance of the model was validated as satisfactory in 82% of the 50 test countries, while asking for prediction for 10 days beyond the period of training. Accuracy of the above prediction with days beyond training was assessed in comparison with the MAPE that the model gave with cumulative global data. The model was applied to study correlation between the growth of infection and deaths, and a number of effectors that may influence the epidemic. The model identified age groups, trade with China, air traffic, country temperature and CoV-2 virus types as the likely effectors of infection and virulence leading to deaths. The predictors likely to promote or suppress the epidemic were identified. Some of the predictors had significant effect on the shape parameters of Weibull distribution. The model can function on cloud, take inputs in real time and handle large data country wise, at low costs to make predictions dynamically. Such predictions are highly valuable in guiding policy makers, administration and health. Interactive curves generated from the W-LSTM model can be seen at http://collaboration.coraltele.com/covid2/.",1
"Tian, Y.; Luthra, I.; Zhang, X.",2020,Forecasting COVID-19 cases using Machine Learning models,Epidemiology,Forecasting COVID-19 cases using Machine Learning models,"Tian, Y.; Luthra, I.; Zhang, X.",Epidemiology,2020-07-04 00:00:00 UTC,"As of April 26, 2020, more than 2,994,958 cases of COVID-19 infection have been confirmed globally, raising a challenging public health issue. A predictive model of the disease would help allocate medical resources and determine social distancing measures more efficiently. In this paper, we gathered case data from Jan 22, 2020 to April 14 for 6 countries to compare different models proficiency in COVID-19 cases prediction. We assessed the performance of 3 machine learning models including hidden Markov chain model (HMM), hierarchical Bayes model, and long-short-term-memory model (LSTM) using the root-mean-square error (RMSE). The LSTM model had the consistently smallest prediction error rates for tracking the dynamics of incidents cases in 4 countries. In contrast, hierarchical Bayes model provided the most realistic prediction with the capability of identifying a plateau point in the incidents growth curve.",10.1101/2020.07.02.20145474,virology-neural-networks.xlsx,"Forecasting COVID-19 cases using Machine Learning models As of April 26, 2020, more than 2,994,958 cases of COVID-19 infection have been confirmed globally, raising a challenging public health issue. A predictive model of the disease would help allocate medical resources and determine social distancing measures more efficiently. In this paper, we gathered case data from Jan 22, 2020 to April 14 for 6 countries to compare different models proficiency in COVID-19 cases prediction. We assessed the performance of 3 machine learning models including hidden Markov chain model (HMM), hierarchical Bayes model, and long-short-term-memory model (LSTM) using the root-mean-square error (RMSE). The LSTM model had the consistently smallest prediction error rates for tracking the dynamics of incidents cases in 4 countries. In contrast, hierarchical Bayes model provided the most realistic prediction with the capability of identifying a plateau point in the incidents growth curve.",1
"Syed, S.; Morseth, B.; Hopstock, L. A.; Horsch, A.",2020,A novel algorithm to detect non-wear time from raw accelerometer data using convolutional neural networks,Epidemiology,A novel algorithm to detect non-wear time from raw accelerometer data using convolutional neural networks,"Syed, S.; Morseth, B.; Hopstock, L. A.; Horsch, A.",Epidemiology,2020-07-09 00:00:00 UTC,"Current non-wear detection algorithms frequently employ a 30- to 90-minute interval in which recorded acceleration needs to be below a threshold value. Such intervals need to be long enough to prevent false positives (type I errors), while short enough to prevent false negatives (type II errors), limiting their ability to achieve a high F1 score. In this paper, we propose a novel non-wear detection algorithm that eliminates the need for an interval. Rather than inspecting acceleration within intervals, we explore acceleration patterns right before and right after an episode of non-wear time. By drawing on insights from the field of activity type recognition, we propose an algorithm that uses a convolutional neural network to detect the preceding activity  taking off the accelerometer and the following activity  placing it back on. We evaluate our algorithm against several baseline and existing non-wear algorithms for raw accelerometer data, and our algorithm achieves a perfect precision, a recall of 0.9962, and an F1 score of 0.9981, outperforming all evaluated baseline and non-wear algorithms. Although our algorithm was developed using patterns learned from a hip-worn accelerometer, we propose algorithmic steps that can easily be applied to a wrist-worn accelerometer and a retrained classification model.",10.1101/2020.07.08.20148015,virology-neural-networks.xlsx,"A novel algorithm to detect non-wear time from raw accelerometer data using convolutional neural networks Current non-wear detection algorithms frequently employ a 30- to 90-minute interval in which recorded acceleration needs to be below a threshold value. Such intervals need to be long enough to prevent false positives (type I errors), while short enough to prevent false negatives (type II errors), limiting their ability to achieve a high F1 score. In this paper, we propose a novel non-wear detection algorithm that eliminates the need for an interval. Rather than inspecting acceleration within intervals, we explore acceleration patterns right before and right after an episode of non-wear time. By drawing on insights from the field of activity type recognition, we propose an algorithm that uses a convolutional neural network to detect the preceding activity  taking off the accelerometer and the following activity  placing it back on. We evaluate our algorithm against several baseline and existing non-wear algorithms for raw accelerometer data, and our algorithm achieves a perfect precision, a recall of 0.9962, and an F1 score of 0.9981, outperforming all evaluated baseline and non-wear algorithms. Although our algorithm was developed using patterns learned from a hip-worn accelerometer, we propose algorithmic steps that can easily be applied to a wrist-worn accelerometer and a retrained classification model.",0
"Ge, Q.; Hu, Z.; Zhang, K.; Li, S.; Lin, W.; Jin, L.; Xiong, M.",2020,Outbreak of Covid-19 worldwide is on the decline-----Recurrent Neural Reinforcement Learning and Health Interventions to Curb the Spread of Covid-19 in the world,Epidemiology,Outbreak of Covid-19 worldwide is on the decline-----Recurrent Neural Reinforcement Learning and Health Interventions to Curb the Spread of Covid-19 in the world,"Ge, Q.; Hu, Z.; Zhang, K.; Li, S.; Lin, W.; Jin, L.; Xiong, M.",Epidemiology,2020-08-12 00:00:00 UTC,"As the Covid-19 pandemic soars around the world, there is urgent need to forecast the expected number of cases worldwide and the length of the pandemic before receding and implement public health interventions for significantly stopping the spread of Covid-19. Widely used statistical and computer methods for modeling and forecasting the trajectory of Covid-19 are epidemiological models. Although these epidemiological models are useful for estimating the dynamics of transmission of epidemics, their prediction accuracies are quite low. Alternative to the epidemiological models, the reinforcement learning (RL) and causal inference emerge as a powerful tool to select optimal interventions for worldwide containment of Covid-19. Therefore, we formulated real-time forecasting and evaluation of multiple public health intervention problems into off-policy evaluation (OPE) and counterfactual outcome forecasting problems and integrated RL and recurrent neural network (RNN) for exploring public health intervention strategies to slow down the spread of Covid-19 worldwide, given the historical data that may have been generated by different public health intervention policies. We applied the developed methods to real data collected from January 22, 2020 to July 30, 2020 for real-time forecasting the confirmed cases of Covid-19 across the world. We observed that the number of new cases of Covid-19 worldwide reached a peak (407,205) on July 24, 2020 and forecasted that the number of laboratory-confirmed cumulative cases of Covid-19 will pass 20 million as of August 22, 2020. The results showed that outbreak of Covid-19 worldwide has peaked and is on the decline",10.1101/2020.07.08.20149146,virology-neural-networks.xlsx,"Outbreak of Covid-19 worldwide is on the decline-----Recurrent Neural Reinforcement Learning and Health Interventions to Curb the Spread of Covid-19 in the world As the Covid-19 pandemic soars around the world, there is urgent need to forecast the expected number of cases worldwide and the length of the pandemic before receding and implement public health interventions for significantly stopping the spread of Covid-19. Widely used statistical and computer methods for modeling and forecasting the trajectory of Covid-19 are epidemiological models. Although these epidemiological models are useful for estimating the dynamics of transmission of epidemics, their prediction accuracies are quite low. Alternative to the epidemiological models, the reinforcement learning (RL) and causal inference emerge as a powerful tool to select optimal interventions for worldwide containment of Covid-19. Therefore, we formulated real-time forecasting and evaluation of multiple public health intervention problems into off-policy evaluation (OPE) and counterfactual outcome forecasting problems and integrated RL and recurrent neural network (RNN) for exploring public health intervention strategies to slow down the spread of Covid-19 worldwide, given the historical data that may have been generated by different public health intervention policies. We applied the developed methods to real data collected from January 22, 2020 to July 30, 2020 for real-time forecasting the confirmed cases of Covid-19 across the world. We observed that the number of new cases of Covid-19 worldwide reached a peak (407,205) on July 24, 2020 and forecasted that the number of laboratory-confirmed cumulative cases of Covid-19 will pass 20 million as of August 22, 2020. The results showed that outbreak of Covid-19 worldwide has peaked and is on the decline",1
"Li, Y.; Jia, W.; Wang, J.; Guo, J.; Liu, Q.; Li, X.; Xie, G.; Wang, F.",2020,ALeRT-COVID: Attentive Lockdown-awaRe Transfer Learning for Predicting COVID-19 Pandemics in Different Countries,Epidemiology,ALeRT-COVID: Attentive Lockdown-awaRe Transfer Learning for Predicting COVID-19 Pandemics in Different Countries,"Li, Y.; Jia, W.; Wang, J.; Guo, J.; Liu, Q.; Li, X.; Xie, G.; Wang, F.",Epidemiology,2020-07-10 00:00:00 UTC,"Countries across the world are in different stages of COVID-19 trajectory, among which many have implemented the lockdown measures to prevent its spread. Although the lockdown is effective in such prevention, it may put the economy into a depression. Predicting the epidemic progression with government switching the lockdown on or off is critical. We propose a transfer learning approach called ALeRT-COVID using attention-based recurrent neural network (RNN) architecture to predict the epidemic trends for different countries. A source model was trained on the pre-defined source countries and then transferred to each target country. The lockdown measure was introduced to our model as a predictor and the attention mechanism was utilized to learn the different contributions of the confirmed cases in the past days to the future trend. Results demonstrated that the transfer learning strategy is helpful especially for early-stage countries. By introducing the lockdown predictor and the attention mechanism, ALeRT-COVID showed a significant improvement on the prediction performance. We predicted the confirmed cases in one week when extending and easing lockdown separately. Results showed the lockdown measures is still necessary for a number of countries. We expect our research can help different countries to make better decisions on the lockdown measures.",10.1101/2020.07.09.20149831,virology-neural-networks.xlsx,"ALeRT-COVID: Attentive Lockdown-awaRe Transfer Learning for Predicting COVID-19 Pandemics in Different Countries Countries across the world are in different stages of COVID-19 trajectory, among which many have implemented the lockdown measures to prevent its spread. Although the lockdown is effective in such prevention, it may put the economy into a depression. Predicting the epidemic progression with government switching the lockdown on or off is critical. We propose a transfer learning approach called ALeRT-COVID using attention-based recurrent neural network (RNN) architecture to predict the epidemic trends for different countries. A source model was trained on the pre-defined source countries and then transferred to each target country. The lockdown measure was introduced to our model as a predictor and the attention mechanism was utilized to learn the different contributions of the confirmed cases in the past days to the future trend. Results demonstrated that the transfer learning strategy is helpful especially for early-stage countries. By introducing the lockdown predictor and the attention mechanism, ALeRT-COVID showed a significant improvement on the prediction performance. We predicted the confirmed cases in one week when extending and easing lockdown separately. Results showed the lockdown measures is still necessary for a number of countries. We expect our research can help different countries to make better decisions on the lockdown measures.",1
"Agarwal, D. K.; De, S.; Shukla, O.; Checker, A.; Mittal, A.; Borah, A.; Gupta, D.",2020,Alternative Approaches for Modelling COVID-19:High-Accuracy Low-Data Predictions,Epidemiology,Alternative Approaches for Modelling COVID-19:High-Accuracy Low-Data Predictions,"Agarwal, D. K.; De, S.; Shukla, O.; Checker, A.; Mittal, A.; Borah, A.; Gupta, D.",Epidemiology,2020-07-25 00:00:00 UTC,"BackgroundNumerous models have tried to predict the spread of COVID-19. Many involve myriad assumptions and parameters which cannot be reliably calculated under current conditions. We describe machine-learning and curve-fitting based models using fewer assumptions and readily available data.

MethodsInstead of relying on highly parameterized models, we design and train multiple neural networks with data on a national and state level, from 9 COVID-19 affected countries, including Indian and US states and territories. Further, we use an array of curve-fitting techniques on government-reported numbers of COVID-19 infections and deaths, separately projecting and collating curves from multiple regions across the globe, at multiple levels of granularity, combining heavily-localized extrapolations to create accurate national predictions.

FindingsWe achieve an R2 of 0{middle dot}999 on average through the use of curve-fits and fine-tuned statistical learning methods on historical, global data. Using neural network implementations, we consistently predict the number of reported cases in 9 geographically- and demographically-varied countries and states with an accuracy of 99{middle dot}53% for 14 days of forecast and 99{middle dot}1% for 24 days of forecast.

InterpretationWe have shown that curve-fitting and machine-learning methods applied on reported COVID-19 data almost perfectly reproduce the results of far more complex and data-intensive epidemiological models. Using our methods, several other parameters may be established, such as the average detection rate of COVID-19. As an example, we find that the detection rate of cases in India (even with our most lenient estimates) is 2.38% - almost a fourth of the world average of 9% [1].",10.1101/2020.07.22.20159731,virology-neural-networks.xlsx,"Alternative Approaches for Modelling COVID-19:High-Accuracy Low-Data Predictions BackgroundNumerous models have tried to predict the spread of COVID-19. Many involve myriad assumptions and parameters which cannot be reliably calculated under current conditions. We describe machine-learning and curve-fitting based models using fewer assumptions and readily available data.

MethodsInstead of relying on highly parameterized models, we design and train multiple neural networks with data on a national and state level, from 9 COVID-19 affected countries, including Indian and US states and territories. Further, we use an array of curve-fitting techniques on government-reported numbers of COVID-19 infections and deaths, separately projecting and collating curves from multiple regions across the globe, at multiple levels of granularity, combining heavily-localized extrapolations to create accurate national predictions.

FindingsWe achieve an R2 of 0{middle dot}999 on average through the use of curve-fits and fine-tuned statistical learning methods on historical, global data. Using neural network implementations, we consistently predict the number of reported cases in 9 geographically- and demographically-varied countries and states with an accuracy of 99{middle dot}53% for 14 days of forecast and 99{middle dot}1% for 24 days of forecast.

InterpretationWe have shown that curve-fitting and machine-learning methods applied on reported COVID-19 data almost perfectly reproduce the results of far more complex and data-intensive epidemiological models. Using our methods, several other parameters may be established, such as the average detection rate of COVID-19. As an example, we find that the detection rate of cases in India (even with our most lenient estimates) is 2.38% - almost a fourth of the world average of 9% [1].",1
"Dandekar, R.; Rackauckas, C.; Barbastathis, G.",2020,A machine learning aided global diagnostic and comparative tool to assess effect of quarantine control in Covid-19 spread,Epidemiology,A machine learning aided global diagnostic and comparative tool to assess effect of quarantine control in Covid-19 spread,"Dandekar, R.; Rackauckas, C.; Barbastathis, G.",Epidemiology,2020-07-24 00:00:00 UTC,"1We have developed a globally applicable diagnostic Covid-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms employed on publicly available Covid-19 data. The model decomposes the contributions to the infection timeseries to analyze and compare the role of quarantine control policies employed in highly affected regions of Europe, North America, South America and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions respective governments. Finally, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform, which can be used for informed decision making by public health officials and researchers alike.

Article Summary LineData-driven epidemiological model to quantify and compare quarantine control policies in controlling COVID-19 spread in Europe, North America, South America and Asia.",10.1101/2020.07.23.20160697,virology-neural-networks.xlsx,"A machine learning aided global diagnostic and comparative tool to assess effect of quarantine control in Covid-19 spread 1We have developed a globally applicable diagnostic Covid-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms employed on publicly available Covid-19 data. The model decomposes the contributions to the infection timeseries to analyze and compare the role of quarantine control policies employed in highly affected regions of Europe, North America, South America and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions respective governments. Finally, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform, which can be used for informed decision making by public health officials and researchers alike.

Article Summary LineData-driven epidemiological model to quantify and compare quarantine control policies in controlling COVID-19 spread in Europe, North America, South America and Asia.",1
"Gola, A.; Arya, R. K.; Animesh, A.; Dugh, R.",2020,Review of Forecasting Models for Coronavirus (COVID-19) Pandemic in India during Country-wise Lockdowns,Epidemiology,Review of Forecasting Models for Coronavirus (COVID-19) Pandemic in India during Country-wise Lockdowns,"Gola, A.; Arya, R. K.; Animesh, A.; Dugh, R.",Epidemiology,2020-08-11 00:00:00 UTC,"BackgroundCOVID-19 is widely spreading across the globe right now. While some countries have flattened the curve, others are struggling to control the spread of the infection. Precise risk prediction modeling is key to accurate prevention and containment of COVID-19 infection, as well as for the preparation of resources needed to deal with the pandemic in different regions.

MethodsGiven the vast differences in approaches and scenarios used by these models to predict future infection rates, in this study, we compared the accuracy among different models such as regression models, ARIMA model, multilayer perceptron, vector autoregression, susceptible exposed infected recovered (SEIR), susceptible infected recovered (SIR), recurrent neural networks (RNNs), long short term memory networks (LSTM) and exponential growth model in prediction of the total COVID-19 confirmed cases. We did so by comparing the predicted rates of these models with actual rates of COVID-19 in India during the nationwide lockdowns.

ResultsFew of these models accurately predicted COVID-19 incidence and mortality rates in six weeks, though some provided close results. While advanced warning can help mitigate and prepare for an impending or ongoing epidemic, using poorly fitting models for prediction could lead to substantial adverse outcomes.

ImplicationsAs the COVID-19 pandemic continues, accurate risk prediction is key to effective public health interventions. Caution should be taken when choosing different risk prediction models based on specific scenarios and needs. To improve risk prediction of infectious disease such as COVID-19 for policy guidance and recommendations on best practices, both internal (e.g., specific virus characteristics in transmission and mutation) and external factors (e.g., large-scale human behaviors such as school opening, parties, and breaks) should be considered and appropriately weighed.",10.1101/2020.08.03.20167254,virology-neural-networks.xlsx,"Review of Forecasting Models for Coronavirus (COVID-19) Pandemic in India during Country-wise Lockdowns BackgroundCOVID-19 is widely spreading across the globe right now. While some countries have flattened the curve, others are struggling to control the spread of the infection. Precise risk prediction modeling is key to accurate prevention and containment of COVID-19 infection, as well as for the preparation of resources needed to deal with the pandemic in different regions.

MethodsGiven the vast differences in approaches and scenarios used by these models to predict future infection rates, in this study, we compared the accuracy among different models such as regression models, ARIMA model, multilayer perceptron, vector autoregression, susceptible exposed infected recovered (SEIR), susceptible infected recovered (SIR), recurrent neural networks (RNNs), long short term memory networks (LSTM) and exponential growth model in prediction of the total COVID-19 confirmed cases. We did so by comparing the predicted rates of these models with actual rates of COVID-19 in India during the nationwide lockdowns.

ResultsFew of these models accurately predicted COVID-19 incidence and mortality rates in six weeks, though some provided close results. While advanced warning can help mitigate and prepare for an impending or ongoing epidemic, using poorly fitting models for prediction could lead to substantial adverse outcomes.

ImplicationsAs the COVID-19 pandemic continues, accurate risk prediction is key to effective public health interventions. Caution should be taken when choosing different risk prediction models based on specific scenarios and needs. To improve risk prediction of infectious disease such as COVID-19 for policy guidance and recommendations on best practices, both internal (e.g., specific virus characteristics in transmission and mutation) and external factors (e.g., large-scale human behaviors such as school opening, parties, and breaks) should be considered and appropriately weighed.",1
"Natarajan, A.; Su, H.-W.; Heneghan, C.",2020,Assessment of physiological signs associated with COVID-19 measured using wearable devices,Epidemiology,Assessment of physiological signs associated with COVID-19 measured using wearable devices,"Natarajan, A.; Su, H.-W.; Heneghan, C.",Epidemiology,2020-08-16 00:00:00 UTC,"Respiration rate, heart rate, and heart rate variability are some health metrics that are easily measured by consumer devices and which can potentially provide early signs of illness. Furthermore, mobile applications which accompany wearable devices can be used to collect relevant self-reported symptoms and demographic data. This makes consumer devices a valuable tool in the fight against the COVID-19 pandemic. We considered two approaches to assessing COVID-19 - a symptom-based approach, and a physiological signs based technique. Firstly, we trained a Logistic Regression classifier to predict the need for hospitalization of COVID-19 patients given the symptoms experienced, age, sex, and BMI. Secondly, we trained a neural network classifier to predict whether a person is sick on any specific day given respiration rate, heart rate, and heart rate variability data for that day and and for the four preceding days. Data on 1,181 subjects diagnosed with COVID-19 (active infection, PCR test) were collected from May 21 - July 14, 2020. 11.0% of COVID-19 subjects were asymptomatic, 47.2% of subjects recovered at home by themselves, 33.2% recovered at home with the help of someone else, 8.16% of subjects required hospitalization without ventilation support, and 0.448% required ventilation. Fever was present in 54.8% of subjects. Based on self-reported symptoms alone, we obtained an AUC of 0.77 {+/-} 0.05 for the prediction of the need for hospitalization. Based on physiological signs, we obtained an AUC of 0.77 {+/-} 0.03 for the prediction of illness on a specific day with 4 previous days of history. Respiration rate and heart rate are typically elevated by illness, while heart rate variability is decreased. Measuring these metrics can help in early diagnosis, and in monitoring the progress of the disease.",10.1101/2020.08.14.20175265,virology-neural-networks.xlsx,"Assessment of physiological signs associated with COVID-19 measured using wearable devices Respiration rate, heart rate, and heart rate variability are some health metrics that are easily measured by consumer devices and which can potentially provide early signs of illness. Furthermore, mobile applications which accompany wearable devices can be used to collect relevant self-reported symptoms and demographic data. This makes consumer devices a valuable tool in the fight against the COVID-19 pandemic. We considered two approaches to assessing COVID-19 - a symptom-based approach, and a physiological signs based technique. Firstly, we trained a Logistic Regression classifier to predict the need for hospitalization of COVID-19 patients given the symptoms experienced, age, sex, and BMI. Secondly, we trained a neural network classifier to predict whether a person is sick on any specific day given respiration rate, heart rate, and heart rate variability data for that day and and for the four preceding days. Data on 1,181 subjects diagnosed with COVID-19 (active infection, PCR test) were collected from May 21 - July 14, 2020. 11.0% of COVID-19 subjects were asymptomatic, 47.2% of subjects recovered at home by themselves, 33.2% recovered at home with the help of someone else, 8.16% of subjects required hospitalization without ventilation support, and 0.448% required ventilation. Fever was present in 54.8% of subjects. Based on self-reported symptoms alone, we obtained an AUC of 0.77 {+/-} 0.05 for the prediction of the need for hospitalization. Based on physiological signs, we obtained an AUC of 0.77 {+/-} 0.03 for the prediction of illness on a specific day with 4 previous days of history. Respiration rate and heart rate are typically elevated by illness, while heart rate variability is decreased. Measuring these metrics can help in early diagnosis, and in monitoring the progress of the disease.",1
"Bhattacharyya, A.; Chakraborty, T.; Rai, S. N.",2021,Stochastic forecasting of COVID-19 daily new cases across countries with a novel hybrid time series model,Epidemiology,Stochastic forecasting of COVID-19 daily new cases across countries with a novel hybrid time series model,"Bhattacharyya, A.; Chakraborty, T.; Rai, S. N.",Epidemiology,2021-05-02 00:00:00 UTC,"An unprecedented outbreak of the novel coronavirus (COVID-19) in the form of peculiar pneumonia has spread globally since its first case in Wuhan province, China, in December 2019. Soon after, the infected cases and mortality increased rapidly. The future of the pandemics progress was uncertain, and thus, predicting it became crucial for public health researchers. These future predictions help the effective allocation of health care resources, stockpiling, and help in strategic planning for clinicians, government authorities, and public health policymakers after understanding the extent of the effect. The main objective of this paper is to develop a hybrid forecasting model that can generate real-time out-of-sample forecasts of COVID-19 outbreaks for five profoundly affected countries, namely the USA, Brazil, India, UK, and Canada. A novel hybrid approach based on the Theta method and Autoregressive neural network (ARNN) model, named Theta-ARNN (TARNN) model, is developed. Daily new cases of COVID-19 are nonlinear, non-stationary, and volatile; thus a single specific model cannot be ideal for future prediction of the pandemic. However, the newly introduced hybrid forecasting model with an acceptable prediction error rate can help healthcare and government for effective planning and resource allocation. The proposed method outperforms traditional univariate and hybrid forecasting models for the test data sets on an average.",10.1101/2020.10.01.20205021,virology-neural-networks.xlsx,"Stochastic forecasting of COVID-19 daily new cases across countries with a novel hybrid time series model An unprecedented outbreak of the novel coronavirus (COVID-19) in the form of peculiar pneumonia has spread globally since its first case in Wuhan province, China, in December 2019. Soon after, the infected cases and mortality increased rapidly. The future of the pandemics progress was uncertain, and thus, predicting it became crucial for public health researchers. These future predictions help the effective allocation of health care resources, stockpiling, and help in strategic planning for clinicians, government authorities, and public health policymakers after understanding the extent of the effect. The main objective of this paper is to develop a hybrid forecasting model that can generate real-time out-of-sample forecasts of COVID-19 outbreaks for five profoundly affected countries, namely the USA, Brazil, India, UK, and Canada. A novel hybrid approach based on the Theta method and Autoregressive neural network (ARNN) model, named Theta-ARNN (TARNN) model, is developed. Daily new cases of COVID-19 are nonlinear, non-stationary, and volatile; thus a single specific model cannot be ideal for future prediction of the pandemic. However, the newly introduced hybrid forecasting model with an acceptable prediction error rate can help healthcare and government for effective planning and resource allocation. The proposed method outperforms traditional univariate and hybrid forecasting models for the test data sets on an average.",1
"Paul, S. K.; Jana, S.; Bhaumik, P.",2020,On nonlinear incidence rate of Covid-19,Epidemiology,On nonlinear incidence rate of Covid-19,"Paul, S. K.; Jana, S.; Bhaumik, P.",Epidemiology,2020-10-21 00:00:00 UTC,"Classical Susceptible-Infected-Removed model with constant transmission rate and removal rate may not capture real world dynamics of epidemic due to complex influence of multiple external factors on the spread. On top of that transmission rate may vary widely in a large region due to non-stationarity of spatial features which poses difficulty in creating a global model. We modified discrete global Susceptible-Infected-Removed model by using time varying transmission rate, recovery rate and multiple spatially local models. No specific functional form of transmission rate has been assumed. We have derived the criteria for disease-free equilibrium within a specific time period. A single Convolutional LSTM model is created and trained to map multiple spatiotemporal features to transmission rate. The model achieved 8.39% mean absolute percent error in terms of cumulative infection cases in each locality in a 10-day prediction period. Local interpretations of the model using perturbation method reveals local influence of different features on transmission rate which in turn is used to generate a set of generalized global interpretations. A what-if scenario with modified recovery rate illustrates rapid dampening of the spread when forecasted with the trained model. A comparative study with current normal scenario reveals key necessary steps to reach baseline.",10.1101/2020.10.19.20215665,virology-neural-networks.xlsx,"On nonlinear incidence rate of Covid-19 Classical Susceptible-Infected-Removed model with constant transmission rate and removal rate may not capture real world dynamics of epidemic due to complex influence of multiple external factors on the spread. On top of that transmission rate may vary widely in a large region due to non-stationarity of spatial features which poses difficulty in creating a global model. We modified discrete global Susceptible-Infected-Removed model by using time varying transmission rate, recovery rate and multiple spatially local models. No specific functional form of transmission rate has been assumed. We have derived the criteria for disease-free equilibrium within a specific time period. A single Convolutional LSTM model is created and trained to map multiple spatiotemporal features to transmission rate. The model achieved 8.39% mean absolute percent error in terms of cumulative infection cases in each locality in a 10-day prediction period. Local interpretations of the model using perturbation method reveals local influence of different features on transmission rate which in turn is used to generate a set of generalized global interpretations. A what-if scenario with modified recovery rate illustrates rapid dampening of the spread when forecasted with the trained model. A comparative study with current normal scenario reveals key necessary steps to reach baseline.",1
"Ardabili, S.; Mosavi, A.; Band, S. S.; Varkonyi-Koczy, A. R.",2020,Coronavirus Disease (COVID-19) Global Prediction Using Hybrid Artificial Intelligence Method of ANN Trained with Grey Wolf Optimizer,Epidemiology,Coronavirus Disease (COVID-19) Global Prediction Using Hybrid Artificial Intelligence Method of ANN Trained with Grey Wolf Optimizer,"Ardabili, S.; Mosavi, A.; Band, S. S.; Varkonyi-Koczy, A. R.",Epidemiology,2020-10-26 00:00:00 UTC,"An accurate outbreak prediction of COVID-19 can successfully help to get insight into the spread and consequences of infectious diseases. Recently, machine learning (ML) based prediction models have been successfully employed for the prediction of the disease outbreak. The present study aimed to engage an artificial neural network-integrated by grey wolf optimizer for COVID-19 outbreak predictions by employing the Global dataset. Training and testing processes have been performed by time-series data related to January 22 to September 15, 2020 and validation has been performed by time-series data related to September 16 to October 15, 2020. Results have been evaluated by employing mean absolute percentage error (MAPE) and correlation coefficient (r) values. ANN-GWO provided a MAPE of 6.23, 13.15 and 11.4% for training, testing and validating phases, respectively. According to the results, the developed model could successfully cope with the prediction task.",10.1101/2020.10.22.20217604,virology-neural-networks.xlsx,"Coronavirus Disease (COVID-19) Global Prediction Using Hybrid Artificial Intelligence Method of ANN Trained with Grey Wolf Optimizer An accurate outbreak prediction of COVID-19 can successfully help to get insight into the spread and consequences of infectious diseases. Recently, machine learning (ML) based prediction models have been successfully employed for the prediction of the disease outbreak. The present study aimed to engage an artificial neural network-integrated by grey wolf optimizer for COVID-19 outbreak predictions by employing the Global dataset. Training and testing processes have been performed by time-series data related to January 22 to September 15, 2020 and validation has been performed by time-series data related to September 16 to October 15, 2020. Results have been evaluated by employing mean absolute percentage error (MAPE) and correlation coefficient (r) values. ANN-GWO provided a MAPE of 6.23, 13.15 and 11.4% for training, testing and validating phases, respectively. According to the results, the developed model could successfully cope with the prediction task.",1
"Abhijit Dandekar, R.; Wang, E.; Barbastathis, G.; Rackauckas, C.",2021,Implications of delayed reopening in controlling the COVID-19 surge in Southern and West-Central USA,Epidemiology,Implications of delayed reopening in controlling the COVID-19 surge in Southern and West-Central USA,"Abhijit Dandekar, R.; Wang, E.; Barbastathis, G.; Rackauckas, C.",Epidemiology,2021-09-16 00:00:00 UTC,"1In the wake of the rapid surge in the Covid-19 infected cases seen in Southern and West-Central USA in the period of June-July 2020, there is an urgent need to develop robust, data-driven models to quantify the effect which early reopening had on the infected case count increase. In particular, it is imperative to address the question: How many infected cases could have been prevented, had the worst affected states not reopened early? To address this question, we have developed a novel Covid-19 model by augmenting the classical SIR epidemiological model with a neural network module. The model decomposes the contribution of quarantine strength to the infection timeseries, allowing us to quantify the role of quarantine control and the associated reopening policies in the US states which showed a major surge in infections. We show that the upsurge in the infected cases seen in these states is strongly co-related with a drop in the quarantine/lockdown strength diagnosed by our model. Further, our results demonstrate that in the event of a stricter lockdown without early reopening, the number of active infected cases recorded on 14 July could have been reduced by more than 40% in all states considered, with the actual number of infections reduced being more than 100, 000 for the states of Florida and Texas. As we continue our fight against Covid-19, our proposed model can be used as a valuable asset to simulate the effect of several reopening strategies on the infected count evolution; for any region under consideration.",10.1101/2020.12.01.20242172,virology-neural-networks.xlsx,"Implications of delayed reopening in controlling the COVID-19 surge in Southern and West-Central USA 1In the wake of the rapid surge in the Covid-19 infected cases seen in Southern and West-Central USA in the period of June-July 2020, there is an urgent need to develop robust, data-driven models to quantify the effect which early reopening had on the infected case count increase. In particular, it is imperative to address the question: How many infected cases could have been prevented, had the worst affected states not reopened early? To address this question, we have developed a novel Covid-19 model by augmenting the classical SIR epidemiological model with a neural network module. The model decomposes the contribution of quarantine strength to the infection timeseries, allowing us to quantify the role of quarantine control and the associated reopening policies in the US states which showed a major surge in infections. We show that the upsurge in the infected cases seen in these states is strongly co-related with a drop in the quarantine/lockdown strength diagnosed by our model. Further, our results demonstrate that in the event of a stricter lockdown without early reopening, the number of active infected cases recorded on 14 July could have been reduced by more than 40% in all states considered, with the actual number of infections reduced being more than 100, 000 for the states of Florida and Texas. As we continue our fight against Covid-19, our proposed model can be used as a valuable asset to simulate the effect of several reopening strategies on the infected count evolution; for any region under consideration.",1
"Rieckmann, A.; Dworzynski, P.; Arras, L.; Lapuschkin, S.; Samek, W.; Arah, O. A.; Rod, N. H.; Ekstrom, C. T.",2020,Causes of Outcome Learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome,Epidemiology,Causes of Outcome Learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome,"Rieckmann, A.; Dworzynski, P.; Arras, L.; Lapuschkin, S.; Samek, W.; Arah, O. A.; Rod, N. H.; Ekstrom, C. T.",Epidemiology,2020-12-13 00:00:00 UTC,"Nearly all diseases can be caused by different combinations of exposures. Yet, most epidemiological studies focus on the causal effect of a single exposure on an outcome. We present the Causes of Outcome Learning (CoOL) approach, which seeks to identify combinations of exposures (which can be interpreted causally if all causal assumptions are met) that could be responsible for an increased risk of a health outcome in population sub-groups. The approach allows for exposures acting alone and in synergy with others. It involves (a) a pre-computational phase that proposes a causal model; (b) a computational phase with three steps, namely (i) analytically fitting a non-negative additive model, (ii) decomposing risk contributions, and (iii) clustering individuals based on the risk contributions into sub-groups based on the predefined causal model; and (c) a post-computational phase on hypothesis development and validation by triangulation on new data before eventually updating the causal model. The computational phase uses a tailored neural network for the non-negative additive model and Layer-wise Relevance Propagation for the risk decomposition through this model. We demonstrate the approach on simulated and real-life data using the R package  CoOL. The presentation is focused on binary exposures and outcomes but can be extended to other measurement types. This approach encourages and enables epidemiologists to identify combinations of pre-outcome exposures as potential causes of the health outcome of interest. Expanding our ability to discover complex causes could eventually result in more effective, targeted, and informed interventions prioritized for their public health impact.",10.1101/2020.12.10.20225243,virology-neural-networks.xlsx,"Causes of Outcome Learning: A causal inference-inspired machine learning approach to disentangling common combinations of potential causes of a health outcome Nearly all diseases can be caused by different combinations of exposures. Yet, most epidemiological studies focus on the causal effect of a single exposure on an outcome. We present the Causes of Outcome Learning (CoOL) approach, which seeks to identify combinations of exposures (which can be interpreted causally if all causal assumptions are met) that could be responsible for an increased risk of a health outcome in population sub-groups. The approach allows for exposures acting alone and in synergy with others. It involves (a) a pre-computational phase that proposes a causal model; (b) a computational phase with three steps, namely (i) analytically fitting a non-negative additive model, (ii) decomposing risk contributions, and (iii) clustering individuals based on the risk contributions into sub-groups based on the predefined causal model; and (c) a post-computational phase on hypothesis development and validation by triangulation on new data before eventually updating the causal model. The computational phase uses a tailored neural network for the non-negative additive model and Layer-wise Relevance Propagation for the risk decomposition through this model. We demonstrate the approach on simulated and real-life data using the R package  CoOL. The presentation is focused on binary exposures and outcomes but can be extended to other measurement types. This approach encourages and enables epidemiologists to identify combinations of pre-outcome exposures as potential causes of the health outcome of interest. Expanding our ability to discover complex causes could eventually result in more effective, targeted, and informed interventions prioritized for their public health impact.",0
"Kabeya, Y.; Okubo, M.; Yonezawa, S.; Nakano, H.; Inoue, M.; Ogasawara, M.; Saito, Y.; Tanboon, J.; Indrawati, L. A.; Kumutpongpanich, T.; Chen, Y.-L.; Yoshioka, W.; Hayashi, S.; Iwamori, T.; Takeuchi, Y.; Tokumasu, R.; Takano, A.; Matsuda, F.; Nishino, I.",2020,A deep convolutional neural network-based algorithm for muscle biopsy diagnosis outperforms human specialists,Pathology,A deep convolutional neural network-based algorithm for muscle biopsy diagnosis outperforms human specialists,"Kabeya, Y.; Okubo, M.; Yonezawa, S.; Nakano, H.; Inoue, M.; Ogasawara, M.; Saito, Y.; Tanboon, J.; Indrawati, L. A.; Kumutpongpanich, T.; Chen, Y.-L.; Yoshioka, W.; Hayashi, S.; Iwamori, T.; Takeuchi, Y.; Tokumasu, R.; Takano, A.; Matsuda, F.; Nishino, I.",Pathology,2020-12-16 00:00:00 UTC,"Histopathologic evaluation is essential for categorizing and studying neuromuscular disorders. However, experienced specialists and pathologists are limited, especially in underserved areas. Although new technologies, such as artificial intelligence, are expected to improve medical reach, their use in rare diseases is challenging because of the limited availability of training datasets. To address this knowledge gap, we developed an algorithm based on deep convolutional neural networks that used data from microscopic images of hematoxylin-and-eosin-stained pathology slides. Our algorithm differentiated idiopathic inflammatory myopathies (mostly treatable) from hereditary muscle diseases (mostly non-treatable) and achieved better sensitivity and specificity than real physicians diagnoses. Furthermore, it successfully and accurately classified four subtypes of the abovementioned muscular conditions. These results suggest that our algorithm can be safely used in a clinical setting. We established the similarity between the algorithms and physicians predictions using visualization technology, and clarified the validity of the predictions.",10.1101/2020.12.15.20248231,virology-neural-networks.xlsx,"A deep convolutional neural network-based algorithm for muscle biopsy diagnosis outperforms human specialists Histopathologic evaluation is essential for categorizing and studying neuromuscular disorders. However, experienced specialists and pathologists are limited, especially in underserved areas. Although new technologies, such as artificial intelligence, are expected to improve medical reach, their use in rare diseases is challenging because of the limited availability of training datasets. To address this knowledge gap, we developed an algorithm based on deep convolutional neural networks that used data from microscopic images of hematoxylin-and-eosin-stained pathology slides. Our algorithm differentiated idiopathic inflammatory myopathies (mostly treatable) from hereditary muscle diseases (mostly non-treatable) and achieved better sensitivity and specificity than real physicians diagnoses. Furthermore, it successfully and accurately classified four subtypes of the abovementioned muscular conditions. These results suggest that our algorithm can be safely used in a clinical setting. We established the similarity between the algorithms and physicians predictions using visualization technology, and clarified the validity of the predictions.",0
"Tabrizchi, H.; Mosavi, A.; Szabo-Gali, A.; Nadai, L.",2020,Rapid COVID-19 Diagnosis Using Deep Learning of the Computerized Tomography Scans,Epidemiology,Rapid COVID-19 Diagnosis Using Deep Learning of the Computerized Tomography Scans,"Tabrizchi, H.; Mosavi, A.; Szabo-Gali, A.; Nadai, L.",Epidemiology,2020-12-23 00:00:00 UTC,"Several studies suggest that COVID-19 may be accompanied by symptoms such as a dry cough, muscle aches, sore throat, and mild to moderate respiratory illness. The symptoms of this disease indicate the fact that COVID-19 causes noticeable negative effects on the lungs. Therefore, considering the health status of the lungs using X-rays and CT scans of the chest can significantly help diagnose COVID-19 infection. Due to the fact that most of the methods that have been proposed to COVID-19 diagnose deal with the lengthy testing time and also might give more false positive and false negative results, this paper aims to review and implement artificial intelligence (AI) image-based diagnosis methods in order to detect coronavirus infection with zero or near to zero false positives and false negatives rates. Besides the already existing AI image-based medical diagnosis method for the other well-known disease, this study aims on finding the most accurate COVID-19 detection method among AI methods such as machine learning (ML) and artificial neural network (ANN), ensemble learning (EL) methods.",10.1101/2020.12.20.20248582,virology-neural-networks.xlsx,"Rapid COVID-19 Diagnosis Using Deep Learning of the Computerized Tomography Scans Several studies suggest that COVID-19 may be accompanied by symptoms such as a dry cough, muscle aches, sore throat, and mild to moderate respiratory illness. The symptoms of this disease indicate the fact that COVID-19 causes noticeable negative effects on the lungs. Therefore, considering the health status of the lungs using X-rays and CT scans of the chest can significantly help diagnose COVID-19 infection. Due to the fact that most of the methods that have been proposed to COVID-19 diagnose deal with the lengthy testing time and also might give more false positive and false negative results, this paper aims to review and implement artificial intelligence (AI) image-based diagnosis methods in order to detect coronavirus infection with zero or near to zero false positives and false negatives rates. Besides the already existing AI image-based medical diagnosis method for the other well-known disease, this study aims on finding the most accurate COVID-19 detection method among AI methods such as machine learning (ML) and artificial neural network (ANN), ensemble learning (EL) methods.",1
"Gahan, P.; Pattnaik, M.; Nayak, A.; Roul, M. K.",2021,Prediction of COVID-19 Pandemic of Top Ten Countries in the World Establishing a Hybrid AARNN LTM Model,Epidemiology,Prediction of COVID-19 Pandemic of Top Ten Countries in the World Establishing a Hybrid AARNN LTM Model,"Gahan, P.; Pattnaik, M.; Nayak, A.; Roul, M. K.",Epidemiology,2021-01-05 00:00:00 UTC,"The novel COVID-19 global pandemic has become a public health emergency of international concern affecting 215 countries and territories around the globe. As of 28 November 2020, it has caused a pandemic outbreak with a total of more than 6,171,5119 confirmed infections and more than 1,44,4235 confirmed deaths reported worldwide. The main focus of this paper is to generate LTM real-time out of sample forecasts of the future COVID-19 confirmed and death cases respectively for the top ten profoundly affected countries including for the world. To solve this problem we introduced a novel hybrid approach AARNN model based on ARIMA and ARNN forecasting model that can generate LTM (fifty days ahead) out of sample forecasts of the number of daily confirmed and death COVID-19 cases for the ten countries namely USA, India, Brazil, Russia, France, Spain, UK, Italy, Argentina, Colombia and also for the world respectively. The predictions of the future outbreak for different countries will be useful for the effective allocation of health care resources and will act as early-warning system for health warriors, corporate leaders, economists, government/public-policy makers, and scientific experts.",10.1101/2020.12.31.20249105,virology-neural-networks.xlsx,"Prediction of COVID-19 Pandemic of Top Ten Countries in the World Establishing a Hybrid AARNN LTM Model The novel COVID-19 global pandemic has become a public health emergency of international concern affecting 215 countries and territories around the globe. As of 28 November 2020, it has caused a pandemic outbreak with a total of more than 6,171,5119 confirmed infections and more than 1,44,4235 confirmed deaths reported worldwide. The main focus of this paper is to generate LTM real-time out of sample forecasts of the future COVID-19 confirmed and death cases respectively for the top ten profoundly affected countries including for the world. To solve this problem we introduced a novel hybrid approach AARNN model based on ARIMA and ARNN forecasting model that can generate LTM (fifty days ahead) out of sample forecasts of the number of daily confirmed and death COVID-19 cases for the ten countries namely USA, India, Brazil, Russia, France, Spain, UK, Italy, Argentina, Colombia and also for the world respectively. The predictions of the future outbreak for different countries will be useful for the effective allocation of health care resources and will act as early-warning system for health warriors, corporate leaders, economists, government/public-policy makers, and scientific experts.",1
"Li, Y.; Pei, X.; Guo, Y.",2021,A 3D CNN Classification Model for Accurate Diagnosis of Coronavirus Disease 2019 using Computed Tomography Images,Epidemiology,A 3D CNN Classification Model for Accurate Diagnosis of Coronavirus Disease 2019 using Computed Tomography Images,"Li, Y.; Pei, X.; Guo, Y.",Epidemiology,2021-01-26 00:00:00 UTC,"The coronavirus disease (COVID-19) has been spreading rapidly around the world. As of August 25, 2020, 23.719 million people have been infected in many countries. The cumulative death toll exceeds 812,000. Early detection of COVID-19 is essential to provide patients with appropriate medical care and protect uninfected people. Leveraging a large computed tomography (CT) database from 1,112 patients provided by China Consortium of Chest CT Image Investigation (CC-CCII), we investigated multiple solutions in detecting COVID-19 and distinguished it from other common pneumonia (CP) and normal controls. We also compared the performance of different models for complete and segmented CT slices. In particular, we studied the effects of CT-superimposition depths into volumes on the performance of our models. The results show that the optimal model can identify the COVID-19 slices with 99.76% accuracy (99.96% recall, 99.35% precision and 99.65% F1-score). The overall performance for three-way classification obtained 99.24% accuracy and the area under the receiver operating characteristic curve (AUROC) of 0.9986. To the best of our knowledge, our method achieves the highest accuracy and recall with the largest public available COVID-19 CT dataset. Our model can help radiologists and physicians perform rapid diagnosis, especially when the healthcare system is overloaded.",10.1101/2021.01.21.21249999,virology-neural-networks.xlsx,"A 3D CNN Classification Model for Accurate Diagnosis of Coronavirus Disease 2019 using Computed Tomography Images The coronavirus disease (COVID-19) has been spreading rapidly around the world. As of August 25, 2020, 23.719 million people have been infected in many countries. The cumulative death toll exceeds 812,000. Early detection of COVID-19 is essential to provide patients with appropriate medical care and protect uninfected people. Leveraging a large computed tomography (CT) database from 1,112 patients provided by China Consortium of Chest CT Image Investigation (CC-CCII), we investigated multiple solutions in detecting COVID-19 and distinguished it from other common pneumonia (CP) and normal controls. We also compared the performance of different models for complete and segmented CT slices. In particular, we studied the effects of CT-superimposition depths into volumes on the performance of our models. The results show that the optimal model can identify the COVID-19 slices with 99.76% accuracy (99.96% recall, 99.35% precision and 99.65% F1-score). The overall performance for three-way classification obtained 99.24% accuracy and the area under the receiver operating characteristic curve (AUROC) of 0.9986. To the best of our knowledge, our method achieves the highest accuracy and recall with the largest public available COVID-19 CT dataset. Our model can help radiologists and physicians perform rapid diagnosis, especially when the healthcare system is overloaded.",1
"Mulugeta, A.; Hypponen, E.; Ala-Korpela, M.; Makinen, V.-P.",2021,Metabolic subgroups and cardiometabolic multimorbidity in the UK Biobank,Epidemiology,Metabolic subgroups and cardiometabolic multimorbidity in the UK Biobank,"Mulugeta, A.; Hypponen, E.; Ala-Korpela, M.; Makinen, V.-P.",Epidemiology,2021-02-03 00:00:00 UTC,"Background

Ischemic heart disease (IHD), diabetes, cancer and dementia share features of age-associated metabolic dysfunction. We hypothesized that metabolic diversity explains the diversity of morbidity later in life.

MethodsWe analyzed data from the UK Biobank (N = 329,908). A self-organizing map (SOM, an artificial neural network) was trained with 51 metabolic traits adjusted for age and sex. The SOM analyses produced six subgroups that summarized the multi-variable metabolic diversity. The subgroup with the lowest adiposity and disease burden was chosen as the reference. Hazard ratios (HR) were modeled by Cox regression (P < 0.0001 unless otherwise indicated). Enrichment of multi-morbidity over random expectation was tested by permutation analysis.

ResultsThe subgroup with the highest sex hormones was not associated with IHD (HR = 1.04, P = 0.14). The subgroup with high urinary excretion without kidney stress (HR = 1.24) and the subgroup with the highest apolipoprotein B and blood pressure (HR = 1.52) were associated with IHD. The subgroup with high adiposity, inflammation and kidney stress was associated with IHD (HR = 2.11), cancer (HR= 1.29), dementia (HR = 1.70) and mortality (HR = 2.12). The subgroup with high triglycerides and liver enzymes was at risk of diabetes (HR = 15.6). Paradoxical enrichment of multimorbidity in young individuals and in favorable subgroups was observed.

ConclusionsThese results support metabolic diversity as an explanation to diverging morbidity and demonstrate the potential value of population-based metabolic subgroups as public health targets for reducing aggregate burden of chronic diseases in ageing populations.

Key messagesO_LIWe introduced six data-driven subgroups of the UK Biobank as a high-dimensional model of metabolic diversity and disease risk within a human population.
C_LIO_LIThree subgroups captured features of the classical cardiometabolic spectrum with stratification along cholesterol and blood pressure, kidney or liver dysfunction and systemic inflammation.
C_LIO_LITwo novel subgroups of high sex hormones and high urinary excretion were observed.
C_LIO_LIWe defined a new concept of multimorbidity enrichment.
C_LIO_LInexpected patterns of multimorbidity indicated that metabolically ""healthy"" individuals with one cardiometabolic disease may be at a disproportional synergistic risk of co-morbidity.
C_LI",10.1101/2021.02.01.21250893,virology-neural-networks.xlsx,"Metabolic subgroups and cardiometabolic multimorbidity in the UK Biobank Background

Ischemic heart disease (IHD), diabetes, cancer and dementia share features of age-associated metabolic dysfunction. We hypothesized that metabolic diversity explains the diversity of morbidity later in life.

MethodsWe analyzed data from the UK Biobank (N = 329,908). A self-organizing map (SOM, an artificial neural network) was trained with 51 metabolic traits adjusted for age and sex. The SOM analyses produced six subgroups that summarized the multi-variable metabolic diversity. The subgroup with the lowest adiposity and disease burden was chosen as the reference. Hazard ratios (HR) were modeled by Cox regression (P < 0.0001 unless otherwise indicated). Enrichment of multi-morbidity over random expectation was tested by permutation analysis.

ResultsThe subgroup with the highest sex hormones was not associated with IHD (HR = 1.04, P = 0.14). The subgroup with high urinary excretion without kidney stress (HR = 1.24) and the subgroup with the highest apolipoprotein B and blood pressure (HR = 1.52) were associated with IHD. The subgroup with high adiposity, inflammation and kidney stress was associated with IHD (HR = 2.11), cancer (HR= 1.29), dementia (HR = 1.70) and mortality (HR = 2.12). The subgroup with high triglycerides and liver enzymes was at risk of diabetes (HR = 15.6). Paradoxical enrichment of multimorbidity in young individuals and in favorable subgroups was observed.

ConclusionsThese results support metabolic diversity as an explanation to diverging morbidity and demonstrate the potential value of population-based metabolic subgroups as public health targets for reducing aggregate burden of chronic diseases in ageing populations.

Key messagesO_LIWe introduced six data-driven subgroups of the UK Biobank as a high-dimensional model of metabolic diversity and disease risk within a human population.
C_LIO_LIThree subgroups captured features of the classical cardiometabolic spectrum with stratification along cholesterol and blood pressure, kidney or liver dysfunction and systemic inflammation.
C_LIO_LITwo novel subgroups of high sex hormones and high urinary excretion were observed.
C_LIO_LIWe defined a new concept of multimorbidity enrichment.
C_LIO_LInexpected patterns of multimorbidity indicated that metabolically ""healthy"" individuals with one cardiometabolic disease may be at a disproportional synergistic risk of co-morbidity.
C_LI",0
"Alruily, M.; Ezz, M.; Mostafa, A. M.; Yanes, N.; Abbas, M.; El-Manzalawy, Y.",2021,Improved Prediction of COVID-19 Transmission and Mortality Using Google Search Trends for Symptoms in the United States,Epidemiology,Improved Prediction of COVID-19 Transmission and Mortality Using Google Search Trends for Symptoms in the United States,"Alruily, M.; Ezz, M.; Mostafa, A. M.; Yanes, N.; Abbas, M.; El-Manzalawy, Y.",Epidemiology,2021-03-24 00:00:00 UTC,"Accurate forecasting of emerging infectious diseases can guide public health officials in making appropriate decisions related to the allocation of public health resources. Due to the exponential spread of the COVID-19 infection worldwide, several computational models for forecasting the transmission and mortality rates of COVID-19 have been proposed in the literature. To accelerate scientific and public health insights into the spread and impact of COVID-19, Google released the Google COVID-19 search trends symptoms open-access dataset. Our objective is to develop 7 and 14 -day-ahead forecasting models of COVID-19 transmission and mortality in the US using the Google search trends for COVID-19 related symptoms. Specifically, we propose a stacked long short-term memory (SLSTM) architecture for predicting COVID-19 confirmed and death cases using historical time series data combined with auxiliary time series data from the Google COVID-19 search trends symptoms dataset. Considering the SLSTM networks trained using historical data only as the base models, our base models for 7 and 14 -day-ahead forecasting of COVID cases had the mean absolute percentage error (MAPE) values of 6.6% and 8.8%, respectively. On the other side, our proposed models had improved MAPE values of 3.2% and 5.6%, respectively. For 7 and 14 -day-ahead forecasting of COVID-19 deaths, the MAPE values of the base models were 4.8% and 11.4%, while the improved MAPE values of our proposed models were 4.7% and 7.8%, respectively. We found that the Google search trends for ""pneumonia,"" ""shortness of breath,"" and ""fever"" are the most informative search trends for predicting COVID-19 transmission. We also found that the search trends for ""hypoxia"" and ""fever"" were the most informative trends for forecasting COVID-19 mortality.",10.1101/2021.03.14.21253554,virology-neural-networks.xlsx,"Improved Prediction of COVID-19 Transmission and Mortality Using Google Search Trends for Symptoms in the United States Accurate forecasting of emerging infectious diseases can guide public health officials in making appropriate decisions related to the allocation of public health resources. Due to the exponential spread of the COVID-19 infection worldwide, several computational models for forecasting the transmission and mortality rates of COVID-19 have been proposed in the literature. To accelerate scientific and public health insights into the spread and impact of COVID-19, Google released the Google COVID-19 search trends symptoms open-access dataset. Our objective is to develop 7 and 14 -day-ahead forecasting models of COVID-19 transmission and mortality in the US using the Google search trends for COVID-19 related symptoms. Specifically, we propose a stacked long short-term memory (SLSTM) architecture for predicting COVID-19 confirmed and death cases using historical time series data combined with auxiliary time series data from the Google COVID-19 search trends symptoms dataset. Considering the SLSTM networks trained using historical data only as the base models, our base models for 7 and 14 -day-ahead forecasting of COVID cases had the mean absolute percentage error (MAPE) values of 6.6% and 8.8%, respectively. On the other side, our proposed models had improved MAPE values of 3.2% and 5.6%, respectively. For 7 and 14 -day-ahead forecasting of COVID-19 deaths, the MAPE values of the base models were 4.8% and 11.4%, while the improved MAPE values of our proposed models were 4.7% and 7.8%, respectively. We found that the Google search trends for ""pneumonia,"" ""shortness of breath,"" and ""fever"" are the most informative search trends for predicting COVID-19 transmission. We also found that the search trends for ""hypoxia"" and ""fever"" were the most informative trends for forecasting COVID-19 mortality.",1
"Choudhary, A.",2021,Using Machine Learning along with Data Science algorithms to pre-process and forecast COVID-19 Cases and Deaths,Epidemiology,Using Machine Learning along with Data Science algorithms to pre-process and forecast COVID-19 Cases and Deaths,"Choudhary, A.",Epidemiology,2021-03-17 00:00:00 UTC,"The Covid-19 pandemic has taken a major toll on the health and state of our global population. With tough decisions for allocating resources(i.e. vaccines)[1] are being made, forecasting through machine learning has become more important than ever. Moreover, as vaccines are being brought to the public and cases are going down, it is time that we reflect on where the pandemic has taken the most toll:for the purpose of future reform. This research illustrates two different models and algorithms for COVID-19 forecasting: Auto Regressive models and Recurrent Neural Networks(RNNs). The results show the true potential of RNNs to work with sequential and time-series data to forecast future cases and deaths in different states. As the paper utilizes the tanh activation function and multiple LSTM layers, the research will show the importance of machine learning and its ability to help politicians make decisions when it comes to helping states during the pandemic and future reform. The data will also pre-process the time-series data, using rolling statistics and will clean the data for the auto-regressive model and RNN layers. Thus, we show that along with Recurrent Neural Network layers, activation functions also play a crucial role in the accuracy of the forecast.",10.1101/2021.03.15.21253571,virology-neural-networks.xlsx,"Using Machine Learning along with Data Science algorithms to pre-process and forecast COVID-19 Cases and Deaths The Covid-19 pandemic has taken a major toll on the health and state of our global population. With tough decisions for allocating resources(i.e. vaccines)[1] are being made, forecasting through machine learning has become more important than ever. Moreover, as vaccines are being brought to the public and cases are going down, it is time that we reflect on where the pandemic has taken the most toll:for the purpose of future reform. This research illustrates two different models and algorithms for COVID-19 forecasting: Auto Regressive models and Recurrent Neural Networks(RNNs). The results show the true potential of RNNs to work with sequential and time-series data to forecast future cases and deaths in different states. As the paper utilizes the tanh activation function and multiple LSTM layers, the research will show the importance of machine learning and its ability to help politicians make decisions when it comes to helping states during the pandemic and future reform. The data will also pre-process the time-series data, using rolling statistics and will clean the data for the auto-regressive model and RNN layers. Thus, we show that along with Recurrent Neural Network layers, activation functions also play a crucial role in the accuracy of the forecast.",1
"Djeddou, M.; Hameed, I. A.; Hellal, A.; Nejatian, A.",2021,Predictive modeling of COVID-19 New Confirmed Cases in Algeria using Artificial Neural Network,Epidemiology,Predictive modeling of COVID-19 New Confirmed Cases in Algeria using Artificial Neural Network,"Djeddou, M.; Hameed, I. A.; Hellal, A.; Nejatian, A.",Epidemiology,2021-04-04 00:00:00 UTC,"This study investigates the potential of a simple artificial neural network for the prediction of COVID-19 New Confirmed Cases in Algeria (CNCC).

Four different ANN models were built (GRNN, RBFNN, ELM, and MLP). The performance of the predictive models is evaluated based on four numerical parameters, namely root mean squared error (RMSE), mean absolute error (MAE), Nash-Sutcliffe efficiency (NSE), and Pearson correlation coefficient (R). Taylor diagram was also used to examine the similarities and differences between the observed and predicted values obtained from the proposed models.

The results showed the potential of the multi-layer perceptron neural network (MLPNN) which exhibited a high level of accuracy in comparison to the other models.",10.1101/2021.03.29.21254532,virology-neural-networks.xlsx,"Predictive modeling of COVID-19 New Confirmed Cases in Algeria using Artificial Neural Network This study investigates the potential of a simple artificial neural network for the prediction of COVID-19 New Confirmed Cases in Algeria (CNCC).

Four different ANN models were built (GRNN, RBFNN, ELM, and MLP). The performance of the predictive models is evaluated based on four numerical parameters, namely root mean squared error (RMSE), mean absolute error (MAE), Nash-Sutcliffe efficiency (NSE), and Pearson correlation coefficient (R). Taylor diagram was also used to examine the similarities and differences between the observed and predicted values obtained from the proposed models.

The results showed the potential of the multi-layer perceptron neural network (MLPNN) which exhibited a high level of accuracy in comparison to the other models.",1
"Winetraub, Y.; Yuan, E.; Terem, I.; Yu, C.; Chan, W.; Do, H.; Shevidi, S.; Mao, M.; Yu, J.; Hong, M.; Blackenberg, E.; Rieger, K.; Chu, S.; Aasi, S.; Sarin, K.; De La Zerda, A.",2021,OCT2Hist: Non-Invasive Virtual Biopsy Using Optical Coherence Tomography,Pathology,OCT2Hist: Non-Invasive Virtual Biopsy Using Optical Coherence Tomography,"Winetraub, Y.; Yuan, E.; Terem, I.; Yu, C.; Chan, W.; Do, H.; Shevidi, S.; Mao, M.; Yu, J.; Hong, M.; Blackenberg, E.; Rieger, K.; Chu, S.; Aasi, S.; Sarin, K.; De La Zerda, A.",Pathology,2021-04-06 00:00:00 UTC,"Histological haematoxylin and eosin-stained (H&E) tissue sections are used as the gold standard for pathologic detection of cancer, tumour margin detection, and disease diagnosis1. Producing H&E sections, however, is invasive and time-consuming. Non-invasive optical imaging modalities, such as optical coherence tomography (OCT), permit label-free, micron-scale 3D imaging of biological tissue microstructure with significant depth (up to 1mm) and large fields-of-view2, but are difficult to interpret and correlate with clinical ground truth without specialized training3. Here we introduce the concept of a virtual biopsy, using generative neural networks to synthesize virtual H&E sections from OCT images. To do so we have developed a novel technique, ""optical barcoding"", which has allowed us to repeatedly extract the 2D OCT slice from a 3D OCT volume that corresponds to a given H&E tissue section, with very high alignment precision down to 25 microns. Using 1,005 prospectively collected human skin sections from Mohs surgery operations of 71 patients, we constructed the largest dataset of H&E images and their corresponding precisely aligned OCT images, and trained a conditional generative adversarial network4 on these image pairs. Our results demonstrate the ability to use OCT images to generate high-fidelity virtual H&E sections and entire 3D H&E volumes. Applying this trained neural network to in vivo OCT images should enable physicians to readily incorporate OCT imaging into their clinical practice, reducing the number of unnecessary biopsy procedures.",10.1101/2021.03.31.21254733,virology-neural-networks.xlsx,"OCT2Hist: Non-Invasive Virtual Biopsy Using Optical Coherence Tomography Histological haematoxylin and eosin-stained (H&E) tissue sections are used as the gold standard for pathologic detection of cancer, tumour margin detection, and disease diagnosis1. Producing H&E sections, however, is invasive and time-consuming. Non-invasive optical imaging modalities, such as optical coherence tomography (OCT), permit label-free, micron-scale 3D imaging of biological tissue microstructure with significant depth (up to 1mm) and large fields-of-view2, but are difficult to interpret and correlate with clinical ground truth without specialized training3. Here we introduce the concept of a virtual biopsy, using generative neural networks to synthesize virtual H&E sections from OCT images. To do so we have developed a novel technique, ""optical barcoding"", which has allowed us to repeatedly extract the 2D OCT slice from a 3D OCT volume that corresponds to a given H&E tissue section, with very high alignment precision down to 25 microns. Using 1,005 prospectively collected human skin sections from Mohs surgery operations of 71 patients, we constructed the largest dataset of H&E images and their corresponding precisely aligned OCT images, and trained a conditional generative adversarial network4 on these image pairs. Our results demonstrate the ability to use OCT images to generate high-fidelity virtual H&E sections and entire 3D H&E volumes. Applying this trained neural network to in vivo OCT images should enable physicians to readily incorporate OCT imaging into their clinical practice, reducing the number of unnecessary biopsy procedures.",0
"Hedman, M.; Rojas, A.; Arora, A.; Ola, D.",2021,Developing and comparing machine learning models to detect sleep apnoea using single-lead electrocardiogram (ECG) monitoring,Respiratory Medicine,Developing and comparing machine learning models to detect sleep apnoea using single-lead electrocardiogram (ECG) monitoring,"Hedman, M.; Rojas, A.; Arora, A.; Ola, D.",Respiratory Medicine,2021-04-27 00:00:00 UTC,"BackgroundSleep apnoea has a high disease burden but remains underdiagnosed, in part due to the expensive and resource intensive nature of polysomnography, its definitive investigation. Emerging literature suggests that it may be possible to detect sleep apnoea using single-lead ECG signals, such as those obtained from smartwatches. In this study, we use two forms of recurrent neural networks (RNNs) to detect sleep apnoea events from single-lead ECG signals.

MethodsWe use single-lead ECG data from the PhysioNet Apnea-ECG database, which contains data from 70 patients. We train a bidirectional gated recurrent unit (GRU) model and a bidirectional long short-term memory (LSTM) model on labelled ECG signals from 35 patients and test the models on the remaining 35 patients in the dataset.

ResultsBoth models achieved 97.1% accuracy, sensitivity and specificity to detect whether the ECG recordings belonged to a patient diagnosed with sleep apnoea. This corresponds to 34/35 patients in the dataset. At detecting individual apnoea events, the GRU and LSTM models achieved 90.4% and 91.7% accuracies respectively.

DiscussionThe models achieved high levels of accuracy, specificity and sensitivity. Bidirectional RNNs are strengthened by the ability of the models to be informed by both past and future states when analysing sequential data, such as ECGs. The models also require minimal human intervention as they automatically extract features from the data. If single-lead ECGs prove a suitable tool for sleep apnoea detection, this may enhance the diagnosis of sleep apnoea and potentially allow widespread screening for the condition.

ConclusionsWe note that using models such as bidirectional RNNs has the potential to augment model performance. However, more research and validation is required in order to test whether these may be applicable to other datasets and in clinical practice.",10.1101/2021.04.19.21255733,virology-neural-networks.xlsx,"Developing and comparing machine learning models to detect sleep apnoea using single-lead electrocardiogram (ECG) monitoring BackgroundSleep apnoea has a high disease burden but remains underdiagnosed, in part due to the expensive and resource intensive nature of polysomnography, its definitive investigation. Emerging literature suggests that it may be possible to detect sleep apnoea using single-lead ECG signals, such as those obtained from smartwatches. In this study, we use two forms of recurrent neural networks (RNNs) to detect sleep apnoea events from single-lead ECG signals.

MethodsWe use single-lead ECG data from the PhysioNet Apnea-ECG database, which contains data from 70 patients. We train a bidirectional gated recurrent unit (GRU) model and a bidirectional long short-term memory (LSTM) model on labelled ECG signals from 35 patients and test the models on the remaining 35 patients in the dataset.

ResultsBoth models achieved 97.1% accuracy, sensitivity and specificity to detect whether the ECG recordings belonged to a patient diagnosed with sleep apnoea. This corresponds to 34/35 patients in the dataset. At detecting individual apnoea events, the GRU and LSTM models achieved 90.4% and 91.7% accuracies respectively.

DiscussionThe models achieved high levels of accuracy, specificity and sensitivity. Bidirectional RNNs are strengthened by the ability of the models to be informed by both past and future states when analysing sequential data, such as ECGs. The models also require minimal human intervention as they automatically extract features from the data. If single-lead ECGs prove a suitable tool for sleep apnoea detection, this may enhance the diagnosis of sleep apnoea and potentially allow widespread screening for the condition.

ConclusionsWe note that using models such as bidirectional RNNs has the potential to augment model performance. However, more research and validation is required in order to test whether these may be applicable to other datasets and in clinical practice.",0
"Ren, S.; Zupetic, J.; Nouraie, M.; Lu, X.; Boyce, R. D.; Lee, J. S.",2021,Imputation of PaO2 from SpO2 values from the MIMIC-III Critical Care Database Using Machine-Learning Based Algorithms,Respiratory Medicine,Imputation of PaO2 from SpO2 values from the MIMIC-III Critical Care Database Using Machine-Learning Based Algorithms,"Ren, S.; Zupetic, J.; Nouraie, M.; Lu, X.; Boyce, R. D.; Lee, J. S.",Respiratory Medicine,2021-04-25 00:00:00 UTC,"BackgroundThe partial pressure of oxygen (PaO2)/fraction of oxygen delivered (FIO2) ratio is the reference standard for assessment of hypoxemia in mechanically ventilated patients. Non-invasive monitoring with the peripheral saturation of oxygen (SpO2) is increasingly utilized to estimate PaO2 because it does not require invasive sampling. Several equations have been reported to impute PaO2/FIO2 from SpO2 /FIO2. However, machine-learning algorithms to impute the PaO2 from the SpO2 has not been compared to published equations.

Research QuestionHow do machine learning algorithms perform at predicting the PaO2 from SpO2 compared to previously published equations?

MethodsThree machine learning algorithms (neural network, regression, and kernel-based methods) were developed using 7 clinical variable features (n=9,900 ICU events) and subsequently 3 features (n=20,198 ICU events) as input into the models from data available in mechanically ventilated patients from the Medical Information Mart for Intensive Care (MIMIC) III database. As a regression task, the machine learning models were used to impute PaO2 values. As a classification task, the models were used to predict patients with moderate-to-severe hypoxemic respiratory failure based on a clinically relevant cut-off of PaO2/FIO2 [&le;] 150. The accuracy of the machine learning models was compared to published log-linear and non-linear equations. An online imputation calculator was created.

ResultsCompared to seven features, three features (SpO2, FiO2 and PEEP) were sufficient to impute PaO2/FIO2 ratio using a large dataset. Any of the tested machine learning models enabled imputation of PaO2/FIO2 from the SpO2/FIO2 with lower error and had greater accuracy in predicting PaO2/FIO2 [&le;] 150 compared to published equations. Using three features, the machine learning models showed superior performance in imputing PaO2 across the entire span of SpO2 values, including those [&ge;] 97%.

InterpretationThe improved performance shown for the machine learning algorithms suggests a promising framework for future use in large datasets.",10.1101/2021.04.21.21255877,virology-neural-networks.xlsx,"Imputation of PaO2 from SpO2 values from the MIMIC-III Critical Care Database Using Machine-Learning Based Algorithms BackgroundThe partial pressure of oxygen (PaO2)/fraction of oxygen delivered (FIO2) ratio is the reference standard for assessment of hypoxemia in mechanically ventilated patients. Non-invasive monitoring with the peripheral saturation of oxygen (SpO2) is increasingly utilized to estimate PaO2 because it does not require invasive sampling. Several equations have been reported to impute PaO2/FIO2 from SpO2 /FIO2. However, machine-learning algorithms to impute the PaO2 from the SpO2 has not been compared to published equations.

Research QuestionHow do machine learning algorithms perform at predicting the PaO2 from SpO2 compared to previously published equations?

MethodsThree machine learning algorithms (neural network, regression, and kernel-based methods) were developed using 7 clinical variable features (n=9,900 ICU events) and subsequently 3 features (n=20,198 ICU events) as input into the models from data available in mechanically ventilated patients from the Medical Information Mart for Intensive Care (MIMIC) III database. As a regression task, the machine learning models were used to impute PaO2 values. As a classification task, the models were used to predict patients with moderate-to-severe hypoxemic respiratory failure based on a clinically relevant cut-off of PaO2/FIO2 [&le;] 150. The accuracy of the machine learning models was compared to published log-linear and non-linear equations. An online imputation calculator was created.

ResultsCompared to seven features, three features (SpO2, FiO2 and PEEP) were sufficient to impute PaO2/FIO2 ratio using a large dataset. Any of the tested machine learning models enabled imputation of PaO2/FIO2 from the SpO2/FIO2 with lower error and had greater accuracy in predicting PaO2/FIO2 [&le;] 150 compared to published equations. Using three features, the machine learning models showed superior performance in imputing PaO2 across the entire span of SpO2 values, including those [&ge;] 97%.

InterpretationThe improved performance shown for the machine learning algorithms suggests a promising framework for future use in large datasets.",0
"Demir, I.; Kirisci, M.",2021,Forecasting COVID-19 disease cases using the SARIMA-NNAR hybrid model,Epidemiology,Forecasting COVID-19 disease cases using the SARIMA-NNAR hybrid model,"Demir, I.; Kirisci, M.",Epidemiology,2021-04-28 00:00:00 UTC,"BackgroundCOVID-19 is a new disease that is associated with high morbidity that has spread around the world. Credible estimating is crucial for control and prevention. Nowadays, hybrid models have become popular, and these models have been widely implemented. Better estimation accuracy may be attained using time-series models. Thus, our aim is to forecast the number of COVID-19 cases with time-series models.

ObjectiveUsing time-series models to predict deaths due to COVID-19.

DesignSARIMA, NNAR, and SARIMA-NNAR hybrid time series models were used using the COVID-19 information of the Republic of Turkey Health Ministry.

ParticipantsWe analyzed data on COVID-19 in Turkey from March 11, 2020 to February 22, 2021.

Main MeasuresDaily numbers of COVID-19 confirmed cases and deaths.

Materials and methodsWe fitted a seasonal autoregressive integrated moving average (SARIMA)-neural network nonlinear autoregressive (NNAR) hybrid model with COVID-19 monthly cases from March 11, 2020, to February 22, 2021, in Turkey. Additionally, a SARIMA model, an NNAR model, and a SARIMA-NNAR hybrid model were established for comparison and estimation.

ResultsThe RMSE, MAE, and MAPE values of the NNAR model were obtained the lowest in the training set and the validation set. Thus, the NNAR model demonstrates excellent performance whether in fitting or forecasting compared with other models.

ConclusionsThe NNAR model that fits this study is the most suitable for estimating the number of deaths due to COVID-19. Hence, it will facilitate the prevention and control of COVID-19.",10.1101/2021.04.26.21256108,virology-neural-networks.xlsx,"Forecasting COVID-19 disease cases using the SARIMA-NNAR hybrid model BackgroundCOVID-19 is a new disease that is associated with high morbidity that has spread around the world. Credible estimating is crucial for control and prevention. Nowadays, hybrid models have become popular, and these models have been widely implemented. Better estimation accuracy may be attained using time-series models. Thus, our aim is to forecast the number of COVID-19 cases with time-series models.

ObjectiveUsing time-series models to predict deaths due to COVID-19.

DesignSARIMA, NNAR, and SARIMA-NNAR hybrid time series models were used using the COVID-19 information of the Republic of Turkey Health Ministry.

ParticipantsWe analyzed data on COVID-19 in Turkey from March 11, 2020 to February 22, 2021.

Main MeasuresDaily numbers of COVID-19 confirmed cases and deaths.

Materials and methodsWe fitted a seasonal autoregressive integrated moving average (SARIMA)-neural network nonlinear autoregressive (NNAR) hybrid model with COVID-19 monthly cases from March 11, 2020, to February 22, 2021, in Turkey. Additionally, a SARIMA model, an NNAR model, and a SARIMA-NNAR hybrid model were established for comparison and estimation.

ResultsThe RMSE, MAE, and MAPE values of the NNAR model were obtained the lowest in the training set and the validation set. Thus, the NNAR model demonstrates excellent performance whether in fitting or forecasting compared with other models.

ConclusionsThe NNAR model that fits this study is the most suitable for estimating the number of deaths due to COVID-19. Hence, it will facilitate the prevention and control of COVID-19.",1
"Khennou, F.; Akhloufi, M. A.",2021,Forecasting COVID-19 Spreading in Canada using Deep Learning,Epidemiology,Forecasting COVID-19 Spreading in Canada using Deep Learning,"Khennou, F.; Akhloufi, M. A.",Epidemiology,2021-05-04 00:00:00 UTC,"AO_SCPLOWBSTRACTC_SCPLOWThe novel coronavirus disease 2019 (COVID-19) is disrupting all aspects of our lives as the global spread of the virus continues. In this difficult period, various research projects are taking place to study and analyse the dynamics of the pandemic. In the present work, we firstly present a deep overview of the main forecasting models to predict the new cases of COVID-19. In this context, we focus on univariate time series models in order to analyze the dynamic change of this pandemic through time. We secondly shed light on multivariate time series forecasting models using weather and daily tests data, to study the impact of exogenous features on the progression of COVID-19. In the final stage of this paper, we present our proposed approach based on LSTM and GRU ensemble learning model and evaluate the results using the MAE, RMSE and MAPE for the prediction of new cases. The results of our experiments using the Canadian dataset show that the ensemble model performs well in comparison to other models. In addition, this research provides us with a new outcome regarding the dynamic correlation between temperature, humidity and daily test data and its impact on the new contaminated cases.",10.1101/2021.05.01.21256447,virology-neural-networks.xlsx,"Forecasting COVID-19 Spreading in Canada using Deep Learning AO_SCPLOWBSTRACTC_SCPLOWThe novel coronavirus disease 2019 (COVID-19) is disrupting all aspects of our lives as the global spread of the virus continues. In this difficult period, various research projects are taking place to study and analyse the dynamics of the pandemic. In the present work, we firstly present a deep overview of the main forecasting models to predict the new cases of COVID-19. In this context, we focus on univariate time series models in order to analyze the dynamic change of this pandemic through time. We secondly shed light on multivariate time series forecasting models using weather and daily tests data, to study the impact of exogenous features on the progression of COVID-19. In the final stage of this paper, we present our proposed approach based on LSTM and GRU ensemble learning model and evaluate the results using the MAE, RMSE and MAPE for the prediction of new cases. The results of our experiments using the Canadian dataset show that the ensemble model performs well in comparison to other models. In addition, this research provides us with a new outcome regarding the dynamic correlation between temperature, humidity and daily test data and its impact on the new contaminated cases.",1
"Lapteva, E. A.; Kharevich, O. N.; Khatsko, V. V.; Voronova, N. A.; Chamko, M. V.; Bezruchko, I. V.; Katibnikova, E. I.; Loban, E. I.; Mouawie, M. M.; Binetskaya, H.; Aleshkevich, S.; Karankevich, A.; Dubinetski, V.; Vestbo, J.; Mathioudakis, A. G.",2021,Automated lung sound analysis using the LungPass platform: A sensitive and specific tool for identifying lower respiratory tract involvement in COVID-19.,Respiratory Medicine,Automated lung sound analysis using the LungPass platform: A sensitive and specific tool for identifying lower respiratory tract involvement in COVID-19.,"Lapteva, E. A.; Kharevich, O. N.; Khatsko, V. V.; Voronova, N. A.; Chamko, M. V.; Bezruchko, I. V.; Katibnikova, E. I.; Loban, E. I.; Mouawie, M. M.; Binetskaya, H.; Aleshkevich, S.; Karankevich, A.; Dubinetski, V.; Vestbo, J.; Mathioudakis, A. G.",Respiratory Medicine,2021-07-08 00:00:00 UTC,"BackgroundLower respiratory tract (LRT) involvement, observed in about 20% of patients suffering from coronavirus disease 2019 (COVID-19) is associated with a more severe clinical course, adverse outcomes and long-term sequelae. Early identification of LRT involvement could facilitated targeted and timely interventions that could alter the short- and long-term disease outcomes. The LungPass is an automated lung sound analysis platform developed using neural network technology and previously trained. We hypothesised that the LungPass could be used as a screening tool for LRT involvement in patients with COVID-19.

MethodsIn a prospective observational study involving 282 individuals with presenting in the emergency department with a strong clinical suspicion of COVID-19 and imaging findings consistent with COVID-19 LRT involvement (25.5% had concomitant hypoxia), and 32 healthy controls, we assessed the sensitivity and specificity of the LungPass in identifying LRT involvement in COVID-19. We also compared the auscultatory findings of the LungPass compared to a chest physician using a traditional, high-quality stethoscope.

ResultsAmong individuals with COVID-19 LRT involvement, the LungPass identified crackles in at least one auscultation site in 93.6% and in two or more points in 84%. Moreover, the LungPass identified any abnormal lung sound (crackles or wheeze) in at least one auscultation site in 98.6% and in at least two points in 94% of the participants. The respective percentages for the respiratory physicians were lower.

Considering the presence of any added abnormal sound (crackles or wheeze) in at least two auscultation points as evidence of LRT involvement, LungPass demonstrated a sensitivity of 98.6% (95% confidence intervals [CI]: 96.4%-99.6%) and a specificity of 96.9% (95% CI: 83.8%-99.9%) in identifying COVID-19 LRT involvement.

ConclusionThis exploratory study suggests the LungPass is a sensitive and specific platform for identifying LRT involvement due to COVID-19, even before the development of hypoxia.",10.1101/2021.07.08.21260125,virology-neural-networks.xlsx,"Automated lung sound analysis using the LungPass platform: A sensitive and specific tool for identifying lower respiratory tract involvement in COVID-19. BackgroundLower respiratory tract (LRT) involvement, observed in about 20% of patients suffering from coronavirus disease 2019 (COVID-19) is associated with a more severe clinical course, adverse outcomes and long-term sequelae. Early identification of LRT involvement could facilitated targeted and timely interventions that could alter the short- and long-term disease outcomes. The LungPass is an automated lung sound analysis platform developed using neural network technology and previously trained. We hypothesised that the LungPass could be used as a screening tool for LRT involvement in patients with COVID-19.

MethodsIn a prospective observational study involving 282 individuals with presenting in the emergency department with a strong clinical suspicion of COVID-19 and imaging findings consistent with COVID-19 LRT involvement (25.5% had concomitant hypoxia), and 32 healthy controls, we assessed the sensitivity and specificity of the LungPass in identifying LRT involvement in COVID-19. We also compared the auscultatory findings of the LungPass compared to a chest physician using a traditional, high-quality stethoscope.

ResultsAmong individuals with COVID-19 LRT involvement, the LungPass identified crackles in at least one auscultation site in 93.6% and in two or more points in 84%. Moreover, the LungPass identified any abnormal lung sound (crackles or wheeze) in at least one auscultation site in 98.6% and in at least two points in 94% of the participants. The respective percentages for the respiratory physicians were lower.

Considering the presence of any added abnormal sound (crackles or wheeze) in at least two auscultation points as evidence of LRT involvement, LungPass demonstrated a sensitivity of 98.6% (95% confidence intervals [CI]: 96.4%-99.6%) and a specificity of 96.9% (95% CI: 83.8%-99.9%) in identifying COVID-19 LRT involvement.

ConclusionThis exploratory study suggests the LungPass is a sensitive and specific platform for identifying LRT involvement due to COVID-19, even before the development of hypoxia.",1
"Sanyal, P.; Paul, S.; Das, A.",2021,Performance of a machine learning model in recognition of normal tissue from histological sections,Pathology,Performance of a machine learning model in recognition of normal tissue from histological sections,"Sanyal, P.; Paul, S.; Das, A.",Pathology,2021-07-22 00:00:00 UTC,"IntroductionMachine learning and artificial intelligence (AI) models have been applied in histopathology to solve specific problems like detection of metastasis in lymph nodes and immunohistochemical scoring. We have aimed to develop a machine learning model which can be trained in histopathology from the basics, i.e. identification of normal tissue. We have tried to replicate the process through which a human pathologist learns recognition of normal tissue from histological sections, and evaluate the performance of a machine learning model at this task.

Materials and methodsA total of 658 histologic images were anonymised, microphotographed at 10x magnification, under the same condition of illumination, with a Magnus DC5 integrated microphotography system. The images were split into two subsets, training (386) and validation (272 images). The images belonged to seven classes of tissue: brain, intestine, kidney, liver, lungs, muscle and skin. Archived material of the hospital were used for the study. A machine learning model using convolutional neural network (CNN) was developed on the Keras platform, using the convolution layers of a pretrained VGG16 model. The model was trained with the training set of images over 10 epochs. After training, performance of the model was assessed on the validation set.

ResultsThe model achieved 88.24% accuracy in classifying the images of the validation set. The most frequent errors were met in recognising images of kidney (14 errors, 33.33%). The commonest error was wrongly classifying kidney tissue as liver (07 errors). Analysis of the deeper layers of the neural network revealed specific patterns in images which were wrongly classified.

ConclusionThe results of the present study indicates that a convolutional neural network might be trained in histology similar to a trainee pathologist. The study represents the first step towards developing a machine learning model as a generalised histopathological image classifier.",10.1101/2021.07.20.21260573,virology-neural-networks.xlsx,"Performance of a machine learning model in recognition of normal tissue from histological sections IntroductionMachine learning and artificial intelligence (AI) models have been applied in histopathology to solve specific problems like detection of metastasis in lymph nodes and immunohistochemical scoring. We have aimed to develop a machine learning model which can be trained in histopathology from the basics, i.e. identification of normal tissue. We have tried to replicate the process through which a human pathologist learns recognition of normal tissue from histological sections, and evaluate the performance of a machine learning model at this task.

Materials and methodsA total of 658 histologic images were anonymised, microphotographed at 10x magnification, under the same condition of illumination, with a Magnus DC5 integrated microphotography system. The images were split into two subsets, training (386) and validation (272 images). The images belonged to seven classes of tissue: brain, intestine, kidney, liver, lungs, muscle and skin. Archived material of the hospital were used for the study. A machine learning model using convolutional neural network (CNN) was developed on the Keras platform, using the convolution layers of a pretrained VGG16 model. The model was trained with the training set of images over 10 epochs. After training, performance of the model was assessed on the validation set.

ResultsThe model achieved 88.24% accuracy in classifying the images of the validation set. The most frequent errors were met in recognising images of kidney (14 errors, 33.33%). The commonest error was wrongly classifying kidney tissue as liver (07 errors). Analysis of the deeper layers of the neural network revealed specific patterns in images which were wrongly classified.

ConclusionThe results of the present study indicates that a convolutional neural network might be trained in histology similar to a trainee pathologist. The study represents the first step towards developing a machine learning model as a generalised histopathological image classifier.",0
"Jarde, A.; Jeffries, D.; Mackenzie, G. A.",2021,DEVELOPMENT AND VALIDATION OF A MODEL FOR THE PREDICTION OF MORTALITY IN CHILDREN UNDER FIVE YEARS WITH CLINICAL PNEUMONIA IN RURAL GAMBIA,Epidemiology,DEVELOPMENT AND VALIDATION OF A MODEL FOR THE PREDICTION OF MORTALITY IN CHILDREN UNDER FIVE YEARS WITH CLINICAL PNEUMONIA IN RURAL GAMBIA,"Jarde, A.; Jeffries, D.; Mackenzie, G. A.",Epidemiology,2021-08-05 00:00:00 UTC,"BackgroundPneumonia is the leading cause of death in children aged 1-59 months. Prediction models for child pneumonia mortality have been developed using regression methods but their performance is insufficient for clinical use.

MethodsWe used a variety of machine learning methods to develop a predictive model for mortality in children with clinical pneumonia enrolled in population-based surveillance in the Basse Health and Demographic Surveillance System in rural Gambia (n=11,012). Four machine learning algorithms (support vector machine, random forest, artifical neural network, and regularized logistic regression) were implemented, fitting all possible combinations of two or more of 16 selected features. Models were shortlisted based on their training set performance, the number of included features, and the reliability of feature measurement. The final model was selected considering its clinical interpretability.

ResultsWhen we applied the final model to the test set (55 deaths), the area under the Receiver Operating Characteristic Curve was 0.88 (95% confidence interval: 0.84, 0.91), sensitivity was 0.78 and specificity was 0.77.

ConclusionsOur evaluation of multiple machine learning methods combined with minimal and pragmatic feature selection led to a predictive model with very good performance. We plan further validation of our model in different populations.",10.1101/2021.08.04.21260737,virology-neural-networks.xlsx,"DEVELOPMENT AND VALIDATION OF A MODEL FOR THE PREDICTION OF MORTALITY IN CHILDREN UNDER FIVE YEARS WITH CLINICAL PNEUMONIA IN RURAL GAMBIA BackgroundPneumonia is the leading cause of death in children aged 1-59 months. Prediction models for child pneumonia mortality have been developed using regression methods but their performance is insufficient for clinical use.

MethodsWe used a variety of machine learning methods to develop a predictive model for mortality in children with clinical pneumonia enrolled in population-based surveillance in the Basse Health and Demographic Surveillance System in rural Gambia (n=11,012). Four machine learning algorithms (support vector machine, random forest, artifical neural network, and regularized logistic regression) were implemented, fitting all possible combinations of two or more of 16 selected features. Models were shortlisted based on their training set performance, the number of included features, and the reliability of feature measurement. The final model was selected considering its clinical interpretability.

ResultsWhen we applied the final model to the test set (55 deaths), the area under the Receiver Operating Characteristic Curve was 0.88 (95% confidence interval: 0.84, 0.91), sensitivity was 0.78 and specificity was 0.77.

ConclusionsOur evaluation of multiple machine learning methods combined with minimal and pragmatic feature selection led to a predictive model with very good performance. We plan further validation of our model in different populations.",1
"Carrillo-Larco, R. M.; Hernandez Santa Cruz, J. F.",2021,"Street images classification according to COVID-19 risk in Lima, Peru: A convolutional neural networks analysis",Epidemiology,"Street images classification according to COVID-19 risk in Lima, Peru: A convolutional neural networks analysis","Carrillo-Larco, R. M.; Hernandez Santa Cruz, J. F.",Epidemiology,2021-09-12 00:00:00 UTC,"BackgroundDuring the COVID-19 pandemic, convolutional neural networks (CNNs) have been used in clinical medicine (e.g., to classify chest X-rays for COVID-19 diagnosis). Whether CNNs could also inform the epidemiology of COVID-19 analysing street images has been understudied, though it could identify high-risk places and relevant features of the built environment. We trained CNNs to classify bus stops (Lima, Peru) into moderate or extreme COVID-19 risk.

MethodsWe used five images per bus stop. The outcome label (moderate or extreme) for each bus stop was extracted from the local transport authority. We used transfer learning and updated the output layer of five CNNs: NASNetLarge, InceptionResNetV2, Xception, ResNet152V2, and ResNet101V2. We chose the best performing network which was further tuned to increase performance.

ResultsThere were 1,788 bus stops (1,173 moderate and 615 extreme), totalling 8,940 images. NASNetLarge outperformed the other CNNs except in the recall metric for the extreme label: 57% versus 59% in NASNetLarge and ResNet152V2, respectively. NASNetLarge was further tuned and reached: training loss of 0.50; training accuracy of 75%; precision, recall and F1 score for the moderate label of 80%, 83% and 82%, respectively; these metrics for the extreme label were 65%, 51% and 63%.

ConclusionsCNNs has the potential to accurately classify street images into levels of COVID-19 risk. In addition to applications in clinical medicine, CNNs and street images could also advance the epidemiology of COVID-19 at the population level.",10.1101/2021.09.06.21263188,virology-neural-networks.xlsx,"Street images classification according to COVID-19 risk in Lima, Peru: A convolutional neural networks analysis BackgroundDuring the COVID-19 pandemic, convolutional neural networks (CNNs) have been used in clinical medicine (e.g., to classify chest X-rays for COVID-19 diagnosis). Whether CNNs could also inform the epidemiology of COVID-19 analysing street images has been understudied, though it could identify high-risk places and relevant features of the built environment. We trained CNNs to classify bus stops (Lima, Peru) into moderate or extreme COVID-19 risk.

MethodsWe used five images per bus stop. The outcome label (moderate or extreme) for each bus stop was extracted from the local transport authority. We used transfer learning and updated the output layer of five CNNs: NASNetLarge, InceptionResNetV2, Xception, ResNet152V2, and ResNet101V2. We chose the best performing network which was further tuned to increase performance.

ResultsThere were 1,788 bus stops (1,173 moderate and 615 extreme), totalling 8,940 images. NASNetLarge outperformed the other CNNs except in the recall metric for the extreme label: 57% versus 59% in NASNetLarge and ResNet152V2, respectively. NASNetLarge was further tuned and reached: training loss of 0.50; training accuracy of 75%; precision, recall and F1 score for the moderate label of 80%, 83% and 82%, respectively; these metrics for the extreme label were 65%, 51% and 63%.

ConclusionsCNNs has the potential to accurately classify street images into levels of COVID-19 risk. In addition to applications in clinical medicine, CNNs and street images could also advance the epidemiology of COVID-19 at the population level.",1
"Liu, S.; Amgad, M.; Rathore, M. A.; Salgado, R.; Cooper, L. A. D.",2023,A panoptic segmentation approach for tumor-infiltrating lymphocyte assessment: development of the MuTILs model and PanopTILs dataset,Pathology,A panoptic segmentation approach for tumor-infiltrating lymphocyte assessment: development of the MuTILs model and PanopTILs dataset,"Liu, S.; Amgad, M.; Rathore, M. A.; Salgado, R.; Cooper, L. A. D.",Pathology,2023-11-20 00:00:00 UTC,"Tumor-Infiltrating Lymphocytes (TILs) have strong prognostic and predictive value in breast cancer, but their visual assessment is subjective. To improve reproducibility, the International Immuno-oncology Working Group recently released recommendations for the computational assessment of TILs that build on visual scoring guidelines. However, existing resources do not adequately address these recommendations due to the lack of annotation datasets that enable joint, panoptic segmentation of tissue regions and cells. Moreover, existing deep-learning methods focus entirely on either tissue segmentation or cell nuclei detection, which complicates the process of TILs assessment by necessitating the use of multiple models and reconciling inconsistent predictions. We introduce PanopTILs, a region and cell-level annotation dataset containing 814,886 nuclei from 151 patients, openly accessible at: sites.google.com/view/panoptils. Using PanopTILs we developed MuTILs, a neural network optimized for assessing TILs in accordance with clinical recommendations. MuTILs is a concept bottleneck model designed to be interpretable and to encourage sensible predictions at multiple resolutions. Using a rigorous internal-external cross-validation procedure, MuTILs achieves an AUROC of 0.93 for lymphocyte detection and a DICE coefficient of 0.81 for tumor-associated stroma segmentation. Our computational score closely matched visual scores from 2 pathologists (Spearman R=0.58-0.61, p<0.001). Moreover, computational TILs scores had a higher prognostic value than visual scores, independent of TNM stage and patient age. In conclusion, we introduce a comprehensive open data resource and a novel modeling approach for detailed mapping of the breast tumor microenvironment.",10.1101/2022.01.08.22268814,virology-neural-networks.xlsx,"A panoptic segmentation approach for tumor-infiltrating lymphocyte assessment: development of the MuTILs model and PanopTILs dataset Tumor-Infiltrating Lymphocytes (TILs) have strong prognostic and predictive value in breast cancer, but their visual assessment is subjective. To improve reproducibility, the International Immuno-oncology Working Group recently released recommendations for the computational assessment of TILs that build on visual scoring guidelines. However, existing resources do not adequately address these recommendations due to the lack of annotation datasets that enable joint, panoptic segmentation of tissue regions and cells. Moreover, existing deep-learning methods focus entirely on either tissue segmentation or cell nuclei detection, which complicates the process of TILs assessment by necessitating the use of multiple models and reconciling inconsistent predictions. We introduce PanopTILs, a region and cell-level annotation dataset containing 814,886 nuclei from 151 patients, openly accessible at: sites.google.com/view/panoptils. Using PanopTILs we developed MuTILs, a neural network optimized for assessing TILs in accordance with clinical recommendations. MuTILs is a concept bottleneck model designed to be interpretable and to encourage sensible predictions at multiple resolutions. Using a rigorous internal-external cross-validation procedure, MuTILs achieves an AUROC of 0.93 for lymphocyte detection and a DICE coefficient of 0.81 for tumor-associated stroma segmentation. Our computational score closely matched visual scores from 2 pathologists (Spearman R=0.58-0.61, p<0.001). Moreover, computational TILs scores had a higher prognostic value than visual scores, independent of TNM stage and patient age. In conclusion, we introduce a comprehensive open data resource and a novel modeling approach for detailed mapping of the breast tumor microenvironment.",0
"Guo, Y.; Strauss, V. Y.; Prieto-Alhambra, D.; Khalid, S.",2022,Use of machine learning for comparing disease risk scores and propensity scores under complex confounding and large sample size scenarios: a simulation study,Epidemiology,Use of machine learning for comparing disease risk scores and propensity scores under complex confounding and large sample size scenarios: a simulation study,"Guo, Y.; Strauss, V. Y.; Prieto-Alhambra, D.; Khalid, S.",Epidemiology,2022-02-04 00:00:00 UTC,"BackgroundThe surge of treatments for COVID-19 in the ongoing pandemic presents an exemplar scenario with low prevalence of a given treatment and high outcome risk. Motivated by that, we conducted a simulation study for treatment effect estimation in such scenarios. We compared the performance of two methods for addressing confounding during the process of estimating treatment effects, namely disease risk scores (DRS) and propensity scores (PS) using different machine learning algorithms.

MethodsMonte Carlo simulated data with 25 different scenarios of treatment prevalence, outcome risk, data complexity, and sample size were created. PS and DRS matching with 1: 1 ratio were applied with logistic regression with least absolute shrinkage and selection operator (LASSO) regularization, multilayer perceptron (MLP), and eXtreme Gradient Boosting (XgBoost). Estimation performance was evaluated using relative bias and corresponding confidence intervals.

ResultsBias in treatment effect estimation increased with decreasing treatment prevalence regardless of matching method. DRS resulted in lower bias compared to PS when treatment prevalence was less than 10%, under strong confounding and nonlinear nonadditive data setting. However, DRS did not outperform PS under linear data setting and small sample size, even when the treatment prevalence was less than 10%. PS had a comparable or lower bias to DRS when treatment prevalence was common or high (10% - 50%). All three machine learning methods had similar performance, with LASSO and XgBoost yielding the lowest bias in some scenarios. Decreasing sample size or adding nonlinearity and non-additivity in data improved the performance of both PS and DRS.

ConclusionsUnder strong confounding with large sample size DRS reduced bias compared to PS in scenarios with low treatment prevalence (less than 10%), whilst PS was preferable for the study of treatments with prevalence greater than 10%, regardless of the outcome prevalence.

Key MessagesO_LIWhen handling nonlinear nonadditive data with strong confounding, DRS estimated by machine learning methods outperforms PS in scenarios with low treatment prevalence (less than 10%).
C_LIO_LIHowever, if having linear data and small sample size data with strong confounding, we did not observe DRS outperformed PS even when treatment prevalence was less than 10%.
C_LIO_LIOur results suggested that using PS performed better compared to DRS in tackling strong confounding problems with treatment prevalence greater than 10%.
C_LIO_LISmall sample size increased bias for both DRS and PS methods, and it affected DRS more than PS.
C_LI",10.1101/2022.02.03.22270151,virology-neural-networks.xlsx,"Use of machine learning for comparing disease risk scores and propensity scores under complex confounding and large sample size scenarios: a simulation study BackgroundThe surge of treatments for COVID-19 in the ongoing pandemic presents an exemplar scenario with low prevalence of a given treatment and high outcome risk. Motivated by that, we conducted a simulation study for treatment effect estimation in such scenarios. We compared the performance of two methods for addressing confounding during the process of estimating treatment effects, namely disease risk scores (DRS) and propensity scores (PS) using different machine learning algorithms.

MethodsMonte Carlo simulated data with 25 different scenarios of treatment prevalence, outcome risk, data complexity, and sample size were created. PS and DRS matching with 1: 1 ratio were applied with logistic regression with least absolute shrinkage and selection operator (LASSO) regularization, multilayer perceptron (MLP), and eXtreme Gradient Boosting (XgBoost). Estimation performance was evaluated using relative bias and corresponding confidence intervals.

ResultsBias in treatment effect estimation increased with decreasing treatment prevalence regardless of matching method. DRS resulted in lower bias compared to PS when treatment prevalence was less than 10%, under strong confounding and nonlinear nonadditive data setting. However, DRS did not outperform PS under linear data setting and small sample size, even when the treatment prevalence was less than 10%. PS had a comparable or lower bias to DRS when treatment prevalence was common or high (10% - 50%). All three machine learning methods had similar performance, with LASSO and XgBoost yielding the lowest bias in some scenarios. Decreasing sample size or adding nonlinearity and non-additivity in data improved the performance of both PS and DRS.

ConclusionsUnder strong confounding with large sample size DRS reduced bias compared to PS in scenarios with low treatment prevalence (less than 10%), whilst PS was preferable for the study of treatments with prevalence greater than 10%, regardless of the outcome prevalence.

Key MessagesO_LIWhen handling nonlinear nonadditive data with strong confounding, DRS estimated by machine learning methods outperforms PS in scenarios with low treatment prevalence (less than 10%).
C_LIO_LIHowever, if having linear data and small sample size data with strong confounding, we did not observe DRS outperformed PS even when treatment prevalence was less than 10%.
C_LIO_LIOur results suggested that using PS performed better compared to DRS in tackling strong confounding problems with treatment prevalence greater than 10%.
C_LIO_LISmall sample size increased bias for both DRS and PS methods, and it affected DRS more than PS.
C_LI",0
"Rurak, B. K.; Tan, J.; Rodrigues, J. P.; Power, B. D.; Drummond, P. D.; Vallence, A.-M.",2024,Cortico-cortical connectivity is influenced by levodopa in tremor-dominant Parkinson's disease,Pathology,Cortico-cortical connectivity is influenced by levodopa in tremor-dominant Parkinson's disease,"Rurak, B. K.; Tan, J.; Rodrigues, J. P.; Power, B. D.; Drummond, P. D.; Vallence, A.-M.",Pathology,2024-02-06 00:00:00 UTC,"BackgroundResting tremor is the most common presenting motor symptom in Parkinsons disease (PD). The supplementary motor area (SMA) is one of the main targets of the basal ganglia-thalamo-cortical circuit and has direct, facilitatory connections with the primary motor cortex (M1), which is important for the execution of voluntary movement. Dopamine potentially modulates SMA and M1 activity, and both regions have been implicated in resting tremor.

ObjectiveTo examine SMA-M1 connectivity in individuals with PD ON and OFF dopamine medication, and whether SMA-M1 connectivity is implicated in resting tremor.

MethodsDual-site transcranial magnetic stimulation was used to measure SMA-M1 facilitatory connectivity in PD participants ON and OFF levodopa. Resting tremor was measured using electromyography and accelerometry.

ResultsStimulating SMA had an inhibitory influence on M1 excitability OFF levodopa, and a facilitatory influence on M1 excitability ON levodopa. ON medication, correlational analysis showed an association between tremor severity and SMA-M1 connectivity, with SMA-M1 facilitation associated with smaller tremor than SMA-M1 inhibition.

ConclusionsThe current findings contribute to our understanding of the neural networks involved in PD which are altered by levodopa medication and provide a neurophysiological basis for the development of interventions to treat resting tremor.",10.1101/2022.02.22.22270921,virology-neural-networks.xlsx,"Cortico-cortical connectivity is influenced by levodopa in tremor-dominant Parkinson's disease BackgroundResting tremor is the most common presenting motor symptom in Parkinsons disease (PD). The supplementary motor area (SMA) is one of the main targets of the basal ganglia-thalamo-cortical circuit and has direct, facilitatory connections with the primary motor cortex (M1), which is important for the execution of voluntary movement. Dopamine potentially modulates SMA and M1 activity, and both regions have been implicated in resting tremor.

ObjectiveTo examine SMA-M1 connectivity in individuals with PD ON and OFF dopamine medication, and whether SMA-M1 connectivity is implicated in resting tremor.

MethodsDual-site transcranial magnetic stimulation was used to measure SMA-M1 facilitatory connectivity in PD participants ON and OFF levodopa. Resting tremor was measured using electromyography and accelerometry.

ResultsStimulating SMA had an inhibitory influence on M1 excitability OFF levodopa, and a facilitatory influence on M1 excitability ON levodopa. ON medication, correlational analysis showed an association between tremor severity and SMA-M1 connectivity, with SMA-M1 facilitation associated with smaller tremor than SMA-M1 inhibition.

ConclusionsThe current findings contribute to our understanding of the neural networks involved in PD which are altered by levodopa medication and provide a neurophysiological basis for the development of interventions to treat resting tremor.",0
"Dijkstra, L.; Schink, T.; Linder, R.; Schwaninger, M.; Pigeot, I.; Wright, M.; Foraita, R.",2022,A Discovery and Verification Approach for Pharmacovigilance using Electronic Health Care Data,Epidemiology,A Discovery and Verification Approach for Pharmacovigilance using Electronic Health Care Data,"Dijkstra, L.; Schink, T.; Linder, R.; Schwaninger, M.; Pigeot, I.; Wright, M.; Foraita, R.",Epidemiology,2022-05-10 00:00:00 UTC,"IntroductionPharmacovigilance shifted its focus from spontaneous reporting systems to electronic health care (EHC) data. Usually, a single statistical method is used to detect signals, i.e., potential adverse drug reactions (ADRs).

Objective and MethodWe present a novel approach to detect ADRs in EHC databases. It aggregates the results of multiple statistical signal detection methods applying Borda count ranking, a preference voting system, which results are used by an expert committee to select plausible signals. The obtained signals are afterwards investigated in tailored pharmacoepidemiological studies to provide support of plausibility or spuriousness of the signal.

We showcase the approach using data from the German Pharmacoepidemiological Research Database on drug reactions of the direct oral anticoagulant rivaroxaban. Results of four statistical methods are aggregated into Borda count rankings: longitudinal Gamma Poisson shrinker, Bayesian confidence propagation neural network, random forests and LASSO. A verification study designed as nested active comparator case-control study was conducted. We included patients diagnosed with atrial fibrillation who initiated anticoagulant treatment with rivaroxaban or with phenprocoumon as active comparator between 2011 and 2017.

ResultsThe case study highlights that our Borda ranking approach (https://borda.bips.eu) is fast, able to retrieve known ADRs and find other interesting signals. Hasty false conclusions are avoided by a verification study, which is, however, time-consuming.

ConclusionPost-market signal detection in EHC data is useful to identify and validate safety signals, particularly a few years after first admission to the market, when spontaneous reports are less frequent and more EHC data are available.",10.1101/2022.05.10.22274885,virology-neural-networks.xlsx,"A Discovery and Verification Approach for Pharmacovigilance using Electronic Health Care Data IntroductionPharmacovigilance shifted its focus from spontaneous reporting systems to electronic health care (EHC) data. Usually, a single statistical method is used to detect signals, i.e., potential adverse drug reactions (ADRs).

Objective and MethodWe present a novel approach to detect ADRs in EHC databases. It aggregates the results of multiple statistical signal detection methods applying Borda count ranking, a preference voting system, which results are used by an expert committee to select plausible signals. The obtained signals are afterwards investigated in tailored pharmacoepidemiological studies to provide support of plausibility or spuriousness of the signal.

We showcase the approach using data from the German Pharmacoepidemiological Research Database on drug reactions of the direct oral anticoagulant rivaroxaban. Results of four statistical methods are aggregated into Borda count rankings: longitudinal Gamma Poisson shrinker, Bayesian confidence propagation neural network, random forests and LASSO. A verification study designed as nested active comparator case-control study was conducted. We included patients diagnosed with atrial fibrillation who initiated anticoagulant treatment with rivaroxaban or with phenprocoumon as active comparator between 2011 and 2017.

ResultsThe case study highlights that our Borda ranking approach (https://borda.bips.eu) is fast, able to retrieve known ADRs and find other interesting signals. Hasty false conclusions are avoided by a verification study, which is, however, time-consuming.

ConclusionPost-market signal detection in EHC data is useful to identify and validate safety signals, particularly a few years after first admission to the market, when spontaneous reports are less frequent and more EHC data are available.",0
"Hue, J.; Valinciute, Z.; Thavaraj, S.; Veschini, L.",2022,High content image analysis in routine diagnostic histopathology predicts outcomes in HPV-associated oropharyngeal squamous cell carcinomas,Pathology,High content image analysis in routine diagnostic histopathology predicts outcomes in HPV-associated oropharyngeal squamous cell carcinomas,"Hue, J.; Valinciute, Z.; Thavaraj, S.; Veschini, L.",Pathology,2022-06-26 00:00:00 UTC,"ObjectiveRoutine haematoxylin and eosin (H&E) photomicrographs from human papillomavirus-associated oropharyngeal squamous cell carcinomas (HPV+OpSCC) contain a wealth of prognostic information. In this study, we set out to develop a high content image analysis workflow to quantify features of H&E images from HPV+OpSCC patients to identify prognostic features which can be used for prediction of patient outcomes.

MethodsWe have developed a dedicated image analysis workflow using open-source software, for single-cell segmentation and classification. This workflow was applied to a set of 567 images from diagnostic H&E slides in a retrospective cohort of HPV+OpSCC patients with favourable (n = 29) and unfavourable (n = 29) outcomes. Using our method, we have identified 31 quantitative prognostic features which were quantified in each sample and used to train a neural network model to predict patient outcomes. The model was validated by k-fold cross-validation using 10 folds and a test set.

ResultsUnivariate and multivariate statistical analyses revealed significant differences between the two patient outcome groups in 31 and 16 variables respectively (P<0.05). The neural network model had an overall accuracy of 78.8% and 77.7% in recognising favourable and unfavourable prognosis patients when applied to the test set and k-fold cross-validation respectively.

ConclusionOur open-source H&E analysis workflow and model can predict HPV+OpSCC outcomes with promising accuracy. Our work supports the use of machine learning in digital pathology to exploit clinically relevant features in routine diagnostic pathology without additional biomarkers.",10.1101/2022.06.24.22276368,virology-neural-networks.xlsx,"High content image analysis in routine diagnostic histopathology predicts outcomes in HPV-associated oropharyngeal squamous cell carcinomas ObjectiveRoutine haematoxylin and eosin (H&E) photomicrographs from human papillomavirus-associated oropharyngeal squamous cell carcinomas (HPV+OpSCC) contain a wealth of prognostic information. In this study, we set out to develop a high content image analysis workflow to quantify features of H&E images from HPV+OpSCC patients to identify prognostic features which can be used for prediction of patient outcomes.

MethodsWe have developed a dedicated image analysis workflow using open-source software, for single-cell segmentation and classification. This workflow was applied to a set of 567 images from diagnostic H&E slides in a retrospective cohort of HPV+OpSCC patients with favourable (n = 29) and unfavourable (n = 29) outcomes. Using our method, we have identified 31 quantitative prognostic features which were quantified in each sample and used to train a neural network model to predict patient outcomes. The model was validated by k-fold cross-validation using 10 folds and a test set.

ResultsUnivariate and multivariate statistical analyses revealed significant differences between the two patient outcome groups in 31 and 16 variables respectively (P<0.05). The neural network model had an overall accuracy of 78.8% and 77.7% in recognising favourable and unfavourable prognosis patients when applied to the test set and k-fold cross-validation respectively.

ConclusionOur open-source H&E analysis workflow and model can predict HPV+OpSCC outcomes with promising accuracy. Our work supports the use of machine learning in digital pathology to exploit clinically relevant features in routine diagnostic pathology without additional biomarkers.",1
"Yellapu, G. D.; Rudraraju, G.; Sripada, N. R.; Mamidgi, B.; Jalukuru, C.; Firmal, P.; Yechuri, V.; Varanasi, S.; Sudhakar, P. V.; Bhimarasetty, D. M.; Kanisetti, S.; Joshi, N.; Mohapatra, P.; Pamarthi, K.",2023,Development and Clinical Validation of Swaasa AI Platform for screening and prioritization of Pulmonary TB,Respiratory Medicine,Development and Clinical Validation of Swaasa AI Platform for screening and prioritization of Pulmonary TB,"Yellapu, G. D.; Rudraraju, G.; Sripada, N. R.; Mamidgi, B.; Jalukuru, C.; Firmal, P.; Yechuri, V.; Varanasi, S.; Sudhakar, P. V.; Bhimarasetty, D. M.; Kanisetti, S.; Joshi, N.; Mohapatra, P.; Pamarthi, K.",Respiratory Medicine,2023-02-22 00:00:00 UTC,"Acoustic signal analysis has been employed in various medical devices. However, studies involving cough sound analysis to screen the potential Pulmonary Tuberculosis (PTB) suspects are very few. The main objective of this cross-sectional validation study was to develop and validate the Swaasa AI platform to screen and prioritize at risk patients for PTB based on the signature cough sound as well as symptomatic information provided by the subjects. The voluntary cough sound data was collected at Andhra Medical College-India. An Algorithm based on multimodal Convolutional Neural Network (CNN) architecture and Feedforward Artificial Neural Network (FFANN) (tabular features) was built and validated on a total of 567 subjects, comprising 278 positive and 289 negative PTB cases. The output from these two models was combined to detect the likely presence (positive cases) of PTB. In the clinical validation phase, the AI-model was found to be 86.82% accurate in detecting the likely presence of PTB with 90.36% sensitivity and 84.67% specificity. The pilot testing of model was conducted at a peripheral health care centre, RHC Simhachalam-India on 65 presumptive PTB cases. Out of which, 15 subjects truly turned out to be PTB positive with a Positive Predictive Value of 75%. The validation results obtained from the model are quite encouraging. This platform has the potential to fulfil the unmet need of a cost-effective PTB screening method. It works remotely, presents instantaneous results, and does not require a highly trained operator. Therefore, it could be implemented in various inaccessible, resource-poor parts of the world.",10.1101/2022.09.19.22280114,virology-neural-networks.xlsx,"Development and Clinical Validation of Swaasa AI Platform for screening and prioritization of Pulmonary TB Acoustic signal analysis has been employed in various medical devices. However, studies involving cough sound analysis to screen the potential Pulmonary Tuberculosis (PTB) suspects are very few. The main objective of this cross-sectional validation study was to develop and validate the Swaasa AI platform to screen and prioritize at risk patients for PTB based on the signature cough sound as well as symptomatic information provided by the subjects. The voluntary cough sound data was collected at Andhra Medical College-India. An Algorithm based on multimodal Convolutional Neural Network (CNN) architecture and Feedforward Artificial Neural Network (FFANN) (tabular features) was built and validated on a total of 567 subjects, comprising 278 positive and 289 negative PTB cases. The output from these two models was combined to detect the likely presence (positive cases) of PTB. In the clinical validation phase, the AI-model was found to be 86.82% accurate in detecting the likely presence of PTB with 90.36% sensitivity and 84.67% specificity. The pilot testing of model was conducted at a peripheral health care centre, RHC Simhachalam-India on 65 presumptive PTB cases. Out of which, 15 subjects truly turned out to be PTB positive with a Positive Predictive Value of 75%. The validation results obtained from the model are quite encouraging. This platform has the potential to fulfil the unmet need of a cost-effective PTB screening method. It works remotely, presents instantaneous results, and does not require a highly trained operator. Therefore, it could be implemented in various inaccessible, resource-poor parts of the world.",1
"Turner, S. D.; Hulme-Lowe, C.; Nagraj, V. P.",2022,Forecasting Influenza-Like Illness (ILI) during the COVID-19 Pandemic,Epidemiology,Forecasting Influenza-Like Illness (ILI) during the COVID-19 Pandemic,"Turner, S. D.; Hulme-Lowe, C.; Nagraj, V. P.",Epidemiology,2022-10-30 00:00:00 UTC,"Near-term probabilistic forecasts for infectious diseases such as COVID-19 and influenza play an important role in public health communication and policymaking. From 2013-2019, the FluSight challenge run by the Centers for Disease Control and Prevention invited researchers to develop and submit forecasts using influenza-like illness (ILI) as a measure of influenza burden. Here we examine how several statistical models and an autoregressive neural network model perform for forecasting ILI during the COVID-19 pandemic, where historical patterns of ILI were highly disrupted. We find that the autoregressive neural network model which forecasted ILI well pre-COVID still performs well for some locations and forecast horizons, but its performance is highly variable, and performs poorly in many cases. We found that a simple exponential smoothing statistical model is in the top half of ranked models we evaluated nearly 75% of the time. Our results suggest that even simple statistical models may perform as well as or better than more complex machine learning models for forecasting ILI during the COVID-19 pandemic. We also created an ensemble model from the limited set of time series forecast models we created here. The limited ensemble model was rarely the best or the worst performing model compared to the rest of the models assessed, confirming previous observations from other infectious disease forecasting efforts on the less variable and generally favorable performance of ensemble forecasts. Our results support previous findings that no single modeling approach outperforms all other models across all locations, time points, and forecast horizons, and that ensemble forecasting consortia such as the COVID-19 Forecast Hub and FluSight continue to serve valuable roles in collecting, aggregating, and ensembling forecasts using fundamentally disparate modeling strategies.",10.1101/2022.10.27.22281617,virology-neural-networks.xlsx,"Forecasting Influenza-Like Illness (ILI) during the COVID-19 Pandemic Near-term probabilistic forecasts for infectious diseases such as COVID-19 and influenza play an important role in public health communication and policymaking. From 2013-2019, the FluSight challenge run by the Centers for Disease Control and Prevention invited researchers to develop and submit forecasts using influenza-like illness (ILI) as a measure of influenza burden. Here we examine how several statistical models and an autoregressive neural network model perform for forecasting ILI during the COVID-19 pandemic, where historical patterns of ILI were highly disrupted. We find that the autoregressive neural network model which forecasted ILI well pre-COVID still performs well for some locations and forecast horizons, but its performance is highly variable, and performs poorly in many cases. We found that a simple exponential smoothing statistical model is in the top half of ranked models we evaluated nearly 75% of the time. Our results suggest that even simple statistical models may perform as well as or better than more complex machine learning models for forecasting ILI during the COVID-19 pandemic. We also created an ensemble model from the limited set of time series forecast models we created here. The limited ensemble model was rarely the best or the worst performing model compared to the rest of the models assessed, confirming previous observations from other infectious disease forecasting efforts on the less variable and generally favorable performance of ensemble forecasts. Our results support previous findings that no single modeling approach outperforms all other models across all locations, time points, and forecast horizons, and that ensemble forecasting consortia such as the COVID-19 Forecast Hub and FluSight continue to serve valuable roles in collecting, aggregating, and ensembling forecasts using fundamentally disparate modeling strategies.",1
"P, P.; Rudraraju, G.; Sripada, N. R.; Mamidgi, B.; Gottipulla, C.; Jalukuru, C.; Palreddy, S.; Bhoge, N. K. R.; Firmal, P.; Yechuri, V.; Sudhakar, P. V.; B, D. M.; S, S.; K, K. L. P.; Joshi, N.",2022,Screening COVID-19 by Swaasa AI Platform using cough sounds: A cross-sectional study,Respiratory Medicine,Screening COVID-19 by Swaasa AI Platform using cough sounds: A cross-sectional study,"P, P.; Rudraraju, G.; Sripada, N. R.; Mamidgi, B.; Gottipulla, C.; Jalukuru, C.; Palreddy, S.; Bhoge, N. K. R.; Firmal, P.; Yechuri, V.; Sudhakar, P. V.; B, D. M.; S, S.; K, K. L. P.; Joshi, N.",Respiratory Medicine,2022-11-04 00:00:00 UTC,"The Advent of Artificial Intelligence (AI) has led to the use of auditory data for detecting various diseases, including COVID-19. SARS-CoV-2 infection has claimed more than 6 million lives till date and hence, needs a robust screening technique to control the disease spread. In the present study we developed and validated the Swaasa AI platform for screening and prioritizing COVID-19 patients based on the signature cough sound and the symptoms presented by the subjects. The cough data records collected from 234 COVID-19 suspects were subjected to validate the convolutional neural network (CNN) architecture and tabular features-based algorithm. The likelihood of the disease was predicted by combining the final output obtained from both the models. In the clinical validation phase, Swaasa was found to be 75.54% accurate in detecting the likely presence of COVID-19 with 95.45% sensitivity and 73.46% specificity. The pilot testing of Swaasa was carried out on 183 presumptive COVID subjects, out of which 82 subjects were found to be positive for the disease by Swaasa. Among them, 58 subjects were truly COVID-19 positive, which corresponds to a Positive Predictive Value of 70.73%. The currently available rapid screening methods are very costly and require technical expertise, therefore a cost effective, remote monitoring tool would be very beneficial for preliminary screening of the potential COVID-19 subject.",10.1101/2022.11.02.22281821,virology-neural-networks.xlsx,"Screening COVID-19 by Swaasa AI Platform using cough sounds: A cross-sectional study The Advent of Artificial Intelligence (AI) has led to the use of auditory data for detecting various diseases, including COVID-19. SARS-CoV-2 infection has claimed more than 6 million lives till date and hence, needs a robust screening technique to control the disease spread. In the present study we developed and validated the Swaasa AI platform for screening and prioritizing COVID-19 patients based on the signature cough sound and the symptoms presented by the subjects. The cough data records collected from 234 COVID-19 suspects were subjected to validate the convolutional neural network (CNN) architecture and tabular features-based algorithm. The likelihood of the disease was predicted by combining the final output obtained from both the models. In the clinical validation phase, Swaasa was found to be 75.54% accurate in detecting the likely presence of COVID-19 with 95.45% sensitivity and 73.46% specificity. The pilot testing of Swaasa was carried out on 183 presumptive COVID subjects, out of which 82 subjects were found to be positive for the disease by Swaasa. Among them, 58 subjects were truly COVID-19 positive, which corresponds to a Positive Predictive Value of 70.73%. The currently available rapid screening methods are very costly and require technical expertise, therefore a cost effective, remote monitoring tool would be very beneficial for preliminary screening of the potential COVID-19 subject.",1
"Kuwahara, B.; Bauch, C.",2023,Predicting COVID-19 pandemic waves with biologically and behaviorally informed universal differential equations,Epidemiology,Predicting COVID-19 pandemic waves with biologically and behaviorally informed universal differential equations,"Kuwahara, B.; Bauch, C.",Epidemiology,2023-03-16 00:00:00 UTC,"In the early stages of the COVID-19 pandemic, it became clear that pandemic waves and population responses were locked in a mutual feedback loop. The initial lull following strict interventions in the first wave often led to a second wave, as restrictions were relaxed. We test the ability of new hybrid machine learning techniques, namely universal differential equations (UDEs) with learning biases, to make predictions in a such a dynamic behavior-disease setting. We develop a UDE model for COVID-19 and test it both with and without learning biases describing simple assumptions about disease transmission and population response. Our results show that UDEs, particularly when supplied with learning biases, are capable of learning coupled behavior-disease dynamics and predicting second waves in a variety of populations. The model predicts a second wave of infections 55% of the time across all populations, having been trained only on the first wave. The predicted second wave is larger than the first. Without learning biases, model predictions are hampered: the unbiased model predicts a second wave only 25% of the time, typically smaller than the first. The biased model consistently predicts the expected increase in the transmission rate with rising mobility, whereas the unbiased model predicts a decrease in mobility as often as a continued increase. The biased model also achieves better accuracy on its training data thanks to fewer and less severely divergent trajectories. These results indicate that biologically informed machine learning can generate qualitatively correct mid to long-term predictions of COVID-19 pandemic waves.

Significance statementUniversal differential equations are a relatively new modelling technique where neural networks use data to learn unknown components of a dynamical system. We demonstrate for the first time that this technique is able to extract valuable information from data on a coupled behaviour-disease system. Our model was able to learn the interplay between COVID-19 infections and time spent travelling to retail and recreation locations in order to predict a second wave of cases, having been trained only on the first wave. We also demonstrate that adding additional terms to the universal differential equations loss function that penalize implausible solutions improves training time and leads to improved predictions.",10.1101/2023.03.11.23287141,virology-neural-networks.xlsx,"Predicting COVID-19 pandemic waves with biologically and behaviorally informed universal differential equations In the early stages of the COVID-19 pandemic, it became clear that pandemic waves and population responses were locked in a mutual feedback loop. The initial lull following strict interventions in the first wave often led to a second wave, as restrictions were relaxed. We test the ability of new hybrid machine learning techniques, namely universal differential equations (UDEs) with learning biases, to make predictions in a such a dynamic behavior-disease setting. We develop a UDE model for COVID-19 and test it both with and without learning biases describing simple assumptions about disease transmission and population response. Our results show that UDEs, particularly when supplied with learning biases, are capable of learning coupled behavior-disease dynamics and predicting second waves in a variety of populations. The model predicts a second wave of infections 55% of the time across all populations, having been trained only on the first wave. The predicted second wave is larger than the first. Without learning biases, model predictions are hampered: the unbiased model predicts a second wave only 25% of the time, typically smaller than the first. The biased model consistently predicts the expected increase in the transmission rate with rising mobility, whereas the unbiased model predicts a decrease in mobility as often as a continued increase. The biased model also achieves better accuracy on its training data thanks to fewer and less severely divergent trajectories. These results indicate that biologically informed machine learning can generate qualitatively correct mid to long-term predictions of COVID-19 pandemic waves.

Significance statementUniversal differential equations are a relatively new modelling technique where neural networks use data to learn unknown components of a dynamical system. We demonstrate for the first time that this technique is able to extract valuable information from data on a coupled behaviour-disease system. Our model was able to learn the interplay between COVID-19 infections and time spent travelling to retail and recreation locations in order to predict a second wave of cases, having been trained only on the first wave. We also demonstrate that adding additional terms to the universal differential equations loss function that penalize implausible solutions improves training time and leads to improved predictions.",1
"Boissin, C.; Wang, Y.; Sharma, A.; Weitz, P.; Karlsson, E.; Robertson, S.; Hartman, J.; Rantalainen, M.",2023,Deep learning-based risk stratification of preoperative breast biopsies using digital whole slide images,Pathology,Deep learning-based risk stratification of preoperative breast biopsies using digital whole slide images,"Boissin, C.; Wang, Y.; Sharma, A.; Weitz, P.; Karlsson, E.; Robertson, S.; Hartman, J.; Rantalainen, M.",Pathology,2023-08-24 00:00:00 UTC,"IntroductionNottingham histological grade (NHG) is a well established prognostic factor in breast cancer histopathology. However, manual NHG assessment of biopsies is challenging and has a large inter-assessor variability with a large proportion being classified as NHG2 (intermediate grade). Here, we evaluate whether DeepGrade, a previously developed model for the risk stratification of resected tumour specimens, could be applied to risk-stratify biopsy specimens.

MethodsA total of 11,943,905 tiles from 1171 whole slide images (WSIs) of preoperative biopsies from 897 patients diagnosed with breast cancer in Stockholm, Sweden, were included in this retrospective observational study. DeepGrade, a deep convolutional neural network model, was applied for classification of low and high risk tumours and evaluated against clinically assigned grades 1 and 3 using area under the operating curve (AUC). The prognostic value of the DeepGrade model in the biopsy setting was evaluated using time-to-event analysis.

ResultsThe DeepGrade model classified resected tumour cases with grades NHG1 and NHG3 using only biopsy specimens with an AUC of 0.903 (95% CI: 0.88;0.93). The model could also classify the biopsy NHG (1 and 3) assessed on the biopsy of 186 patients with an AUC of 0.959 (95% CI: 0.93; 0.99). Furthermore, out of the 434 NHG2 tumours, 255 (59%) were classified as DeepGrade2-low, and 179 (41%) were classified as DeepGrade2-high. Using a multivariable Cox proportional hazards model the hazard ratio between low- and high-risk groups was estimated as 2.01 (p-value = 0.036).

ConclusionsDeepGrade could predict the resected tumour grades NHG1 and NHG3 using only the biopsy specimen and sub-classify grade 2 tumours into low and high risks. The results demonstrate that the DeepGrade model can provide decision support for biopsy grading, and potentially provide decision support in the clinical setting to identifying high-risk tumours based on preoperative breast biopsies, thus improving information available for clinical treatment decisions.",10.1101/2023.08.22.23294409,virology-neural-networks.xlsx,"Deep learning-based risk stratification of preoperative breast biopsies using digital whole slide images IntroductionNottingham histological grade (NHG) is a well established prognostic factor in breast cancer histopathology. However, manual NHG assessment of biopsies is challenging and has a large inter-assessor variability with a large proportion being classified as NHG2 (intermediate grade). Here, we evaluate whether DeepGrade, a previously developed model for the risk stratification of resected tumour specimens, could be applied to risk-stratify biopsy specimens.

MethodsA total of 11,943,905 tiles from 1171 whole slide images (WSIs) of preoperative biopsies from 897 patients diagnosed with breast cancer in Stockholm, Sweden, were included in this retrospective observational study. DeepGrade, a deep convolutional neural network model, was applied for classification of low and high risk tumours and evaluated against clinically assigned grades 1 and 3 using area under the operating curve (AUC). The prognostic value of the DeepGrade model in the biopsy setting was evaluated using time-to-event analysis.

ResultsThe DeepGrade model classified resected tumour cases with grades NHG1 and NHG3 using only biopsy specimens with an AUC of 0.903 (95% CI: 0.88;0.93). The model could also classify the biopsy NHG (1 and 3) assessed on the biopsy of 186 patients with an AUC of 0.959 (95% CI: 0.93; 0.99). Furthermore, out of the 434 NHG2 tumours, 255 (59%) were classified as DeepGrade2-low, and 179 (41%) were classified as DeepGrade2-high. Using a multivariable Cox proportional hazards model the hazard ratio between low- and high-risk groups was estimated as 2.01 (p-value = 0.036).

ConclusionsDeepGrade could predict the resected tumour grades NHG1 and NHG3 using only the biopsy specimen and sub-classify grade 2 tumours into low and high risks. The results demonstrate that the DeepGrade model can provide decision support for biopsy grading, and potentially provide decision support in the clinical setting to identifying high-risk tumours based on preoperative breast biopsies, thus improving information available for clinical treatment decisions.",0
"Griffin, M.; Gruver, A.; Shah, C.; Wani, Q.; Fahy, D.; Khosla, A.; Kirkup, C.; Borders, D.; Brosnancashman, J. A.; Fulford, A. D.; Credille, K. M.; Jayson, C.; Najdawi, F.; Gottlieb, K.",2023,Fully automated histological classification of cell types and tissue regions of celiac disease is feasible and correlates with the Marsh score,Pathology,Fully automated histological classification of cell types and tissue regions of celiac disease is feasible and correlates with the Marsh score,"Griffin, M.; Gruver, A.; Shah, C.; Wani, Q.; Fahy, D.; Khosla, A.; Kirkup, C.; Borders, D.; Brosnancashman, J. A.; Fulford, A. D.; Credille, K. M.; Jayson, C.; Najdawi, F.; Gottlieb, K.",Pathology,2023-12-11 00:00:00 UTC,"AimsHistological assessment is essential for the diagnosis and management of celiac disease. Current scoring systems, including modified Marsh (Marsh-Oberhuber) score, lack inter-pathologist agreement. To address this unmet need, we aimed to develop a fully automated, quantitative approach for histology characterisation of celiac disease.

MethodsConvolutional neural network models were trained using pathologist annotations of haematoxylin and eosin-stained biopsies of celiac disease mucosa and normal duodenum to identify cells, tissue and artifact regions. Human interpretable features were extracted and the strength of their correlation with Marsh scores were calculated using Spearman rank correlations.

ResultsOur model accurately identified cells, tissue regions and artifacts, including distinguishing intraepithelial lymphocytes and differentiating villous epithelium from crypt epithelium. Proportional area measurements representing villous atrophy negatively correlated with Marsh scores (r=-0.79), while measurements indicative of crypt hyperplasia and intraepithelial lymphocytosis positively correlated (r=0.71 and r=0.44, respectively). Furthermore, features distinguishing celiac disease from normal colon were identified.

ConclusionsOur novel model provides an explainable and fully automated approach for histology characterisation of celiac disease that correlates with modified Marsh scores, facilitating diagnosis, prognosis, clinical trials and treatment response monitoring.

KEY MESSAGESO_ST_ABSWhat is already known on this topicC_ST_ABS[tpltrtarr] Prior research has utilised machine learning (ML) techniques to detect celiac disease and evaluate disease severity based on Marsh scores.
[tpltrtarr]However, existing approaches lack the capability to provide fully explainable tissue segmentation and cell classifications across whole slide images in celiac disease histology.
[tpltrtarr]The need for a more comprehensive and interpretable ML-based method for celiac disease diagnosis and characterisation is evident from the limitations of currently available scoring systems as well as inter-pathologist variability.


What this study adds[tpltrtarr] This study is the first to introduce an explainable ML-based approach that provides comprehensive, objective celiac disease histology characterisation, overcoming inter-observer variability and offering a scalable tool for assessing disease severity and monitoring treatment response.


How this study might affect research, practice or policy[tpltrtarr] This studys fully automated and ML-based histological analysis, including the correlation of Marsh scores, has the potential to enable more precise disease severity measurement, risk assessment and clinical trial endpoint evaluation, ultimately improving patient care.",10.1101/2023.12.11.23299520,virology-neural-networks.xlsx,"Fully automated histological classification of cell types and tissue regions of celiac disease is feasible and correlates with the Marsh score AimsHistological assessment is essential for the diagnosis and management of celiac disease. Current scoring systems, including modified Marsh (Marsh-Oberhuber) score, lack inter-pathologist agreement. To address this unmet need, we aimed to develop a fully automated, quantitative approach for histology characterisation of celiac disease.

MethodsConvolutional neural network models were trained using pathologist annotations of haematoxylin and eosin-stained biopsies of celiac disease mucosa and normal duodenum to identify cells, tissue and artifact regions. Human interpretable features were extracted and the strength of their correlation with Marsh scores were calculated using Spearman rank correlations.

ResultsOur model accurately identified cells, tissue regions and artifacts, including distinguishing intraepithelial lymphocytes and differentiating villous epithelium from crypt epithelium. Proportional area measurements representing villous atrophy negatively correlated with Marsh scores (r=-0.79), while measurements indicative of crypt hyperplasia and intraepithelial lymphocytosis positively correlated (r=0.71 and r=0.44, respectively). Furthermore, features distinguishing celiac disease from normal colon were identified.

ConclusionsOur novel model provides an explainable and fully automated approach for histology characterisation of celiac disease that correlates with modified Marsh scores, facilitating diagnosis, prognosis, clinical trials and treatment response monitoring.

KEY MESSAGESO_ST_ABSWhat is already known on this topicC_ST_ABS[tpltrtarr] Prior research has utilised machine learning (ML) techniques to detect celiac disease and evaluate disease severity based on Marsh scores.
[tpltrtarr]However, existing approaches lack the capability to provide fully explainable tissue segmentation and cell classifications across whole slide images in celiac disease histology.
[tpltrtarr]The need for a more comprehensive and interpretable ML-based method for celiac disease diagnosis and characterisation is evident from the limitations of currently available scoring systems as well as inter-pathologist variability.


What this study adds[tpltrtarr] This study is the first to introduce an explainable ML-based approach that provides comprehensive, objective celiac disease histology characterisation, overcoming inter-observer variability and offering a scalable tool for assessing disease severity and monitoring treatment response.


How this study might affect research, practice or policy[tpltrtarr] This studys fully automated and ML-based histological analysis, including the correlation of Marsh scores, has the potential to enable more precise disease severity measurement, risk assessment and clinical trial endpoint evaluation, ultimately improving patient care.",0
"Navascues, M.; Guryanova, Y.; Budroni, C.",2021,Disease control as an optimization problem,Epidemiology,Disease control as an optimization problem,"Navascues, M.; Guryanova, Y.; Budroni, C.",Epidemiology,2021-03-01 00:00:00 UTC,"Traditionally, expert epidemiologists devise policies for disease control through a mixture of intuition and brute force. Namely, they use their know-how to narrow down the set of logically conceivable policies to a small family described by a few parameters, following which they conduct a grid search to identify the optimal policy within the set. This scheme is not scalable, in the sense that, when used to optimize over policies which depend on many parameters, it will likely fail to output an optimal disease policy in time for its implementation. In this article, we use techniques from convex optimization theory and machine learning to conduct optimizations over disease policies described by hundreds of parameters. In contrast to past approaches for policy optimization based on control theory, our framework can deal with arbitrary uncertainties on the initial conditions and model parameters controlling the spread of the disease. In addition, our methods allow for optimization over weekly-constant policies, specified by either continuous or discrete government measures (e.g.: lockdown on/off). We illustrate our approach by minimizing the total time required to eradicate COVID-19 within the Susceptible-Exposed-Infected-Recovered (SEIR) model proposed by Kissler et al. (March, 2020).",10.1101/2020.09.15.20194811,virology-reinforcement.xlsx,"Disease control as an optimization problem Traditionally, expert epidemiologists devise policies for disease control through a mixture of intuition and brute force. Namely, they use their know-how to narrow down the set of logically conceivable policies to a small family described by a few parameters, following which they conduct a grid search to identify the optimal policy within the set. This scheme is not scalable, in the sense that, when used to optimize over policies which depend on many parameters, it will likely fail to output an optimal disease policy in time for its implementation. In this article, we use techniques from convex optimization theory and machine learning to conduct optimizations over disease policies described by hundreds of parameters. In contrast to past approaches for policy optimization based on control theory, our framework can deal with arbitrary uncertainties on the initial conditions and model parameters controlling the spread of the disease. In addition, our methods allow for optimization over weekly-constant policies, specified by either continuous or discrete government measures (e.g.: lockdown on/off). We illustrate our approach by minimizing the total time required to eradicate COVID-19 within the Susceptible-Exposed-Infected-Recovered (SEIR) model proposed by Kissler et al. (March, 2020).",1
"Hu, Z.; Ge, Q.; Li, S.; Jin, L.; Xiong, M.",2020,Evaluating the effect of public health intervention on the global-wide spread trajectory of Covid-19,Epidemiology,Evaluating the effect of public health intervention on the global-wide spread trajectory of Covid-19,"Hu, Z.; Ge, Q.; Li, S.; Jin, L.; Xiong, M.",Epidemiology,2020-03-16 00:00:00 UTC,"As COVID-19 evolves rapidly, the issues the governments of affected countries facing are whether and when to take public health interventions and what levels of strictness of these interventions should be, as well as when the COVID-19 spread reaches the stopping point after interventions are taken. To help governments with policy-making, we developed modified auto-encoders (MAE) method to forecast spread trajectory of Covid-19 of countries affected, under different levels and timing of intervention strategies. Our analysis showed public health interventions should be executed as soon as possible. Delaying intervention 4 weeks after March 8, 2020 would cause the maximum number of cumulative cases of death increase from 7,174 to 133,608 and the ending points of the epidemic postponed from Jun 25 to Aug 22.",10.1101/2020.03.11.20033639,virology-transformer.xlsx,"Evaluating the effect of public health intervention on the global-wide spread trajectory of Covid-19 As COVID-19 evolves rapidly, the issues the governments of affected countries facing are whether and when to take public health interventions and what levels of strictness of these interventions should be, as well as when the COVID-19 spread reaches the stopping point after interventions are taken. To help governments with policy-making, we developed modified auto-encoders (MAE) method to forecast spread trajectory of Covid-19 of countries affected, under different levels and timing of intervention strategies. Our analysis showed public health interventions should be executed as soon as possible. Delaying intervention 4 weeks after March 8, 2020 would cause the maximum number of cumulative cases of death increase from 7,174 to 133,608 and the ending points of the epidemic postponed from Jun 25 to Aug 22.",1
"Prowse, T.; Purcell, T.; Clarys Baia-Da-Silva, D.; Sampaio, V.; Marcelo Monteiro, W.; Wood, J.; Mueller, I.; Mcvernon, J.; Lacerda, M.; Ross, J.",2020,"INFERRED RESOLUTION THROUGH HERD IMMMUNITY OF FIRST COVID-19 WAVE IN MANAUS, BRAZILIAN AMAZON",Epidemiology,"INFERRED RESOLUTION THROUGH HERD IMMMUNITY OF FIRST COVID-19 WAVE IN MANAUS, BRAZILIAN AMAZON","Prowse, T.; Purcell, T.; Clarys Baia-Da-Silva, D.; Sampaio, V.; Marcelo Monteiro, W.; Wood, J.; Mueller, I.; Mcvernon, J.; Lacerda, M.; Ross, J.",Epidemiology,2020-10-15 00:00:00 UTC,"INTRODUCTORY PARAGRAPHAs in many other settings, peak excess mortality preceded the officially reported  first wave peak of the COVID-19 epidemic in Manaus, Brazil, reflecting delayed case recognition and limited initial access to diagnostic testing. To avoid early information bias, we used detailed age and gender stratified death certificate and hospitalisation data to evaluate the epidemics trajectory and infer the cause of its decline using a stochastic model. Our results are consistent with heterogenous transmission reducing over time due to the development of herd immunity. Relative to a baseline model that assumed homogenous mixing across Manaus, a model that permitted a small, self-isolated population fraction raised the estimated herd-immunity threshold from 28% to 30% and reduced the final attack rate from 86% to 65%. In the latter scenario, a substantial proportion of vulnerable, older individuals remained susceptible to infection. Given uncertainties regarding the distancing behaviours of population subgroups with different social and economic characteristics, and the duration of sterilising or transmission-modifying immunity in exposed individuals, we conclude that the potential for epidemic outbreaks remains, but that future waves of infection are likely to be much less pronounced than that already experienced.",10.1101/2020.09.25.20201939,virology-transformer.xlsx,"INFERRED RESOLUTION THROUGH HERD IMMMUNITY OF FIRST COVID-19 WAVE IN MANAUS, BRAZILIAN AMAZON INTRODUCTORY PARAGRAPHAs in many other settings, peak excess mortality preceded the officially reported  first wave peak of the COVID-19 epidemic in Manaus, Brazil, reflecting delayed case recognition and limited initial access to diagnostic testing. To avoid early information bias, we used detailed age and gender stratified death certificate and hospitalisation data to evaluate the epidemics trajectory and infer the cause of its decline using a stochastic model. Our results are consistent with heterogenous transmission reducing over time due to the development of herd immunity. Relative to a baseline model that assumed homogenous mixing across Manaus, a model that permitted a small, self-isolated population fraction raised the estimated herd-immunity threshold from 28% to 30% and reduced the final attack rate from 86% to 65%. In the latter scenario, a substantial proportion of vulnerable, older individuals remained susceptible to infection. Given uncertainties regarding the distancing behaviours of population subgroups with different social and economic characteristics, and the duration of sterilising or transmission-modifying immunity in exposed individuals, we conclude that the potential for epidemic outbreaks remains, but that future waves of infection are likely to be much less pronounced than that already experienced.",1
"Pietre, E.; Amorim, G. P.; Bittencourt, M. F.; Ribeiro-Alves, M.; Acquarone, M.",2021,Prevalent comorbidities among young and underprivileged: Death portrait of COVID-19 among 235 555 hospitalized patients in Brazil,Epidemiology,Prevalent comorbidities among young and underprivileged: Death portrait of COVID-19 among 235 555 hospitalized patients in Brazil,"Pietre, E.; Amorim, G. P.; Bittencourt, M. F.; Ribeiro-Alves, M.; Acquarone, M.",Epidemiology,2021-01-25 00:00:00 UTC,"BackgroundCOVID-19 has been alarmingly spreading worldwide, with Brazil ranking third in total number of cases and second in deaths. Being a continental country, which comprises many ethnic groups and an engrained social inequality, the pandemic evidenced this heterogeneous discrepancy. We aimed to estimate the impact of associated risk factors, isolated or combined, on COVID-19 severeness, detecting specific epidemiological profiles for multiple age ranges in hospitalized Brazilians.

MethodsIn this large retrospective cohort study, we used open-access data from the Ministry of Health of Brazil with COVID-19 confirmed hospitalized patients annotated in SRAG system between February and August 2020, a total of 235555 entries. The association of COVID-19 death with socio-demographic and clinical characteristics was analysed and presented as odds ratios adjusted by confounding co-variables. We also presented marginal mean aOR values for high-order interactions either by or not another fixed level or condition. We kept all other variables in the multivariate logistic models in their mean values or equal proportions.

FindingsYounger individuals with one or more comorbidities had an adjusted odds ratio up to four-fold compared to those without it, in the same age interval. Younger diabetic patients either self-declared as brown ethnicity (aOR 5{middle dot}58, 95% CI 4{middle dot}97-6{middle dot}25; p<0{middle dot}0001) or with some other associated comorbidities, mainly chronic hematologic disease (21{middle dot}09, 13{middle dot}64-32{middle dot}6; p<0{middle dot}0001) and obesity (aOR 21{middle dot}7, 95% CI not calculated; p<0{middle dot}0001), resulted in outstanding death risk. Age over 60, particularly over 90 (28{middle dot}91, 24{middle dot}5-34{middle dot}11; p<0.001), usage of invasive ventilatory support (16{middle dot}23, 14{middle dot}05-18{middle dot}75; p<0{middle dot}001), admission to intensive care units (3{middle dot}14, 2{middle dot}82-3{middle dot}48; p<0{middle dot}001), multiple respiratory symptoms (3{middle dot}24, 2{middle dot}79-3{middle dot}75; p<0{middle dot}0001), black ethnicity (1{middle dot}78, 1{middle dot}52-2{middle dot}07; p<0{middle dot}05), and diagnosis previous to hospitalization (1{middle dot}32, 1{middle dot}19-1{middle dot}47; p<0{middle dot}05) were associated with higher death odds. As protective factors, with roughly one third less death risk, we found hospitalization duration of (4, 7] days and illness onset to hospitalization over 6 days.

InterpretationWe found evidence for increased COVID-19 risk in two distinct groups: younger patients with prevalent comorbidities, especially in brown ethnicity, and patients with black ethnicity. We speculate that the pro-inflammatory synergism of COVID-19 and comorbidities, promoting an overproduction of cytokines, is partially the cause of higher mortality in this young group. Brazilian black and brown are underprivileged populations, with structural social inequality, limited healthcare access and, thus, remarkable disease vulnerability. Our study supplies essential data to patient stratification upon admission, optimizing hospital management, and to guide public policy determinations, including group prioritization for COVID-19 vaccination in Brazil.

FundingNone.

O_TEXTBOXResearch in context

Evidence before this studyCOVID-19 is still very active, having spread to over two hundred countries and caused more than one million deaths worldwide. Its current situation requires large-scale studies to assess the impact of preexisting comorbidities, symptoms, and socioeconomic issues regarding mortality rate, especially where lack of control is evident. We searched PubMed, Google Scholar, medRxiv, and bioRxiv on Dec 12, 2020, for studies published in English or Brazilian Portuguese, estimating the impact of several risk factors in COVID-19 prognosis. We used the search terms ""Brazil"" or ""risk factors"" or ""ethnicity"" or ""cohort"" or ""diabetes mellitus"" or ""mortality"" or ""symptoms"" or ""comorbidities"", and related synonyms, combined with ""SARS-CoV-2"" or ""COVID-19"". Many pre-existing conditions have shown to directly impact patient prognosis, out of which cancer, chronic kidney disease, chronic obstructive pulmonary disease, cardiovascular disease, obesity, and diabetes, among others, are well established in SARS-CoV-2 infection severeness. Some studies reported an increased death risk for non-white Brazilians, but no large scale cohort analyzing the impact of one or more associated risk factors in younger Brazilians patients were found.

Added value of this studyWe found that the impact of having one or two or more risk factors on mortality are progressively higher in ages (60, 80], (40, 60], (20, 40], and (0, 20], compared with people of the same age interval without comorbidities. We also found that young brown individuals with diabetes, as well as black ethnicity on its own, are population subgroups at remarkably higher risk for severe COVID-19 in Brazil. Furthermore, advanced age, usage of ventilatory support, admission to intensive care units, multiple respiratory symptoms, and diagnosis previous to hospitalization were associated with higher death odds. As protective factors, we found hospitalization duration of (4, 7] days and illness onset to hospitalization over 6 days.

Implications of all the available evidenceWe identified multiple epidemiological profiles associated with death risk in different age ranges in Brazilian COVID-19 hospitalized patients. These findings unveil that a large part of Brazilian working-age population is at a higher risk for SARS-CoV-2 death, a neglected situation that is further exacerbating inequalities, leading to a striking sociodemographic and economic impact. We hope that our analysis aids patient risk stratification, hospital management optimization, and public policy determination, including prioritization for COVID-19 vaccination in Brazil.

C_TEXTBOX",10.1101/2021.01.22.21250346,virology-transformer.xlsx,"Prevalent comorbidities among young and underprivileged: Death portrait of COVID-19 among 235 555 hospitalized patients in Brazil BackgroundCOVID-19 has been alarmingly spreading worldwide, with Brazil ranking third in total number of cases and second in deaths. Being a continental country, which comprises many ethnic groups and an engrained social inequality, the pandemic evidenced this heterogeneous discrepancy. We aimed to estimate the impact of associated risk factors, isolated or combined, on COVID-19 severeness, detecting specific epidemiological profiles for multiple age ranges in hospitalized Brazilians.

MethodsIn this large retrospective cohort study, we used open-access data from the Ministry of Health of Brazil with COVID-19 confirmed hospitalized patients annotated in SRAG system between February and August 2020, a total of 235555 entries. The association of COVID-19 death with socio-demographic and clinical characteristics was analysed and presented as odds ratios adjusted by confounding co-variables. We also presented marginal mean aOR values for high-order interactions either by or not another fixed level or condition. We kept all other variables in the multivariate logistic models in their mean values or equal proportions.

FindingsYounger individuals with one or more comorbidities had an adjusted odds ratio up to four-fold compared to those without it, in the same age interval. Younger diabetic patients either self-declared as brown ethnicity (aOR 5{middle dot}58, 95% CI 4{middle dot}97-6{middle dot}25; p<0{middle dot}0001) or with some other associated comorbidities, mainly chronic hematologic disease (21{middle dot}09, 13{middle dot}64-32{middle dot}6; p<0{middle dot}0001) and obesity (aOR 21{middle dot}7, 95% CI not calculated; p<0{middle dot}0001), resulted in outstanding death risk. Age over 60, particularly over 90 (28{middle dot}91, 24{middle dot}5-34{middle dot}11; p<0.001), usage of invasive ventilatory support (16{middle dot}23, 14{middle dot}05-18{middle dot}75; p<0{middle dot}001), admission to intensive care units (3{middle dot}14, 2{middle dot}82-3{middle dot}48; p<0{middle dot}001), multiple respiratory symptoms (3{middle dot}24, 2{middle dot}79-3{middle dot}75; p<0{middle dot}0001), black ethnicity (1{middle dot}78, 1{middle dot}52-2{middle dot}07; p<0{middle dot}05), and diagnosis previous to hospitalization (1{middle dot}32, 1{middle dot}19-1{middle dot}47; p<0{middle dot}05) were associated with higher death odds. As protective factors, with roughly one third less death risk, we found hospitalization duration of (4, 7] days and illness onset to hospitalization over 6 days.

InterpretationWe found evidence for increased COVID-19 risk in two distinct groups: younger patients with prevalent comorbidities, especially in brown ethnicity, and patients with black ethnicity. We speculate that the pro-inflammatory synergism of COVID-19 and comorbidities, promoting an overproduction of cytokines, is partially the cause of higher mortality in this young group. Brazilian black and brown are underprivileged populations, with structural social inequality, limited healthcare access and, thus, remarkable disease vulnerability. Our study supplies essential data to patient stratification upon admission, optimizing hospital management, and to guide public policy determinations, including group prioritization for COVID-19 vaccination in Brazil.

FundingNone.

O_TEXTBOXResearch in context

Evidence before this studyCOVID-19 is still very active, having spread to over two hundred countries and caused more than one million deaths worldwide. Its current situation requires large-scale studies to assess the impact of preexisting comorbidities, symptoms, and socioeconomic issues regarding mortality rate, especially where lack of control is evident. We searched PubMed, Google Scholar, medRxiv, and bioRxiv on Dec 12, 2020, for studies published in English or Brazilian Portuguese, estimating the impact of several risk factors in COVID-19 prognosis. We used the search terms ""Brazil"" or ""risk factors"" or ""ethnicity"" or ""cohort"" or ""diabetes mellitus"" or ""mortality"" or ""symptoms"" or ""comorbidities"", and related synonyms, combined with ""SARS-CoV-2"" or ""COVID-19"". Many pre-existing conditions have shown to directly impact patient prognosis, out of which cancer, chronic kidney disease, chronic obstructive pulmonary disease, cardiovascular disease, obesity, and diabetes, among others, are well established in SARS-CoV-2 infection severeness. Some studies reported an increased death risk for non-white Brazilians, but no large scale cohort analyzing the impact of one or more associated risk factors in younger Brazilians patients were found.

Added value of this studyWe found that the impact of having one or two or more risk factors on mortality are progressively higher in ages (60, 80], (40, 60], (20, 40], and (0, 20], compared with people of the same age interval without comorbidities. We also found that young brown individuals with diabetes, as well as black ethnicity on its own, are population subgroups at remarkably higher risk for severe COVID-19 in Brazil. Furthermore, advanced age, usage of ventilatory support, admission to intensive care units, multiple respiratory symptoms, and diagnosis previous to hospitalization were associated with higher death odds. As protective factors, we found hospitalization duration of (4, 7] days and illness onset to hospitalization over 6 days.

Implications of all the available evidenceWe identified multiple epidemiological profiles associated with death risk in different age ranges in Brazilian COVID-19 hospitalized patients. These findings unveil that a large part of Brazilian working-age population is at a higher risk for SARS-CoV-2 death, a neglected situation that is further exacerbating inequalities, leading to a striking sociodemographic and economic impact. We hope that our analysis aids patient risk stratification, hospital management optimization, and public policy determination, including prioritization for COVID-19 vaccination in Brazil.

C_TEXTBOX",1
"Acevedo, N.; Escamilla-Gil, J. M.; Espinoza, H.; Regino, R.; Ramirez, J.; Florez De Arco, L.; Dennis, R.; Torres-Duque, C.; Caraballo, L.",2021,Patients with Asthma and Chronic Obstructive Pulmonary Disease (COPD) have increased levels of plasma inflammatory mediators upregulated in severe COVID-19,Respiratory Medicine,Patients with Asthma and Chronic Obstructive Pulmonary Disease (COPD) have increased levels of plasma inflammatory mediators upregulated in severe COVID-19,"Acevedo, N.; Escamilla-Gil, J. M.; Espinoza, H.; Regino, R.; Ramirez, J.; Florez De Arco, L.; Dennis, R.; Torres-Duque, C.; Caraballo, L.",Respiratory Medicine,2021-03-09 00:00:00 UTC,"BackgroundChronic obstructive pulmonary disease (COPD) is associated with increased risk of severe COVID-19, but the mechanisms are unclear. Besides, patients with severe COVID-19 have been reported to have increased levels of several immune mediators.

ObjectiveTo perform an immunoproteomic profiling of dysregulated plasma proteins in patients with asthma and COPD and to evaluate their relationship with biomarkers of severe COVID-19.

MethodsNinety-two proteins were quantified in 315 plasma samples from adult subjects (age 40-90 years) including 118 asthmatics, 99 COPD patients and 98 healthy controls, that have been recruited in two reference pneumology clinics in Colombia before the beginning of the COVID-19 pandemic. Protein levels were compared between each disease group and healthy controls.

Significant proteins were compared to the gene signatures of SARS-CoV-2 infection reported in the ""COVID-19 Drug and Gene Set Library"" and with known protein biomarkers of severe COVID-19.

ResultsForty-one plasma proteins showed differences between patients and controls. Asthmatic patients have increased levels in IL-6 while COPD patients have a broader systemic inflammatory dysregulation driven by HGF, OPG, and several chemokines (CXCL9, CXCL10, CXCL11, CX3CL1, CXCL1, MCP-3, MCP-4, CCL3, CCL4 and CCL11). These proteins are involved in chemokine signaling pathways related with response to viral infections and some, were found up-regulated upon SARS-CoV-2 experimental infection of Calu-3 cells as reported in the COVID-19 Related Gene Sets database. An increase of HPG, CXCL9, CXCL10, IL-6, MCP-3, TNF and EN-RAGE has also been found in patients with severe COVID-19.

ConclusionsCOPD patients have altered levels of plasma proteins that have been reported increased in patients with severe COVID-19. Our study suggests that COPD patients have a systemic dysregulation in chemokine networks (including HGF and CXCL9) that could make them more susceptible to severe COVID-19. Our study also suggest that IL-6 levels are increased in some asthmatics and this may influence their immune response to COVID-19.",10.1101/2021.01.23.21250370,virology-transformer.xlsx,"Patients with Asthma and Chronic Obstructive Pulmonary Disease (COPD) have increased levels of plasma inflammatory mediators upregulated in severe COVID-19 BackgroundChronic obstructive pulmonary disease (COPD) is associated with increased risk of severe COVID-19, but the mechanisms are unclear. Besides, patients with severe COVID-19 have been reported to have increased levels of several immune mediators.

ObjectiveTo perform an immunoproteomic profiling of dysregulated plasma proteins in patients with asthma and COPD and to evaluate their relationship with biomarkers of severe COVID-19.

MethodsNinety-two proteins were quantified in 315 plasma samples from adult subjects (age 40-90 years) including 118 asthmatics, 99 COPD patients and 98 healthy controls, that have been recruited in two reference pneumology clinics in Colombia before the beginning of the COVID-19 pandemic. Protein levels were compared between each disease group and healthy controls.

Significant proteins were compared to the gene signatures of SARS-CoV-2 infection reported in the ""COVID-19 Drug and Gene Set Library"" and with known protein biomarkers of severe COVID-19.

ResultsForty-one plasma proteins showed differences between patients and controls. Asthmatic patients have increased levels in IL-6 while COPD patients have a broader systemic inflammatory dysregulation driven by HGF, OPG, and several chemokines (CXCL9, CXCL10, CXCL11, CX3CL1, CXCL1, MCP-3, MCP-4, CCL3, CCL4 and CCL11). These proteins are involved in chemokine signaling pathways related with response to viral infections and some, were found up-regulated upon SARS-CoV-2 experimental infection of Calu-3 cells as reported in the COVID-19 Related Gene Sets database. An increase of HPG, CXCL9, CXCL10, IL-6, MCP-3, TNF and EN-RAGE has also been found in patients with severe COVID-19.

ConclusionsCOPD patients have altered levels of plasma proteins that have been reported increased in patients with severe COVID-19. Our study suggests that COPD patients have a systemic dysregulation in chemokine networks (including HGF and CXCL9) that could make them more susceptible to severe COVID-19. Our study also suggest that IL-6 levels are increased in some asthmatics and this may influence their immune response to COVID-19.",1
"Zhang, Y.-H.; Hoopmann, M.; Castaldi, P.; Simonsen, K.; Midha, M.; Cho, M.; Criner, G.; Bueno, R.; Liu, J.; Moritz, R.; Silverman, E.",2021,Lung proteomic biomarkers associated with chronic obstructive pulmonary disease,Respiratory Medicine,Lung proteomic biomarkers associated with chronic obstructive pulmonary disease,"Zhang, Y.-H.; Hoopmann, M.; Castaldi, P.; Simonsen, K.; Midha, M.; Cho, M.; Criner, G.; Bueno, R.; Liu, J.; Moritz, R.; Silverman, E.",Respiratory Medicine,2021-04-10 00:00:00 UTC,"BackgroundIdentifying protein biomarkers for chronic obstructive pulmonary disease (COPD) has been challenging. Most previous studies have utilized individual proteins or pre-selected protein panels measured in blood samples. Mass spectrometry proteomic studies of lung tissue have been based on small sample sizes.

MethodsWe utilized mass spectrometry proteomic approaches to discover protein biomarkers from 150 lung tissue samples representing COPD cases and controls. Top COPD-associated proteins were identified based on multiple linear regression analysis with false discovery rate (FDR) < 0.05. Correlations between pairs of COPD-associated proteins were examined. Machine learning models were also evaluated to identify potential combinations of protein biomarkers related to COPD.

ResultsWe identified 4407 proteins passing quality controls. Twenty-five proteins were significantly associated with COPD at FDR < 0.05, including Interleukin 33, Ferritin (light chain and heavy chain), and two proteins related to caveolae (CAV1 and CAVIN1). Multiple previously reported plasma protein biomarkers for COPD were not significantly associated with proteomic analysis of COPD in lung tissue, although RAGE was borderline significant. Eleven pairs of top significant proteins were highly correlated (r > 0.8), including several strongly correlated with RAGE (EHD2 and CAVIN1). Machine learning models using Random Forests with the top 5% of protein biomarkers demonstrated reasonable accuracy (0.766) and AUC (0.702) for COPD prediction.

ConclusionsMass spectrometry proteomic analysis of lung tissue is a promising approach for the identification of biomarkers for COPD.",10.1101/2021.04.07.21255030,virology-transformer.xlsx,"Lung proteomic biomarkers associated with chronic obstructive pulmonary disease BackgroundIdentifying protein biomarkers for chronic obstructive pulmonary disease (COPD) has been challenging. Most previous studies have utilized individual proteins or pre-selected protein panels measured in blood samples. Mass spectrometry proteomic studies of lung tissue have been based on small sample sizes.

MethodsWe utilized mass spectrometry proteomic approaches to discover protein biomarkers from 150 lung tissue samples representing COPD cases and controls. Top COPD-associated proteins were identified based on multiple linear regression analysis with false discovery rate (FDR) < 0.05. Correlations between pairs of COPD-associated proteins were examined. Machine learning models were also evaluated to identify potential combinations of protein biomarkers related to COPD.

ResultsWe identified 4407 proteins passing quality controls. Twenty-five proteins were significantly associated with COPD at FDR < 0.05, including Interleukin 33, Ferritin (light chain and heavy chain), and two proteins related to caveolae (CAV1 and CAVIN1). Multiple previously reported plasma protein biomarkers for COPD were not significantly associated with proteomic analysis of COPD in lung tissue, although RAGE was borderline significant. Eleven pairs of top significant proteins were highly correlated (r > 0.8), including several strongly correlated with RAGE (EHD2 and CAVIN1). Machine learning models using Random Forests with the top 5% of protein biomarkers demonstrated reasonable accuracy (0.766) and AUC (0.702) for COPD prediction.

ConclusionsMass spectrometry proteomic analysis of lung tissue is a promising approach for the identification of biomarkers for COPD.",0
"Herr, C.; Mang, S.; Mozafari, B.; Guenther, K.; Speer, T.; Seibert, M.; Srikakulam, S. K.; Beisswenger, C.; Ritzmann, F.; Keller, A.; Mueller, R.; Smola, S.; Eisinger, D.; Zemlin, M.; Danziger, G.; Volk, T.; Hoersch, S.; Krawczyk, M.; Lammert, F.; Adams, T.; Wagenpfeil, G.; Kindermann, M.; Marcu, C.; Ataya, Z. W. D.; Mittag, M.; Schwarzkopf, K.; Custodis, F.; Grandt, D.; Schaefer, H.; Eltges, K.; Lepper, P.; Bals, R.",2021,Distinct patterns of blood cytokines beyond a cytokine storm predict mortality in COVID-19,Respiratory Medicine,Distinct patterns of blood cytokines beyond a cytokine storm predict mortality in COVID-19,"Herr, C.; Mang, S.; Mozafari, B.; Guenther, K.; Speer, T.; Seibert, M.; Srikakulam, S. K.; Beisswenger, C.; Ritzmann, F.; Keller, A.; Mueller, R.; Smola, S.; Eisinger, D.; Zemlin, M.; Danziger, G.; Volk, T.; Hoersch, S.; Krawczyk, M.; Lammert, F.; Adams, T.; Wagenpfeil, G.; Kindermann, M.; Marcu, C.; Ataya, Z. W. D.; Mittag, M.; Schwarzkopf, K.; Custodis, F.; Grandt, D.; Schaefer, H.; Eltges, K.; Lepper, P.; Bals, R.",Respiratory Medicine,2021-05-04 00:00:00 UTC,"BackgroundCOVID-19 comprises several severity stages ranging from oligosymptomatic disease to multi-organ failure and fatal outcomes. The mechanisms why COVID-19 is a mild disease in some patients and progresses to a severe multi-organ and often fatal disease with respiratory failure are not known. Biomarkers that predict the course of disease are urgently needed. The aim of this study was to evaluate a large spectrum of established laboratory measurements.

Patients and methodsPatients from the prospective PULMPOHOM and CORSAAR studies were recruited and comprised 35 patients with COVID-19, 23 with conventional pneumonia, and 28 control patients undergoing elective non-pulmonary surgery. Venous blood was used to measure the serum concentrations of 79 proteins by Luminex multiplex immunoassay technology. Distribution of biomarkers between groups and association with disease severity and outcomes were analyzed.

FindingsThe biomarker profiles between the three groups differed significantly with elevation of specific proteins specific for the respective conditions. Several biomarkers correlated significantly with disease severity and death. Uniform manifold approximation and projection (UMAP) analysis revealed a significant separation of the three disease groups and separated between survivors and deceased patients. Different models were developed to predict mortality based on the baseline measurements of several protein markers.

InterpretationSeveral newly identified blood markers were increased in patients with severe COVID-19 (AAT, EN-RAGE, ICAM-1, myoglobin, SAP, TIMP-1, vWF, decorin, HGF, MMP7, PECAM-1) or in patients that died (FRTN, SCF, TIMP-1, CA-9, CEA, decorin, HGF). The use of established assay technologies allows for rapid translation into clinical practice.

FundingNo role of the funding source.",10.1101/2021.05.04.21256497,virology-transformer.xlsx,"Distinct patterns of blood cytokines beyond a cytokine storm predict mortality in COVID-19 BackgroundCOVID-19 comprises several severity stages ranging from oligosymptomatic disease to multi-organ failure and fatal outcomes. The mechanisms why COVID-19 is a mild disease in some patients and progresses to a severe multi-organ and often fatal disease with respiratory failure are not known. Biomarkers that predict the course of disease are urgently needed. The aim of this study was to evaluate a large spectrum of established laboratory measurements.

Patients and methodsPatients from the prospective PULMPOHOM and CORSAAR studies were recruited and comprised 35 patients with COVID-19, 23 with conventional pneumonia, and 28 control patients undergoing elective non-pulmonary surgery. Venous blood was used to measure the serum concentrations of 79 proteins by Luminex multiplex immunoassay technology. Distribution of biomarkers between groups and association with disease severity and outcomes were analyzed.

FindingsThe biomarker profiles between the three groups differed significantly with elevation of specific proteins specific for the respective conditions. Several biomarkers correlated significantly with disease severity and death. Uniform manifold approximation and projection (UMAP) analysis revealed a significant separation of the three disease groups and separated between survivors and deceased patients. Different models were developed to predict mortality based on the baseline measurements of several protein markers.

InterpretationSeveral newly identified blood markers were increased in patients with severe COVID-19 (AAT, EN-RAGE, ICAM-1, myoglobin, SAP, TIMP-1, vWF, decorin, HGF, MMP7, PECAM-1) or in patients that died (FRTN, SCF, TIMP-1, CA-9, CEA, decorin, HGF). The use of established assay technologies allows for rapid translation into clinical practice.

FundingNo role of the funding source.",1
"Trares, K.; Bhardwaj, M.; Perna, L.; Stocker, H.; Petrera, A.; Hauck, S. M.; Beyreuther, K.; Brenner, H.; Schoettker, B.",2021,"Association of the inflammation-related proteome with dementia development at older age: results from a large, prospective, population-based cohort study",Epidemiology,"Association of the inflammation-related proteome with dementia development at older age: results from a large, prospective, population-based cohort study","Trares, K.; Bhardwaj, M.; Perna, L.; Stocker, H.; Petrera, A.; Hauck, S. M.; Beyreuther, K.; Brenner, H.; Schoettker, B.",Epidemiology,2021-06-22 00:00:00 UTC,"ImportanceChronic inflammation is increasingly recognized as a central feature of several forms of dementia.

ObjectiveTo determine which biomarkers of the inflammation-related proteome are associated with all-cause dementia, Alzheimers disease (AD), or vascular dementia (VD).

DesignAnalyses were performed in a case-cohort study design based on an ongoing German population-based cohort study.

SettingSerum samples of study participants were collected at baseline (2000-20002), and participants were followed up for 17 years. Information about a dementia diagnosis was collected during follow-up via collection of medical records from general practitioners.

ParticipantsAscertainment of potential dementia development during follow-ups was conducted for 6,284 study participants aged 50-75 years at baseline. Biomarker measurements were performed in a randomly collected sample of 1,435 participants and all incident dementia cases of the rest of the cohort (n=393).

Main Outcomes and MeasuresAll-cause dementia, AD and VD were the primary outcomes of this analysis.

ResultsBiomarkers were analyzed in 504 all-cause dementia cases (mean age, 67.0 [SD, 5.1] years; 262 female [52.0%], and 242 male [48.0%]) and 1,278 controls (mean age, 61.9 [standard deviation (SD): 6.5] years; 703 female [55.0%], and 575 male [45.0%]). Among the dementia cases, 163 participants developed AD and 195 VD. After correction for multiple testing, 58 biomarkers were statistically significantly associated with all-cause dementia, 22 with AD, and 33 with VD incidence. All analyses were adjusted for potential confounders. Besides single biomarker associations, we identified four biomarker clusters based on the strongest and independently associated biomarkers CX3CL1, EN-RAGE, LAP TGF-beta-1 and VEGF-A. CX3CL1 (Odds ratio [95%-confidence interval] per 1 standard deviation increase: 1.41 [1.24-1.60]) and EN-RAGE (1.41 [1.25-1.60]) were associated with all-cause dementia incidence, EN-RAGE (1.51 [1.25-1.83]) and LAP TGF-beta-1 (1.46 [1.21-1.76]) with AD incidence, and VEGF-A (1.43 [1.20-1.70]) with VD incidence. All named associations were stronger among APOE {varepsilon}4 negative subjects.

Conclusion and RelevanceThis study shows for the first time that the majority of inflammation-related proteins measured in serum samples (58 of 72 tested (80.6%)) are associated with all-cause dementia incidence. Future studies should not only concentrate on single biomarkers but also the complex relationships in biomarker clusters.

Key PointsO_ST_ABSQuestionC_ST_ABSWhich biomarkers of the inflammatory proteome are risk factors for dementia?

FindingsAfter correction for multiple testing, in this large prospective cohort study (n=1,782), 58 of 72 tested (80.6%) inflammation-related proteins were associated with all-cause dementia.

Furthermore, 22 and 33 were significantly associated with Alzheimers disease and vascular dementia. Due to high inter-correlation, only four biomarkers (CX3CL1, EN-RAGE, LAP TGF-beta-1, VEGF-A) were independently associated with dementia outcomes.

MeaningThe underlying pathophysiology of dementia development might involve complex inflammatory protein clusters, and the identified biomarkers might be promising new drug targets, early diagnostic markers, or parts of prediction models.",10.1101/2021.06.15.21258913,virology-transformer.xlsx,"Association of the inflammation-related proteome with dementia development at older age: results from a large, prospective, population-based cohort study ImportanceChronic inflammation is increasingly recognized as a central feature of several forms of dementia.

ObjectiveTo determine which biomarkers of the inflammation-related proteome are associated with all-cause dementia, Alzheimers disease (AD), or vascular dementia (VD).

DesignAnalyses were performed in a case-cohort study design based on an ongoing German population-based cohort study.

SettingSerum samples of study participants were collected at baseline (2000-20002), and participants were followed up for 17 years. Information about a dementia diagnosis was collected during follow-up via collection of medical records from general practitioners.

ParticipantsAscertainment of potential dementia development during follow-ups was conducted for 6,284 study participants aged 50-75 years at baseline. Biomarker measurements were performed in a randomly collected sample of 1,435 participants and all incident dementia cases of the rest of the cohort (n=393).

Main Outcomes and MeasuresAll-cause dementia, AD and VD were the primary outcomes of this analysis.

ResultsBiomarkers were analyzed in 504 all-cause dementia cases (mean age, 67.0 [SD, 5.1] years; 262 female [52.0%], and 242 male [48.0%]) and 1,278 controls (mean age, 61.9 [standard deviation (SD): 6.5] years; 703 female [55.0%], and 575 male [45.0%]). Among the dementia cases, 163 participants developed AD and 195 VD. After correction for multiple testing, 58 biomarkers were statistically significantly associated with all-cause dementia, 22 with AD, and 33 with VD incidence. All analyses were adjusted for potential confounders. Besides single biomarker associations, we identified four biomarker clusters based on the strongest and independently associated biomarkers CX3CL1, EN-RAGE, LAP TGF-beta-1 and VEGF-A. CX3CL1 (Odds ratio [95%-confidence interval] per 1 standard deviation increase: 1.41 [1.24-1.60]) and EN-RAGE (1.41 [1.25-1.60]) were associated with all-cause dementia incidence, EN-RAGE (1.51 [1.25-1.83]) and LAP TGF-beta-1 (1.46 [1.21-1.76]) with AD incidence, and VEGF-A (1.43 [1.20-1.70]) with VD incidence. All named associations were stronger among APOE {varepsilon}4 negative subjects.

Conclusion and RelevanceThis study shows for the first time that the majority of inflammation-related proteins measured in serum samples (58 of 72 tested (80.6%)) are associated with all-cause dementia incidence. Future studies should not only concentrate on single biomarkers but also the complex relationships in biomarker clusters.

Key PointsO_ST_ABSQuestionC_ST_ABSWhich biomarkers of the inflammatory proteome are risk factors for dementia?

FindingsAfter correction for multiple testing, in this large prospective cohort study (n=1,782), 58 of 72 tested (80.6%) inflammation-related proteins were associated with all-cause dementia.

Furthermore, 22 and 33 were significantly associated with Alzheimers disease and vascular dementia. Due to high inter-correlation, only four biomarkers (CX3CL1, EN-RAGE, LAP TGF-beta-1, VEGF-A) were independently associated with dementia outcomes.

MeaningThe underlying pathophysiology of dementia development might involve complex inflammatory protein clusters, and the identified biomarkers might be promising new drug targets, early diagnostic markers, or parts of prediction models.",0
"Markevych, I.; Orlov, N. D.; Grellier, J.; Majer, K. K.; Lipowska, M.; Sitnik-Warchulska, K.; Mysak, Y.; Baumbach, C.; Wierzba-Lukaszyk, M.; Soomro, M.; Compa, M.; Izydorczyk, B.; Skotak, K.; Degorska, A.; Bratkowski, J.; Kossowski, B.; Domagalik, A.; Szwed, M.",2021,NeuroSmog: Determining the impact of air pollution on the developing brain: project protocol,Epidemiology,NeuroSmog: Determining the impact of air pollution on the developing brain: project protocol,"Markevych, I.; Orlov, N. D.; Grellier, J.; Majer, K. K.; Lipowska, M.; Sitnik-Warchulska, K.; Mysak, Y.; Baumbach, C.; Wierzba-Lukaszyk, M.; Soomro, M.; Compa, M.; Izydorczyk, B.; Skotak, K.; Degorska, A.; Bratkowski, J.; Kossowski, B.; Domagalik, A.; Szwed, M.",Epidemiology,2021-10-26 00:00:00 UTC,"BackgroundExposure to airborne particulate matter (PM) may affect neurodevelopmental outcomes in children. The mechanisms underlying these relationships are not currently known. We aim to assess whether PM affects the developing brains of schoolchildren in Poland, a European country characterized by very high levels of particulate air pollution.

MethodsBetween 2020 and 2022, 800 children aged 10 to 13 years are being recruited as participants in a case-control study. Cases (children with attention deficit hyperactivity disorder (ADHD)) are being recruited from psychology clinics. Population-based controls are being sampled from schools. The study area comprises 18 towns in southern Poland characterized by wide-ranging levels of PM. Comprehensive psychological assessments are being conducted to assess cognitive and social functioning. Cases and controls undergo MRI including T1, T2 and MP2RAGE structural imaging, task (Go/NoGo) and resting-state MRI, and diffusion-weighted imaging (DWI). Concentrations of PM are being assessed using land use regression models, which incorporate data from air monitoring networks, dispersion models, and characteristics of roads and other land cover types. The estimated concentrations will be assigned to prenatal and postnatal residential and preschool/school addresses of all study subjects. We will assess whether long-term exposure to outdoor PM affects brain function, structure, and connectivity in healthy children and those diagnosed with ADHD.

Results and DiscussionThis comprehensive study will provide novel, in-depth understanding of the neurodevelopmental effects of air pollution. f",10.1101/2021.10.22.21265366,virology-transformer.xlsx,"NeuroSmog: Determining the impact of air pollution on the developing brain: project protocol BackgroundExposure to airborne particulate matter (PM) may affect neurodevelopmental outcomes in children. The mechanisms underlying these relationships are not currently known. We aim to assess whether PM affects the developing brains of schoolchildren in Poland, a European country characterized by very high levels of particulate air pollution.

MethodsBetween 2020 and 2022, 800 children aged 10 to 13 years are being recruited as participants in a case-control study. Cases (children with attention deficit hyperactivity disorder (ADHD)) are being recruited from psychology clinics. Population-based controls are being sampled from schools. The study area comprises 18 towns in southern Poland characterized by wide-ranging levels of PM. Comprehensive psychological assessments are being conducted to assess cognitive and social functioning. Cases and controls undergo MRI including T1, T2 and MP2RAGE structural imaging, task (Go/NoGo) and resting-state MRI, and diffusion-weighted imaging (DWI). Concentrations of PM are being assessed using land use regression models, which incorporate data from air monitoring networks, dispersion models, and characteristics of roads and other land cover types. The estimated concentrations will be assigned to prenatal and postnatal residential and preschool/school addresses of all study subjects. We will assess whether long-term exposure to outdoor PM affects brain function, structure, and connectivity in healthy children and those diagnosed with ADHD.

Results and DiscussionThis comprehensive study will provide novel, in-depth understanding of the neurodevelopmental effects of air pollution. f",1
"Liou, T. G.; Argel, N.; Asfour, F.; Brown, P. S.; Chatfield, B. A.; Cox, D. R.; Daines, C. L.; Durham, D.; Francis, J. B.; Glover, B.; Helms, M.; Heynekamp, T.; Hoidal, J. R.; Jensen, J. L.; Kartsonaki, C.; Keogh, R.; Kopecky, C. M.; Lechtzin, N.; Li, Y.; Lysinger, J.; Molina, O.; Nakamura, C.; Packer, K. A.; Paine, R.; Poch, K. R.; Quittner, A. L.; Radford, P.; Redway, A. J.; Sagel, S. D.; Szczesniak, R. D.; Sprandel, S.; Taylor-Cousar, J. L.; Vroom, J. B.; Yoshikawa, R.; Clancy, J. P.; Elborn, J. S.; Olivier, K. N.; Adler, F. R.",2022,Associations of Sputum Biomarkers with Clinical Outcomes in People with Cystic Fibrosis,Respiratory Medicine,Associations of Sputum Biomarkers with Clinical Outcomes in People with Cystic Fibrosis,"Liou, T. G.; Argel, N.; Asfour, F.; Brown, P. S.; Chatfield, B. A.; Cox, D. R.; Daines, C. L.; Durham, D.; Francis, J. B.; Glover, B.; Helms, M.; Heynekamp, T.; Hoidal, J. R.; Jensen, J. L.; Kartsonaki, C.; Keogh, R.; Kopecky, C. M.; Lechtzin, N.; Li, Y.; Lysinger, J.; Molina, O.; Nakamura, C.; Packer, K. A.; Paine, R.; Poch, K. R.; Quittner, A. L.; Radford, P.; Redway, A. J.; Sagel, S. D.; Szczesniak, R. D.; Sprandel, S.; Taylor-Cousar, J. L.; Vroom, J. B.; Yoshikawa, R.; Clancy, J. P.; Elborn, J. S.; Olivier, K. N.; Adler, F. R.",Respiratory Medicine,2022-05-26 00:00:00 UTC,"BackgroundAirway inflammation promotes bronchiectasis and lung injury in cystic fibrosis (CF). Amplification of inflammation underlies pulmonary exacerbations of disease. We asked whether sputum inflammatory biomarkers provide explanatory information on pulmonary exacerbations.

Patients and MethodsWe collected sputum from randomly chosen stable adolescents and adults and prospectively observed time to next exacerbation, our primary outcome. We evaluated relationships between potential biomarkers of inflammation, clinical characteristics and outcomes and assessed clinical variables as potential confounders or mediators of explanatory models. We assessed associations between the markers and time to next exacerbation using proportional hazard models adjusting for confounders.

ResultsWe enrolled 114 patients, collected data on clinical variables [December 8, 2014 to January 16, 2016; 46% male, mean age 28 years (SD 12), mean percent predicted forced expiratory volume in 1 s (FEV1%) 70 (SD 22)] and measured 24 inflammatory markers. Half of the inflammatory markers were plausibly associated with time to next exacerbation. Age and sex were confounders while we found that FEV1% was a mediator.

Three potential biomarkers of RAGE axis inflammation were associated with time to next exacerbation while six potential neutrophil-associated biomarkers indicate associations between protease activity or reactive oxygen species with time to next exacerbation.

ConclusionPulmonary exacerbation biomarkers are part of the RAGE proinflammatory axis or reflect neutrophil activity, specifically implicating protease and oxidative stress injury. Further investigations or development of novel anti-inflammatory agents should consider RAGE axis, protease and oxidant stress antagonists.

Tweetable abstractSputum from 114 randomly chosen people with CF show RAGE axis inflammation, protease and oxidative stress injury are associated with time to next pulmonary exacerbation and may be targets for bench or factorial design interventional studies. (242 characters)",10.1101/2022.05.25.22275540,virology-transformer.xlsx,"Associations of Sputum Biomarkers with Clinical Outcomes in People with Cystic Fibrosis BackgroundAirway inflammation promotes bronchiectasis and lung injury in cystic fibrosis (CF). Amplification of inflammation underlies pulmonary exacerbations of disease. We asked whether sputum inflammatory biomarkers provide explanatory information on pulmonary exacerbations.

Patients and MethodsWe collected sputum from randomly chosen stable adolescents and adults and prospectively observed time to next exacerbation, our primary outcome. We evaluated relationships between potential biomarkers of inflammation, clinical characteristics and outcomes and assessed clinical variables as potential confounders or mediators of explanatory models. We assessed associations between the markers and time to next exacerbation using proportional hazard models adjusting for confounders.

ResultsWe enrolled 114 patients, collected data on clinical variables [December 8, 2014 to January 16, 2016; 46% male, mean age 28 years (SD 12), mean percent predicted forced expiratory volume in 1 s (FEV1%) 70 (SD 22)] and measured 24 inflammatory markers. Half of the inflammatory markers were plausibly associated with time to next exacerbation. Age and sex were confounders while we found that FEV1% was a mediator.

Three potential biomarkers of RAGE axis inflammation were associated with time to next exacerbation while six potential neutrophil-associated biomarkers indicate associations between protease activity or reactive oxygen species with time to next exacerbation.

ConclusionPulmonary exacerbation biomarkers are part of the RAGE proinflammatory axis or reflect neutrophil activity, specifically implicating protease and oxidative stress injury. Further investigations or development of novel anti-inflammatory agents should consider RAGE axis, protease and oxidant stress antagonists.

Tweetable abstractSputum from 114 randomly chosen people with CF show RAGE axis inflammation, protease and oxidative stress injury are associated with time to next pulmonary exacerbation and may be targets for bench or factorial design interventional studies. (242 characters)",0
"Gu, Q.; Meroueh, C.; Levernier, J. G.; Kroneman, T. N.; Flotte, T. J.; Hart, S. N.",2023,Using an Anomaly Detection Approach for the Segmentation of Colorectal Cancer Tumors in Whole Slide Images,Pathology,Using an Anomaly Detection Approach for the Segmentation of Colorectal Cancer Tumors in Whole Slide Images,"Gu, Q.; Meroueh, C.; Levernier, J. G.; Kroneman, T. N.; Flotte, T. J.; Hart, S. N.",Pathology,2023-07-23 00:00:00 UTC,"Colorectal cancer (CRC) is the 2nd most commonly diagnosed cancer in the United States. Genetic testing is critical in assisting in the early detection of CRC and selection of individualized treatment plans, which have shown to improve the survival rate of CRC patients. The tissue slides review (TSR), a tumor tissue macro-dissection procedure, is a required pre-analytical step to perform genetic testing. Due to the subjective nature of the process, major discrepancies in CRC diagnostics by pathologists are reported, and metrics for quality are often only qualitative. Progressive context encoder anomaly detection (P-CEAD) is an anomaly detection approach to detect tumor tissue from Whole Slide Images (WSIs), since tumor tissue is by its nature, an anomaly. P-CEAD-based CRC tumor segmentation achieves a 71% {+/-}26% sensitivity, 92% {+/-}7% specificity, and 63% {+/-}23% F1 score. The proposed approach provides an automated CRC tumor segmentation pipeline with a quantitatively reproducible quality compared with the conventional manual tumor segmentation procedure.",10.1101/2023.07.17.23292768,virology-transformer.xlsx,"Using an Anomaly Detection Approach for the Segmentation of Colorectal Cancer Tumors in Whole Slide Images Colorectal cancer (CRC) is the 2nd most commonly diagnosed cancer in the United States. Genetic testing is critical in assisting in the early detection of CRC and selection of individualized treatment plans, which have shown to improve the survival rate of CRC patients. The tissue slides review (TSR), a tumor tissue macro-dissection procedure, is a required pre-analytical step to perform genetic testing. Due to the subjective nature of the process, major discrepancies in CRC diagnostics by pathologists are reported, and metrics for quality are often only qualitative. Progressive context encoder anomaly detection (P-CEAD) is an anomaly detection approach to detect tumor tissue from Whole Slide Images (WSIs), since tumor tissue is by its nature, an anomaly. P-CEAD-based CRC tumor segmentation achieves a 71% {+/-}26% sensitivity, 92% {+/-}7% specificity, and 63% {+/-}23% F1 score. The proposed approach provides an automated CRC tumor segmentation pipeline with a quantitatively reproducible quality compared with the conventional manual tumor segmentation procedure.",0
"Hu, Y.; Sirinukunwattana, K.; Li, B.; Gaitskell, K.; Bonnaffe, W.; Wojciechowska, M.; Wood, R.; Alham, N. K.; Malacrino, S.; Woodcock, D.; Verrill, C.; Ahmed, A.; Rittscher, J.",2023,Flexible and Highly-Efficient Feature Perception for Molecular Traits Prediction via Self-interactive Deep Learning,Pathology,Flexible and Highly-Efficient Feature Perception for Molecular Traits Prediction via Self-interactive Deep Learning,"Hu, Y.; Sirinukunwattana, K.; Li, B.; Gaitskell, K.; Bonnaffe, W.; Wojciechowska, M.; Wood, R.; Alham, N. K.; Malacrino, S.; Woodcock, D.; Verrill, C.; Ahmed, A.; Rittscher, J.",Pathology,2023-08-05 00:00:00 UTC,"Predicting disease-related molecular traits from histomorphology brings great opportunities for precision medicine. Despite the rich information present in histopathological images, extracting fine-grained molecular features from standard whole slide images (WSI) is non-trivial. The task is further complicated by the lack of annotations for subtyping and contextual histomorphological features that might span multiple scales. This work proposes a novel multiple-instance learning (MIL) framework capable of WSI-based cancer morpho-molecular subtyping across scales. Our method, debuting as Inter-MIL, follows a weakly-supervised scheme. It enables the training of the patch-level encoder for WSI in a task-aware optimisation procedure, a step normally improbable in most existing MIL-based WSI analysis frameworks. We demonstrate that optimising the patch-level encoder is crucial to achieving high-quality fine-grained and tissue-level subtyping results and offers a significant improvement over task-agnostic encoders. Our approach deploys a pseudo-label propagation strategy to update the patch encoder iteratively, allowing discriminative subtype features to be learned. This mechanism also empowers extracting fine-grained attention within image tiles (the small patches), a task largely ignored in most existing weakly supervised-based frameworks. With Inter-MIL, we carried out four challenging cancer molecular subtyping tasks in the context of ovarian, colorectal, lung, and breast cancer. Extensive evaluation results show that Inter-MIL is a robust framework for cancer morpho-molecular subtyping with superior performance compared to several recently proposed methods, even in data-limited scenarios where the number of available training slides is less than 100. The iterative optimisation mechanism of Inter-MIL significantly improves the quality of the image features learned by the patch embedded and generally directs the attention map to areas that better align with experts interpretation, leading to the identification of more reliable histopathology biomarkers.",10.1101/2023.07.30.23293391,virology-transformer.xlsx,"Flexible and Highly-Efficient Feature Perception for Molecular Traits Prediction via Self-interactive Deep Learning Predicting disease-related molecular traits from histomorphology brings great opportunities for precision medicine. Despite the rich information present in histopathological images, extracting fine-grained molecular features from standard whole slide images (WSI) is non-trivial. The task is further complicated by the lack of annotations for subtyping and contextual histomorphological features that might span multiple scales. This work proposes a novel multiple-instance learning (MIL) framework capable of WSI-based cancer morpho-molecular subtyping across scales. Our method, debuting as Inter-MIL, follows a weakly-supervised scheme. It enables the training of the patch-level encoder for WSI in a task-aware optimisation procedure, a step normally improbable in most existing MIL-based WSI analysis frameworks. We demonstrate that optimising the patch-level encoder is crucial to achieving high-quality fine-grained and tissue-level subtyping results and offers a significant improvement over task-agnostic encoders. Our approach deploys a pseudo-label propagation strategy to update the patch encoder iteratively, allowing discriminative subtype features to be learned. This mechanism also empowers extracting fine-grained attention within image tiles (the small patches), a task largely ignored in most existing weakly supervised-based frameworks. With Inter-MIL, we carried out four challenging cancer molecular subtyping tasks in the context of ovarian, colorectal, lung, and breast cancer. Extensive evaluation results show that Inter-MIL is a robust framework for cancer morpho-molecular subtyping with superior performance compared to several recently proposed methods, even in data-limited scenarios where the number of available training slides is less than 100. The iterative optimisation mechanism of Inter-MIL significantly improves the quality of the image features learned by the patch embedded and generally directs the attention map to areas that better align with experts interpretation, leading to the identification of more reliable histopathology biomarkers.",0
"Mclachlan, I.; Huntley, S.; Leslie, K.; Bishop, J.; Redman, C.; Yebra, G.; Shaaban, S.; Christofidis, N.; Lycett, S.; Holden, M. T. G.; Robertson, D. L.; Smith-Palmer, A.; Hughes, J.; Nickbakhsh, S.",2023,Evaluating public health effects of risk-based travel policy for the COVID-19 epidemic in Scotland,Epidemiology,Evaluating public health effects of risk-based travel policy for the COVID-19 epidemic in Scotland,"Mclachlan, I.; Huntley, S.; Leslie, K.; Bishop, J.; Redman, C.; Yebra, G.; Shaaban, S.; Christofidis, N.; Lycett, S.; Holden, M. T. G.; Robertson, D. L.; Smith-Palmer, A.; Hughes, J.; Nickbakhsh, S.",Epidemiology,2023-08-21 00:00:00 UTC,"BackgroundDecisions to impose temporary travel measures are less common as the global epidemiology of COVID-19 evolves. Risk-based travel measures may avoid the need for a complete travel ban, however evaluations of their effects are lacking. Here we investigated the public health effects of a temporary traffic light system introduced in the United Kingdom (UK) in 2021, imposing red-amber-green (RAG) status based on risk assessment.

MethodsWe analysed data on international flight passengers arriving into Scotland, COVID-19 testing surveillance, and SARS-CoV-2 whole genome sequences to quantify effects of the traffic light system on (i) international travel frequency, (ii) travel-related SARS-CoV-2 case importations, (iii) national SARS-CoV-2 case incidence, and (iv) importation of novel SARS-CoV-2 variants.

ResultsInternational flight passengers arriving into Scotland had increased by 754% during the traffic light period. Amber list countries were the most frequently visited and ranked highly for SARS-CoV-2 importations and contribution to national case incidence. Rates of international travel and associated SARS-CoV-2 cases varied significantly across age, health board, and deprivation groups. Multivariable logistic regression revealed SARS-CoV-2 cases detections were less likely among travellers than non-travellers, although increasing from green-to-amber and amber-to-red lists. When examined according to travel destination, SARS-CoV-2 importation risks did not strictly follow RAG designations, and red lists did not prevent establishment of novel SARS-CoV-2 variants.

ConclusionsOur findings suggest that country-specific post-arrival screening undertaken in Scotland did not prohibit the public health impact of COVID-19 in Scotland. Travel rates likely contributed to patterns of high SARS-CoV-2 case importation and population impact.",10.1101/2023.08.20.23293987,virology-transformer.xlsx,"Evaluating public health effects of risk-based travel policy for the COVID-19 epidemic in Scotland BackgroundDecisions to impose temporary travel measures are less common as the global epidemiology of COVID-19 evolves. Risk-based travel measures may avoid the need for a complete travel ban, however evaluations of their effects are lacking. Here we investigated the public health effects of a temporary traffic light system introduced in the United Kingdom (UK) in 2021, imposing red-amber-green (RAG) status based on risk assessment.

MethodsWe analysed data on international flight passengers arriving into Scotland, COVID-19 testing surveillance, and SARS-CoV-2 whole genome sequences to quantify effects of the traffic light system on (i) international travel frequency, (ii) travel-related SARS-CoV-2 case importations, (iii) national SARS-CoV-2 case incidence, and (iv) importation of novel SARS-CoV-2 variants.

ResultsInternational flight passengers arriving into Scotland had increased by 754% during the traffic light period. Amber list countries were the most frequently visited and ranked highly for SARS-CoV-2 importations and contribution to national case incidence. Rates of international travel and associated SARS-CoV-2 cases varied significantly across age, health board, and deprivation groups. Multivariable logistic regression revealed SARS-CoV-2 cases detections were less likely among travellers than non-travellers, although increasing from green-to-amber and amber-to-red lists. When examined according to travel destination, SARS-CoV-2 importation risks did not strictly follow RAG designations, and red lists did not prevent establishment of novel SARS-CoV-2 variants.

ConclusionsOur findings suggest that country-specific post-arrival screening undertaken in Scotland did not prohibit the public health impact of COVID-19 in Scotland. Travel rates likely contributed to patterns of high SARS-CoV-2 case importation and population impact.",1
"Khrennikov, A.",2020,Utrametric diffusion model for spread of covid-19 in socially clustered population: Can herd immunity be approached in Sweden?,Epidemiology,Utrametric diffusion model for spread of covid-19 in socially clustered population: Can herd immunity be approached in Sweden?,"Khrennikov, A.",Epidemiology,2020-07-16 00:00:00 UTC,"We present a new mathematical model of disease spread reflecting specialties of covid-19 epidemic by elevating the role social clustering of population. The model can be used to explain slower approaching herd immunity in Sweden, than it was predicted by a variety of other mathematical models; see graphs Fig. 2. The hierarchic structure of social clusters is mathematically modeled with ultrametric spaces having treelike geometry. To simplify mathematics, we consider homogeneous trees with p-branches leaving each vertex. Such trees are endowed with algebraic structure, the p-adic number fields. We apply theory of the p-adic diffusion equation to describe coronavirus spread in hierarchically clustered population. This equation has applications to statistical physics and microbiology for modeling dynamics on energy landscapes. To move from one social cluster (valley) to another, the virus (its carrier) should cross a social barrier between them. The magnitude of a barrier depends on the number of social hierarchys levels composing this barrier. As the most appropriate for the recent situation in Sweden, we consider linearly increasing barriers. This structure matches with mild regulations in Sweden. The virus spreads rather easily inside a social cluster (say working collective), but jumps to other clusters are constrained by social barriers. This behavior matches with the covid-19 epidemic, with its cluster spreading structure. Our model differs crucially from the standard mathematical models of spread of disease, such as the SIR-model. We present socio-medical specialties of the covid-19 epidemic supporting our purely diffusional model.

O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=126 SRC=""FIGDIR/small/20154419v1_fig2.gif"" ALT=""Figure 2"">
View larger version (9K):
org.highwire.dtl.DTLVardef@1fc8a97org.highwire.dtl.DTLVardef@eef1c3org.highwire.dtl.DTLVardef@1423ed0org.highwire.dtl.DTLVardef@29f150_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOFigure 2:C_FLOATNO Asymptotic behavior of probability to become immune; increasing of herd immunity (for fixed social temperature T, the upper graphs correspond to one-step barrier growth 10 and 100 times, respectively.

C_FIG",10.1101/2020.07.15.20154419,virology-vision-transformer.xlsx,"Utrametric diffusion model for spread of covid-19 in socially clustered population: Can herd immunity be approached in Sweden? We present a new mathematical model of disease spread reflecting specialties of covid-19 epidemic by elevating the role social clustering of population. The model can be used to explain slower approaching herd immunity in Sweden, than it was predicted by a variety of other mathematical models; see graphs Fig. 2. The hierarchic structure of social clusters is mathematically modeled with ultrametric spaces having treelike geometry. To simplify mathematics, we consider homogeneous trees with p-branches leaving each vertex. Such trees are endowed with algebraic structure, the p-adic number fields. We apply theory of the p-adic diffusion equation to describe coronavirus spread in hierarchically clustered population. This equation has applications to statistical physics and microbiology for modeling dynamics on energy landscapes. To move from one social cluster (valley) to another, the virus (its carrier) should cross a social barrier between them. The magnitude of a barrier depends on the number of social hierarchys levels composing this barrier. As the most appropriate for the recent situation in Sweden, we consider linearly increasing barriers. This structure matches with mild regulations in Sweden. The virus spreads rather easily inside a social cluster (say working collective), but jumps to other clusters are constrained by social barriers. This behavior matches with the covid-19 epidemic, with its cluster spreading structure. Our model differs crucially from the standard mathematical models of spread of disease, such as the SIR-model. We present socio-medical specialties of the covid-19 epidemic supporting our purely diffusional model.

O_FIG O_LINKSMALLFIG WIDTH=200 HEIGHT=126 SRC=""FIGDIR/small/20154419v1_fig2.gif"" ALT=""Figure 2"">
View larger version (9K):
org.highwire.dtl.DTLVardef@1fc8a97org.highwire.dtl.DTLVardef@eef1c3org.highwire.dtl.DTLVardef@1423ed0org.highwire.dtl.DTLVardef@29f150_HPS_FORMAT_FIGEXP  M_FIG O_FLOATNOFigure 2:C_FLOATNO Asymptotic behavior of probability to become immune; increasing of herd immunity (for fixed social temperature T, the upper graphs correspond to one-step barrier growth 10 and 100 times, respectively.

C_FIG",1
"Ouyang, J.; Shan, X.; Wang, X.; Zhang, X.; Chen, Y.; Qi, M.; Xia, C.; Gu, D.; Chen, Y.; Zhang, B.",2020,Clinical characteristics of COVID-19 and the model for predicting the occurrence of critically ill patients: a retrospective cohort study.,Epidemiology,Clinical characteristics of COVID-19 and the model for predicting the occurrence of critically ill patients: a retrospective cohort study.,"Ouyang, J.; Shan, X.; Wang, X.; Zhang, X.; Chen, Y.; Qi, M.; Xia, C.; Gu, D.; Chen, Y.; Zhang, B.",Epidemiology,2020-08-14 00:00:00 UTC,"BackgroundThe present study aim to comprehensively report the epidemiological and clinical characteristics of the COVID-19 patients and to develop a multi-feature fusion model for predicting the critical ill probability.

MethodsIt was a retrospective cohort study that incorporating the laboratory-confirmed COVID-19 patients in the Chongqing Public Health Medical Center. The prediction model was constructed with least absolute shrinkage and selection operator (LASSO) logistic regression method and the model was further tested in the validation cohort. The performance was evaluated by the receiver operating curve (ROC), calibration curve and decision curve analysis (DCA).

ResultsA total of 217 patients were included in the study. During the treatment, 34 patients were admitted to intensive care unit (ICU) and no developed death. A model incorporating the demographic and clinical characteristics, imaging features and laboratory findings were constructed to predict the critical ill probability and it was proved to have good calibration, discrimination ability and clinic use.

ConclusionsThe prevalence of critical ill was relatively high and the model may help the clinicians to identify the patients with high risk for developing the critical ill, thus to conduct timely and targeted treatment to reduce the mortality rate.",10.1101/2020.08.13.20173799,virology-vision-transformer.xlsx,"Clinical characteristics of COVID-19 and the model for predicting the occurrence of critically ill patients: a retrospective cohort study. BackgroundThe present study aim to comprehensively report the epidemiological and clinical characteristics of the COVID-19 patients and to develop a multi-feature fusion model for predicting the critical ill probability.

MethodsIt was a retrospective cohort study that incorporating the laboratory-confirmed COVID-19 patients in the Chongqing Public Health Medical Center. The prediction model was constructed with least absolute shrinkage and selection operator (LASSO) logistic regression method and the model was further tested in the validation cohort. The performance was evaluated by the receiver operating curve (ROC), calibration curve and decision curve analysis (DCA).

ResultsA total of 217 patients were included in the study. During the treatment, 34 patients were admitted to intensive care unit (ICU) and no developed death. A model incorporating the demographic and clinical characteristics, imaging features and laboratory findings were constructed to predict the critical ill probability and it was proved to have good calibration, discrimination ability and clinic use.

ConclusionsThe prevalence of critical ill was relatively high and the model may help the clinicians to identify the patients with high risk for developing the critical ill, thus to conduct timely and targeted treatment to reduce the mortality rate.",1
"Albani, V. V. L.; Zubelli, J. P.",2023,Stochastic Transmission in Epidemiological Models,Epidemiology,Stochastic Transmission in Epidemiological Models,"Albani, V. V. L.; Zubelli, J. P.",Epidemiology,2023-01-18 00:00:00 UTC,"Recent empirical evidence suggests that the transmission coefficient in susceptible-exposed-infected-removed-like (SEIR-like) models evolves with time, presenting random patterns, and some stylized facts, such as mean-reversion and jumps. To address such observations we propose the use of jump-diffusion stochastic processes to parameterize the transmission coefficient in an SEIR-like model that accounts for death and time-dependent parameters. We provide a detailed theoretical analysis of the proposed model proving the existence and uniqueness of solutions as well as studying its asymptotic behavior. We also compare the proposed model with some variations possibly including jumps. The forecast performance of the considered models, using reported COVID-19 infections from New York City, is then tested in different scenarios, including major outbreaks. The proposed jump-diffusion model presented remarkably accurate out-of-sample predictions, even during larger forecasted periods.",10.1101/2023.01.15.23284574,virology-vision-transformer.xlsx,"Stochastic Transmission in Epidemiological Models Recent empirical evidence suggests that the transmission coefficient in susceptible-exposed-infected-removed-like (SEIR-like) models evolves with time, presenting random patterns, and some stylized facts, such as mean-reversion and jumps. To address such observations we propose the use of jump-diffusion stochastic processes to parameterize the transmission coefficient in an SEIR-like model that accounts for death and time-dependent parameters. We provide a detailed theoretical analysis of the proposed model proving the existence and uniqueness of solutions as well as studying its asymptotic behavior. We also compare the proposed model with some variations possibly including jumps. The forecast performance of the considered models, using reported COVID-19 infections from New York City, is then tested in different scenarios, including major outbreaks. The proposed jump-diffusion model presented remarkably accurate out-of-sample predictions, even during larger forecasted periods.",1
