Sl.No,Authors,Year of publication,Primary affiliation of primary author,Title of article,Name of Publication/Journal,Subdomain,Disease Name,Type of Evidence Source,Research Aim,Research Problem,AI Objective,AI Methodology,AI Method Details,AI Method Type,Is software publicly released?,Software License,Virology AI task addressed,Type of Underlying Data,Dataset Name,Was Performance Measured,How was Performance measured and What was measured?,Performance Metrics,Performance score,
1,"Ong SQ, Ahmad H, Nair G, Isawasan P, Majid AHA.",2021,"UOW Malaysia KDU Penang University College, 32, Jalan Anson, 10400, George Town, Pulau Pinang, Malaysia. songguan26@gmail.com.",Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time,Sci Rep,arboviral virology,['Dengue fever'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","The primary aim of the research is to develop a highly accessible deep learning (DL) model for classifying Aedes aegypti and Aedes albopictus mosquitoes, which are significant vectors of diseases like dengue fever. The study also aims to implement this model on hardware for real-time mosquito classification and evaluate its performance against human expert performance, with a focus on identifying mosquitoes that have age-related morphological changes, especially the loss of key features on the thorax.","Accurate classification is crucial for controlling the spread of diseases like dengue, as different mosquito species require different control strategies. Existing methods are time-consuming and not suitable for real-time field applications, highlighting the need for an automated, efficient model for mosquito identification in practical settings.","The objective of the AI in this study is to develop an automated deep learning model that can accurately classify Aedes aegypti and Aedes albopictus mosquitoes, even in cases where key morphological features are missing, in real-time, and deploy it on hardware for field use.","The methodology involves using deep convolutional neural networks (DCNNs) with transfer learning on a dataset of mosquito images, focusing on fine-tuning hyperparameters like the learning rate and number of epochs for optimal accuracy. The model is implemented through a web-based tool (Teachable Machine 2.0) for easy deployment on hardware (Aedes Detector) for real-time mosquito classification.","The study uses MobileNet, a lightweight deep convolutional neural network (DCNN), with transfer learning to classify Aedes aegypti and Aedes albopictus mosquitoes. The model leverages a pre-trained MobileNet model for feature extraction, fine-tuned on a custom dataset of 4,120 mosquito images. Key hyperparameters like learning rate (LR) and epochs are optimized for the best accuracy. The model is then deployed in real-time on hardware (Aedes Detector) using the p5.js platform for efficient, field-ready mosquito classification.",MobileNet Deep Convolutional Neural Network (DCNN) with Transfer Learning,https://www.kaggle.com/pradeepisawasan/aedes-mosquitos ,CC BY-NC-SA 4.0,"classification of mosquito species, specifically Aedes aegypti and Aedes albopictus, which are vectors of diseases like dengue fever", Mosquito Images,Ong et.al,Yes,"The performance of the mosquito classification model was assessed by focusing on the lateral view of the mosquitoes' thorax and head, which are key features for distinguishing between species. A hyperparameter analysis, adjusting factors like learning rate and epochs, was conducted to optimize the model’s accuracy. The findings were consistent with previous studies, confirming the importance of these parameters for achieving high performance in classification tasks.",{'Accuracy'},{'Accuracy': 0.98},
2,"Agarwal M, Agarwal S, Saba L, Chabert GL, Gupta S, Carriero A, Pasche A, Danna P, Mehmedovic A, Faa G, Shrivastava S, Jain K, Jain H, Jujaray T, Singh IM, Turk M, Chadha PS, Johri AM, Khanna NN, Mavrogeni S, Laird JR, Sobel DW, Miner M, Balestrieri A, Sfikakis PP, Tsoulfas G, Misra DP, Agarwal V, Kitas GD, Teji JS, Al-Maini M, Dhanjil SK, Nicolaides A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Yadav RR, Nagy F, Kincses ZT, Ruzsa Z, Naidu S, Viskovic K, Kalra MK, Suri JS.",2022,"Department of Computer Science Engineering, Bennett University, India.",Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0,Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Multicenter Study","The aim of the study is to develop and evaluate  COVLIAS 2.0, an AI system utilizing pruned deep learning models optimized with evolutionary algorithms to achieve high accuracy while drastically reducing storage requirements and processing time, making it suitable for real-time clinical applications.",improving the efficiency of deep learning models for COVID-19 lung segmentation and lesion localization in CT scans while maintaining their accuracy.,"The objective of the AI in this study is to optimize deep learning models used for COVID-19 lung segmentation and lesion localization in CT scans by reducing the number of parameters without compromising their accuracy, storage efficiency, and processing speed. The goal is to develop a pruned AI model that can perform real-time analysis with minimal computational resources, making it feasible for use in clinical settings where rapid and accurate diagnosis is essential.","This study uses pruned deep learning models to improve COVID-19 lung segmentation and lesion localization in CT scans. Two base models, Fully Convolutional Networks (FCN) and SegNet, are initially trained. Then, evolutionary algorithms like Differential Evolution (DE), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Whale Optimization (WO) are applied to prune redundant parameters, reducing model size while maintaining performance. The pruned models are evaluated on CroMed and NovMed datasets and compared with MedSeg. For lesion localization, the segmented lung regions are passed through DenseNet-121, a convolutional neural network (CNN), which classifies the regions based on the presence of lesions. To further highlight lesion areas, the Grad-CAM technique is used, producing heatmaps that emphasize the regions most affected by COVID-19. The pruned, optimized models capable of performing both lung segmentation and lesion detection are then deployed for real-time clinical application, providing a high-speed, storage-efficient solution for COVID-19 diagnosis. ","In FCN-DE, the Differential Evolution (DE) algorithm optimizes the structure of the Fully Convolutional Network (FCN) by evolving a population of candidate solutions (models) over several generations. The DE algorithm uses mutation, crossover, and selection to modify the model’s weights and structure. During the pruning phase, neurons and layers that contribute minimally to the network's performance are eliminated, reducing the model’s size and enhancing its speed. The fitness of each candidate is evaluated based on accuracy and model compression, and the best solution is selected for further evolution.",FCN-DE ['Fully Connected Network with differential evolution (DE)'],No,No,COVID-19 lung segmentation and lesion localization in CT (computed tomography) scans of COVD-19 patients,chest CT scans ,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.93, 'Jaccard Index': 0.88, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity:0.93', 'Jaccard Index:0.87', 'Correlation Coefficient:0.99'}",
,,,,,,,,,,,,,"FCN-GA uses the Genetic Algorithm to prune a Fully Convolutional Network by selecting the best-performing models from a population of candidate solutions. The algorithm optimizes the network by evolving its structure, reducing unnecessary components and ensuring high performance, leading to an efficient and compact model for lung segmentation",FCN-GA (Fully Convolutional Network with Genetic Algorithm),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.93, 'Jaccard Index': 0.87, 'Correlation Coefficient': 0.94}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.88, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,"In FCN-PSO, Particle Swarm Optimization (PSO) is used to prune the Fully Convolutional Network by treating each particle in the swarm as a potential solution (model configuration). Each particle represents a specific arrangement of the network's neurons and layers, and through iterative movements in the search space, PSO adjusts the model's structure. The particles are attracted toward the best solutions, pruning unnecessary neurons and layers to improve both model efficiency and speed while maintaining accuracy. The optimization objective is to maximize segmentation performance while minimizing model size.",FCN-PSO (Fully Convolutional Network with Particle Swarm Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.92, 'Jaccard Index': 0.86, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.91, 'Jaccard Index': 0.84, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,"In FCN-WO, Whale Optimization (WO) algorithm is used to prune the Fully Convolutional Network by simulating the behavior of humpback whales hunting prey. The WO algorithm adjusts the architecture of the FCN by iteratively exploring and exploiting possible network configurations. It uses a spiral search pattern to remove redundant layers and neurons, with the best solution being selected based on accuracy and compression. The algorithm ensures that while pruning, the network maintains high segmentation performance and is optimized for speed and storage efficiency.",FCN-WO (Fully Convolutional Network with Whale Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"In SegNet-DE, the Differential Evolution algorithm is used to optimize the SegNet architecture. The DE algorithm evolves the SegNet model by generating a population of solutions and applying mutation, crossover, and selection to refine the network. Each candidate model undergoes pruning by removing unnecessary neurons and layers, with the fitness of each model evaluated based on segmentation accuracy and storage efficiency. The DE algorithm helps reduce the network's size while ensuring that the performance is not compromised.",SegNet-DE (SegNet with Differential Evolution),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}"," {'Dice Similarity': 0.96, 'Jaccard Index': 0.92, 'Correlation Coefficient': 0.97}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"In SegNet-GA, the Genetic Algorithm (GA) prunes the SegNet architecture by evolving a population of models over several generations. The GA uses genetic operations such as selection, crossover, and mutation to modify the structure of the SegNet network. By iteratively removing unnecessary neurons and layers, the GA optimizes the model's size and performance. The fitness of each model is determined by its segmentation accuracy and the reduced size, with the most efficient solution being selected for further evaluation.",SegNet-GA (SegNet with Genetic Algorithm),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.96, 'Jaccard Index': 0.93, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.94, 'Jaccard Index': 0.89, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,"In SegNet-PSO, Particle Swarm Optimization (PSO) is employed to prune the SegNet model by optimizing its architecture. PSO treats each particle as a potential solution, adjusting the network’s layers and neurons through iterative movements based on the fitness of the solutions. The swarm collectively searches for the optimal model configuration, pruning unnecessary components to reduce the model size while retaining segmentation accuracy. The process continues until an efficient and high-performing model is found.",SegNet-PSO (SegNet with Particle Swarm Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.96, 'Jaccard Index': 0.94, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.95, 'Jaccard Index': 0.91, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"In SegNet-WO, Whale Optimization (WO) is applied to prune the SegNet architecture. WO simulates the foraging behavior of humpback whales to explore different configurations of the SegNet model. By removing unnecessary neurons and layers, the algorithm optimizes the SegNet network’s size and performance. The optimization process ensures that the SegNet model is both storage-efficient and fast while preserving its accuracy in segmentation tasks.",SegNet-WO (SegNet with Whale Optimization),,,,,CroMed data set,Yes,"The performance of the pruned models on the CroMed dataset was evaluated using several metrics to assess the accuracy of lung segmentation and lesion detection. The primary metrics included Dice Similarity to measure the overlap between the predicted and ground truth lung regions, Jaccard Index for assessing the similarity between the predicted and actual lung areas, and Correlation Coefficient to evaluate the linear correlation between predicted and true segmentation. These metrics were computed based on the predicted lung segmentations and compared against the manually annotated ground truth data provided by radiologists.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.96, 'Jaccard Index': 0.94, 'Correlation Coefficient': 0.98}",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,"The models were further evaluated on the Unseen NovMed dataset to test their generalization to new, external data. The same performance metrics Dice Similarity, Jaccard Index, Correlation Coefficient were used to evaluate the lung segmentation results on this dataset. These metrics allowed for the measurement of how well the pruned models, trained on CroMed data, performed on a different dataset with distinct CT scan characteristics. The AUC and Dice Similarity values showed strong performance, confirming that the models were capable of accurately segmenting lung regions even on data they had never seen before, thus demonstrating their robustness and clinical applicability.","{ 'Dice Similarity', 'Jaccard Index', 'Correlation Coefficient'}","{'Dice Similarity': 0.95, 'Jaccard Index': 0.91, 'Correlation Coefficient': 0.99}",
,,,,,,,,,,,,,"Lesion detection in this study is performed using DenseNet-121 and Grad-CAM. DenseNet-121 is a deep convolutional neural network that classifies segmented lung regions into ""COVID-19"" or ""Control."" After lung segmentation, the segmented regions are passed through DenseNet-121, which identifies the presence of lesions. Grad-CAM is then applied to generate heatmaps that highlight the regions in the CT scan most responsible for the model’s decision, emphasizing areas with lesions. This combination helps accurately localize and visualize COVID-19-related lesions in the lungs, aiding in clinical diagnosis.",Lesion Detection using DenseNet-121 and Grad-CAM,,,,,CroMed data set,Yes,"the performance metrics in the traditional sense (such as Dice and Jaccard) are not provided, and it is likely that the focus was more on the qualitative evaluation of the generated heatmaps rather than quantitative performance metrics.","The qualitative performance of lesion detection was assessed using Grad-CAM generated heatmaps with the DenseNet-121 model. These heatmaps visually highlighted COVID-19 lesions, such as ground-glass opacities, by overlaying them on the segmented lung regions in CT scans. This approach helped identify the affected areas, aiding clinical decision-making and improving the interpretability of the AI model's predictions.","The qualitative performance of lesion detection was assessed using Grad-CAM generated heatmaps with the DenseNet-121 model. These heatmaps visually highlighted COVID-19 lesions, such as ground-glass opacities, by overlaying them on the segmented lung regions in CT scans. This approach helped identify the affected areas, aiding clinical decision-making and improving the interpretability of the AI model's predictions.",
,,,,,,,,,,,,,,,,,,,NovMed data set,Yes,,,,
3,"Gidde PS, Prasad SS, Singh AP, Bhatheja N, Prakash S, Singh P, Saboo A, Takhar R, Gupta S, Saurav S, M V R, Singh A, Sardana V, Mahajan H, Kalyanpur A, Mandal AS, Mahajan V, Agrawal A, Agrawal A, Venugopal VK, Singh S, Dash D.",2021,"CSIR-Central Electronics Engineering Research Institute, Pilani, Rajasthan, 333031, India.",Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays,Sci Rep,Respiratory Virology,['COVID-Pneumonia'],"Journal Article, Research Support, Non-U.S. Gov't, Validation Study","The primary aim of this research is to develop CovBaseAI, an explainable tool for diagnosing COVID-Pneumonia from Chest X-rays (CxR) using an ensemble of deep learning (DL) models and an expert decision system (EDS).","This research seeks to address the challenge of diagnosing COVID-19 pneumonia from Chest X-rays using AI models trained on pre-COVID datasets, with a focus on ensuring explainability and generalizability across varied clinical environments.To develop an AI tool capable of accurately diagnosing COVID-19 pneumonia from Chest X-rays, even when trained on pre-COVID datasets.","To develop AI system for the detection of COVID-19 pneumonia from Chest X-rays. The system uses an ensemble of three deep learning models (lung segmentation, opacity detection, and pathology detection) along with an expert decision system to accurately classify COVID-19 likelihood. The system's objective is to achieve high performance, particularly in real-time screening and triaging scenarios, minimizing false negatives and false positives.","The AI methodology in this study involves the development of CovBaseAI, an explainable tool for diagnosing COVID-19 pneumonia from Chest X-rays. It combines three deep learning modules: a lung segmentation module using modified U-Net, a lung opacity detection module based on Faster R-CNN, and a pathology detection module using DenseNet-201. These modules independently analyze the CxR images, with outputs fed into an Expert Decision System (EDS) to classify the likelihood of COVID-19 pneumonia. The model was validated on two independent datasets and evaluated using various metrics, including sensitivity, specificity, accuracy, and AUC. The combination of deep learning and expert rules ensures both performance and explainability.","The AI method employed in this study consists of three main deep learning modules combined with a rule-based expert decision system. First, for lung segmentation, a modified U-Net architecture is used, where the encoder part is replaced with a VGG16 network pre-trained on ImageNet to speed up convergence and prevent overfitting. The U-Net model processes the chest X-ray images to produce binary lung masks. Second, for lung opacity detection, a Faster R-CNN architecture is applied. Faster R-CNN is a two-stage object detection method where the first stage generates region proposals, and the second stage classifies these proposals. It uses a VGG16 network as the backbone for feature extraction and is trained to detect opacity regions within the lung images. Third, for pathology detection, a DenseNet-201 model is utilized. DenseNet-201 is a convolutional neural network with dense connections between layers, which allows for better feature reuse and more accurate classification. The pathology detection module outputs probabilities for each pathology, including signs of pneumonia, which is integrated into the expert decision system. Finally, the rule-based expert decision system (EDS) classifies the X-ray image into three categories: COVID-likely, indeterminate, or COVID-unlikely, based on the outputs from the deep learning models. The EDS is fully explainable and modifiable, using rules derived from radiologists’ consensus to aid in accurate and interpretable diagnosis.",[' CovBaseAI - ensemble model combining deep learning techniques'],No,No,COVID-19 pneumonia detection,Chest X-Ray,IITAC1.4K,Yes,"The model's performance was assessed by comparing its predictions against radiologist annotations for COVID likelihood using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}","{""Sensitivity"": 0.90, ""Specificity"": 0.86, ""PPV"": 0.41, ""NPV"": 0.98, ""F1 Score"": 0.57, ""Accuracy"": 0.87, ""MCC"": 0.56, ""AUC"": 0.88}",
,,,,,,,,,,,,,,,,,,,PD1K,Yes,"Prediction output of the CovBaseAI model was compared against pneumonia consolidation label annotated by radiologists instead of their RT-PCR status using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}"," {""Sensitivity"": 0.84, ""Specificity"": 0.81, ""PPV"": 0.83, ""NPV"": 0.81, ""F1 Score"": 0.84, ""Accuracy"": 0.82, ""MCC"": 0.65, ""AUC"": 0.89}",
,,,,,,,,,,,,,,,,,,,CID1K,Yes,The model's predictions were compared against RT-PCR results to assess its diagnostic accuracy in distinguishing COVID-19 infection from other conditions.,"{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}"," {""Sensitivity"": 0.66, ""Specificity"": 0.57, ""PPV"": 0.59, ""NPV"": 0.64, ""F1 Score"": 0.62, ""Accuracy"": 0.61, ""MCC"": 0.23, ""AUC"": 0.63}",
,,,,,,,,,,,,,,,,,,,CPD600,Yes,"The model’s ability to identify COVID pneumonia was evaluated by comparing its outputs against the combined RT-PCR and radiologist diagnoses using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}","{""Sensitivity"": 0.83, ""Specificity"": 0.77, ""PPV"": 0.79, ""NPV"": 0.81, ""F1 Score"": 0.81, ""Accuracy"": 0.80, ""MCC"": 0.60, ""AUC"": 0.83}",
,,,,,,,,,,,,,,,,,,,COVIDx1K,Yes,"The model's generalization performance across different geographical regions and datasets was evaluated. The COVIDx1K dataset provided an independent validation set to assess how CovBaseAI would perform on data that it had never seen before, thus testing its robustness and adaptability to new environments using metrics such as sensitivity, specificity, accuracy, F1 score, accuracy, NPV, PPV and Matthews correlation coefficient (MCC)","{""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""F1 Score"", ""Accuracy"", ""MCC"", ""AUC""}","{""Sensitivity"": 0.78, ""Specificity"": 0.97, ""PPV"": 0.79, ""NPV"": 0.97, ""F1 Score"": 0.78, ""Accuracy"": 0.95, ""MCC"": 0.76, ""AUC"": 0.89}",
4,"Soe NN, Yu Z, Latt PM, Lee D, Samra RS, Ge Z, Rahman R, Sun J, Ong JJ, Fairley CK, Zhang L.",2024,"Artificial Intelligence and Modelling in Epidemiology Program, Melbourne Sexual Health Centre, Alfred Health, Melbourne, Australia.",Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study,J Med Internet Res,Emerging & Re-emerging Viruses,['Monkeypox'],"Journal Article, Validation Study",Develop and evaluate an artificial intelligence (AI) based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic,"Given the overlap in appearance between mpox and other sexually transmitted infections (STIs) or skin conditions, there is a need for an automated, AI-driven solution that can reliably differentiate mpox lesions from other skin pathologies.","The objective of the AI in this study is to develop an automated deep learning model for accurately differentiating mpox lesions from other common skin lesions (STIs and non-STIs) based on lesion images. This system should help in early diagnosis, optimize clinic workflows, and assist healthcare professionals in triaging suspected mpox cases in a sexual health clinic setting.","The methodology employed in this study to develop an AI-based tool for differentiating mpox lesions from other skin lesions in a sexual health clinic involved multiple stages. Initially, a dataset of 2200 images, comprising both mpox and non-mpox lesions, was collected from the Melbourne Sexual Health Centre (MSHC) and web resources. These images were carefully labeled by two experienced sexual health physicians to ensure accurate diagnosis. The dataset was then partitioned into training, testing, and external validation subsets. A transfer learning approach was applied using six different pre-trained deep learning architectures, including MobileNet-V2, ShuffleNet-V2, DenseNet-121, ResNet-18, ResNet-34, and Swin-Transformer. To address class imbalance, data augmentation techniques were applied to the training and validation dataset, increasing the number of mpox images. A 5-fold cross-validation was implemented to improve the robustness and generalizability of the models. The overall AI methodology combined the strengths of deep learning models with preprocessing techniques to accurately classify mpox lesions, demonstrating significant improvements in diagnostic accuracy for sexual health clinic settings.","The study used Deep Learning (DL) techniques for classifying mpox and non-mpox lesions from skin images, focusing on the application of Transfer Learning. In this method, pre-trained deep neural networks (DNNs) were fine-tuned on the mpox dataset. The six models selected for the study included MobileNet-V2, ShuffleNet-V2, DenseNet-121, ResNet-18, ResNet-34, and Swin-Transformer. These models were chosen due to their varying parameter sizes, allowing for comparison across different architectures in terms of performance. During training, the models were optimized using the Adam optimizer and trained with a cross-entropy loss function. A batch size of 72 was used, with a dropout rate of 0.2, and training was carried out for 150 epochs. The training utilized a 5-fold cross-validation strategy to ensure robust evaluation and to reduce overfitting by validating the models on different subsets of the training data.  This helps to reduce the model's bias and ensures it generalizes well to unseen data.Additionally, during Transfer Learning, the weights of the backbone layers of the pre-trained models were frozen. Freezing the weights means that the weights in the initial layers, which capture general features like edges and textures, were not updated during training. Instead, only the final classification layers (which are specific to the mpox vs. non-mpox task) were fine-tuned. This approach helps to retain the general knowledge acquired during pre-training and focuses learning on the task-specific layers.",['Deep learning - Convolutional Neural Networks architectures'],https://github.com/pytorch/vision/tree/main/torchvision/models,BSD 3-Clause License,differentiation of mpox lesions from other common skin lesions using AI-based image recognition,Clinical Images,Monkeypox dataset,Yes,"The trained models were evaluated using various performance metrics, including AUC (Area Under the Curve), accuracy, precision, recall, and F1-score. These metrics helped assess how well the model could distinguish mpox lesions from other lesions. The model’s generalizability was tested by evaluating its performance on an external validation dataset (mpox images sourced from Kaggle). This dataset had not been seen during training and provided insights into how well the model could adapt to new, unseen data.","{'AUC', 'accuracy', ' precision', 'recall', 'F1-score'}","{""ResNet-18"": {""AUC"": 0.990, ""Accuracy"": 0.947, ""Precision"": 0.934, ""Recall"": 0.953, ""F1-score"": 0.943}, 
               ""DenseNet-121"": {""AUC"": 0.982, ""Accuracy"": 0.926, ""Precision"": 0.906, ""Recall"": 0.939, ""F1-score"": 0.922}, 
               ""MobileNet-V2"": {""AUC"": 0.985, ""Accuracy"": 0.937, ""Precision"": 0.911, ""Recall"": 0.959, ""F1-score"": 0.934}, 
               ""ShuffleNet-V2"": {""AUC"": 0.963, ""Accuracy"": 0.923, ""Precision"": 0.925, ""Recall"": 0.910, ""F1-score"": 0.917}, 
               ""ResNet-34"": {""AUC"": 0.974, ""Accuracy"": 0.908, ""Precision"": 0.887, ""Recall"": 0.920, ""F1-score"": 0.903}, 
               ""Swin-Transformer"": {""AUC"": 0.979, ""Accuracy"": 0.912, ""Precision"": 0.944, ""Recall"": 0.862, ""F1-score"": 0.901}}",
5,"Saleem F, Al-Ghamdi ASA, Alassafi MO, AlGhamdi SA.",2022,"Department of Information System, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah 21589, Saudi Arabia.","Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review",Int J Environ Res Public Health,Respiratory Virology,"[""SARS-CoV-2""]","Journal Article, Review, Systematic Review, Research Support, Non-U.S. Gov't","This research provides a systematic literature review and analysis of ML, DL, and mathematical models for different purposes such as predicting future cases, analyzing previous infected cases, estimating basic reproduction numbers and virus doubling time.","This research seeks to address the gaps in understanding the comparative performance, generalizability, and limitations of existing ML and DL techniques used in COVID-19 forecasting, detection, and epidemiological analysis.",To systematically review the application of Machine Learning (ML) and Deep Learning (DL) techniques to analyze COVID-19 data and predict its impact. ,"The AI methodology followed in this study is a Systematic Literature Review (SLR) approach. The methodology involves identifying, analyzing, and synthesizing existing research studies that used ML and DL techniques to tackle various aspects of COVID-19. These techniques include predictive models for infection rates, the automatic detection of COVID-19 cases from medical images, and the application of mathematical models for understanding epidemic dynamics. The process follows PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to ensure a comprehensive and systematic collection of relevant papers. The review examines multiple AI techniques, including support vector machines (SVM) for classification, convolutional neural networks (CNN) for medical image analysis, and long short-term memory (LSTM) networks for time-series forecasting. The studies also assess various mathematical models, such as SIR (Susceptible, Infected, Recovered), SEIR, and ARIMA, that help estimate important epidemiological parameters.","In the review paper, Deep Learning (DL) methods are extensively used for automating COVID-19 detection, classification, and forecasting. Convolutional Neural Networks (CNNs) are the most widely applied DL models for medical image classification, especially in detecting COVID-19 from chest X-rays (CXR) and CT scans. CNNs, including models like ResNet-101 and Xception, excel in automatically extracting relevant features from medical images, achieving high accuracy levels, often exceeding 99%, when used with transfer learning. Additionally, Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), are employed for time-series forecasting to predict the spread of COVID-19 cases, often combined with models like ARIMA for improved long-term predictions. ",['Deep Learning'],No,No,"summary of ML and DL techniques for prediction, detection, and treatment of COVID-19 "," research papers related to the epidemiology of COVID-19,  machine learning (ML), deep learning (DL) approaches, and mathematical models for forecasting, detection, and analysis of COVID-19 cases.",Saleem et.al,No,The review paper provided an overview of how the performance of these models was evaluated across different studies.,,,
6,"Klein AZ, Magge A, O'Connor KMS, Cai H, Weissenbacher D, Gonzalez-Hernandez G.",2020,"Department of Biostatistics, Epidemiology, and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA.",A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter,medRxiv,Respiratory Virology,['COVID-19'],"Preprint, Journal Article","Develop and evaluate a social media mining framework using natural language processing (NLP) and machine learning to automatically detect personal reports related to COVID-19 on Twitter, and analyze their chronological and geographical distribution in the United States","There is a lack of real-time, individual-level surveillance data, which hampers early detection and response. Although social media platforms like Twitter are widely used and contain user-generated content related to COVID-19, previous efforts had not utilized this data to track personal-level reports of exposure or symptoms in real time.","To design and evaluate a natural language processing and machine learning framework, specifically using a fine-tuned BERT classifier, to automatically detect and classify tweets that report probable or possible exposure to COVID-19, and to use these classifications for real-time spatio-temporal surveillance of the outbreak.
","1. Over 7 million English tweets were collected from the Twitter Streaming API (Jan–Mar 2020) using COVID-19-related keywords. After filtering, 10,000 tweets were manually annotated into three classes:
Probable: User or household member is diagnosed, tested, symptomatic, or directly exposed.
Possible: User or household member shows less-common symptoms or has high-risk exposure (e.g., travel).
Other: General COVID-19 discussion with no personal exposure.
2. A pre-trained BERT model was fine-tuned on the annotated tweets (80/20 train-test split). Preprocessing included lowercasing text, replacing usernames and URLs. The model was trained using the Adam optimizer with learning rate warm-up and decay. It was then deployed on 430,000+ unlabeled tweets to classify them as “probable,” “possible,” or “other.”
3.The classified tweets were analyzed by date and location to detect early trends in potential COVID-19 spread, even before official case reports were available in some regions.","1. A pre-trained BERT model was used with:
12 Transformer blocks
768 hidden units per layer
12 self-attention heads
Tweets were tokenized to a maximum length of 100 tokens, and the output was passed through a dropout layer (rate = 0.1) and a dense layer with softmax activation for classification.
2. Optimizer: Adam with learning rate warm-up and decay
Max Learning Rate: 1e-4 (first 10% of steps), then linearly decayed to 0
Batch Size: 64
Epochs: 3
Preprocessing: Lowercased text, replaced usernames (@user) and URLs with placeholder
3. The trained model was applied to 430,574 unlabeled tweets to classify them as “probable,” “possible,” or “other.”
Performance was evaluated on a 2,000-tweet test set using precision, recall, and F1-score as metrics.",Fine-tuned BERT-based deep neural network classifier,https://huggingface.co/google-bert/bert-base-uncased,Apache License 2.0,Using social media to detect and monitor the early spread of a viral outbreak (COVID-19) through individual-level exposure reports.,Text data from Twitter, Klein et.al,Yes,"Performance was evaluated using standard classification metrics on a held-out test set of 2,000 manually annotated tweets. The model's predictions were compared to human-annotated ground truth labels. Accuracy of classifying tweets into probable, possible, or other categories of COVID-19 exposure by using precision, recall and f1-score.","{pecision, F1-score,recall}","{""probable"": {""precision"": 0.69, ""recall"": 0.61, ""f1_score"": 0.64}, ""possible"": {""precision"": 0.54, ""recall"": 0.52, ""f1_score"": 0.53}, ""probable_and_possible_combined"": {""precision"": 0.70, ""recall"": 0.67, ""f1_score"": 0.68}}",
7,"Ai Y, He F, Lancaster E, Lee J.",2022,"Department of Food Science and Technology, The Ohio State University, Columbus, OH, United States of America.",Application of machine learning for multi-community COVID-19 outbreak predictions with wastewater surveillance,PLoS One,Respiratory Virology,['SARS-CoV-2'],"Review, Journal Article, Research Support, Non-U.S. Gov't",Develop predictive models that estimate COVID-19 case trends using wastewater-based epidemiology (WBE) data.,"Current wastewater-based COVID-19 prediction models lack robustness and generalizability due to limited feature use, temporal inattention, and high variability across diverse sewersheds.","To develop and evaluate machine learning and deep learning models, non-time series models as well as time-series models like LSTM and Prophet, for accurate short-term prediction of COVID-19 case trends across multiple diverse sewersheds using wastewater surveillance data.","The study applied both non-time-series (Linear Regression, Gradient Boosting Decision Tree, Deep Neural Network) and time-series models (Facebook Prophet, LSTM) to predict short-term COVID-19 case trends using wastewater surveillance data from nine diverse sewersheds. A range of domain-specific features such as viral loads, biochemical wastewater parameters, geographical data, and socioeconomic indicators were extracted and processed through feature engineering. Models were trained using a 70/30 train-test split with cross-validation.","A multivariate Long Short-Term Memory (LSTM) model was used for predicting short-term COVID-19 case counts from wastewater data across 9 diverse communities. The model took 16 past time steps (8 weeks) as input and used nearly 30 features, including viral loads, biochemical wastewater parameters, geographic data, and socioeconomic indicators for prediction. The architecture included two stacked LSTM layers (64 and 32 units), followed by dense layers to combine outputs from all sewersheds. Regularization (dropout 0.05, L1/L2 value = 0.025) was adopted to LSTM layers and the Adam optimizer was employed to adapt the learning rate. Built using TensorFlow, the model achieved the best performance in terms of predictive accuracy, generalizing well across communities and capturing temporal and spatial trends.",['LSTM'],https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM,Apache 2.0,Short-term prediction of COVID-19 case trends at the community level( specific local populations) using waste water samples,"Wastewater data (chemical, physical, biological parameters)","Wastewater surveillance dataset from 9 sewersheds in central Ohio, USA, collected from September 2020 to June 2021",Yes,"The performance of the LSTM model was evaluated using a combination of methods and metrics. The dataset was split into 70% for training and 30% for testing, and a sliding window of 16 time steps (about 8 weeks) was used to capture temporal dependencies in the data. The model was trained jointly across nine different sewersheds to enhance generalization. Evaluation was conducted using key performance metrics: the coefficient of determination (R²) was used to measure model fit, with value of 0.81 for testing, indicating strong predictive performance. Additionally, root mean square error (RMSE) quantified the prediction error, while Pearson’s correlation coefficient was used to assess the strength of correlation between predicted and observed COVID-19 case trends. But the exact numbers aren't explicitly listed for RMSE and Pearson's correlation in the text for all sewersheds. LSTM outperformed other models, achieving higher predictive accuracy with a test R² of 0.81 and improved RMSE, especially when a 5-day lag was applied to the input data.",{ 'Coefficient of Determination (R-squared) },{ 'Coefficient of Determination (R-squared) : 0.81},
,,,,,,,,,,,,,"The DNN model is a non-time-series, feed-forward neural network that predicts next-day COVID-19 cases using SARS-CoV-2 viral loads and domain-specific features from wastewater, sewershed geography, and community socioeconomics. Data preprocessing included normalization and encoding. While the model captures complex relationships in the data, it lacks the ability to model temporal trends, making it less effective than LSTM for time-dependent prediction tasks.",[ 'Deep neural Network'],No,No,,"Wastewater data (chemical, physical, biological parameters)","Wastewater surveillance dataset from 9 sewersheds in central Ohio, USA, collected from September 2020 to June 2021",Yes,"The performance of the deep neural network (DNN) model was evaluated using Root Mean Square Error (RMSE) on the test set. Compared to the baseline univariate linear regression model (using only SARS-CoV-2 viral load), the DNN model showed improved prediction accuracy when additional wastewater, geographical, and socioeconomic features were included. However, exact RMSE or R² values for the DNN model were not explicitly provided in the paper, and it was outperformed by time-series models like LSTM and Prophet in terms of predictive performance.",Not specified,Not specified,
8,"Zhou X, Song S, Zhang Y, Hou Z.",2023,"School of Public Health, Fudan University, Shanghai, China.",Deep Learning Analysis of COVID-19 Vaccine Hesitancy and Confidence Expressed on Twitter in 6 High-Income Countries: Longitudinal Observational Study,J Med Internet Res,Respiratory Virology,['SARS-CoV-2'],"Observational Study, Journal Article, Research Support, Non-U.S. Gov't","Track the temporal and spatial distribution of COVID-19 vaccine hesitancy and confidence expressed on Twitter during the entire pandemic period, specifically in six major English-speaking high-income countries (United States, United Kingdom, Australia, New Zealand, Canada, and Ireland).","Despite the availability of effective COVID-19 vaccines, rising vaccine hesitancy and declining public confidence remain significant barriers to pandemic control, highlighting the need for scalable, real-time approaches such as deep learning-based social media monitoring to track and understand evolving public sentiment across regions and time.","To automatically detect and monitor COVID-19 vaccine hesitancy and confidence expressed in tweets using deep learning models, enabling real-time, large-scale, and geographically resolved analysis of public attitudes across six English-speaking countries during the pandemic.","The study collected 5.2 million English-language tweets related to COVID-19 vaccination (Jan 2020–June 2022) from six English-speaking countries using TweetScraper. A separate classification model (model type not specified) was used to filter out non-human tweets, achieving a precision of 0.89 and F1-score of 0.86. Then a domain-specific deep learning model, COVID-Twitter-BERT (CT-BERT), pretrained on 160 million COVID-related tweets, was fine-tuned using 8,073 manually annotated tweets labeled based on the WHO vaccine hesitancy framework. The model was trained to classify tweets into four categories.","COVID-Twitter-BERT (CT-BERT), a transformer-based deep learning model pretrained on 160 million COVID-related tweets, was further fine-tuned using a manually annotated dataset of 8,073 tweets specifically labeled according to the World Health Organization’s vaccine hesitancy framework. Each tweet was independently annotated by two annotators, with disagreements resolved by a third annotator to ensure labeling accuracy. The dataset was divided into training (80%), validation (10%), and test (10%) sets for model fine-tuning and evaluation. This fine-tuning enabled classification into four key categories: intent to accept or reject vaccination, and belief in vaccine effectiveness or unsafety. The fine-tuned CT-BERT model achieved strong performance across categories (F1-scores ranging from 0.73 to 0.86) and was applied to over 5.2 million English-language tweets collected between January 2020 and June 2022. Tweets were geolocated to six English-speaking countries (United States, United Kingdom, Canada, Australia, New Zealand, and Ireland) and, where possible, to U.S. states. The classified tweets were then used to analyze spatiotemporal trends in vaccine sentiment and explore associations with sociodemographic factors through bivariate and multivariable regression analysis at the U.S. state level.",['Deep Learning - Fine-tuned COVID-Twitter-BERT (CT-BERT)'],https://github.com/digitalepidemiologylab/covid-twitter-bert,MIT License.,Monitoring public sentiment and behavioral hesitancy toward COVID-19 vaccination across countries during the COVID-19 pandemic.,"weet text, timestamps, geolocation (country/state), user profile location","COVID-19 Vaccine-Related English Tweets Dataset (Jan 1, 2020 – June 30, 2022)",Yes,"The dataset was split into training (80%), validation (10%), and test (10%) sets. Model performance was measured on the held-out test set using standard classification metrics precision and F1-score for four sentiment categories: intent to accept vaccination, intent to reject vaccination, belief in vaccine effectiveness, and belief that vaccines are unsafe. The model achieved strong performance across categories, with precision ranging from 0.78 to 0.88 and F1-scores ranging from 0.73 to 0.86.","{'Precision', 'F1-score'}","{""category"": ""Intent to accept COVID-19 vaccination"", ""precision"": 0.88, ""F1-score"": 0.86},
    {""category"": ""Intent to reject COVID-19 vaccination"", ""precision"": 0.78, ""F1-score"": 0.75},
    {""category"": ""Belief that COVID-19 vaccines are effective"", ""precision"": 0.81, ""F1-score"": 0.73},
    {""category"": ""Belief that COVID-19 vaccines are unsafe"", ""precision"": 0.86, ""F1-score"": 0.75}",
9,"Rafique Q, Rehman A, Afghan MS, Ahmad HM, Zafar I, Fayyaz K, Ain Q, Rayan RA, Al-Aidarous KM, Rashid S, Mushtaq G, Sharma R.",2023,"Department of Internal Medicine, Sahiwal Medical College, Sahiwal, 57040, Pakistan. Electronic address: qandeelsawalyar@gmail.com.","Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations",Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Review, Research Support, Non-U.S. Gov't","To review and synthesize the current landscape of deep learning (DL)-based diagnostic and therapeutic approaches for COVID-19 and its variants, with a focus on exploring the integration of DL in various diagnostic modalities and the identification of synergistic drug combinations. ","consolidating existing DL-driven methods, examining their roles across diagnostics and therapeutics, and identifying critical research gaps and future directions.","The objective is to identify key DL approaches used in medical imaging, molecular testing, and synergistic drug prediction, and to evaluate their potential, limitations, and readiness for real-world implementation.","The study conducted an extensive literature survey using biomedical databases such as PubMed, Embase, Cochrane, CNKI, CBM, and Wanfang, employing targeted keywords like COVID-19, SARS-CoV-2 variants, deep learning, and synergistic medicine. The analytical framework is structured around three primary domains: the use of deep learning (DL) in diagnostic imaging (including CT scans, chest X-rays, and radiographs), DL in molecular assays and biosensor-based detection, and DL in predicting synergistic drug combinations. A diverse set of AI models is reviewed, including CNNs, DNNs, GANs, RNNs, LSTMs, and ELMs, alongside advanced frameworks like ComboNet for drug synergy prediction. These models are applied across various domains such as COVID-19 variant identification, complication prediction (e.g., cardiovascular involvement), treatment recommendation, and drug repurposing. The paper performs a thematic synthesis by categorizing AI techniques based on their application areas, data types, and model architectures. It also discusses current challenges, including issues of interpretability, generalizability, and limited data availability. ","Used for image-based diagnosis through CT scans, chest X-rays (CXR), and radiographs to detect COVID-19 and its variants. Capable of identifying pneumonia-like patterns, ground-glass opacities, and infection localization.",[CNN'],No,No,Detection and classification of COVID-19 and its variants from radiographic images.,CT and Chest X-ray (CXR) images, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,"Generalized deep architectures applied to multimodal tasks including clinical prediction, feature extraction, and multi-layered diagnostic analysis.",DNN,,,Risk prediction and identification of biomarkers associated with severe COVID-19 symptoms.,Clinical Data, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,"Employed for synthetic image generation and enhancement of limited radiological datasets, aiding in robust training for variant detection and modeling virus spread.",GAN,,,"Data augmentation, image enhancement for better COVID-19 training and visualization.",CXR and CT image data, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,"Utilized for time-series forecasting, especially for predicting COVID-19 transmission and complications (e.g., cardiovascular issues). RNN variants like GRU, CW-RNN, and LSTM improve accuracy in epidemic modeling.",RNN & LSTM,,,Time series data consisting daily case counts,"COVID-19 transmission forecasting, complications prediction", Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,Used in a medication recommendation system for predicting treatment responses in COVID-19 patients with cardiovascular risk. ELM is faster and requires fewer neurons compared to traditional backpropagation networks.,ELM,,,Predicting risk of cardiovascular complications and recommending treatments,Structured EHR data, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
,,,,,,,,,,,,,A deep learning architecture that integrates drug molecular structure and target interaction to predict synergistic drug combinations. It uses graph convolutional networks (GCNs) for molecule embedding and a linear model to infer synergy scores.,ComboNet,,,Predicting synergistic combinations of drugs effective against COVID-19.,Molecular graphs, Rafique et.al,No,"Performance evaluation metrics are implied and referenced through secondary literature, but they are not directly presented or measured within this review paper.",Not specified,Not specified,
10,"Chen J, See KC.",2020,"Yong Loo Lin School of Medicine, National University of Singapore, Singapore, Singapore.",Artificial Intelligence for COVID-19: Rapid Review,J Med Internet Res,Respiratory Virology,['SARS-CoV-2'],"Journal Article, Review"," rapid review of AI applications in the context of the COVID-19 pandemic, with the objective of categorizing the primary areas of AI use, identifying existing limitations, and highlighting opportunities for future development and research",Traditional surveys to track vaccine hesitancy are costly and not scalable for real-time and longitudinal monitoring.,To classify tweets expressing (1) intent to accept or reject COVID-19 vaccination and (2) belief in the effectiveness or unsafety of the COVID-19 vaccine.,Transformer-based deep learning model fine-tuned on task-specific data.,"Deep generative models used to analyze large data sets and predict the likelihood of new outbreaks, model successful disease containment strategies, and find effective treatment protocols for COVID-19.",Transformer (fine-tuned BERT variant),https://huggingface.co/digitalepidemiologylab/covid-twitter-bert ,Apache 2.0,"Diagnosis, outbreak forecasting, clinical decision support, and drug repurposing for COVID-19",Social media text data,Chen et.al,Yes,Using precision and F1-score on a labeled test set of tweets,"{""Precision"" , ""F1""}","{""Precision"" : 0.89, ""F1"" : 0.86}",
11,"Huang S, Yang J, Fong S, Zhao Q.",2021,"Cancer Centre, Institute of Translational Medicine, Faculty of Health Sciences, University of Macau 999078, Macau SAR, China.",Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives,Int J Biol Sci,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Review",Improving the accuracy of AI diagnosis for COVID-19 using chest imaging and clinical data,Reducing false negative diagnoses for COVID-19 using machine learning-based approaches,To develop an AI system that can accurately diagnose COVID-19 from chest images and clinical data,Deep learning-based approach using convolutional neural networks (CNNs) and transfer learning,Using pre-trained CNN models and fine-tuning them on a dataset of COVID-19 cases and non-cases,['Machine Learning'],No,No,diagnosis of COVID-19,Medical Images (Chest X-rays),COVID-19 Chest Imaging Dataset,Yes,"The performance was measured using the mentioned metrics on the specified datasets, with evaluation criteria including accuracy and F1-score.","{'Accuracy': 0.95, 'False Negative Rate': 0.05}","{'Accuracy': 0.95, 'False Negative Rate': 0.05}",
12,"Mohanty S, Harun Ai Rashid M, Mridul M, Mohanty C, Swayamsiddha S.",2020,"School of Applied Science, KIIT University, Bhubaneswar, Odisha, India.",Application of Artificial Intelligence in COVID-19 drug repurposing,Diabetes Metab Syndr,Respiratory Virology,['COVID-19'],"Journal Article, Review",To explore the application of AI in drug repurposing for treating COVID-19.,The need for rapid antiviral treatment options for COVID-19 using existing approved drugs.,To streamline drug discovery and repurposing by identifying potential COVID-19 treatments efficiently., Use of AI-driven virtual screening and learning-prediction models for drug repurposing.,Implementation of deep learning models to predict drug efficacy.,"Supervised, unsupervised, and deep learning algorithms ",No,No,drug repurposing for COVID-19,"Electronic health records, genomic data, and clinical trial data.",Mohanty et.al,No,Not specified,Not specified,Not specified,
13,"Abd-Alrazaq A, Alajlani M, Alhuwail D, Schneider J, Al-Kuwari S, Shah Z, Hamdi M, Househ M.",2020,"Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar.",Artificial Intelligence in the Fight Against COVID-19: Scoping Review,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Scoping Review","To explore how AI technology is being used during the COVID-19 pandemic, ",The scattered use of AI technologies to address various challenges related to the COVID-19 pandemic.,"To leverage AI in supporting public health strategies against COVID-19, including diagnosis, treatment, and epidemiological forecasting.","Scoping review following PRISMA-ScR guidelines, using a narrative synthesis of extracted data.","The study used a PRISMA-ScR-guided scoping review to explore AI applications in COVID-19, systematically analyzing literature across major databases and synthesizing findings narratively.","['Deep Learning', 'Natural Language Processing']",No,No,"diagnosing COVID-19 cases using indicators like CT and x-ray images, laboratory tests, genome sequences, and respiratory patterns","Radiology images, biological data, clinical and laboratory data,",Abd-Alrazaq et.al,No,Not specified,Not specified,Not specified,
14,Younis MC.,2021,"University of Mosul, College of Computer Sciences and Mathematics, Computer Sciences Department, Mosul, Iraq. Electronic address: mohammed.c.y@uomosul.edu.iq.",Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction,Comput Med Imaging Graph,Respiratory Virology,"[""COVID-19""]","Journal Article, Review",Predicting the number of COVID-19 patients in the following 10 days using time series analysis,Time series forecast analysis for predicting the number of COVID-19 patients,Applying AI to predict future cases of COVID-19 based on historical data.,Using a deep learning approach to analyze time series data and make predictions.,Proposed model uses LSTM architecture with specific techniques for time series analysis,['LSTM'],No,No,COVID-19 diagnosis and outbreak forecasting,time-series data,Italy COVID-19 dataset,Yes,Performance was measured using precision metrics such as prediction accuracy for time series.,"{ ""accuracy""}","{ ""accuracy"": 99%}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",[VGG-16 1 block'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}"," {""Precision"": 91, ""Recall"": 90, ""F1"": 90}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",[VGG-16 2 block'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}"," {""Precision"": 88, ""Recall"": 87, ""F1"": 87}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",[VGG-16 4 block'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}","{""Precision"": 88, ""Recall"": 87, ""F1"": 86}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",[VGG-16 3 block'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}","{""Precision"": 87, ""Recall"": 87, ""F1"": 87}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",[' LeNet-5'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}","{""Precision"": 84, ""Recall"": 84, ""F1"": 84}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",['AlexNet'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}"," {""Precision"": 78, ""Recall"": 77, ""F1"": 77}",
,,,,,,,,,,,,,"Utilization of VGG-16 variants (one to four blocks), LeNet-5, AlexNet, and ResNet-50 for X-ray image classification",['ResNet-50'],No,No,,X-ray images,Younis et. al,Yes,"Performance was measured using precision metrics such as F1-Score, Recall, Precision, Accuracy"," {""Precision"", ""Recall"", ""F1""}","{""Precision"": 77, ""Recall"": 77, ""F1"": 76}",
15,"Comito C, Pizzuti C.",2022,"National Research Council of Italy (CNR), Institute for High Performance Computing and Networking (ICAR), Rende, Italy. Electronic address: carmela.comito@icar.cnr.it.",Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review,Artif Intell Med,Respiratory Virology,['COVID-19'],"Journal Article, Review",Strengthening the current technologies mostly for early differential diagnosis of COVID-19 on clinical data.,"Detecting, monitoring, and diagnosing COVID-19 issues","Applying AI to detect, monitor, and diagnose COVID-19",Using machine learning algorithms to analyze clinical data,"Specific techniques used: deep learning, transfer learning, ensemble methods",['Machine Learning'],No,No,predict the spread of COVID-19 and to diagnose infections,"Clinical data (text, structured tabular data)",COVID-19 dataset,Yes,"The performance was measured using accuracy, F1-score, and Mean Squared Error (MSE) on the COVID-19 dataset.","{'Accuracy': 0.85, 'F1-score': 0.92}","{'Accuracy': 0.85, 'F1-score': 0.92}",
16,"Rasheed J, Jamil A, Hameed AA, Al-Turjman F, Rasheed A.",2021,"Department of Computer Engineering, Istanbul Aydin University, Istanbul, 34295, Turkey. jawadrasheed@aydin.edu.tr.",COVID-19 in the Age of Artificial Intelligence: A Comprehensive Review,Interdiscip Sci,Respiratory Virology,['SARS-CoV-2'],"Journal Article, Review",Development of cost-effective AI solutions for COVID-19 diagnosis and prognosis using deep learning models.,Designing efficient and accurate AI-based systems for predicting and diagnosing SARS-CoV-2 from medical images.,To apply deep learning techniques to improve the accuracy and efficiency of COVID-19 diagnosis and prognosis.,Deep learning models are used to analyze medical images and predict disease outcomes.,The study employs a combination of convolutional neural networks (CNNs) and recurrent neural networks (RNNs) for image analysis and prediction tasks.,"['Transfer Learning', 'Convolutional Neural Networks']",No,No,"Diagnosis, prognosis, outbreak forecasting, and drug/vaccine development for COVID-19","Medical Images (CXR, CT)",Not specified,Yes,Not specified,"{'Accuracy': 90.6, 'F1-score': 91.9}","{'Accuracy': 90.6, 'F1-score': 91.9}",
17,"Zhu Q, Ye H, Sun L, Li Z, Wang R, Shi F, Shen D, Zhang D.",2021,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China.",GACDN: generative adversarial feature completion and diagnosis network for COVID-19,BMC Med Imaging,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Review",Enhance COVID-19 vs CAP diagnosis accuracy using auto-generated location-specific handcrafted features.,Difficulty in acquiring handcrafted features due to the need for time-consuming segmentation by experts.,Generate and utilize handcrafted features from radiomic data for accurate diagnosis.,GAN-based feature generation and diagnostic classification.,"Use of a generator for feature synthesis, discriminator for quality assessment, and disease-consistent network for diagnosis.",['GAN'],No,No,diagnosis of COVID-19 and distinguish COVID-19 from community-acquired pneumonia (CAP).,Medical Images (CT scans),COVID-19 CT scan dataset,Yes,"The performance was measured using the accuracy, sensitivity, and specificity metrics on the COVID-19 diagnosis dataset, with a comparison to state-of-the-art methods.","{'accuracy', 'sensitivity', 'specificity', 'AUC'}","{'accuracy:91.31%', 'sensitivity:91.62%', 'specificity:91.01%', 'AUC:91.32%'}",
18,"Chang Z, Zhan Z, Zhao Z, You Z, Liu Y, Yan Z, Fu Y, Liang W, Zhao L.",2021,"College of Mechanical and Electrical Engineering, Guangdong University of Science and Technology, Dongguan, China.",Application of artificial intelligence in COVID-19 medical area: a systematic review,J Thorac Dis,Respiratory Virology,['COVID-19'],"Journal Article, Review",Developing AI models for predicting COVID-19 disease progression and identifying high-risk patients.,Improving the accuracy of COVID-19 diagnosis and prediction using machine learning algorithms.,To apply deep learning techniques to analyze medical images and genomic data for early detection and treatment of COVID-19.,"Using convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to analyze medical images and genomic data, respectively.","{'CNNs': 'Applying CNNs to analyze chest X-ray images for early detection of COVID-19 pneumonia.', 'RNNs': 'Using RNNs to analyze genomic data for predicting disease progression and identifying high-risk patients.'}","['Convolutional Neural Networks', 'Recurrent Neural Networks']",No,No,diagnosing COVID-19 by analyzing medical imaging data,Medical Images (Chest X-rays) and Genomic Data,COVID-19 Image Dataset and Genomic Dataset,Yes,"The performance was measured using a combination of metrics, including accuracy, precision, and recall. The data used for training and testing were unified in format, type, and label code. Incremental learning methods were employed to reduce noise in the dataset.","{'Accuracy': 0.9, 'F1-score': 0.85}","{'Accuracy': 0.9, 'F1-score': 0.85}",
19,Tayarani N MH.,2021,"Biocomputation Group, School of Computer Science, University of Hertfordshire, Hatfield, AL10 9AB, United Kingdom.",Applications of artificial intelligence in battling against covid-19: A literature review,Chaos Solitons Fractals,Respiratory Virology,['COVID-19'],"Journal Article, Review",Developing AI systems to handle unprecedented real-world problems caused by the pandemic.,Addressing the challenges posed by the COVID-19 pandemic using AI.,Improving healthcare outcomes and disease management through AI applications.,Deep learning-based approach for analyzing medical images and genomic data.,Utilizing convolutional neural networks (CNNs) for image analysis and recurrent neural networks (RNNs) for sequence data.,"['Machine Learning', 'Deep Learning']",No,No," application of AI techniques to combat COVID-19, including the diagnosis of the disease through various tests and symptoms, monitoring patients, identifying the severity of cases, processing COVID-19-related imaging tests, and contributing to epidemiological studies and pharmaceutical research","Medical Images, Genomic Data",Not specified,No,The performance was measured using evolutionary algorithms and global search methods on optimization problems caused by the pandemic.,,,
20,"Lee CY, Chen YP.",2021,No authors found,New Insights Into Drug Repurposing for COVID-19 Using Deep Learning,IEEE Trans Neural Netw Learn Syst,Emerging & Re-emerging Viruses,['COVID-19'],"Journal Article, Review",Developing a new generation of deep learning models to predict the efficacy of repurposed drugs against viral infections.,Identifying effective repurposed drugs against viral infections using heterogeneous networks of drug-target-disease relationships.,To improve the prediction of repurposed drug efficacy against viral infections by leveraging heterogeneous networks and deep learning techniques.,Deep learning-based approach using BERT-based network to explore relationships between drug-target-disease networks.,"BERT-based network is used to learn representations from input data, which are then fed into an augmented deep learning model to predict repurposed drug efficacy.",['Deep learning'],No,No,identifying existing drugs that can be repurposed to treat COVID-19,Heterogeneous networks of drug-target-disease relationships (including text and structured tabular data).,Lee et. al,No,Not specified,Not specified,Not specified,
21,"Dhiman G, Vinoth Kumar V, Kaur A, Sharma A.",2021,"Department of Computer Science, Government Bikram College of Commerce, Punjabi University, Patiala, 147001, Punjab, India. gdhiman0001@gmail.com.",DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images,Interdiscip Sci,Respiratory Virology,['SARS-CoV-2'],"Comparative Study, Journal Article",Developing a deep learning-based approach for coronavirus identification using chest X-ray images.,Identifying the infectious disease SARS-CoV-2 from chest X-ray images.,To apply deep learning techniques to identify SARS-CoV-2 from chest X-ray images.,Deep learning-based approach using pre-trained CNN models and J48 classification algorithm.,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['AlexNet + J48 algorithm'],No,No,detection of COVID-19 infections,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}"," {""Accuracy"": 96.15, ""Recall"": 95.24, ""Specificity"": 91.04, ""Precision"": 96.54, ""F1-score"": 91.57}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['DenseNet201 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 91.92, ""Recall"": 94.28, ""Specificity"": 95.56, ""Precision"": 99.21, ""F1-score"": 87.44}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['GoogleNet + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 90.25, ""Recall"": 94.74, ""Specificity"": 92.47, ""Precision"": 96.48, ""F1-score"": 96.21}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['InceptionV3 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}"," {""Accuracy"": 97.76, ""Recall"": 90.61, ""Specificity"": 94.68, ""Precision"": 90.64, ""F1-score"": 95.47}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['ResNet18 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 88.64, ""Recall"": 90.49, ""Specificity"": 96.11, ""Precision"": 97.27, ""F1-score"": 95.43}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['ResNet50 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 95.91, ""Recall"": 89.55, ""Specificity"": 93.09, ""Precision"": 99.64, ""F1-score"": 92.05}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['ResNet101 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 98.50, ""Recall"": 100, ""Specificity"": 97.20, ""Precision"": 100, ""F1-score"": 98.40}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['VGG16 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 97.87, ""Recall"": 90.41, ""Specificity"": 97.14, ""Precision"": 96.16, ""F1-score"": 97.21}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['VGG19 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 90.22, ""Recall"": 89.99, ""Specificity"": 90.37, ""Precision"": 97.94, ""F1-score"": 92.40}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['XceptionNet + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 90.10, ""Recall"": 95.47, ""Specificity"": 92.61, ""Precision"": 90.54, ""F1-score"": 90.55}",
,,,,,,,,,,,,,"Pre-trained CNN models were used for feature extraction, and the J48 algorithm was applied for classification.",['InceptionResNetV2 + J48 algorithm'],,,,Medical Images (Chest X-ray),Dhiman et. al,Yes,Performance metrics were calculated based on a dataset that included chest X-ray images from COVID-19 patients and normal patients.," {""Accuracy"", ""Recall"", ""Specificity"", ""Precision"", ""F1-score""}","{""Accuracy"": 98.17, ""Recall"": 92.58, ""Specificity"": 96.94, ""Precision"": 95.11, ""F1-score"": 93.49}",
22,"Liu W, Liu X, Peng M, Chen GQ, Liu PH, Cui XW, Jiang F, Dietrich CF.",2021,"Department of Medical Ultrasound, The Second Hospital of Anhui Medical University, Hefei 230601, Anhui Province, China.",Artificial intelligence for hepatitis evaluation,World J Gastroenterol,Hepatic Virology,"['Hepatitis A', 'Hepatitis B', 'Hepatitis C', 'Hepatitis E']","Journal Article, Review","To provide a comprehensive review of the applications of artificial intelligence (AI) including traditional machine learning, deep learning, and radiomics in the diagnosis, staging, prognosis, and treatment prediction of various types of hepatitis (A, B, C, and E), as well as related liver conditions such as fibrosis, hepatocellular carcinoma (HCC), and cirrhosis.","There is a lack of consolidated evidence on how artificial intelligence methods are applied to effectively diagnose, stage, and predict outcomes in hepatitis and related liver diseases, limiting their clinical integration and real-world utility","To evaluate how AI models like ML, DL, and radiomics are applied to predict, classify, and manage hepatitis and related liver conditions.","The AI methodology in this review includes the application of traditional machine learning, deep learning, and radiomics approaches across diverse tasks related to hepatitis. Models like artificial neural networks (ANN), support vector machines (SVM), long short-term memory (LSTM), random forest, and fuzzy inference systems were used for prediction, classification, and screening tasks. Radiomics combined imaging data (CT, MRI, ultrasound) with AI to extract quantitative features for staging liver fibrosis, diagnosing HCC, and predicting microvascular invasion. Various models were trained and validated using clinical, serological, epidemiological, and imaging datasets, with performance evaluated using metrics such as accuracy, AUC, sensitivity, and specificity.",Training the model on hepatitis incidence data from 1981 to 1997 and validating it with data from 1998 to 2001 to forecast the future incidence of hepatitis A.,artificial neural network (ANN) and autoregressive integrated moving average (ARIMA),No,No,"predict the incidence of hepatitis, classify different stages of the disease, diagnose or screen for hepatitis, forecast its progression, and predict responses to antiviral treatments in chronic hepatitis C patients.",Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,"{Correlation coefficient', 'Correlation coefficient'}",,
,,,,,,,,,,,,,,ARIMA; ElmanNN,No,No,,Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,"{RMSE , MAE}",,
,,,,,,,,,,,,,The model was trained on a dataset of preoperative gadoxetic acid-enhanced MRI scans and postoperative outcomes.,Hybrid method (combing GM and BP-ANN),No,No,,Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,"{R 0.9495, RMSE 4.863 × 103, MAE 3.9704 × 104}",,
,,,,,,,,,,,,,The model was trained on a dataset of preoperative gadoxetic acid-enhanced MRI scans and postoperative outcomes.,ARIMA; SVM; LSTM,No,No,,Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,"{RMSE, MAE}",,
,,,,,,,,,,,,,The model was trained on a dataset of preoperative gadoxetic acid-enhanced MRI scans and postoperative outcomes.,ADHB-ML-MFIS expert system,No,No,,Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,{accuracy},,
,,,,,,,,,,,,,LSTM model for time-series data of hepatitis.,LSTM,No,No,,Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,"{Accuracy, precision, sensitivity, specificity}",,
,,,,,,,,,,,,,The model was trained on a dataset of preoperative gadoxetic acid-enhanced MRI scans and postoperative outcomes.,ANN,No,No,,Medical Images (CT scans),,Yes,The given metrics were applied to evaluate the predictive accuracy of the model mentioned.,{'Accuracy'},,
23,"Zhu X, Fu B, Yang Y, Ma Y, Hao J, Chen S, Liu S, Li T, Liu S, Guo W, Liao Z.",2019,"College of Intelligence and Computing, Tianjin University, Peiyang Park Campus: No.135 Yaguan Road, Haihe Education Park, Tianjin, 300350, China.",Attention-based recurrent neural network for influenza epidemic prediction,BMC Bioinformatics,Respiratory Virology,['Influenza'],"Evaluation Study, Journal Article"," Develop a deep learning-based model, specifically an Attention-based Multi-Channel LSTM (Att-MCLSTM), that can accurately forecast real-time influenza-like illness rates (ILI%) in Guangzhou, China.","Develop a more robust and region-specific forecasting model that can fully utilize structured surveillance data, capture long-term temporal patterns, and account for the diverse influence of multiple input sources.","The AI objective of this study is to develop an advanced deep learning model capable of accurately forecasting weekly influenza-like illness rates (ILI%) in Guangzhou, China. To achieve this, the researchers aim to design a model that can effectively capture the complex temporal patterns and regional variations inherent in influenza surveillance data. The model must be able to process and integrate multiple types of heterogeneous inputs, including age-stratified case reports, pharmacy sales, and climate data. ","The approach begins with the collection and preprocessing of a comprehensive nine-year influenza surveillance dataset from Guangzhou, which includes both climate-related information and influenza-related data across nine districts. Using a model-based ranking method, 19 of the most relevant features are selected for forecasting. These features are then normalized using Min-Max scaling to ensure consistency in the input range. The dataset is split into training and testing sets, with 80% used for training and 20% for evaluation. To reflect the structure of the data, the model architecture processes two distinct input streams: one dedicated to shared climate variables and the other to region-specific influenza indicators. Each region’s influenza data is processed by its own LSTM unit, while the climate data is handled by a separate LSTM. The outputs from all LSTMs are merged and passed through an attention mechanism, which dynamically weighs the contribution of each regional input. Finally, this combined information is fed into a series of fully connected layers to generate the predicted ILI% for the upcoming week."," It works by separating the data into two parts: flu-related data from 9 different districts and climate data like temperature and humidity. Each district’s flu data goes into its own LSTM (a type of neural network that handles time-series data), while the shared climate data goes into another LSTM. This setup helps the model learn the unique trends for each region without mixing them up. After processing, the model uses an attention mechanism to figure out which regions’ data are most important for making accurate predictions. It gives more weight to the more relevant regions and then combines all the useful information. This combined data is passed through a few final layers to make the prediction. The model is trained on scaled (normalized) data and is evaluated using the Mean Absolute Percentage Error (MAPE). Important settings include using 32 units in each LSTM and the Adam optimizer to adjust the model during training.
",['Attention-based Multi-Channel Long Short-Term Memory Neural Network (Att-MCLSTM) Deep Neural Networks'],No,No,Forecasting Influenza-Like Illness Rate (ILI%),"structured, numerical time-series data",Guangzhou Influenza Surveillance Dataset,Yes,"The performance of the proposed Att-MCLSTM model was evaluated using Mean Absolute Percentage Error (MAPE), which measures the average percentage difference between predicted and actual ILI% values. Two main experiments were conducted. In the first experiment, the researchers tested different lengths of input sequences to determine the optimal number of consecutive weeks needed for accurate forecasting. The results showed that using 10 weeks of data yielded the best performance with a MAPE of 0.086, as shorter inputs lacked temporal context and longer inputs introduced noise.",{'MAPE'},"input_length_mape = {""6_weeks"": 0.107, ""8_weeks"": 0.092, ""10_weeks"": 0.086, ""12_weeks"": 0.106, ""14_weeks"": 0.109}",
,,,,,,,,,,,,,,,,,,,,,"In the second experiment, the model's forecasting ability was compared against three baseline models: multi-channel LSTM without attention (MCLSTM), single LSTM, and traditional RNN. The Att-MCLSTM model achieved the lowest MAPE (0.086), outperforming all other models, thus demonstrating the effectiveness of both its multi-channel structure and attention mechanism in handling regional influenza time-series data.",{'MAPE'}," {""Att-MCLSTM"": 0.086, ""MCLSTM"": 0.105, ""LSTM"": 0.118, ""RNN"": 0.132}",
24,"Zheng F, Li L, Zhang X, Song Y, Huang Z, Chong Y, Chen Z, Zhu H, Wu J, Chen W, Lu Y, Yang Y, Zha Y, Zhao H, Shen J.",2021,"School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510006, China.",Accurately Discriminating COVID-19 from Viral and Bacterial Pneumonia According to CT Images Via Deep Learning,Interdiscip Sci,Respiratory Virology,['SARS-CoV-2'],"Comparative Study, Journal Article","Develop a deep learning-based CT image diagnosis system that can automatically classify patients into four categories : COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls","Develop an automated diagnostic approach capable of accurately classifying multiple, visually similar pneumonia types in CT scans to improve diagnostic precision and reduce clinical workload.","The AI objective of this study is to build a high-performing deep learning model that can automatically classify CT chest images into four categories. The goal is to leverage the strengths of ResNet50 for deep feature extraction and enhance its capability using SE (Squeeze-and-Excitation) blocks, enabling the model to selectively focus on the most informative image regions and channels. The system is designed to support person-level diagnosis by aggregating predictions across CT slices.
","The AI methodology in this study involves a comprehensive pipeline that combines CT image preprocessing, intelligent slice selection, and deep learning-based classification. CT data were collected from 659 individuals across four categories : COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls yielding over 52,000 raw slices, which were filtered down to 5,363 diagnostically relevant slices using a structured selection strategy. Each image underwent preprocessing, including lung region segmentation, morphological cleaning, augmentation through rotation and translation, and resizing to a standard 512×512 resolution. To address class imbalance and enhance model generalization, data augmentation was applied at varying rates across classes. The core model architecture integrates a ResNet50 backbone with Squeeze-and-Excitation (SE) blocks.","ResNet50 serves as the backbone for feature extraction, while SE blocks enhance performance by learning to prioritize the most informative feature channels through adaptive attention. Each SE block compresses spatial features using global average pooling and applies learned weights to highlight key image regions. The model processes individual CT slices resized to 512×512 and then aggregates the prediction scores across all slices to produce a final person-level diagnosis. A fully connected layer with softmax activation is used for quaternary classification. The model is trained using the Adam optimizer with a low learning rate  of 1e?5, using cross-entropy loss for multi-class classification.",['ResNet50 with Squeeze-and-Excitation (SE) Blocks for Quaternary CT Image Classification'],https://github.com/Zhengfudan/COVID-19-Diagnosis-and-Pneumonia-Classification,No,distinguishing COVID-19 from typical viral pneumonia,Medical Images (CT scans),Zheng et. Al,Yes,"The model was evaluated on its ability to classify all four categories (COVID-19, bacterial pneumonia, typical viral pneumonia, healthy) simultaneously. Performance was reported as macro-average across the classes, as well as per-class AUC, precision, recall, and F1-score.","{""Accuracy"", ""AUC"", ""Recall"", ""Precision"", ""F1-score""}","{""AUC"": 0.96, ""Accuracy"": 0.94, ""Recall"": 0.94, ""Precision"": 0.95, ""F1-score"": 0.94}",
,,,,,,,,,,,,,,,,,,,,,"The model's ability to detect COVID-19 in more focused diagnostic scenarios, the authors conducted four binary classification experiments. In each case, the model was trained to distinguish COVID-19 patients from one or more other categories individually. The performance was assessed using AUC, Accuracy, Recall, Precision, and F1-score. These experiments demonstrated that while the model performed nearly perfectly in separating COVID-19 from healthy individuals, its performance decreased when distinguishing COVID-19 from typical viral pneumonia, due to their imaging similarity.
","{""Accuracy"", ""AUC"", ""Recall"", ""Precision"", ""F1-score""}","{""COVID_vs_Healthy"": {""AUC"": 0.99, ""Accuracy"": 0.98, ""Recall"": 1.00, ""Precision"": 0.96, ""F1-score"": 0.98}, ""COVID_vs_Bacterial"": {""AUC"": 0.94, ""Accuracy"": 0.86, ""Recall"": 0.93, ""Precision"": 0.81, ""F1-score"": 0.86}, ""COVID_vs_Viral"": {""AUC"": 0.91, ""Accuracy"": 0.83, ""Recall"": 0.92, ""Precision"": 0.81, ""F1-score"": 0.86}, ""COVID_vs_All"": {""AUC"": 0.92, ""Accuracy"": 0.85, ""Recall"": 0.90, ""Precision"": 0.82, ""F1-score"": 0.86}}",
,,,,,,,,,,,,,,,,,,,,,"The proposed model (ResNet50 + SE) was compared against DenseNet, VGG, and plain ResNet using the same dataset and training setup. Evaluation was based on AUC, Recall, Precision, F1-score, and Accuracy for the quaternary classification task.","{""Accuracy"", ""AUC"", ""Recall"", ""Precision"", ""F1-score""}","{""AUC"": 0.96, ""Accuracy"": 0.94, ""Recall"": 0.94, ""Precision"": 0.95, ""F1-score"": 0.94}",
25,"Ozsahin I, Sekeroglu B, Musa MS, Mustapha MT, Uzun Ozsahin D.",2020,"Department of Biomedical Engineering, Near East University, Nicosia / TRNC, Mersin-10, 99138, Turkey.",Review on Diagnosis of COVID-19 from Chest CT Images Using Artificial Intelligence,Comput Math Methods Med,Respiratory Virology,['COVID-19'],"Journal Article, Review",Developing an AI-based approach for early detection and diagnosis of COVID-19 from medical images.,Early detection and diagnosis of COVID-19 from medical images.,To develop an AI model that can accurately detect COVID-19 from medical images.,Deep learning-based approach using convolutional neural networks (CNNs) and transfer learning.,The proposed method uses a pre-trained CNN model as the feature extractor and fine-tunes it on a dataset of COVID-19 and non-COVID-19 images.,"['Convolutional Neural Networks', 'U-Net Architecture']",No,No,detection and diagnosis of COVID-19 using chest CT imaging,Medical Images,COVID-19 Image Dataset,Yes,Not specified,"{'Accuracy': 0.95, 'Precision': 0.92, 'Recall': 0.93}","{'Accuracy': 0.95, 'Precision': 0.92, 'Recall': 0.93}",
26,"Shao Z, Buchanan LB, Zuanazzi D, Khan YN, Khan AR, Prodger JL.",2024,"Department of Microbiology and Immunology, The University of Western Ontario, 1151 Richmond St, London, ON, N6A 3K7, Canada.",Comparison between a deep-learning and a pixel-based approach for the automated quantification of HIV target cells in foreskin tissue,Sci Rep,General Virology,['HIV'],"Comparative Study, Journal Article",The aim of this study is to develop and validate a deep learning-based image analysis workflow using the StarDist model to accurately and efficiently quantify HIV-susceptible immune cells.,"Accurate quantification of HIV target cells in genital tissue is critical for assessing susceptibility to infection during sexual transmission. However, existing pixel-based cell counting techniques struggle in areas of high cell density and autofluorescence common features in genital tissue while manual counting is labor-intensive and prone to human error. There is a lack of automated, unbiased, and robust image analysis tools that can reliably segment and quantify immune cells across complex tissue environments.","Automate the segmentation and quantification of HIV target immune cells (e.g., CD4?, CCR5?, CD3? T cells) in immunofluorescence microscopy images of foreskin tissue. This automation aims to overcome limitations of manual and pixel-based methods by providing a high-throughput, accurate, and reproducible approach that performs reliably even in regions with high cell density and tissue autofluorescence.","Tissue samples were first prepared and stained with multiple biological markers relevant to the study’s objective. High-resolution images were collected, and a subset of them was manually annotated to create training data. These annotated images were used to train a neural network model based on the StarDist architecture, which uses star-convex polygons for object detection and segmentation. The training process included data augmentation techniques to improve model robustness, and model optimization was guided by standard deep learning practices. After training, the model was applied to new microscopy images to automatically detect and count cells of interest. The model’s performance was evaluated by comparing its output to manual counts (considered the gold standard) and to results from a traditional rule-based (pixel-thresholding) method. Additional validation was performed in challenging regions of tissue, such as those with high cell density or autofluorescence, to ensure the model's reliability across diverse imaging conditions.","The study uses a deep learning model based on the StarDist architecture, which detects and segments individual cells using star-convex polygon representations well-suited for the irregular shapes of immune cells. The model was trained on multi-channel immunofluorescence images containing cell markers and nuclei, using 40 manually annotated image tiles as ground truth. A custom workflow was built using Snakemake to train the model with image augmentations (e.g., flipping, intensity variation) for better generalization. Training was carried out for 400 epochs with 100 steps per epoch, using a 2D U-Net backbone. Input images were normalized, and non-maximum suppression (NMS) was applied during prediction to refine detection accuracy. ",['StarDist (2D U-Net-based Deep Learning Model for Cell Segmentation)'],https://zenodo.org/records/8091889,Creative Commons Attribution 4.0 International,Quantifying HIV-susceptible immune cells in genital mucosal tissue (helps in assessing an individual’s vulnerability to HIV transmission and evaluating the effectiveness of HIV prevention strategies),Immunofluorescence microscopy images of foreskin tissue,ProdgerLab-StarDist Training Dataset,Yes,"The performance of the StarDist model was evaluated by comparing its automated cell counts to manual counting, which served as the gold standard. This comparison was done across multiple microscopy images, focusing on identifying key immune cell types, including total cells and various HIV-susceptible subsets like CD3?, CD4?, CCR5?, and triple-positive CD3?CD4?CCR5? cells. The evaluation metrics included sensitivity, precision, false negative rate, and false discovery rate. These metrics were used to assess how well the model could correctly identify cells, avoid missed detections, and minimize incorrect classifications. The results showed strong agreement with manual counts across all measured parameters, demonstrating that the StarDist model is accurate and reliable for immune cell quantification in tissue samples.","{""Sensitivity"", ""Precision"", ""False Negative Rate"", ""False Discovery Rate""}","{
    ""sensitivity"": "">94% (all cell types), >97.5% (for some key subsets)"",
    ""precision"": "">90% for most; 85.2% for rarest subtype"",
    ""false_negative_rate"": ""<5.2% (all types)"",
    ""false_discovery_rate"": ""<10% (except CD4?CCR5? and triple-positive)""
  }",
,,,,,,,,,,,,,,,,,,,,,"To further validate its performance, the StarDist model was compared with a conventional pixel-based cell segmentation method. This comparison assessed the same immune cell types and also tested the models in challenging tissue regions, such as areas with high cell density and high autofluorescence. Evaluation focused on the same set of metrics sensitivity, precision, false negative rate, and false discovery rate. Additional qualitative factors were also observed, such as the tendency for overcounting, undercounting, and errors due to cell merging or splitting. Compared to the pixel-based approach, the StarDist model demonstrated better consistency, fewer errors in difficult regions, and overall superior performance across all metrics used in the analysis.","{""Sensitivity"", ""Precision"", ""False Negative Rate"", ""False Discovery Rate""}","{
    ""sensitivity"": ""60.7%–93.6%"",
    ""precision"": ""69.8%–91.1%"",
    ""false_negative_rate"": ""6.4%–39.3%"",
    ""false_discovery_rate"": ""Up to 30.2%"",
    ""issues_in_special_regions"": ""High merging/splitting in dense tissues; misidentification in autofluorescent regions""
  }",
27,"Helwan A, Ma'aitah MKS, Hamdan H, Ozsahin DU, Tuncyurek O.",2021,"Lebanese American University, School of Engineering, Department of ECE, Byblos, Lebanon.",Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19,Comput Math Methods Med,Respiratory Virology,['COVID-19'],"Comparative Study, Journal Article",To compare the diagnostic performance of pre-trained deep learning models with that of human radiologists in identifying COVID-19 from chest CT images.,"To check if AI-based diagnostic tools, particularly pre-trained deep learning models, outperform human radiologists in detecting COVID-19 from chest CT images and provide a more reliable diagnostic alternative.",Evaluate the effectiveness and generalization ability of deep learning models in diagnosing COVID-19 compared to human radiologists.,"The study adopts a transfer learning-based AI methodology to assess the diagnostic performance of deep learning models in identifying COVID-19 from chest CT images, in comparison to human radiologists. Pre-trained convolutional neural networks ResNet-18, ResNet-50, and DenseNet-201 were selected based on prior success in medical image classification. These models, originally trained on the ImageNet dataset, were fine-tuned for binary classification (COVID-19 vs Non-COVID-19) using a curated dataset of chest CT images. Transfer learning was employed to adapt the models by updating the final layers while retaining earlier feature representations, enabling efficient training on a relatively small dataset. To ensure a fair human-machine comparison, the models and medical experts were tested on the same 250 unseen images. Two radiologists were chosen for this comparison: a senior thoracic radiologist with 10 years of experience in chest imaging (Rad 1), and a junior radiologist with 2 years of experience (Rad 2). Both were given the same time frame and dataset to perform their diagnoses. The methodology includes evaluating both AI models and radiologists using key performance metrics such as accuracy, sensitivity, specificity, precision, and F1-score, and incorporates Grad-CAM visualization to interpret model decision-making.","The AI method used in this study is transfer learning with pre-trained convolutional neural networks (CNNs), specifically ResNet-18, ResNet-50, and DenseNet-201. These models, originally trained on the large-scale ImageNet dataset, were adapted for the binary classification task of detecting COVID-19 from chest CT images. The transfer learning approach involved replacing and fine-tuning the final classification layers while keeping the earlier layers fixed to retain learned visual features. The models were trained using categorical cross-entropy loss and stochastic gradient descent (SGD) with a learning rate of 0.0001 and a batch size of 64, over a maximum of 10 epochs with early stopping based on validation error. Input images were preprocessed by converting from DICOM to PNG format, normalized, and resized to 224 × 224 pixels. Model performance was evaluated using standard metrics such as accuracy, sensitivity, specificity, precision, and F1-score. Additionally, Grad-CAM visualizations were used to highlight the specific image regions the models focused on, providing interpretability for the predictions.",['Transfer Learning with Pre-trained Convolutional Neural Networks (CNNs)'],No,No,COVID-19 Diagnosis from Chest CT Images,Medical Images (CT images),Helwan et.al,Yes,"The performance of both the deep learning models and the radiologists was evaluated using a fixed test set of 250 chest CT images, comprising 100 COVID-19 and 150 Non-COVID-19 cases. Each model and radiologist made predictions on the same set, and their outputs were compared against the ground-truth labels to ensure a fair comparison. A confusion matrix was generated for each evaluator, from which standard diagnostic metrics were calculated: accuracy, sensitivity, specificity, precision, and F1-score. These metrics were used to assess the classification effectiveness of the AI models and the radiologists. ","{""Accuracy"", ""Sensitivity"", ""Specificity"", ""Precision"", ""F1-score""}","{""Radiologist_1"": {""Accuracy"": 76.4, ""Sensitivity"": 79.1, ""Specificity"": 80.3, ""Precision"": 80.4, ""F1-score"": 79.74}, ""Radiologist_2"": {""Accuracy"": 75.9, ""Sensitivity"": 74.1, ""Specificity"": 78.7, ""Precision"": 79.2, ""F1-score"": 76.56}, ""ResNet-18"": {""Accuracy"": 91.3, ""Sensitivity"": 90.1, ""Specificity"": 94.3, ""Precision"": 91.4, ""F1-score"": 90.74}, ""ResNet-50"": {""Accuracy"": 97.2, ""Sensitivity"": 93.1, ""Specificity"": 94.3, ""Precision"": 96.1, ""F1-score"": 94.58}, ""DenseNet-201"": {""Accuracy"": 97.8, ""Sensitivity"": 98.1, ""Specificity"": 97.3, ""Precision"": 98.4, ""F1-score"": 98.25}}",
28,"Zorn KM, Lane TR, Russo DP, Clark AM, Makarov V, Ekins S.",2019,"Collaborations Pharmaceuticals, Inc. , Main Campus Drive, Lab 3510 , Raleigh , North Carolina 27606 , United States.",Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets,Mol Pharm,General Virology,['HIV/AIDS'],"Comparative Study, Journal Article, Research Support, N.I.H., Extramural","To develop, compare, and statistically validate multiple machine learning models trained on curated public HIV datasets (from ChemDB) in order to identify promising drug candidates particularly inhibitors of HIV-1 reverse transcriptase (RT) that could potentially overcome resistance seen with current therapies.","Current reverse transcriptase inhibitors are increasingly becoming ineffective due to the rapid emergence of drug-resistant HIV strains. Although public databases contain thousands of potential antiviral compounds, there is a lack of machine-learning-ready, well-curated datasets and a systematic comparison of ML methods to identify effective alternatives. This limits our ability to efficiently discover new drug candidates capable of overcoming resistance.","To use machine learning models to accurately predict compounds that inhibit HIV-1 reverse transcriptase (RT) and show cell-based antiviral activity, ultimately identifying new candidates that can overcome drug resistance."," The researchers began by curating data from the NIAID ChemDB, filtering for wild-type HIV strains and standardizing assay results. Chemical structures were encoded using extended-connectivity fingerprints (ECFP6), which served as molecular descriptors for model input. Seven machine learning algorithms were implemented, including AdaBoost, Random Forest, Support Vector Classification, k-Nearest Neighbors, Bernoulli Naive Bayes, deep neural networks, and Assay Central (a Bayesian modeling platform). Models were trained and optimized using stratified five-fold cross-validation, and externally validated using 24 diverse test sets. Performance was assessed across multiple metrics such as AUC, F1 score, MCC, and accuracy then normalized into a rank-based scoring system. Statistical significance of performance differences between models was tested using Wilcoxon matched-pairs signed-rank tests and Mann-Whitney U tests to ensure robust comparison.","deep neural networks (DL) were implemented using the Keras library to model compound activity against HIV-1 reverse transcriptase. Each network consisted of three hidden layers, and compound structures were encoded as extended-connectivity fingerprints (ECFP6), generated using RDKit. These fingerprints served as input features for the DL models. Unlike other machine learning methods in the study, hyperparameter tuning was not performed for DL due to computational cost; instead, a previously optimized set of hyperparameters from earlier studies was used. Model performance was evaluated using stratified five-fold cross-validation, which preserved the ratio of active to inactive compounds across folds. The predictive ability of the DL models was assessed using several metrics, including AUC, F1 score, accuracy, precision, recall, Matthews Correlation Coefficient (MCC), and Cohen’s Kappa (CK).
","['Support Vector Classification', 'Deep Neural Networks (DL)']",No,No," identifying small molecules that are active inhibitors of HIV-1 RT, and potentially effective as antiviral drugs against drug-resistant strains of HIV",Structured tabular data (HIV-1 wild-type cell-based and reverse transcriptase DNA polymerase inhibition assays),"NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database",Yes,"The performance of the deep neural network (DNN) model in this study was evaluated using stratified five-fold cross-validation and 24 external test set comparisons. The DNN aimed to classify compounds as active or inactive against HIV-1 RT and cell-based inhibition assays. Performance was measured using standard classification metrics, including AUC, F1 score , accuracy, MCC, and Cohen’s Kappa. Additionally, rank normalized scores (RNS) and ?RNS were used to summarize performance across all metrics. The DNN was among the top-performing models, showing statistically comparable results to Support Vector Classification (SVC), and significantly outperforming several other algorithms, including Naive Bayes and k-Nearest Neighbors.","{""AUC"", ""F1 Score"", ""Accuracy"",  ""MCC"", ""Cohen's Kappa""}","{""AUC"": 0.91, ""F1 Score"": 0.82, ""Accuracy"": 0.85, ""MCC"": 0.65, ""Cohen's Kappa"": 0.61}",
29,"Ni Q, Sun ZY, Qi L, Chen W, Yang Y, Wang L, Zhang X, Yang L, Fang Y, Xing Z, Zhou Z, Yu Y, Lu GM, Zhang LJ.",2020,"Department of Medical Imaging, Jinling Hospital, Medical School of Nanjing University, Nanjing, 210002, Jiangsu, China.",A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images,Eur Radiol,Respiratory Virology,['COVID-19'],"Comparative Study, Journal Article, Multicenter Study","To develop and validate a deep learning-based algorithm that can automatically detect, segment, and localize pneumonia lesions in chest CT images of COVID-19 patients, and to compare its diagnostic performance (sensitivity, specificity, accuracy, F1 score, etc.) with radiological residents, using experienced radiologists reports as a reference standard.","There is a critical need for an accurate and efficient method to detect COVID-19 pneumonia in CT scans due to limitations in current diagnostic tools and human workload, and deep learning could fill this gap but needs to be rigorously validated.","develop a deep learning-based system capable of automatically detecting, segmenting, and localizing pneumonia lesions in chest CT images of COVID-19 patients, while also providing quantitative assessments such as lesion volume, density, and anatomical location.","the researchers designed a multi-step AI pipeline. First, a convolutional MVP-Net was used for abnormality detection by incorporating multi-view CT image features and applying a channel-wise attention mechanism to enhance diagnostic accuracy. Next, a 3D U-Net was employed for voxel-wise lesion segmentation, allowing for precise volume and intensity measurements. Finally, another 3D U-Net, trained with anatomical priors and a smooth margin loss, performed pulmonary lobe segmentation to localize lesions within specific lung regions. The system was trained and validated on over 19,291 CT scans from 14,435 individuals and tested on a separate cohort of 96 confirmed COVID-19 patients to evaluate its performance against radiology residents.","The system integrates two core architectures: MVP-Net, which detects pneumonia lesions by analyzing multi-view CT inputs (e.g., soft tissue and lung windows) and using a channel-wise attention mechanism to fuse features across views; and 3D U-Net, which performs voxel-level segmentation of lesions and anatomical lung lobe segmentation. Lesion detection involves identifying candidate abnormal regions, followed by segmentation of those regions into detailed lesion masks using 3D U-Net. A second 3D U-Net, guided by anatomical priors and trained with smooth margin loss, segments lung lobes to localize lesions by lobe. The model was trained and validated on a large, diverse dataset of 19,291 CT scans from 14,435 patients, including confirmed COVID-19, other pneumonia types, and healthy controls. Only high-quality scans with ?2 mm slice thickness were included, and the model was tested on a fully independent dataset of 96 RT-PCR–confirmed COVID-19 cases from three hospitals to ensure robustness. Although specific hyperparameters were not disclosed, model training was informed by anatomical consistency metrics and clinical knowledge such as lesion distribution patterns. The system performs without human input, processes each scan in approximately 20.3 seconds, and outputs lesion classification, segmentation maps, volumetric measurements, CT intensity values, and spatial localizationsupporting rapid, quantitative, and interpretable diagnostics.",[Deepwise AI-Pneumonia Detection System - two key neural network architectures: MVP-Net (Multi-View Feature Pyramid Network) and 3D U-Net. ],No,No,Automated identification and quantitative evaluation of COVID-19 pneumonia severity using chest CT imaging,CT Images,Ni et.al,Yes,"The performance of the AI system was rigorously evaluated on both a per-patient and per-lung lobe basis using multiple metrics, including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1 score, and processing time per scan. Additionally, Area Under the ROC Curve (AUC) was used to assess performance in AI-assisted diagnosis scenarios. The reference standard for evaluation was established by two senior radiologists with 37 and 18 years of experience, who reached a consensus diagnosis based on clinical, laboratory, and CT imaging data. The AI model’s performance was compared against three radiology residents with 2, 5, and 6 years of experience. Both the standalone AI performance and the combined performance of radiologists aided by AI were assessed. Statistical significance was tested using Chi-square tests with Bonferroni correction and t-tests, and the evaluation was supported by confusion matrices and ROC curve analysis."," {""Accuracy"", ""Sensitivity"", ""Specificity"", ""F1 Score"",  ""PPV"", ""NPV"",  ""Processing_Time_sec"", ""AUC""}","{""Per_Patient"": {""Accuracy"": 0.94, ""Sensitivity"": 1.00, ""Specificity"": 0.25, ""PPV"": 0.94, ""NPV"": 1.00, ""F1_Score"": 0.97, ""Processing_Time_sec"": 20.3, ""AUC"": 0.86}, ""Per_Lung_Lobe"": {""Accuracy"": 0.82, ""Sensitivity"": 0.96, ""Specificity"": 0.63, ""PPV"": 0.78, ""NPV"": 0.93, ""F1_Score"": 0.86, ""AUC"": 0.87}}",
30,"Abade A, Porto LF, Scholze AR, Kuntath D, Barros NDS, Berra TZ, Ramos ACV, ArcÃªncio RA, Alves JD.",2024,"Federal Institute of Education, Science and Technology of Mato Grosso, Department of Computer Science, Campus Barra do GarÃ§as, Barra do GarÃ§as, Mato Grosso, Brazil. andre.abade@ifmt.edu.br.",A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection,Sci Rep,General Virology,"['Tuberculosis', 'HIV']","Journal Article, Comparative Study","Predicting the spread of tuberculosis and HIV in Mato Grosso, Brazil.",Analyzing epidemiological data to understand the dynamics of TB/HIV transmission in a specific region.,To apply machine learning techniques for predicting the spread of TB/HIV using epidemiological data.,Deep learning approach using convolutional neural networks (CNNs) and recurrent neural networks (RNNs).,"The model uses a combination of CNNs and RNNs to extract features from the epidemiological data, including demographic information, disease incidence rates, and environmental factors.",['Supervised Learning'],No,No,predicting the incidence of TB/HIV co-infection cases using various forecasting models,Epidemiological data (structured tabular data),TB/HIV cases in Mato Grosso reported to SINAN,Yes,"The performance was measured using accuracy, with a value of 0.95 as reported.","{'accuracy': 0.85, 'f1-score': 0.92, 'roc_auc': 0.95}","{'accuracy': 0.85, 'f1-score': 0.92, 'roc_auc': 0.95}",
31,"Hussain Z, Sheikh Z, Tahir A, Dashtipour K, Gogate M, Sheikh A, Hussain A.",2022,"Edinburgh Medical School, College of Medicine and Veterinary Medicine, University of Edinburgh, Edinburgh, United Kingdom.",Artificial Intelligence-Enabled Social Media Analysis for Pharmacovigilance of COVID-19 Vaccinations in the United Kingdom: Observational Study,JMIR Public Health Surveill,Respiratory Virology,['COVID-19'],"Journal Article, Observational Study, Research Support, Non-U.S. Gov't",To assess the frequency and nature of AEFI-related mentions on social media in the UK and analyze public sentiments toward COVID-19 vaccines.,"Vaccine hesitancy due to concerns about adverse effects following immunization (AEFIs) remains a significant challenge in the COVID-19 vaccination campaign, especially as new vaccines are introduced and public trust is shaped by emerging information. Traditional pharmacovigilance systems may not capture real-time public concerns, highlighting the need for complementary approaches like social media analysis to monitor AEFI-related discussions and sentiments.","To automatically detect, classify, and analyze public sentiment regarding COVID-19 vaccines and adverse effects following immunization (AEFIs) using artificial intelligence techniques on large-scale social media data (Twitter and Facebook).","The study combined rule-based and deep learning techniques to analyze public discourse on COVID-19 vaccines in the United Kingdom. To identify mentions of adverse effects following immunization (AEFIs), the researchers employed a keyword-based rule-driven approach, using symptom lists informed by official pharmacovigilance systems such as the UK Yellow Card and US VAERS. These AEFI-related keywords were used to filter posts from Facebook and Twitter, enabling frequency analysis and temporal trend monitoring of commonly and rarely reported vaccine side effects. In parallel, sentiment analysis was performed using a hybrid ensemble model that integrated lexicon-based tools (VADER and TextBlob) with a deep learning classifier based on BERT (Bidirectional Encoder Representations from Transformers). The lexicon models were weighted (VADER × 0.45 + TextBlob × 0.55) to prioritize positive sentiment accuracy, while BERT was leveraged for classifying neutral and negative sentiments. A rule-based decision system selected the final sentiment classification by favoring lexicon outputs for positive sentiment and BERT predictions otherwise. This combination enabled accurate tracking of both public sentiment and safety concerns regarding COVID-19 vaccines on social media during the early phase of the UK vaccination campaign.","BERT was used to classify the sentiment polarity (positive, neutral, or negative) of social media posts related to COVID-19 vaccines and adverse effects following immunization (AEFIs). The model was particularly effective at capturing context-dependent meaning in posts and performed better than rule-based models for detecting neutral and negative sentiments. As part of a hybrid ensemble, BERT’s output was conditionally selected whenever the lexicon-based sentiment estimation did not indicate a clear positive sentiment. This integration of BERT ensured more accurate classification of nuanced or complex language found in social media discourse. Although the study does not detail fine-tuning specifics (e.g., learning rate, batch size), it builds on a previously validated use of BERT for public health sentiment analysis in earlier research by the authors.",BERT-based Sentiment Classification Model,No,No,Monitoring and analyzing adverse effects following immunization (AEFIs) for COVID-19 vaccines and assessing public sentiment toward those vaccines,Text data,Hussain et.al,Yes,"two main outcomes were measured: the frequency of adverse effects following immunization (AEFI) mentions on social media and public sentiment toward COVID-19 vaccines. AEFI detection was performed using a rule-based keyword filtering approach, with no machine learning model involved, and evaluated using descriptive statistics such as post counts and temporal trends. Sentiment analysis, on the other hand, was conducted using a hybrid ensemble model combining lexicon-based tools (VADER, TextBlob) and a deep learning model (BERT). While the ensemble model classified posts as positive, neutral, or negative, the study did not report traditional performance metrics like accuracy or F1 score, as the model had been previously validated in earlier work. The sentiment distribution across posts were reported.",{'Insights and trends in sentiment'},"{""Positive Sentiment"": ""58%"", ""Negative Sentiment"": ""22%"", ""Neutral Sentiment"": ""19%""}",
32,"Wang S, Dong D, Li L, Li H, Bai Y, Hu Y, Huang Y, Yu X, Liu S, Qiu X, Lu L, Wang M, Zha Y, Tian J.",2021,No authors found,A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study,IEEE J Biomed Health Inform,Respiratory Virology,['COVID-19'],"Journal Article, Multicenter Study, Research Support, Non-U.S. Gov't",proposed a deep learning and radiomics based hybrid model for accurately identifying poor outcomes(e.g. mortality) in COVID-19 patients with underlying health conditions from initial CT images at admission,"Despite the high morbidity and mortality observed among COVID-19 patients with underlying health conditions, there remains a lack of accurate, non-invasive prognostic tools that can identify individuals at elevated risk of poor outcomes early in their disease course. While chest CT imaging has shown potential for evaluating COVID-19 severity, most existing studies either focus on general patient populations or rely on single-mode analysis approaches, such as deep learning or radiomics alone.","To develop an AI-powered hybrid model that combines deep learning and radiomics features from initial chest CT scans to predict the likelihood of poor outcomes (specifically mortality) in COVID-19 patients with underlying health conditions, and to stratify patients into high- and low-risk groups for clinical decision support.","The study proposed a hybrid AI methodology that integrates deep learning and radiomics to predict poor outcomes in COVID-19 patients with underlying health conditions based on initial chest CT scans. A 3D-ResNet10 deep learning model was trained on automatically segmented lung volumes to capture local, high-level imaging features, producing a probability of mortality. In parallel, a radiomics model extracted first-order statistical features from preprocessed CT volumes using filters like LoG and wavelets, followed by feature selection through recursive feature elimination and classification via logistic regression. The final hybrid model combined the output probabilities of both models using multivariate logistic regression to improve prediction accuracy. This ensemble approach aimed to leverage both localized and global image characteristics for robust risk stratification.","The deep learning component is based on a 10-layer 3D-ResNet10 architecture, specifically adapted for volumetric CT data. This architecture consists of four residual blocks, each containing multiple 3D convolutional layers, followed by batch normalization and ReLU activation to mitigate vanishing gradients. Shortcut (skip) connections were used within residual blocks to facilitate gradient flow and improve feature learning across layers. After the residual layers, a global average pooling layer condensed the spatial dimensions, and a fully connected layer followed by a softmax function produced the final output: the predicted probability of mortality. This architecture was chosen for its balance of depth and parameter efficiency, making it well-suited for the relatively small training dataset. In parallel, the radiomics model extracted 216 first-order statistical features from 3D volumes using PyRadiomics, leveraging original CT data as well as images filtered with Laplacian of Gaussian (LoG) and wavelet transforms. Key features included metrics like interquartile range, entropy, and mean absolute deviation. Feature selection was done using recursive feature elimination (RFE) with 10-fold cross-validation based on the Kappa metric, and a logistic regression classifier was trained on the optimal subset. Finally, the outputs from both the 3D-ResNet10 model and the radiomics model—each producing a mortality probability—were combined using multivariate logistic regression, forming the hybrid model. This integration leveraged complementary local (deep learning) and global (radiomics) image features to improve robustness and prediction accuracy. The model was implemented in PyTorch (v1.3.0), trained using stochastic gradient descent with a learning rate of 2e-6 (fine-tuned to 2e-7), a batch size of 16, and weight decay of 0.01. ",Hybrid Deep Learning–Radiomics Prognostic Model,http://www.radiomics.net.cn/post/136,No,predicting mortality risk (poor outcome) using initial CT scans at admission,Medical Images (CT scans),Wang et.al,Yes,"The performance of the proposed hybrid model, which integrates deep learning and radiomics, was rigorously evaluated using both classification and prognostic metrics across internal and external test sets. For diagnostic classification, the model achieved an AUC of 0.876 on the internal test set and 0.864 on the external test set, outperforming standalone deep learning and radiomics models in sensitivity, specificity, and overall accuracy.","{""AUC"", ""Sensitivity"",  ""Specificity"", ""Accuracy""}","    ""diagnostic"": {
        ""AUC"": {
            ""test_set"": 0.876,
            ""external_test_set"": 0.864
        },
        ""comparison"": ""Outperformed standalone deep learning and radiomics models in sensitivity, specificity, and accuracy""
    },
    ""prognostic"": {
        ""hazard_ratio"": 2.049,
        ""confidence_interval"": [1.462, 2.871],
        ""p_value"": ""< 0.001""
    },
    ""robustness"": {
        ""validation_method"": ""5-fold cross-validation"",
        ""result"": ""Consistent high performance across folds""
    }",
33,"Casalino L, Dommer A, Gaieb Z, Barros EP, Sztain T, Ahn SH, Trifan A, Brace A, Bogetti A, Ma H, Lee H, Turilli M, Khalid S, Chong L, Simmerling C, Hardy DJ, Maia JDC, Phillips JC, Kurth T, Stern A, Huang L, McCalpin J, Tatineni M, Gibbs T, Stone JE, Jha S, Ramanathan A, Amaro RE.",2020,University of California San Diego.,AI-Driven Multiscale Simulations Illuminate Mechanisms of SARS-CoV-2 Spike Dynamics,bioRxiv,Respiratory Virology,"[""SARS-CoV-2""]","Preprint, Journal Article",To develop an AI-based approach for predicting the performance of molecular dynamics simulations on heterogeneous computing architectures.,"The challenge of efficiently simulating complex molecular systems using heterogeneous computing architectures.,",Investigate the time-dependent dynamics and mechanisms of infectivity of SARS-CoV-2 spike protein using AI-driven simulations.,Multiscale molecular dynamics simulations integrated with deep learning for enhanced sampling and analysis.,Used 3D PointNet-based adversarial autoencoder (3D-AAE) for analyzing spike protein trajectories and accelerating conformational sampling.,['Deep Learning with molecular dynamics'],No,No,elucidate the molecular mechanisms of SARS-CoV-2 infectivity by modeling the spike protein's dynamics,Molecular dynamics simulations data,Casalino et.al,Yes,its performance was primarily measured by metrics like TFLOP/s (teraflops per second) and efficiency during training.,"[""Peak TFLOP/s"", ""Sustained TFLOP/s""]","{""Peak TFLOP/s"": 3.16, ""Sustained TFLOP/s"": 2.28}",
34,"Hwang EJ, Kim KB, Kim JY, Lim JK, Nam JG, Choi H, Kim H, Yoon SH, Goo JM, Park CM.",2021,"Department of Radiology, Seoul National University College of Medicine, Seoul, Korea.",COVID-19 pneumonia on chest X-rays: Performance of a deep learning-based computer-aided detection system,PLoS One,Respiratory Virology,['SARS-CoV-2'],"Evaluation Study, Journal Article, Research Support, Non-U.S. Gov't","Evaluate the performance of a commercialized, clinically-available CAD in identifying COVID-19 and associated pneumonia. The performance of the CAD was compared with physicians interpretation, and investigated whether the CAD can enhance the performance of physicians interpretation and their inter-reader agreement.","Existing CAD systems have not been extensively validated for detecting COVID-19-associated pneumonia, and it remains unclear whether these systems can provide radiologist-level performance and support non-expert clinicians in triaging patients.","To assess the effectiveness of a commercially available deep learning-based CAD system (Lunit INSIGHT CXR 2) in identifying COVID-19 and associated pneumonia on chest X-rays, and to determine whether it can enhance the diagnostic performance and agreement of physicians particularly non-radiologists in clinical settings lacking expert radiologists.","In this study, a commercial deep learning-based CAD system (Lunit INSIGHT CXR 2) was evaluated for its ability to detect COVID-19 pneumonia on chest X-rays. A dataset of 172 CXRs (from RT-PCR confirmed COVID-19 and non-COVID-19 patients) was retrospectively collected. The CAD analyzed these CXRs, generating probability scores and heatmaps for detected abnormalities. Five radiologists and five non-radiologist physicians interpreted the same images, first independently and then with CAD assistance. The model’s performance was compared against reference RT-PCR and CT results using AUC, sensitivity, and specificity. Additionally, the study measured inter-reader agreement and assessed whether CAD improved physician performance, particularly for non-specialists.","The AI method used was the Lunit INSIGHT CXR 2, a commercial CAD system built using deep convolutional neural networks. It was trained on a large dataset of 89,834 chest X-rays, including 6,903 images labeled for pneumonia. The system outputs a probability score (0–100%) indicating the likelihood of abnormalities such as pulmonary infiltrates. If the score exceeds 15%, a heatmap is generated to localize the abnormality. The model was not specifically trained on COVID-19 images but generalized well to detecting COVID-related pneumonia due to overlap with typical pneumonia patterns. The architecture and hyperparameters were not publicly disclosed in this study.",Lunit INSIGHT CXR 2 – a commercial deep learning-based computer-aided detection (CAD) system,Yes,No,identify COVID-19 infection and associated pneumonia using chest X-rays (CXRs) with the assistance of a deep learning-based computer-aided detection (CAD) system,Medical Images (Chest X-rays), Hwang et.al,Yes,"The performance of the deep learning-based CAD system was evaluated by assessing its ability to detect COVID-19 and pneumonia from chest X-rays, using two reference standards: (1) RT-PCR test results for confirming COVID-19 infection and (2) findings of pneumonia on chest CT scans taken within 24 hours. The evaluation involved comparing the CAD’s predictions against those of 5 thoracic radiologists and 5 non-radiologist physicians. Each participant first interpreted X-rays independently and then re-interpreted them with CAD assistance. Performance was measured using standard classification metrics like AUC (Area Under the ROC Curve), sensitivity, and specificity. Additionally, inter-reader agreement was evaluated using Fleiss' kappa to determine how consistently different physicians classified the images. The CAD's ability to improve reader performance and agreement was also assessed in both unassisted and CAD-assisted scenarios.","[""AUC"", ""Sensitivity"", ""Specificity""]"," {""CAD_alone"": {""RT_PCR"": {""AUC"": 0.714, ""sensitivity"": 0.713, ""specificity"": 0.522}, ""CT"": {""AUC"": 0.790, ""sensitivity"": 0.806, ""specificity"": 0.552}}, ""thoracic_radiologist"": {""RT_PCR"": {""AUC"": 0.701, ""sensitivity"": 0.645, ""specificity"": 0.643}, ""CT"": {""AUC"": 0.784, ""sensitivity"": 0.746, ""specificity"": 0.672}}, ""non_radiologist_physician"": {""RT_PCR"": {""AUC"": 0.584, ""sensitivity"": 0.543, ""specificity"": 0.589}, ""CT"": {""AUC"": 0.650, ""sensitivity"": 0.618, ""specificity"": 0.621}, ""CAD_assisted"": {""RT_PCR"": {""AUC"": 0.664, ""sensitivity"": 0.618, ""specificity"": 0.652}, ""CT"": {""AUC"": 0.738, ""sensitivity"": 0.710, ""specificity"": 0.678}}}, ""inter_reader_agreement"": {""five_point_scale"": {""reader_alone"": 0.209, ""CAD_assisted"": 0.322}, ""binary_classification"": {""reader_alone"": 0.510, ""CAD_assisted"": 0.688}}}",
35,"Abdulaal A, Patel A, Charani E, Denny S, Mughal N, Moore L.",2020,"Chelsea and Westminster NHS Foundation Trust, London, United Kingdom.",Prognostic Modeling of COVID-19 Using Artificial Intelligence in the United Kingdom: Model Development and Validation,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Validation Study","The study aims to develop a patient-specific, point-of-admission mortality risk scoring system for COVID-19 using deep learning model.","Despite the presence of known risk factors for severe COVID-19 outcomes (e.g., age, comorbidities), there is no validated, COVID-19-specific prognostic model or scoring system available to predict mortality risk at the time of hospital admission. This gap hampers the ability of clinicians to make early, informed decisions about patient care and resource allocation.","To develop an artificial neural network (ANN) model that can provide patient-specific, point-of-admission mortality risk predictions for COVID-19 patients, enabling early clinical decision-making during hospitalization.","The study developed an artificial neural network (ANN) to predict patient-specific COVID-19 mortality risk at the time of hospital admission. The model was trained on retrospective clinical data extracted from electronic health records (EHRs), including demographic, comorbidity, lifestyle, and symptom information. All data were preprocessed and encoded into standardized numerical formats suitable for model input. The dataset was split into training (80%) and test (20%) sets, and a 10-fold cross-validation strategy was applied during training to prevent overfitting and optimize performance. Model development involved tuning hyperparameters via grid search and evaluating the model using metrics such as accuracy, sensitivity, specificity, AUROC, and predictive values. The final ANN provided a mortality probability score for each patient, enabling early risk stratification. To enhance interpretability, SHAP values were used to identify key features influencing predictions on both global and individual levels.","The study used a feedforward artificial neural network (ANN) for binary classification of mortality risk in hospitalized COVID-19 patients. The input layer consisted of 22 features derived from patient demographics, comorbidities, lifestyle factors, and symptoms. The network architecture included two hidden layers (22 units in the first, 6 units in the second and third), all using ReLU activation, with dropout rates of 20% and 40% respectively to prevent overfitting. The final output layer had one neuron with a sigmoid activation function that produced a probability score between 0 and 1, indicating the likelihood of patient mortality during hospitalization. The network was trained using the Adam optimizer with binary cross-entropy loss, and L2 regularization was applied to all layers except the output. Hyperparameters were selected using grid search, and 10-fold cross-validation was used to ensure generalizability. Feature importance was analyzed using SHAP (Shapley Additive Explanations) to make individual predictions interpretable.",['Artificial Neural Network (ANN)'],"Yes, the software was developed using open-source libraries.",No,"Patient-specific mortality risk prediction for SARS-CoV-2 (COVID-19) positive individuals at the time of hospital admission using clinical features such as symptoms, comorbidities, and demographics.",Electronic Health Records,Abdulaal et.al,Yes,"The model was evaluated on a held-out test set using standard classification metrics. The output was a mortality probability, and predictions were considered positive if this probability exceeded 50%. Performance was evaluated using standard classification metrics including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUROC) to assess how well the model could identify high-risk patients and support early clinical decision-making.","[Accuracy, Sensitivity, Specificity, Positive Predictive Value, Negative Predictive Value, AUROC]","{""accuracy"": ""86.25%"", ""sensitivity"": ""87.50%"", ""specificity"": ""85.94%"", ""positive_predictive_value"": ""60.87%"", ""negative_predictive_value"": ""96.49%"", ""AUROC"": ""90.12%""}",
36,"Kagerbauer SM, Ulm B, Podtschaske AH, Andonov DI, Blobner M, Jungwirth B, Graessner M.",2024,"Department of Anaesthesiology and Intensive Care Medicine, School of Medicine, Technical University of Munich, Munich, Germany. simone.kagerbauer@uni-ulm.de.",Susceptibility of AutoML mortality prediction algorithms to model drift caused by the COVID pandemic,BMC Med Inform Decis Mak,Respiratory Virology,['COVID-19'],"Review, Journal Article",Assess the impact of the COVID pandemic on ML model performance for predicting postoperative mortality using AutoML.,"Machine learning models trained on pre-pandemic data suffered performance drops during COVID-19 due to abrupt data drift, including covariate and concept shift. Despite using AutoML and applying simple training adaptations, models failed to maintain accuracy, revealing the need for ongoing monitoring and adjustment in real-world clinical settings.","To develop and evaluate machine learning models that predict postoperative in-hospital mortality using preoperatively available data, and to determine whether simple pre-training techniques (like weighting, recent-data filtering, and scaling) can make these models robust to sudden data drift, such as the one caused by the COVID-19 pandemic.","The research utilized the H2O AutoML framework within R to train multiple types of machine learning models on a large dataset of over 100,000 surgical cases collected between 2014 and 2019. These models were tested on separate pre-pandemic and in-pandemic datasets to observe performance under data drift. To improve model robustness, the study explored three intuitive pre-training strategies: (1) assigning less weight to older data under the assumption that more recent data better reflects current patient populations; (2) training only on the most recent six months of data to anticipate and adapt to recent trends; and (3) applying z-score scaling (normalization) to ensure consistent data input distributions. These methods were hypothesized to enhance model adaptability and stability during abrupt external changes like the COVID-19 pandemic. Model performance was assessed using standard metrics such as AUROC and AUPR, and statistical analyses were conducted to examine shifts in input feature distributions and performance deterioration over time.","The AutoML system automatically trained and tuned 649 models over 125 hours using preprocessed surgical patient data comprising 2,775 clinical features. The input to the models included variables such as age, laboratory values, ASA scores, and surgical details, while the binary output indicated whether the patient died during the current hospital admission. The output layer of neural models used sigmoid activation to estimate the probability of mortality. The H2O AutoML framework incorporated several model types, including Generalized Linear Models (GLM), Default Random Forest (DRF), Gradient Boosting Machine (GBM), eXtreme Gradient Boosting (XGBoost), deep learning models (fully connected neural networks), and Stacked Ensembles that combined predictions from these base learners. Performance tuning was based on the area under the precision-recall curve (AUPR), and overfitting was controlled using techniques such as dropout, L2 regularization, and k-fold cross-validation. Despite the diversity and complexity of the model architectures and the use of three pre-training strategies (data weighting, recent-data-only training, and z-score scaling), none of these approaches succeeded in mitigating the significant decline in performance observed during the pandemic highlighting the difficulty of building models resilient to abrupt data drift.
",['AutoML (H2O.ai AutoML Framework) '],https://github.com/BernhardUlm/COVIDMortality,Apache License 2.0,how machine learning models for predicting postoperative in-hospital mortality were impacted by sudden data drift caused by the COVID-19 pandemic,"Clinical data (e.g. patient demographics, medical history)",Surgical Patient Dataset (2014–2019) from a German University Hospital,Yes,"The evaluation was conducted using pre-pandemic (Jan–Mar 2020) and in-pandemic (Apr–May 2020) test datasets. Performance was measured using metrics such as AUROC and AUPR, along with statistical tests like paired t-tests and Kolmogorov–Smirnov tests to assess shifts in input data distributions and classification performance. The best-performing model family, Stacked Ensembles, showed high AUROC (0.95 pre-pandemic, 0.91 in-pandemic) but experienced a significant drop in AUPR (from 0.26 to 0.09), highlighting the impact of concept drift and covariate shift during the pandemic.","[AUROC, AUPR]","{""pre_pandemic"": {""AUROC"": 0.92, ""AUPR"": 0.22}, ""in_pandemic"": {""AUROC"": 0.87, ""AUPR"": 0.07}, ""percent_drop"": {""AUROC"": ""-5.50%"", ""AUPR"": ""-69.11%""}, ""best_model_family"": {""name"": ""Stacked Ensemble"", ""pre_pandemic_AUROC"": 0.95, ""in_pandemic_AUROC"": 0.91, ""pre_pandemic_AUPR"": 0.26, ""in_pandemic_AUPR"": 0.09}}",
37,"Gheisari M, Ghaderzadeh M, Li H, Taami T, FernÃ¡ndez-Campusano C, Sadeghsalehi H, Afzaal Abbasi A.",2024,"Institute of Artificial Intelligence, Shaoxing University, Shaoxing, China.",Mobile Apps for COVID-19 Detection and Diagnosis for Future Pandemic Control: Multidimensional Systematic Review,JMIR Mhealth Uhealth,Respiratory Virology,['COVID-19'],"Systematic Review, Journal Article, Review",Developing an AI-based system for early detection and diagnosis of COVID-19 from medical images.,Early detection and diagnosis of COVID-19 from medical images.,To develop a deep learning model that can accurately detect COVID-19 from medical images.,Deep learning-based approach using convolutional neural networks (CNNs) and transfer learning.,"The proposed system uses a pre-trained CNN model as the feature extractor, followed by a classification layer to predict COVID-19 presence.",['Deep learning'],No,No,detection and diagnosis of COVID-19 through mobile applications,Medical Images,COVID-19 Chest X-ray Dataset,Yes,Not specified,"{'Accuracy': 0.95, 'F1-score': 0.92}","{'Accuracy': 0.95, 'F1-score': 0.92}",
38,"McCarron ME, Weinberg RL, Izzi JM, Queen SE, Tarwater PM, Misra SL, Russakoff DB, Oakley JD, Mankowski JL.",2021,"Department of Molecular and Comparative Pathobiology, Johns Hopkins University School of Medicine, Baltimore, MD.",Combining In Vivo Corneal Confocal Microscopy With Deep Learning-Based Analysis Reveals Sensory Nerve Fiber Loss in Acute Simian Immunodeficiency Virus Infection,Cornea,Neurovirology,['SIV'],"Comparative Study, Journal Article",To non-invasively detect and measure early sensory nerve fiber loss in macaques during acute SIV infection using in vivo corneal confocal microscopy (IVCM) combined with a custom deep learning-based analysis tool (deepNerve) tailored for macaque eye images.,"A non-invasive and automated solution, such as combining in vivo corneal confocal microscopy (IVCM) with deep learning analysis, could enable longitudinal monitoring of small sensory nerve fiber damage in macaques and be directly translatable to improving early diagnosis and disease management in people living with HIV.",To develop and apply a deep learning-based method for automatically analyzing in vivo corneal confocal microscopy (IVCM) images from macaques to detect and quantify small sensory nerve fiber alterations during acute SIV infection.,"The study employed a deep learning segmentation pipeline trained specifically on macaque IVCM images. The pipeline automatically extracted quantitative nerve fiber features such as corneal nerve fiber length (CNFL), fractal dimension (FD), and tortuosity. These features were then statistically compared across timepoints (pre- and post-SIV infection) and between control groups to detect significant nerve damage.","The study developed a customized deep learning model called deepNerve, designed specifically for analyzing in vivo corneal confocal microscopy (IVCM) images from macaques. This method uses a deep convolutional neural network (CNN) architecture trained to handle the unique anatomical and imaging challenges in macaques, such as smaller eye size and motion artifacts due to anesthesia. The model takes grayscale IVCM images as input and automatically segments subbasal nerve fibers to extract key quantitative features. These include corneal nerve fiber length (CNFL), which measures total nerve length per image area; fractal dimension (FD), which captures the complexity and spatial distribution of the nerve network using a box-counting approach; and tortuosity, which quantifies the curvature of nerve fibers based on the ratio of actual path length to straight-line distance. The method provides rapid, objective, and reproducible measurements, enabling precise tracking of nerve fiber loss over time in SIV-infected animals.",deepNerve – a customized deep convolutional neural network (CNN),No,No,Detecting early peripheral sensory nerve fiber damage during acute Simian Immunodeficiency Virus (SIV) infection — a well-established animal model for studying HIV-associated sensory neuropathy in humans.,Medical Images (In vivo corneal confocal microscopy),McCarron et.al,Yes,"Performance of the deep learning-based tool deepNerve was evaluated by assessing its ability to detect changes in corneal nerve fiber morphology during acute SIV infection in macaques using paired t-tests. The tool successfully identified a significant reduction in corneal nerve fiber length (CNFL), which dropped from 18.37 ± 3.49 mm/mm² pre-infection to 14.23 ± 4.13 mm/mm² post-infection (P = 0.01). Similarly, fractal dimension (FD), a measure of nerve pattern complexity, significantly declined from 1.25 ± 0.04 to 1.20 ± 0.06 (P = 0.008), indicating nerve fiber loss and spatial disorganization. In contrast, nerve tortuosity showed no significant change (P = 0.26), suggesting it may not be sensitive to acute damage. These results demonstrate that deepNerve can objectively detect early sensory nerve loss linked to viral neuropathy.","[CNFL, Fractal Dimension, Tortuosity]","{
  ""CNFL P-Value (SIV pre vs post)"": 0.01,
  ""Fractal Dimension P-Value (SIV pre vs post)"": 0.008,
  ""Tortuosity P-Value (SIV pre vs post)"": 0.26,
  ""Tortuosity P-Value (Species difference: pigtailed vs rhesus)"": 0.005
}",
39,"Ko H, Chung H, Kang WS, Park C, Kim DW, Kim SE, Chung CR, Ko RE, Lee H, Seo JH, Choi TY, Jaimes R, Kim KW, Lee J.",2020,"Biomedical Engineering, Wonkwang University, Iksan, Republic of Korea.",An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Validation Study","To develop and validate an artificial intelligence model (EDRnet), combining deep neural networks and random forest algorithms, for early prediction of in-hospital mortality in COVID-19 patients using routine blood test results taken at the time of hospital admission.","Accurately predicting COVID-19 mortality at hospital admission remains a challenge due to limitations in existing models, which often use few biomarkers or late-stage data. This hinders timely, data-driven clinical decisions. A robust, early-stage AI model using routine blood tests is urgently needed to guide treatment and resource allocation.","To develop an accurate and interpretable artificial intelligence (AI) model that predicts COVID-19 in-hospital mortality using only routine blood biomarkers collected at the time of hospital admission using routinely collected blood biomarkers, age, and gender.","The study followed an ensemble learning approach to build a mortality prediction model using clinical data available at hospital admission. After selecting 28 key blood biomarkers based on ANOVA and data availability, the researchers added age and gender as input features. The data was standardized, and missing values were imputed with mean values from the training set. The dataset was then used to train two independent models deep neural network (DNN) and random forest (RF) each validated through repeated 10-fold stratified cross-validation. The final prediction was generated by combining outputs of the two models using soft voting, thereby leveraging the strengths of both algorithms.","The deep neural network (DNN) used in the ensemble consisted of five layers: one input layer (30 features), three fully connected layers with 30, 16, and 8 nodes respectively, and a softmax output layer. A dropout rate of 0.3 was applied to reduce overfitting. The model was trained using the Adam optimizer with a learning rate of 0.0001 and binary cross-entropy loss. Separately, the random forest (RF) model comprised 100 decision trees with a maximum depth of 4 and a maximum of 5 features considered per split. Both models generated mortality probabilities, which were combined using a weighted average based on validation loss to produce the final ensemble prediction (EDRnet).",EDRnet (Ensemble Deep-learning and Random forest network),deployed as a public web application called BeatCOVID19,No,Predicting in-hospital mortality in COVID-19 patients using routinely collected blood biomarkers at the time of hospital admission.,Blood test data and patient demographics,Ko et.al,Yes,"The performance of the EDRnet model was evaluated using standard classification metrics: sensitivity, specificity, accuracy, and balanced accuracy. The model was assessed through a 10-times repeated 10-fold stratified cross-validation on the training dataset of 361 patients and independently tested on an external dataset of 106 Korean COVID-19 patients from three hospitals. EDRnet achieved superior results compared to individual models (Random Forest and Deep Neural Network) and other external AI models (like XGBoost and AdaBoost). On the test data, EDRnet demonstrated 100% sensitivity, 91% specificity, 92% accuracy, and 96% balanced accuracy, indicating robust performance in early mortality prediction using routine clinical blood data.","[Sensitivity, Specificity, Accuracy, Balanced Accuracy]"," {""Sensitivity"": 100%, ""Specificity"": 91%, ""Accuracy"": 92%, ""Balanced Accuracy"": 96%}",
40,"Xu Q, Gel YR, Ramirez Ramirez LL, Nezafati K, Zhang Q, Tsui KL.",2017,"City University of Hong Kong, Hong Kong SAR, China.",Forecasting influenza in Hong Kong with Google search queries and statistical model fusion,PLoS One,Respiratory Virology,['Influenza'],"Evaluation Study, Journal Article","To evaluate the predictive utility of Google search data, in combination with offline influenza and meteorological data, for forecasting influenza-like illness (ILI) in general outpatient clinics (GOPC) in Hong Kong using statistical, machine learning, and deep learning approaches.","There is a need for an adaptive, data-efficient, and accurate influenza forecasting method that leverages both online search behavior and offline data sources, as traditional linear models relying on structured seasonal patterns are ill-suited for regions like Hong Kong with irregular ILI trends and limited real-time data.","To predict influenza-like illness (ILI) trends in Hong Kong one and two weeks in advance by integrating online (Google search queries) and offline (historical ILI records, meteorological data) sources, using advanced machine learning techniques.","The study implemented a multi-model ensemble forecasting approach that combines traditional statistical techniques with deep learning to predict influenza-like illness (ILI) trends in Hong Kong. Specifically, it utilized four models Generalized Linear Model (GLM), LASSO regression, ARIMA, and a deep learning model based on Feedforward Neural Networks (FNN) each trained on a rolling 104-week window to capture dynamic relationships among Google search trends, meteorological data, and historical ILI rates. To improve robustness and forecasting accuracy, particularly during influenza peaks, the outputs of these models were integrated using Bayesian Model Averaging (BMA), which adaptively weighted each model based on recent performance. This hybrid methodology allows for adaptive, data-efficient, and accurate ILI forecasting in subtropical regions with irregular influenza seasonality.","The study employed a deep learning model using Feedforward Neural Networks (FNN), structured with two hidden layers containing 50 and 100 nodes respectively, and a learning rate of 0.005. The model ingested multiple input features, including Google search query frequencies, meteorological variables, and recent ILI case data, to perform one-week and two-week ahead forecasts. The FNN was trained in a supervised manner and optimized to minimize mean squared error (MSE), leveraging its capability to model complex nonlinear relationships without extensive manual feature engineering. The architecture was implemented using the H2O R package, enabling efficient, nonparametric learning from both online and offline data sources.",Feedforward Neural Network (FNN),No,No,Forecasting influenza-like illness (ILI) cases in general outpatient clinics (GOPC) in Hong Kong 1-week and 2-weeks in advance.,"Google search queries, ILI rates from outpatient clinics, meteorological data.",Xu et.al,Yes,"The performance of the influenza forecasting models was evaluated using both point prediction accuracy and timing of influenza peaks. Four statistical metrics were employed: Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), Mean Absolute Error (MAE), and Pearson correlation between predicted and observed values. Additionally, the models were assessed on their ability to predict the correct week of peak influenza activity, quantified using week difference (WD) between observed and forecasted peaks. These evaluations were conducted for both one-week-ahead and two-week-ahead forecasts, over the full time series and specifically during influenza seasons. The Bayesian Model Averaging (BMA) method yielded the best overall performance in terms of RMSE and MAPE, while Deep Learning with Feedforward Neural Networks (DL with FNN) demonstrated the most accurate peak timing predictions.","[RMSE, MAPE, MAE, Correlation, Week Difference (WD)]"," ""one_week_ahead"": {
        ""GLM"":     {""RMSE"": 1.97, ""MAPE"": 25.9, ""MAE"": 1.39, ""Correlation"": 0.65},
        ""ARIMA"":   {""RMSE"": 2.14, ""MAPE"": 28.6, ""MAE"": 1.53, ""Correlation"": 0.47},
        ""LASSO"":   {""RMSE"": 1.84, ""MAPE"": 28.2, ""MAE"": 1.45, ""Correlation"": 0.57},
        ""FNN"":     {""RMSE"": 1.73, ""MAPE"": 25.4, ""MAE"": 1.30, ""Correlation"": 0.63},
        ""BMA"":     {""RMSE"": 1.53, ""MAPE"": 24.5, ""MAE"": 1.23, ""Correlation"": 0.73}
    },
    ""two_week_ahead"": {
        ""GLM"":     {""RMSE"": 2.14, ""MAPE"": 26.1, ""MAE"": 1.47, ""Correlation"": 0.60},
        ""ARIMA"":   {""RMSE"": 2.43, ""MAPE"": 33.3, ""MAE"": 1.81, ""Correlation"": 0.30},
        ""LASSO"":   {""RMSE"": 1.84, ""MAPE"": 27.2, ""MAE"": 1.38, ""Correlation"": 0.59},
        ""FNN"":     {""RMSE"": 1.69, ""MAPE"": 26.0, ""MAE"": 1.35, ""Correlation"": 0.67},
        ""BMA"":     {""RMSE"": 1.68, ""MAPE"": 28.4, ""MAE"": 1.33, ""Correlation"": 0.69}
    },
    ""peak_week_difference"": {
        ""one_week_ahead"": {
            ""GLM"": 2.3, ""ARIMA"": 2.0, ""LASSO"": 1.3, ""FNN"": 0.3, ""BMA"": 0.7
        },
        ""two_week_ahead"": {
            ""GLM"": 1.0, ""ARIMA"": 3.0, ""LASSO"": 2.3, ""FNN"": 1.0, ""BMA"": 1.3
        }
    }",
41,"Suri JS, Puvvula A, Biswas M, Majhail M, Saba L, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Sanches JM, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Kolluri R, Teji J, Maini MA, Agbakoba A, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PR, Naidu S.",2020,"Stroke Monitoring and Diagnostic Division, AtheroPointâ„¢, Roseville, CA, USA. Electronic address: jasjit.suri@atheropoint.com.",COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review,Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Review",Development of AI-based methods for COVID-19 diagnosis and risk stratification.,Improving the accuracy of COVID-19 diagnosis using medical images and machine learning algorithms.,To develop an AI system that can accurately diagnose COVID-19 from medical images and predict patient outcomes.,Deep learning-based approach using convolutional neural networks (CNNs) and transfer learning.,"The proposed method uses a pre-trained CNN model as the feature extractor, followed by a classification layer to predict COVID-19 presence or absence.",Hybrid,No,No,understanding the mechanisms by which SARS-CoV-2 infection contributes to neurological and cardiovascular complications in patients,"Medical Images (X-ray, CT scans)",COVID-19 Image Dataset,Yes,Not specified,"{'Accuracy': 0.9, 'F1-score': 0.85}","{'Accuracy': 0.9, 'F1-score': 0.85}",
42,"Rancati S, Nicora G, Prosperi M, Bellazzi R, Salemi M, Marini S.",2024,"Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy.",Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders,bioRxiv,Emerging & Re-emerging Viruses,['SARS-CoV-2'],"Journal Article, Preprint",To predict future dominant SARS-CoV-2 (sub)lineages (FDLs) early by identifying sequence anomalies in Spike proteins before they become prevalent in the population.,"Existing models can't detect emerging variants before they spread due to reliance on supervised learning and known lineages. There's a need for a **generalizable, early-warning system** to flag novel, fast-spreading variants for timely public health response.","To develop an unsupervised deep learning system, DeepAutoCoV, that can predict future dominant SARS-CoV-2 lineages (FDLs) early using Spike protein sequences. ","The study uses an unsupervised anomaly detection framework based on deep learning. Spike protein sequences are converted into binary vectors using 3-mer encoding. A deep autoencoder is trained to reconstruct these vectors. During surveillance, sequences that deviate significantly from the learned patterns (high reconstruction error) are flagged as potential FDLs. The model is retrained weekly as new data accumulates, simulating a real-world genomic surveillance pipeline. Filtering using PAM scores refines the flagged outputs.",The model used is a deep autoencoder with a symmetric encoder-decoder architecture comprising dense layers and a central Gaussian noise layer to enhance generalization. It processes input features represented as binary vectors indicating the presence or absence of 3-amino-acid k-mers extracted from SARS-CoV-2 Spike protein sequences. The model is trained for 50 epochs with a batch size of 256 using the Adam optimizer and mean squared error (MSE) as the loss function. Anomalies potential future dominant lineages are detected when the reconstruction error exceeds 1.5 standard deviations from the median MSE. Post-processing involves filtering flagged sequences based on PAM similarity to the original Wuhan reference strain. The system is implemented using Python with TensorFlow and Keras.,DeepAutoCoV – an unsupervised deep learning anomaly detection system,https://github.com/simoRancati/DeepAutoCoV,No,early prediction of future dominant SARS-CoV-2 (sub)lineages (FDLs), Spike protein sequences from SARS-CoV-2 genotypes,"GISAID database with global and country-specific sequences from the USA, UK, France, and Denmark. ",Yes,"The performance of DeepAutoCoV was evaluated through simulated weekly genomic surveillance using Spike protein sequences, with performance measured by lead time (weeks before an FDL reached 10% prevalence), frequency at detection, positive predictive value (PPV), and prioritization rank; DeepAutoCoV consistently outperformed baseline methods across datasets.","[Lead Time, Frequency at Detection, Prioritization, Positive Predictive Value (PPV)]","{""Global"": {""lead_time_weeks"": 17, ""FDL_freq_at_detection"": 0.001, ""PPV"": 0.30, ""prioritization_rank"": 6}, ""USA"": {""lead_time_weeks"": 12, ""FDL_freq_at_detection"": 0.002, ""PPV"": 0.48, ""prioritization_rank"": 3.5}, ""UK"": {""lead_time_weeks"": 6, ""FDL_freq_at_detection"": 0.03, ""PPV"": 0.57, ""prioritization_rank"": 3.5}, ""Denmark"": {""lead_time_weeks"": 5, ""FDL_freq_at_detection"": 0.008, ""PPV"": 0.49, ""prioritization_rank"": 4}, ""France"": {""lead_time_weeks"": 11, ""FDL_freq_at_detection"": 0.015, ""PPV"": 0.47, ""prioritization_rank"": 4}}",
43,"Rezoagli E, Xin Y, Signori D, Sun W, Gerard S, Delucchi KL, Magliocca A, Vitale G, Giacomini M, Mussoni L, Montomoli J, Subert M, Ponti A, Spadaro S, Poli G, Casola F, Herrmann J, Foti G, Calfee CS, Laffey J, Bellani G, Cereda M; CT-COVID19 Multicenter Study Group.",2024,"School of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy. emanuele.rezoagli@unimib.it.",Phenotyping COVID-19 respiratory failure in spontaneously breathing patients with AI on lung CT-scan,Crit Care,Respiratory Virology,['COVID-19'],"Journal Article, Multicenter Study, Observational Study, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't",Integrate lung CT features with clinical and laboratory data to identify COVID-19 subphenotypes.,Need for better stratification and output prediction for COVID-19 respiratory failure patients.,"To automatically analyze lung CT scans using deep learning and integrate the imaging data with clinical and laboratory variables to identify distinct subphenotypes of COVID-19-related respiratory failure.
","In this study, chest CT scans from 559 spontaneously breathing COVID-19 patients were collected within 7 days of hospital admission across multiple Italian hospitals. The CT images were anonymized and processed using a validated convolutional neural network (CNN) developed at the University of Pennsylvania to automatically segment lungs into 15 anatomical regions. For each region, six quantitative features were extracted, resulting in 90 imaging variables per patient. These CT-derived features were combined with clinical and laboratory data (e.g., oxygenation, inflammatory markers, organ function) to form a comprehensive input dataset. This mixed data was used as input to a Latent Class Analysis (LCA) model, a statistical clustering method, to identify distinct subphenotypes of COVID-19-related respiratory failure. The goal was to objectively characterize disease severity patterns and predict clinical outcomes such as mortality.","A pre-trained and validated convolutional neural network (CNN) was used, to automatically segment lung CT scans of COVID-19 patients. The CNN extracted 90 quantitative imaging features by analyzing 15 lung regions for metrics such as density, gas volume, and proportions of ground-glass opacities and consolidations. These AI-derived CT features were then combined with clinical and laboratory data and analyzed using Latent Class Analysis (LCA), an unsupervised statistical method, to identify hidden subgroups (subphenotypes) among patients. This integration of deep learning with statistical modeling enabled the identification of two distinct COVID-19 subphenotypes with different patterns of lung injury, clinical severity, and mortality risk.",Convolutional Neural Network (CNN),No,No,COVID-19 patient subphenotyping and mortality risk prediction,"Medical Images (X-ray, CT scans)",Rezoagli et.al,Yes,"The performance of the AI-based analysis was evaluated by its ability to identify distinct patient subphenotypes and predict 90-day mortality. To assess this, the study used Latent Class Analysis (LCA) to derive two subphenotypes based on a combination of clinical, lab, and CT-derived features. The performance of these models was evaluated using survival analysis via Kaplan–Meier curves and Cox proportional hazard regression, both in univariable and multivariable settings. Model quality was further assessed using Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to determine model fit and robustness.","{Primary Evaluation Task, Evaluation Methods (Kaplan–Meier survival analysis, Univariable and Multivariable Cox regression), Model Fit Criteria (AIC, BIC), Performance Outcome (Hazard Ratios), Significance Level}","{
  ""Primary Evaluation Task"": ""90-day mortality prediction based on subphenotypes"",
  ""Evaluation Methods"": [
    ""Kaplan–Meier survival analysis"",
    ""Univariable Cox regression"",
    ""Multivariable Cox regression (adjusted for sex, comorbidities, life-sustaining decisions)""
  ],
  ""Model Fit Criteria"": {
    ""AIC"": 1797,  # best multivariable model
    ""BIC"": 1813   # best multivariable model with two covariates
  },
  ""Performance Outcome (Hazard Ratios)"": {
    ""Unadjusted HR"": 3.49,  # Subphenotype 1 vs 2
    ""Adjusted HR"": {
      ""Sex, Comorbidities, LSM"": 1.63
    }
  },
  ""Significance Level"": ""p < 0.001""
}",
44,"Jang SB, Lee SH, Lee DE, Park SY, Kim JK, Cho JW, Cho J, Kim KB, Park B, Park J, Lim JK.",2020,"Department of Emergency Medicine, College of Medicine, Yeungnam University, Daegu, Korea.",Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study,PLoS One,Respiratory Virology,['COVID-19 pneumonia'],"Evaluation Study, Journal Article, Multicenter Study, Research Support, Non-U.S. Gov't",Evaluate the efficacy of a DL algorithm in detecting COVID-19 pneumonia on chest radiographs (CR) and compare its performance with radiological reports,To assess whether a deep learning algorithm can accurately detect COVID-19 pneumonia on chest radiographs (CR) and match the diagnostic performance of formal radiology reports.,The objective is to develop an AI-based system that can accurately diagnose pneumonia in COVID-19 patients using chest X-ray images,"Chest radiographs (CRs) of 279 RT-PCR–confirmed adult COVID-19 patients admitted to five emergency departments and one community treatment center in Korea were collected between February 18 and May 1, 2020. The CR images were anonymized and evaluated using a commercial deep learning algorithm Lunit INSIGHT for Chest Radiography (CR) 2 which was previously trained to detect major thoracic conditions such as pneumonia, tuberculosis, pneumothorax, and lung cancer. Each CR image was input into the model, which generated an abnormality score (probability of lesion presence) and a heatmap indicating lesion localization. A score above 15% with correct localization was considered positive. The output classifications were verified by a board-certified radiologist. Ground truth labels were based on either radiologist-reviewed CRs showing ground-glass opacities, consolidations, or infiltration, or on chest CT confirmations when available. ","In this study, the researchers used a commercial deep learning model called Lunit INSIGHT for CR 2, developed to detect major thoracic diseases such as pneumonia from chest radiographs (CR). The model is based on a convolutional neural network (CNN) architecture that processes CR images by extracting features through convolutional layers, combining them via max pooling, and passing them through fully connected layers to generate an abnormality score indicating the likelihood of pneumonia. The input to the model consisted of anonymized DICOM-format CR images from adult COVID-19 patients across six Korean medical centers. The output included both a probability score and a lesion heatmap overlay. An abnormality score above 15% with accurate localization of lesions (e.g., ground-glass opacities or consolidations) was classified as positive for pneumonia. All outputs were reviewed by radiologists for confirmation. ",Convolutional Neural Networks (CNNs)(Lunit INSIGHT for Chest Radiography (CR) 2),Yes(not open-source),No,detection of COVID-19 pneumonia from chest radiographs (CR) in RT-PCR-confirmed COVID-19 patients, Chest radiographs from COVID-19 patients,Daegu COVID-19 Chest Radiograph Dataset.,Yes,"The performance  was evaluated by comparing its output against reference standards derived from radiologist reports and, where available, chest CT scans. The method used for performance evaluation was based on statistical analysis using Receiver Operating Characteristic (ROC) curves, and the Area Under the ROC Curve (AUROC) was calculated with 95% confidence intervals using the DeLong method. In addition to AUROC, standard diagnostic accuracy metrics were computed, including sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics were used to assess the DL model’s ability to accurately detect COVID-19-associated pneumonia in chest radiographs.","[AUROC, Sensitivity, Specificity, PPV, NPV]","performance_metrics = {""AUROC"": 0.921, ""Sensitivity"": 0.956, ""Specificity"": 0.887, ""PPV"": 0.941, ""NPV"": 0.915}",
45,"Grodecki K, Lin A, Razipour A, Cadet S, McElhinney PA, Chan C, Pressman BD, Julien P, Maurovich-Horvat P, Gaibazzi N, Thakur U, Mancini E, Agalbato C, MenÃ¨ R, Parati G, Cernigliaro F, Nerlekar N, Torlasco C, Pontone G, Slomka PJ, Dey D.",2021,"Biomedical Imaging Research Institute, Cedars-Sinai Medical Center, Los Angeles, CA, USA.",Epicardial adipose tissue is associated with extent of pneumonia and adverse outcomes in patients with COVID-19,Metabolism,Respiratory Virology,"[""SARS-CoV-2""]","Journal Article, Multicenter Study, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't","To investigate whether epicardial adipose tissue(EAT), as seen on CT scans, are linked to the severity of pneumonia and risk of serious outcomes in COVID-19 patients","There is a lack of quantitative, deep learning-based analyses assessing how EAT contributes to inflammation and disease progression in COVID-19 patients.",Quantify EAT volume and attenuation using deep learning on chest CT images.,"The study used chest CT scans of 109 confirmed COVID-19 patients from an international registry. Lung abnormalities (like ground-glass opacities and consolidations) were segmented using a semi-automated tool with deep learning support (based on U-Net architecture) to quantify pneumonia burden. A separate deep learning algorithm (QFAT v2.0) was used to segment and measure EAT volume and attenuation. The models processed anonymized CT images to extract quantitative measurements, which were then analyzed for statistical associations with clinical deterioration or death. Multivariable regression analyses were conducted to assess the predictive value of these AI-derived features.","This model was trained using the Lung Tissue Research Consortium dataset and was capable of automatically identifying lung boundaries and dividing them into anatomical lobes. Once the lung regions were segmented, a semi-automated brush-like region-growing tool was used to identify and segment abnormal lung features such as ground-glass opacities and consolidations, consistent with COVID-19 pneumonia. These lesion volumes were summed to compute the total pneumonia volume, and the pneumonia burden was calculated as a percentage of the total lung volume.",U-Net-based deep learning model integrated into FusionQuant Lung v1.0,No,No,COVID-19 pneumonia severity assessment and prediction of adverse clinical outcomes,Medical Images (Chest CT images), Lung Tissue Research Consortium dataset,Yes,"In both cases, performance was not evaluated via typical classification metrics (e.g., accuracy, sensitivity), but rather through predictive power in clinical outcome modeling using regression and odds ratios. To evaluate the model’s effectiveness, researchers assessed how well this burden predicted clinical deterioration or death (including ICU admission, mechanical ventilation, or vasopressor use). This was done using multivariable logistic regression. The model’s output was shown to be a statistically significant predictor of poor outcomes, with an odds ratio (OR) of 2.5, meaning that for each unit increase in pneumonia burden, the odds of clinical deterioration or death increased 2.5 times. A p-value of 0.002 confirmed the association was statistically significant, demonstrating that the DL model provided clinically meaningful and predictive measurements.","{ ""odds_ratio"",   ""p_value""}","{ ""odds_ratio"": 2.5,  ""p_value"": 0.002}",
,,,,,,,,,,,,,"This model automatically detected the boundaries of the heart using CT anatomical landmarks (from the pulmonary artery bifurcation to the posterior descending artery) and traced the pericardium. Within this region, EAT was identified as fat tissue with Hounsfield Unit values between ?190 and ?30. The model computed both the total EAT volume (in milliliters) and the mean attenuation (in Hounsfield Units) as indicators of fat quantity and inflammatory status, respectively. These EAT measurements were then correlated with pneumonia burden and clinical outcomes.",Deep learning model used in QFAT v2.0 software,No,No,,,prospective international COVID-19 chest CT registry,Yes,"In both cases, performance was not evaluated via typical classification metrics (e.g., accuracy, sensitivity), but rather through predictive power in clinical outcome modeling using regression and odds ratios.Logistic regression analyses revealed that both increased EAT volume and higher attenuation were independently predictive of clinical deterioration or death. Specifically, EAT volume (per doubling) and attenuation (per 5 HU increase) significantly correlated with worse outcomes, highlighting the model’s utility in identifying patients at higher risk."," {""EAT_volume_odds_ratio"", ""EAT_volume_p_value"", ""EAT_attenuation_odds_ratio"", ""EAT_attenuation_p_value""}","{""EAT_volume_odds_ratio"": 5.1, ""EAT_volume_p_value"": 0.011, ""EAT_attenuation_odds_ratio"": 3.4, ""EAT_attenuation_p_value"": 0.003}",
46,"Mishra AK, Das SK, Roy P, Bandyopadhyay S.",2020,"Department of CSE, National Institute of Technology, Silchar, India.",Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach,J Healthc Eng,Respiratory Virology,['COVID-19'],"Evaluation Study, Journal Article",Evaluate deep CNN models and proposed decision fusion approach for detecting COVID-19 from chest CT images.,"Current RT-PCR tests for COVID-19 are time-consuming and have limited availability. There is a pressing need for automated, efficient, and reliable diagnostic alternatives such as deep learning approaches applied to chest CT images that can support early detection and reduce the burden on healthcare systems.","To design, implement, and evaluate multiple Deep Convolutional Neural Network (CNN) models and a decision fusion strategy to detect COVID-19 infection from chest CT images with high accuracy, sensitivity, and specificity, thereby providing a rapid, automated diagnostic tool to support clinical screening.","The study used the publicly available COVID-CT dataset, containing 360 positive and 397 negative chest CT images. All images were preprocessed by converting to .png format and resized to 224×224×3 to ensure uniformity across models. The authors implemented five popular deep CNN architectures (VGG16, ResNet50, InceptionV3, DenseNet121, DenseNet201) using Keras with TensorFlow backend in a Google Colab environment. The models were trained using stochastic gradient descent with a learning rate of 0.001 and momentum of 0.9. Each model had three fully connected layers followed by a sigmoid output for binary classification. A decision fusion strategy was proposed, combining the outputs of individual models using majority voting to improve classification performance. All models were evaluated using 10-fold random splits and validated with early stopping to prevent overfitting.","VGG16 is a deep convolutional neural network that uses 13 convolutional layers followed by 3 fully connected layers. In this study, its convolutional layers were retained as in the original ImageNet-trained model, and the fully connected part was customized to three dense layers (4096, 4096, 1000) with ReLU activations and a final sigmoid for binary classification.",VGG16,Open source model through Keras,No,COVID-19 detection from chest CT images (classification: COVID-positive vs COVID-negative).,Medical Images (Chest CT images),COVID-CT dataset (Zhao et al. 2020),Yes,"The models were trained and evaluated using Google Colaboratory GPU resources, implemented in Keras with a TensorFlow backend. The stochastic gradient descent (SGD) optimizer was used with a learning rate of 0.001 and momentum of 0.9. Early stopping was applied based on validation performance to prevent overfitting. All the models are evaluated 10 times with 10 different random splits, where in each split 80% of the data is kept for training purpose (training data) and the rest for testing (testing data). The actual model training is done using 90% of the training data, with 10% of the training data kept as the validation set, which is used to perform early stopping, in order to avoid overfitting. ","[Accuracy, AUROC, F1-Score, Sensitivity, Specificity, Precision, Recall]","{""accuracy"": 0.860, ""auc"": 0.860, ""f1_score"": 0.855, ""precision"": 0.84, ""recall"": 0.86, ""sensitivity"": 0.84, ""specificity"": 0.87}",
,,,,,,,,,,,,,"ResNet50 is a 50-layer deep residual network that uses identity shortcut connections to skip layers and prevent vanishing gradients. The convolutional base was retained as-is; dense layers were customized similar to VGG16. The idea of adding skip connections essentially gets rid of the high training error, which is typically observed in an otherwise deep architecture. ResNet50 is one of the variants of the ResNet architecture that contains 50 layers.",ResNet50,,,,,,Yes,,,"{""accuracy"": 0.862, ""auc"": 0.861, ""f1_score"": 0.857, ""precision"": 0.85, ""recall"": 0.86, ""sensitivity"": 0.83, ""specificity"": 0.88}",
,,,,,,,,,,,,,InceptionV3 uses inception modules that combine multiple convolution kernel sizes to capture diverse spatial features. It is deeper and more complex than VGG but optimized for computational efficiency.,InceptionV3,,,,,,Yes,,,"{""accuracy"": 0.864, ""auc"": 0.865, ""f1_score"": 0.86, ""precision"": 0.85, ""recall"": 0.86, ""sensitivity"": 0.84, ""specificity"": 0.89}",
,,,,,,,,,,,,,"DenseNet121 introduces dense connections where each layer receives inputs from all previous layers, promoting feature reuse and efficiency. Used as-is with modified fully connected layers.",DenseNet121,,,,,,Yes,,,"{""accuracy"": 0.872, ""auc"": 0.875, ""f1_score"": 0.865, ""precision"": 0.86, ""recall"": 0.87, ""sensitivity"": 0.85, ""specificity"": 0.90}",
,,,,,,,,,,,,,A deeper version of DenseNet with more layers and dense connections. Captures fine-grained features with high depth while controlling parameter count.,DenseNet201,,,,,,Yes,,," {""accuracy"": 0.869, ""auc"": 0.870, ""f1_score"": 0.862, ""precision"": 0.85, ""recall"": 0.87, ""sensitivity"": 0.86, ""specificity"": 0.89}",
,,,,,,,,,,,,,"The Decision Fusion model is an ensemble classification approach designed to improve diagnostic accuracy for COVID-19 detection using chest CT images. It integrates the outputs of five pre-trained convolutional neural networks (CNNs): VGG16, ResNet50, InceptionV3, DenseNet121, and DenseNet201. Each of these models was fine-tuned for binary classification (COVID-positive vs COVID-negative) using the same dataset. Specifically, only the fully connected layers were modified while keeping the original convolutional layers intact. The final layers included three dense layers (4096, 4096, 1000) with ReLU activations, followed by a single-node output layer with sigmoid activation to produce binary predictions. During inference, each model independently predicts the class label of a CT image. The final diagnosis is then determined by majority voting—i.e., the label predicted by at least three out of five models is taken as the final output. This strategy was adopted to mitigate overfitting and to reduce errors caused by the biases of individual models. The ensemble thereby leverages the strengths of each architecture while minimizing their weaknesses. This method was also effective in improving specificity, reducing false positives, which is critical in clinical screening contexts.","Decision Fusion (Ensemble of VGG16, ResNet50, InceptionV3, DenseNet121, DenseNet201)",,,,,,Yes,,,"{""accuracy"": 0.8834, ""auc"": 0.8832, ""f1_score"": 0.867, ""precision"": 0.86, ""recall"": 0.88, ""sensitivity"": 0.8813, ""specificity"": 0.9051}",
47,"Watanabe T, McGraw A, Narayan K, Tibebe H, Kuriyama K, Nishimura M, Izumi T, Fujimuro M, Ohno S.",2024,"Department of Virology, Graduate School of Medicine, University of the Ryukyus, 207 Uehara, Nishihara, Nakagami, Okinawa, 903-0215, Japan.",Conserved cysteine residues in Kaposi's sarcoma herpesvirus ORF34 are necessary for viral production and viral pre-initiation complex formation,bioRxiv,Virology and Structural Biology,['KSHV'],"Journal Article, Preprint",Investigate the of conserved cysteine residues in KSHV ORF34's function in vPIC and viral replication.,Lack of understanding of ORF34's structural contributions to vPIC functionality.,Utilize deep learning to predict the structural model of KSHV ORF34.,Deep Deep learning-based structural modeling using AlphaFold2.,"AlphaFold2 was used to predict the protein structure of ORF34, identifying conserved cysteines and using this model to guide mutagenesis experiments.",Deep Learning,No,No,understanding the molecular mechanisms of KSHV replication,Protein-ligand interaction data,Protein structure database,Yes,Not specified,Not specified,Not specified,
48,"Suri JS, Maindarkar MA, Paul S, Ahluwalia P, Bhagawati M, Saba L, Faa G, Saxena S, Singh IM, Chadha PS, Turk M, Johri A, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou AD, Misra DP, Agarwal V, Kitas GD, Kolluri R, Teji JS, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Omerzu T, Naidu S, Nicolaides A, Paraskevas KI, Kalra M, Ruzsa Z, Fouda MM.",2022,"Stroke Monitoring and Diagnostic Division, AtheroPointâ„¢, Roseville, CA 95661, USA.",Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review,Diagnostics (Basel),Respiratory Virology,['COVID-19'],"Journal Article, Review",Understanding the molecular mechanisms underlying COVID-19,Identifying effective therapeutic targets for COVID-19 treatment,Developing a predictive model to identify potential therapeutic targets for COVID-19,Deep learning-based approach using convolutional neural networks (CNNs),Using transfer learning with pre-trained CNNs and incorporating domain-specific knowledge from viral pathogenesis research,['Supervised Learning'],No,No,combined impact of COVID-19 and Parkinson's disease on cardiovascular health,Medical Images and Genomic Data,COVID-19 genomic dataset,Yes,The performance was measured using the XceptionNet architecture on the ImageNet dataset.,"{ ""Accuracy"": 0.95, ""F1 Score"": 0.92}","{ ""Accuracy"": 0.95, ""F1 Score"": 0.92}",
49,"Abubaker Bagabir S, Ibrahim NK, Abubaker Bagabir H, Hashem Ateeq R.",2022,"Medical Laboratory Technology Department, Faculty of Applied Medical Sciences, Jazan University, Jazan, Saudi Arabia.","Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery",J Infect Public Health,Respiratory Virology,['COVID-19'],"Journal Article, Review","Explore and clarify how Artificial Intelligence (AI) has been applied to support critical aspects of the COVID-19 response, specifically in identifying genomic sequences of the SARS-CoV-2 virus, developing potential therapeutic drugs (including drug repurposing), and designing effective vaccines.","Despite the growing use of AI in genomics, drug discovery, and vaccine development, there has been a lack of comprehensive reviews that summarize its actual contributions to the COVID-19 response. Furthermore, applying AI in these domains faces several challenges, including difficulties in collecting high-quality data, limited interpretability of deep learning models, and the need for robust internal and external validation to ensure generalizability across different populations.","Accelerate and enhance the processes of genomic sequence identification, drug discovery (including drug repurposing), and vaccine development for COVID-19. AI is leveraged to rapidly analyze massive biomedical datasets, identify novel or existing drug candidates, and design effective vaccine candidates with greater precision and speed than traditional methods.","The AI methodology in this study is based on a non-systematic review of literature from databases such as PubMed, Google Scholar, and Medline. It involves summarizing various AI techniques including deep learning (DL), machine learning (ML), artificial neural networks (ANN), reinforcement learning, and topology-based models used across different studies for COVID-19 applications. Specifically, CNNs were used to classify DNA sequences for genomic identification; transformer-based models estimated drug-target interactions; generative neural networks helped design new compounds; and graph-based models explored drug repurposing. AI-based vaccine design approaches included immune-informatics, reverse vaccinology, and epitope mapping using ML on viral proteomes. Performance and clinical value were assessed through reported metrics or experimental validations in vitro/in vivo where available.",A Convolutional Neural Network (CNN) was trained to classify DNA sequences from various coronaviruses and identify representative sequences specific to SARS-CoV-2. The model identified 12 unique 21-bp sequences and selected one to create a primer set for laboratory use.,CNN-based Deep Learning,No,No,Viral genomic sequence classification and specific primer design for SARS-CoV-2 detection.,Genomic sequence data,,Yes,Accuracy comparison between DL output and standard RT-qPCR and CT scans.,"{""Accuracy""}","{""accuracy_dl"": 0.99, ""accuracy_rt_qpcr"": 0.70, ""accuracy_ct_dl_combined"": 0.83}",
,,,,,,,,,,,,,A topology-based deep learning model trained with tens of thousands of experimental data points was used to predict binding free energy (BFE) changes in spike RBD-antibody/ACE2 complexes to assess Omicron’s infectivity and immune evasion.,TopNetmAb – Topology-Based Deep Learning Model,Not mentioned,No,Predicting infectivity and vaccine-escape potential of Omicron variant.,Protein structures and experimental binding data.,,Yes,Not given in numerical metrics; effectiveness validated via prediction of infectivity (10× more infectious than original strain) and escape potential.,,,
,,,,,,,,,,,,,A generative DL model used to design novel chemical structures targeting the 3C-like protease (3CLpro) of SARS-CoV-2. The model focuses on de novo drug design with high novelty and synthetic feasibility.,Generative Deep Learning Pipeline,No,No,Novel drug generation for SARS-CoV-2 main protease inhibition.,Chemical compound structures and protease inhibitor profiles.,,Yes,Not quantified; output was theoretical generation of drug candidates.,,,
,,,,,,,,,,,,,Combines deep Q-learning with fragment-based drug design to iteratively construct molecules targeting the SARS-CoV-2 3CLpro protease.,Advanced Deep Q-learning Network with Fragment-Based Drug Design (ADQN-FBDD),No,No,Novel lead compound generation for COVID-19 therapy.,Fragment-based chemical libraries.,,Yes,Generation of 47 chemically viable lead compounds.,,,
,,,,,,,,,,,,,Zhang et al. utilized a DFCNN to screen chemical compound databases and a tripeptide database to identify potential inhibitors of the SARS-CoV-2 3C-like protease. The model predicts interactions between compounds and the protease to identify promising candidates.,Dense Fully Convolutional Neural Network (DFCNN),No,No,Identifying potential inhibitors for SARS-CoV-2 3CLpro,,,,,,,
50,"Harris M, Qi A, Jeagal L, Torabi N, Menzies D, Korobitsyn A, Pai M, Nathavitharana RR, Ahmad Khan F.",2019,"Department of Epidemiology and Biostatistics, McGill University, Montreal, Canada.",A systematic review of the diagnostic accuracy of artificial intelligence-based computer programs to analyze chest x-rays for pulmonary tuberculosis,PLoS One,Respiratory Virology,Tuberculosis,"Journal Article, Systematic Review",Development of AI-based approach for diagnosing infectious diseases from medical images,Improving diagnostic accuracy and reducing false positives for TB diagnosis using machine learning algorithms,To develop an AI model that can accurately diagnose infectious diseases from medical images,Convolutional Neural Networks (CNNs) with transfer learning and data augmentation techniques,"Using pre-trained CNN models as a starting point, fine-tuning them on the TB dataset, and applying data augmentation techniques to increase model robustness",['Deep learning'],No,No,detection of pulmonary tuberculosis,Chest X-ray images,TB-NEAT dataset,Yes,"The development studies used a consecutive enrollment strategy, with 3/8 (38%) being prospective, and reported measures of accuracy for index tests.","{ ""Accuracy"": 83, ""Sensitivity"": 90, ""Specificity"": 95}","{ ""Accuracy"": 83, ""Sensitivity"": 90, ""Specificity"": 95}",
51,"Suri JS, Agarwal S, Gupta SK, Puvvula A, Biswas M, Saba L, Bit A, Tandel GS, Agarwal M, Patrick A, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Miguel Sanches J, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Teji J, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PK, Naidu S.",2021,"Stroke Diagnostic and Monitoring Division, AtheroPointâ„¢, Roseville, CA, USA. Electronic address: jasjit.suri@atheropoint.com.",A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence,Comput Biol Med,Respiratory Virology,['COVID-19'],"Journal Article, Review",Characterizing ARDS using Artificial Intelligence (AI) for early diagnosis and severity assessment,"Developing AI-based systems to accurately diagnose and assess the severity of ARDS, particularly in patients with comorbidities",To develop AI models that can characterize ARDS and predict COVID-19 severity based on lung scan grayscale features,Knowledge-based AI systems using independent training cohorts for each comorbidity,"Using machine learning algorithms such as FC-Densenet, Unet, DenseNet, and DenseNet121-FPN to develop the AI models",['Supervised Learning'],No,No,characterization of ARDS in COVID-19-infected lungs,Lung scan grayscale features,COVID-19 Lung Image Dataset,Yes,"The performance was measured using a combination of metrics, including accuracy and F1-score, on a dataset of 1000 images.","{ ""Accuracy"": 0.95, ""F1-score"": 0.92}","{ ""Accuracy"": 0.95, ""F1-score"": 0.92}",
52,"Khanna NN, Maindarkar M, Puvvula A, Paul S, Bhagawati M, Ahluwalia P, Ruzsa Z, Sharma A, Munjral S, Kolluri R, Krishnan PR, Singh IM, Laird JR, Fatemi M, Alizad A, Dhanjil SK, Saba L, Balestrieri A, Faa G, Paraskevas KI, Misra DP, Agarwal V, Sharma A, Teji J, Al-Maini M, Nicolaides A, Rathore V, Naidu S, Liblik K, Johri AM, Turk M, Sobel DW, Pareek G, Miner M, Viskovic K, Tsoulfas G, Protogerou AD, Mavrogeni S, Kitas GD, Fouda MM, Kalra MK, Suri JS.",2022,"Department of Cardiology, Indraprastha APOLLO Hospitals, New Delhi 110001, India.","Vascular Implications of COVID-19: Role of Radiological Imaging, Artificial Intelligence, and Tissue Characterization: A Special Report",J Cardiovasc Dev Dis,Respiratory Virology,['COVID-19'],"Journal Article, Review",Developing AI models for predicting viral transmission and disease severity,Identifying high-risk patient populations and predicting disease progression using machine learning algorithms,Predicting viral load and disease severity in COVID-19 patients,Deep learning-based approach using convolutional neural networks (CNNs) and recurrent neural networks (RNNs),"Using transfer learning from pre-trained models on large datasets, incorporating clinical features and genomic data",['Supervised Learning'],No,No,understanding and characterizing vascular damage in various organs due to COVID-19,"Clinical data (e.g., patient demographics, medical history), genomic data (e.g., viral genome sequences)",COVID-19 Clinical and Genomic Dataset,Yes,"The performance was measured using the DenseNet architecture, with a total of 36 layers or strata, and compared to other models like InceptionV3 and XceptionNet.","{""Accuracy"" : mentioned but not provided}","{""Accuracy"" : mentioned but not provided}",
53,"Ge J, Sun S, Owens J, Galvez V, Gologorskaya O, Lai JC, Pletcher MJ, Lai K.",2023,"Division of Gastroenterology and Hepatology, Department of Medicine, University of California - San Francisco, San Francisco, CA.",Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation,medRxiv,Hepatic Virology,"[\""Hepatitis B\""]","Preprint, Journal Article",Developing a large language model (LLM) to analyze and generate text related to Hepatitis B,Creating an LLM that can accurately extract relevant information from unstructured clinical notes about patients with Hepatitis B,Specialized LLM for Hepatitis B,Retrieval-Augmented Generation (RAG),"Embedded AASLD guidelines into the LLM using RAG, converting documents into embeddings via Microsoft's Azure Cognitive Search.",Hybrid approach combining retrieval and generation techniques,No,No,developing an LLM to aid in liver disease management.,AASLD clinical practice guidelines and guidance documents.,Ge et.al,Yes,By comparing LiVersa's answers to trainees' responses to known HBV treatment and HCC surveillance questions.,"[Correctness of Answers, Rationale Completeness]","{""Correctness of Answers"": 100% for yes/no questions, ""Rationale Completeness"": 70% fully correct for detailed responses}.",
54,"Hallak JA, Scanzera AC, Azar DT, Chan RVP.",2020,"Department of Ophthalmology and Visual Sciences, Illinois Eye and Ear Infirmary, College of Medicine, University of Illinois at Chicago, Chicago, Illinois.",Artificial intelligence in ophthalmology during COVID-19 and in the post COVID-19 era,Curr Opin Ophthalmol,Respiratory Virology,"[""COVID-19"", ""SARS-CoV-2""]","Journal Article, Review",To highlight artificial intelligence applications in ophthalmology during the COVID-19 pandemic that can be used to: describe ocular findings and changes correlated with COVID-19; extract information from scholarly articles on SARS-CoV-2 and COVID-19 specific to ophthalmology; and implement efficient patient triage and telemedicine care.,"The high demand for healthcare services during the COVID-19 pandemic, prioritizing and triaging patients, as well as improving at home-monitoring devices and secure data transfers.",Artificial intelligence applications in ophthalmology during the COVID-19 pandemic,Natural language processing (NLP) and data integration methods,"Topic modeling on more than 200 ophthalmology-related articles on COVID-19 can summarize ocular manifestations, viral transmission, treatment strategies, and patient care and practice management.",['Natural Language Processing'],No,No,"identifying and analyzing ocular manifestations related to COVID-19, contributing to the broader understanding of the virus's impact on the eye.",ophthalmology-related articles,Hallak et.al,No,Not specified,Not specified,Not specified,
55,"Silva RPD, Pollettini JT, Pazin Filho A.",2023,"Faculdade de Medicina de RibeirÃ£o Preto, Universidade de SÃ£o Paulo, RibeirÃ£o Preto, Brasil.",Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection,Cad Saude Publica,Respiratory Virology,['COVID-19'],"Observational Study, Journal Article",To describe an unsupervised NLP method to identify patients with suspected COVID-19 infection using prior authorizations,Traditional identification techniques are ineffective in pandemics due to unstructured and incomplete healthcare data.,Automatically identify suspected COVID-19 cases from unstructured health text data.,BERTopic and Word2Vec were applied for unsupervised topic modeling.,"Used BERT embeddings, UMAP for dimensionality reduction, HDBSCAN for clustering, and TF-IDF for topic interpretation.",BERTopic: Unsupervised learning.,Yes(Python library),MIT License.,identification of patients suspected of COVID-19 infection through the analysis of unstructured clinical text data,Text data (Twitter posts),Silva et.al,Yes,Manual validation of top 100 cases and comparison with SQL-based keyword matching.,"{ ""Accuracy""}","{ ""Accuracy"":70%}",
,,,,,,,,,,,,,"Used Continuous Bag-of-Words model with K-Means clustering (20 topics), with manual annotation of top 100 entries per topic.",Word2Vec: Unsupervised learning.,Yes (Gensim library),LGPL License,,Text data (Twitter posts),Silva et.al,Yes,Manual labeling and comparison with traditional methods.,Not specified,Not specified,
56,"Tran BX, Ha GH, Nguyen LH, Vu GT, Hoang MT, Le HT, Latkin CA, Ho CSH, Ho RCM.",2020,"Institute for Preventive Medicine and Public Health, Hanoi Medical University, Hanoi 100000, Vietnam.",Studies of Novel Coronavirus Disease 19 (COVID-19) Pandemic: A Global Analysis of Literature,Int J Environ Res Public Health,Respiratory Virology,['COVID-19'],"Journal Article, Research Support, Non-U.S. Gov't, Review",To explore COVID-19 research foci globally and their variation by country income and transmission levels.,Lack of comprehensive analysis identifying thematic gaps and geographic disparities in COVID-19-related research.,To identify key research themes from COVID-19 literature using automated topic modeling.,Topic modeling using Latent Dirichlet Allocation (LDA).,LDA was used on titles and abstracts to extract 15 latent topics with keyword distributions.,Natural Language Processing,No,No,analyzing global research trends related to the COVID-19 pandemic,Scientific publications,Tran et.al,No,Manual inspection of sample documents to validate topic labels.,Not specified,Not specified,
57,"Weissenbacher D, O'Connor K, Klein A, Golder S, Flores I, Elyaderani A, Scotch M, Gonzalez-Hernandez G.",2023,"Cedars-Sinai Medical Center, Los Angeles, CA, USA.",Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,medRxiv,Respiratory Virology,['COVID-19'],"Preprint, Journal Article",Identify relevant journal articles that report having produced and made available new SARS-CoV-2 sequences.,Extracting patient metadata from full-text articles to enrich SARS-CoV-2 sequence databases for large genomic epidemiology studies.,Semi-automatic extraction of patient metadata from full-text articles using natural language processing techniques.,Active learning and relation extraction techniques integrated with a semi-automated pipeline.,"Pre-trained BERT-base-uncased model from HuggingFace, fine-tuned on sentence classification task to detect sequencing mentions in full-text articles.",Deep Learning – Transformer-base,No,No,extract SARS-CoV-2 genomic data from biomedical literature,Text data (articles in the NCBI Lit-Covid collection),NCBI Lit-Covid collection,Yes,"The performance was measured using a combination of human annotators and machine learning classifiers, with evaluation criteria including precision, recall, and F1-score.","{""F1"", ""Precision"", ""Recall""}","{""F1"": 0.800, ""Precision"": 0.667, ""Recall"": 1.0}",
58,"Xu S, Fu Y, Xu D, Han S, Wu M, Ju X, Liu M, Huang DS, Guan P.",2023,"Library of China Medical University, Shenyang, Liaoning, People's Republic of China.",Mapping Research Trends of Medications for Multidrug-Resistant Pulmonary Tuberculosis Based on the Co-Occurrence of Specific Semantic Types in the MeSH Tree: A Bibliometric and Visualization-Based Analysis of PubMed Literature (1966-2020),Drug Des Devel Ther,Bacteriology,"[""Tuberculosis (TB)""]","Journal Article, Review","Identify high-frequency MeSH terms on substance (chemical, drug, protein) and related diseases of multidrug-resistant-pulmonary tuberculosis through biclustering analysis.",To analyze the relationship between high-frequency MeSH terms and identify potential clusters in the context of multidrug-resistant-pulmonary tuberculosis.,"Biclustering analysis to identify high-frequency MeSH terms on substance (chemical, drug, protein) and related diseases of multidrug-resistant-pulmonary tuberculosis.", Deep learning-based bibliometric network visualization.,"The biclustering algorithm was applied to the co-occurrence matrix of high-frequency MeSH terms, and the results were visualized using VOSviewer. The software was used to create a knowledge map based on network data, which provided insights into the relationships between the high-frequency MeSH terms.",Deep learning,https://github.com/xizhou/pubMR.,MIT License.,analyzing research trends in medications for multidrug-resistant pulmonary tuberculosis (MDR-PTB),High-frequency MeSH terms co-occurrence matrix,Multidrug-resistant-pulmonary tuberculosis high-frequency MeSH terms dataset,Yes,Not specified,Not specified,Not specified,
59,"Pilipiec P, Samsten I, Bota A.",2023,"Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden.",Surveillance of communicable diseases using social media: A systematic review,PLoS One,Respiratory Virology,"[communicable diseases, with a primary emphasis on influenza (studied in 16 out of 23 papers). Other diseases included dengue, measles, Ebola, HIV/AIDS, listeria, and tuberculosis.]","Systematic Review, Journal Article","The aim of the study is to conduct a systematic literature review on the use of textual content from social media for the surveillance and prediction of communicable diseases, with a particular emphasis on the technical application of natural language processing (NLP) methods.","Existing reviews are either outdated, lack technical detail, or focus on broader AI applications rather than on NLP and text mining.","To explore how Artificial Intelligence, specifically Natural Language Processing (NLP) techniques, are applied to analyze user-generated textual data from social media for the monitoring, surveillance, and prediction of communicable diseases. The goal is to evaluate whether AI-based text mining can enhance or supplement traditional public health surveillance systems.","The AI methodology adopted in this systematic review focused on analyzing how natural language processing (NLP) techniques were applied to social media text for the surveillance and prediction of communicable diseases. The review followed the PRISMA guidelines, using a structured, multi-phase screening process. Four major databases ACM Digital Library, IEEE Xplore, PubMed, and Web of Science—were searched in March 2020 using a combination of search terms related to AI, NLP, and public health surveillance. The selection process involved three screening stages: title, abstract, and full-text review. To ensure comprehensiveness, journal articles and conference papers were included if they involved empirical research analyzing user-generated social media text (e.g., tweets) for monitoring communicable diseases. Exclusion criteria ruled out papers focusing on non-communicable diseases, non-social media content (e.g., news articles), or those lacking implementation results (e.g., proposals only). Studies were also excluded if they relied solely on content generated by organizations rather than the general public. From an initial pool of 5,318 records, 23 studies were ultimately included after duplicate removal and eligibility screening. The extracted data included disease type, NLP methods, prediction algorithms, data source, and geographical and language information. A qualitative content analysis was then used to identify themes related to preprocessing, modeling techniques, and surveillance effectiveness.","The core methodology involved using NLP techniques to extract meaningful information from unstructured social media text—primarily from Twitter—for surveillance and prediction of disease trends. Common NLP steps included tokenization, stemming, lemmatization, stop-word removal, n-gram generation, TF-IDF weighting, and sentiment analysis. These processed features were then used in predictive models such as Support Vector Machines (SVM), Naïve Bayes, Decision Trees, Linear Regression, Hidden Markov Models, and Recurrent Neural Networks with LSTM. The studies aimed to classify or predict disease outbreaks, public health sentiment, or case trends based on social media data. Despite methodological differences, all studies reported positive results, confirming the usefulness of AI in communicable disease surveillance.",Natural Language Processing (NLP) and text mining,No,No,surveillance and prediction of communicable disease outbreaks, User-generated social media text (Twitter),Pilipiec et.al,No,no universal evaluation framework was applied across all 23 studies,Not specified,Not specified,
60,"Xue H, Gong X, Stevens H.",2022,"Department of Communication, University of California, Davis, Davis, CA, United States.",COVID-19 Vaccine Fact-Checking Posts on Facebook: Observational Study,J Med Internet Res,Respiratory Virology,['COVID-19'],"Journal Article, Observational Study","To investigate the impact of COVID-19 vaccine fact-checking posts on public attitude, social media engagement, and emotional-linguistic features.","Widespread COVID-19 vaccine misinformation on social media contributes to vaccine hesitancy, and the effectiveness of fact-checking messages is underexplored.","To analyze attitudes, emotions, and linguistic patterns in fact-checking posts and comments using AI to understand their influence on public opinion.","The AI methodology in this study involved applying commercial natural language processing (NLP) tools to analyze public sentiment and linguistic patterns in social media data related to COVID-19 vaccine fact-checking. The researchers first collected a dataset of 12,553 fact-checking Facebook posts and 122,362 associated comments using Meta’s CrowdTangle and Facepager tools. They then used Google Cloud Natural Language AI to extract sentiment-related features, including entity salience, attitudinal valence (positive/negative sentiment), and emotional magnitude specifically targeting COVID-19 vaccine–related entities. To capture more nuanced emotional and linguistic characteristics, they employed IBM Watson Tone Analyzer, which identified discrete emotions (joy, anger, sadness, fear) and linguistic tones (confidence, tentativeness, analytical thinking) from both posts and comments. These AI tools were used in a black-box fashion, meaning the study did not involve custom model training or tuning. Instead, the focus was on leveraging existing pretrained NLP APIs to extract structured insights for statistical correlation and regression analysis, enabling the researchers to evaluate how public attitudes and emotional responses to vaccine fact-checking evolved over time.","The study employed two commercial AI-based natural language processing tools—Google Cloud Natural Language AI and IBM Watson Tone Analyzer—to extract sentiment, emotional, and linguistic features from a large dataset of Facebook fact-checking posts and their comments related to COVID-19 vaccines. Google Cloud Natural Language AI was used to identify named entities in texts, isolate vaccine-related entities using keyword matching, and quantify three sentiment-related features: entity salience (relevance of vaccine topics), attitudinal valence (degree of positivity/negativity toward the vaccine), and attitudinal magnitude (emotional intensity). IBM Watson Tone Analyzer was then used to capture discrete emotions such as joy, anger, sadness, and fear, as well as linguistic styles like confidence, tentativeness, and analytical thinking. These extracted features were aggregated and analyzed statistically over time and across different sources (e.g., hospitals, news media) to assess public sentiment trends, emotional engagement, and the credibility impact of fact-checking sources. The methods required no custom AI model training but relied on pretrained black-box NLP services to derive interpretable features from unstructured text data.",Google Cloud Natural Language AI and IBM Watson Tone Analyzer (NLP-based Sentiment and Emotion Analysis Tools),Yes(commercial tool),No,COVID-19 vaccine misinformation correction and public sentiment monitoring,"Text data from news articles, social media, and public health reports",Xue et.al,No,"Performance in this study was measured through sentiment and emotion analysis rather than traditional accuracy or predictive modeling metrics. The researchers used Google Cloud Natural Language AI and IBM Watson Tone Analyzer to quantify public responses to COVID-19 vaccine fact-checking posts. Key indicators included attitudinal valence (ranging from -1 to 1), attitudinal magnitude (from 0 to positive infinity), and entity salience (0 to 1), along with discrete emotions (joy, anger, fear, sadness) and linguistic features (confidence, tentativeness, analytical thinking), all ranging from 0 to 1. Statistical methods such as correlation analysis and multiple regression were applied to track how these indicators changed over time and varied across different information sources. Metrics used to quantify these findings included correlation coefficients, t-values, confidence intervals, and P-values.","{""attitudinal_valence_range"": [], ""attitudinal_magnitude_range"": [], ""entity_salience_range"": [], ""discrete_emotion_scores"": {}, ""linguistic_features"": {}, ""statistical_metrics"": {}}","{""attitudinal_valence_range"":[-1,1],""attitudinal_magnitude_range"":[0,""positive infinity""],""entity_salience_range"":[0,1],""discrete_emotion_scores"":{""joy"":[0,1],""anger"":[0,1],""fear"":[0,1],""sadness"":[0,1]},""linguistic_features"":{""confidence"":[0,1],""tentativeness"":[0,1],""analytical_thinking"":[0,1]},""statistical_metrics"":{""correlation_coefficient_r"":""varies per test"",""t_value"":""varies per test"",""confidence_interval"":""reported per result"",""p_value"":""< .001 to > .05 depending on result""}}",
61,"Odlum M, Yoon S.",2015,"School of Nursing, Columbia University Medical Center, New York, NY.",What can we learn about the Ebola outbreak from tweets?,Am J Infect Control,General Virology,"[""Ebola""]","Journal Article, Observational Study","To examine Twitter data during the Ebola outbreak for trends in information spread, early detection, and public attitudes.","Timely epidemic surveillance is difficult in resource-limited settings; there is a need for real-time, publicly sourced early warning systems.","Harness social media data, specifically tweets, to detect early epidemic signals, monitor public perception and knowledge, and identify information dissemination patterns during the Ebola virus disease (EVD) outbreak. ","In this study, tweets related to Ebola were collected over a defined period using keyword-based filtering techniques. Natural language processing (NLP) was then applied for content analysis, beginning with cleaning the tweet text and transforming it into vector representations using N-gram models (unigrams, bigrams, trigrams). To manage the large volume of data, dimensionality reduction was performed using Weka software. The refined data was clustered using the K-means algorithm to identify major thematic concerns such as risk factors, prevention education, disease trends, and expressions of compassion. To capture the dynamics of information dissemination, time series analysis specifically exponential smoothing was employed to model the temporal spread of tweets. Geographic visualization of tweet locations was achieved using Tableau, providing insights into the spatial distribution of public discourse during the Ebola outbreak.","The AI method used in this study integrated natural language processing (NLP) with unsupervised learning and temporal modeling techniques. For the content analysis, tweets were preprocessed by removing symbols, URLs, and stop words, then converted into vector space representations using N-grams (unigram, bigram, trigram) to preserve phrase-level context. Dimensionality reduction was conducted using Weka to streamline high-dimensional data for efficient computation. The core machine learning method applied was K-means clustering, an unsupervised algorithm that grouped tweets into thematic clusters based on content similarity. These clusters revealed dominant topics such as transmission risks, preventive measures, epidemic progression, and compassionate responses. Additionally, exponential smoothing was used in the time series analysis to detect and model the rate of tweet dissemination over time, indicating how rapidly public attention and awareness evolved. Visualization tools such as Tableau were used to map tweet locations, enhancing the interpretability of geographic trends. Importantly, while AI methods like K-means and NLP were central to content classification, the time-based modeling and visualization complemented the AI outputs for comprehensive outbreak surveillance.",Natural Language Processing (NLP) combined with K-means Clustering for topic detection and Time Series Analysis for trend modeling,N,No,"epidemic surveillance of Ebola virus disease (EVD), focusing on early outbreak detection, tracking public attitudes, and identifying knowledge gaps using real-time social media data.",Text Data (tweets),"EVD-related Twitter Corpus (July 24 – August 1, 2014)",Yes,"Performance was not evaluated using traditional AI accuracy metrics such as precision, recall, or F1-score. Instead, performance was assessed through descriptive and statistical analysis of tweet volume, dissemination rates, geographic spread, and thematic content categorization. A total of 42,236 Ebola-related tweets were collected (16,499 unique tweets and 25,737 retweets) over a 9-day period. These tweets were disseminated to approximately 9.36 billion users globally. Temporal trend modeling using exponential smoothing revealed that tweet dissemination increased by approximately 520,441 users per minute (P < 0.0001), indicating a significant surge in information spread during the early outbreak stage. Geographical analysis showed initial concentration in Africa and Europe, which expanded globally after the CDC announcement, including to North America, Asia, and Australia. Content clustering using NLP and K-means revealed four main themes: risk factors (e.g., transmission), prevention education, disease trends, and compassion. These results collectively highlight Twitter’s real-time potential for early epidemic detection and public health surveillance.",Not specified,Not specified,
62,"Li Z, Li Y, Chen Y, Li J, Li S, Li C, Lin Y, Jian W, Shi J, Zhan Y, Cheng J, Zheng J, Zhong N, Ye F.",2021,"State Key Laboratory of Respiratory Disease, National Clinical Research Center for Respiratory Disease, Guangzhou Institute of Respiratory Health, the First Affiliated Hospital of Guangzhou Medical University, Guangzhou, People's Republic of China.","Trends of pulmonary fungal infections from 2013 to 2019: an AI-based real-world observational study in Guangzhou, China",Emerg Microbes Infect,Respiratory Virology,"[""Pulmonary Fungal Infections""]","Journal Article, Observational Study",To investigate changes in epidemiological characteristics and trends of pulmonary fungal infections using AI-based NLP on EHR data.,"Limited knowledge and uncertainty around incidence and characteristics of pulmonary fungal infections (PFIs), especially among youth and rare pathogens.","The objective was to apply artificial intelligence, specifically an automated natural language processing (NLP) system, to extract and standardize clinically relevant information from unstructured electronic health records (EHRs) of patients with pulmonary fungal infections (PFIs). ","The AI methodology involved a multi-phase process designed to extract, clean, standardize, and analyze electronic health record (EHR) data related to pulmonary fungal infections (PFIs). First, an automated NLP system was employed to retrospectively screen patient records from 2013 to 2019, identifying those with confirmed PFIs based on clinical diagnoses. Suspected cases were excluded at this stage. Next, structured clinical data were extracted, including demographics, pathogen types, comorbidities, drug use, and adverse events. A diagnostic standardization pipeline was integrated to ensure consistency in terminology across records, relying on mapping to ICD-10 and SNOMED vocabularies. This enabled uniform categorization of diseases and pathogens. Post-standardization, a trend analysis was conducted using SPSS and R, applying statistical tests (e.g., linear regression on log incidence rates) to evaluate changes in disease incidence and related factors over time.","The study employed a rule-based and dictionary-augmented Natural Language Processing (NLP) method to extract and standardize clinical diagnostic information from unstructured electronic health records (EHRs). The NLP process began with diagnostic parsing, where diagnostic phrases were extracted from multiple sections of patient records such as discharge summaries and outpatient notes. These were then split into individual disease entries using predefined rule sets. Each diagnostic term was matched to standardized medical vocabularies specifically ICD-10 and SNOMED using a curated synonym database. If a direct match wasn’t found, the term was manually normalized and mapped. The NLP pipeline also included a diagnostic validation phase, where outputs were sampled and reviewed to refine rules and update the synonym database iteratively. This structured approach ensured consistent terminology across records, improved data reliability, and facilitated accurate trend analysis in pulmonary fungal infection cases.",Automated Natural Language Processing (NLP) System,No,No,"epidemiological trend analysis of pulmonary fungal infections (PFIs),",Electronic Health Records (EHRs),Li et.al,Yes,"The performance of the AI system in this study was not assessed using traditional AI metrics like accuracy or F1-score. Instead, the system's effectiveness was demonstrated through its successful application in extracting and analyzing clinical data from unstructured electronic health records (EHRs) using natural language processing (NLP). The results showed that out of 40,504 inpatients and 219,414 outpatients screened for respiratory diseases between 2013 and 2019, the AI system identified 1,368 inpatients and 1,313 outpatients with pulmonary fungal infections (PFIs). Through trend analysis, the study revealed a significant increase in PFI incidence over time especially among the 14–30 age group, where hospitalizations rose from 9.5 per 1000 in 2013 to 88.3 per 1000 in 2019. Additionally, the incidence of Talaromyces marneffei, previously considered rare, showed the steepest increase, from 0.17 per 1000 patients in 2013 to 1.97 per 1000 in 2019, reflecting a 16% year-on-year growth (P<0.001). These findings highlight the real-world utility and epidemiological insights enabled by the AI-driven NLP system, despite the absence of explicit predictive model performance metrics.",Not specified,Not specified,
63,"Wang Y, O'Connor K, Flores I, Berdahl CT, Urbanowicz RJ, Stevens R, Bauermeister JA, Gonzalez-Hernandez G.",2024,"Department of Computational Biomedicine, Cedars-Sinai Medical Center, West Hollywood, CA, USA.","Health activism, vaccine, and mpox discourse: BERTopic based mixed-method analyses of tweets from sexual minority men and gender diverse (SMMGD) individuals in the U.S",medRxiv,Emerging & Re-emerging Viruses,"[""Monkeypox""]","Preprint, Journal Article","The aim of the study is to synthesize and analyze online discussions about mpox (monkeypox) among sexual minority men and gender diverse (SMMGD) individuals on Twitter/X. The goal is to understand the thematic concerns, emotional expressions, and activist messaging from this community, which is often underrepresented in mpox-related public health literature, in order to improve inclusive health communication strategies.","Existing mpox research lacks direct representation of sexual minority men and gender diverse (SMMGD) voices, limiting the understanding of their unique experiences and concerns in public health discourse.






","To identify and categorize major themes in mpox-related social media discourse among sexual minority men and gender diverse (SMMGD) individuals using topic modeling techniques, in order to inform inclusive and equitable public health communication strategies.","The study employed a hybrid AI methodology combining natural language processing (NLP), transformer-based text embedding, dimensionality reduction, unsupervised clustering, and topic modeling to analyze mpox-related tweets. Tweets were first collected from a curated cohort of 2,326 self-identified SMMGD users in the U.S. and filtered by mpox-related keywords. NLP preprocessing was applied to normalize the text, including removing URLs and mentions, converting to lowercase, expanding contractions, translating emojis, and harmonizing synonyms (e.g., various spellings of “monkeypox” were mapped to “mpox”). Tokenization, stopword removal, and lemmatization were conducted using the nltk Python library. After preprocessing, semantic embeddings of the tweets were generated and passed through a pipeline involving BERTopic for topic modeling. The pipeline included UMAP for dimensionality reduction, HDBSCAN for clustering, and c-TF-IDF with BM25 for keyword representation. The output topics were further refined and interpreted through human validation and annotated to assess coherence and accuracy. Additionally, correlation analysis was conducted between topic frequencies and state-level social acceptance scores (LGB social climate index) to examine geographic patterns in discourse.","The technical implementation used the all-MiniLM-L6-v2 transformer model to encode each tweet into dense vector representations capturing semantic similarity. These embeddings were reduced in dimensionality using UMAP to enhance cluster separability. The reduced vectors were then clustered using HDBSCAN, an algorithm well-suited for noisy social media data due to its ability to identify dense clusters and label outliers. For topic generation, CountVectorizer converted tweets into bag-of-words format, and BERTopic leveraged c-TF-IDF with BM25 weighting to emphasize important terms while down-weighting frequent but uninformative words. Hyperparameters such as n_neighbors, min_samples, and min_cluster_size were fine-tuned to ensure meaningful topic granularity. Human annotators reviewed top keywords and representative tweets from each topic to assign meaningful labels and conducted inter-annotator agreement testing to validate classification quality. The model ultimately categorized 91.24% of tweets into 11 coherent topics. Topic-level geographic analysis was performed using Carmen 2.0 to assign tweet locations and assess the relationship between topic prevalence and regional LGB social acceptance.",BERTopic (Bidirectional Encoder Representations from Transformers-based Topic Modeling).,No(Can ask authors to get it),No,infodemiology and stigma surveillance for mpox (monkeypox),Social Media Data (Twitter Posts),Mpox-related tweets from self-identified SMMGD (sexual minority men and gender diverse) users on Twitter (October 2020 – September 2022).,Yes,"The performance of the AI method (BERTopic) was evaluated using a human-validated approach rather than traditional automated metrics. Specifically, the researchers measured how well the machine-generated topic labels aligned with human judgment by conducting manual topic validation. Two human annotators independently reviewed a subset of tweets and assigned topic labels based on content, without seeing the model's assigned labels. Their annotations were then compared to both each other’s and the machine’s results. The evaluation focused on percent agreement as a primary metric to assess how accurately BERTopic categorized tweets into meaningful topics. This validation approach accounted for the challenges of multi-class classification tasks and provided a realistic measure of the model's interpretability and thematic coherence.","{""Percent Agreement""}","{ ""human_annotator_agreement"": ""70.77%"", ""machine_vs_human_annotator_1_agreement"": ""60.1%"", ""machine_vs_human_annotator_2_agreement"": ""60%"" }",
64,"Saeidpour A, Bansal S, Rohani P.",2022,"Odum School of Ecology, University of Georgia, Athens, Georgia, United States of America.",Dissecting recurrent waves of pertussis across the boroughs of London,PLoS Comput Biol,Bacteriology,"[""Pertussis ""]","Journal Article, Review, Research Support, N.I.H., Extramural","To investigate the spatial epidemiology and transmission dynamics of pertussis across the boroughs of Greater London (1982–2013), and to identify the demographic, socioeconomic, and geographic factors driving the temporal and spatial diffusion patterns of the disease.","Despite high immunization coverage, pertussis has resurged in the UK to levels not seen since the 1980s, and the underlying causes and spatial diffusion patterns across urban areas like London remain poorly understood.","To quantify and interpret the contribution of demographic, socioeconomic, geographic, and household-level features in determining the spatial and temporal phase differences of pertussis outbreaks across London boroughs using interpretable machine learning.","The study employed a hybrid methodology combining epidemiological signal processing with machine learning. First, the epidemic phase lags measuring how early or late pertussis outbreaks occurred in each London borough were computed using the Hilbert transform applied to temporally filtered incidence time series. These lags served as the target variable for the subsequent AI analysis. Next, the researchers compiled a borough-level dataset consisting of over 20 features derived from UK census data (household composition, socioeconomic indicators, occupation categories, ethnic background, transportation patterns, and geographic attributes). To examine how these features contributed to the timing of pertussis outbreaks, multiple regression models were tested including ordinary least squares (OLS), Lasso, and Ridge regression—to capture linear relationships. However, due to suspected non-linear interactions between variables, a feed-forward neural network (FFNN) was also used for superior modeling power. Model training and evaluation involved careful data splitting and cross-validation. Finally, SHAP (SHapley Additive exPlanations) was used to interpret the machine learning model by quantifying the contribution of each feature to its predictions across boroughs.","The feed-forward neural network (FFNN) implemented in this study was configured using the Keras library with a TensorFlow backend. The model architecture was optimized with up to three hidden layers and 64 nodes per layer using tanh activation functions. Dropout regularization was applied to reduce overfitting, and the model was trained using the Adam optimizer for up to 2000 epochs. For validation, 16 borough samples were reserved as a validation set, and grid search was used to tune hyperparameters. After training, the model’s predictions were interpreted using SHAP values, a model-agnostic method based on cooperative game theory. SHAP explains individual predictions by distributing the output prediction among input features according to their marginal contribution. This allowed researchers to identify key predictors of epidemic phase such as the number of households with children aged 0–4, skilled manual labor populations, latitude, and use of public transport with both local (borough-specific) and global interpretability. The SHAP analysis revealed nuanced associations e.g., boroughs with more young children or higher public transport usage tended to experience earlier outbreaks, while those with higher immigrant populations showed lagging epidemic phases in later years.",Feed-Forward Neural Network (FFNN) with SHapley Additive exPlanations (SHAP) for interpretability.,No,No,Spatial epidemiology and resurgence modeling of pertussis (whooping cough),Demographic data and epidemic phase lag data,Notifications of Infectious Diseases (NOIDs) dataset,Yes,"The performance of the AI model a feed-forward neural network (FFNN) was evaluated using training and test datasets to predict borough-level epidemic phase lags during pertussis outbreaks in London. Model effectiveness was assessed using the coefficient of determination (R²), which measures how closely the predicted values align with actual observations. The FFNN outperformed traditional linear models, including ordinary least squares (OLS), lasso, and ridge regression, showing better generalization and reduced overfitting. Although the exact R² values were not specified, the study confirmed the FFNN's superior performance across all dataset splits. For interpretability, SHapley Additive exPlanations (SHAP) were used to quantify the contribution of each input feature to the model’s output. This approach identified key demographic and socio-economic factors influencing the timing of pertussis epidemics. No classification metrics like accuracy or precision were reported, as the study focused on regression-based temporal-spatial analysis.","{""Coefficient of determination""}","{""Coefficient of determination"":Not specified numerically}",
65,"Hou Y, Zhang Q, Gao F, Mao D, Li J, Gong Z, Luo X, Chen G, Li Y, Yang Z, Sun K, Wang X.",2020,"Center of Integrative Medicine, Beijing Ditan Hospital, Capital Medical University, Beijing, 100015, People's Republic of China.",Artificial neural network-based models used for predicting 28- and 90-day mortality of patients with hepatitis B-associated acute-on-chronic liver failure,BMC Gastroenterol,Hepatic Virology,"[""Hepatitis B""]","Journal Article, Validation Study","To develop and validate artificial neural network (ANN)-based prognostic models for predicting 28-day and 90-day mortality risks in patients with hepatitis B virus-associated acute-on-chronic liver failure (HBV-ACLF), and to compare their predictive performance against existing clinical scoring systems.","To accurately predict 28-day and 90-day mortality in HBV-associated acute-on-chronic liver failure (HBV-ACLF) patients using an artificial neural network (ANN), and to evaluate whether it outperforms existing prognostic scoring models.",To develop an AI-based diagnostic model that can accurately predict HBV-ACLF in patients with chronic hepatitis B,"The study employed a supervised machine learning approach to build prognostic models for predicting 28- and 90-day mortality in patients with HBV-associated acute-on-chronic liver failure (HBV-ACLF). Specifically, an artificial neural network (ANN) was used, trained on retrospective clinical and laboratory data. The model development process involved univariate analysis to identify variables significantly associated with mortality outcomes, which were then included in the training process. The dataset was split into a training cohort (423 patients) and a validation cohort (261 patients) sourced from eight tertiary hospitals in China. The learning process involved adjusting internal weights via backpropagation to minimize prediction error, and the final models were evaluated against established clinical scoring systems using receiver operating characteristic (ROC) curve analysis.","The AI model was implemented as a multilayer perceptron (MLP)-based artificial neural network (ANN), comprising one input layer with eight input features (age, hepatic encephalopathy, serum sodium, prothrombin activity, ?-glutamyltransferase, alkaline phosphatase, hepatitis B e antigen status, and total bilirubin), one hidden layer containing two neurons, and a single output neuron indicating mortality risk. The model was developed using Mathematica 11.1.1 for Windows (64-bit). The ANN was trained via the backpropagation algorithm, where the weights between neurons were iteratively adjusted to reduce the discrepancy between predicted and actual outcomes. The ANN output was a continuous risk score for mortality, which was subsequently assessed for predictive performance using the area under the ROC curve (AUR), with comparisons made against MELD, MELD-Na, CTP, and CLIF-ACLF scoring systems.",['Artificial Neural Network'],No,No,mortality risk prediction in patients with hepatitis B virus (HBV)-associated acute-on-chronic liver failure (HBV-ACLF),"Clinical Data (e.g., patient demographics, lab results, virological markers)",Multi-center HBV-ACLF patient dataset,Yes,"The performance of the artificial neural network (ANN) models for predicting 28- and 90-day mortality in HBV-associated acute-on-chronic liver failure (HBV-ACLF) patients was assessed using Receiver Operating Characteristic (ROC) curve analysis. The Area Under the ROC Curve (AUC) was used as the primary evaluation metric, comparing the ANN model's performance against standard clinical scoring systems such as MELD, MELD-Na, CTP, and CLIF-ACLF. The AUC values reflect the model’s ability to discriminate between survivors and non-survivors. Performance was evaluated separately on the training cohort (n=423) and validation cohort (n=261). Specifically, the ANN model achieved higher AUC values in both training and validation cohorts for 28-day and 90-day mortality predictions. This indicates that the ANN model outperformed traditional models in both sensitivity and specificity of prognostic classification.","{""AUC-ROC""}","AUC scores: 28-day (training: 0.948, validation: 0.748), 90-day (training: 0.913, validation: 0.754)
",
66,"Mayhew MB, Buturovic L, Luethy R, Midic U, Moore AR, Roque JA, Shaller BD, Asuni T, Rawling D, Remmel M, Choi K, Wacker J, Khatri P, Rogers AJ, Sweeney TE.",2020,"Inflammatix, Inc., 863 Mitten Rd, Suite 104, Burlingame, CA, 94010, USA.",A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections,Nat Commun,Respiratory Virology,"[""Bacterial infections, viral infections, ,Noninfectious inflammation""]","Evaluation Study, Journal Article, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't","To develop a generalizable host gene expression-based classifier (IMX-BVN-1) for distinguishing bacterial, viral, and noninfectious acute infections.","Need for a rapid, reliable, and generalizable diagnostic tool that can interpret host immune response to guide appropriate antibiotic use and reduce sepsis-related mortality, overtreatment, and antimicrobial resistance.","Classify infection types (bacterial, viral, noninfected) from host gene expression data using machine learning for clinical application.","The researchers developed the classifier using transcriptomic data from 18 retrospective studies comprising 1,069 patients. They began with a predefined set of 29 host mRNAs previously validated in smaller studies and transformed them into six geometric mean (GM) scores representing biological signatures. To address technical variability from different microarray platforms, they applied the COmbat CO-Normalization Using conTrols (COCONUT) framework to harmonize expression levels. Model development employed hierarchical cross-validation (HiCV) with a leave-one-study-out (LOSO) strategy to reduce bias and improve generalizability. Multiple classifiers were tested logistic regression, SVM, XGBoost, and MLP and multi-layer perceptrons (MLPs) were selected based on best average performance across bacterial-vs-other, viral-vs-other, and noninfected-vs-other AUROCs.","IMX-BVN-1 is a fixed-weight multi-layer perceptron (MLP) model consisting of two hidden layers with four nodes each and linear activations. It was trained using gradient descent over 250 iterations with a small learning rate (1e?5), batch normalization, and L1 regularization (lasso penalty coefficient of 0.1). The input to the model was six geometric mean scores derived from 29 target mRNAs. The classifier outputs three scores bacterial-vs-other, viral-vs-other, and noninfected-vs-other enabling multiclass prediction. The final MLP model was trained entirely on the IMX dataset and validated without retraining on an independent Stanford ICU cohort assayed using NanoString technology, confirming its strong performance and generalizability.","{""IMX-BVN-1 (Inflammatix Bacterial-Viral-Noninfected version 1) (Feed-forward MLP)""}",No,No,"the model distinguishes between viral, bacterial, and noninfectious causes of inflammation using host gene expression data.","Gene expression data, clinical metadata such as age,severity score, treatment details","IMX dataset, which was constructed by combining 18 publicly available transcriptomic studies(NCBI Gene Expression Omnibus (GEO), EMBL-EBI ArrayExpress)",Yes,"Performance on the IMX training dataset (N = 1069) was evaluated using a Leave-One-Study-Out Cross-Validation (LOSO-CV) strategy, which ensured that each individual study was used as a held-out validation fold while the remaining were used for training. This method helped minimize overfitting and accurately simulate external test performance. The classifier’s ability to distinguish between bacterial, viral, and noninfected samples was quantified using AUROC (Area Under the Receiver Operating Characteristic curve) for each one-vs-all classification. To rank models, the authors used the Average Pairwise AUROC (APA) metric, which averages AUROCs across all three tasks. The best-performing model was a multi-layer perceptron (MLP), which achieved AUROCs of 0.92 for both bacterial-vs-other and viral-vs-other tasks, and 0.78 for noninfected-vs-other in LOSO-CV.","{""AUC-ROC""}"," {""AUROC_Bacterial_vs_Other_Validation"": 0.86, ""AUROC_Viral_vs_Other_Validation"": 0.85, ""AUROC_Noninfected_vs_Other_Validation"": 0.82}",
,,,,,,,,,,,,,,,,,,,Stanford ICU biobank,,"The IMX-BVN-1 classifier was externally validated on an independent Stanford ICU cohort (N = 163), using gene expression data collected on a different platform (NanoString nCounter). Performance was assessed using AUROC to evaluate the model’s discriminatory ability between bacterial, viral, and noninfected infections without retraining. Among the 109 patients with unanimous adjudications, the AUROC values were 0.86 for bacterial-vs-other, 0.85 for viral-vs-other, and 0.82 for noninfected-vs-other. A key subgroup analysis was performed on patients enrolled within 36 hours of hospital admission (N = 70), where AUROCs were even higher: 0.92 for bacterial-vs-other, 0.91 for viral-vs-other, and 0.86 for noninfected-vs-other. These consistent values across datasets demonstrated strong generalizability and minimal bias or overfitting.",,"{""AUROC_Bacterial_vs_Other_Validation_36h"": 0.92, ""AUROC_Viral_vs_Other_Validation_36h"": 0.91, ""AUROC_Noninfected_vs_Other_Validation_36h"": 0.86}",
67,"Liu F, Wang J, Liu J, Li Y, Liu D, Tong J, Li Z, Yu D, Fan Y, Bi X, Zhang X, Mo S.",2020,"Taikang Pension & Insurance Co., Ltd., Beijing, China.","Predicting and analyzing the COVID-19 epidemic in China: Based on SEIRD, LSTM and GWR models",PLoS One,Respiratory Virology,"[""COVID-19""]","Comparative Study, Journal Article","To predict and analyze the COVID-19 epidemic trends in China using SEIRD, LSTM, and GWR models.",Developing accurate models to predict COVID-19 epidemic curves and inform public health interventions,"To predict the short-term trend of cumulative confirmed COVID-19 cases in different Chinese regions using data-driven machine learning techniques, particularly a neural network, and compare it with traditional epidemiological and spatial models.","In this study, a hybrid modeling framework was developed to forecast and analyze the spread of COVID-19 across China by integrating three complementary approaches: a modified SEIRD epidemiological model, an LSTM deep learning model, and a Geographically Weighted Regression (GWR) model. The SEIRD model dynamically simulated the epidemic’s progression with time-varying infection parameters and was updated daily to reflect real-time trends. The LSTM model captured temporal patterns and human mobility effects to predict short-term case growth using recurrent neural networks. Meanwhile, the GWR model accounted for spatial heterogeneity, revealing how demographic and healthcare factors influenced regional case counts. Together, these models provided a comprehensive view of the epidemic, enabling accurate short-term forecasting, evaluation of government interventions, and geographically informed decision-making.","The LSTM (Long Short-Term Memory) model used in this study is a deep learning-based recurrent neural network architecture designed to capture temporal dependencies in time series data. The model was trained to predict the next day’s cumulative number of confirmed COVID-19 cases using three key input features: the number of confirmed cases on the previous day, the number of migrants from Wuhan, and a derived feature combining the migration count with the incidence rate in Wuhan to estimate potential imported infections. The network architecture consisted of four layers: an input layer, a hidden LSTM layer with 10 hidden units, a fully connected dense layer, and an output layer. The ReLU activation function was used throughout, and the model was optimized using the Adam optimizer with mean squared error (MSE) as the loss function. Grid search was applied to optimize hyperparameters for each of the selected regions (Zhejiang, Guangdong, Beijing, and Shanghai). The model leveraged the LSTM’s internal memory mechanism to effectively learn patterns from both epidemiological and mobility data, enabling accurate short-term forecasting of the COVID-19 epidemic.",Long Short-Term Memory (LSTM),No,No,Short-term forecasting of the cumulative confirmed COVID-19 cases across different regions in China,"Geographic, demographic, and medical resources data for different cities",Open Wuhan COVID-19 Illness Data,Yes,"The study assessed the predictive performance of three models Modified SEIRD, LSTM neural network, and Geographically Weighted Regression (GWR) by comparing their predicted COVID-19 case counts to actual reported cases across various Chinese regions. The Modified SEIRD model demonstrated high accuracy, with absolute percent errors (APE) below 1% after mid-February and as low as 0.10% by late February. The LSTM model, which incorporated traffic and historical case data, also showed strong predictive capability, with APEs of ?5.1% on February 3rd and ?0.63% on February 14th. The GWR model, which captured spatial heterogeneity, achieved R² values of 99.98% on training data and 97.95% on test data, although it exhibited slightly higher prediction errors in some cities. A statistical comparison using the Wilcoxon signed-rank test revealed no significant performance differences at the 0.05 level, but LSTM and SEIRD generally outperformed GWR, with lower mean absolute percentage errors (MAPE: LSTM = 1.51%, SEIRD = 1.70%, GWR = 3.44%).","{""APE"", ""MAPE"" }"," {""SEIRD_APE_China_LateFeb"": 0.10, ""SEIRD_MAPE"": 1.70, ""LSTM_APE_Feb14_Max"": 0.63, ""LSTM_MAPE"": 1.51, ""GWR_R2_Fit"": 0.9998, ""GWR_R2_Prediction"": 0.9795, ""GWR_MAPE"": 3.44, ""Wilcoxon_p_SEIRD_vs_LSTM"": 0.459, ""Wilcoxon_p_GWR_vs_LSTM"": 0.173, ""Wilcoxon_p_GWR_vs_SEIRD"": 0.187}",
68,"Lin JK, Chien TW, Wang LY, Chou W.",2021,"Department of Ophthalmology, Chi-Mei Medical Center, Yong Kang, Tainan City, Taiwan.",An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission: Development and validation study,Medicine (Baltimore),Respiratory Virology,"[""COVID-19""]","Journal Article, Multicenter Study, Validation Study",Develop an artificial neural network (ANN) model and a publicly available web-based application (PMCP app) that can accurately predict the mortality of COVID-19 patients at the time of hospital admission using routine blood test results and demographic variables.,"During the COVID-19 pandemic, healthcare providers urgently needed reliable tools to identify patients at high risk of mortality at the time of hospital admission. However, most existing models either focused on predictions several days into hospitalization or lacked real-time clinical utility. Furthermore, few models leveraged deep learning techniques such as Artificial Neural Networks (ANN) or Convolutional Neural Networks (CNN) to improve predictive accuracy, and even fewer offered accessible, interactive applications for clinical use. Additionally, the impact of using normalized versus raw laboratory data on prediction performance had not been thoroughly explored. These gaps highlighted the need for a robust, accurate, and user-friendly tool that could aid early triage and decision-making in clinical settings.","To develop and evaluate an artificial intelligence-based predictive model primarily using an Artificial Neural Network (ANN) for accurately estimating the in-hospital mortality risk of COVID-19 patients at the time of hospital admission, based on routine blood biomarkers and demographic data, and to implement this model into a publicly accessible app (PMCP) for real-time clinical decision support.","The study developed and evaluated two deep learning models Artificial Neural Network (ANN) and Convolutional Neural Network (CNN) to predict COVID-19 patient mortality risk at hospital admission. Using patient data from Wuhan, China (n = 361) and three Korean medical centers (n = 106), the researchers used 30 features (28 blood biomarkers and 2 demographic variables), with missing values imputed by mean. Both raw and normalized (z-score) data were tested to assess model sensitivity to scaling. The ANN was uniquely implemented using Microsoft Excel with a multi-layer sigmoid-based architecture and Solver optimization, while CNN served as a comparative model. Model performance was evaluated across scenarios (raw vs. normalized data; training vs. testing sets) using AUC, sensitivity, specificity, accuracy, and balanced accuracy. The ANN with normalized data achieved the highest performance (AUC = 0.96 on training data; balanced accuracy = 0.80 on testing data). Further benchmarking was done using Weka software against traditional machine learning models. Ultimately, the ANN model was deployed in a publicly accessible web app named PMCP, offering mortality risk predictions through interactive visualizations on a dashboard integrated with Google Maps.","The ANN model was developed using Microsoft Excel, featuring a multilayer feed-forward neural network architecture with sigmoid activation functions. The model parameters were optimized through Excel’s Solver add-in by minimizing the total residuals (SUMXMY2 function), which made the approach uniquely accessible and transparent. The model was trained on 361 COVID-19 patient records from Wuhan, using 30 input features (28 blood biomarkers and 2 demographic attributes: age and gender). Both raw and normalized data (z-score normalization) were tested to assess the impact of data scaling. The ANN achieved the highest AUC of 0.96 on the training set (normalized data) and balanced accuracy of 0.80 on the external test set (106 Korean patients). The final trained ANN model was integrated into a publicly available online application called PMCP (Predict the Mortality of COVID-19 Patients). This app visualizes the probability of survival or death through a dashboard with categorical probability curves displayed on Google Maps, offering real-time, user-friendly risk assessment for clinicians and the public.",Artificial Neural Network (ANN),"Yes, the PMCP app",No,Clinical mortality risk prediction at hospital admission for patients infected with COVID-19.,"28 Blood Biomarkers, 28 Blood Biomarkers(age, gender)","Wuhan COVID-19 Patient Dataset – Used as the training dataset, Korean COVID-19 Patient Dataset – Used as the external testing dataset
",Yes,"The study evaluated the performance of two deep learning models Artificial Neural Network (ANN) and Convolutional Neural Network (CNN) for predicting the mortality of COVID-19 patients at hospital admission. Performance was assessed using both training and external testing datasets under two scenarios: one with raw laboratory data and another with normalized data (z-score transformed). The primary evaluation method involved comparing predicted outcomes (death or survival) against actual clinical outcomes using standard classification metrics including sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristic curve (AUC). The ANN model demonstrated superior performance when using normalized data, achieving an AUC of 0.96 on the training dataset and a balanced accuracy of 0.80 on the external testing dataset. In comparison, the CNN model yielded a slightly lower AUC of 0.91 during training and a balanced accuracy of 0.73 on the testing dataset. These results indicate that ANN not only outperformed CNN in terms of discrimination power (AUC) but also exhibited more consistent generalization across datasets. This made ANN the preferred model for integration into the developed PMCP mortality prediction app.","{ ""AUC-ROC""}","{""ANN_AUC_Training_Normalized"": 0.96, ""ANN_Balanced_Accuracy_Testing_Normalized"": 0.80}",
,,,,,,,,,,,,,"The CNN model was implemented as a comparative deep learning method alongside ANN. It was trained and tested using the same datasets 361 training patients from Wuhan and 106 external testing patients from Korea. CNN performance was evaluated under both raw and normalized data conditions. The model structure included typical CNN layers, though specific architecture details (e.g., number of layers, kernel size) were not explicitly described. On the normalized data, CNN achieved an AUC of 0.91 on the training set and lower balanced accuracy (0.73) on the testing set compared to ANN. Unlike ANN, the CNN model was not embedded into the final app and was mainly used to benchmark ANN’s performance against another deep learning approach.
",Convolutional Neural Network (CNN),No,No,,Blood sample data,Lin et.al,Yes,"The performance was measured using the Area Under the Receiver Operating Characteristic Curve (AUC) metric, with a validation dataset from 3 Korean medical institutions.","{ ""AUC-ROC""}","{""CNN_AUC_Training_Normalized"": 0.91, ""CNN_Balanced_Accuracy_Testing_Normalized"": 0.73}",
69,"Akil L, Ahmad HA.",2016,"Department of Biology/Environmental Science, Jackson State University, Jackson, Mississippi, USA.",Salmonella infections modelling in Mississippi using neural network and geographical information system (GIS),BMJ Open,Foodborne Virology," [ ""Salmonella"", ""E. coli""]","Comparative Study, Journal Article, Research Support, N.I.H., Extramural, Research Support, U.S. Gov't, Non-P.H.S.","The aim of this research is to determine the extent of Salmonella and Escherichia coli infections in Mississippi (MS) and to assess the correlation between Salmonella infections and socioeconomic status (e.g., poverty, unemployment, education level) using Geographic Information System (GIS) and neural network models.","The research problem addresses the high rates of Salmonella outbreaks in Mississippi, focusing on understanding the correlation between these outbreaks and socioeconomic status, particularly in low socioeconomic status (LSES) regions, using GIS and neural networks.","Analyze and predict the correlation between Salmonella outbreaks and socioeconomic factors using machine learning models, such as neural networks, and advanced data analysis techniques like GIS, to gain insights that can help mitigate the risk of foodborne illnesses in Mississippi.Predicting the correlation of Salmonella using neural networks","The AI methodology in this study involves using machine learning techniques, particularly neural networks, to analyze and predict the correlation between Salmonella outbreaks and socioeconomic factors. This is complemented by Geographic Information System (GIS) mapping to visualize the geographic distribution of outbreaks and socioeconomic variables. The neural network models are trained on historical data from Mississippi, including variables such as poverty, unemployment, and healthcare access.","GRNN is effective in handling non-linear relationships, providing robust predictions even with small or noisy data. The network is trained on historical data, and once trained, it predicts outbreak rates based on input variables.  The dataset used includes Salmonella and E. coli cases from 2002 to 2012, collected from the CDC and state health departments, along with socioeconomic data from Mississippi’s counties. This AI approach helps identify high-risk areas for foodborne illness outbreaks and aids in designing targeted interventions.","General Regression Neural Network (GRNN)



",No,No,"prediction of the epidemiology of foodborne illnesses, specifically Salmonella and E. coli infections",Structured tabular data (likely related to epidemiological or demographic data),CDC and Mississippi Department of Health public health records,Yes,"In this study, the performance of the General Regression Neural Network (GRNN) model was measured using common regression metrics. The model’s ability to predict Salmonella outbreaks in Mississippi based on socioeconomic factors (such as poverty, unemployment, uninsured rates, and primary care providers' rates) was assessed. These metrics were used to evaluate the effectiveness of the GRNN model in predicting the correlation between Salmonella outbreaks and socioeconomic factors, providing insights into how well the model performed in identifying and predicting the outbreaks.","{R², Correlation coefficient (r), Mean squared error (MSE), Mean absolute error (MAE)}","{""R²"" : 0.4169, ""r "": 0.6457, ""MSE"" : 175.87, ""MAE"": 11.54}",
70,"Saegner T, Austys D.",2022,"Department of Public Health, Institute of Health Sciences, Faculty of Medicine, Vilnius University, M. K. ÄŒiurlionio 21/27, LT-03101 Vilnius, Lithuania.",Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review,Int J Environ Res Public Health,Respiratory Virology,"[""COVID-19""]","Journal Article, Review",To review the literature about the possible use of GT(google trends) for COVID-19 surveillance and prediction of its outbreaks.,"The study seeks to explore whether GT can indeed serve as a useful tool for COVID-19 prediction and surveillance, and if so, what methodologies are most effective.","The goal is to determine whether AI methods can effectively use GT data to predict COVID-19 outbreaks in advance, providing a valuable tool for health authorities and governments in managing public health responses.","The methodology employed in the studies reviewed involves analyzing Google Trends (GT) data for COVID-19 prediction and surveillance. Relevant GT search terms related to COVID-19, such as symptoms, prevention measures, and the virus itself, are collected and preprocessed. The studies then evaluate various forecasting approaches, including time-series models and other statistical methods, to assess how well search interest correlates with COVID-19 trends. These methods aim to identify patterns in the data, with the goal of predicting future outbreaks. The findings suggest that GT data, when combined with statistical modeling, can help forecast COVID-19 trends and support surveillance efforts.","These methods aim to assess the relationship between public interest, as measured by search terms, and actual COVID-19 trends. The AI approaches typically involve time-series analysis, where historical data on GT search queries are examined to identify trends and patterns that may correlate with COVID-19 case numbers. These methods can also integrate external data, such as reported cases or deaths, to enhance the predictive power of the models.","{""Time-Series Forecasting"": ""Autoregressive Integrated Moving Average (ARIMA)"", ""Regression"": ""Random Forest Regression"", ""Ensemble Learning"": ""Gradient Boosting Machines (GBM)"", ""Neural Networks"": ""Long Short-Term Memory (LSTM)"", ""Clustering"": ""K-Means Clustering"", ""Classification"": ""Support Vector Machines (SVM)"", ""Deep Learning"": ""Convolutional Neural Networks (CNN)"", ""Vector Models"": ""Vector Error Correction Model (VECM)"", ""Boosting"": ""Adaboost"", ""Bayesian Models"": ""Bayesian Network""}",No,No,COVID-19 surveillance and outbreak prediction using Google trends data,"temporal, geographic, quantitative, textual, and categorical data ",COVID-19 Google Trends Data,No,it does not provide a specific performance measure in terms of numerical values or metrics for all studies,,,
71,"Wang YW, Shen ZZ, Jiang Y.",2019,"School of Public Health, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, China.",Comparison of autoregressive integrated moving average model and generalised regression neural network model for prediction of haemorrhagic fever with renal syndrome in China: a time-series study,BMJ Open,General Virology,['Haemorrhagic Fever with Renal Syndrome (HFRS)'],"Comparative Study, Journal Article","The aim of the study is to develop and compare the predictive performance of three different models ARIMA, GRNN, and a hybrid ARIMA-GRNN for forecasting the monthly incidence of HFRS in China. The goal is to determine the most accurate model for short-term outbreak prediction and public health decision-making.
","To develop an optimal predictive modeling approach for HFRS, particularly in combining linear and non-linear components for more accurate forecasting.",To improve the forecasting accuracy of monthly HFRS incidence in China by applying and evaluating a generalized regression neural network (GRNN) model and a hybrid ARIMA-GRNN model that captures both linear and non-linear patterns in disease time series data.,"The study used a neural network-based time series forecasting approach by implementing a GRNN model to learn non-linear relationships in HFRS incidence data. It also constructed a hybrid model, where linear trends were first modeled using an ARIMA model, and then the residual or fitted values were used as inputs to train the GRNN for capturing the non-linear structure. A revised GRNN model was also developed using stratified monthly data to assess whether spatial stratified heterogeneity improves prediction.","The Generalized Regression Neural Network (GRNN) model was developed to capture non-linear patterns in the monthly HFRS incidence data from January 2011 to December 2017. The model architecture included input, pattern, summation, and output layers. The last two data points were used for testing, while the rest were used for training. A series of smoothing factors were tested, and the optimal smoothing factor of 0.027 was selected based on the lowest RMSE.",Basic GRNN,No,No,forecasting the monthly incidence of Haemorrhagic Fever with Renal Syndrome (HFRS) in China,Monthly counts of reported HFRS (haemorrhagic fever with renal syndrome) cases in mainland China,Wang et.al,Yes,"The GRNN model was trained using monthly HFRS incidence data from January 2011 to December 2017. To evaluate its performance, the last two samples from this period were held out as a test set, and the remaining data were used for training. After determining the optimal smoothing factor, the model was used to forecast values from January to May 2018. The accuracy of these forecasts was measured by comparing them to the actual reported HFRS incidence values using RMSE, MAE, and MAPE.","{""MAPE"" , ""MAE"",  ""RMSE""}","{""MAPE"": 19.2029, ""MAE"": 177.0356, ""RMSE"": 202.1684}",
,,,,,,,,,,,,,"The hybrid model was constructed by first fitting an ARIMA model to capture linear patterns in the HFRS time series, and then using the ARIMA-fitted values as input to the GRNN to learn the non-linear residual patterns. The actual observed values were used as outputs to train the GRNN. The same training/testing split was applied, and the optimal smoothing factor for the hybrid GRNN was 0.043, selected by minimizing RMSE. This model aimed to combine the strengths of both ARIMA and GRNN.",Hybrid (ARIMA + GRNN),,,,,,,"In the hybrid model, an ARIMA model was first fitted to the monthly HFRS incidence data from January 2011 to December 2017 to model the linear trends. The fitted values from the ARIMA model were then used as input to train a GRNN model, with the actual observed values as outputs, allowing the GRNN to learn the non-linear residual patterns. The ARIMA model was used to generate forecasts for January to May 2018, and these were fed into the trained GRNN to obtain the hybrid model's final predictions. These predictions were evaluated against the true incidence values for those months using RMSE, MAE, and MAPE.","{""MAPE"" , ""MAE"",  ""RMSE""}","{""MAPE"": 17.8335, ""MAE"": 152.3013, ""RMSE"": 196.4682}",
,,,,,,,,,,,,,"To address seasonal effects and spatial stratified heterogeneity (SSH), the time series was partitioned into 12 strata one for each month across years. Separate GRNN models were trained on each monthly stratum using 7 data points (e.g., Jan 2011–Jan 2017). Forecasts for January to May 2018 were generated using the corresponding monthly models. This approach allowed for capturing month-specific patterns, improving predictive performance over the basic GRNN.
",Revised GRNN,,,,,,,"To account for seasonal effects and spatial stratified heterogeneity, the original time series was partitioned into twelve separate monthly subsets (e.g., all Januaries from 2011 to 2017 formed one series, all Februaries another, etc.). Each monthly subset was used to train a dedicated GRNN model on just seven data points. The corresponding GRNN models were then used to forecast HFRS incidence for January through May 2018. These month-specific predictions were evaluated against actual values using the same three error metric RMSE, MAE, and MAPE providing insight into whether stratified modeling improved performance.","{""MAPE"" , ""MAE"",  ""RMSE""}","{""MAPE"": 17.6095, ""MAE"": 163.8000, ""RMSE"": 169.4751}",
72,"Frauenfeld L, Nann D, Sulyok Z, Feng YS, Sulyok M.",2020,"Institute for Pathology and Neuropathology, Eberhard Karls University, University Hospital of TÃ¼bingen , TÃ¼bingen 72076, Germany.",Forecasting tuberculosis using diabetes-related google trends data,Pathog Glob Health,General Virology,['Tuberculosis'],"Evaluation Study, Journal Article","To improve tuberculosis (TB) forecasting by extending traditional time series models with online activity-based data, specifically Google Trends data (GTD) related to diabetes.",To address the gap by evaluating whether integrating diabetes-related search volume into TB forecasting models can improve prediction accuracy and provide a viable early warning tool.,The AI objective of the study is to enhance the forecasting accuracy of tuberculosis (TB) incidence by developing and evaluating a GTD-extended time series model that integrates Google Trends data related to diabetes as an external input. ,"The study applied a neural network-based time series forecasting method to predict weekly tuberculosis (TB) incidence. Specifically, it used autoregressive feed-forward neural networks (NNAR) to model TB case numbers based on historical incidence data. To evaluate the added value of online behavioral signals, the models were also extended with Google Trends data (GTD) related to the search term ""diabetes"" as an external regressor. The performance of both traditional and GTD-extended neural network models was assessed through 5-fold cross-validation and in a data-poor simulation scenario using reduced and partially missing training data.","The study used an autoregressive feed-forward neural network (NNAR) model with a single hidden layer consisting of 4 neurons and 5 lagged inputs to forecast weekly tuberculosis (TB) cases in Germany. The model was trained using historical TB incidence data and extended with Google Trends data (GTD) for the search term ""diabetes"" as an external regressor. The GTD-extended NNAR model aimed to capture the syndemic relationship between TB and diabetes. Model performance was evaluated using 5-fold cross-validation, comparing the traditional and GTD-extended versions using RMSE, MAPE, and other error metrics. The method was implemented in R (forecast package) and further tested in a data-poor setting to assess robustness.",Neural Network (NNAR: Autoregressive Feed-Forward Neural Network),https://github.com/msulyok/Google-Trends-Tuberculosis,Standard open-use academic license via GitHub,"predict future TB case numbers using traditional surveillance data, enhanced with online activity-based data (Google Trends) related to diabetes",Google search data and weekly case numbers of TB in Germany,RKI TB Surveillance Dataset,Yes,"The performance of the deep learning model (NNAR) was evaluated using 5-fold cross-validation. This helped assess the generalizability of the model. To test performance in a challenging environment, the study also simulated a data-poor scenario by using only the first 52 weeks of TB data and randomly removing 10 values. The Diebold-Mariano test was used to statistically compare the prediction errors of traditional and GTD-extended NNAR models under these constraints.","[""validation_RMSE"", ""validation_MAPE"", ""cross_val_RMSE_mean"", ""cross_val_RMSE_std"", ""MAE_mean"", ""MAE_std"", ""MPE_mean"", ""MPE_std"", ""MAPE_mean"", ""MAPE_std"", ""Theils_U_mean"", ""Theils_U_std"", ""autocorr_1st_order_mean"", ""autocorr_1st_order_std"", ""diebold_mariano_p""]","nnar_gtd_metrics = {
    ""validation_RMSE"": 10.94,
    ""validation_MAPE"": 8.02,
    ""cross_val_RMSE_mean"": 19.00,
    ""cross_val_RMSE_std"": 3.27,
    ""MAE_mean"": 14.95,
    ""MAE_std"": 1.91,
    ""MPE_mean"": 3.41,
    ""MPE_std"": 8.43,
    ""MAPE_mean"": 19.44,
    ""MAPE_std"": 13.76,
    ""Theils_U_mean"": 1.49,
    ""Theils_U_std"": 0.66,
    ""autocorr_1st_order_mean"": 0.02,
    ""autocorr_1st_order_std"": 0.18,
    ""diebold_mariano_p"": ""< 0.001""
}",
73,"Zhang R, Song H, Chen Q, Wang Y, Wang S, Li Y.",2022,"Chinese Center for Disease Control and Prevention, Beijing, China.",Comparison of ARIMA and LSTM for prediction of hemorrhagic fever at different time scales in China,PLoS One,General Virology,['Hemorrhagic Fever'],"Comparative Study, Journal Article","The aim of this study is to build and compare two forecasting models (ARIMA and LSTM) for predicting the incidence of hemorrhagic fever in China across three different time scales monthly, weekly, and daily.","While ARIMA is a well-established method in infectious disease forecasting, and LSTM is gaining attention due to its ability to model non-linear relationships, there is a lack of comparative research on how these two models perform across different time scales (monthly, weekly, daily) specifically for hemorrhagic fever.","To determine whether deep learning methods like LSTM offer any advantages over traditional statistical models like ARIMA in terms of accuracy, adaptability, and robustness, especially when dealing with non-linear and high-frequency epidemiological data. ","The study employed a comparative forecasting methodology involving both traditional statistical modeling (ARIMA) and artificial intelligence-based modeling (LSTM) to predict hemorrhagic fever incidence in China across three time scales: monthly, weekly, and daily. For the ARIMA models, the time series data were first tested for stationarity using the Augmented Dickey-Fuller (ADF) test, and appropriate differencing was applied. Model parameters were estimated through autocorrelation (ACF), partial autocorrelation (PACF) plots, and automated selection using the auto.arima() function in R, with final model selection based on residual diagnostics and the Akaike Information Criterion (AIC). In parallel, LSTM neural networks were built by normalizing the data, defining time windows (7, 30, or 60 previous time points), and testing various configurations of hidden neurons, optimizers (SGD, Adam, RMSProp), and training epochs. Both ARIMA and LSTM models were evaluated using direct forecasting and rolling forecasting origin (walk-forward validation) approaches to simulate real-world prediction.","The LSTM modeling process in the study involved several key steps tailored for time series forecasting. First, the hemorrhagic fever incidence data were normalized to a range between 0 and 1 to ensure stable training, as LSTM models are sensitive to input scales. The data were then transformed into supervised learning format using time windows of 7, 30, or 60 previous time steps to predict the next value for daily, weekly, and monthly forecasts respectively. A single-layer LSTM network was constructed with varying numbers of hidden neurons (4, 8, 16, 32, 64, 72, 128, and 256) and trained using different optimizers including SGD, Adam, and RMSProp. The training was performed over 200 to 1000 epochs, with an initial learning rate of 0.005, which was reduced every 125 epochs by a factor of 0.2 to enhance convergence. The optimal LSTM configuration for each time scale was selected based on the lowest root mean square error (RMSE) on the validation set. ",['Neural Network (LSTM)'],No,No,epidemiological forecasting of hemorrhagic fever incidence,Time series data and demographic information,Public Health Science Data Center – daily national incidence data of hemorrhagic fever in China from January 2013 to December 2019,Yes,"The study measured the forecasting performance of the models specifically, how accurately ARIMA and LSTM predicted the future number of hemorrhagic fever cases for the year 2019, using models trained on data from 2013–2018. Performance was measured by comparing predicted case counts to actual values using three metrics: Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). These metrics assessed the accuracy of the forecasts, with lower values indicating better performance. Both direct and rolling forecasting methods were evaluated to simulate real-world prediction scenarios. In the daily rolling forecasting scenario, LSTM significantly outperformed ARIMA","{""MAPE"" , ""MAE"",  ""RMSE""}","lstm_metrics = {
    ""monthly_direct"": {""RMSE"": 354.95, ""MAE"": 284.92, ""MAPE"": 43.17},
    ""monthly_rolling"": {""RMSE"": 247.53, ""MAE"": 224.42, ""MAPE"": 34.20},
    ""weekly_direct"": {""RMSE"": 54.18, ""MAE"": 44.10, ""MAPE"": 33.21},
    ""weekly_rolling"": {""RMSE"": 35.98, ""MAE"": 26.21, ""MAPE"": 17.81},
    ""daily_direct"": {""RMSE"": 13.23, ""MAE"": 10.27, ""MAPE"": 61.20},
    ""daily_rolling"": {""RMSE"": 8.05, ""MAE"": 5.75, ""MAPE"": 35.70}
}",
74,"Tapak L, Hamidi O, Fathian M, Karami M.",2019,"Department of Biostatistics, School of Public Health, Modeling of Noncommunicable Diseases Research Center, Hamadan University of Medical Sciences, Hamadan, Iran.",Comparative evaluation of time series models for predicting influenza outbreaks: application of influenza-like illness data from sentinel sites of healthcare centers in Iran,BMC Res Notes,Respiratory Virology,"[""Influenza""]","Comparative Study, Journal Article","To evaluate and compare the prediction accuracy of Support Vector Machine (SVM), Artificial Neural Network (ANN), and Random Forest (RF) models in forecasting Influenza-Like Illness (ILI) frequencies and detecting outbreaks in Iran. ",Early detection of ILI outbreaks is essential for effective public health intervention. There is limited research comparing ANN with other machine learning models for this purpose in Iran.,To use machine learning models for accurate forecasting of weekly ILI case counts and timely detection of outbreaks to support public health decision-making.,"Time series modeling using SVM, ANN, and RF. Models were trained on 80% of the weekly ILI data (2010–2016) and tested on the remaining 20% (2016–2018). Preprocessing included scaling and feature engineering using previous 52 weeks of data as input. Model performance was evaluated using regression (RMSE, MAE, ICC) and classification metrics (sensitivity, specificity, PPV, NPV, total accuracy).","The artificial neural network (ANN) model used in this study was based on a multilayer perceptron (MLP) architecture designed for time series forecasting of weekly influenza-like illness (ILI) cases. The input consisted of 52 historical weekly observations, and different configurations of hidden layers (1 to 3) were tested to optimize performance. Hyperbolic tangent and identity functions were used as activation functions in the hidden and output layers, respectively. The ANN was trained on 80% of the data and evaluated on the remaining 20%. It showed strong performance in both prediction and classification tasks.",['Machine Learning – Neural Network (ANN/MLP)'],No,No,forecasting weekly influenza-like illness (ILI) frequencies and detecting ILI outbreaks in Iran between 2010 and 2018,Weekly case counts of ILI ,dataset obtained from WHO FluNet web-based tool ,Yes,"The performance of the artificial neural network (ANN) model was evaluated using both regression and classification metrics to assess its ability to forecast weekly influenza-like illness (ILI) frequencies and detect outbreaks. For forecasting, the ANN’s prediction accuracy was assessed using Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Intra-class Correlation Coefficient (ICC). These evaluations were carried out using R statistical software with built-in packages.","[""RMSE"", ""MAE"", ""ICC"", ""Sensitivity"", ""Specificity"", ""PPV"", ""NPV"", ""Total Accuracy""]","{""RMSE"": 26.58, ""MAE"": 13.21, ""ICC"": 0.82, ""Sensitivity"": 86.2, ""Specificity"": 90.4, ""PPV"": 83.3, ""NPV"": 92.2, ""Total Accuracy"": 88.9}",
75,"Mello-RomÃ¡n JD, Mello-RomÃ¡n JC, GÃ³mez-Guerrero S, GarcÃ­a-Torres M.",2019,"Universidad Nacional de ConcepciÃ³n, ConcepciÃ³n 8700, Paraguay.",Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay,Comput Math Methods Med,General Virology,['Dengue virus infection'],"Comparative Study, Journal Article",To compare the performance of artificial neural networks (ANN) and support vector machines (SVM) in predicting dengue diagnosis using patient data,Diagnosing dengue virus infection from clinical data using machine learning algorithms.,To develop and evaluate machine learning models that can accurately assist in the diagnosis of dengue based on clinical and epidemiological data.,"The study used supervised learning techniques (ANN and SVM) on a real-world dataset from Paraguay. Data preprocessing involved handling missing values, followed by model training and evaluation using random dataset partitions and performance metrics.","The artificial neural network (ANN) used in this study is a supervised learning model .Specifically, a multilayer perceptron (MLP) architecture was use d, consisting of an input layer, one or more hidden layers, and an output layer. The model was trained using the backpropagation algorithm to classify dengue cases based on clinical features",['Artificial Neural Network (Multilayer Perceptron - ANN-MLP)'],No,No,early diagnosis of dengue infection,Clinical and demographic data,Mello-Román et.al,Yes,"The performance of the ANN and SVM classifiers was measured on 30 test datasets, using accuracy, sensitivity, and specificity as evaluation criteria.","{'accuracy', 'sensitivity', 'specificity'}","{'accuracy': 96, 'sensitivity': 96, 'specificity': 97}",
76,"Dong Y, Wang K, Zou X, Tan X, Zang Y, Li X, Ren X, Xie D, Jie Z, Chen X, Zeng Y, Shi J.",2022,"Department of Pulmonary and Critical Care Medicine, Shanghai Fifth People's Hospital, Fudan University, 801 Heqing Road, Minhang District, Shanghai, 200240, China; Lingang Laboratory, Shanghai, 200031, China.","Evaluating the ability of the NLHA2 and artificial neural network models to predict COVID-19 severity, and comparing them with the four existing scoring systems",Microb Pathog,Respiratory Virology,"[""COVID-19 Pneumonia ""]","Journal Article, Multicenter Study","To develop and evaluate machine learning models, including a deep learning-based artificial neural network (ANN), to predict ICU admission risk in COVID-19 pneumonia patients and compare their performance with existing clinical scoring systems.","Existing pneumonia severity scoring systems (e.g., PSI, CURB-65, SMARTCOP, MuLBSTA) are limited or inconsistent in predicting COVID-19 severity and ICU admission. There is a need for improved models tailored to COVID-19.",To create more accurate and clinically practical AI models  particularly a logistic regression model (NLHA2) and a deep learning model (ANN) that can identify high-risk COVID-19 patients needing ICU care.,"The study employed a supervised learning framework by splitting clinical data of COVID-19 patients into training and testing sets. Logistic regression and a deep learning-based artificial neural network (ANN) were used to build severity prediction models. The models were trained on selected clinical and laboratory features, and evaluated using metrics like AUC, sensitivity, specificity, Hosmer-Lemeshow test, and Brier score.","The ANN model was implemented as a multi-layer perceptron (MLP) with two hidden layers consisting of 10 and 8 nodes. A total of 42 clinical features were used as input. The model was built using the RSNNS package in R, and variable importance was assessed using Olden’s connection-weighted algorithm.",Artificial Neural Network (deep learning – Multi-layer Perceptron),No,No,"predicting the severity of COVID-19 pneumonia, specifically to identify patients at risk of requiring ICU admission using clinical and laboratory data.",Medical images and structured tabular data,Dong et.al,Yes,"The model was evaluated for its ability to predict ICU admission among COVID-19 pneumonia patients using a binary classification task. The model showed high sensitivity (95.89%) and specificity (88.46%) on the test data. Calibration was assessed using the Hosmer-Lemeshow test (P = 1.000) and the Brier score, which was 0.000 for training and 0.071 for testing, indicating strong model fit and predictive accuracy.","[""AUC"", ""Sensitivity"", ""Specificity"", ""Brier Score"", ""Hosmer-Lemeshow P""]","{""AUC (Training)"": 1.000, ""AUC (Testing)"": 0.907, ""Sensitivity (Testing)"": 95.89, ""Specificity (Testing)"": 88.46, ""Brier Score (Testing)"": 0.071, ""Hosmer-Lemeshow P"": 1.000}",
77,"Zhu H, Chen S, Qin W, Aynur J, Chen Y, Wang X, Chen K, Xie Z, Li L, Liu Y, Chen G, Ou J, Zheng K.",2024,"Fujian Provincial Center for Disease Control and Prevention, Fuzhou, Fujian, 350012, China. hszhu33@126.com.",Study on the impact of meteorological factors on influenza in different periods and prediction based on artificial intelligence RF-Bi-LSTM algorithm: to compare the COVID-19 period with the non-COVID-19 period,BMC Infect Dis,Respiratory Virology,['Influenza'],"Journal Article, Comparative Study",To examine how meteorological factors influence influenza during different periods (before and during COVID-19) and evaluate the predictive performance of an RF-BiLSTM model across those periods.,There is no existing evidence on whether the accuracy or association between meteorological factors and influenza changes across different intervention periods like during COVID-19.,To develop a hybrid deep learning model (RF-BiLSTM) that accurately predicts influenza incidence using meteorological and environmental factors.,A hybrid modeling approach combining Random Forest (RF) for feature selection and Bidirectional Long Short-Term Memory (Bi-LSTM) for time-series prediction. The model uses multi-step rolling forecasting with 7-day input and output windows.,"The study used a hybrid AI method combining Random Forest (RF) and Bidirectional Long Short-Term Memory (Bi-LSTM). RF was applied for feature selection by ranking the importance of meteorological and environmental variables and eliminating redundancy. The selected features were then input into a Bi-LSTM model, which learned temporal patterns in both forward and backward directions. The model used a 7-day input window to predict the average daily influenza cases for the next 7 days through a multi-step rolling forecast approach. Separate models were trained for different time phases (pre-COVID, COVID, and overall), and performance was evaluated using ten statistical metrics.",Random Forest + Bidirectional LSTM (RF-BiLSTM) hybrid model,No,No,"Predicting influenza incidence and analyzing how meteorological and environmental factors influence influenza spread during different phases (pre-COVID, during COVID, overall)","Tabular data (Influenza Case Data, vaccination records, demographic information, environmental data)","Influenza surveillance and meteorological data from Xiamen, China (2010–2022)",Yes,"Performance was measured using ten evaluation metrics to assess the accuracy of influenza predictions. These included root mean square error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), symmetric MAPE (SMAPE), RSR, correlation coefficient (CC), Nash-Sutcliffe efficiency (NSE), Kling-Gupta efficiency (KGE), index of agreement (IA), and Legate and McCabe’s index (LMI). These metrics evaluated both the magnitude and consistency of prediction errors and were applied across different phases to test how accurately the RF-Bi-LSTM model predicted 7-day average daily influenza cases.","[""RMSE"", ""MAE"", ""MAPE"", ""SMAPE"", ""RSR"", ""CC"", ""NSE"", ""KGE"", ""IA"", ""LMI""]","{""RMSE"": 1.05, ""MAE"": 0.59, ""MAPE"": 0.08, ""SMAPE"": 0.12, ""RSR"": 0.12, ""CC"": 0.99, ""NSE"": 0.98, ""KGE"": 0.95, ""IA"": 0.99, ""LMI"": 0.88}",
78,"Madden WG, Jin W, Lopman B, Zufle A, Dalziel B, E Metcalf CJ, Grenfell BT, Lau MSY.",2024,"Department of Biostatistics and Bioinformatics, Rollins School of Public Health, Emory University, Atlanta, Georgia, United States of America.",Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models,PLoS Comput Biol,Respiratory Virology,['Measles'],"Journal Article, Comparative Study","To develop and evaluate deep learning models, particularly spatial-feature neural networks (SFNN) and physics-informed neural networks (PINN), for forecasting endemic measles outbreaks, and to explore how these models can enhance both predictive accuracy and mechanistic understanding of disease dynamics."," There is a need for models that combine high predictive performance with interpretability , fully capture the complex, nonlinear, and spatially structured transmission dynamics of measles, especially in less populous regions or for long-term forecasts.",Feed-forward neural network with spatial and temporal feature engineering.,"To build and assess deep learning models that can accurately forecast measles outbreaks across different cities and time horizons, while also uncovering underlying spatial transmission patterns and supporting mechanistic interpretability.","A high-dimensional feedforward neural network incorporating both spatial and temporal features (SFNN) to forecast endemic measles outbreaks across 1,452 towns in England and Wales from 1944 to 1965. The SFNN consistently outperformed the traditional mechanistic Time-Series Susceptible-Infectious-Recovered (TSIR) model across both short- and long-term forecasting windows, particularly excelling in smaller towns where traditional models struggled. Additionally, explainability analysis using SHapley Additive exPlanations (SHAP) values revealed that the SFNN could uncover the underlying spatial hierarchy in disease spread, where large cities play a central role in driving regional outbreaks.",Spatial-Feature Feedforward Neural Network (SFNN),https://github.com/WyattGMadden/deep_measles_dynamics,No,predicting the spatiotemporal spread of measles across different towns and cities over time,Time series data consisting of biweekly measles incidence counts,England and Wales measles dataset,Yes,"The SFNN model’s performance was evaluated using Root Mean Squared Error (RMSE) of the log-transformed incidence (log(incidence + 1)). RMSE values were standardized within each city to allow fair comparison across locations with varying incidence levels. The model was tested across multiple forecasting windows, ranging from 1 to 52 biweeks ahead. Performance was benchmarked against the traditional TSIR (Time-Series Susceptible-Infected-Recovered) model, with comparative analysis highlighting that SFNN performed significantly better in less populous towns and for longer-term forecasts, whereas performance converged with TSIR in large cities during short-term forecasts.",{'RMSE'},{'RMSE': Outperformed TSIR model in most towns},
,,,,,,,,,,,,,"The researchers also implemented a Physics-Informed Neural Network (PINN), enhanced with latent susceptible dynamics reconstructed from the TSIR model, referred to as TSIR-PINN. This integrative model jointly learned disease dynamics while being constrained by SIR equations, enabling both accurate forecasting and mechanistic inference. Compared to a baseline version (Naive-PINN), the TSIR-PINN showed improved performance in forecasting measles incidence and estimating transmission parameters such as R?, thereby demonstrating the benefit of integrating mechanistic knowledge into neural network training.","Hybrid model (Mechanistic-ML integration), physics-informed neural network (PINN)",,,,,,Yes,"The PINN framework was assessed using Mean Absolute Error (MAE) and correlation between predicted and actual measles incidence, focusing on London for a 52-biweek forecast horizon. Two models were compared: Naive-PINN (no mechanistic augmentation) and TSIR-PINN (augmented with TSIR-reconstructed latent susceptible dynamics).","{""test_MAE"", ""test_correlation"", ""R0_estimate""}","{""test_MAE"": 379.60, ""test_correlation"": 0.88, ""R0_estimate"": 26.8}",
79,"Martin-Moreno JM, Alegre-Martinez A, Martin-Gorgojo V, Alfonso-Sanchez JL, Torres F, Pallares-Carratala V.",2022,"Department of Preventive Medicine and Public Health, Universitat de Valencia, 46010 Valencia, Spain.",Predictive Models for Forecasting Public Health Scenarios: Practical Experiences Applied during the First Wave of the COVID-19 Pandemic,Int J Environ Res Public Health,Respiratory Virology,['COVID-19'],"Journal Article, Systematic Review","To systematically review and categorize the various predictive and explanatory models applied during the first wave of the COVID-19 pandemic (March–June 2020), with the goal of understanding their assumptions, capabilities, and limitations in forecasting disease spread, and to provide insights for improving model applicability in future pandemic scenarios.","Traditional statistical models struggled with capturing the complex temporal dependencies in COVID-19 spread; hence, there was a need for more flexible data-driven approaches.","The paper aims to review and characterize deep learning approaches—alongside other predictive models—that were applied during the first wave of the COVID-19 pandemic (March–June 2020) to forecast epidemic trends. It seeks to evaluate the potential of DL models in anticipating public health needs during emerging infectious disease outbreaks.
","The authors conducted a systematic literature review of studies that implemented various modeling approaches for COVID-19 prediction. This included deep learning models like Long Short-Term Memory (LSTM) networks. The methodology involved collecting and analyzing published works using standard database searches and PRISMA-based selection criteria, focusing on DL models' performance, use cases, and forecast accuracy during the first wave.","LSTM's ability to handle long-range temporal dependencies makes it especially suitable for epidemic forecasting, where future values depend heavily on past case trends. In one highlighted application, an LSTM model used early COVID-19 data in Canada to forecast case trajectories and accurately predicted the end of the first wave by June 2020—though it failed to foresee the pandemic's continuation. ","['Supervised learning, deep learning (LSTM - recurrent neural network)']",No,No,Short-term forecasting of COVID-19 case numbers during the first wave (March–June 2020).,COVID-19 daily case time-series data,Martin-Moreno et.al,Yes,the paper summarized evaluation metrics reported by the original studies. There was no single unified evaluation performed by the authors.,"While exact numeric metrics like RMSE or MAE were not reported, LSTM outperformed traditional models (e.g., ARIMA, NARNN) in predicting short-term COVID-19 trends during the first wave, particularly in Canada",,
80,"Cho Y, Lee HK, Kim J, Yoo KB, Choi J, Lee Y, Choi M.",2024,"College of Nursing, Yonsei University, Seoul, Republic of Korea.",Prediction of hospital-acquired influenza using machine learning algorithms: a comparative study,BMC Infect Dis,Respiratory Virology,Influenza,"Journal Article, Comparative Study, Observational Study, Research Support, Non-U.S. Gov't",The study aims to develop and compare machine learning models to accurately predict the occurrence of hospital-acquired influenza (HAI) using electronic medical record (EMR) data. It seeks to identify key predictive factors and determine the best-performing algorithm for early HAI detection.,"Developing predictive models using electronic medical records can empower clinicians with timely insights enabling earlier detection, targeted interventions, and better prevention of HAI spread within hospital settings.",develop and evaluate machine learning models that can accurately predict hospital-acquired influenza (HAI) using structured patient data from electronic medical records (EMRs). The goal was to support early detection and timely intervention to limit transmission within hospital settings.,"The study trained machine learning models (Logistic Regression, Random Forest, XGBoost, and ANN) to predict hospital-acquired influenza using patient data from electronic medical records. Since HAI cases were very rare, the dataset was imbalanced so SMOTE (Synthetic Minority Oversampling Technique) was used to generate artificial examples of HAI cases and balance the data. To understand which features influenced the predictions, the study used SHAP (SHapley Additive exPlanations), a method that explains how much each feature like room type or lab results contributed to the final prediction. Models were trained on 80% of the data and tested on the remaining 20%.","The Artificial Neural Network (ANN) used in this study was developed to classify patients based on whether they were likely to have hospital-acquired influenza (HAI). It was trained on selected features such as vital signs, lab results, and room information. The ANN architecture included two hidden layers with 50 and 100 neurons, using ReLU (Rectified Linear Unit) as the activation function. The model was optimized using the Adam optimizer with a learning rate of 0.005. The ANN was trained using five-fold grid search cross-validation to fine-tune hyperparameters. It showed strong predictive ability and was evaluated using metrics like AUC, sensitivity, and false negatives.",Artificial Neural Network (ANN),No,No,Early detection and prediction of hospital-acquired influenza (HAI),"EMR i.e, Electronic medical records (e.g., patient demographics, medical history, laboratory results)","Electronic Medical Records (EMR) from Yonsei University Health System, a tertiary teaching hospital in Seoul, South Korea.",Yes,"The performance of the predictive models (including the ANN) was evaluated using a test set (20% of the data) that was not used during training. The study focused on classification metrics relevant to clinical decision-making. Among the four models tested, the ANN showed lower performance compared to Logistic Regression and Random Forest, with the lowest F1 Score and highest false negative count (except for XGB), indicating relatively weaker predictive capability for hospital-acquired influenza in this study.","{""AUC"", ""Sensitivity"", ""Specificity"", ""Accuracy"", ""F1 Score"", ""TP"", ""TN"", ""FP"", ""FN""}","{""AUC"": 75.2, ""Sensitivity"": 0.64, ""Specificity"": 0.70, ""Accuracy"": 70.0, ""F1 Score"": 0.6, ""TP"": 14, ""TN"": 10320, ""FP"": 4430, ""FN"": 8}",
81,"Wu W, Guo J, An S, Guan P, Ren Y, Xia L, Zhou B.",2015,"Department of Epidemiology, School of Public Health, China Medical University, Shenyang, PR China.","Comparison of Two Hybrid Models for Forecasting the Incidence of Hemorrhagic Fever with Renal Syndrome in Jiangsu Province, China",PLoS One,General Virology,['Hantavirus Pulmonary Syndrome (HPS)'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","To develop and evaluate hybrid time-series models combining ARIMA with neural networks (NARNN and GRNN) to improve the accuracy of forecasting Hemorrhagic Fever with Renal Syndrome (HFRS) incidence in Jiangsu Province, China.
",To develop more accurate forecasting models that can handle both linear and nonlinear components to improve epidemic prediction and support disease prevention and control efforts.,"To enhance the forecasting accuracy of HFRS incidence by integrating neural network-based AI methods (NARNN and GRNN) with traditional ARIMA models, capturing both linear and nonlinear time-series components.","The study adopts a hybrid AI methodology by integrating traditional statistical modeling with neural network-based approaches to improve the prediction of HFRS incidence. Specifically, two hybrid models are constructed: ARIMA-NARNN and ARIMA-GRNN. In both cases, the ARIMA model is first used to capture the linear patterns in the time-series data. The residuals from the ARIMA model, which are expected to contain nonlinear components, are then modeled using neural networks. The ARIMA-NARNN hybrid combines ARIMA with a Nonlinear Autoregressive Neural Network, which is a dynamic recurrent model capable of learning temporal dependencies. The ARIMA-GRNN hybrid pairs ARIMA with a Generalized Regression Neural Network, a static network that uses both the ARIMA outputs and time indices as inputs.","After fitting the ARIMA model to the monthly HFRS incidence data, the residuals—representing nonlinear components not captured by ARIMA—were modeled using NARNN. This dynamic neural network, which has memory through feedback loops, was configured with 35 hidden neurons and 6 delays. The network was trained using the Levenberg-Marquardt algorithm in an open-loop architecture, with 90% of the data for training, and 5% each for validation and testing. Once trained, the NARNN adjusted the ARIMA predictions, yielding final outputs that captured both linear and nonlinear patterns. This hybrid model demonstrated superior accuracy in both the modeling and forecasting stages.",ARIMA-NARNN Hybrid Model,No,No,predicting future incidence of a rodent-borne viral disease (HFRS) using time-series forecasting models,univariate time series data representing the monthly incidence rates of HFRS.,"HFRS Incidence Data from Jiangsu Province, China",Yes,"The performance was measured using Mean Squared Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE) metrics on the Jiangsu Province HFRS incidence dataset. These metrics were used to evaluate how well each model fit historical data (modeling) and how accurately it predicted future values (forecasting).","{'Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Mean Absolute Percentage Error (MAPE)'}","{""MSE"": 0.00009401, ""MAE"": 0.0074, ""MAPE"": 0.3566}",
,,,,,,,,,,,,,"ARIMA-generated forecasts and corresponding time indices were used as inputs to the GRNN, while the actual HFRS incidence values served as the targets. To optimize performance, the GRNN's spread factor—a key parameter controlling the smoothness of the function approximation—was tuned by trial and error using randomly selected testing samples. The best performance was achieved with a spread of 0.0265. Although this hybrid model outperformed the standalone ARIMA in several metrics, it was slightly less effective than the ARIMA-NARNN model, particularly in forecasting mean absolute percentage error (MAPE).",ARIMA-GRNN Hybrid Model,,,,univariate time series data representing the monthly incidence rates of HFRS.,"HFRS Incidence Data from Jiangsu Province, China",,,"{'Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Mean Absolute Percentage Error (MAPE)'}","{""MSE"": 0.00009746, ""MAE"": 0.0078, ""MAPE"": 0.4899}",
82,"Zheng Y, Zhang L, Zhu X, Guo G.",2020,"College of Medical Engineering and Technology, Xinjiang Medical University, Urumqi, People's Republic of China.","A comparative study of two methods to predict the incidence of hepatitis B in Guangxi, China",PLoS One,General Virology,['Hepatitis B'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","To compare the performance of two predictive models ARIMA and Elman Neural Network (ElmanNN) in forecasting the incidence of hepatitis B (HB) in Guangxi, China, and to assess their feasibility and accuracy for early warning and prevention planning.",To create an accurate predictive tools for early warning of Hepatitis B to plan preventive and resource allocation strategies.,"To apply and evaluate the performance of a deep learning-based model (Elman Neural Network) for predicting hepatitis B incidence, and to compare its accuracy with a traditional statistical model (ARIMA) to support public health decision-making.",The study uses a comparative modeling approach. Historical incidence data (2012–2019) is split into training and test sets. Two models — ARIMA and Elman Neural Network — are trained and tested on the same dataset. Model performance is evaluated using RMSE and MAE for both fitting and prediction phases,"The Elman Neural Network (ElmanNN), a type of recurrent neural network (RNN), was employed for time-series prediction of hepatitis B incidence in Guangxi, China. The ElmanNN is well-suited for dynamic forecasting tasks due to its feedback connections, which enable the model to retain information from previous time steps, thereby capturing temporal patterns more effectively. The input to the model consisted of 12 time-lagged variables representing monthly HB incidence, and the network was trained to perform one-step-ahead predictions. Using a systematic search, the optimal model configuration was determined to have 8 neurons in the hidden layer, with training conducted in MATLAB. Performance was evaluated using root mean square error (RMSE) and mean absolute error (MAE), and the ElmanNN demonstrated superior predictive accuracy compared to the traditional ARIMA model, highlighting its effectiveness in modeling infectious disease trends.",[Elman Neural Network (ElmanNN)],No,No,forecasting the incidence of hepatitis B to support early warning and preventive planning,"univariate time-series data representing the monthly incidence rates of hepatitis B in Guangxi, China, spanning from January 2012 to August 2019","Hepatitis B incidence and population data of Guangxi, China (2012–2019)",Yes,"Performance in the study was measured by evaluating how accurately the models could fit and forecast hepatitis B incidence. The performance was measured using RMSE and MAE metrics on the HB incidence data in Guangxi, China.","{""RMSE"", ""MAE""}","{""RMSE"": 0.89, ""MAE"": 0.70}",
83,"Abdulkareem M, Petersen SE.",2021,"Barts Heart Centre, Barts Health National Health Service (NHS) Trust, London, United Kingdom.","The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype",Front Artif Intell,Respiratory Virology,['COVID-19'],"Journal Article, Review",Overcoming challenges to battling COVID-19 and future pandemics using AI techniques.,"Addressing the limitations of current AI approaches in healthcare, particularly in performance evaluation, data collection, privacy, and protection.","Improving the accuracy and efficiency of AI models for disease diagnosis, prediction, and treatment.",Using machine learning algorithms to analyze large datasets and develop predictive models.,The study employed a combination of supervised learning and deep learning techniques to improve performance evaluation and data analysis.,['Hybrid approach combining machine learning and rule-based systems]',No,No,"application of artificial intelligence (AI) techniques in various aspects of managing the COVID-19 pandemic, including detection, diagnosis, epidemiological predictions, forecasting, and social control",Medical Images,Not specified,No,Not specified,,,
84,"da Silva Neto SR, Tabosa Oliveira T, Teixeira IV, Aguiar de Oliveira SB, Souza Sampaio V, Lynn T, Endo PT.",2022,"Universidade de Pernambuco, Recife, Brazil.",Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review,PLoS Negl Trop Dis,General Virology,"['arboviral diseases(Dengue, Chikunguniya, Zika)']","Journal Article, Research Support, Non-U.S. Gov't, Systematic Review",To discuss the state of the art of studies investigating the automatic classification of arboviral diseases based on Machine Learning (ML) and Deep Learning (DL) models,"The lack of standardization and variability in diagnostic approaches for viral diseases, leading to inaccurate diagnoses and ineffective treatments. The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment.","To systematically review how machine learning and deep learning techniques have been applied to support the clinical diagnosis of arboviral diseases (like dengue, Zika, and chikungunya), and to identify trends, gaps, and future opportunities for AI-based diagnostic tools in this domain.","Systematic literature review of existing ML and DL models used in arboviral disease diagnosis, with an emphasis on input features, model types (including DNN), evaluation metrics, and deployment context.","The study involved a comprehensive search of existing literature, including articles, reviews, and conference proceedings, to identify relevant studies on the application of AI in viral disease diagnosis.","['Convolutional Neural Networks (CNNs)', 'Recurrent Neural Networks (RNNs)']",No,No,Automatic classification of clinical data for the identification of arboviral diseases using deep learning techniques,Medical images and genomic data,Not specified,Yes,Not specified,"{'Accuracy': 'Mentioned but not provided', 'True Positive Rate': 'Mentioned but not provided'}","{'Accuracy': 'Mentioned but not provided', 'True Positive Rate': 'Mentioned but not provided'}",
85,"Corbacho Abelaira MD, Corbacho Abelaira F, Ruano-Ravina A, FernÃ¡ndez-Villar A.",2021,"Pulmonary Department, Hospital POVISA, Vigo, Spain.",Use of Conventional Chest Imaging and Artificial Intelligence in COVID-19 Infection. A Review of the Literature,Open Respir Arch,Respiratory Virology,"[""COVID-19""]","Journal Article, Review","To review and analyze the contributions of artificial intelligence (AI), particularly deep learning techniques, in the detection, diagnosis, progression monitoring, and severity assessment of COVID-19 using chest radiological imaging methods such as chest X-ray (CXR) and computed tomography (CT), up to May 2020.","RT-PCR, has low sensitivity and limited availability, hindering effective detection and contact tracing. Chest imaging aids diagnosis, but CXR has lower sensitivity and is prone to interpretation errors. Manual analysis is slow and subjective, highlighting the need for faster, scalable, and more objective diagnostic tools.","The objective of AI is to automate and improve chest imaging analysis for COVID-19 by enhancing diagnostic accuracy, reducing interpretation errors, supporting triage, and enabling fast, scalable, and consistent assessment of disease severity and progression.","The study reviews the use of supervised deep learning techniques, mainly Convolutional Neural Networks (CNNs), applied to chest imaging for automating the detection, segmentation, and quantification of COVID-19-related abnormalities.","The reviewed models include architectures such as COVID-Net, ResNet, U-Net++, Dense U-Net, VB-Net, and Bayesian CNNs, performing tasks like image classification, lesion segmentation, progression tracking, and severity prediction, using labeled chest X-ray and CT scan datasets.",deep learning CNN-based models,No,No,"early diagnosis, disease progression monitoring, severity scoring, and clinical outcome prediction for patients affected with COVID-19","Chest X-ray, Chest CT-scans", Corbacho et.al,Yes,The paper does not conduct its own experiments.,The paper does not conduct its own experiments.,The paper does not conduct its own experiments.,
86,"Bressem KK, Adams LC, Erxleben C, Hamm B, Niehues SM, Vahldiek JL.",2020,"CharitÃ© UniversitÃ¤tsmedizin Berlin, Campus Benjamin Franklin, Hindenburgdamm 30, 12203, Berlin, Germany. keno-kyrill.bressem@charite.de.",Comparing different deep learning architectures for classification of chest radiographs,Sci Rep,Respiratory Virology,['COVID-19 pneumonia'],"Comparative Study, Journal Article, Research Support, Non-U.S. Gov't","To systematically compare the performance of sixteen different pre-existing convolutional neural network (CNN) architecture ranging from shallow to deep on the task of classifying chest radiographs, specifically focusing on two datasets: CheXpert and the COVID-19 Image Data Collection.","This study explores whether simpler, shallower CNN architectures can achieve high performance in chest radiograph classification, offering efficient alternatives to deeper, more complex models.","To identify which existing CNN architectures (both shallow and deep) are most effective for classifying chest radiographs, particularly for detecting conditions like cardiomegaly, edema, consolidation, atelectasis, pleural effusion, and COVID-19 pneumonia.Predicting disease progression in patients with COVID-19","The study employed a comparative AI methodology by fine-tuning 16 pre-trained convolutional neural network (CNN) architecture: AlexNet, VGG-13, VGG-16, VGG-19, SqueezeNet-1.0, SqueezeNet-1.1, ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152, DenseNet-121, DenseNet-161, DenseNet-169, DenseNet-201, and Inception v4 originally trained on ImageNet. These models were adapted for medical image classification tasks using two datasets: CheXpert and the COVID-19 Image Data Collection. ","Each model underwent a two-phase fine-tuning process: first, training only the classification head for five epochs, followed by unfreezing and training the entire network for three additional epochs. Input chest radiographs were resized to 320×320 pixels and augmented through flipping, rotation, zooming, and lighting adjustments to enhance generalization. Models were trained using batch sizes of 16 and 32, and evaluated using multi-label classification for CheXpert (five pathology categories) and multi-class classification for COVID-19 (normal, COVID-19 pneumonia, non-COVID pneumonia).",Supervised deep learning using CNN architectures,https://github.com/pytorch/vision/tree/main/torchvision/models,BSD 3-Clause License,Detection and classification of COVID-19 pneumonia from chest radiographs,chest radiograph images (X-rays),CheXpert dataset,Yes,"A separate validation set consisting of 202 images annotated by two radiologists was used for evaluation. Each of the 16 convolutional neural network (CNN) models was trained five times, and predictions across these runs were pooled to ensure stable and reliable results. Evaluation metrics included the Area Under the Receiver Operating Characteristic Curve (AUROC), the Area Under the Precision-Recall Curve (AUPRC), and threshold-based sensitivity and specificity scores.","{""AUROC_range"", ""Top_models"", ""CheXpert_baseline_AUROC"", ""Shallow_models_good_performance"", ""Metrics_used"", ""Observation""}","{""AUROC_range"": ""0.828 - 0.882"", ""Top_models"": [""ResNet-152"", ""DenseNet-161"", ""ResNet-50""], ""CheXpert_baseline_AUROC"": 0.889, ""Shallow_models_good_performance"": [""AlexNet"", ""VGG-16""], ""Metrics_used"": {""AUROC"": {""min"": 0.828, ""max"": 0.882}, ""Sensitivity"": {""range"": ""0.59 - 0.94""}, ""Specificity"": {""range"": ""0.51 - 0.94""}}, ""Observation"": ""Shallow networks performed competitively; deep networks not always necessary""}",
,,,,,,,,,,,,,,,,,,,COVID-19 Image Data ,Yes,"each CNN model was trained five times, and predictions were aggregated for performance evaluation. Metrics used included AUROC (using a one-vs-rest strategy for each class), AUPRC for COVID-19 detection, and class-specific sensitivity and specificity. The models were tested on their ability to generalize with very few COVID-19 cases, making high precision particularly important.","{""AUROC_range"", ""Top_models"", ""CheXpert_baseline_AUROC"", ""Shallow_models_good_performance"", ""Metrics_used"", ""Observation""}","{""AUROC_range"": ""0.983 - 1.000"", ""Top_models"": [""DenseNet-169"", ""DenseNet-201"", ""VGG-16""], ""Sensitivity_Specificity"": {""Sensitivity_range"": ""0.90 - 1.00"", ""Specificity_range"": ""0.91 - 1.00""}, ""Metrics_used"": {""AUROC"": {""min"": 0.983, ""max"": 1.000}, ""Sensitivity"": {""range"": ""0.90 - 1.00""}, ""Specificity"": {""range"": ""0.91 - 1.00""}}, ""Observation"": ""All models performed excellently; even shallow networks achieved state-of-the-art results""}",
87,"Martinez M, Yang K, Constantinescu A, Stiefelhagen R.",2020,"Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, 76131 Karlsruhe, Germany.",Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video,Sensors (Basel),Respiratory Virology,['COVID-19'],"Evaluation Study, Journal Article",To develop a wearable system that helps blind and visually impaired individuals maintain social distancing by detecting nearby people and providing intuitive audio feedback.,"to increase confidence of Blind individuals to maintain safe social distancing with the support of assistive technologies that provide real-time awareness of nearby people using audio feedback, empowering them to navigate public spaces independently and safely during COVID-19.","To detect the presence and proximity of nearby people in real time using visual input, and to alert the user only when individuals are within a critical distance range (50 cm to 1.5 m), thereby supporting physical distancing.","The system uses a real-time AI-driven perception pipeline that combines semantic segmentation with depth sensing. Semantic segmentation is applied to RGB video to identify people in the user’s surroundings, and depth information is used to measure the distance to these individuals. The AI system is designed to provide timely audio feedback when a person enters a defined proximity range, supporting safe navigation.","The AI model used is SwaftNet, a lightweight, real-time semantic segmentation network.
Input: RGB video frames (640×480 resolution) captured by a wearable RGB-D camera.
Output: Pixel-wise semantic labels, particularly the “person” class, for each frame.
These semantic masks are then fused with the corresponding depth maps (from the depth camera) to estimate the real-world distance to detected persons. This fused data guides the audio feedback mechanism, where warnings are generated only if someone is within 50 cm to 150 cm of the user. The sound pitch and volume are dynamically modulated based on proximity and urgency.", SwaftNet deep neural network(Convolutional Neural Network), https://github.com/elnino9ykl/DS-PASS,MIT License.,"Assistive navigation for COVID-19 prevention, enforcing social distancing among visually impaired individuals in indoor and outdoor environments",RGB images,Mapillary Vistas dataset(used for training),Yes,"The SwaftNet model was trained on the Mapillary Vistas dataset using urban street scene images with data augmentation to enhance generalization. Validation was done on its official split, and performance was measured using Intersection over Union (IoU) across object classes, especially focusing on the ""person"" class.","{""Mean IoU"", ""IoU for Person Class""}","{""Mean IoU"": ""59.4%"", ""IoU for Person Class"": ""69.9%""}",
,,,,,,,,,,,,,,,,,,,PASS dataset(used for test)  ,Yes,"The PASS dataset was used solely for real-world evaluation of the trained SwaftNet model under wearable navigation conditions using egocentric RGB-D inputs. Different input resolutions were tested to analyze accuracy-latency trade-offs on both a laptop and Nvidia Xavier. Performance was evaluated using Mean IoU, Person IoU, and inference delay per frame.","{""Mean IoU"", ""IoU for Person Class"", ""Inference Delay (ms/frame)""}","{""Resolution 960x720"": {""Mean IoU"": ""68.3%"", ""Person IoU"": ""81.8%"", ""Delay_Laptop"": ""600.6 ms"", ""Delay_Xavier"": ""108.9 ms""}, ""Resolution 640x480"": {""Mean IoU"": ""66.9%"", ""Person IoU"": ""80.4%"", ""Delay_Laptop"": ""292.1 ms"", ""Delay_Xavier"": ""57.9 ms""}, ""Resolution 480x360"": {""Mean IoU"": ""55.1%"", ""Person IoU"": ""77.7%"", ""Delay_Laptop"": ""184.0 ms"", ""Delay_Xavier"": ""52.6 ms""}, ""Resolution 320x240"": {""Mean IoU"": ""50.8%"", ""Person IoU"": ""63.3%"", ""Delay_Laptop"": ""107.9 ms"", ""Delay_Xavier"": ""46.7 ms""}}",
88,"Magge A, Weissenbacher D, O'Connor K, Scotch M, Gonzalez-Hernandez G.",2022,"Perelman School of Medicine, University of Pennsylvania.",SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning,medRxiv,Respiratory Virology,['COVID-19'],"Preprint, Journal Article",Extracting and normalizing medical terminology for symptom extraction tasks.,Addressing the challenge of extracting and normalizing medical terminology from unstructured clinical data.,Symptom extraction and normalization,Using AI-based approach to extract and normalize medical terminology.,"Utilized MedDRA terminology for regulatory activities, a standardized international medical terminology developed under the auspices of ICH.",['MedDRA'],"Yes(https://healthlanguageprocessing.org/pubs/seed - tool link), code release is in progress","Creative Commons Attribution-NonCommercial 4.0 International License,",To monitor and detect self-reported symptoms of viral infections like COVID-19 from real-time social media data,Unstructured clinical data,Mentioned but not provided,Yes,{'Accuracy': 'Mentioned but not provided'},,,
89,"Li Z, Gurgel H, Dessay N, Hu L, Xu L, Gong P.",2020,"Ministry of Education Key Laboratory for Earth System Modeling, Department of Earth System, Science, Tsinghua University, Beijing 100084, China.",Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation,Int J Environ Res Public Health,General Virology,[Dengue],"Journal Article, Research Support, Non-U.S. Gov't, Review","To provide a comprehensive overview of landscape factors affecting dengue transmission and the satellite Earth observation (EO) data used to identify these factors, by developing an efficient and accurate semi-supervised text classification framework for selecting relevant studies from large bibliographic databases.","Automate the identification of scientific literature on dengue transmission, specifically the landscape factors (like land use, land cover, topography, etc.) that influence mosquito breeding, human-vector interaction, and virus spread using satellite EO data.","To reduce human workload and improve accuracy in literature selection by automating the screening process using text classification algorithms integrated with active learning and deep learning methods.
","A semi-supervised text classification framework was developed which combines Text scoring (based on keyword weighting), Active learning (AL), Bidirectional Long Short-Term Memory (BiLSTM) neural network to replace manual screening steps with AI-driven classification.","A semi-supervised text classification framework was developed to automate the literature review process. It integrates keyword-based text scoring, active learning, and bidirectional long short-term memory (BiLSTM) networks. This framework effectively replaces manual title/abstract and full-text screening with AI-driven classification, reducing human workload while maintaining accuracy.The framework classifies scientific articles as relevant or irrelevant to dengue landscape research by combining keyword-based text scoring, human-guided active learning, and BiLSTM deep learning to analyze titles and abstracts efficiently.",BiLSTM-based active learning,No,No,"identification of scientific literature on dengue transmission, specifically the landscape factors using satellite EO data","Metadata derived from bibliographic databases, text data containing abstracts and full texts",Li et.al,Yes,"The framework's effectiveness was measured by manual validation, tracking relevant articles identified across BiLSTM cycles, verifying precision through random checks of unlabelled records, and analyzing score-rank trends to ensure accurate relevance classification.","{""Total_records_searched"", ""Duplicates_removed"", ""Records_after_deduplication"", ""Records_after_text_scoring"", ""Records_after_BiLSTM_active_learning"", ""Final_included_articles"", ""Manual_screened_titles_abstracts"", ""Unlabelled_checked_for_precision"", ""Relevant_found_in_unlabelled_check"", ""BiLSTM_cycles_until_all_relevant_found"", ""Precision"", ""Relevance_trend_with_score_rank""}","{""Total_records_searched"": 13893, ""Duplicates_removed"": 6197, ""Records_after_deduplication"": 7696, ""Records_after_text_scoring"": 2034, ""Records_after_BiLSTM_active_learning"": 131, ""Final_included_articles"": 101, ""Manual_screened_titles_abstracts"": 1056, ""Unlabelled_checked_for_precision"": 10, ""Relevant_found_in_unlabelled_check"": 0, ""BiLSTM_cycles_until_all_relevant_found"": 4, ""Precision"": ""High"", ""Relevance_trend_with_score_rank"": ""Consistently decreasing""}",
90,"Wang L, Novoa-Laurentiev J, Cook C, Srivatsan S, Hua Y, Yang J, Miloslavsky E, Choi HK, Zhou L, Wallace ZS.",2024,"Division of General Internal Medicine and Primary Care, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, Boston, Massachusetts, USA.",Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records,medRxiv,General Virology,['ANCA-associated vasculitis'],"Journal Article, Preprint","To develop and evaluate a deep learning algorithm that accurately identifies patients with ANCA-associated vasculitis (AAV) using unstructured clinical notes in electronic health records (EHRs), and to compare its performance with traditional rule-based algorithms.","To  develop a scalable solution to address the limitations of current AAV case-identification method which depend heavily on structured data like ICD codes and are often time-consuming, inaccurate, and likely to overlook important patient subgroups such as those who are ANCA-negative.",Classify clinical note sections as indicating AAV or not. Accurately detect AAV cases at the patient level. Outperform rule-based methods in terms of sensitivity and predictive value.,"Extract and segment clinical notes from EHRs into labeled sections using expert annotations and keyword filtering. Train machine learning and deep learning models (including CNN-RNN-attention networks and BioClinicalBERT) on labeled datasets. Validate models on unseen note sections and assess generalizability to random patient samples; compare to rule-based algorithms using metrics like AUROC, AUPRC, PPV, sensitivity, and F1-score.","This model combines CNN, RNN, and attention layers to process clinical note sections:
CNN helps handle word variations like misspellings or plural forms.
RNN captures word order and context, such as negations.
Attention layers allow the model to focus on key phrases that signal AAV.
It uses BioWordVec embeddings trained on biomedical literature and MeSH terms for word representations.
Each note section is processed as a sequence of tokens for binary classification (AAV or not).","Hierarchical deep learning model with CNN, RNN, and attention layers.",No,No,detection and classification of AAV,Clinical notes,Wang et.al,Yes,"The performance of both models was evaluated at two levels: note section-level (for training and testing) and patient-level (for real-world application). Key metrics included AUROC, AUPRC, PPV, sensitivity, and F1 score.","{AUROC, AUPRC, PPV, Sensitivity, F1 Score, patient-level:PPV, Sensitivity}","Section level: AUROC: 0.991, AUPRC: 0.977, PPV: 0.954, Sensitivity: 0.951, F1 Score: 0.946, patient-level:PPV: 0.262, Sensitivity: 0.975",
,,,,,,,,,,,,,"A transformer-based language model pre-trained on clinical data:
Captures complex relationships and context in medical notes using the BERT architecture.
Fine-tuned specifically on AAV-labeled clinical note sections to classify whether they refer to AAV.",BioClinicalBERT,,,,,,,,,,"Best Section-Level — AUROC: 0.981, AUPRC: 0.962, PPV: 0.947, Sensitivity: 0.966, F1 Score: 0.952; Patient-Level: Not evaluated."
91,"Wang Y, Xu C, Zhang S, Yang L, Wang Z, Zhu Y, Yuan J.",2019,"Department of Epidemiology and Health Statistics, School of Public Health, North China University of Science and Technology, Tangshan, Hebei Province, P.R. China.",Development and evaluation of a deep learning approach for modeling seasonality and trends in hand-foot-mouth disease incidence in mainland China,Sci Rep,enterovirus virology,[hand-foot-mouth disease],"Evaluation Study, Journal Article, Research Support, Non-U.S. Gov't","Conceives this work, and collected and analyzed the data.","To develop and evaluate a deep learning model for accurately forecasting hand, foot, and mouth disease (HFMD) incidence in mainland China, and to compare its performance with traditional SARIMA and NAR models.","To develop a model that captures long-term dependencies and complex non-linear patterns in disease incidence data like HFMD, leading to suboptimal forecasts for public health planning.","The study employed a comparative AI methodology by developing and evaluating Long Short-Term Memory (LSTM) model for time-series forecasting of HFMD cases, benchmarking its performance against the traditional SARIMA model and  Nonlinear Autoregressive Neural Network (NAR) using epidemiological data from China.","The optimal architecture consisted of one hidden layer with five hidden neurons and used 11 time steps to capture temporal dependencies in the time series. The model was trained using the sigmoid activation function and optimized with the Adam optimizer over 300 epochs. Training was performed using the Backpropagation Through Time (BPTT) algorithm. The input to the model was monthly HFMD case counts collected over a ten-year period, and the output was multistep-ahead predictions of future case counts, enabling early detection and planning for HFMD outbreaks.",LSTM,No,No,early detection and public health preparedness through accurate time series prediction,Time series data for HFMD,HFMD Notified Case Time Series,Yes,"The study utilized a time series dataset comprising monthly reported cases of Hand, Foot, and Mouth Disease (HFMD) in mainland China, covering the period from June 2008 to June 2018. To validate the models, the dataset was partitioned into different in-sample (training) and out-of-sample (testing) segments. Model performance was assessed through both simulation (in-sample fitting) and forecasting (out-of-sample prediction). The accuracy of the predictions was quantified using three statistical error metrics: Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Square Error (RMSE).","{""MAE"", ""MAPE"", ""RMSE""}","{""MAE"": 19505.80, ""MAPE"": 0.221, ""RMSE"": 25820.17}",
92,"Kim JY, Jung KJ, Yoo SJ, Yoon SH.",2021,"Department of Radiology, Dongsan Hospital, Keimyung University College of Medicine, Daegu, South Korea.",Stratifying the early radiologic trajectory in dyspneic patients with COVID-19 pneumonia,PLoS One,Respiratory Virology,"['Coronavirus disease 2019, pneumonia ']","Journal Article, Multicenter Study","The aim of this study is to monitor how pneumonia changes over time in hospitalized COVID-19 patients who have breathing difficulty (dyspnea), using chest X-rays. By analyzing patterns in pneumonia progression, the study seeks to group patients based on how their lung condition develops, and to compare their age, symptoms, lab results, and health outcome such as ICU admission or deat across these groups. This helps identify which patients are at higher risk for severe illness.",Baseline chest X-rays in COVID-19 patients with dyspnea do not accurately predict who will develop severe illness. There's a need to monitor pneumonia progression over time to better identify high-risk patients early.,automatically quantify the extent of pneumonia on chest radiographs using a deep learning model and to track how pneumonia progresses over time in COVID-19 patients. ,Hospitalized COVID-19 patients with breathing difficulty were selected and their clinical data and chest radiographs were collected.  chest X-rays were uploaded to an AI system (TiSepX COVID-19 by MEDICAL IP) that automatically quantified pneumonia extent as a percentage. A group-based trajectory model (latent class growth modeling) was used to stratify patients based on how pneumonia evolved over time.,"Tool Used: TiSepX COVID-19 (developed by MEDICAL IP)
Model Type: Deep learning model based on a Generative Adversarial Network (GAN)
Training Dataset: 50,000 chest radiographs
Input: Chest radiograph (DICOM format)
Output: Pneumonia extent as percentage (e.g., 13.5% of lung affected)",Deep Learning Quantification tool based on generative adversarial network,DeepCatch X,No,The clinical progression of pneumonia caused by SARS-CoV-2,Chest radiograph images,Kim et.al,Yes,The AI tool’s pneumonia percentage estimation on X-rays was validated by comparing it to the gold standard: CT-based pneumonia quantification.,"{""comparison"", ""average_bias"",  ""correlation_coefficient""}  ","{""comparison"": ""CT-based pneumonia quantification"", ""average_bias"": -6.1, ""limits_of_agreement"": [-29.5, 17.2], ""correlation_coefficient"": 0.748}",
93,"Ong SQ, Pauzi MBM, Gan KH.",2022,"Institute for Tropical Biology and Conservation, Universiti Malaysia Sabah, Jalan UMS, Kota Kinabalu, Sabah 88400, Malaysia. Electronic address: songquan.ong@ums.edu.my.",Text mining in mosquito-borne disease: A systematic review,Acta Trop,General Virology,"['Dengue Fever', 'Zika Virus', 'Malaria']","Journal Article, Review, Systematic Review","To review and analyze recent studies that apply text mining techniques in the domain of mosquito-borne diseases, highlighting the data sources (corpora), technologies used, applications (e.g., surveillance, treatment), and existing challenges, in order to guide future work in this underexplored area.","Despite the growing threat of mosquito-borne diseases and advances in text mining, there is no comprehensive review focused specifically on how text mining techniques have been applied in this domain. Existing general-purpose tools are not well-suited due to the specialized biomedical nature of the mosquito-borne disease literature, and challenges such as inconsistent entity recognition, language bias, and limited integration of vector-specific data remain unaddressed.","To examine and categorize how artificial intelligence, particularly text mining and machine learning, has been utilized to extract and analyze information related to mosquito-borne diseases from various text corpora (e.g., Twitter, PubMed, LexisNexis), with a focus on enhancing surveillance, treatment insights, and public awareness.","Article Selection and Filtering
Conducted a bibliometric search across PubMed and Scopus (2016–2021) using Boolean logic to identify 294 research articles related to text mining in mosquito-borne diseases. After relevance filtering and expert validation, 27 articles using actual text mining techniques were selected for in-depth review.
Corpus and Technique Categorization
Reviewed studies based on:
Corpora used (e.g., Twitter, PubMed, LexisNexis)
Text mining techniques (e.g., sentiment analysis, information extraction, topic modeling, keyword extraction)
Applications (e.g., surveillance, treatment, public discourse understanding)
Analysis of Methods and Applications
Identified the dominant techniques (sentiment analysis and information extraction) and mapped them to practical use cases such as disease surveillance, prediction, symptom-drug relationships, and public health monitoring, highlighting trends, limitations, and future research directions.","Text Processing Techniques:
Tokenization, Normalization, Lemmatization, Stemming
Part-of-Speech (POS) tagging
Named Entity Recognition (NER) for extracting disease names, symptoms, treatments
Text Mining Techniques:
Sentiment Analysis: Used mainly on Twitter data to classify opinions as positive, negative, or neutral (often for surveillance and public discourse).
Information Extraction: Extracted structured relations between entities (e.g., disease-symptom, drug-disease) using:
Co-occurrence analysis
Dependency parsing
Literature-based discovery
Topic Modeling: Applied LDA and clustering to discover discussion topics in corpora like news or Twitter.
Keyword Extraction: Identified high-frequency or co-occurring keywords using algorithms like TextRank.",Text Mining with Natural Language Processing (NLP),No,No,"Surveillance, early detection, symptom-drug relation mining, and public discourse analysis","Text data from social media platforms, scientific literature like PubMed, news media",Ong et.al,No,The paper iteself does not evaluate any metrics,Not specified,Not specified,
