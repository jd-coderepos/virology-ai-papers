PMID,Title,Authors,Citation,First Author,Journal/Book,Publication Year,Create Date,PMCID,NIHMS ID,DOI,Abstract,Combined_Text,Is_ManuallyCopied
36143468,Artificial Intelligence in Biological Sciences,"Bhardwaj A, Kishore S, Pandey DK.",Life (Basel). 2022 Sep 14;12(9):1430. doi: 10.3390/life12091430.,Bhardwaj A,Life (Basel),2022,23-09-2022,PMC9505413,,10.3390/life12091430,"Artificial intelligence (AI), currently a cutting-edge concept, has the potential to improve the quality of life of human beings. The fields of AI and biological research are becoming more intertwined, and methods for extracting and applying the information stored in live organisms are constantly being refined. As the field of AI matures with more trained algorithms, the potential of its application in epidemiology, the study of host-pathogen interactions and drug designing widens. AI is now being applied in several fields of drug discovery, customized medicine, gene editing, radiography, image processing and medication management. More precise diagnosis and cost-effective treatment will be possible in the near future due to the application of AI-based technologies. In the field of agriculture, farmers have reduced waste, increased output and decreased the amount of time it takes to bring their goods to market due to the application of advanced AI-based approaches. Moreover, with the use of AI through machine learning (ML) and deep-learning-based smart programs, one can modify the metabolic pathways of living systems to obtain the best possible outputs with the minimal inputs. Such efforts can improve the industrial strains of microbial species to maximize the yield in the bio-based industrial setup. This article summarizes the potentials of AI and their application to several fields of biology, such as medicine, agriculture, and bio-based industry.","Artificial Intelligence in Biological Sciences Artificial intelligence (AI), currently a cutting-edge concept, has the potential to improve the quality of life of human beings. The fields of AI and biological research are becoming more intertwined, and methods for extracting and applying the information stored in live organisms are constantly being refined. As the field of AI matures with more trained algorithms, the potential of its application in epidemiology, the study of host-pathogen interactions and drug designing widens. AI is now being applied in several fields of drug discovery, customized medicine, gene editing, radiography, image processing and medication management. More precise diagnosis and cost-effective treatment will be possible in the near future due to the application of AI-based technologies. In the field of agriculture, farmers have reduced waste, increased output and decreased the amount of time it takes to bring their goods to market due to the application of advanced AI-based approaches. Moreover, with the use of AI through machine learning (ML) and deep-learning-based smart programs, one can modify the metabolic pathways of living systems to obtain the best possible outputs with the minimal inputs. Such efforts can improve the industrial strains of microbial species to maximize the yield in the bio-based industrial setup. This article summarizes the potentials of AI and their application to several fields of biology, such as medicine, agriculture, and bio-based industry.",0
34056579,"The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype","Abdulkareem M, Petersen SE.",Front Artif Intell. 2021 May 14;4:652669. doi: 10.3389/frai.2021.652669. eCollection 2021.,Abdulkareem M,Front Artif Intell,2021,31-05-2021,PMC8160471,,10.3389/frai.2021.652669,"COVID-19 has created enormous suffering, affecting lives, and causing deaths. The ease with which this type of coronavirus can spread has exposed weaknesses of many healthcare systems around the world. Since its emergence, many governments, research communities, commercial enterprises, and other institutions and stakeholders around the world have been fighting in various ways to curb the spread of the disease. Science and technology have helped in the implementation of policies of many governments that are directed toward mitigating the impacts of the pandemic and in diagnosing and providing care for the disease. Recent technological tools, artificial intelligence (AI) tools in particular, have also been explored to track the spread of the coronavirus, identify patients with high mortality risk and diagnose patients for the disease. In this paper, areas where AI techniques are being used in the detection, diagnosis and epidemiological predictions, forecasting and social control for combating COVID-19 are discussed, highlighting areas of successful applications and underscoring issues that need to be addressed to achieve significant progress in battling COVID-19 and future pandemics. Several AI systems have been developed for diagnosing COVID-19 using medical imaging modalities such as chest CT and X-ray images. These AI systems mainly differ in their choices of the algorithms for image segmentation, classification and disease diagnosis. Other AI-based systems have focused on predicting mortality rate, long-term patient hospitalization and patient outcomes for COVID-19. AI has huge potential in the battle against the COVID-19 pandemic but successful practical deployments of these AI-based tools have so far been limited due to challenges such as limited data accessibility, the need for external evaluation of AI models, the lack of awareness of AI experts of the regulatory landscape governing the deployment of AI tools in healthcare, the need for clinicians and other experts to work with AI experts in a multidisciplinary context and the need to address public concerns over data collection, privacy, and protection. Having a dedicated team with expertise in medical data collection, privacy, access and sharing, using federated learning whereby AI scientists hand over training algorithms to the healthcare institutions to train models locally, and taking full advantage of biomedical data stored in biobanks can alleviate some of problems posed by these challenges. Addressing these challenges will ultimately accelerate the translation of AI research into practical and useful solutions for combating pandemics.","The Promise of AI in Detection, Diagnosis, and Epidemiology for Combating COVID-19: Beyond the Hype COVID-19 has created enormous suffering, affecting lives, and causing deaths. The ease with which this type of coronavirus can spread has exposed weaknesses of many healthcare systems around the world. Since its emergence, many governments, research communities, commercial enterprises, and other institutions and stakeholders around the world have been fighting in various ways to curb the spread of the disease. Science and technology have helped in the implementation of policies of many governments that are directed toward mitigating the impacts of the pandemic and in diagnosing and providing care for the disease. Recent technological tools, artificial intelligence (AI) tools in particular, have also been explored to track the spread of the coronavirus, identify patients with high mortality risk and diagnose patients for the disease. In this paper, areas where AI techniques are being used in the detection, diagnosis and epidemiological predictions, forecasting and social control for combating COVID-19 are discussed, highlighting areas of successful applications and underscoring issues that need to be addressed to achieve significant progress in battling COVID-19 and future pandemics. Several AI systems have been developed for diagnosing COVID-19 using medical imaging modalities such as chest CT and X-ray images. These AI systems mainly differ in their choices of the algorithms for image segmentation, classification and disease diagnosis. Other AI-based systems have focused on predicting mortality rate, long-term patient hospitalization and patient outcomes for COVID-19. AI has huge potential in the battle against the COVID-19 pandemic but successful practical deployments of these AI-based tools have so far been limited due to challenges such as limited data accessibility, the need for external evaluation of AI models, the lack of awareness of AI experts of the regulatory landscape governing the deployment of AI tools in healthcare, the need for clinicians and other experts to work with AI experts in a multidisciplinary context and the need to address public concerns over data collection, privacy, and protection. Having a dedicated team with expertise in medical data collection, privacy, access and sharing, using federated learning whereby AI scientists hand over training algorithms to the healthcare institutions to train models locally, and taking full advantage of biomedical data stored in biobanks can alleviate some of problems posed by these challenges. Addressing these challenges will ultimately accelerate the translation of AI research into practical and useful solutions for combating pandemics.",0
38424562,Prevalence of computer vision syndrome during the COVID-19 pandemic: a systematic review and meta-analysis,"León-Figueroa DA, Barboza JJ, Siddiq A, Sah R, Valladares-Garrido MJ, Adhikari S, Aguirre-Milachay E, Sah S, Rodriguez-Morales AJ.",BMC Public Health. 2024 Feb 29;24(1):640. doi: 10.1186/s12889-024-17636-5.,León-Figueroa DA,BMC Public Health,2024,29-02-2024,PMC10902934,,10.1186/s12889-024-17636-5,"BACKGROUND: Computer vision syndrome has become a significant public health problem, especially in developing countries. Therefore, this study aims to identify the prevalence of computer vision syndrome during the COVID-19 pandemic.
METHODS: A systematic review and meta-analysis of the literature was conducted using the databases PubMed, Scopus, Web of Science, and Embase up to February 22, 2023, using the search terms ""Computer Vision Syndrome"" and ""COVID-19"". Three authors independently performed study selection, quality assessment, and data extraction, and the Joanna Briggs Institute Meta-Analysis of Statistics Assessment and Review Instrument was used to evaluate study quality. Heterogeneity was assessed using the statistical test I2, and the R version 4.2.3 program was used for statistical analysis.
RESULTS: A total of 192 studies were retrieved, of which 18 were included in the final meta-analysis. The total sample included 10,337 participants from 12 countries. The combined prevalence of computer vision syndrome was 74% (95% CI: 66, 81). Subgroup analysis based on country revealed a higher prevalence of computer vision syndrome in Pakistan (99%, 95% CI: 97, 100) and a lower prevalence in Turkey (48%, 95% CI: 44, 52). In addition, subgroup analysis based on study subjects showed a prevalence of 82% (95% CI: 74, 89) for computer vision syndrome in non-students and 70% (95% CI: 60, 80) among students.
CONCLUSION: According to the study, 74% of the participants experienced computer vision syndrome during the COVID-19 pandemic. Given this finding, it is essential to implement preventive and therapeutic measures to reduce the risk of developing computer vision syndrome and improve the quality of life of those affected.
TRIAL REGISTRATION: The protocol for this systematic review and meta-analysis was registered in the international registry of systematic reviews, the International Prospective Register of Systematic Reviews (PROSPERO), with registration number CRD42022345965.","Prevalence of computer vision syndrome during the COVID-19 pandemic: a systematic review and meta-analysis BACKGROUND: Computer vision syndrome has become a significant public health problem, especially in developing countries. Therefore, this study aims to identify the prevalence of computer vision syndrome during the COVID-19 pandemic.
METHODS: A systematic review and meta-analysis of the literature was conducted using the databases PubMed, Scopus, Web of Science, and Embase up to February 22, 2023, using the search terms ""Computer Vision Syndrome"" and ""COVID-19"". Three authors independently performed study selection, quality assessment, and data extraction, and the Joanna Briggs Institute Meta-Analysis of Statistics Assessment and Review Instrument was used to evaluate study quality. Heterogeneity was assessed using the statistical test I2, and the R version 4.2.3 program was used for statistical analysis.
RESULTS: A total of 192 studies were retrieved, of which 18 were included in the final meta-analysis. The total sample included 10,337 participants from 12 countries. The combined prevalence of computer vision syndrome was 74% (95% CI: 66, 81). Subgroup analysis based on country revealed a higher prevalence of computer vision syndrome in Pakistan (99%, 95% CI: 97, 100) and a lower prevalence in Turkey (48%, 95% CI: 44, 52). In addition, subgroup analysis based on study subjects showed a prevalence of 82% (95% CI: 74, 89) for computer vision syndrome in non-students and 70% (95% CI: 60, 80) among students.
CONCLUSION: According to the study, 74% of the participants experienced computer vision syndrome during the COVID-19 pandemic. Given this finding, it is essential to implement preventive and therapeutic measures to reduce the risk of developing computer vision syndrome and improve the quality of life of those affected.
TRIAL REGISTRATION: The protocol for this systematic review and meta-analysis was registered in the international registry of systematic reviews, the International Prospective Register of Systematic Reviews (PROSPERO), with registration number CRD42022345965.",0
33972645,Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time,"Ong SQ, Ahmad H, Nair G, Isawasan P, Majid AHA.",Sci Rep. 2021 May 10;11(1):9908. doi: 10.1038/s41598-021-89365-3.,Ong SQ,Sci Rep,2021,11-05-2021,PMC8110999,,10.1038/s41598-021-89365-3,"Classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) by humans remains challenging. We proposed a highly accessible method to develop a deep learning (DL) model and implement the model for mosquito image classification by using hardware that could regulate the development process. In particular, we constructed a dataset with 4120 images of Aedes mosquitoes that were older than 12 days old and had common morphological features that disappeared, and we illustrated how to set up supervised deep convolutional neural networks (DCNNs) with hyperparameter adjustment. The model application was first conducted by deploying the model externally in real time on three different generations of mosquitoes, and the accuracy was compared with human expert performance. Our results showed that both the learning rate and epochs significantly affected the accuracy, and the best-performing hyperparameters achieved an accuracy of more than 98% at classifying mosquitoes, which showed no significant difference from human-level performance. We demonstrated the feasibility of the method to construct a model with the DCNN when deployed externally on mosquitoes in real time.","Implementation of a deep learning model for automated classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) in real time Classification of Aedes aegypti (Linnaeus) and Aedes albopictus (Skuse) by humans remains challenging. We proposed a highly accessible method to develop a deep learning (DL) model and implement the model for mosquito image classification by using hardware that could regulate the development process. In particular, we constructed a dataset with 4120 images of Aedes mosquitoes that were older than 12 days old and had common morphological features that disappeared, and we illustrated how to set up supervised deep convolutional neural networks (DCNNs) with hyperparameter adjustment. The model application was first conducted by deploying the model externally in real time on three different generations of mosquitoes, and the accuracy was compared with human expert performance. Our results showed that both the learning rate and epochs significantly affected the accuracy, and the best-performing hyperparameters achieved an accuracy of more than 98% at classifying mosquitoes, which showed no significant difference from human-level performance. We demonstrated the feasibility of the method to construct a model with the DCNN when deployed externally on mosquitoes in real time.",0
38620646,Use of Conventional Chest Imaging and Artificial Intelligence in COVID-19 Infection. A Review of the Literature,"Corbacho Abelaira MD, Corbacho Abelaira F, Ruano-Ravina A, Fernández-Villar A.",Open Respir Arch. 2021 Jan 8;3(1):100078. doi: 10.1016/j.opresp.2020.100078. eCollection 2021 Jan-Mar.,Corbacho Abelaira MD,Open Respir Arch,2021,15-04-2024,PMC7834680,,10.1016/j.opresp.2020.100078,"The coronavirus disease caused by SARS-Cov-2 is a pandemic with millions of confirmed cases around the world and a high death toll. Currently, the real-time polymerase chain reaction (RT-PCR) is the standard diagnostic method for determining COVID-19 infection. Various failures in the detection of the disease by means of laboratory samples have raised certain doubts about the characterisation of the infection and the spread of contacts. In clinical practice, chest radiography (RT) and chest computed tomography (CT) are extremely helpful and have been widely used in the detection and diagnosis of COVID-19. RT is the most common and widely available diagnostic imaging technique, however, its reading by less qualified personnel, in many cases with work overload, causes a high number of errors to be committed. Chest CT can be used for triage, diagnosis, assessment of severity, progression, and response to treatment. Currently, artificial intelligence (AI) algorithms have shown promise in image classification, showing that they can reduce diagnostic errors by at least matching the diagnostic performance of radiologists. This review shows how AI applied to thoracic radiology speeds up and improves diagnosis, allowing to optimise the workflow of radiologists. It can provide an objective evaluation and achieve a reduction in subjectivity and variability. AI can also help to optimise the resources and increase the efficiency in the management of COVID-19 infection.","Use of Conventional Chest Imaging and Artificial Intelligence in COVID-19 Infection. A Review of the Literature The coronavirus disease caused by SARS-Cov-2 is a pandemic with millions of confirmed cases around the world and a high death toll. Currently, the real-time polymerase chain reaction (RT-PCR) is the standard diagnostic method for determining COVID-19 infection. Various failures in the detection of the disease by means of laboratory samples have raised certain doubts about the characterisation of the infection and the spread of contacts. In clinical practice, chest radiography (RT) and chest computed tomography (CT) are extremely helpful and have been widely used in the detection and diagnosis of COVID-19. RT is the most common and widely available diagnostic imaging technique, however, its reading by less qualified personnel, in many cases with work overload, causes a high number of errors to be committed. Chest CT can be used for triage, diagnosis, assessment of severity, progression, and response to treatment. Currently, artificial intelligence (AI) algorithms have shown promise in image classification, showing that they can reduce diagnostic errors by at least matching the diagnostic performance of radiologists. This review shows how AI applied to thoracic radiology speeds up and improves diagnosis, allowing to optimise the workflow of radiologists. It can provide an objective evaluation and achieve a reduction in subjectivity and variability. AI can also help to optimise the resources and increase the efficiency in the management of COVID-19 infection.",0
28895064,A mouse model of HIV-associated neurocognitive disorders: a brain-behavior approach to discover disease mechanisms and novel treatments,"Tyor WR, Bimonte-Nelson H.",J Neurovirol. 2018 Apr;24(2):180-184. doi: 10.1007/s13365-017-0572-6. Epub 2017 Sep 11.,Tyor WR,J Neurovirol,2018,13-09-2017,PMC5845816,NIHMS905650,10.1007/s13365-017-0572-6,"HIV-associated neurocognitive disorders (HAND) remain highly prevalent despite combined antiretroviral therapy (cART). Although the most common forms of HAND are mild and identified through neuropsychological testing, there is evidence that with aging these mild forms become more prevalent and may advance to the most severe form of HAND, HIV-associated dementia. Therefore, novel therapies must be developed that can be used adjunctively with cART to prevent deterioration or restore normal cognitive function. In order to develop innovative treatments, animal models are used for preclinical testing. Ideally, a HAND animal model should portray similar mild cognitive deficits that are found in humans. A mouse model of HAND is discussed, which demonstrates mild behavioral deficits and has been used to investigate cART and novel treatments for HAND. This model also shows correlations between abnormal mouse behavior due to HIV in the brain and pathological parameters such as gliosis and neuronal abnormalities. A recent advancement utilizes the object recognition test to monitor mouse behavior before and after treatment. It is postulated that this model is well suited for preclinical testing of novel therapies and provides correlations of mild cognitive impairment with pathological markers that can give further insight into the pathophysiology of HAND.","A mouse model of HIV-associated neurocognitive disorders: a brain-behavior approach to discover disease mechanisms and novel treatments HIV-associated neurocognitive disorders (HAND) remain highly prevalent despite combined antiretroviral therapy (cART). Although the most common forms of HAND are mild and identified through neuropsychological testing, there is evidence that with aging these mild forms become more prevalent and may advance to the most severe form of HAND, HIV-associated dementia. Therefore, novel therapies must be developed that can be used adjunctively with cART to prevent deterioration or restore normal cognitive function. In order to develop innovative treatments, animal models are used for preclinical testing. Ideally, a HAND animal model should portray similar mild cognitive deficits that are found in humans. A mouse model of HAND is discussed, which demonstrates mild behavioral deficits and has been used to investigate cART and novel treatments for HAND. This model also shows correlations between abnormal mouse behavior due to HIV in the brain and pathological parameters such as gliosis and neuronal abnormalities. A recent advancement utilizes the object recognition test to monitor mouse behavior before and after treatment. It is postulated that this model is well suited for preclinical testing of novel therapies and provides correlations of mild cognitive impairment with pathological markers that can give further insight into the pathophysiology of HAND.",0
32788602,Comparing different deep learning architectures for classification of chest radiographs,"Bressem KK, Adams LC, Erxleben C, Hamm B, Niehues SM, Vahldiek JL.",Sci Rep. 2020 Aug 12;10(1):13590. doi: 10.1038/s41598-020-70479-z.,Bressem KK,Sci Rep,2020,14-08-2020,PMC7423963,,10.1038/s41598-020-70479-z,"Chest radiographs are among the most frequently acquired images in radiology and are often the subject of computer vision research. However, most of the models used to classify chest radiographs are derived from openly available deep neural networks, trained on large image datasets. These datasets differ from chest radiographs in that they are mostly color images and have substantially more labels. Therefore, very deep convolutional neural networks (CNN) designed for ImageNet and often representing more complex relationships, might not be required for the comparably simpler task of classifying medical image data. Sixteen different architectures of CNN were compared regarding the classification performance on two openly available datasets, the CheXpert and COVID-19 Image Data Collection. Areas under the receiver operating characteristics curves (AUROC) between 0.83 and 0.89 could be achieved on the CheXpert dataset. On the COVID-19 Image Data Collection, all models showed an excellent ability to detect COVID-19 and non-COVID pneumonia with AUROC values between 0.983 and 0.998. It could be observed, that more shallow networks may achieve results comparable to their deeper and more complex counterparts with shorter training times, enabling classification performances on medical image data close to the state-of-the-art methods even when using limited hardware.","Comparing different deep learning architectures for classification of chest radiographs Chest radiographs are among the most frequently acquired images in radiology and are often the subject of computer vision research. However, most of the models used to classify chest radiographs are derived from openly available deep neural networks, trained on large image datasets. These datasets differ from chest radiographs in that they are mostly color images and have substantially more labels. Therefore, very deep convolutional neural networks (CNN) designed for ImageNet and often representing more complex relationships, might not be required for the comparably simpler task of classifying medical image data. Sixteen different architectures of CNN were compared regarding the classification performance on two openly available datasets, the CheXpert and COVID-19 Image Data Collection. Areas under the receiver operating characteristics curves (AUROC) between 0.83 and 0.89 could be achieved on the CheXpert dataset. On the COVID-19 Image Data Collection, all models showed an excellent ability to detect COVID-19 and non-COVID pneumonia with AUROC values between 0.983 and 0.998. It could be observed, that more shallow networks may achieve results comparable to their deeper and more complex counterparts with shorter training times, enabling classification performances on medical image data close to the state-of-the-art methods even when using limited hardware.",0
34580318,A comparative study on image-based snake identification using machine learning,"Rajabizadeh M, Rezghi M.",Sci Rep. 2021 Sep 27;11(1):19142. doi: 10.1038/s41598-021-96031-1.,Rajabizadeh M,Sci Rep,2021,28-09-2021,PMC8476526,,10.1038/s41598-021-96031-1,"Automated snake image identification is important from different points of view, most importantly, snake bite management. Auto-identification of snake images might help the avoidance of venomous snakes and also providing better treatment for patients. In this study, for the first time, it's been attempted to compare the accuracy of a series of state-of-the-art machine learning methods, ranging from the holistic to neural network algorithms. The study is performed on six snake species in Lar National Park, Tehran Province, Iran. In this research, the holistic methods [k-nearest neighbors (kNN), support vector machine (SVM) and logistic regression (LR)] are used in combination with a dimension reduction approach [principle component analysis (PCA) and linear discriminant analysis (LDA)] as the feature extractor. In holistic methods (kNN, SVM, LR), the classifier in combination with PCA does not yield an accuracy of more than 50%, But the use of LDA to extract the important features significantly improves the performance of the classifier. A combination of LDA and SVM (kernel = 'rbf') is achieved to a test accuracy of 84%. Compared to holistic methods, convolutional neural networks show similar to better performance, and accuracy reaches 93.16% using MobileNetV2. Visualizing intermediate activation layers in VGG model reveals that just in deep activation layers, the color pattern and the shape of the snake contribute to the discrimination of snake species. This study presents MobileNetV2 as a powerful deep convolutional neural network algorithm for snake image classification that could be used even on mobile devices. This finding pave the road for generating mobile applications for snake image identification.","A comparative study on image-based snake identification using machine learning Automated snake image identification is important from different points of view, most importantly, snake bite management. Auto-identification of snake images might help the avoidance of venomous snakes and also providing better treatment for patients. In this study, for the first time, it's been attempted to compare the accuracy of a series of state-of-the-art machine learning methods, ranging from the holistic to neural network algorithms. The study is performed on six snake species in Lar National Park, Tehran Province, Iran. In this research, the holistic methods [k-nearest neighbors (kNN), support vector machine (SVM) and logistic regression (LR)] are used in combination with a dimension reduction approach [principle component analysis (PCA) and linear discriminant analysis (LDA)] as the feature extractor. In holistic methods (kNN, SVM, LR), the classifier in combination with PCA does not yield an accuracy of more than 50%, But the use of LDA to extract the important features significantly improves the performance of the classifier. A combination of LDA and SVM (kernel = 'rbf') is achieved to a test accuracy of 84%. Compared to holistic methods, convolutional neural networks show similar to better performance, and accuracy reaches 93.16% using MobileNetV2. Visualizing intermediate activation layers in VGG model reveals that just in deep activation layers, the color pattern and the shape of the snake contribute to the discrimination of snake species. This study presents MobileNetV2 as a powerful deep convolutional neural network algorithm for snake image classification that could be used even on mobile devices. This finding pave the road for generating mobile applications for snake image identification.",0
35751196,Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0,"Agarwal M, Agarwal S, Saba L, Chabert GL, Gupta S, Carriero A, Pasche A, Danna P, Mehmedovic A, Faa G, Shrivastava S, Jain K, Jain H, Jujaray T, Singh IM, Turk M, Chadha PS, Johri AM, Khanna NN, Mavrogeni S, Laird JR, Sobel DW, Miner M, Balestrieri A, Sfikakis PP, Tsoulfas G, Misra DP, Agarwal V, Kitas GD, Teji JS, Al-Maini M, Dhanjil SK, Nicolaides A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Yadav RR, Nagy F, Kincses ZT, Ruzsa Z, Naidu S, Viskovic K, Kalra MK, Suri JS.",Comput Biol Med. 2022 Jul;146:105571. doi: 10.1016/j.compbiomed.2022.105571. Epub 2022 May 21.,Agarwal M,Comput Biol Med,2022,25-06-2022,PMC9123805,,10.1016/j.compbiomed.2022.105571,"BACKGROUND: COVLIAS 1.0: an automated lung segmentation was designed for COVID-19 diagnosis. It has issues related to storage space and speed. This study shows that COVLIAS 2.0 uses pruned AI (PAI) networks for improving both storage and speed, wiliest high performance on lung segmentation and lesion localization.
METHOD: ology: The proposed study uses multicenter ∼9,000 CT slices from two different nations, namely, CroMed from Croatia (80 patients, experimental data), and NovMed from Italy (72 patients, validation data). We hypothesize that by using pruning and evolutionary optimization algorithms, the size of the AI models can be reduced significantly, ensuring optimal performance. Eight different pruning techniques (i) differential evolution (DE), (ii) genetic algorithm (GA), (iii) particle swarm optimization algorithm (PSO), and (iv) whale optimization algorithm (WO) in two deep learning frameworks (i) Fully connected network (FCN) and (ii) SegNet were designed. COVLIAS 2.0 was validated using ""Unseen NovMed"" and benchmarked against MedSeg. Statistical tests for stability and reliability were also conducted.
RESULTS: Pruning algorithms (i) FCN-DE, (ii) FCN-GA, (iii) FCN-PSO, and (iv) FCN-WO showed improvement in storage by 92.4%, 95.3%, 98.7%, and 99.8% respectively when compared against solo FCN, and (v) SegNet-DE, (vi) SegNet-GA, (vii) SegNet-PSO, and (viii) SegNet-WO showed improvement by 97.1%, 97.9%, 98.8%, and 99.2% respectively when compared against solo SegNet. AUC > 0.94 (p < 0.0001) on CroMed and > 0.86 (p < 0.0001) on NovMed data set for all eight EA model. PAI <0.25 s per image. DenseNet-121-based Grad-CAM heatmaps showed validation on glass ground opacity lesions.
CONCLUSIONS: Eight PAI networks that were successfully validated are five times faster, storage efficient, and could be used in clinical settings.","Eight pruning deep learning models for low storage and high-speed COVID-19 computed tomography lung segmentation and heatmap-based lesion localization: A multicenter study using COVLIAS 2.0 BACKGROUND: COVLIAS 1.0: an automated lung segmentation was designed for COVID-19 diagnosis. It has issues related to storage space and speed. This study shows that COVLIAS 2.0 uses pruned AI (PAI) networks for improving both storage and speed, wiliest high performance on lung segmentation and lesion localization.
METHOD: ology: The proposed study uses multicenter ∼9,000 CT slices from two different nations, namely, CroMed from Croatia (80 patients, experimental data), and NovMed from Italy (72 patients, validation data). We hypothesize that by using pruning and evolutionary optimization algorithms, the size of the AI models can be reduced significantly, ensuring optimal performance. Eight different pruning techniques (i) differential evolution (DE), (ii) genetic algorithm (GA), (iii) particle swarm optimization algorithm (PSO), and (iv) whale optimization algorithm (WO) in two deep learning frameworks (i) Fully connected network (FCN) and (ii) SegNet were designed. COVLIAS 2.0 was validated using ""Unseen NovMed"" and benchmarked against MedSeg. Statistical tests for stability and reliability were also conducted.
RESULTS: Pruning algorithms (i) FCN-DE, (ii) FCN-GA, (iii) FCN-PSO, and (iv) FCN-WO showed improvement in storage by 92.4%, 95.3%, 98.7%, and 99.8% respectively when compared against solo FCN, and (v) SegNet-DE, (vi) SegNet-GA, (vii) SegNet-PSO, and (viii) SegNet-WO showed improvement by 97.1%, 97.9%, 98.8%, and 99.2% respectively when compared against solo SegNet. AUC > 0.94 (p < 0.0001) on CroMed and > 0.86 (p < 0.0001) on NovMed data set for all eight EA model. PAI <0.25 s per image. DenseNet-121-based Grad-CAM heatmaps showed validation on glass ground opacity lesions.
CONCLUSIONS: Eight PAI networks that were successfully validated are five times faster, storage efficient, and could be used in clinical settings.",0
39297572,Artificial intelligence strengthenes cervical cancer screening - present and future,"Wu T, Lucas E, Zhao F, Basu P, Qiao Y.",Cancer Biol Med. 2024 Sep 19;21(10):864-79. doi: 10.20892/j.issn.2095-3941.2024.0198.,Wu T,Cancer Biol Med,2024,19-09-2024,PMC11523278,,10.20892/j.issn.2095-3941.2024.0198,"Cervical cancer is a severe threat to women's health. The majority of cervical cancer cases occur in developing countries. The WHO has proposed screening 70% of women with high-performance tests between 35 and 45 years of age by 2030 to accelerate the elimination of cervical cancer. Due to an inadequate health infrastructure and organized screening strategy, most low- and middle-income countries are still far from achieving this goal. As part of the efforts to increase performance of cervical cancer screening, it is necessary to investigate the most accurate, efficient, and effective methods and strategies. Artificial intelligence (AI) is rapidly expanding its application in cancer screening and diagnosis and deep learning algorithms have offered human-like interpretation capabilities on various medical images. AI will soon have a more significant role in improving the implementation of cervical cancer screening, management, and follow-up. This review aims to report the state of AI with respect to cervical cancer screening. We discuss the primary AI applications and development of AI technology for image recognition applied to detection of abnormal cytology and cervical neoplastic diseases, as well as the challenges that we anticipate in the future.","Artificial intelligence strengthenes cervical cancer screening - present and future Cervical cancer is a severe threat to women's health. The majority of cervical cancer cases occur in developing countries. The WHO has proposed screening 70% of women with high-performance tests between 35 and 45 years of age by 2030 to accelerate the elimination of cervical cancer. Due to an inadequate health infrastructure and organized screening strategy, most low- and middle-income countries are still far from achieving this goal. As part of the efforts to increase performance of cervical cancer screening, it is necessary to investigate the most accurate, efficient, and effective methods and strategies. Artificial intelligence (AI) is rapidly expanding its application in cancer screening and diagnosis and deep learning algorithms have offered human-like interpretation capabilities on various medical images. AI will soon have a more significant role in improving the implementation of cervical cancer screening, management, and follow-up. This review aims to report the state of AI with respect to cervical cancer screening. We discuss the primary AI applications and development of AI technology for image recognition applied to detection of abnormal cytology and cervical neoplastic diseases, as well as the challenges that we anticipate in the future.",0
30409313,Utility of CD8 score by automated quantitative image analysis in head and neck squamous cell carcinoma,"Hartman DJ, Ahmad F, Ferris RL, Rimm DL, Pantanowitz L.",Oral Oncol. 2018 Nov;86:278-287. doi: 10.1016/j.oraloncology.2018.10.005. Epub 2018 Oct 11.,Hartman DJ,Oral Oncol,2018,10-11-2018,PMC6260977,NIHMS1510193,10.1016/j.oraloncology.2018.10.005,"INTRODUCTION: In head and neck squamous cell carcinoma (HNSCC) high numbers of tumor infiltrating CD8 T cells in the tumor microenvironment are associated with better outcome. However, no investigators have employed automated image analysis on whole slide images to permit CD8 scores for use in clinical practice. The aim of this study was to develop and validate an image analysis algorithm to automatically quantify CD8 T cells in patients with oropharyngeal HNSCC.
MATERIALS AND METHODS: Using brightfield image analysis results were cross-validated with fluorescence based quantification (AQUA™). A nuclear image algorithm designed to run on whole slide images was optimized to manual count. The algorithm was locked down and used on a cohort of whole tissue sections from HNSCC patients. Multivariate clinicopathologic parameters and outcomes were statistically correlated with image analysis results.
RESULTS: Linear correlation between manual counts and the customized CD8 algorithm was 0.943. A total of 74 oropharyngeal HNSCC cases were analyzed for CD8 immune cell infiltrate using this image analysis algorithm. A CD8 immune cell density above 136 cells/mm2 was associated with median survival of 18 years compared to 5 years. When multivariate modeling was performed, HPV infection was the only predictor of survival; however, when HPV was excluded only CD8 cell density predicts survival.
CONCLUSIONS: We report the successful technical development and clinical validation of an image algorithm to automate CD8 immune cell density for oropharyngeal HNSCC. Employing brightfield image analysis on entire tumor sections instead of tumor subcompartments permits this strategy to be widely implemented.","Utility of CD8 score by automated quantitative image analysis in head and neck squamous cell carcinoma INTRODUCTION: In head and neck squamous cell carcinoma (HNSCC) high numbers of tumor infiltrating CD8 T cells in the tumor microenvironment are associated with better outcome. However, no investigators have employed automated image analysis on whole slide images to permit CD8 scores for use in clinical practice. The aim of this study was to develop and validate an image analysis algorithm to automatically quantify CD8 T cells in patients with oropharyngeal HNSCC.
MATERIALS AND METHODS: Using brightfield image analysis results were cross-validated with fluorescence based quantification (AQUA™). A nuclear image algorithm designed to run on whole slide images was optimized to manual count. The algorithm was locked down and used on a cohort of whole tissue sections from HNSCC patients. Multivariate clinicopathologic parameters and outcomes were statistically correlated with image analysis results.
RESULTS: Linear correlation between manual counts and the customized CD8 algorithm was 0.943. A total of 74 oropharyngeal HNSCC cases were analyzed for CD8 immune cell infiltrate using this image analysis algorithm. A CD8 immune cell density above 136 cells/mm2 was associated with median survival of 18 years compared to 5 years. When multivariate modeling was performed, HPV infection was the only predictor of survival; however, when HPV was excluded only CD8 cell density predicts survival.
CONCLUSIONS: We report the successful technical development and clinical validation of an image algorithm to automate CD8 immune cell density for oropharyngeal HNSCC. Employing brightfield image analysis on entire tumor sections instead of tumor subcompartments permits this strategy to be widely implemented.",0
36607623,Deep Convolutional Neural Networks Detect no Morphological Differences Between Culture-Positive and Culture-Negative Infectious Keratitis Images,"Kogachi K, Lalitha P, Prajna NV, Gunasekaran R, Keenan JD, Campbell JP, Song X, Redd TK.",Transl Vis Sci Technol. 2023 Jan 3;12(1):12. doi: 10.1167/tvst.12.1.12.,Kogachi K,Transl Vis Sci Technol,2023,06-01-2023,PMC9836011,,10.1167/tvst.12.1.12,"PURPOSE: To determine whether convolutional neural networks can detect morphological differences between images of microbiologically positive and negative corneal ulcers.
METHODS: A cross-sectional comparison of prospectively collected data consisting of bacterial and fungal cultures and smears from eyes with acute infectious keratitis at Aravind Eye Hospital. Two convolutional neural network architectures (DenseNet and MobileNet) were trained using images obtained from handheld cameras collected from culture-positive and negative images and smear-positive and -negative images. Each architecture was trained on two image sets: (1) one with labels assigned using only culture results and (2) one using culture and smear results. The outcome measure was area under the receiver operating characteristic curve for predicting whether an ulcer would be microbiologically positive or negative.
RESULTS: There were 1970 images from 886 patients were included. None of the models were better than random chance at predicting positive microbiologic results (area under the receiver operating characteristic curve ranged from 0.49 to 0.56; all confidence intervals included 0.5).
CONCLUSIONS: These two state-of-the-art deep convolutional neural network architectures could not reliably predict whether a corneal ulcer would be microbiologically positive or negative based on clinical photographs. This absence of detectable morphological differences informs the future development of computer vision models trained to predict the causative agent in infectious keratitis using corneal photography.
TRANSLATIONAL RELEVANCE: These deep learning models were not able to identify morphological differences between microbiologically positive and negative corneal ulcers. This finding suggests that similar artificial intelligence models trained to identify the causative pathogen using only microbiologically positive cases may have potential to generalize well, including to cases with falsely negative microbiologic testing.","Deep Convolutional Neural Networks Detect no Morphological Differences Between Culture-Positive and Culture-Negative Infectious Keratitis Images PURPOSE: To determine whether convolutional neural networks can detect morphological differences between images of microbiologically positive and negative corneal ulcers.
METHODS: A cross-sectional comparison of prospectively collected data consisting of bacterial and fungal cultures and smears from eyes with acute infectious keratitis at Aravind Eye Hospital. Two convolutional neural network architectures (DenseNet and MobileNet) were trained using images obtained from handheld cameras collected from culture-positive and negative images and smear-positive and -negative images. Each architecture was trained on two image sets: (1) one with labels assigned using only culture results and (2) one using culture and smear results. The outcome measure was area under the receiver operating characteristic curve for predicting whether an ulcer would be microbiologically positive or negative.
RESULTS: There were 1970 images from 886 patients were included. None of the models were better than random chance at predicting positive microbiologic results (area under the receiver operating characteristic curve ranged from 0.49 to 0.56; all confidence intervals included 0.5).
CONCLUSIONS: These two state-of-the-art deep convolutional neural network architectures could not reliably predict whether a corneal ulcer would be microbiologically positive or negative based on clinical photographs. This absence of detectable morphological differences informs the future development of computer vision models trained to predict the causative agent in infectious keratitis using corneal photography.
TRANSLATIONAL RELEVANCE: These deep learning models were not able to identify morphological differences between microbiologically positive and negative corneal ulcers. This finding suggests that similar artificial intelligence models trained to identify the causative pathogen using only microbiologically positive cases may have potential to generalize well, including to cases with falsely negative microbiologic testing.",0
32932585,Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video,"Martinez M, Yang K, Constantinescu A, Stiefelhagen R.",Sensors (Basel). 2020 Sep 12;20(18):5202. doi: 10.3390/s20185202.,Martinez M,Sensors (Basel),2020,16-09-2020,PMC7571123,,10.3390/s20185202,"The current COVID-19 pandemic is having a major impact on our daily lives. Social distancing is one of the measures that has been implemented with the aim of slowing the spread of the disease, but it is difficult for blind people to comply with this. In this paper, we present a system that helps blind people to maintain physical distance to other persons using a combination of RGB and depth cameras. We use a real-time semantic segmentation algorithm on the RGB camera to detect where persons are and use the depth camera to assess the distance to them; then, we provide audio feedback through bone-conducting headphones if a person is closer than 1.5 m. Our system warns the user only if persons are nearby but does not react to non-person objects such as walls, trees or doors; thus, it is not intrusive, and it is possible to use it in combination with other assistive devices. We have tested our prototype system on one blind and four blindfolded persons, and found that the system is precise, easy to use, and amounts to low cognitive load.","Helping the Blind to Get through COVID-19: Social Distancing Assistant Using Real-Time Semantic Segmentation on RGB-D Video The current COVID-19 pandemic is having a major impact on our daily lives. Social distancing is one of the measures that has been implemented with the aim of slowing the spread of the disease, but it is difficult for blind people to comply with this. In this paper, we present a system that helps blind people to maintain physical distance to other persons using a combination of RGB and depth cameras. We use a real-time semantic segmentation algorithm on the RGB camera to detect where persons are and use the depth camera to assess the distance to them; then, we provide audio feedback through bone-conducting headphones if a person is closer than 1.5 m. Our system warns the user only if persons are nearby but does not react to non-person objects such as walls, trees or doors; thus, it is not intrusive, and it is possible to use it in combination with other assistive devices. We have tested our prototype system on one blind and four blindfolded persons, and found that the system is precise, easy to use, and amounts to low cognitive load.",0
28941728,Preoperative Prediction of Microvascular Invasion in Hepatocellular Carcinoma Using Quantitative Image Analysis,"Zheng J, Chakraborty J, Chapman WC, Gerst S, Gonen M, Pak LM, Jarnagin WR, DeMatteo RP, Do RKG, Simpson AL; Hepatopancreatobiliary Service in the Department of Surgery of the Memorial Sloan Kettering Cancer Center; Research Staff in the Department of Surgery at Washington University School of Medicine.",J Am Coll Surg. 2017 Dec;225(6):778-788.e1. doi: 10.1016/j.jamcollsurg.2017.09.003. Epub 2017 Sep 21.,Zheng J,J Am Coll Surg,2017,25-09-2017,PMC5705269,NIHMS907723,10.1016/j.jamcollsurg.2017.09.003,"BACKGROUND: Microvascular invasion (MVI) is a significant risk factor for early recurrence after resection or transplantation for hepatocellular carcinoma (HCC). Knowledge of MVI status would help guide treatment recommendations, but is generally identified after operation. This study aims to predict MVI preoperatively using quantitative image analysis.
STUDY DESIGN: One hundred and twenty patients from 2 institutions underwent resection of HCC from 2003 to 2015 were included. The largest tumor from preoperative CT was subjected to quantitative image analysis, which uses an automated computer algorithm to capture regional variation in CT enhancement patterns. Quantitative imaging features by automatic analysis, qualitative radiographic descriptors by 2 radiologists, and preoperative clinical variables were included in multivariate analysis to predict histologic MVI.
RESULTS: Histologic MVI was identified in 19 (37%) patients with tumors ≤5 cm and 34 (49%) patients with tumors >5 cm. Among patients with tumors ≤5 cm, none of the clinical findings or radiographic descriptors were associated with MVI; however, quantitative features based on angle co-occurrence matrix predicted MVI with an area under curve of 0.80, positive predictive value of 63%, and negative predictive value of 85%. In patients with tumors >5 cm, higher α-fetoprotein level, larger tumor size, and viral hepatitis history were associated with MVI, and radiographic descriptors were not. However, a multivariate model combining α-fetoprotein, tumor size, hepatitis status, and quantitative feature based on local binary pattern predicted MVI with area under curve of 0.88, positive predictive value of 72%, and negative predictive value of 96%.
CONCLUSIONS: This study reveals the potential importance of quantitative image analysis as a predictor of MVI.","Preoperative Prediction of Microvascular Invasion in Hepatocellular Carcinoma Using Quantitative Image Analysis BACKGROUND: Microvascular invasion (MVI) is a significant risk factor for early recurrence after resection or transplantation for hepatocellular carcinoma (HCC). Knowledge of MVI status would help guide treatment recommendations, but is generally identified after operation. This study aims to predict MVI preoperatively using quantitative image analysis.
STUDY DESIGN: One hundred and twenty patients from 2 institutions underwent resection of HCC from 2003 to 2015 were included. The largest tumor from preoperative CT was subjected to quantitative image analysis, which uses an automated computer algorithm to capture regional variation in CT enhancement patterns. Quantitative imaging features by automatic analysis, qualitative radiographic descriptors by 2 radiologists, and preoperative clinical variables were included in multivariate analysis to predict histologic MVI.
RESULTS: Histologic MVI was identified in 19 (37%) patients with tumors ≤5 cm and 34 (49%) patients with tumors >5 cm. Among patients with tumors ≤5 cm, none of the clinical findings or radiographic descriptors were associated with MVI; however, quantitative features based on angle co-occurrence matrix predicted MVI with an area under curve of 0.80, positive predictive value of 63%, and negative predictive value of 85%. In patients with tumors >5 cm, higher α-fetoprotein level, larger tumor size, and viral hepatitis history were associated with MVI, and radiographic descriptors were not. However, a multivariate model combining α-fetoprotein, tumor size, hepatitis status, and quantitative feature based on local binary pattern predicted MVI with area under curve of 0.88, positive predictive value of 72%, and negative predictive value of 96%.
CONCLUSIONS: This study reveals the potential importance of quantitative image analysis as a predictor of MVI.",0
39269753,Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study,"Soe NN, Yu Z, Latt PM, Lee D, Samra RS, Ge Z, Rahman R, Sun J, Ong JJ, Fairley CK, Zhang L.",J Med Internet Res. 2024 Sep 13;26:e52490. doi: 10.2196/52490.,Soe NN,J Med Internet Res,2024,13-09-2024,PMC11437223,,10.2196/52490,"BACKGROUND: The 2022 global outbreak of mpox has significantly impacted health facilities, and necessitated additional infection prevention and control measures and alterations to clinic processes. Early identification of suspected mpox cases will assist in mitigating these impacts.
OBJECTIVE: We aimed to develop and evaluate an artificial intelligence (AI)-based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic.
METHODS: We used a data set with 2200 images, that included mpox and non-mpox lesions images, collected from Melbourne Sexual Health Centre and web resources. We adopted deep learning approaches which involved 6 different deep learning architectures to train our AI models. We subsequently evaluated the performance of each model using a hold-out data set and an external validation data set to determine the optimal model for differentiating between mpox and non-mpox lesions.
RESULTS: The DenseNet-121 model outperformed other models with an overall area under the receiver operating characteristic curve (AUC) of 0.928, an accuracy of 0.848, a precision of 0.942, a recall of 0.742, and an F<sub>1</sub>-score of 0.834. Implementation of a region of interest approach significantly improved the performance of all models, with the AUC for the DenseNet-121 model increasing to 0.982. This approach resulted in an increase in the correct classification of mpox images from 79% (55/70) to 94% (66/70). The effectiveness of this approach was further validated by a visual analysis with gradient-weighted class activation mapping, demonstrating a reduction in false detection within the background of lesion images. On the external validation data set, ResNet-18 and DenseNet-121 achieved the highest performance. ResNet-18 achieved an AUC of 0.990 and an accuracy of 0.947, and DenseNet-121 achieved an AUC of 0.982 and an accuracy of 0.926.
CONCLUSIONS: Our study demonstrated it was possible to use an AI-based image recognition algorithm to accurately differentiate between mpox and common skin lesions. Our findings provide a foundation for future investigations aimed at refining the algorithm and establishing the place of such technology in a sexual health clinic.","Using AI to Differentiate Mpox From Common Skin Lesions in a Sexual Health Clinic: Algorithm Development and Validation Study BACKGROUND: The 2022 global outbreak of mpox has significantly impacted health facilities, and necessitated additional infection prevention and control measures and alterations to clinic processes. Early identification of suspected mpox cases will assist in mitigating these impacts.
OBJECTIVE: We aimed to develop and evaluate an artificial intelligence (AI)-based tool to differentiate mpox lesion images from other skin lesions seen in a sexual health clinic.
METHODS: We used a data set with 2200 images, that included mpox and non-mpox lesions images, collected from Melbourne Sexual Health Centre and web resources. We adopted deep learning approaches which involved 6 different deep learning architectures to train our AI models. We subsequently evaluated the performance of each model using a hold-out data set and an external validation data set to determine the optimal model for differentiating between mpox and non-mpox lesions.
RESULTS: The DenseNet-121 model outperformed other models with an overall area under the receiver operating characteristic curve (AUC) of 0.928, an accuracy of 0.848, a precision of 0.942, a recall of 0.742, and an F<sub>1</sub>-score of 0.834. Implementation of a region of interest approach significantly improved the performance of all models, with the AUC for the DenseNet-121 model increasing to 0.982. This approach resulted in an increase in the correct classification of mpox images from 79% (55/70) to 94% (66/70). The effectiveness of this approach was further validated by a visual analysis with gradient-weighted class activation mapping, demonstrating a reduction in false detection within the background of lesion images. On the external validation data set, ResNet-18 and DenseNet-121 achieved the highest performance. ResNet-18 achieved an AUC of 0.990 and an accuracy of 0.947, and DenseNet-121 achieved an AUC of 0.982 and an accuracy of 0.926.
CONCLUSIONS: Our study demonstrated it was possible to use an AI-based image recognition algorithm to accurately differentiate between mpox and common skin lesions. Our findings provide a foundation for future investigations aimed at refining the algorithm and establishing the place of such technology in a sexual health clinic.",0
30252971,Artificial Intelligence Applied to Osteoporosis: A Performance Comparison of Machine Learning Algorithms in Predicting Fragility Fractures From MRI Data,"Ferizi U, Besser H, Hysi P, Jacobs J, Rajapakse CS, Chen C, Saha PK, Honig S, Chang G.",J Magn Reson Imaging. 2019 Apr;49(4):1029-1038. doi: 10.1002/jmri.26280. Epub 2018 Sep 25.,Ferizi U,J Magn Reson Imaging,2019,26-09-2018,PMC7340101,NIHMS1033111,10.1002/jmri.26280,"BACKGROUND: A current challenge in osteoporosis is identifying patients at risk of bone fracture.
PURPOSE: To identify the machine learning classifiers that predict best osteoporotic bone fractures and, from the data, to highlight the imaging features and the anatomical regions that contribute most to prediction performance.
STUDY TYPE: Prospective (cross-sectional) case-control study.
POPULATION: Thirty-two women with prior fragility bone fractures, of mean age = 61.6 and body mass index (BMI) = 22.7 kg/m2 , and 60 women without fractures, of mean age = 62.3 and BMI = 21.4 kg/m2 . Field Strength/ Sequence: 3D FLASH at 3T.
ASSESSMENT: Quantitative MRI outcomes by software algorithms. Mechanical and topological microstructural parameters of the trabecular bone were calculated for five femoral regions, and added to the vector of features together with bone mineral density measurement, fracture risk assessment tool (FRAX) score, and personal characteristics such as age, weight, and height. We fitted 15 classifiers using 200 randomized cross-validation datasets. Statistical Tests: Data: Kolmogorov-Smirnov test for normality. Model Performance: sensitivity, specificity, precision, accuracy, F1-test, receiver operating characteristic curve (ROC). Two-sided t-test, with P < 0.05 for statistical significance.
RESULTS: The top three performing classifiers are RUS-boosted trees (in particular, performing best with head data, F1 = 0.64 ± 0.03), the logistic regression and the linear discriminant (both best with trochanteric datasets, F1 = 0.65 ± 0.03 and F1 = 0.67 ± 0.03, respectively). A permutation of these classifiers comprised the best three performers for four out of five anatomical datasets. After averaging across all the anatomical datasets, the score for the best performer, the boosted trees, was F1 = 0.63 ± 0.03 for All-features dataset, F1 = 0.52 ± 0.05 for the no-MRI dataset, and F1 = 0.48 ± 0.06 for the no-FRAX dataset. Data Conclusion: Of many classifiers, the RUS-boosted trees, the logistic regression, and the linear discriminant are best for predicting osteoporotic fracture. Both MRI and FRAX independently add value in identifying osteoporotic fractures. The femoral head, greater trochanter, and inter-trochanter anatomical regions within the proximal femur yielded better F1-scores for the best three classifiers.
LEVEL OF EVIDENCE: 2 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019;49:1029-1038.","Artificial Intelligence Applied to Osteoporosis: A Performance Comparison of Machine Learning Algorithms in Predicting Fragility Fractures From MRI Data BACKGROUND: A current challenge in osteoporosis is identifying patients at risk of bone fracture.
PURPOSE: To identify the machine learning classifiers that predict best osteoporotic bone fractures and, from the data, to highlight the imaging features and the anatomical regions that contribute most to prediction performance.
STUDY TYPE: Prospective (cross-sectional) case-control study.
POPULATION: Thirty-two women with prior fragility bone fractures, of mean age = 61.6 and body mass index (BMI) = 22.7 kg/m2 , and 60 women without fractures, of mean age = 62.3 and BMI = 21.4 kg/m2 . Field Strength/ Sequence: 3D FLASH at 3T.
ASSESSMENT: Quantitative MRI outcomes by software algorithms. Mechanical and topological microstructural parameters of the trabecular bone were calculated for five femoral regions, and added to the vector of features together with bone mineral density measurement, fracture risk assessment tool (FRAX) score, and personal characteristics such as age, weight, and height. We fitted 15 classifiers using 200 randomized cross-validation datasets. Statistical Tests: Data: Kolmogorov-Smirnov test for normality. Model Performance: sensitivity, specificity, precision, accuracy, F1-test, receiver operating characteristic curve (ROC). Two-sided t-test, with P < 0.05 for statistical significance.
RESULTS: The top three performing classifiers are RUS-boosted trees (in particular, performing best with head data, F1 = 0.64 ± 0.03), the logistic regression and the linear discriminant (both best with trochanteric datasets, F1 = 0.65 ± 0.03 and F1 = 0.67 ± 0.03, respectively). A permutation of these classifiers comprised the best three performers for four out of five anatomical datasets. After averaging across all the anatomical datasets, the score for the best performer, the boosted trees, was F1 = 0.63 ± 0.03 for All-features dataset, F1 = 0.52 ± 0.05 for the no-MRI dataset, and F1 = 0.48 ± 0.06 for the no-FRAX dataset. Data Conclusion: Of many classifiers, the RUS-boosted trees, the logistic regression, and the linear discriminant are best for predicting osteoporotic fracture. Both MRI and FRAX independently add value in identifying osteoporotic fractures. The femoral head, greater trochanter, and inter-trochanter anatomical regions within the proximal femur yielded better F1-scores for the best three classifiers.
LEVEL OF EVIDENCE: 2 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019;49:1029-1038.",0
35589255,Artificial intelligence for the prevention and clinical management of hepatocellular carcinoma,"Calderaro J, Seraphin TP, Luedde T, Simon TG.",J Hepatol. 2022 Jun;76(6):1348-1361. doi: 10.1016/j.jhep.2022.01.014.,Calderaro J,J Hepatol,2022,19-05-2022,PMC9126418,NIHMS1776807,10.1016/j.jhep.2022.01.014,"Hepatocellular carcinoma (HCC) currently represents the fifth most common malignancy and the third-leading cause of cancer-related death worldwide, with incidence and mortality rates that are increasing. Recently, artificial intelligence (AI) has emerged as a unique opportunity to improve the full spectrum of HCC clinical care, by improving HCC risk prediction, diagnosis, and prognostication. AI approaches include computational search algorithms, machine learning (ML) and deep learning (DL) models. ML consists of a computer running repeated iterations of models, in order to progressively improve performance of a specific task, such as classifying an outcome. DL models are a subtype of ML, based on neural network structures that are inspired by the neuroanatomy of the human brain. A growing body of recent data now apply DL models to diverse data sources - including electronic health record data, imaging modalities, histopathology and molecular biomarkers - to improve the accuracy of HCC risk prediction, detection and prediction of treatment response. Despite the promise of these early results, future research is still needed to standardise AI data, and to improve both the generalisability and interpretability of results. If such challenges can be overcome, AI has the potential to profoundly change the way in which care is provided to patients with or at risk of HCC.","Artificial intelligence for the prevention and clinical management of hepatocellular carcinoma Hepatocellular carcinoma (HCC) currently represents the fifth most common malignancy and the third-leading cause of cancer-related death worldwide, with incidence and mortality rates that are increasing. Recently, artificial intelligence (AI) has emerged as a unique opportunity to improve the full spectrum of HCC clinical care, by improving HCC risk prediction, diagnosis, and prognostication. AI approaches include computational search algorithms, machine learning (ML) and deep learning (DL) models. ML consists of a computer running repeated iterations of models, in order to progressively improve performance of a specific task, such as classifying an outcome. DL models are a subtype of ML, based on neural network structures that are inspired by the neuroanatomy of the human brain. A growing body of recent data now apply DL models to diverse data sources - including electronic health record data, imaging modalities, histopathology and molecular biomarkers - to improve the accuracy of HCC risk prediction, detection and prediction of treatment response. Despite the promise of these early results, future research is still needed to standardise AI data, and to improve both the generalisability and interpretability of results. If such challenges can be overcome, AI has the potential to profoundly change the way in which care is provided to patients with or at risk of HCC.",0
36688019,Artificial intelligence and inflammatory bowel disease: Where are we going?,"Da Rio L, Spadaccini M, Parigi TL, Gabbiadini R, Dal Buono A, Busacca A, Maselli R, Fugazza A, Colombo M, Carrara S, Franchellucci G, Alfarone L, Facciorusso A, Hassan C, Repici A, Armuzzi A.",World J Gastroenterol. 2023 Jan 21;29(3):508-520. doi: 10.3748/wjg.v29.i3.508.,Da Rio L,World J Gastroenterol,2023,23-01-2023,PMC9850939,,10.3748/wjg.v29.i3.508,"Inflammatory bowel diseases, namely ulcerative colitis and Crohn's disease, are chronic and relapsing conditions that pose a growing burden on healthcare systems worldwide. Because of their complex and partly unknown etiology and pathogenesis, the management of ulcerative colitis and Crohn's disease can prove challenging not only from a clinical point of view but also for resource optimization. Artificial intelligence, an umbrella term that encompasses any cognitive function developed by machines for learning or problem solving, and its subsets machine learning and deep learning are becoming ever more essential tools with a plethora of applications in most medical specialties. In this regard gastroenterology is no exception, and due to the importance of endoscopy and imaging numerous clinical studies have been gradually highlighting the relevant role that artificial intelligence has in inflammatory bowel diseases as well. The aim of this review was to summarize the most recent evidence on the use of artificial intelligence in inflammatory bowel diseases in various contexts such as diagnosis, follow-up, treatment, prognosis, cancer surveillance, data collection, and analysis. Moreover, insights into the potential further developments in this field and their effects on future clinical practice were discussed.","Artificial intelligence and inflammatory bowel disease: Where are we going? Inflammatory bowel diseases, namely ulcerative colitis and Crohn's disease, are chronic and relapsing conditions that pose a growing burden on healthcare systems worldwide. Because of their complex and partly unknown etiology and pathogenesis, the management of ulcerative colitis and Crohn's disease can prove challenging not only from a clinical point of view but also for resource optimization. Artificial intelligence, an umbrella term that encompasses any cognitive function developed by machines for learning or problem solving, and its subsets machine learning and deep learning are becoming ever more essential tools with a plethora of applications in most medical specialties. In this regard gastroenterology is no exception, and due to the importance of endoscopy and imaging numerous clinical studies have been gradually highlighting the relevant role that artificial intelligence has in inflammatory bowel diseases as well. The aim of this review was to summarize the most recent evidence on the use of artificial intelligence in inflammatory bowel diseases in various contexts such as diagnosis, follow-up, treatment, prognosis, cancer surveillance, data collection, and analysis. Moreover, insights into the potential further developments in this field and their effects on future clinical practice were discussed.",0
37799217,Reimagining Healthcare: Unleashing the Power of Artificial Intelligence in Medicine,"Iqbal J, Cortés Jaimes DC, Makineni P, Subramani S, Hemaida S, Thugu TR, Butt AN, Sikto JT, Kaur P, Lak MA, Augustine M, Shahzad R, Arain M.",Cureus. 2023 Sep 4;15(9):e44658. doi: 10.7759/cureus.44658. eCollection 2023 Sep.,Iqbal J,Cureus,2023,06-10-2023,PMC10549955,,10.7759/cureus.44658,"Artificial intelligence (AI) has opened new medical avenues and revolutionized diagnostic and therapeutic practices, allowing healthcare providers to overcome significant challenges associated with cost, disease management, accessibility, and treatment optimization. Prominent AI technologies such as machine learning (ML) and deep learning (DL) have immensely influenced diagnostics, patient monitoring, novel pharmaceutical discoveries, drug development, and telemedicine. Significant innovations and improvements in disease identification and early intervention have been made using AI-generated algorithms for clinical decision support systems and disease prediction models. AI has remarkably impacted clinical drug trials by amplifying research into drug efficacy, adverse events, and candidate molecular design. AI's precision and analysis regarding patients' genetic, environmental, and lifestyle factors have led to individualized treatment strategies. During the COVID-19 pandemic, AI-assisted telemedicine set a precedent for remote healthcare delivery and patient follow-up. Moreover, AI-generated applications and wearable devices have allowed ambulatory monitoring of vital signs. However, apart from being immensely transformative, AI's contribution to healthcare is subject to ethical and regulatory concerns. AI-backed data protection and algorithm transparency should be strictly adherent to ethical principles. Vigorous governance frameworks should be in place before incorporating AI in mental health interventions through AI-operated chatbots, medical education enhancements, and virtual reality-based training. The role of AI in medical decision-making has certain limitations, necessitating the importance of hands-on experience. Therefore, reaching an optimal balance between AI's capabilities and ethical considerations to ensure impartial and neutral performance in healthcare applications is crucial. This narrative review focuses on AI's impact on healthcare and the importance of ethical and balanced incorporation to make use of its full potential.","Reimagining Healthcare: Unleashing the Power of Artificial Intelligence in Medicine Artificial intelligence (AI) has opened new medical avenues and revolutionized diagnostic and therapeutic practices, allowing healthcare providers to overcome significant challenges associated with cost, disease management, accessibility, and treatment optimization. Prominent AI technologies such as machine learning (ML) and deep learning (DL) have immensely influenced diagnostics, patient monitoring, novel pharmaceutical discoveries, drug development, and telemedicine. Significant innovations and improvements in disease identification and early intervention have been made using AI-generated algorithms for clinical decision support systems and disease prediction models. AI has remarkably impacted clinical drug trials by amplifying research into drug efficacy, adverse events, and candidate molecular design. AI's precision and analysis regarding patients' genetic, environmental, and lifestyle factors have led to individualized treatment strategies. During the COVID-19 pandemic, AI-assisted telemedicine set a precedent for remote healthcare delivery and patient follow-up. Moreover, AI-generated applications and wearable devices have allowed ambulatory monitoring of vital signs. However, apart from being immensely transformative, AI's contribution to healthcare is subject to ethical and regulatory concerns. AI-backed data protection and algorithm transparency should be strictly adherent to ethical principles. Vigorous governance frameworks should be in place before incorporating AI in mental health interventions through AI-operated chatbots, medical education enhancements, and virtual reality-based training. The role of AI in medical decision-making has certain limitations, necessitating the importance of hands-on experience. Therefore, reaching an optimal balance between AI's capabilities and ethical considerations to ensure impartial and neutral performance in healthcare applications is crucial. This narrative review focuses on AI's impact on healthcare and the importance of ethical and balanced incorporation to make use of its full potential.",0
35564493,"Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review","Saleem F, Al-Ghamdi ASA, Alassafi MO, AlGhamdi SA.",Int J Environ Res Public Health. 2022 Apr 22;19(9):5099. doi: 10.3390/ijerph19095099.,Saleem F,Int J Environ Res Public Health,2022,14-05-2022,PMC9099605,,10.3390/ijerph19095099,"COVID-19 is a disease caused by SARS-CoV-2 and has been declared a worldwide pandemic by the World Health Organization due to its rapid spread. Since the first case was identified in Wuhan, China, the battle against this deadly disease started and has disrupted almost every field of life. Medical staff and laboratories are leading from the front, but researchers from various fields and governmental agencies have also proposed healthy ideas to protect each other. In this article, a Systematic Literature Review (SLR) is presented to highlight the latest developments in analyzing the COVID-19 data using machine learning and deep learning algorithms. The number of studies related to Machine Learning (ML), Deep Learning (DL), and mathematical models discussed in this research has shown a significant impact on forecasting and the spread of COVID-19. The results and discussion presented in this study are based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Out of 218 articles selected at the first stage, 57 met the criteria and were included in the review process. The findings are therefore associated with those 57 studies, which recorded that CNN (DL) and SVM (ML) are the most used algorithms for forecasting, classification, and automatic detection. The importance of the compartmental models discussed is that the models are useful for measuring the epidemiological features of COVID-19. Current findings suggest that it will take around 1.7 to 140 days for the epidemic to double in size based on the selected studies. The 12 estimates for the basic reproduction range from 0 to 7.1. The main purpose of this research is to illustrate the use of ML, DL, and mathematical models that can be helpful for the researchers to generate valuable solutions for higher authorities and the healthcare industry to reduce the impact of this epidemic.","Machine Learning, Deep Learning, and Mathematical Models to Analyze Forecasting and Epidemiology of COVID-19: A Systematic Literature Review COVID-19 is a disease caused by SARS-CoV-2 and has been declared a worldwide pandemic by the World Health Organization due to its rapid spread. Since the first case was identified in Wuhan, China, the battle against this deadly disease started and has disrupted almost every field of life. Medical staff and laboratories are leading from the front, but researchers from various fields and governmental agencies have also proposed healthy ideas to protect each other. In this article, a Systematic Literature Review (SLR) is presented to highlight the latest developments in analyzing the COVID-19 data using machine learning and deep learning algorithms. The number of studies related to Machine Learning (ML), Deep Learning (DL), and mathematical models discussed in this research has shown a significant impact on forecasting and the spread of COVID-19. The results and discussion presented in this study are based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Out of 218 articles selected at the first stage, 57 met the criteria and were included in the review process. The findings are therefore associated with those 57 studies, which recorded that CNN (DL) and SVM (ML) are the most used algorithms for forecasting, classification, and automatic detection. The importance of the compartmental models discussed is that the models are useful for measuring the epidemiological features of COVID-19. Current findings suggest that it will take around 1.7 to 140 days for the epidemic to double in size based on the selected studies. The 12 estimates for the basic reproduction range from 0 to 7.1. The main purpose of this research is to illustrate the use of ML, DL, and mathematical models that can be helpful for the researchers to generate valuable solutions for higher authorities and the healthcare industry to reduce the impact of this epidemic.",0
36909463,REPRODUCIBLE AND CLINICALLY TRANSLATABLE DEEP NEURAL NETWORKS FOR CANCER SCREENING,"Ahmed SR, Befano B, Lemay A, Egemen D, Rodriguez AC, Angara S, Desai K, Jeronimo J, Antani S, Campos N, Inturrisi F, Perkins R, Kreimer A, Wentzensen N, Herrero R, Del Pino M, Quint W, de Sanjose S, Schiffman M, Kalpathy-Cramer J.",Res Sq [Preprint]. 2023 Mar 3:rs.3.rs-2526701. doi: 10.21203/rs.3.rs-2526701/v1.,Ahmed SR,Res Sq,2023,13-03-2023,PMC10002800,,10.21203/rs.3.rs-2526701/v1,"Cervical cancer is a leading cause of cancer mortality, with approximately 90% of the 250,000 deaths per year occurring in low- and middle-income countries (LMIC). Secondary prevention with cervical screening involves detecting and treating precursor lesions; however, scaling screening efforts in LMIC has been hampered by infrastructure and cost constraints. Recent work has supported the development of an artificial intelligence (AI) pipeline on digital images of the cervix to achieve an accurate and reliable diagnosis of treatable precancerous lesions. In particular, WHO guidelines emphasize visual triage of women testing positive for human papillomavirus (HPV) as the primary screen, and AI could assist in this triage task. Published AI reports have exhibited overfitting, lack of portability, and unrealistic, near-perfect performance estimates. To surmount recognized issues, we implemented a comprehensive deep-learning model selection and optimization study on a large, collated, multi-institutional dataset of 9,462 women (17,013 images). We evaluated relative portability, repeatability, and classification performance. The top performing model, when combined with HPV type, achieved an area under the Receiver Operating Characteristics (ROC) curve (AUC) of 0.89 within our study population of interest, and a limited total extreme misclassification rate of 3.4%, on held-aside test sets. Our work is among the first efforts at designing a robust, repeatable, accurate and clinically translatable deep-learning model for cervical screening.","REPRODUCIBLE AND CLINICALLY TRANSLATABLE DEEP NEURAL NETWORKS FOR CANCER SCREENING Cervical cancer is a leading cause of cancer mortality, with approximately 90% of the 250,000 deaths per year occurring in low- and middle-income countries (LMIC). Secondary prevention with cervical screening involves detecting and treating precursor lesions; however, scaling screening efforts in LMIC has been hampered by infrastructure and cost constraints. Recent work has supported the development of an artificial intelligence (AI) pipeline on digital images of the cervix to achieve an accurate and reliable diagnosis of treatable precancerous lesions. In particular, WHO guidelines emphasize visual triage of women testing positive for human papillomavirus (HPV) as the primary screen, and AI could assist in this triage task. Published AI reports have exhibited overfitting, lack of portability, and unrealistic, near-perfect performance estimates. To surmount recognized issues, we implemented a comprehensive deep-learning model selection and optimization study on a large, collated, multi-institutional dataset of 9,462 women (17,013 images). We evaluated relative portability, repeatability, and classification performance. The top performing model, when combined with HPV type, achieved an area under the Receiver Operating Characteristics (ROC) curve (AUC) of 0.89 within our study population of interest, and a limited total extreme misclassification rate of 3.4%, on held-aside test sets. Our work is among the first efforts at designing a robust, repeatable, accurate and clinically translatable deep-learning model for cervical screening.",0
35711777,Machine Learning Advances in Microbiology: A Review of Methods and Applications,"Jiang Y, Luo J, Huang D, Liu Y, Li DD.",Front Microbiol. 2022 May 26;13:925454. doi: 10.3389/fmicb.2022.925454. eCollection 2022.,Jiang Y,Front Microbiol,2022,17-06-2022,PMC9196628,,10.3389/fmicb.2022.925454,"Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery.","Machine Learning Advances in Microbiology: A Review of Methods and Applications Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery.",0
35991702,Dengue outbreak and severity prediction: current methods and the future scope,"Balakumar M, Vontela HR, Shinde VV, Kulshrestha V, Mishra B, Aduri R.",Virusdisease. 2022 Jun;33(2):125-131. doi: 10.1007/s13337-022-00767-x. Epub 2022 May 13.,Balakumar M,Virusdisease,2022,22-08-2022,PMC9381676,,10.1007/s13337-022-00767-x,"Dengue virus (DENV) is the causative agent of dengue fever and severe dengue. Every year, millions of people are infected with this virus. There is no vaccine available for this disease. Dengue virus is present in four serologically varying strains, DENV 1, 2, 3, and 4, and each of these serotypes is further classified into various genotypes based on the geographic distribution and genetic variance. Mosquitoes play the role of vectors for this disease. Tropical countries and some temperate parts of the world witness outbreaks of dengue mainly during the monsoon (rainy) seasons. Several algorithms have been developed to predict the occurrence and prognosis of dengue disease. These algorithms are mainly based on epidemiological data, climate factors, and online search patterns in the infected area. Most of these algorithms are based on either machine learning or deep learning techniques. We summarize the different software tools available for predicting the outbreaks of dengue based on the aforementioned factors, briefly outline the methodology used in these algorithms, and provide a comprehensive list of programs available for the same in this article.","Dengue outbreak and severity prediction: current methods and the future scope Dengue virus (DENV) is the causative agent of dengue fever and severe dengue. Every year, millions of people are infected with this virus. There is no vaccine available for this disease. Dengue virus is present in four serologically varying strains, DENV 1, 2, 3, and 4, and each of these serotypes is further classified into various genotypes based on the geographic distribution and genetic variance. Mosquitoes play the role of vectors for this disease. Tropical countries and some temperate parts of the world witness outbreaks of dengue mainly during the monsoon (rainy) seasons. Several algorithms have been developed to predict the occurrence and prognosis of dengue disease. These algorithms are mainly based on epidemiological data, climate factors, and online search patterns in the infected area. Most of these algorithms are based on either machine learning or deep learning techniques. We summarize the different software tools available for predicting the outbreaks of dengue based on the aforementioned factors, briefly outline the methodology used in these algorithms, and provide a comprehensive list of programs available for the same in this article.",0
36355921,Application of machine learning for multi-community COVID-19 outbreak predictions with wastewater surveillance,"Ai Y, He F, Lancaster E, Lee J.",PLoS One. 2022 Nov 10;17(11):e0277154. doi: 10.1371/journal.pone.0277154. eCollection 2022.,Ai Y,PLoS One,2022,10-11-2022,PMC9648834,,10.1371/journal.pone.0277154,"The potential of wastewater-based epidemiology (WBE) as a surveillance and early warning tool for the COVID-19 outbreak has been demonstrated. For areas with limited testing capacity, wastewater surveillance can provide information on the disease dynamic at a community level. A predictive model is a key to generating quantitative estimates of the infected population. Modeling longitudinal wastewater data can be challenging as biomarkers in wastewater are susceptible to variations caused by multiple factors associated with the wastewater matrix and the sewersheds characteristics. As WBE is an emerging trend, the model should be able to address the uncertainties of wastewater from different sewersheds. We proposed exploiting machine learning and deep learning techniques, which are supported by the growing WBE data. In this article, we reviewed the existing predictive models, among which the emerging machine learning/deep learning models showed great potential. However, most models are built for individual sewersheds with few features extracted from the wastewater. To fulfill the research gap, we compared different time-series and non-time-series models for their short-term predictive performance of COVID-19 cases in 9 diverse sewersheds. The time-series models, long short-term memory (LSTM) and Prophet, outcompeted the non-time-series models. Besides viral (SARS-CoV-2) loads and location identity, domain-specific features like biochemical parameters of wastewater, geographical parameters of the sewersheds, and some socioeconomic parameters of the communities can contribute to the models. With proper feature engineering and hyperparameter tuning, we believe machine learning models like LSTM can be a feasible solution for the COVID-19 trend prediction via WBE. Overall, this is a proof-of-concept study on the application of machine learning in COVID-19 WBE. Future studies are needed to deploy and maintain the model in more real-world applications.","Application of machine learning for multi-community COVID-19 outbreak predictions with wastewater surveillance The potential of wastewater-based epidemiology (WBE) as a surveillance and early warning tool for the COVID-19 outbreak has been demonstrated. For areas with limited testing capacity, wastewater surveillance can provide information on the disease dynamic at a community level. A predictive model is a key to generating quantitative estimates of the infected population. Modeling longitudinal wastewater data can be challenging as biomarkers in wastewater are susceptible to variations caused by multiple factors associated with the wastewater matrix and the sewersheds characteristics. As WBE is an emerging trend, the model should be able to address the uncertainties of wastewater from different sewersheds. We proposed exploiting machine learning and deep learning techniques, which are supported by the growing WBE data. In this article, we reviewed the existing predictive models, among which the emerging machine learning/deep learning models showed great potential. However, most models are built for individual sewersheds with few features extracted from the wastewater. To fulfill the research gap, we compared different time-series and non-time-series models for their short-term predictive performance of COVID-19 cases in 9 diverse sewersheds. The time-series models, long short-term memory (LSTM) and Prophet, outcompeted the non-time-series models. Besides viral (SARS-CoV-2) loads and location identity, domain-specific features like biochemical parameters of wastewater, geographical parameters of the sewersheds, and some socioeconomic parameters of the communities can contribute to the models. With proper feature engineering and hyperparameter tuning, we believe machine learning models like LSTM can be a feasible solution for the COVID-19 trend prediction via WBE. Overall, this is a proof-of-concept study on the application of machine learning in COVID-19 WBE. Future studies are needed to deploy and maintain the model in more real-world applications.",0
35025860,Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review,"da Silva Neto SR, Tabosa Oliveira T, Teixeira IV, Aguiar de Oliveira SB, Souza Sampaio V, Lynn T, Endo PT.",PLoS Negl Trop Dis. 2022 Jan 13;16(1):e0010061. doi: 10.1371/journal.pntd.0010061. eCollection 2022 Jan.,da Silva Neto SR,PLoS Negl Trop Dis,2022,13-01-2022,PMC8791518,,10.1371/journal.pntd.0010061,"BACKGROUND: Neglected tropical diseases (NTDs) primarily affect the poorest populations, often living in remote, rural areas, urban slums or conflict zones. Arboviruses are a significant NTD category spread by mosquitoes. Dengue, Chikungunya, and Zika are three arboviruses that affect a large proportion of the population in Latin and South America. The clinical diagnosis of these arboviral diseases is a difficult task due to the concurrent circulation of several arboviruses which present similar symptoms, inaccurate serologic tests resulting from cross-reaction and co-infection with other arboviruses.
OBJECTIVE: The goal of this paper is to present evidence on the state of the art of studies investigating the automatic classification of arboviral diseases to support clinical diagnosis based on Machine Learning (ML) and Deep Learning (DL) models.
METHOD: We carried out a Systematic Literature Review (SLR) in which Google Scholar was searched to identify key papers on the topic. From an initial 963 records (956 from string-based search and seven from a single backward snowballing procedure), only 15 relevant papers were identified.
RESULTS: Results show that current research is focused on the binary classification of Dengue, primarily using tree-based ML algorithms. Only one paper was identified using DL. Five papers presented solutions for multi-class problems, covering Dengue (and its variants) and Chikungunya. No papers were identified that investigated models to differentiate between Dengue, Chikungunya, and Zika.
CONCLUSIONS: The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment. It should help physicians in their decision-making process and, consequently, improve the use of resources and the patient's quality of life.","Machine learning and deep learning techniques to support clinical diagnosis of arboviral diseases: A systematic review BACKGROUND: Neglected tropical diseases (NTDs) primarily affect the poorest populations, often living in remote, rural areas, urban slums or conflict zones. Arboviruses are a significant NTD category spread by mosquitoes. Dengue, Chikungunya, and Zika are three arboviruses that affect a large proportion of the population in Latin and South America. The clinical diagnosis of these arboviral diseases is a difficult task due to the concurrent circulation of several arboviruses which present similar symptoms, inaccurate serologic tests resulting from cross-reaction and co-infection with other arboviruses.
OBJECTIVE: The goal of this paper is to present evidence on the state of the art of studies investigating the automatic classification of arboviral diseases to support clinical diagnosis based on Machine Learning (ML) and Deep Learning (DL) models.
METHOD: We carried out a Systematic Literature Review (SLR) in which Google Scholar was searched to identify key papers on the topic. From an initial 963 records (956 from string-based search and seven from a single backward snowballing procedure), only 15 relevant papers were identified.
RESULTS: Results show that current research is focused on the binary classification of Dengue, primarily using tree-based ML algorithms. Only one paper was identified using DL. Five papers presented solutions for multi-class problems, covering Dengue (and its variants) and Chikungunya. No papers were identified that investigated models to differentiate between Dengue, Chikungunya, and Zika.
CONCLUSIONS: The use of an efficient clinical decision support system for arboviral diseases can improve the quality of the entire clinical process, thus increasing the accuracy of the diagnosis and the associated treatment. It should help physicians in their decision-making process and, consequently, improve the use of resources and the patient's quality of life.",0
33907522,Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives,"Huang S, Yang J, Fong S, Zhao Q.",Int J Biol Sci. 2021 Apr 10;17(6):1581-1587. doi: 10.7150/ijbs.58855. eCollection 2021.,Huang S,Int J Biol Sci,2021,28-04-2021,PMC8071762,,10.7150/ijbs.58855,"Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic.","Artificial intelligence in the diagnosis of COVID-19: challenges and perspectives Artificial intelligence (AI) is being used to aid in various aspects of the COVID-19 crisis, including epidemiology, molecular research and drug development, medical diagnosis and treatment, and socioeconomics. The association of AI and COVID-19 can accelerate to rapidly diagnose positive patients. To learn the dynamics of a pandemic with relevance to AI, we search the literature using the different academic databases (PubMed, PubMed Central, Scopus, Google Scholar) and preprint servers (bioRxiv, medRxiv, arXiv). In the present review, we address the clinical applications of machine learning and deep learning, including clinical characteristics, electronic medical records, medical images (CT, X-ray, ultrasound images, etc.) in the COVID-19 diagnosis. The current challenges and future perspectives provided in this review can be used to direct an ideal deployment of AI technology in a pandemic.",0
33594374,SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning,"Magge A, Weissenbacher D, O'Connor K, Scotch M, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2022 Mar 21:2021.02.09.21251454. doi: 10.1101/2021.02.09.21251454.,Magge A,medRxiv,2022,17-02-2021,PMC7885933,,10.1101/2021.02.09.21251454,"The increase of social media usage across the globe has fueled efforts in digital epidemiology for mining valuable information such as medication use, adverse drug effects and reports of viral infections that directly and indirectly affect population health. Such specific information can, however, be scarce, hard to find, and mostly expressed in very colloquial language. In this work, we focus on a fundamental problem that enables social media mining for disease monitoring. We present and make available SEED, a natural language processing approach to detect symptom and disease mentions from social media data obtained from platforms such as Twitter and DailyStrength and to normalize them into UMLS terminology. Using multi-corpus training and deep learning models, the tool achieves an overall F1 score of 0.86 and 0.72 on DailyStrength and balanced Twitter datasets, significantly improving over previous approaches on the same datasets. We apply the tool on Twitter posts that report COVID19 symptoms, particularly to quantify whether the SEED system can extract symptoms absent in the training data. The study results also draw attention to the potential of multi-corpus training for performance improvements and the need for continuous training on newly obtained data for consistent performance amidst the ever-changing nature of the social media vocabulary.","SEED: Symptom Extraction from English Social Media Posts using Deep Learning and Transfer Learning The increase of social media usage across the globe has fueled efforts in digital epidemiology for mining valuable information such as medication use, adverse drug effects and reports of viral infections that directly and indirectly affect population health. Such specific information can, however, be scarce, hard to find, and mostly expressed in very colloquial language. In this work, we focus on a fundamental problem that enables social media mining for disease monitoring. We present and make available SEED, a natural language processing approach to detect symptom and disease mentions from social media data obtained from platforms such as Twitter and DailyStrength and to normalize them into UMLS terminology. Using multi-corpus training and deep learning models, the tool achieves an overall F1 score of 0.86 and 0.72 on DailyStrength and balanced Twitter datasets, significantly improving over previous approaches on the same datasets. We apply the tool on Twitter posts that report COVID19 symptoms, particularly to quantify whether the SEED system can extract symptoms absent in the training data. The study results also draw attention to the potential of multi-corpus training for performance improvements and the need for continuous training on newly obtained data for consistent performance amidst the ever-changing nature of the social media vocabulary.",0
35326674,The Role of Artificial Intelligence in Early Cancer Diagnosis,"Hunter B, Hindocha S, Lee RW.",Cancers (Basel). 2022 Mar 16;14(6):1524. doi: 10.3390/cancers14061524.,Hunter B,Cancers (Basel),2022,25-03-2022,PMC8946688,,10.3390/cancers14061524,"Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.","The Role of Artificial Intelligence in Early Cancer Diagnosis Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.",0
36056223,Usage of Compartmental Models in Predicting COVID-19 Outbreaks,"Zhang P, Feng K, Gong Y, Lee J, Lomonaco S, Zhao L.",AAPS J. 2022 Sep 2;24(5):98. doi: 10.1208/s12248-022-00743-9.,Zhang P,AAPS J,2022,02-09-2022,PMC9439263,,10.1208/s12248-022-00743-9,"Accurately predicting the spread of the SARS-CoV-2, the cause of the COVID-19 pandemic, is of great value for global regulatory authorities to overcome a number of challenges including medication shortage, outcome of vaccination, and control strategies planning. Modeling methods that are used to simulate and predict the spread of COVID-19 include compartmental model, structured metapopulations, agent-based networks, deep learning, and complex network, with compartmental modeling as one of the most widely used methods. Compartmental model has two noteworthy features, a flexible framework that allows users to easily customize the model structure and its high adaptivity that allows well-matured approaches (e.g., Bayesian inference and mixed-effects modeling) to improve parameter estimation. We retrospectively evaluated the prediction performances of the compartmental models on the CDC COVID-19 Mathematical Modeling webpage based on data collected between August 2020 and February 2021, and subsequently discussed in detail their corresponding model enhancement. Finally, we presented examples using the compartmental models to assist policymaking. By evaluating all models in parallel, we systemically evaluated the performance and evolution of using compartmental models for COVID-19 pandemic prediction. In summary, as a 100-year-old epidemic approach, the compartmental model presents a powerful tool that is extremely adaptive and can be readily customized and implemented to address new data or emerging needs during a pandemic.","Usage of Compartmental Models in Predicting COVID-19 Outbreaks Accurately predicting the spread of the SARS-CoV-2, the cause of the COVID-19 pandemic, is of great value for global regulatory authorities to overcome a number of challenges including medication shortage, outcome of vaccination, and control strategies planning. Modeling methods that are used to simulate and predict the spread of COVID-19 include compartmental model, structured metapopulations, agent-based networks, deep learning, and complex network, with compartmental modeling as one of the most widely used methods. Compartmental model has two noteworthy features, a flexible framework that allows users to easily customize the model structure and its high adaptivity that allows well-matured approaches (e.g., Bayesian inference and mixed-effects modeling) to improve parameter estimation. We retrospectively evaluated the prediction performances of the compartmental models on the CDC COVID-19 Mathematical Modeling webpage based on data collected between August 2020 and February 2021, and subsequently discussed in detail their corresponding model enhancement. Finally, we presented examples using the compartmental models to assist policymaking. By evaluating all models in parallel, we systemically evaluated the performance and evolution of using compartmental models for COVID-19 pandemic prediction. In summary, as a 100-year-old epidemic approach, the compartmental model presents a powerful tool that is extremely adaptive and can be readily customized and implemented to address new data or emerging needs during a pandemic.",0
32634717,Application of Artificial Intelligence in COVID-19 drug repurposing,"Mohanty S, Harun Ai Rashid M, Mridul M, Mohanty C, Swayamsiddha S.",Diabetes Metab Syndr. 2020 Sep-Oct;14(5):1027-1031. doi: 10.1016/j.dsx.2020.06.068. Epub 2020 Jul 3.,Mohanty S,Diabetes Metab Syndr,2020,08-07-2020,PMC7332938,,10.1016/j.dsx.2020.06.068,"BACKGROUND AND AIM: COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario.
METHODS: The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are 'COVID-19', ' AI ', and 'Drug Repurposing'.
RESULTS: AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool.
CONCLUSIONS: Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly.","Application of Artificial Intelligence in COVID-19 drug repurposing BACKGROUND AND AIM: COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario.
METHODS: The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are 'COVID-19', ' AI ', and 'Drug Repurposing'.
RESULTS: AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool.
CONCLUSIONS: Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly.",0
33284779,Artificial Intelligence in the Fight Against COVID-19: Scoping Review,"Abd-Alrazaq A, Alajlani M, Alhuwail D, Schneider J, Al-Kuwari S, Shah Z, Hamdi M, Househ M.",J Med Internet Res. 2020 Dec 15;22(12):e20756. doi: 10.2196/20756.,Abd-Alrazaq A,J Med Internet Res,2020,07-12-2020,PMC7744141,,10.2196/20756,"BACKGROUND: In December 2019, COVID-19 broke out in Wuhan, China, leading to national and international disruptions in health care, business, education, transportation, and nearly every aspect of our daily lives. Artificial intelligence (AI) has been leveraged amid the COVID-19 pandemic; however, little is known about its use for supporting public health efforts.
OBJECTIVE: This scoping review aims to explore how AI technology is being used during the COVID-19 pandemic, as reported in the literature. Thus, it is the first review that describes and summarizes features of the identified AI techniques and data sets used for their development and validation.
METHODS: A scoping review was conducted following the guidelines of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). We searched the most commonly used electronic databases (eg, MEDLINE, EMBASE, and PsycInfo) between April 10 and 12, 2020. These terms were selected based on the target intervention (ie, AI) and the target disease (ie, COVID-19). Two reviewers independently conducted study selection and data extraction. A narrative approach was used to synthesize the extracted data.
RESULTS: We considered 82 studies out of the 435 retrieved studies. The most common use of AI was diagnosing COVID-19 cases based on various indicators. AI was also employed in drug and vaccine discovery or repurposing and for assessing their safety. Further, the included studies used AI for forecasting the epidemic development of COVID-19 and predicting its potential hosts and reservoirs. Researchers used AI for patient outcome-related tasks such as assessing the severity of COVID-19, predicting mortality risk, its associated factors, and the length of hospital stay. AI was used for infodemiology to raise awareness to use water, sanitation, and hygiene. The most prominent AI technique used was convolutional neural network, followed by support vector machine.
CONCLUSIONS: The included studies showed that AI has the potential to fight against COVID-19. However, many of the proposed methods are not yet clinically accepted. Thus, the most rewarding research will be on methods promising value beyond COVID-19. More efforts are needed for developing standardized reporting protocols or guidelines for studies on AI.","Artificial Intelligence in the Fight Against COVID-19: Scoping Review BACKGROUND: In December 2019, COVID-19 broke out in Wuhan, China, leading to national and international disruptions in health care, business, education, transportation, and nearly every aspect of our daily lives. Artificial intelligence (AI) has been leveraged amid the COVID-19 pandemic; however, little is known about its use for supporting public health efforts.
OBJECTIVE: This scoping review aims to explore how AI technology is being used during the COVID-19 pandemic, as reported in the literature. Thus, it is the first review that describes and summarizes features of the identified AI techniques and data sets used for their development and validation.
METHODS: A scoping review was conducted following the guidelines of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). We searched the most commonly used electronic databases (eg, MEDLINE, EMBASE, and PsycInfo) between April 10 and 12, 2020. These terms were selected based on the target intervention (ie, AI) and the target disease (ie, COVID-19). Two reviewers independently conducted study selection and data extraction. A narrative approach was used to synthesize the extracted data.
RESULTS: We considered 82 studies out of the 435 retrieved studies. The most common use of AI was diagnosing COVID-19 cases based on various indicators. AI was also employed in drug and vaccine discovery or repurposing and for assessing their safety. Further, the included studies used AI for forecasting the epidemic development of COVID-19 and predicting its potential hosts and reservoirs. Researchers used AI for patient outcome-related tasks such as assessing the severity of COVID-19, predicting mortality risk, its associated factors, and the length of hospital stay. AI was used for infodemiology to raise awareness to use water, sanitation, and hygiene. The most prominent AI technique used was convolutional neural network, followed by support vector machine.
CONCLUSIONS: The included studies showed that AI has the potential to fight against COVID-19. However, many of the proposed methods are not yet clinically accepted. Thus, the most rewarding research will be on methods promising value beyond COVID-19. More efforts are needed for developing standardized reporting protocols or guidelines for studies on AI.",0
33930734,Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction,Younis MC.,Comput Med Imaging Graph. 2021 Jun;90:101921. doi: 10.1016/j.compmedimag.2021.101921. Epub 2021 Apr 23.,Younis MC,Comput Med Imaging Graph,2021,30-04-2021,PMC8062905,,10.1016/j.compmedimag.2021.101921,"Novel corona-virus (nCOV) has been declared as a pandemic that started from the city Wuhan of China. This deadly virus is infecting people rapidly and has targeted 4.93 million people across the world, with 227 K people being infected only in Italy. Cases of nCOV are quickly increasing whereas the number of nCOV test kits available in hospitals are limited. Under these conditions, an automated system for the classification of patients into nCOV positive and negative cases, is a much needed tool against the pandemic, helping in a selective use of the limited number of test kits. In this research, Convolutional Neural Network-based models (one block VGG, two block VGG, three block VGG, four block VGG, LetNet-5, AlexNet, and Resnet-50) have been employed for the detection of Corona-virus and SARS_MERS infected patients, distinguishing them from the healthy subjects, using lung X-ray scans, which has proven to be a challenging task, due to overlapping characteristics of different corona virus types. Furthermore, LSTM model has been used for time series forecasting of nCOV cases, in the following 10 days, in Italy. The evaluation results obtained, proved that the VGG1 model distinguishes the three classes at an accuracy of almost 91%, as compared to other models, whereas the approach based on the LSTM predicts the number of nCOV cases with 99% accuracy.","Evaluation of deep learning approaches for identification of different corona-virus species and time series prediction Novel corona-virus (nCOV) has been declared as a pandemic that started from the city Wuhan of China. This deadly virus is infecting people rapidly and has targeted 4.93 million people across the world, with 227 K people being infected only in Italy. Cases of nCOV are quickly increasing whereas the number of nCOV test kits available in hospitals are limited. Under these conditions, an automated system for the classification of patients into nCOV positive and negative cases, is a much needed tool against the pandemic, helping in a selective use of the limited number of test kits. In this research, Convolutional Neural Network-based models (one block VGG, two block VGG, three block VGG, four block VGG, LetNet-5, AlexNet, and Resnet-50) have been employed for the detection of Corona-virus and SARS_MERS infected patients, distinguishing them from the healthy subjects, using lung X-ray scans, which has proven to be a challenging task, due to overlapping characteristics of different corona virus types. Furthermore, LSTM model has been used for time series forecasting of nCOV cases, in the following 10 days, in Italy. The evaluation results obtained, proved that the VGG1 model distinguishes the three classes at an accuracy of almost 91%, as compared to other models, whereas the approach based on the LSTM predicts the number of nCOV cases with 99% accuracy.",0
37889739,When Everything Becomes Bigger: Big Data for Big Poultry Production,"Franzo G, Legnardi M, Faustini G, Tucciarone CM, Cecchinato M.",Animals (Basel). 2023 May 30;13(11):1804. doi: 10.3390/ani13111804.,Franzo G,Animals (Basel),2023,27-10-2023,PMC10252109,,10.3390/ani13111804,"In future decades, the demand for poultry meat and eggs is predicted to considerably increase in pace with human population growth. Although this expansion clearly represents a remarkable opportunity for the sector, it conceals a multitude of challenges. Pollution and land erosion, competition for limited resources between animal and human nutrition, animal welfare concerns, limitations on the use of growth promoters and antimicrobial agents, and increasing risks and effects of animal infectious diseases and zoonoses are several topics that have received attention from authorities and the public. The increase in poultry production must be achieved mainly through optimization and increased efficiency. The increasing ability to generate large amounts of data (""big data"") is pervasive in both modern society and the farming industry. Information accessibility-coupled with the availability of tools and computational power to store, share, integrate, and analyze data with automatic and flexible algorithms-offers an unprecedented opportunity to develop tools to maximize farm profitability, reduce socio-environmental impacts, and increase animal and human health and welfare. A detailed description of all topics and applications of big data analysis in poultry farming would be infeasible. Therefore, the present work briefly reviews the application of sensor technologies, such as optical, acoustic, and wearable sensors, as well as infrared thermal imaging and optical flow, to poultry farming. The principles and benefits of advanced statistical techniques, such as machine learning and deep learning, and their use in developing effective and reliable classification and prediction models to benefit the farming system, are also discussed. Finally, recent progress in pathogen genome sequencing and analysis is discussed, highlighting practical applications in epidemiological tracking, and reconstruction of microorganisms' population dynamics, evolution, and spread. The benefits of the objective evaluation of the effectiveness of applied control strategies are also considered. Although human-artificial intelligence collaborations in the livestock sector can be frightening because they require farmers and employees in the sector to adapt to new roles, challenges, and competencies-and because several unknowns, limitations, and open-ended questions are inevitable-their overall benefits appear to be far greater than their drawbacks. As more farms and companies connect to technology, artificial intelligence (AI) and sensing technologies will begin to play a greater role in identifying patterns and solutions to pressing problems in modern animal farming, thus providing remarkable production-based and commercial advantages. Moreover, the combination of diverse sources and types of data will also become fundamental for the development of predictive models able to anticipate, rather than merely detect, disease occurrence. The increasing availability of sensors, infrastructures, and tools for big data collection, storage, sharing, and analysis-together with the use of open standards and integration with pathogen molecular epidemiology-have the potential to address the major challenge of producing higher-quality, more healthful food on a larger scale in a more sustainable manner, thereby protecting ecosystems, preserving natural resources, and improving animal and human welfare and health.","When Everything Becomes Bigger: Big Data for Big Poultry Production In future decades, the demand for poultry meat and eggs is predicted to considerably increase in pace with human population growth. Although this expansion clearly represents a remarkable opportunity for the sector, it conceals a multitude of challenges. Pollution and land erosion, competition for limited resources between animal and human nutrition, animal welfare concerns, limitations on the use of growth promoters and antimicrobial agents, and increasing risks and effects of animal infectious diseases and zoonoses are several topics that have received attention from authorities and the public. The increase in poultry production must be achieved mainly through optimization and increased efficiency. The increasing ability to generate large amounts of data (""big data"") is pervasive in both modern society and the farming industry. Information accessibility-coupled with the availability of tools and computational power to store, share, integrate, and analyze data with automatic and flexible algorithms-offers an unprecedented opportunity to develop tools to maximize farm profitability, reduce socio-environmental impacts, and increase animal and human health and welfare. A detailed description of all topics and applications of big data analysis in poultry farming would be infeasible. Therefore, the present work briefly reviews the application of sensor technologies, such as optical, acoustic, and wearable sensors, as well as infrared thermal imaging and optical flow, to poultry farming. The principles and benefits of advanced statistical techniques, such as machine learning and deep learning, and their use in developing effective and reliable classification and prediction models to benefit the farming system, are also discussed. Finally, recent progress in pathogen genome sequencing and analysis is discussed, highlighting practical applications in epidemiological tracking, and reconstruction of microorganisms' population dynamics, evolution, and spread. The benefits of the objective evaluation of the effectiveness of applied control strategies are also considered. Although human-artificial intelligence collaborations in the livestock sector can be frightening because they require farmers and employees in the sector to adapt to new roles, challenges, and competencies-and because several unknowns, limitations, and open-ended questions are inevitable-their overall benefits appear to be far greater than their drawbacks. As more farms and companies connect to technology, artificial intelligence (AI) and sensing technologies will begin to play a greater role in identifying patterns and solutions to pressing problems in modern animal farming, thus providing remarkable production-based and commercial advantages. Moreover, the combination of diverse sources and types of data will also become fundamental for the development of predictive models able to anticipate, rather than merely detect, disease occurrence. The increasing availability of sensors, infrastructures, and tools for big data collection, storage, sharing, and analysis-together with the use of open standards and integration with pathogen molecular epidemiology-have the potential to address the major challenge of producing higher-quality, more healthful food on a larger scale in a more sustainable manner, thereby protecting ecosystems, preserving natural resources, and improving animal and human welfare and health.",0
34674660,GACDN: generative adversarial feature completion and diagnosis network for COVID-19,"Zhu Q, Ye H, Sun L, Li Z, Wang R, Shi F, Shen D, Zhang D.",BMC Med Imaging. 2021 Oct 21;21(1):154. doi: 10.1186/s12880-021-00681-6.,Zhu Q,BMC Med Imaging,2021,22-10-2021,PMC8529574,,10.1186/s12880-021-00681-6,"BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) causes tens of million infection world-wide. Many machine learning methods have been proposed for the computer-aided diagnosis between COVID-19 and community-acquired pneumonia (CAP) from chest computed tomography (CT) images. Most of these methods utilized the location-specific handcrafted features based on the segmentation results to improve the diagnose performance. However, the prerequisite segmentation step is time-consuming and needs the intervention by lots of expert radiologists, which cannot be achieved in the areas with limited medical resources.
METHODS: We propose a generative adversarial feature completion and diagnosis network (GACDN) that simultaneously generates handcrafted features by radiomic counterparts and makes accurate diagnoses based on both original and generated features. Specifically, we first calculate the radiomic features from the CT images. Then, in order to fast obtain the location-specific handcrafted features, we use the proposed GACDN to generate them by its corresponding radiomic features. Finally, we use both radiomic features and location-specific handcrafted features for COVID-19 diagnosis.
RESULTS: For the performance of our generated location-specific handcrafted features, the results of four basic classifiers show that it has an average of 3.21% increase in diagnoses accuracy. Besides, the experimental results on COVID-19 dataset show that our proposed method achieved superior performance in COVID-19 vs. community acquired pneumonia (CAP) classification compared with the state-of-the-art methods.
CONCLUSIONS: The proposed method significantly improves the diagnoses accuracy of COVID-19 vs. CAP in the condition of incomplete location-specific handcrafted features. Besides, it is also applicable in some regions lacking of expert radiologists and high-performance computing resources.","GACDN: generative adversarial feature completion and diagnosis network for COVID-19 BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) causes tens of million infection world-wide. Many machine learning methods have been proposed for the computer-aided diagnosis between COVID-19 and community-acquired pneumonia (CAP) from chest computed tomography (CT) images. Most of these methods utilized the location-specific handcrafted features based on the segmentation results to improve the diagnose performance. However, the prerequisite segmentation step is time-consuming and needs the intervention by lots of expert radiologists, which cannot be achieved in the areas with limited medical resources.
METHODS: We propose a generative adversarial feature completion and diagnosis network (GACDN) that simultaneously generates handcrafted features by radiomic counterparts and makes accurate diagnoses based on both original and generated features. Specifically, we first calculate the radiomic features from the CT images. Then, in order to fast obtain the location-specific handcrafted features, we use the proposed GACDN to generate them by its corresponding radiomic features. Finally, we use both radiomic features and location-specific handcrafted features for COVID-19 diagnosis.
RESULTS: For the performance of our generated location-specific handcrafted features, the results of four basic classifiers show that it has an average of 3.21% increase in diagnoses accuracy. Besides, the experimental results on COVID-19 dataset show that our proposed method achieved superior performance in COVID-19 vs. community acquired pneumonia (CAP) classification compared with the state-of-the-art methods.
CONCLUSIONS: The proposed method significantly improves the diagnoses accuracy of COVID-19 vs. CAP in the condition of incomplete location-specific handcrafted features. Besides, it is also applicable in some regions lacking of expert radiologists and high-performance computing resources.",0
35264189,"Application of machine learning in understanding plant virus pathogenesis: trends and perspectives on emergence, diagnosis, host-virus interplay and management","Ghosh D, Chakraborty S, Kodamana H, Chakraborty S.",Virol J. 2022 Mar 9;19(1):42. doi: 10.1186/s12985-022-01767-5.,Ghosh D,Virol J,2022,10-03-2022,PMC8905280,,10.1186/s12985-022-01767-5,"BACKGROUND: Inclusion of high throughput technologies in the field of biology has generated massive amounts of data in the recent years. Now, transforming these huge volumes of data into knowledge is the primary challenge in computational biology. The traditional methods of data analysis have failed to carry out the task. Hence, researchers are turning to machine learning based approaches for the analysis of high-dimensional big data. In machine learning, once a model is trained with a training dataset, it can be applied on a testing dataset which is independent. In current times, deep learning algorithms further promote the application of machine learning in several field of biology including plant virology.
MAIN BODY: Plant viruses have emerged as one of the principal global threats to food security due to their devastating impact on crops and vegetables. The emergence of new viral strains and species help viruses to evade the concurrent preventive methods. According to a survey conducted in 2014, plant viruses are anticipated to cause a global yield loss of more than thirty billion USD per year. In order to design effective, durable and broad-spectrum management protocols, it is very important to understand the mechanistic details of viral pathogenesis. The application of machine learning enables precise diagnosis of plant viral diseases at an early stage. Furthermore, the development of several machine learning-guided bioinformatics platforms has primed plant virologists to understand the host-virus interplay better. In addition, machine learning has tremendous potential in deciphering the pattern of plant virus evolution and emergence as well as in developing viable control options.
CONCLUSIONS: Considering a significant progress in the application of machine learning in understanding plant virology, this review highlights an introductory note on machine learning and comprehensively discusses the trends and prospects of machine learning in the diagnosis of viral diseases, understanding host-virus interplay and emergence of plant viruses.","Application of machine learning in understanding plant virus pathogenesis: trends and perspectives on emergence, diagnosis, host-virus interplay and management BACKGROUND: Inclusion of high throughput technologies in the field of biology has generated massive amounts of data in the recent years. Now, transforming these huge volumes of data into knowledge is the primary challenge in computational biology. The traditional methods of data analysis have failed to carry out the task. Hence, researchers are turning to machine learning based approaches for the analysis of high-dimensional big data. In machine learning, once a model is trained with a training dataset, it can be applied on a testing dataset which is independent. In current times, deep learning algorithms further promote the application of machine learning in several field of biology including plant virology.
MAIN BODY: Plant viruses have emerged as one of the principal global threats to food security due to their devastating impact on crops and vegetables. The emergence of new viral strains and species help viruses to evade the concurrent preventive methods. According to a survey conducted in 2014, plant viruses are anticipated to cause a global yield loss of more than thirty billion USD per year. In order to design effective, durable and broad-spectrum management protocols, it is very important to understand the mechanistic details of viral pathogenesis. The application of machine learning enables precise diagnosis of plant viral diseases at an early stage. Furthermore, the development of several machine learning-guided bioinformatics platforms has primed plant virologists to understand the host-virus interplay better. In addition, machine learning has tremendous potential in deciphering the pattern of plant virus evolution and emergence as well as in developing viable control options.
CONCLUSIONS: Considering a significant progress in the application of machine learning in understanding plant virology, this review highlights an introductory note on machine learning and comprehensively discusses the trends and prospects of machine learning in the diagnosis of viral diseases, understanding host-virus interplay and emergence of plant viruses.",0
35070385,Application of artificial intelligence in COVID-19 medical area: a systematic review,"Chang Z, Zhan Z, Zhao Z, You Z, Liu Y, Yan Z, Fu Y, Liang W, Zhao L.",J Thorac Dis. 2021 Dec;13(12):7034-7053. doi: 10.21037/jtd-21-747.,Chang Z,J Thorac Dis,2021,24-01-2022,PMC8743418,,10.21037/jtd-21-747,"BACKGROUND: Coronavirus disease 2019 (COVID-19) has caused a large-scale global epidemic, impacting international politics and the economy. At present, there is no particularly effective medicine and treatment plan. Therefore, it is urgent and significant to find new technologies to diagnose early, isolate early, and treat early. Multimodal data drove artificial intelligence (AI) can potentially be the option. During the COVID-19 Pandemic, AI provided cutting-edge applications in disease, medicine, treatment, and target recognition. This paper reviewed the literature on the intersection of AI and medicine to analyze and compare different AI model applications in the COVID-19 Pandemic, evaluate their effectiveness, show their advantages and differences, and introduce the main models and their characteristics.
METHODS: We searched PubMed, arXiv, medRxiv, and Google Scholar through February 2020 to identify studies on AI applications in the medical areas for the COVID-19 Pandemic.
RESULTS: We summarize the main AI applications in six areas: (I) epidemiology, (II) diagnosis, (III) progression, (IV) treatment, (V) psychological health impact, and (VI) data security. The ongoing development in AI has significantly improved prediction, contact tracing, screening, diagnosis, treatment, medication, and vaccine development for the COVID-19 Pandemic and reducing human intervention in medical practice.
DISCUSSION: This paper provides strong advice for using AI-based auxiliary tools for related applications of human diseases. We also discuss the clinicians' role in the further development of AI. They and AI researchers can integrate AI technology with current clinical processes and information systems into applications. In the future, AI personnel and medical workers will further cooperate closely.","Application of artificial intelligence in COVID-19 medical area: a systematic review BACKGROUND: Coronavirus disease 2019 (COVID-19) has caused a large-scale global epidemic, impacting international politics and the economy. At present, there is no particularly effective medicine and treatment plan. Therefore, it is urgent and significant to find new technologies to diagnose early, isolate early, and treat early. Multimodal data drove artificial intelligence (AI) can potentially be the option. During the COVID-19 Pandemic, AI provided cutting-edge applications in disease, medicine, treatment, and target recognition. This paper reviewed the literature on the intersection of AI and medicine to analyze and compare different AI model applications in the COVID-19 Pandemic, evaluate their effectiveness, show their advantages and differences, and introduce the main models and their characteristics.
METHODS: We searched PubMed, arXiv, medRxiv, and Google Scholar through February 2020 to identify studies on AI applications in the medical areas for the COVID-19 Pandemic.
RESULTS: We summarize the main AI applications in six areas: (I) epidemiology, (II) diagnosis, (III) progression, (IV) treatment, (V) psychological health impact, and (VI) data security. The ongoing development in AI has significantly improved prediction, contact tracing, screening, diagnosis, treatment, medication, and vaccine development for the COVID-19 Pandemic and reducing human intervention in medical practice.
DISCUSSION: This paper provides strong advice for using AI-based auxiliary tools for related applications of human diseases. We also discuss the clinicians' role in the further development of AI. They and AI researchers can integrate AI technology with current clinical processes and information systems into applications. In the future, AI personnel and medical workers will further cooperate closely.",0
32013791,Development and Validation of a Multitask Deep Learning Model for Severity Grading of Hip Osteoarthritis Features on Radiographs,"von Schacky CE, Sohn JH, Liu F, Ozhinsky E, Jungmann PM, Nardo L, Posadzy M, Foreman SC, Nevitt MC, Link TM, Pedoia V.",Radiology. 2020 Apr;295(1):136-145. doi: 10.1148/radiol.2020190925. Epub 2020 Feb 4.,von Schacky CE,Radiology,2020,05-02-2020,PMC7104703,NIHMS1582363,10.1148/radiol.2020190925,"Background A multitask deep learning model might be useful in large epidemiologic studies wherein detailed structural assessment of osteoarthritis still relies on expert radiologists' readings. The potential of such a model in clinical routine should be investigated. Purpose To develop a multitask deep learning model for grading radiographic hip osteoarthritis features on radiographs and compare its performance to that of attending-level radiologists. Materials and Methods This retrospective study analyzed hip joints seen on weight-bearing anterior-posterior pelvic radiographs from participants in the Osteoarthritis Initiative (OAI). Participants were recruited from February 2004 to May 2006 for baseline measurements, and follow-up was performed 48 months later. Femoral osteophytes (FOs), acetabular osteophytes (AOs), and joint-space narrowing (JSN) were graded as absent, mild, moderate, or severe according to the Osteoarthritis Research Society International atlas. Subchondral sclerosis and subchondral cysts were graded as present or absent. The participants were split at 80% (n = 3494), 10% (n = 437), and 10% (n = 437) by using split-sample validation into training, validation, and testing sets, respectively. The multitask neural network was based on DenseNet-161, a shared convolutional features extractor trained with multitask loss function. Model performance was evaluated in the internal test set from the OAI and in an external test set by using temporal and geographic validation consisting of routine clinical radiographs. Results A total of 4368 participants (mean age, 61.0 years ± 9.2 [standard deviation]; 2538 women) were evaluated (15 364 hip joints on 7738 weight-bearing anterior-posterior pelvic radiographs). The accuracy of the model for assessing these five features was 86.7% (1333 of 1538) for FOs, 69.9% (1075 of 1538) for AOs, 81.7% (1257 of 1538) for JSN, 95.8% (1473 of 1538) for subchondral sclerosis, and 97.6% (1501 of 1538) for subchondral cysts in the internal test set, and 82.7% (86 of 104) for FOS, 65.4% (68 of 104) for AOs, 80.8% (84 of 104) for JSN, 88.5% (92 of 104) for subchondral sclerosis, and 91.3% (95 of 104) for subchondral cysts in the external test set. Conclusion A multitask deep learning model is a feasible approach to reliably assess radiographic features of hip osteoarthritis. © RSNA, 2020 Online supplemental material is available for this article.","Development and Validation of a Multitask Deep Learning Model for Severity Grading of Hip Osteoarthritis Features on Radiographs Background A multitask deep learning model might be useful in large epidemiologic studies wherein detailed structural assessment of osteoarthritis still relies on expert radiologists' readings. The potential of such a model in clinical routine should be investigated. Purpose To develop a multitask deep learning model for grading radiographic hip osteoarthritis features on radiographs and compare its performance to that of attending-level radiologists. Materials and Methods This retrospective study analyzed hip joints seen on weight-bearing anterior-posterior pelvic radiographs from participants in the Osteoarthritis Initiative (OAI). Participants were recruited from February 2004 to May 2006 for baseline measurements, and follow-up was performed 48 months later. Femoral osteophytes (FOs), acetabular osteophytes (AOs), and joint-space narrowing (JSN) were graded as absent, mild, moderate, or severe according to the Osteoarthritis Research Society International atlas. Subchondral sclerosis and subchondral cysts were graded as present or absent. The participants were split at 80% (n = 3494), 10% (n = 437), and 10% (n = 437) by using split-sample validation into training, validation, and testing sets, respectively. The multitask neural network was based on DenseNet-161, a shared convolutional features extractor trained with multitask loss function. Model performance was evaluated in the internal test set from the OAI and in an external test set by using temporal and geographic validation consisting of routine clinical radiographs. Results A total of 4368 participants (mean age, 61.0 years ± 9.2 [standard deviation]; 2538 women) were evaluated (15 364 hip joints on 7738 weight-bearing anterior-posterior pelvic radiographs). The accuracy of the model for assessing these five features was 86.7% (1333 of 1538) for FOs, 69.9% (1075 of 1538) for AOs, 81.7% (1257 of 1538) for JSN, 95.8% (1473 of 1538) for subchondral sclerosis, and 97.6% (1501 of 1538) for subchondral cysts in the internal test set, and 82.7% (86 of 104) for FOS, 65.4% (68 of 104) for AOs, 80.8% (84 of 104) for JSN, 88.5% (92 of 104) for subchondral sclerosis, and 91.3% (95 of 104) for subchondral cysts in the external test set. Conclusion A multitask deep learning model is a feasible approach to reliably assess radiographic features of hip osteoarthritis. © RSNA, 2020 Online supplemental material is available for this article.",0
33041533,Applications of artificial intelligence in battling against covid-19: A literature review,Tayarani N MH.,Chaos Solitons Fractals. 2021 Jan;142:110338. doi: 10.1016/j.chaos.2020.110338. Epub 2020 Oct 3.,Tayarani N MH,Chaos Solitons Fractals,2021,12-10-2020,PMC7532790,,10.1016/j.chaos.2020.110338,"Colloquially known as coronavirus, the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2), that causes CoronaVirus Disease 2019 (COVID-19), has become a matter of grave concern for every country around the world. The rapid growth of the pandemic has wreaked havoc and prompted the need for immediate reactions to curb the effects. To manage the problems, many research in a variety of area of science have started studying the issue. Artificial Intelligence is among the area of science that has found great applications in tackling the problem in many aspects. Here, we perform an overview on the applications of AI in a variety of fields including diagnosis of the disease via different types of tests and symptoms, monitoring patients, identifying severity of a patient, processing covid-19 related imaging tests, epidemiology, pharmaceutical studies, etc. The aim of this paper is to perform a comprehensive survey on the applications of AI in battling against the difficulties the outbreak has caused. Thus we cover every way that AI approaches have been employed and to cover all the research until the writing of this paper. We try organize the works in a way that overall picture is comprehensible. Such a picture, although full of details, is very helpful in understand where AI sits in current pandemonium. We also tried to conclude the paper with ideas on how the problems can be tackled in a better way and provide some suggestions for future works.","Applications of artificial intelligence in battling against covid-19: A literature review Colloquially known as coronavirus, the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2), that causes CoronaVirus Disease 2019 (COVID-19), has become a matter of grave concern for every country around the world. The rapid growth of the pandemic has wreaked havoc and prompted the need for immediate reactions to curb the effects. To manage the problems, many research in a variety of area of science have started studying the issue. Artificial Intelligence is among the area of science that has found great applications in tackling the problem in many aspects. Here, we perform an overview on the applications of AI in a variety of fields including diagnosis of the disease via different types of tests and symptoms, monitoring patients, identifying severity of a patient, processing covid-19 related imaging tests, epidemiology, pharmaceutical studies, etc. The aim of this paper is to perform a comprehensive survey on the applications of AI in battling against the difficulties the outbreak has caused. Thus we cover every way that AI approaches have been employed and to cover all the research until the writing of this paper. We try organize the works in a way that overall picture is comprehensible. Such a picture, although full of details, is very helpful in understand where AI sits in current pandemonium. We also tried to conclude the paper with ideas on how the problems can be tackled in a better way and provide some suggestions for future works.",0
32585932,Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation,"Li Z, Gurgel H, Dessay N, Hu L, Xu L, Gong P.",Int J Environ Res Public Health. 2020 Jun 23;17(12):4509. doi: 10.3390/ijerph17124509.,Li Z,Int J Environ Res Public Health,2020,27-06-2020,PMC7344967,,10.3390/ijerph17124509,"In recent years there has been an increasing use of satellite Earth observation (EO) data in dengue research, in particular the identification of landscape factors affecting dengue transmission. Summarizing landscape factors and satellite EO data sources, and making the information public are helpful for guiding future research and improving health decision-making. In this case, a review of the literature would appear to be an appropriate tool. However, this is not an easy-to-use tool. The review process mainly includes defining the topic, searching, screening at both title/abstract and full-text levels and data extraction that needs consistent knowledge from experts and is time-consuming and labor intensive. In this context, this study integrates the review process, text scoring, active learning (AL) mechanism, and bidirectional long short-term memory (BiLSTM) networks, and proposes a semi-supervised text classification framework that enables the efficient and accurate selection of the relevant articles. Specifically, text scoring and BiLSTM-based active learning were used to replace the title/abstract screening and full-text screening, respectively, which greatly reduces the human workload. In this study, 101 relevant articles were selected from 4 bibliographic databases, and a catalogue of essential dengue landscape factors was identified and divided into four categories: land use (LU), land cover (LC), topography and continuous land surface features. Moreover, various satellite EO sensors and products used for identifying landscape factors were tabulated. Finally, possible future directions of applying satellite EO data in dengue research in terms of landscape patterns, satellite sensors and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context.","Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation In recent years there has been an increasing use of satellite Earth observation (EO) data in dengue research, in particular the identification of landscape factors affecting dengue transmission. Summarizing landscape factors and satellite EO data sources, and making the information public are helpful for guiding future research and improving health decision-making. In this case, a review of the literature would appear to be an appropriate tool. However, this is not an easy-to-use tool. The review process mainly includes defining the topic, searching, screening at both title/abstract and full-text levels and data extraction that needs consistent knowledge from experts and is time-consuming and labor intensive. In this context, this study integrates the review process, text scoring, active learning (AL) mechanism, and bidirectional long short-term memory (BiLSTM) networks, and proposes a semi-supervised text classification framework that enables the efficient and accurate selection of the relevant articles. Specifically, text scoring and BiLSTM-based active learning were used to replace the title/abstract screening and full-text screening, respectively, which greatly reduces the human workload. In this study, 101 relevant articles were selected from 4 bibliographic databases, and a catalogue of essential dengue landscape factors was identified and divided into four categories: land use (LU), land cover (LC), topography and continuous land surface features. Moreover, various satellite EO sensors and products used for identifying landscape factors were tabulated. Finally, possible future directions of applying satellite EO data in dengue research in terms of landscape patterns, satellite sensors and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context.",0
38946986,Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records,"Wang L, Novoa-Laurentiev J, Cook C, Srivatsan S, Hua Y, Yang J, Miloslavsky E, Choi HK, Zhou L, Wallace ZS.",medRxiv [Preprint]. 2024 Jun 10:2024.06.09.24308603. doi: 10.1101/2024.06.09.24308603.,Wang L,medRxiv,2024,01-07-2024,PMC11213085,,10.1101/2024.06.09.24308603,"BACKGROUND: ANCA-associated vasculitis (AAV) is a rare but serious disease. Traditional case-identification methods using claims data can be time-intensive and may miss important subgroups. We hypothesized that a deep learning model analyzing electronic health records (EHR) can more accurately identify AAV cases.
METHODS: We examined the Mass General Brigham (MGB) repository of clinical documentation from 12/1/1979 to 5/11/2021, using expert-curated keywords and ICD codes to identify a large cohort of potential AAV cases. Three labeled datasets (I, II, III) were created, each containing note sections. We trained and evaluated a range of machine learning and deep learning algorithms for note-level classification, using metrics like positive predictive value (PPV), sensitivity, F-score, area under the receiver operating characteristic curve (AUROC), and area under the precision and recall curve (AUPRC). The deep learning model was further evaluated for its ability to classify AAV cases at the patient-level, compared with rule-based algorithms in 2,000 randomly chosen samples.
RESULTS: Datasets I, II, and III comprised 6,000, 3,008, and 7,500 note sections, respectively. Deep learning achieved the highest AUROC in all three datasets, with scores of 0.983, 0.991, and 0.991. The deep learning approach also had among the highest PPVs across the three datasets (0.941, 0.954, and 0.800, respectively). In a test cohort of 2,000 cases, the deep learning model achieved a PPV of 0.262 and an estimated sensitivity of 0.975. Compared to the best rule-based algorithm, the deep learning model identified six additional AAV cases, representing 13% of the total.
CONCLUSION: The deep learning model effectively classifies clinical note sections for AAV diagnosis. Its application to EHR notes can potentially uncover additional cases missed by traditional rule-based methods.","Identification of an ANCA-Associated Vasculitis Cohort Using Deep Learning and Electronic Health Records BACKGROUND: ANCA-associated vasculitis (AAV) is a rare but serious disease. Traditional case-identification methods using claims data can be time-intensive and may miss important subgroups. We hypothesized that a deep learning model analyzing electronic health records (EHR) can more accurately identify AAV cases.
METHODS: We examined the Mass General Brigham (MGB) repository of clinical documentation from 12/1/1979 to 5/11/2021, using expert-curated keywords and ICD codes to identify a large cohort of potential AAV cases. Three labeled datasets (I, II, III) were created, each containing note sections. We trained and evaluated a range of machine learning and deep learning algorithms for note-level classification, using metrics like positive predictive value (PPV), sensitivity, F-score, area under the receiver operating characteristic curve (AUROC), and area under the precision and recall curve (AUPRC). The deep learning model was further evaluated for its ability to classify AAV cases at the patient-level, compared with rule-based algorithms in 2,000 randomly chosen samples.
RESULTS: Datasets I, II, and III comprised 6,000, 3,008, and 7,500 note sections, respectively. Deep learning achieved the highest AUROC in all three datasets, with scores of 0.983, 0.991, and 0.991. The deep learning approach also had among the highest PPVs across the three datasets (0.941, 0.954, and 0.800, respectively). In a test cohort of 2,000 cases, the deep learning model achieved a PPV of 0.262 and an estimated sensitivity of 0.975. Compared to the best rule-based algorithm, the deep learning model identified six additional AAV cases, representing 13% of the total.
CONCLUSION: The deep learning model effectively classifies clinical note sections for AAV diagnosis. Its application to EHR notes can potentially uncover additional cases missed by traditional rule-based methods.",0
34546931,New Insights Into Drug Repurposing for COVID-19 Using Deep Learning,"Lee CY, Chen YP.",IEEE Trans Neural Netw Learn Syst. 2021 Nov;32(11):4770-4780. doi: 10.1109/TNNLS.2021.3111745. Epub 2021 Oct 27.,Lee CY,IEEE Trans Neural Netw Learn Syst,2021,21-09-2021,PMC8843052,,10.1109/TNNLS.2021.3111745,"The coronavirus disease 2019 (COVID-19) has continued to spread worldwide since late 2019. To expedite the process of providing treatment to those who have contracted the disease and to ensure the accessibility of effective drugs, numerous strategies have been implemented to find potential anti-COVID-19 drugs in a short span of time. Motivated by this critical global challenge, in this review, we detail approaches that have been used for drug repurposing for COVID-19 and suggest improvements to the existing deep learning (DL) approach to identify and repurpose drugs to treat this complex disease. By optimizing hyperparameter settings, deploying suitable activation functions, and designing optimization algorithms, the improved DL approach will be able to perform feature extraction from quality big data, turning the traditional DL approach, referred to as a ""black box,"" which generalizes and learns the transmitted data, into a ""glass box"" that will have the interpretability of its rationale while maintaining a high level of prediction accuracy. When adopted for drug repurposing for COVID-19, this improved approach will create a new generation of DL approaches that can establish a cause and effect relationship as to why the repurposed drugs are suitable for treating COVID-19. Its ability can also be extended to repurpose drugs for other complex diseases, develop appropriate treatment strategies for new diseases, and provide precision medical treatment to patients, thus paving the way to discover new drugs that can potentially be effective for treating COVID-19.","New Insights Into Drug Repurposing for COVID-19 Using Deep Learning The coronavirus disease 2019 (COVID-19) has continued to spread worldwide since late 2019. To expedite the process of providing treatment to those who have contracted the disease and to ensure the accessibility of effective drugs, numerous strategies have been implemented to find potential anti-COVID-19 drugs in a short span of time. Motivated by this critical global challenge, in this review, we detail approaches that have been used for drug repurposing for COVID-19 and suggest improvements to the existing deep learning (DL) approach to identify and repurpose drugs to treat this complex disease. By optimizing hyperparameter settings, deploying suitable activation functions, and designing optimization algorithms, the improved DL approach will be able to perform feature extraction from quality big data, turning the traditional DL approach, referred to as a ""black box,"" which generalizes and learns the transmitted data, into a ""glass box"" that will have the interpretability of its rationale while maintaining a high level of prediction accuracy. When adopted for drug repurposing for COVID-19, this improved approach will create a new generation of DL approaches that can establish a cause and effect relationship as to why the repurposed drugs are suitable for treating COVID-19. Its ability can also be extended to repurpose drugs for other complex diseases, develop appropriate treatment strategies for new diseases, and provide precision medical treatment to patients, thus paving the way to discover new drugs that can potentially be effective for treating COVID-19.",0
33587262,DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images,"Dhiman G, Vinoth Kumar V, Kaur A, Sharma A.",Interdiscip Sci. 2021 Jun;13(2):260-272. doi: 10.1007/s12539-021-00418-7. Epub 2021 Feb 15.,Dhiman G,Interdiscip Sci,2021,15-02-2021,PMC7882874,,10.1007/s12539-021-00418-7,"In the hospital, a limited number of COVID-19 test kits are available due to the spike in cases every day. For this reason, a rapid alternative diagnostic option should be introduced as an automated detection method to prevent COVID-19 spreading among individuals. This article proposes multi-objective optimization and a deep-learning methodology for the detection of infected coronavirus patients with X-rays. J48 decision tree method classifies the deep characteristics of affected X-ray corona images to detect the contaminated patients effectively. Eleven different convolutional neuronal network-based (CNN) models were developed in this study to detect infected patients with coronavirus pneumonia using X-ray images (AlexNet, VGG16, VGG19, GoogleNet, ResNet18, ResNet500, ResNet101, InceptionV3, InceptionResNetV2, DenseNet201 and XceptionNet). In addition, the parameters of the CNN profound learning model are described using an emperor penguin optimizer with several objectives (MOEPO). A broad review reveals that the proposed model can categorise the X-ray images at the correct rates of precision, accuracy, recall, specificity and F1-score. Extensive test results show that the proposed model outperforms competitive models with well-known efficiency metrics. The proposed model is, therefore, useful for the real-time classification of X-ray chest images of COVID-19 disease.","DON: Deep Learning and Optimization-Based Framework for Detection of Novel Coronavirus Disease Using X-ray Images In the hospital, a limited number of COVID-19 test kits are available due to the spike in cases every day. For this reason, a rapid alternative diagnostic option should be introduced as an automated detection method to prevent COVID-19 spreading among individuals. This article proposes multi-objective optimization and a deep-learning methodology for the detection of infected coronavirus patients with X-rays. J48 decision tree method classifies the deep characteristics of affected X-ray corona images to detect the contaminated patients effectively. Eleven different convolutional neuronal network-based (CNN) models were developed in this study to detect infected patients with coronavirus pneumonia using X-ray images (AlexNet, VGG16, VGG19, GoogleNet, ResNet18, ResNet500, ResNet101, InceptionV3, InceptionResNetV2, DenseNet201 and XceptionNet). In addition, the parameters of the CNN profound learning model are described using an emperor penguin optimizer with several objectives (MOEPO). A broad review reveals that the proposed model can categorise the X-ray images at the correct rates of precision, accuracy, recall, specificity and F1-score. Extensive test results show that the proposed model outperforms competitive models with well-known efficiency metrics. The proposed model is, therefore, useful for the real-time classification of X-ray chest images of COVID-19 disease.",0
34481301,Emergence and evolution of big data science in HIV research: Bibliometric analysis of federally sponsored studies 2000-2019,"Liang C, Qiao S, Olatosi B, Lyu T, Li X.",Int J Med Inform. 2021 Oct;154:104558. doi: 10.1016/j.ijmedinf.2021.104558. Epub 2021 Aug 18.,Liang C,Int J Med Inform,2021,04-09-2021,PMC8529625,NIHMS1735490,10.1016/j.ijmedinf.2021.104558,"BACKGROUND: The rapid growth of inherently complex and heterogeneous data in HIV/AIDS research underscores the importance of Big Data Science. Recently, there have been increasing uptakes of Big Data techniques in basic, clinical, and public health fields of HIV/AIDS research. However, no studies have systematically elaborated on the evolving applications of Big Data in HIV/AIDS research. We sought to explore the emergence and evolution of Big Data Science in HIV/AIDS-related publications that were funded by the US federal agencies.
METHODS: We identified HIV/AIDS and Big Data related publications that were funded by seven federal agencies from 2000 to 2019 by integrating data from National Institutes of Health (NIH) ExPORTER, MEDLINE, and MeSH. Building on bibliometrics and Natural Language Processing (NLP) methods, we constructed co-occurrence networks using bibliographic metadata (e.g., countries, institutes, MeSH terms, and keywords) of the retrieved publications. We then detected clusters among the networks as well as the temporal dynamics of clusters, followed by expert evaluation and clinical implications.
RESULTS: We harnessed nearly 600 thousand publications related to HIV/AIDS, of which 19,528 publications relating to Big Data were included in bibliometric analysis. Results showed that (1) the number of Big Data publications has been increasing since 2000, (2) US institutes have been in close collaborations with China, Canada, and Germany, (3) some institutes (e.g., University of California system, MD Anderson Cancer Center, and Harvard Medical School) are among the most productive institutes and started using Big Data in HIV/AIDS research early, (4) Big Data research was not active in public health disciplines until 2015, (5) research topics such as genomics, HIV comorbidities, population-based studies, Electronic Health Records (EHR), social media, precision medicine, and methodologies such as machine learning, Deep Learning, radiomics, and data mining emerge quickly in recent years.
CONCLUSIONS: We identified a rapid growth in the cross-disciplinary research of HIV/AIDS and Big Data over the past two decades. Our findings demonstrated patterns and trends of prevailing research topics and Big Data applications in HIV/AIDS research and suggested a number of fast-evolving areas of Big Data Science in HIV/AIDS research including secondary analysis of EHR, machine learning, Deep Learning, predictive analysis, and NLP.","Emergence and evolution of big data science in HIV research: Bibliometric analysis of federally sponsored studies 2000-2019 BACKGROUND: The rapid growth of inherently complex and heterogeneous data in HIV/AIDS research underscores the importance of Big Data Science. Recently, there have been increasing uptakes of Big Data techniques in basic, clinical, and public health fields of HIV/AIDS research. However, no studies have systematically elaborated on the evolving applications of Big Data in HIV/AIDS research. We sought to explore the emergence and evolution of Big Data Science in HIV/AIDS-related publications that were funded by the US federal agencies.
METHODS: We identified HIV/AIDS and Big Data related publications that were funded by seven federal agencies from 2000 to 2019 by integrating data from National Institutes of Health (NIH) ExPORTER, MEDLINE, and MeSH. Building on bibliometrics and Natural Language Processing (NLP) methods, we constructed co-occurrence networks using bibliographic metadata (e.g., countries, institutes, MeSH terms, and keywords) of the retrieved publications. We then detected clusters among the networks as well as the temporal dynamics of clusters, followed by expert evaluation and clinical implications.
RESULTS: We harnessed nearly 600 thousand publications related to HIV/AIDS, of which 19,528 publications relating to Big Data were included in bibliometric analysis. Results showed that (1) the number of Big Data publications has been increasing since 2000, (2) US institutes have been in close collaborations with China, Canada, and Germany, (3) some institutes (e.g., University of California system, MD Anderson Cancer Center, and Harvard Medical School) are among the most productive institutes and started using Big Data in HIV/AIDS research early, (4) Big Data research was not active in public health disciplines until 2015, (5) research topics such as genomics, HIV comorbidities, population-based studies, Electronic Health Records (EHR), social media, precision medicine, and methodologies such as machine learning, Deep Learning, radiomics, and data mining emerge quickly in recent years.
CONCLUSIONS: We identified a rapid growth in the cross-disciplinary research of HIV/AIDS and Big Data over the past two decades. Our findings demonstrated patterns and trends of prevailing research topics and Big Data applications in HIV/AIDS research and suggested a number of fast-evolving areas of Big Data Science in HIV/AIDS research including secondary analysis of EHR, machine learning, Deep Learning, predictive analysis, and NLP.",0
35812486,A Survey on Machine Learning and Internet of Medical Things-Based Approaches for Handling COVID-19: Meta-Analysis,"Band SS, Ardabili S, Yarahmadi A, Pahlevanzadeh B, Kiani AK, Beheshti A, Alinejad-Rokny H, Dehzangi I, Chang A, Mosavi A, Moslehpour M.",Front Public Health. 2022 Jun 23;10:869238. doi: 10.3389/fpubh.2022.869238. eCollection 2022.,Band SS,Front Public Health,2022,11-07-2022,PMC9260273,,10.3389/fpubh.2022.869238,"Early diagnosis, prioritization, screening, clustering, and tracking of patients with COVID-19, and production of drugs and vaccines are some of the applications that have made it necessary to use a new style of technology to involve, manage, and deal with this epidemic. Strategies backed by artificial intelligence (A.I.) and the Internet of Things (IoT) have been undeniably effective to understand how the virus works and prevent it from spreading. Accordingly, the main aim of this survey is to critically review the ML, IoT, and the integration of IoT and ML-based techniques in the applications related to COVID-19, from the diagnosis of the disease to the prediction of its outbreak. According to the main findings, IoT provided a prompt and efficient approach to tracking the disease spread. On the other hand, most of the studies developed by ML-based techniques aimed at the detection and handling of challenges associated with the COVID-19 pandemic. Among different approaches, Convolutional Neural Network (CNN), Support Vector Machine, Genetic CNN, and pre-trained CNN, followed by ResNet have demonstrated the best performances compared to other methods.","A Survey on Machine Learning and Internet of Medical Things-Based Approaches for Handling COVID-19: Meta-Analysis Early diagnosis, prioritization, screening, clustering, and tracking of patients with COVID-19, and production of drugs and vaccines are some of the applications that have made it necessary to use a new style of technology to involve, manage, and deal with this epidemic. Strategies backed by artificial intelligence (A.I.) and the Internet of Things (IoT) have been undeniably effective to understand how the virus works and prevent it from spreading. Accordingly, the main aim of this survey is to critically review the ML, IoT, and the integration of IoT and ML-based techniques in the applications related to COVID-19, from the diagnosis of the disease to the prediction of its outbreak. According to the main findings, IoT provided a prompt and efficient approach to tracking the disease spread. On the other hand, most of the studies developed by ML-based techniques aimed at the detection and handling of challenges associated with the COVID-19 pandemic. Among different approaches, Convolutional Neural Network (CNN), Support Vector Machine, Genetic CNN, and pre-trained CNN, followed by ResNet have demonstrated the best performances compared to other methods.",0
31760945,Attention-based recurrent neural network for influenza epidemic prediction,"Zhu X, Fu B, Yang Y, Ma Y, Hao J, Chen S, Liu S, Li T, Liu S, Guo W, Liao Z.",BMC Bioinformatics. 2019 Nov 25;20(Suppl 18):575. doi: 10.1186/s12859-019-3131-8.,Zhu X,BMC Bioinformatics,2019,26-11-2019,PMC6876090,,10.1186/s12859-019-3131-8,"BACKGROUND: Influenza is an infectious respiratory disease that can cause serious public health hazard. Due to its huge threat to the society, precise real-time forecasting of influenza outbreaks is of great value to our public.
RESULTS: In this paper, we propose a new deep neural network structure that forecasts a real-time influenza-like illness rate (ILI%) in Guangzhou, China. Long short-term memory (LSTM) neural networks is applied to precisely forecast accurateness due to the long-term attribute and diversity of influenza epidemic data. We devise a multi-channel LSTM neural network that can draw multiple information from different types of inputs. We also add attention mechanism to improve forecasting accuracy. By using this structure, we are able to deal with relationships between multiple inputs more appropriately. Our model fully consider the information in the data set, targetedly solving practical problems of the Guangzhou influenza epidemic forecasting.
CONCLUSION: We assess the performance of our model by comparing it with different neural network structures and other state-of-the-art methods. The experimental results indicate that our model has strong competitiveness and can provide effective real-time influenza epidemic forecasting.","Attention-based recurrent neural network for influenza epidemic prediction BACKGROUND: Influenza is an infectious respiratory disease that can cause serious public health hazard. Due to its huge threat to the society, precise real-time forecasting of influenza outbreaks is of great value to our public.
RESULTS: In this paper, we propose a new deep neural network structure that forecasts a real-time influenza-like illness rate (ILI%) in Guangzhou, China. Long short-term memory (LSTM) neural networks is applied to precisely forecast accurateness due to the long-term attribute and diversity of influenza epidemic data. We devise a multi-channel LSTM neural network that can draw multiple information from different types of inputs. We also add attention mechanism to improve forecasting accuracy. By using this structure, we are able to deal with relationships between multiple inputs more appropriately. Our model fully consider the information in the data set, targetedly solving practical problems of the Guangzhou influenza epidemic forecasting.
CONCLUSION: We assess the performance of our model by comparing it with different neural network structures and other state-of-the-art methods. The experimental results indicate that our model has strong competitiveness and can provide effective real-time influenza epidemic forecasting.",0
33641077,Accurately Discriminating COVID-19 from Viral and Bacterial Pneumonia According to CT Images Via Deep Learning,"Zheng F, Li L, Zhang X, Song Y, Huang Z, Chong Y, Chen Z, Zhu H, Wu J, Chen W, Lu Y, Yang Y, Zha Y, Zhao H, Shen J.",Interdiscip Sci. 2021 Jun;13(2):273-285. doi: 10.1007/s12539-021-00420-z. Epub 2021 Feb 27.,Zheng F,Interdiscip Sci,2021,28-02-2021,PMC7914048,,10.1007/s12539-021-00420-z,"Computed tomography (CT) is one of the most efficient diagnostic methods for rapid diagnosis of the widespread COVID-19. However, reading CT films brings a lot of concentration and time for doctors. Therefore, it is necessary to develop an automatic CT image diagnosis system to assist doctors in diagnosis. Previous studies devoted to COVID-19 in the past months focused mostly on discriminating COVID-19 infected patients from healthy persons and/or bacterial pneumonia patients, and have ignored typical viral pneumonia since it is hard to collect samples for viral pneumonia that is less frequent in adults. In addition, it is much more challenging to discriminate COVID-19 from typical viral pneumonia as COVID-19 is also a kind of virus. In this study, we have collected CT images of 262, 100, 219, and 78 persons for COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls, respectively. To the best of our knowledge, this was the first study of quaternary classification to include also typical viral pneumonia. To effectively capture the subtle differences in CT images, we have constructed a new model by combining the ResNet50 backbone with SE blocks that was recently developed for fine image analysis. Our model was shown to outperform commonly used baseline models, achieving an overall accuracy of 0.94 with AUC of 0.96, recall of 0.94, precision of 0.95, and F1-score of 0.94. The model is available in https://github.com/Zhengfudan/COVID-19-Diagnosis-and-Pneumonia-Classification .","Accurately Discriminating COVID-19 from Viral and Bacterial Pneumonia According to CT Images Via Deep Learning Computed tomography (CT) is one of the most efficient diagnostic methods for rapid diagnosis of the widespread COVID-19. However, reading CT films brings a lot of concentration and time for doctors. Therefore, it is necessary to develop an automatic CT image diagnosis system to assist doctors in diagnosis. Previous studies devoted to COVID-19 in the past months focused mostly on discriminating COVID-19 infected patients from healthy persons and/or bacterial pneumonia patients, and have ignored typical viral pneumonia since it is hard to collect samples for viral pneumonia that is less frequent in adults. In addition, it is much more challenging to discriminate COVID-19 from typical viral pneumonia as COVID-19 is also a kind of virus. In this study, we have collected CT images of 262, 100, 219, and 78 persons for COVID-19, bacterial pneumonia, typical viral pneumonia, and healthy controls, respectively. To the best of our knowledge, this was the first study of quaternary classification to include also typical viral pneumonia. To effectively capture the subtle differences in CT images, we have constructed a new model by combining the ResNet50 backbone with SE blocks that was recently developed for fine image analysis. Our model was shown to outperform commonly used baseline models, achieving an overall accuracy of 0.94 with AUC of 0.96, recall of 0.94, precision of 0.95, and F1-score of 0.94. The model is available in https://github.com/Zhengfudan/COVID-19-Diagnosis-and-Pneumonia-Classification .",0
33014121,Review on Diagnosis of COVID-19 from Chest CT Images Using Artificial Intelligence,"Ozsahin I, Sekeroglu B, Musa MS, Mustapha MT, Uzun Ozsahin D.",Comput Math Methods Med. 2020 Sep 26;2020:9756518. doi: 10.1155/2020/9756518. eCollection 2020.,Ozsahin I,Comput Math Methods Med,2020,05-10-2020,PMC7519983,,10.1155/2020/9756518,"The COVID-19 diagnostic approach is mainly divided into two broad categories, a laboratory-based and chest radiography approach. The last few months have witnessed a rapid increase in the number of studies use artificial intelligence (AI) techniques to diagnose COVID-19 with chest computed tomography (CT). In this study, we review the diagnosis of COVID-19 by using chest CT toward AI. We searched ArXiv, MedRxiv, and Google Scholar using the terms ""deep learning"", ""neural networks"", ""COVID-19"", and ""chest CT"". At the time of writing (August 24, 2020), there have been nearly 100 studies and 30 studies among them were selected for this review. We categorized the studies based on the classification tasks: COVID-19/normal, COVID-19/non-COVID-19, COVID-19/non-COVID-19 pneumonia, and severity. The sensitivity, specificity, precision, accuracy, area under the curve, and F1 score results were reported as high as 100%, 100%, 99.62, 99.87%, 100%, and 99.5%, respectively. However, the presented results should be carefully compared due to the different degrees of difficulty of different classification tasks.","Review on Diagnosis of COVID-19 from Chest CT Images Using Artificial Intelligence The COVID-19 diagnostic approach is mainly divided into two broad categories, a laboratory-based and chest radiography approach. The last few months have witnessed a rapid increase in the number of studies use artificial intelligence (AI) techniques to diagnose COVID-19 with chest computed tomography (CT). In this study, we review the diagnosis of COVID-19 by using chest CT toward AI. We searched ArXiv, MedRxiv, and Google Scholar using the terms ""deep learning"", ""neural networks"", ""COVID-19"", and ""chest CT"". At the time of writing (August 24, 2020), there have been nearly 100 studies and 30 studies among them were selected for this review. We categorized the studies based on the classification tasks: COVID-19/normal, COVID-19/non-COVID-19, COVID-19/non-COVID-19 pneumonia, and severity. The sensitivity, specificity, precision, accuracy, area under the curve, and F1 score results were reported as high as 100%, 100%, 99.62, 99.87%, 100%, and 99.5%, respectively. However, the presented results should be carefully compared due to the different degrees of difficulty of different classification tasks.",0
38263439,Comparison between a deep-learning and a pixel-based approach for the automated quantification of HIV target cells in foreskin tissue,"Shao Z, Buchanan LB, Zuanazzi D, Khan YN, Khan AR, Prodger JL.",Sci Rep. 2024 Jan 23;14(1):1985. doi: 10.1038/s41598-024-52613-3.,Shao Z,Sci Rep,2024,24-01-2024,PMC10806185,,10.1038/s41598-024-52613-3,"The availability of target cells expressing the HIV receptors CD4 and CCR5 in genital tissue is a critical determinant of HIV susceptibility during sexual transmission. Quantification of immune cells in genital tissue is therefore an important outcome for studies on HIV susceptibility and prevention. Immunofluorescence microscopy allows for precise visualization of immune cells in mucosal tissues; however, this technique is limited in clinical studies by the lack of an accurate, unbiased, high-throughput image analysis method. Current pixel-based thresholding methods for cell counting struggle in tissue regions with high cell density and autofluorescence, both of which are common features in genital tissue. We describe a deep-learning approach using the publicly available StarDist method to count cells in immunofluorescence microscopy images of foreskin stained for nuclei, CD3, CD4, and CCR5. The accuracy of the model was comparable to manual counting (gold standard) and surpassed the capability of a previously described pixel-based cell counting method. We show that the performance of our deep-learning model is robust in tissue regions with high cell density and high autofluorescence. Moreover, we show that this deep-learning analysis method is both easy to implement and to adapt for the identification of other cell types in genital mucosal tissue.","Comparison between a deep-learning and a pixel-based approach for the automated quantification of HIV target cells in foreskin tissue The availability of target cells expressing the HIV receptors CD4 and CCR5 in genital tissue is a critical determinant of HIV susceptibility during sexual transmission. Quantification of immune cells in genital tissue is therefore an important outcome for studies on HIV susceptibility and prevention. Immunofluorescence microscopy allows for precise visualization of immune cells in mucosal tissues; however, this technique is limited in clinical studies by the lack of an accurate, unbiased, high-throughput image analysis method. Current pixel-based thresholding methods for cell counting struggle in tissue regions with high cell density and autofluorescence, both of which are common features in genital tissue. We describe a deep-learning approach using the publicly available StarDist method to count cells in immunofluorescence microscopy images of foreskin stained for nuclei, CD3, CD4, and CCR5. The accuracy of the model was comparable to manual counting (gold standard) and surpassed the capability of a previously described pixel-based cell counting method. We show that the performance of our deep-learning model is robust in tissue regions with high cell density and high autofluorescence. Moreover, we show that this deep-learning analysis method is both easy to implement and to adapt for the identification of other cell types in genital mucosal tissue.",0
34055034,Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19,"Helwan A, Ma'aitah MKS, Hamdan H, Ozsahin DU, Tuncyurek O.",Comput Math Methods Med. 2021 May 10;2021:5527271. doi: 10.1155/2021/5527271. eCollection 2021.,Helwan A,Comput Math Methods Med,2021,31-05-2021,PMC8112196,,10.1155/2021/5527271,"The reverse transcriptase polymerase chain reaction (RT-PCR) is still the routinely used test for the diagnosis of SARS-CoV-2 (COVID-19). However, according to several reports, RT-PCR showed a low sensitivity and multiple tests may be required to rule out false negative results. Recently, chest computed tomography (CT) has been an efficient tool to diagnose COVID-19 as it is directly affecting the lungs. In this paper, we investigate the application of pre-trained models in diagnosing patients who are positive for COVID-19 and differentiating it from normal patients, who tested negative for coronavirus. The study aims to compare the generalization capabilities of deep learning models with two thoracic radiologists in diagnosing COVID-19 chest CT images. A dataset of 3000 images was obtained from the Near East Hospital, Cyprus, and used to train and to test the three employed pre-trained models. In a test set of 250 images used to evaluate the deep neural networks and the radiologists, it was found that deep networks (ResNet-18, ResNet-50, and DenseNet-201) can outperform the radiologists in terms of higher accuracy (97.8%), sensitivity (98.1%), specificity (97.3%), precision (98.4%), and F1-score (198.25%), in classifying COVID-19 images.","Radiologists versus Deep Convolutional Neural Networks: A Comparative Study for Diagnosing COVID-19 The reverse transcriptase polymerase chain reaction (RT-PCR) is still the routinely used test for the diagnosis of SARS-CoV-2 (COVID-19). However, according to several reports, RT-PCR showed a low sensitivity and multiple tests may be required to rule out false negative results. Recently, chest computed tomography (CT) has been an efficient tool to diagnose COVID-19 as it is directly affecting the lungs. In this paper, we investigate the application of pre-trained models in diagnosing patients who are positive for COVID-19 and differentiating it from normal patients, who tested negative for coronavirus. The study aims to compare the generalization capabilities of deep learning models with two thoracic radiologists in diagnosing COVID-19 chest CT images. A dataset of 3000 images was obtained from the Near East Hospital, Cyprus, and used to train and to test the three employed pre-trained models. In a test set of 250 images used to evaluate the deep neural networks and the radiologists, it was found that deep networks (ResNet-18, ResNet-50, and DenseNet-201) can outperform the radiologists in terms of higher accuracy (97.8%), sensitivity (98.1%), specificity (97.3%), precision (98.4%), and F1-score (198.25%), in classifying COVID-19 images.",0
31142826,Development and evaluation of a deep learning approach for modeling seasonality and trends in hand-foot-mouth disease incidence in mainland China,"Wang Y, Xu C, Zhang S, Yang L, Wang Z, Zhu Y, Yuan J.",Sci Rep. 2019 May 29;9(1):8046. doi: 10.1038/s41598-019-44469-9.,Wang Y,Sci Rep,2019,31-05-2019,PMC6541597,,10.1038/s41598-019-44469-9,"The high incidence, seasonal pattern and frequent outbreaks of hand, foot, and mouth disease (HFMD) represent a threat for millions of children in mainland China. And advanced response is being used to address this. Here, we aimed to model time series with a long short-term memory (LSTM) based on the HFMD notified data from June 2008 to June 2018 and the ultimate performance was compared with the autoregressive integrated moving average (ARIMA) and nonlinear auto-regressive neural network (NAR). The results indicated that the identified best-fitting LSTM with the better superiority, be it in modeling dataset or two robustness tests dataset, than the best-conducting NAR and seasonal ARIMA (SARIMA) methods in forecasting performances, including the minimum indices of root mean square error, mean absolute error and mean absolute percentage error. The epidemic trends of HFMD remained stable during the study period, but the reported cases were even at significantly high levels with a notable high-risk seasonality in summer, and the incident cases projected by the LSTM would still be fairly high with a slightly upward trend in the future. In this regard, the LSTM approach should be highlighted in forecasting the epidemics of HFMD, and therefore assisting decision makers in making efficient decisions derived from the early detection of the disease incidents.","Development and evaluation of a deep learning approach for modeling seasonality and trends in hand-foot-mouth disease incidence in mainland China The high incidence, seasonal pattern and frequent outbreaks of hand, foot, and mouth disease (HFMD) represent a threat for millions of children in mainland China. And advanced response is being used to address this. Here, we aimed to model time series with a long short-term memory (LSTM) based on the HFMD notified data from June 2008 to June 2018 and the ultimate performance was compared with the autoregressive integrated moving average (ARIMA) and nonlinear auto-regressive neural network (NAR). The results indicated that the identified best-fitting LSTM with the better superiority, be it in modeling dataset or two robustness tests dataset, than the best-conducting NAR and seasonal ARIMA (SARIMA) methods in forecasting performances, including the minimum indices of root mean square error, mean absolute error and mean absolute percentage error. The epidemic trends of HFMD remained stable during the study period, but the reported cases were even at significantly high levels with a notable high-risk seasonality in summer, and the incident cases projected by the LSTM would still be fairly high with a slightly upward trend in the future. In this regard, the LSTM approach should be highlighted in forecasting the epidemics of HFMD, and therefore assisting decision makers in making efficient decisions derived from the early detection of the disease incidents.",0
30779585,Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets,"Zorn KM, Lane TR, Russo DP, Clark AM, Makarov V, Ekins S.",Mol Pharm. 2019 Apr 1;16(4):1620-1632. doi: 10.1021/acs.molpharmaceut.8b01297. Epub 2019 Feb 26.,Zorn KM,Mol Pharm,2019,20-02-2019,PMC7702308,NIHMS1619910,10.1021/acs.molpharmaceut.8b01297,"The human immunodeficiency virus (HIV) causes over a million deaths every year and has a huge economic impact in many countries. The first class of drugs approved were nucleoside reverse transcriptase inhibitors. A newer generation of reverse transcriptase inhibitors have become susceptible to drug resistant strains of HIV, and hence, alternatives are urgently needed. We have recently pioneered the use of Bayesian machine learning to generate models with public data to identify new compounds for testing against different disease targets. The current study has used the NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database for machine learning studies. We curated and cleaned data from HIV-1 wild-type cell-based and reverse transcriptase (RT) DNA polymerase inhibition assays. Compounds from this database with ≤1 μM HIV-1 RT DNA polymerase activity inhibition and cell-based HIV-1 inhibition are correlated (Pearson r = 0.44, n = 1137, p < 0.0001). Models were trained using multiple machine learning approaches (Bernoulli Naive Bayes, AdaBoost Decision Tree, Random Forest, support vector classification, k-Nearest Neighbors, and deep neural networks as well as consensus approaches) and then their predictive abilities were compared. Our comparison of different machine learning methods demonstrated that support vector classification, deep learning, and a consensus were generally comparable and not significantly different from each other using 5-fold cross validation and using 24 training and test set combinations. This study demonstrates findings in line with our previous studies for various targets that training and testing with multiple data sets does not demonstrate a significant difference between support vector machine and deep neural networks.","Multiple Machine Learning Comparisons of HIV Cell-based and Reverse Transcriptase Data Sets The human immunodeficiency virus (HIV) causes over a million deaths every year and has a huge economic impact in many countries. The first class of drugs approved were nucleoside reverse transcriptase inhibitors. A newer generation of reverse transcriptase inhibitors have become susceptible to drug resistant strains of HIV, and hence, alternatives are urgently needed. We have recently pioneered the use of Bayesian machine learning to generate models with public data to identify new compounds for testing against different disease targets. The current study has used the NIAID ChemDB HIV, Opportunistic Infection and Tuberculosis Therapeutics Database for machine learning studies. We curated and cleaned data from HIV-1 wild-type cell-based and reverse transcriptase (RT) DNA polymerase inhibition assays. Compounds from this database with ≤1 μM HIV-1 RT DNA polymerase activity inhibition and cell-based HIV-1 inhibition are correlated (Pearson r = 0.44, n = 1137, p < 0.0001). Models were trained using multiple machine learning approaches (Bernoulli Naive Bayes, AdaBoost Decision Tree, Random Forest, support vector classification, k-Nearest Neighbors, and deep neural networks as well as consensus approaches) and then their predictive abilities were compared. Our comparison of different machine learning methods demonstrated that support vector classification, deep learning, and a consensus were generally comparable and not significantly different from each other using 5-fold cross validation and using 24 training and test set combinations. This study demonstrates findings in line with our previous studies for various targets that training and testing with multiple data sets does not demonstrate a significant difference between support vector machine and deep neural networks.",0
32617690,A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images,"Ni Q, Sun ZY, Qi L, Chen W, Yang Y, Wang L, Zhang X, Yang L, Fang Y, Xing Z, Zhou Z, Yu Y, Lu GM, Zhang LJ.",Eur Radiol. 2020 Dec;30(12):6517-6527. doi: 10.1007/s00330-020-07044-9. Epub 2020 Jul 2.,Ni Q,Eur Radiol,2020,04-07-2020,PMC7331494,,10.1007/s00330-020-07044-9,"OBJECTIVES: To utilize a deep learning model for automatic detection of abnormalities in chest CT images from COVID-19 patients and compare its quantitative determination performance with radiological residents.
METHODS: A deep learning algorithm consisted of lesion detection, segmentation, and location was trained and validated in 14,435 participants with chest CT images and definite pathogen diagnosis. The algorithm was tested in a non-overlapping dataset of 96 confirmed COVID-19 patients in three hospitals across China during the outbreak. Quantitative detection performance of the model was compared with three radiological residents with two experienced radiologists' reading reports as reference standard by assessing the accuracy, sensitivity, specificity, and F1 score.
RESULTS: Of 96 patients, 88 had pneumonia lesions on CT images and 8 had no abnormities on CT images. For per-patient basis, the algorithm showed superior sensitivity of 1.00 (95% confidence interval (CI) 0.95, 1.00) and F1 score of 0.97 in detecting lesions from CT images of COVID-19 pneumonia patients. While for per-lung lobe basis, the algorithm achieved a sensitivity of 0.96 (95% CI 0.94, 0.98) and a slightly inferior F1 score of 0.86. The median volume of lesions calculated by algorithm was 40.10 cm3. An average running speed of 20.3 s ± 5.8 per case demonstrated the algorithm was much faster than the residents in assessing CT images (all p &lt; 0.017). The deep learning algorithm can also assist radiologists make quicker diagnosis (all p &lt; 0.0001) with superior diagnostic performance.
CONCLUSIONS: The algorithm showed excellent performance in detecting COVID-19 pneumonia on chest CT images compared with resident radiologists.
KEY POINTS: • The higher sensitivity of deep learning model in detecting COVID-19 pneumonia were found compared with radiological residents on a per-lobe and per-patient basis. • The deep learning model improves diagnosis efficiency by shortening processing time. • The deep learning model can automatically calculate the volume of the lesions and whole lung.","A deep learning approach to characterize 2019 coronavirus disease (COVID-19) pneumonia in chest CT images OBJECTIVES: To utilize a deep learning model for automatic detection of abnormalities in chest CT images from COVID-19 patients and compare its quantitative determination performance with radiological residents.
METHODS: A deep learning algorithm consisted of lesion detection, segmentation, and location was trained and validated in 14,435 participants with chest CT images and definite pathogen diagnosis. The algorithm was tested in a non-overlapping dataset of 96 confirmed COVID-19 patients in three hospitals across China during the outbreak. Quantitative detection performance of the model was compared with three radiological residents with two experienced radiologists' reading reports as reference standard by assessing the accuracy, sensitivity, specificity, and F1 score.
RESULTS: Of 96 patients, 88 had pneumonia lesions on CT images and 8 had no abnormities on CT images. For per-patient basis, the algorithm showed superior sensitivity of 1.00 (95% confidence interval (CI) 0.95, 1.00) and F1 score of 0.97 in detecting lesions from CT images of COVID-19 pneumonia patients. While for per-lung lobe basis, the algorithm achieved a sensitivity of 0.96 (95% CI 0.94, 0.98) and a slightly inferior F1 score of 0.86. The median volume of lesions calculated by algorithm was 40.10 cm3. An average running speed of 20.3 s ± 5.8 per case demonstrated the algorithm was much faster than the residents in assessing CT images (all p &lt; 0.017). The deep learning algorithm can also assist radiologists make quicker diagnosis (all p &lt; 0.0001) with superior diagnostic performance.
CONCLUSIONS: The algorithm showed excellent performance in detecting COVID-19 pneumonia on chest CT images compared with resident radiologists.
KEY POINTS: • The higher sensitivity of deep learning model in detecting COVID-19 pneumonia were found compared with radiological residents on a per-lobe and per-patient basis. • The deep learning model improves diagnosis efficiency by shortening processing time. • The deep learning model can automatically calculate the volume of the lesions and whole lung.",0
39152187,A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection,"Abade A, Porto LF, Scholze AR, Kuntath D, Barros NDS, Berra TZ, Ramos ACV, Arcêncio RA, Alves JD.",Sci Rep. 2024 Aug 16;14(1):18991. doi: 10.1038/s41598-024-69580-4.,Abade A,Sci Rep,2024,16-08-2024,PMC11329657,,10.1038/s41598-024-69580-4,"TB/HIV coinfection poses a complex public health challenge. Accurate forecasting of future trends is essential for efficient resource allocation and intervention strategy development. This study compares classical statistical and machine learning models to predict TB/HIV coinfection cases stratified by gender and the general populations. We analyzed time series data using exponential smoothing and ARIMA to establish the baseline trend and seasonality. Subsequently, machine learning models (SVR, XGBoost, LSTM, CNN, GRU, CNN-GRU, and CNN-LSTM) were employed to capture the complex dynamics and inherent non-linearities of TB/HIV coinfection data. Performance metrics (MSE, MAE, sMAPE) and the Diebold-Mariano test were used to evaluate the model performance. Results revealed that Deep Learning models, particularly Bidirectional LSTM and CNN-LSTM, significantly outperformed classical methods. This demonstrates the effectiveness of Deep Learning for modeling TB/HIV coinfection time series and generating more accurate forecasts.","A comparative analysis of classical and machine learning methods for forecasting TB/HIV co-infection TB/HIV coinfection poses a complex public health challenge. Accurate forecasting of future trends is essential for efficient resource allocation and intervention strategy development. This study compares classical statistical and machine learning models to predict TB/HIV coinfection cases stratified by gender and the general populations. We analyzed time series data using exponential smoothing and ARIMA to establish the baseline trend and seasonality. Subsequently, machine learning models (SVR, XGBoost, LSTM, CNN, GRU, CNN-GRU, and CNN-LSTM) were employed to capture the complex dynamics and inherent non-linearities of TB/HIV coinfection data. Performance metrics (MSE, MAE, sMAPE) and the Diebold-Mariano test were used to evaluate the model performance. Results revealed that Deep Learning models, particularly Bidirectional LSTM and CNN-LSTM, significantly outperformed classical methods. This demonstrates the effectiveness of Deep Learning for modeling TB/HIV coinfection time series and generating more accurate forecasts.",0
35144240,Artificial Intelligence-Enabled Social Media Analysis for Pharmacovigilance of COVID-19 Vaccinations in the United Kingdom: Observational Study,"Hussain Z, Sheikh Z, Tahir A, Dashtipour K, Gogate M, Sheikh A, Hussain A.",JMIR Public Health Surveill. 2022 May 27;8(5):e32543. doi: 10.2196/32543.,Hussain Z,JMIR Public Health Surveill,2022,10-02-2022,PMC9150729,,10.2196/32543,"BACKGROUND: The rollout of vaccines for COVID-19 in the United Kingdom started in December 2020. Uptake has been high, and there has been a subsequent reduction in infections, hospitalizations, and deaths among vaccinated individuals. However, vaccine hesitancy remains a concern, in particular relating to adverse effects following immunization (AEFIs). Social media analysis has the potential to inform policy makers about AEFIs being discussed by the public as well as public attitudes toward the national immunization campaign.
OBJECTIVE: We sought to assess the frequency and nature of AEFI-related mentions on social media in the United Kingdom and to provide insights on public sentiments toward COVID-19 vaccines.
METHODS: We extracted and analyzed over 121,406 relevant Twitter and Facebook posts, from December 8, 2020, to April 30, 2021. These were thematically filtered using a 2-step approach, initially using COVID-19-related keywords and then using vaccine- and manufacturer-related keywords. We identified AEFI-related keywords and modeled their word frequency to monitor their trends over 2-week periods. We also adapted and utilized our recently developed hybrid ensemble model, which combines state-of-the-art lexicon rule-based and deep learning-based approaches, to analyze sentiment trends relating to the main vaccines available in the United Kingdom.
RESULTS: Our COVID-19 AEFI search strategy identified 46,762 unique Facebook posts by 14,346 users and 74,644 tweets (excluding retweets) by 36,446 users over the 4-month period. We identified an increasing trend in the number of mentions for each AEFI on social media over the study period. The most frequent AEFI mentions were found to be symptoms related to appetite (n=79,132, 14%), allergy (n=53,924, 9%), injection site (n=56,152, 10%), and clots (n=43,907, 8%). We also found some rarely reported AEFIs such as Bell palsy (n=11,909, 2%) and Guillain-Barre syndrome (n=9576, 2%) being discussed as frequently as more well-known side effects like headache (n=10,641, 2%), fever (n=12,707, 2%), and diarrhea (n=16,559, 3%). Overall, we found public sentiment toward vaccines and their manufacturers to be largely positive (58%), with a near equal split between negative (22%) and neutral (19%) sentiments. The sentiment trend was relatively steady over time and had minor variations, likely based on political and regulatory announcements and debates.
CONCLUSIONS: The most frequently discussed COVID-19 AEFIs on social media were found to be broadly consistent with those reported in the literature and by government pharmacovigilance. We also detected potential safety signals from our analysis that have been detected elsewhere and are currently being investigated. As such, we believe our findings support the use of social media analysis to provide a complementary data source to conventional knowledge sources being used for pharmacovigilance purposes.","Artificial Intelligence-Enabled Social Media Analysis for Pharmacovigilance of COVID-19 Vaccinations in the United Kingdom: Observational Study BACKGROUND: The rollout of vaccines for COVID-19 in the United Kingdom started in December 2020. Uptake has been high, and there has been a subsequent reduction in infections, hospitalizations, and deaths among vaccinated individuals. However, vaccine hesitancy remains a concern, in particular relating to adverse effects following immunization (AEFIs). Social media analysis has the potential to inform policy makers about AEFIs being discussed by the public as well as public attitudes toward the national immunization campaign.
OBJECTIVE: We sought to assess the frequency and nature of AEFI-related mentions on social media in the United Kingdom and to provide insights on public sentiments toward COVID-19 vaccines.
METHODS: We extracted and analyzed over 121,406 relevant Twitter and Facebook posts, from December 8, 2020, to April 30, 2021. These were thematically filtered using a 2-step approach, initially using COVID-19-related keywords and then using vaccine- and manufacturer-related keywords. We identified AEFI-related keywords and modeled their word frequency to monitor their trends over 2-week periods. We also adapted and utilized our recently developed hybrid ensemble model, which combines state-of-the-art lexicon rule-based and deep learning-based approaches, to analyze sentiment trends relating to the main vaccines available in the United Kingdom.
RESULTS: Our COVID-19 AEFI search strategy identified 46,762 unique Facebook posts by 14,346 users and 74,644 tweets (excluding retweets) by 36,446 users over the 4-month period. We identified an increasing trend in the number of mentions for each AEFI on social media over the study period. The most frequent AEFI mentions were found to be symptoms related to appetite (n=79,132, 14%), allergy (n=53,924, 9%), injection site (n=56,152, 10%), and clots (n=43,907, 8%). We also found some rarely reported AEFIs such as Bell palsy (n=11,909, 2%) and Guillain-Barre syndrome (n=9576, 2%) being discussed as frequently as more well-known side effects like headache (n=10,641, 2%), fever (n=12,707, 2%), and diarrhea (n=16,559, 3%). Overall, we found public sentiment toward vaccines and their manufacturers to be largely positive (58%), with a near equal split between negative (22%) and neutral (19%) sentiments. The sentiment trend was relatively steady over time and had minor variations, likely based on political and regulatory announcements and debates.
CONCLUSIONS: The most frequently discussed COVID-19 AEFIs on social media were found to be broadly consistent with those reported in the literature and by government pharmacovigilance. We also detected potential safety signals from our analysis that have been detected elsewhere and are currently being investigated. As such, we believe our findings support the use of social media analysis to provide a complementary data source to conventional knowledge sources being used for pharmacovigilance purposes.",0
34679127,Stratifying the early radiologic trajectory in dyspneic patients with COVID-19 pneumonia,"Kim JY, Jung KJ, Yoo SJ, Yoon SH.",PLoS One. 2021 Oct 22;16(10):e0259010. doi: 10.1371/journal.pone.0259010. eCollection 2021.,Kim JY,PLoS One,2021,22-10-2021,PMC8535425,,10.1371/journal.pone.0259010,"OBJECTIVE: This study aimed to stratify the early pneumonia trajectory on chest radiographs and compare patient characteristics in dyspneic patients with coronavirus disease 2019 (COVID-19).
MATERIALS AND METHODS: We retrospectively included 139 COVID-19 patients with dyspnea (87 men, 62.7±16.3 years) and serial chest radiographs from January to September 2020. Radiographic pneumonia extent was quantified as a percentage using a previously-developed deep learning algorithm. A group-based trajectory model was used to categorize the pneumonia trajectory after symptom onset during hospitalization. Clinical findings, and outcomes were compared, and Cox regression was performed for survival analysis.
RESULTS: Radiographic pneumonia trajectories were categorized into four groups. Group 1 (n = 83, 59.7%) had negligible pneumonia, and group 2 (n = 29, 20.9%) had mild pneumonia. Group 3 (n = 13, 9.4%) and group 4 (n = 14, 10.1%) showed similar considerable pneumonia extents at baseline, but group 3 had decreasing pneumonia extent at 1-2 weeks, while group 4 had increasing pneumonia extent. Intensive care unit admission and mortality were significantly more frequent in groups 3 and 4 than in groups 1 and 2 (P < .05). Groups 3 and 4 shared similar clinical and laboratory findings, but thrombocytopenia (<150×103/μL) was exclusively observed in group 4 (P = .016). When compared to groups 1 and 2, group 4 (hazard ratio, 63.3; 95% confidence interval, 7.9-504.9) had a two-fold higher risk for mortality than group 3 (hazard ratio, 31.2; 95% confidence interval, 3.5-280.2), and this elevated risk was maintained after adjusting confounders.
CONCLUSION: Monitoring the early radiologic trajectory beyond baseline further prognosticated at-risk COVID-19 patients, who potentially had thrombo-inflammatory responses.","Stratifying the early radiologic trajectory in dyspneic patients with COVID-19 pneumonia OBJECTIVE: This study aimed to stratify the early pneumonia trajectory on chest radiographs and compare patient characteristics in dyspneic patients with coronavirus disease 2019 (COVID-19).
MATERIALS AND METHODS: We retrospectively included 139 COVID-19 patients with dyspnea (87 men, 62.7±16.3 years) and serial chest radiographs from January to September 2020. Radiographic pneumonia extent was quantified as a percentage using a previously-developed deep learning algorithm. A group-based trajectory model was used to categorize the pneumonia trajectory after symptom onset during hospitalization. Clinical findings, and outcomes were compared, and Cox regression was performed for survival analysis.
RESULTS: Radiographic pneumonia trajectories were categorized into four groups. Group 1 (n = 83, 59.7%) had negligible pneumonia, and group 2 (n = 29, 20.9%) had mild pneumonia. Group 3 (n = 13, 9.4%) and group 4 (n = 14, 10.1%) showed similar considerable pneumonia extents at baseline, but group 3 had decreasing pneumonia extent at 1-2 weeks, while group 4 had increasing pneumonia extent. Intensive care unit admission and mortality were significantly more frequent in groups 3 and 4 than in groups 1 and 2 (P < .05). Groups 3 and 4 shared similar clinical and laboratory findings, but thrombocytopenia (<150×103/μL) was exclusively observed in group 4 (P = .016). When compared to groups 1 and 2, group 4 (hazard ratio, 63.3; 95% confidence interval, 7.9-504.9) had a two-fold higher risk for mortality than group 3 (hazard ratio, 31.2; 95% confidence interval, 3.5-280.2), and this elevated risk was maintained after adjusting confounders.
CONCLUSION: Monitoring the early radiologic trajectory beyond baseline further prognosticated at-risk COVID-19 patients, who potentially had thrombo-inflammatory responses.",0
34097708,COVID-19 pneumonia on chest X-rays: Performance of a deep learning-based computer-aided detection system,"Hwang EJ, Kim KB, Kim JY, Lim JK, Nam JG, Choi H, Kim H, Yoon SH, Goo JM, Park CM.",PLoS One. 2021 Jun 7;16(6):e0252440. doi: 10.1371/journal.pone.0252440. eCollection 2021.,Hwang EJ,PLoS One,2021,07-06-2021,PMC8184006,,10.1371/journal.pone.0252440,"Chest X-rays (CXRs) can help triage for Coronavirus disease (COVID-19) patients in resource-constrained environments, and a computer-aided detection system (CAD) that can identify pneumonia on CXR may help the triage of patients in those environment where expert radiologists are not available. However, the performance of existing CAD for identifying COVID-19 and associated pneumonia on CXRs has been scarcely investigated. In this study, CXRs of patients with and without COVID-19 confirmed by reverse transcriptase polymerase chain reaction (RT-PCR) were retrospectively collected from four and one institution, respectively, and a commercialized, regulatory-approved CAD that can identify various abnormalities including pneumonia was used to analyze each CXR. Performance of the CAD was evaluated using area under the receiver operating characteristic curves (AUCs), with reference standards of the RT-PCR results and the presence of findings of pneumonia on chest CTs obtained within 24 hours from the CXR. For comparison, 5 thoracic radiologists and 5 non-radiologist physicians independently interpreted the CXRs. Afterward, they re-interpreted the CXRs with corresponding CAD results. The performance of CAD (AUCs, 0.714 and 0.790 against RT-PCR and chest CT, respectively hereinafter) were similar with those of thoracic radiologists (AUCs, 0.701 and 0.784), and higher than those of non-radiologist physicians (AUCs, 0.584 and 0.650). Non-radiologist physicians showed significantly improved performance when assisted with the CAD (AUCs, 0.584 to 0.664 and 0.650 to 0.738). In addition, inter-reader agreement among physicians was also improved in the CAD-assisted interpretation (Fleiss' kappa coefficient, 0.209 to 0.322). In conclusion, radiologist-level performance of the CAD in identifying COVID-19 and associated pneumonia on CXR and enhanced performance of non-radiologist physicians with the CAD assistance suggest that the CAD can support physicians in interpreting CXRs and helping image-based triage of COVID-19 patients in resource-constrained environment.","COVID-19 pneumonia on chest X-rays: Performance of a deep learning-based computer-aided detection system Chest X-rays (CXRs) can help triage for Coronavirus disease (COVID-19) patients in resource-constrained environments, and a computer-aided detection system (CAD) that can identify pneumonia on CXR may help the triage of patients in those environment where expert radiologists are not available. However, the performance of existing CAD for identifying COVID-19 and associated pneumonia on CXRs has been scarcely investigated. In this study, CXRs of patients with and without COVID-19 confirmed by reverse transcriptase polymerase chain reaction (RT-PCR) were retrospectively collected from four and one institution, respectively, and a commercialized, regulatory-approved CAD that can identify various abnormalities including pneumonia was used to analyze each CXR. Performance of the CAD was evaluated using area under the receiver operating characteristic curves (AUCs), with reference standards of the RT-PCR results and the presence of findings of pneumonia on chest CTs obtained within 24 hours from the CXR. For comparison, 5 thoracic radiologists and 5 non-radiologist physicians independently interpreted the CXRs. Afterward, they re-interpreted the CXRs with corresponding CAD results. The performance of CAD (AUCs, 0.714 and 0.790 against RT-PCR and chest CT, respectively hereinafter) were similar with those of thoracic radiologists (AUCs, 0.701 and 0.784), and higher than those of non-radiologist physicians (AUCs, 0.584 and 0.650). Non-radiologist physicians showed significantly improved performance when assisted with the CAD (AUCs, 0.584 to 0.664 and 0.650 to 0.738). In addition, inter-reader agreement among physicians was also improved in the CAD-assisted interpretation (Fleiss' kappa coefficient, 0.209 to 0.322). In conclusion, radiologist-level performance of the CAD in identifying COVID-19 and associated pneumonia on CXR and enhanced performance of non-radiologist physicians with the CAD assistance suggest that the CAD can support physicians in interpreting CXRs and helping image-based triage of COVID-19 patients in resource-constrained environment.",0
32735549,Prognostic Modeling of COVID-19 Using Artificial Intelligence in the United Kingdom: Model Development and Validation,"Abdulaal A, Patel A, Charani E, Denny S, Mughal N, Moore L.",J Med Internet Res. 2020 Aug 25;22(8):e20259. doi: 10.2196/20259.,Abdulaal A,J Med Internet Res,2020,01-08-2020,PMC7451108,,10.2196/20259,"BACKGROUND: The current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) outbreak is a public health emergency and the case fatality rate in the United Kingdom is significant. Although there appear to be several early predictors of outcome, there are no currently validated prognostic models or scoring systems applicable specifically to patients with confirmed SARS-CoV-2.
OBJECTIVE: We aim to create a point-of-admission mortality risk scoring system using an artificial neural network (ANN).
METHODS: We present an ANN that can provide a patient-specific, point-of-admission mortality risk prediction to inform clinical management decisions at the earliest opportunity. The ANN analyzes a set of patient features including demographics, comorbidities, smoking history, and presenting symptoms and predicts patient-specific mortality risk during the current hospital admission. The model was trained and validated on data extracted from 398 patients admitted to hospital with a positive real-time reverse transcription polymerase chain reaction (RT-PCR) test for SARS-CoV-2.
RESULTS: Patient-specific mortality was predicted with 86.25% accuracy, with a sensitivity of 87.50% (95% CI 61.65%-98.45%) and specificity of 85.94% (95% CI 74.98%-93.36%). The positive predictive value was 60.87% (95% CI 45.23%-74.56%), and the negative predictive value was 96.49% (95% CI 88.23%-99.02%). The area under the receiver operating characteristic curve was 90.12%.
CONCLUSIONS: This analysis demonstrates an adaptive ANN trained on data at a single site, which demonstrates the early utility of deep learning approaches in a rapidly evolving pandemic with no established or validated prognostic scoring systems.","Prognostic Modeling of COVID-19 Using Artificial Intelligence in the United Kingdom: Model Development and Validation BACKGROUND: The current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) outbreak is a public health emergency and the case fatality rate in the United Kingdom is significant. Although there appear to be several early predictors of outcome, there are no currently validated prognostic models or scoring systems applicable specifically to patients with confirmed SARS-CoV-2.
OBJECTIVE: We aim to create a point-of-admission mortality risk scoring system using an artificial neural network (ANN).
METHODS: We present an ANN that can provide a patient-specific, point-of-admission mortality risk prediction to inform clinical management decisions at the earliest opportunity. The ANN analyzes a set of patient features including demographics, comorbidities, smoking history, and presenting symptoms and predicts patient-specific mortality risk during the current hospital admission. The model was trained and validated on data extracted from 398 patients admitted to hospital with a positive real-time reverse transcription polymerase chain reaction (RT-PCR) test for SARS-CoV-2.
RESULTS: Patient-specific mortality was predicted with 86.25% accuracy, with a sensitivity of 87.50% (95% CI 61.65%-98.45%) and specificity of 85.94% (95% CI 74.98%-93.36%). The positive predictive value was 60.87% (95% CI 45.23%-74.56%), and the negative predictive value was 96.49% (95% CI 88.23%-99.02%). The area under the receiver operating characteristic curve was 90.12%.
CONCLUSIONS: This analysis demonstrates an adaptive ANN trained on data at a single site, which demonstrates the early utility of deep learning approaches in a rapidly evolving pandemic with no established or validated prognostic scoring systems.",0
36150046,Emotions and Topics Expressed on Twitter During the COVID-19 Pandemic in the United Kingdom: Comparative Geolocation and Text Mining Analysis,"Alhuzali H, Zhang T, Ananiadou S.",J Med Internet Res. 2022 Oct 5;24(10):e40323. doi: 10.2196/40323.,Alhuzali H,J Med Internet Res,2022,23-09-2022,PMC9536769,,10.2196/40323,"BACKGROUND: In recent years, the COVID-19 pandemic has brought great changes to public health, society, and the economy. Social media provide a platform for people to discuss health concerns, living conditions, and policies during the epidemic, allowing policymakers to use this content to analyze the public emotions and attitudes for decision-making.
OBJECTIVE: The aim of this study was to use deep learning-based methods to understand public emotions on topics related to the COVID-19 pandemic in the United Kingdom through a comparative geolocation and text mining analysis on Twitter.
METHODS: Over 500,000 tweets related to COVID-19 from 48 different cities in the United Kingdom were extracted, with the data covering the period of the last 2 years (from February 2020 to November 2021). We leveraged three advanced deep learning-based models for topic modeling to geospatially analyze the sentiment, emotion, and topics of tweets in the United Kingdom: SenticNet 6 for sentiment analysis, SpanEmo for emotion recognition, and combined topic modeling (CTM).
RESULTS: We observed a significant change in the number of tweets as the epidemiological situation and vaccination situation shifted over the 2 years. There was a sharp increase in the number of tweets from January 2020 to February 2020 due to the outbreak of COVID-19 in the United Kingdom. Then, the number of tweets gradually declined as of February 2020. Moreover, with identification of the COVID-19 Omicron variant in the United Kingdom in November 2021, the number of tweets grew again. Our findings reveal people's attitudes and emotions toward topics related to COVID-19. For sentiment, approximately 60% of tweets were positive, 20% were neutral, and 20% were negative. For emotion, people tended to express highly positive emotions in the beginning of 2020, while expressing highly negative emotions over time toward the end of 2021. The topics also changed during the pandemic.
CONCLUSIONS: Through large-scale text mining of Twitter, our study found meaningful differences in public emotions and topics regarding the COVID-19 pandemic among different UK cities. Furthermore, efficient location-based and time-based comparative analysis can be used to track people's thoughts and feelings, and to understand their behaviors. Based on our analysis, positive attitudes were common during the pandemic; optimism and anticipation were the dominant emotions. With the outbreak and epidemiological change, the government developed control measures and vaccination policies, and the topics also shifted over time. Overall, the proportion and expressions of emojis, sentiments, emotions, and topics varied geographically and temporally. Therefore, our approach of exploring public emotions and topics on the pandemic from Twitter can potentially lead to informing how public policies are received in a particular geographical area.","Emotions and Topics Expressed on Twitter During the COVID-19 Pandemic in the United Kingdom: Comparative Geolocation and Text Mining Analysis BACKGROUND: In recent years, the COVID-19 pandemic has brought great changes to public health, society, and the economy. Social media provide a platform for people to discuss health concerns, living conditions, and policies during the epidemic, allowing policymakers to use this content to analyze the public emotions and attitudes for decision-making.
OBJECTIVE: The aim of this study was to use deep learning-based methods to understand public emotions on topics related to the COVID-19 pandemic in the United Kingdom through a comparative geolocation and text mining analysis on Twitter.
METHODS: Over 500,000 tweets related to COVID-19 from 48 different cities in the United Kingdom were extracted, with the data covering the period of the last 2 years (from February 2020 to November 2021). We leveraged three advanced deep learning-based models for topic modeling to geospatially analyze the sentiment, emotion, and topics of tweets in the United Kingdom: SenticNet 6 for sentiment analysis, SpanEmo for emotion recognition, and combined topic modeling (CTM).
RESULTS: We observed a significant change in the number of tweets as the epidemiological situation and vaccination situation shifted over the 2 years. There was a sharp increase in the number of tweets from January 2020 to February 2020 due to the outbreak of COVID-19 in the United Kingdom. Then, the number of tweets gradually declined as of February 2020. Moreover, with identification of the COVID-19 Omicron variant in the United Kingdom in November 2021, the number of tweets grew again. Our findings reveal people's attitudes and emotions toward topics related to COVID-19. For sentiment, approximately 60% of tweets were positive, 20% were neutral, and 20% were negative. For emotion, people tended to express highly positive emotions in the beginning of 2020, while expressing highly negative emotions over time toward the end of 2021. The topics also changed during the pandemic.
CONCLUSIONS: Through large-scale text mining of Twitter, our study found meaningful differences in public emotions and topics regarding the COVID-19 pandemic among different UK cities. Furthermore, efficient location-based and time-based comparative analysis can be used to track people's thoughts and feelings, and to understand their behaviors. Based on our analysis, positive attitudes were common during the pandemic; optimism and anticipation were the dominant emotions. With the outbreak and epidemiological change, the government developed control measures and vaccination policies, and the topics also shifted over time. Overall, the proportion and expressions of emojis, sentiments, emotions, and topics varied geographically and temporally. Therefore, our approach of exploring public emotions and topics on the pandemic from Twitter can potentially lead to informing how public policies are received in a particular geographical area.",0
38308256,Susceptibility of AutoML mortality prediction algorithms to model drift caused by the COVID pandemic,"Kagerbauer SM, Ulm B, Podtschaske AH, Andonov DI, Blobner M, Jungwirth B, Graessner M.",BMC Med Inform Decis Mak. 2024 Feb 2;24(1):34. doi: 10.1186/s12911-024-02428-z.,Kagerbauer SM,BMC Med Inform Decis Mak,2024,02-02-2024,PMC10837894,,10.1186/s12911-024-02428-z,"BACKGROUND: Concept drift and covariate shift lead to a degradation of machine learning (ML) models. The objective of our study was to characterize sudden data drift as caused by the COVID pandemic. Furthermore, we investigated the suitability of certain methods in model training to prevent model degradation caused by data drift.
METHODS: We trained different ML models with the H2O AutoML method on a dataset comprising 102,666 cases of surgical patients collected in the years 2014-2019 to predict postoperative mortality using preoperatively available data. Models applied were Generalized Linear Model with regularization, Default Random Forest, Gradient Boosting Machine, eXtreme Gradient Boosting, Deep Learning and Stacked Ensembles comprising all base models. Further, we modified the original models by applying three different methods when training on the original pre-pandemic dataset: (Rahmani K, et al, Int J Med Inform 173:104930, 2023) we weighted older data weaker, (Morger A, et al, Sci Rep 12:7244, 2022) used only the most recent data for model training and (Dilmegani C, 2023) performed a z-transformation of the numerical input parameters. Afterwards, we tested model performance on a pre-pandemic and an in-pandemic data set not used in the training process, and analysed common features.
RESULTS: The models produced showed excellent areas under receiver-operating characteristic and acceptable precision-recall curves when tested on a dataset from January-March 2020, but significant degradation when tested on a dataset collected in the first wave of the COVID pandemic from April-May 2020. When comparing the probability distributions of the input parameters, significant differences between pre-pandemic and in-pandemic data were found. The endpoint of our models, in-hospital mortality after surgery, did not differ significantly between pre- and in-pandemic data and was about 1% in each case. However, the models varied considerably in the composition of their input parameters. None of our applied modifications prevented a loss of performance, although very different models emerged from it, using a large variety of parameters.
CONCLUSIONS: Our results show that none of our tested easy-to-implement measures in model training can prevent deterioration in the case of sudden external events. Therefore, we conclude that, in the presence of concept drift and covariate shift, close monitoring and critical review of model predictions are necessary.","Susceptibility of AutoML mortality prediction algorithms to model drift caused by the COVID pandemic BACKGROUND: Concept drift and covariate shift lead to a degradation of machine learning (ML) models. The objective of our study was to characterize sudden data drift as caused by the COVID pandemic. Furthermore, we investigated the suitability of certain methods in model training to prevent model degradation caused by data drift.
METHODS: We trained different ML models with the H2O AutoML method on a dataset comprising 102,666 cases of surgical patients collected in the years 2014-2019 to predict postoperative mortality using preoperatively available data. Models applied were Generalized Linear Model with regularization, Default Random Forest, Gradient Boosting Machine, eXtreme Gradient Boosting, Deep Learning and Stacked Ensembles comprising all base models. Further, we modified the original models by applying three different methods when training on the original pre-pandemic dataset: (Rahmani K, et al, Int J Med Inform 173:104930, 2023) we weighted older data weaker, (Morger A, et al, Sci Rep 12:7244, 2022) used only the most recent data for model training and (Dilmegani C, 2023) performed a z-transformation of the numerical input parameters. Afterwards, we tested model performance on a pre-pandemic and an in-pandemic data set not used in the training process, and analysed common features.
RESULTS: The models produced showed excellent areas under receiver-operating characteristic and acceptable precision-recall curves when tested on a dataset from January-March 2020, but significant degradation when tested on a dataset collected in the first wave of the COVID pandemic from April-May 2020. When comparing the probability distributions of the input parameters, significant differences between pre-pandemic and in-pandemic data were found. The endpoint of our models, in-hospital mortality after surgery, did not differ significantly between pre- and in-pandemic data and was about 1% in each case. However, the models varied considerably in the composition of their input parameters. None of our applied modifications prevented a loss of performance, although very different models emerged from it, using a large variety of parameters.
CONCLUSIONS: Our results show that none of our tested easy-to-implement measures in model training can prevent deterioration in the case of sudden external events. Therefore, we conclude that, in the presence of concept drift and covariate shift, close monitoring and critical review of model predictions are necessary.",0
38231538,Mobile Apps for COVID-19 Detection and Diagnosis for Future Pandemic Control: Multidimensional Systematic Review,"Gheisari M, Ghaderzadeh M, Li H, Taami T, Fernández-Campusano C, Sadeghsalehi H, Afzaal Abbasi A.",JMIR Mhealth Uhealth. 2024 Feb 22;12:e44406. doi: 10.2196/44406.,Gheisari M,JMIR Mhealth Uhealth,2024,17-01-2024,PMC10896318,,10.2196/44406,"BACKGROUND: In the modern world, mobile apps are essential for human advancement, and pandemic control is no exception. The use of mobile apps and technology for the detection and diagnosis of COVID-19 has been the subject of numerous investigations, although no thorough analysis of COVID-19 pandemic prevention has been conducted using mobile apps, creating a gap.
OBJECTIVE: With the intention of helping software companies and clinical researchers, this study provides comprehensive information regarding the different fields in which mobile apps were used to diagnose COVID-19 during the pandemic.
METHODS: In this systematic review, 535 studies were found after searching 5 major research databases (ScienceDirect, Scopus, PubMed, Web of Science, and IEEE). Of these, only 42 (7.9%) studies concerned with diagnosing and detecting COVID-19 were chosen after applying inclusion and exclusion criteria using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) protocol.
RESULTS: Mobile apps were categorized into 6 areas based on the content of these 42 studies: contact tracing, data gathering, data visualization, artificial intelligence (AI)-based diagnosis, rule- and guideline-based diagnosis, and data transformation. Patients with COVID-19 were identified via mobile apps using a variety of clinical, geographic, demographic, radiological, serological, and laboratory data. Most studies concentrated on using AI methods to identify people who might have COVID-19. Additionally, symptoms, cough sounds, and radiological images were used more frequently compared to other data types. Deep learning techniques, such as convolutional neural networks, performed comparatively better in the processing of health care data than other types of AI techniques, which improved the diagnosis of COVID-19.
CONCLUSIONS: Mobile apps could soon play a significant role as a powerful tool for data collection, epidemic health data analysis, and the early identification of suspected cases. These technologies can work with the internet of things, cloud storage, 5th-generation technology, and cloud computing. Processing pipelines can be moved to mobile device processing cores using new deep learning methods, such as lightweight neural networks. In the event of future pandemics, mobile apps will play a critical role in rapid diagnosis using various image data and clinical symptoms. Consequently, the rapid diagnosis of these diseases can improve the management of their effects and obtain excellent results in treating patients.","Mobile Apps for COVID-19 Detection and Diagnosis for Future Pandemic Control: Multidimensional Systematic Review BACKGROUND: In the modern world, mobile apps are essential for human advancement, and pandemic control is no exception. The use of mobile apps and technology for the detection and diagnosis of COVID-19 has been the subject of numerous investigations, although no thorough analysis of COVID-19 pandemic prevention has been conducted using mobile apps, creating a gap.
OBJECTIVE: With the intention of helping software companies and clinical researchers, this study provides comprehensive information regarding the different fields in which mobile apps were used to diagnose COVID-19 during the pandemic.
METHODS: In this systematic review, 535 studies were found after searching 5 major research databases (ScienceDirect, Scopus, PubMed, Web of Science, and IEEE). Of these, only 42 (7.9%) studies concerned with diagnosing and detecting COVID-19 were chosen after applying inclusion and exclusion criteria using the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) protocol.
RESULTS: Mobile apps were categorized into 6 areas based on the content of these 42 studies: contact tracing, data gathering, data visualization, artificial intelligence (AI)-based diagnosis, rule- and guideline-based diagnosis, and data transformation. Patients with COVID-19 were identified via mobile apps using a variety of clinical, geographic, demographic, radiological, serological, and laboratory data. Most studies concentrated on using AI methods to identify people who might have COVID-19. Additionally, symptoms, cough sounds, and radiological images were used more frequently compared to other data types. Deep learning techniques, such as convolutional neural networks, performed comparatively better in the processing of health care data than other types of AI techniques, which improved the diagnosis of COVID-19.
CONCLUSIONS: Mobile apps could soon play a significant role as a powerful tool for data collection, epidemic health data analysis, and the early identification of suspected cases. These technologies can work with the internet of things, cloud storage, 5th-generation technology, and cloud computing. Processing pipelines can be moved to mobile device processing cores using new deep learning methods, such as lightweight neural networks. In the event of future pandemics, mobile apps will play a critical role in rapid diagnosis using various image data and clinical symptoms. Consequently, the rapid diagnosis of these diseases can improve the management of their effects and obtain excellent results in treating patients.",0
33870846,Viral quasispecies quantitative analysis: a novel approach for appraising the immune tolerant phase of chronic hepatitis B virus infection,"Wang M, Chen L, Dong M, Li J, Zhu B, Yang Z, Gong Q, Han Y, Yu D, Zhang D, Zoulim F, Zhang J, Zhang X.",Emerg Microbes Infect. 2021 Dec;10(1):842-851. doi: 10.1080/22221751.2021.1919033.,Wang M,Emerg Microbes Infect,2021,19-04-2021,PMC8812768,,10.1080/22221751.2021.1919033,"Few non-invasive models were established for precisely identifying the immune tolerant (IT) phase from chronic hepatitis B (CHB). This study aimed to develop a novel approach that combined next-generation sequencing (NGS) and machine learning algorithms using our recently published viral quasispecies (QS) analysis package. 290 HBeAg positive patients from whom liver biopsies were taken were enrolled and divided into a training group (n = 148) and a validation group (n = 142). HBV DNA was extracted and QS sequences were obtained by NGS. Hierarchical clustering analysis (HCA) and principal component analysis (PCA) based on viral operational taxonomic units (OTUs) were performed to explore the correlations among QS and clinical phenotypes. Three machine learning algorithms, including K-nearest neighbour, support vector machine, and random forest algorithm, were used to construct diagnostic models for IT phase classification. Based on histopathology, 90 IT patients and 200 CHB patients were diagnosed. HBsAg titres for IT patients were higher than those of CHB patients (p &lt; 0.001). HCA and PCA analysis grouped IT and CHB patients into two distinct clusters. The relative abundance of viral OTUs differed mainly within the BCP/precore/core region and was significantly correlated with liver inflammation and fibrosis. For the IT phase classification, all machine-learning models showed higher AUC values compared to models based on HBsAg, APRI, and FIB-4. The relative abundance of viral OTUs reflects the severity of liver inflammation and fibrosis. The novel QS quantitative analysis approach could be used to diagnose IT patients more precisely and reduce the need for liver biopsy.","Viral quasispecies quantitative analysis: a novel approach for appraising the immune tolerant phase of chronic hepatitis B virus infection Few non-invasive models were established for precisely identifying the immune tolerant (IT) phase from chronic hepatitis B (CHB). This study aimed to develop a novel approach that combined next-generation sequencing (NGS) and machine learning algorithms using our recently published viral quasispecies (QS) analysis package. 290 HBeAg positive patients from whom liver biopsies were taken were enrolled and divided into a training group (n = 148) and a validation group (n = 142). HBV DNA was extracted and QS sequences were obtained by NGS. Hierarchical clustering analysis (HCA) and principal component analysis (PCA) based on viral operational taxonomic units (OTUs) were performed to explore the correlations among QS and clinical phenotypes. Three machine learning algorithms, including K-nearest neighbour, support vector machine, and random forest algorithm, were used to construct diagnostic models for IT phase classification. Based on histopathology, 90 IT patients and 200 CHB patients were diagnosed. HBsAg titres for IT patients were higher than those of CHB patients (p &lt; 0.001). HCA and PCA analysis grouped IT and CHB patients into two distinct clusters. The relative abundance of viral OTUs differed mainly within the BCP/precore/core region and was significantly correlated with liver inflammation and fibrosis. For the IT phase classification, all machine-learning models showed higher AUC values compared to models based on HBsAg, APRI, and FIB-4. The relative abundance of viral OTUs reflects the severity of liver inflammation and fibrosis. The novel QS quantitative analysis approach could be used to diagnose IT patients more precisely and reduce the need for liver biopsy.",0
36993761,Predicting metabolite response to dietary intervention using deep learning,"Wang T, Holscher HD, Maslov S, Hu FB, Weiss ST, Liu YY.",bioRxiv [Preprint]. 2024 Sep 19:2023.03.14.532589. doi: 10.1101/2023.03.14.532589.,Wang T,bioRxiv,2024,30-03-2023,PMC10054958,,10.1101/2023.03.14.532589,"Due to highly personalized biological and lifestyle characteristics, different individuals may have different metabolite responses to specific foods and nutrients. In particular, the gut microbiota, a collection of trillions of microorganisms living in the gastrointestinal tract, is highly personalized and plays a key role in the metabolite responses to foods and nutrients. Accurately predicting metabolite responses to dietary interventions based on individuals' gut microbial compositions holds great promise for precision nutrition. Existing prediction methods are typically limited to traditional machine learning models. Deep learning methods dedicated to such tasks are still lacking. Here we develop a method McMLP (Metabolite response predictor using coupled Multilayer Perceptrons) to fill in this gap. We provide clear evidence that McMLP outperforms existing methods on both synthetic data generated by the microbial consumer-resource model and real data obtained from six dietary intervention studies. Furthermore, we perform sensitivity analysis of McMLP to infer the tripartite food-microbe-metabolite interactions, which are then validated using the ground-truth (or literature evidence) for synthetic (or real) data, respectively. The presented tool has the potential to inform the design of microbiota-based personalized dietary strategies to achieve precision nutrition.","Predicting metabolite response to dietary intervention using deep learning Due to highly personalized biological and lifestyle characteristics, different individuals may have different metabolite responses to specific foods and nutrients. In particular, the gut microbiota, a collection of trillions of microorganisms living in the gastrointestinal tract, is highly personalized and plays a key role in the metabolite responses to foods and nutrients. Accurately predicting metabolite responses to dietary interventions based on individuals' gut microbial compositions holds great promise for precision nutrition. Existing prediction methods are typically limited to traditional machine learning models. Deep learning methods dedicated to such tasks are still lacking. Here we develop a method McMLP (Metabolite response predictor using coupled Multilayer Perceptrons) to fill in this gap. We provide clear evidence that McMLP outperforms existing methods on both synthetic data generated by the microbial consumer-resource model and real data obtained from six dietary intervention studies. Furthermore, we perform sensitivity analysis of McMLP to infer the tripartite food-microbe-metabolite interactions, which are then validated using the ground-truth (or literature evidence) for synthetic (or real) data, respectively. The presented tool has the potential to inform the design of microbiota-based personalized dietary strategies to achieve precision nutrition.",0
28464015,Forecasting influenza in Hong Kong with Google search queries and statistical model fusion,"Xu Q, Gel YR, Ramirez Ramirez LL, Nezafati K, Zhang Q, Tsui KL.",PLoS One. 2017 May 2;12(5):e0176690. doi: 10.1371/journal.pone.0176690. eCollection 2017.,Xu Q,PLoS One,2017,03-05-2017,PMC5413039,,10.1371/journal.pone.0176690,"BACKGROUND: The objective of this study is to investigate predictive utility of online social media and web search queries, particularly, Google search data, to forecast new cases of influenza-like-illness (ILI) in general outpatient clinics (GOPC) in Hong Kong. To mitigate the impact of sensitivity to self-excitement (i.e., fickle media interest) and other artifacts of online social media data, in our approach we fuse multiple offline and online data sources.
METHODS: Four individual models: generalized linear model (GLM), least absolute shrinkage and selection operator (LASSO), autoregressive integrated moving average (ARIMA), and deep learning (DL) with Feedforward Neural Networks (FNN) are employed to forecast ILI-GOPC both one week and two weeks in advance. The covariates include Google search queries, meteorological data, and previously recorded offline ILI. To our knowledge, this is the first study that introduces deep learning methodology into surveillance of infectious diseases and investigates its predictive utility. Furthermore, to exploit the strength from each individual forecasting models, we use statistical model fusion, using Bayesian model averaging (BMA), which allows a systematic integration of multiple forecast scenarios. For each model, an adaptive approach is used to capture the recent relationship between ILI and covariates.
RESULTS: DL with FNN appears to deliver the most competitive predictive performance among the four considered individual models. Combing all four models in a comprehensive BMA framework allows to further improve such predictive evaluation metrics as root mean squared error (RMSE) and mean absolute predictive error (MAPE). Nevertheless, DL with FNN remains the preferred method for predicting locations of influenza peaks.
CONCLUSIONS: The proposed approach can be viewed a feasible alternative to forecast ILI in Hong Kong or other countries where ILI has no constant seasonal trend and influenza data resources are limited. The proposed methodology is easily tractable and computationally efficient.","Forecasting influenza in Hong Kong with Google search queries and statistical model fusion BACKGROUND: The objective of this study is to investigate predictive utility of online social media and web search queries, particularly, Google search data, to forecast new cases of influenza-like-illness (ILI) in general outpatient clinics (GOPC) in Hong Kong. To mitigate the impact of sensitivity to self-excitement (i.e., fickle media interest) and other artifacts of online social media data, in our approach we fuse multiple offline and online data sources.
METHODS: Four individual models: generalized linear model (GLM), least absolute shrinkage and selection operator (LASSO), autoregressive integrated moving average (ARIMA), and deep learning (DL) with Feedforward Neural Networks (FNN) are employed to forecast ILI-GOPC both one week and two weeks in advance. The covariates include Google search queries, meteorological data, and previously recorded offline ILI. To our knowledge, this is the first study that introduces deep learning methodology into surveillance of infectious diseases and investigates its predictive utility. Furthermore, to exploit the strength from each individual forecasting models, we use statistical model fusion, using Bayesian model averaging (BMA), which allows a systematic integration of multiple forecast scenarios. For each model, an adaptive approach is used to capture the recent relationship between ILI and covariates.
RESULTS: DL with FNN appears to deliver the most competitive predictive performance among the four considered individual models. Combing all four models in a comprehensive BMA framework allows to further improve such predictive evaluation metrics as root mean squared error (RMSE) and mean absolute predictive error (MAPE). Nevertheless, DL with FNN remains the preferred method for predicting locations of influenza peaks.
CONCLUSIONS: The proposed approach can be viewed a feasible alternative to forecast ILI in Hong Kong or other countries where ILI has no constant seasonal trend and influenza data resources are limited. The proposed methodology is easily tractable and computationally efficient.",0
32919186,COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review,"Suri JS, Puvvula A, Biswas M, Majhail M, Saba L, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Sanches JM, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Kolluri R, Teji J, Maini MA, Agbakoba A, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PR, Naidu S.",Comput Biol Med. 2020 Sep;124:103960. doi: 10.1016/j.compbiomed.2020.103960. Epub 2020 Aug 14.,Suri JS,Comput Biol Med,2020,12-09-2020,PMC7426723,,10.1016/j.compbiomed.2020.103960,"Artificial intelligence (AI) has penetrated the field of medicine, particularly the field of radiology. Since its emergence, the highly virulent coronavirus disease 2019 (COVID-19) has infected over 10 million people, leading to over 500,000 deaths as of July 1st, 2020. Since the outbreak began, almost 28,000 articles about COVID-19 have been published (https://pubmed.ncbi.nlm.nih.gov); however, few have explored the role of imaging and artificial intelligence in COVID-19 patients-specifically, those with comorbidities. This paper begins by presenting the four pathways that can lead to heart and brain injuries following a COVID-19 infection. Our survey also offers insights into the role that imaging can play in the treatment of comorbid patients, based on probabilities derived from COVID-19 symptom statistics. Such symptoms include myocardial injury, hypoxia, plaque rupture, arrhythmias, venous thromboembolism, coronary thrombosis, encephalitis, ischemia, inflammation, and lung injury. At its core, this study considers the role of image-based AI, which can be used to characterize the tissues of a COVID-19 patient and classify the severity of their infection. Image-based AI is more important than ever as the pandemic surges and countries worldwide grapple with limited medical resources for detection and diagnosis.","COVID-19 pathways for brain and heart injury in comorbidity patients: A role of medical imaging and artificial intelligence-based COVID severity classification: A review Artificial intelligence (AI) has penetrated the field of medicine, particularly the field of radiology. Since its emergence, the highly virulent coronavirus disease 2019 (COVID-19) has infected over 10 million people, leading to over 500,000 deaths as of July 1st, 2020. Since the outbreak began, almost 28,000 articles about COVID-19 have been published (https://pubmed.ncbi.nlm.nih.gov); however, few have explored the role of imaging and artificial intelligence in COVID-19 patients-specifically, those with comorbidities. This paper begins by presenting the four pathways that can lead to heart and brain injuries following a COVID-19 infection. Our survey also offers insights into the role that imaging can play in the treatment of comorbid patients, based on probabilities derived from COVID-19 symptom statistics. Such symptoms include myocardial injury, hypoxia, plaque rupture, arrhythmias, venous thromboembolism, coronary thrombosis, encephalitis, ischemia, inflammation, and lung injury. At its core, this study considers the role of image-based AI, which can be used to characterize the tissues of a COVID-19 patient and classify the severity of their infection. Image-based AI is more important than ever as the pandemic surges and countries worldwide grapple with limited medical resources for detection and diagnosis.",0
33232368,Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study,"Jang SB, Lee SH, Lee DE, Park SY, Kim JK, Cho JW, Cho J, Kim KB, Park B, Park J, Lim JK.",PLoS One. 2020 Nov 24;15(11):e0242759. doi: 10.1371/journal.pone.0242759. eCollection 2020.,Jang SB,PLoS One,2020,24-11-2020,PMC7685476,,10.1371/journal.pone.0242759,"The recent medical applications of deep-learning (DL) algorithms have demonstrated their clinical efficacy in improving speed and accuracy of image interpretation. If the DL algorithm achieves a performance equivalent to that achieved by physicians in chest radiography (CR) diagnoses with Coronavirus disease 2019 (COVID-19) pneumonia, the automatic interpretation of the CR with DL algorithms can significantly reduce the burden on clinicians and radiologists in sudden surges of suspected COVID-19 patients. The aim of this study was to evaluate the efficacy of the DL algorithm for detecting COVID-19 pneumonia on CR compared with formal radiology reports. This is a retrospective study of adult patients that were diagnosed as positive COVID-19 cases based on the reverse transcription polymerase chain reaction among all the patients who were admitted to five emergency departments and one community treatment center in Korea from February 18, 2020 to May 1, 2020. The CR images were evaluated with a publicly available DL algorithm. For reference, CR images without chest computed tomography (CT) scans classified as positive for COVID-19 pneumonia were used given that the radiologist identified ground-glass opacity, consolidation, or other infiltration in retrospectively reviewed CR images. Patients with evidence of pneumonia on chest CT scans were also classified as COVID-19 pneumonia positive outcomes. The overall sensitivity and specificity of the DL algorithm for detecting COVID-19 pneumonia on CR were 95.6%, and 88.7%, respectively. The area under the curve value of the DL algorithm for the detection of COVID-19 with pneumonia was 0.921. The DL algorithm demonstrated a satisfactory diagnostic performance comparable with that of formal radiology reports in the CR-based diagnosis of pneumonia in COVID-19 patients. The DL algorithm may offer fast and reliable examinations that can facilitate patient screening and isolation decisions, which can reduce the medical staff workload during COVID-19 pandemic situations.","Deep-learning algorithms for the interpretation of chest radiographs to aid in the triage of COVID-19 patients: A multicenter retrospective study The recent medical applications of deep-learning (DL) algorithms have demonstrated their clinical efficacy in improving speed and accuracy of image interpretation. If the DL algorithm achieves a performance equivalent to that achieved by physicians in chest radiography (CR) diagnoses with Coronavirus disease 2019 (COVID-19) pneumonia, the automatic interpretation of the CR with DL algorithms can significantly reduce the burden on clinicians and radiologists in sudden surges of suspected COVID-19 patients. The aim of this study was to evaluate the efficacy of the DL algorithm for detecting COVID-19 pneumonia on CR compared with formal radiology reports. This is a retrospective study of adult patients that were diagnosed as positive COVID-19 cases based on the reverse transcription polymerase chain reaction among all the patients who were admitted to five emergency departments and one community treatment center in Korea from February 18, 2020 to May 1, 2020. The CR images were evaluated with a publicly available DL algorithm. For reference, CR images without chest computed tomography (CT) scans classified as positive for COVID-19 pneumonia were used given that the radiologist identified ground-glass opacity, consolidation, or other infiltration in retrospectively reviewed CR images. Patients with evidence of pneumonia on chest CT scans were also classified as COVID-19 pneumonia positive outcomes. The overall sensitivity and specificity of the DL algorithm for detecting COVID-19 pneumonia on CR were 95.6%, and 88.7%, respectively. The area under the curve value of the DL algorithm for the detection of COVID-19 with pneumonia was 0.921. The DL algorithm demonstrated a satisfactory diagnostic performance comparable with that of formal radiology reports in the CR-based diagnosis of pneumonia in COVID-19 patients. The DL algorithm may offer fast and reliable examinations that can facilitate patient screening and isolation decisions, which can reduce the medical staff workload during COVID-19 pandemic situations.",0
32832047,Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach,"Mishra AK, Das SK, Roy P, Bandyopadhyay S.",J Healthc Eng. 2020 Aug 11;2020:8843664. doi: 10.1155/2020/8843664. eCollection 2020.,Mishra AK,J Healthc Eng,2020,25-08-2020,PMC7424536,,10.1155/2020/8843664,"Coronavirus Disease (COVID19) is a fast-spreading infectious disease that is currently causing a healthcare crisis around the world. Due to the current limitations of the reverse transcription-polymerase chain reaction (RT-PCR) based tests for detecting COVID19, recently radiology imaging based ideas have been proposed by various works. In this work, various Deep CNN based approaches are explored for detecting the presence of COVID19 from chest CT images. A decision fusion based approach is also proposed, which combines predictions from multiple individual models, to produce a final prediction. Experimental results show that the proposed decision fusion based approach is able to achieve above 86% results across all the performance metrics under consideration, with average AUROC and F1-Score being 0.883 and 0.867, respectively. The experimental observations suggest the potential applicability of such Deep CNN based approach in real diagnostic scenarios, which could be of very high utility in terms of achieving fast testing for COVID19.","Identifying COVID19 from Chest CT Images: A Deep Convolutional Neural Networks Based Approach Coronavirus Disease (COVID19) is a fast-spreading infectious disease that is currently causing a healthcare crisis around the world. Due to the current limitations of the reverse transcription-polymerase chain reaction (RT-PCR) based tests for detecting COVID19, recently radiology imaging based ideas have been proposed by various works. In this work, various Deep CNN based approaches are explored for detecting the presence of COVID19 from chest CT images. A decision fusion based approach is also proposed, which combines predictions from multiple individual models, to produce a final prediction. Experimental results show that the proposed decision fusion based approach is able to achieve above 86% results across all the performance metrics under consideration, with average AUROC and F1-Score being 0.883 and 0.867, respectively. The experimental observations suggest the potential applicability of such Deep CNN based approach in real diagnostic scenarios, which could be of very high utility in terms of achieving fast testing for COVID19.",0
32750973,Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models,"Bridge J, Meng Y, Zhao Y, Du Y, Zhao M, Sun R, Zheng Y.",IEEE J Biomed Health Inform. 2020 Oct;24(10):2776-2786. doi: 10.1109/JBHI.2020.3012383. Epub 2020 Jul 28.,Bridge J,IEEE J Biomed Health Inform,2020,06-08-2020,PMC8545159,,10.1109/JBHI.2020.3012383,"Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.","Introducing the GEV Activation Function for Highly Unbalanced Data to Develop COVID-19 Diagnostic Models Fast and accurate diagnosis is essential for the efficient and effective control of the COVID-19 pandemic that is currently disrupting the whole world. Despite the prevalence of the COVID-19 outbreak, relatively few diagnostic images are openly available to develop automatic diagnosis algorithms. Traditional deep learning methods often struggle when data is highly unbalanced with many cases in one class and only a few cases in another; new methods must be developed to overcome this challenge. We propose a novel activation function based on the generalized extreme value (GEV) distribution from extreme value theory, which improves performance over the traditional sigmoid activation function when one class significantly outweighs the other. We demonstrate the proposed activation function on a publicly available dataset and externally validate on a dataset consisting of 1,909 healthy chest X-rays and 84 COVID-19 X-rays. The proposed method achieves an improved area under the receiver operating characteristic (DeLong's p-value < 0.05) compared to the sigmoid activation. Our method is also demonstrated on a dataset of healthy and pneumonia vs. COVID-19 X-rays and a set of computerized tomography images, achieving improved sensitivity. The proposed GEV activation function significantly improves upon the previously used sigmoid activation for binary classification. This new paradigm is expected to play a significant role in the fight against COVID-19 and other diseases, with relatively few training cases available.",0
36147628,Artificial intelligence performance in image-based ovarian cancer identification: A systematic review and meta-analysis,"Xu HL, Gong TT, Liu FH, Chen HY, Xiao Q, Hou Y, Huang Y, Sun HZ, Shi Y, Gao S, Lou Y, Chang Q, Zhao YH, Gao QL, Wu QJ.",EClinicalMedicine. 2022 Sep 17;53:101662. doi: 10.1016/j.eclinm.2022.101662. eCollection 2022 Nov.,Xu HL,EClinicalMedicine,2022,23-09-2022,PMC9486055,,10.1016/j.eclinm.2022.101662,"BACKGROUND: Accurate identification of ovarian cancer (OC) is of paramount importance in clinical treatment success. Artificial intelligence (AI) is a potentially reliable assistant for the medical imaging recognition. We systematically review articles on the diagnostic performance of AI in OC from medical imaging for the first time.
METHODS: The Medline, Embase, IEEE, PubMed, Web of Science, and the Cochrane library databases were searched for related studies published until August 1, 2022. Inclusion criteria were studies that developed or used AI algorithms in the diagnosis of OC from medical images. The binary diagnostic accuracy data were extracted to derive the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022324611.
FINDINGS: Thirty-four eligible studies were identified, of which twenty-eight studies were included in the meta-analysis with a pooled SE of 88% (95%CI: 85-90%), SP of 85% (82-88%), and AUC of 0.93 (0.91-0.95). Analysis for different algorithms revealed a pooled SE of 89% (85-92%) and SP of 88% (82-92%) for machine learning; and a pooled SE of 88% (84-91%) and SP of 84% (80-87%) for deep learning. Acceptable diagnostic performance was demonstrated in subgroup analyses stratified by imaging modalities (Ultrasound, Magnetic Resonance Imaging, or Computed Tomography), sample size (≤300 or >300), AI algorithms versus clinicians, year of publication (before or after 2020), geographical distribution (Asia or non Asia), and the different risk of bias levels (≥3 domain low risk or < 3 domain low risk).
INTERPRETATION: AI algorithms exhibited favorable performance for the diagnosis of OC through medical imaging. More rigorous reporting standards that address specific challenges of AI research could improve future studies.
FUNDING: This work was supported by the Natural Science Foundation of China (No. 82073647 to Q-JW and No. 82103914 to T-TG), LiaoNing Revitalization Talents Program (No. XLYC1907102 to Q-JW), and 345 Talent Project of Shengjing Hospital of China Medical University (No. M0268 to Q-JW and No. M0952 to T-TG).","Artificial intelligence performance in image-based ovarian cancer identification: A systematic review and meta-analysis BACKGROUND: Accurate identification of ovarian cancer (OC) is of paramount importance in clinical treatment success. Artificial intelligence (AI) is a potentially reliable assistant for the medical imaging recognition. We systematically review articles on the diagnostic performance of AI in OC from medical imaging for the first time.
METHODS: The Medline, Embase, IEEE, PubMed, Web of Science, and the Cochrane library databases were searched for related studies published until August 1, 2022. Inclusion criteria were studies that developed or used AI algorithms in the diagnosis of OC from medical images. The binary diagnostic accuracy data were extracted to derive the outcomes of interest: sensitivity (SE), specificity (SP), and Area Under the Curve (AUC). The study was registered with the PROSPERO, CRD42022324611.
FINDINGS: Thirty-four eligible studies were identified, of which twenty-eight studies were included in the meta-analysis with a pooled SE of 88% (95%CI: 85-90%), SP of 85% (82-88%), and AUC of 0.93 (0.91-0.95). Analysis for different algorithms revealed a pooled SE of 89% (85-92%) and SP of 88% (82-92%) for machine learning; and a pooled SE of 88% (84-91%) and SP of 84% (80-87%) for deep learning. Acceptable diagnostic performance was demonstrated in subgroup analyses stratified by imaging modalities (Ultrasound, Magnetic Resonance Imaging, or Computed Tomography), sample size (≤300 or >300), AI algorithms versus clinicians, year of publication (before or after 2020), geographical distribution (Asia or non Asia), and the different risk of bias levels (≥3 domain low risk or < 3 domain low risk).
INTERPRETATION: AI algorithms exhibited favorable performance for the diagnosis of OC through medical imaging. More rigorous reporting standards that address specific challenges of AI research could improve future studies.
FUNDING: This work was supported by the Natural Science Foundation of China (No. 82073647 to Q-JW and No. 82103914 to T-TG), LiaoNing Revitalization Talents Program (No. XLYC1907102 to Q-JW), and 345 Talent Project of Shengjing Hospital of China Medical University (No. M0268 to Q-JW and No. M0952 to T-TG).",0
35885449,Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review,"Suri JS, Maindarkar MA, Paul S, Ahluwalia P, Bhagawati M, Saba L, Faa G, Saxena S, Singh IM, Chadha PS, Turk M, Johri A, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou AD, Misra DP, Agarwal V, Kitas GD, Kolluri R, Teji JS, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Sharma A, Rathore V, Fatemi M, Alizad A, Krishnan PR, Omerzu T, Naidu S, Nicolaides A, Paraskevas KI, Kalra M, Ruzsa Z, Fouda MM.",Diagnostics (Basel). 2022 Jun 24;12(7):1543. doi: 10.3390/diagnostics12071543.,Suri JS,Diagnostics (Basel),2022,27-07-2022,PMC9324237,,10.3390/diagnostics12071543,"Background and Motivation: Parkinson's disease (PD) is one of the most serious, non-curable, and expensive to treat. Recently, machine learning (ML) has shown to be able to predict cardiovascular/stroke risk in PD patients. The presence of COVID-19 causes the ML systems to become severely non-linear and poses challenges in cardiovascular/stroke risk stratification. Further, due to comorbidity, sample size constraints, and poor scientific and clinical validation techniques, there have been no well-explained ML paradigms. Deep neural networks are powerful learning machines that generalize non-linear conditions. This study presents a novel investigation of deep learning (DL) solutions for CVD/stroke risk prediction in PD patients affected by the COVID-19 framework. Method: The PRISMA search strategy was used for the selection of 292 studies closely associated with the effect of PD on CVD risk in the COVID-19 framework. We study the hypothesis that PD in the presence of COVID-19 can cause more harm to the heart and brain than in non-COVID-19 conditions. COVID-19 lung damage severity can be used as a covariate during DL training model designs. We, therefore, propose a DL model for the estimation of, (i) COVID-19 lesions in computed tomography (CT) scans and (ii) combining the covariates of PD, COVID-19 lesions, office and laboratory arterial atherosclerotic image-based biomarkers, and medicine usage for the PD patients for the design of DL point-based models for CVD/stroke risk stratification. Results: We validated the feasibility of CVD/stroke risk stratification in PD patients in the presence of a COVID-19 environment and this was also verified. DL architectures like long short-term memory (LSTM), and recurrent neural network (RNN) were studied for CVD/stroke risk stratification showing powerful designs. Lastly, we examined the artificial intelligence bias and provided recommendations for early detection of CVD/stroke in PD patients in the presence of COVID-19. Conclusion: The DL is a very powerful tool for predicting CVD/stroke risk in PD patients affected by COVID-19.","Deep Learning Paradigm for Cardiovascular Disease/Stroke Risk Stratification in Parkinson's Disease Affected by COVID-19: A Narrative Review Background and Motivation: Parkinson's disease (PD) is one of the most serious, non-curable, and expensive to treat. Recently, machine learning (ML) has shown to be able to predict cardiovascular/stroke risk in PD patients. The presence of COVID-19 causes the ML systems to become severely non-linear and poses challenges in cardiovascular/stroke risk stratification. Further, due to comorbidity, sample size constraints, and poor scientific and clinical validation techniques, there have been no well-explained ML paradigms. Deep neural networks are powerful learning machines that generalize non-linear conditions. This study presents a novel investigation of deep learning (DL) solutions for CVD/stroke risk prediction in PD patients affected by the COVID-19 framework. Method: The PRISMA search strategy was used for the selection of 292 studies closely associated with the effect of PD on CVD risk in the COVID-19 framework. We study the hypothesis that PD in the presence of COVID-19 can cause more harm to the heart and brain than in non-COVID-19 conditions. COVID-19 lung damage severity can be used as a covariate during DL training model designs. We, therefore, propose a DL model for the estimation of, (i) COVID-19 lesions in computed tomography (CT) scans and (ii) combining the covariates of PD, COVID-19 lesions, office and laboratory arterial atherosclerotic image-based biomarkers, and medicine usage for the PD patients for the design of DL point-based models for CVD/stroke risk stratification. Results: We validated the feasibility of CVD/stroke risk stratification in PD patients in the presence of a COVID-19 environment and this was also verified. DL architectures like long short-term memory (LSTM), and recurrent neural network (RNN) were studied for CVD/stroke risk stratification showing powerful designs. Lastly, we examined the artificial intelligence bias and provided recommendations for early detection of CVD/stroke in PD patients in the presence of COVID-19. Conclusion: The DL is a very powerful tool for predicting CVD/stroke risk in PD patients affected by COVID-19.",0
35078755,"Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery","Abubaker Bagabir S, Ibrahim NK, Abubaker Bagabir H, Hashem Ateeq R.",J Infect Public Health. 2022 Feb;15(2):289-296. doi: 10.1016/j.jiph.2022.01.011. Epub 2022 Jan 19.,Abubaker Bagabir S,J Infect Public Health,2022,26-01-2022,PMC8767913,,10.1016/j.jiph.2022.01.011,"OBJECTIVES: To clarify the work done by using AI for identifying the genomic sequences, development of drugs and vaccines for COVID-19 and to recognize the advantages and challenges of using such technology.
METHODS: A non-systematic review was done. All articles published on Pub-Med, Medline, Google, and Google Scholar on AI or digital health regarding genomic sequencing, drug development, and vaccines of COVID-19 were scrutinized and summarized.
RESULTS: The sequence of SARS- CoV-2 was identified with the help of AI. It can help also in the prompt identification of variants of concern (VOC) as delta strains and Omicron. Furthermore, there are many drugs applied with the help of AI. These drugs included Atazanavir, Remdesivir, Efavirenz, Ritonavir, and Dolutegravir, PARP1 inhibitors (Olaparib and CVL218 which is Mefuparib hydrochloride), Abacavir, Roflumilast, Almitrine, and Mesylate. Many vaccines were developed utilizing the new technology of bioinformatics, databases, immune-informatics, machine learning, and reverse vaccinology to the whole SARS-CoV-2 proteomes or the structural proteins. Examples of these vaccines are the messenger RNA and viral vector vaccines. AI provides cost-saving and agility. However, the challenges of its usage are the difficulty of collecting data, the internal and external validation, ethical consideration, therapeutic effect, and the time needed for clinical trials after drug approval. Moreover, there is a common problem in the deep learning (DL) model which is the shortage of interpretability.
CONCLUSION: The growth of AI techniques in health care opened a broad gate for discovering the genomic sequences of the COVID-19 virus and the VOC. AI helps also in the development of vaccines and drugs (including drug repurposing) to obtain potential preventive and therapeutic agents for controlling the COVID-19 pandemic.","Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery OBJECTIVES: To clarify the work done by using AI for identifying the genomic sequences, development of drugs and vaccines for COVID-19 and to recognize the advantages and challenges of using such technology.
METHODS: A non-systematic review was done. All articles published on Pub-Med, Medline, Google, and Google Scholar on AI or digital health regarding genomic sequencing, drug development, and vaccines of COVID-19 were scrutinized and summarized.
RESULTS: The sequence of SARS- CoV-2 was identified with the help of AI. It can help also in the prompt identification of variants of concern (VOC) as delta strains and Omicron. Furthermore, there are many drugs applied with the help of AI. These drugs included Atazanavir, Remdesivir, Efavirenz, Ritonavir, and Dolutegravir, PARP1 inhibitors (Olaparib and CVL218 which is Mefuparib hydrochloride), Abacavir, Roflumilast, Almitrine, and Mesylate. Many vaccines were developed utilizing the new technology of bioinformatics, databases, immune-informatics, machine learning, and reverse vaccinology to the whole SARS-CoV-2 proteomes or the structural proteins. Examples of these vaccines are the messenger RNA and viral vector vaccines. AI provides cost-saving and agility. However, the challenges of its usage are the difficulty of collecting data, the internal and external validation, ethical consideration, therapeutic effect, and the time needed for clinical trials after drug approval. Moreover, there is a common problem in the deep learning (DL) model which is the shortage of interpretability.
CONCLUSION: The growth of AI techniques in health care opened a broad gate for discovering the genomic sequences of the COVID-19 virus and the VOC. AI helps also in the development of vaccines and drugs (including drug repurposing) to obtain potential preventive and therapeutic agents for controlling the COVID-19 pandemic.",0
32616597,Development of a clinical decision support system for severity risk prediction and triage of COVID-19 patients at hospital admission: an international multicentre study,"Wu G, Yang P, Xie Y, Woodruff HC, Rao X, Guiot J, Frix AN, Louis R, Moutschen M, Li J, Li J, Yan C, Du D, Zhao S, Ding Y, Liu B, Sun W, Albarello F, D'Abramo A, Schininà V, Nicastri E, Occhipinti M, Barisione G, Barisione E, Halilaj I, Lovinfosse P, Wang X, Wu J, Lambin P.",Eur Respir J. 2020 Aug 20;56(2):2001104. doi: 10.1183/13993003.01104-2020. Print 2020 Aug.,Wu G,Eur Respir J,2020,04-07-2020,PMC7331655,,10.1183/13993003.01104-2020,"BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) has globally strained medical resources and caused significant mortality.
OBJECTIVE: To develop and validate a machine-learning model based on clinical features for severity risk assessment and triage for COVID-19 patients at hospital admission.
METHOD: 725 patients were used to train and validate the model. This included a retrospective cohort from Wuhan, China of 299 hospitalised COVID-19 patients from 23 December 2019 to 13 February 2020, and five cohorts with 426 patients from eight centres in China, Italy and Belgium from 20 February 2020 to 21 March 2020. The main outcome was the onset of severe or critical illness during hospitalisation. Model performances were quantified using the area under the receiver operating characteristic curve (AUC) and metrics derived from the confusion matrix.
RESULTS: In the retrospective cohort, the median age was 50 years and 137 (45.8%) were male. In the five test cohorts, the median age was 62 years and 236 (55.4%) were male. The model was prospectively validated on five cohorts yielding AUCs ranging from 0.84 to 0.93, with accuracies ranging from 74.4% to 87.5%, sensitivities ranging from 75.0% to 96.9%, and specificities ranging from 55.0% to 88.0%, most of which performed better than the pneumonia severity index. The cut-off values of the low-, medium- and high-risk probabilities were 0.21 and 0.80. The online calculators can be found at www.covid19risk.ai.
CONCLUSION: The machine-learning model, nomogram and online calculator might be useful to access the onset of severe and critical illness among COVID-19 patients and triage at hospital admission.","Development of a clinical decision support system for severity risk prediction and triage of COVID-19 patients at hospital admission: an international multicentre study BACKGROUND: The outbreak of coronavirus disease 2019 (COVID-19) has globally strained medical resources and caused significant mortality.
OBJECTIVE: To develop and validate a machine-learning model based on clinical features for severity risk assessment and triage for COVID-19 patients at hospital admission.
METHOD: 725 patients were used to train and validate the model. This included a retrospective cohort from Wuhan, China of 299 hospitalised COVID-19 patients from 23 December 2019 to 13 February 2020, and five cohorts with 426 patients from eight centres in China, Italy and Belgium from 20 February 2020 to 21 March 2020. The main outcome was the onset of severe or critical illness during hospitalisation. Model performances were quantified using the area under the receiver operating characteristic curve (AUC) and metrics derived from the confusion matrix.
RESULTS: In the retrospective cohort, the median age was 50 years and 137 (45.8%) were male. In the five test cohorts, the median age was 62 years and 236 (55.4%) were male. The model was prospectively validated on five cohorts yielding AUCs ranging from 0.84 to 0.93, with accuracies ranging from 74.4% to 87.5%, sensitivities ranging from 75.0% to 96.9%, and specificities ranging from 55.0% to 88.0%, most of which performed better than the pneumonia severity index. The cut-off values of the low-, medium- and high-risk probabilities were 0.21 and 0.80. The online calculators can be found at www.covid19risk.ai.
CONCLUSION: The machine-learning model, nomogram and online calculator might be useful to access the onset of severe and critical illness among COVID-19 patients and triage at hospital admission.",0
33550068,A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence,"Suri JS, Agarwal S, Gupta SK, Puvvula A, Biswas M, Saba L, Bit A, Tandel GS, Agarwal M, Patrick A, Faa G, Singh IM, Oberleitner R, Turk M, Chadha PS, Johri AM, Miguel Sanches J, Khanna NN, Viskovic K, Mavrogeni S, Laird JR, Pareek G, Miner M, Sobel DW, Balestrieri A, Sfikakis PP, Tsoulfas G, Protogerou A, Misra DP, Agarwal V, Kitas GD, Ahluwalia P, Teji J, Al-Maini M, Dhanjil SK, Sockalingam M, Saxena A, Nicolaides A, Sharma A, Rathore V, Ajuluchukwu JNA, Fatemi M, Alizad A, Viswanathan V, Krishnan PK, Naidu S.",Comput Biol Med. 2021 Mar;130:104210. doi: 10.1016/j.compbiomed.2021.104210. Epub 2021 Jan 18.,Suri JS,Comput Biol Med,2021,07-02-2021,PMC7813499,,10.1016/j.compbiomed.2021.104210,"COVID-19 has infected 77.4 million people worldwide and has caused 1.7 million fatalities as of December 21, 2020. The primary cause of death due to COVID-19 is Acute Respiratory Distress Syndrome (ARDS). According to the World Health Organization (WHO), people who are at least 60 years old or have comorbidities that have primarily been targeted are at the highest risk from SARS-CoV-2. Medical imaging provides a non-invasive, touch-free, and relatively safer alternative tool for diagnosis during the current ongoing pandemic. Artificial intelligence (AI) scientists are developing several intelligent computer-aided diagnosis (CAD) tools in multiple imaging modalities, i.e., lung computed tomography (CT), chest X-rays, and lung ultrasounds. These AI tools assist the pulmonary and critical care clinicians through (a) faster detection of the presence of a virus, (b) classifying pneumonia types, and (c) measuring the severity of viral damage in COVID-19-infected patients. Thus, it is of the utmost importance to fully understand the requirements of for a fast and successful, and timely lung scans analysis. This narrative review first presents the pathological layout of the lungs in the COVID-19 scenario, followed by understanding and then explains the comorbid statistical distributions in the ARDS framework. The novelty of this review is the approach to classifying the AI models as per the by school of thought (SoTs), exhibiting based on segregation of techniques and their characteristics. The study also discusses the identification of AI models and its extension from non-ARDS lungs (pre-COVID-19) to ARDS lungs (post-COVID-19). Furthermore, it also presents AI workflow considerations of for medical imaging modalities in the COVID-19 framework. Finally, clinical AI design considerations will be discussed. We conclude that the design of the current existing AI models can be improved by considering comorbidity as an independent factor. Furthermore, ARDS post-processing clinical systems must involve include (i) the clinical validation and verification of AI-models, (ii) reliability and stability criteria, and (iii) easily adaptable, and (iv) generalization assessments of AI systems for their use in pulmonary, critical care, and radiological settings.","A narrative review on characterization of acute respiratory distress syndrome in COVID-19-infected lungs using artificial intelligence COVID-19 has infected 77.4 million people worldwide and has caused 1.7 million fatalities as of December 21, 2020. The primary cause of death due to COVID-19 is Acute Respiratory Distress Syndrome (ARDS). According to the World Health Organization (WHO), people who are at least 60 years old or have comorbidities that have primarily been targeted are at the highest risk from SARS-CoV-2. Medical imaging provides a non-invasive, touch-free, and relatively safer alternative tool for diagnosis during the current ongoing pandemic. Artificial intelligence (AI) scientists are developing several intelligent computer-aided diagnosis (CAD) tools in multiple imaging modalities, i.e., lung computed tomography (CT), chest X-rays, and lung ultrasounds. These AI tools assist the pulmonary and critical care clinicians through (a) faster detection of the presence of a virus, (b) classifying pneumonia types, and (c) measuring the severity of viral damage in COVID-19-infected patients. Thus, it is of the utmost importance to fully understand the requirements of for a fast and successful, and timely lung scans analysis. This narrative review first presents the pathological layout of the lungs in the COVID-19 scenario, followed by understanding and then explains the comorbid statistical distributions in the ARDS framework. The novelty of this review is the approach to classifying the AI models as per the by school of thought (SoTs), exhibiting based on segregation of techniques and their characteristics. The study also discusses the identification of AI models and its extension from non-ARDS lungs (pre-COVID-19) to ARDS lungs (post-COVID-19). Furthermore, it also presents AI workflow considerations of for medical imaging modalities in the COVID-19 framework. Finally, clinical AI design considerations will be discussed. We conclude that the design of the current existing AI models can be improved by considering comorbidity as an independent factor. Furthermore, ARDS post-processing clinical systems must involve include (i) the clinical validation and verification of AI-models, (ii) reliability and stability criteria, and (iii) easily adaptable, and (iv) generalization assessments of AI systems for their use in pulmonary, critical care, and radiological settings.",0
36005433,"Vascular Implications of COVID-19: Role of Radiological Imaging, Artificial Intelligence, and Tissue Characterization: A Special Report","Khanna NN, Maindarkar M, Puvvula A, Paul S, Bhagawati M, Ahluwalia P, Ruzsa Z, Sharma A, Munjral S, Kolluri R, Krishnan PR, Singh IM, Laird JR, Fatemi M, Alizad A, Dhanjil SK, Saba L, Balestrieri A, Faa G, Paraskevas KI, Misra DP, Agarwal V, Sharma A, Teji J, Al-Maini M, Nicolaides A, Rathore V, Naidu S, Liblik K, Johri AM, Turk M, Sobel DW, Pareek G, Miner M, Viskovic K, Tsoulfas G, Protogerou AD, Mavrogeni S, Kitas GD, Fouda MM, Kalra MK, Suri JS.",J Cardiovasc Dev Dis. 2022 Aug 15;9(8):268. doi: 10.3390/jcdd9080268.,Khanna NN,J Cardiovasc Dev Dis,2022,25-08-2022,PMC9409845,,10.3390/jcdd9080268,"The SARS-CoV-2 virus has caused a pandemic, infecting nearly 80 million people worldwide, with mortality exceeding six million. The average survival span is just 14 days from the time the symptoms become aggressive. The present study delineates the deep-driven vascular damage in the pulmonary, renal, coronary, and carotid vessels due to SARS-CoV-2. This special report addresses an important gap in the literature in understanding (i) the pathophysiology of vascular damage and the role of medical imaging in the visualization of the damage caused by SARS-CoV-2, and (ii) further understanding the severity of COVID-19 using artificial intelligence (AI)-based tissue characterization (TC). PRISMA was used to select 296 studies for AI-based TC. Radiological imaging techniques such as magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound were selected for imaging of the vasculature infected by COVID-19. Four kinds of hypotheses are presented for showing the vascular damage in radiological images due to COVID-19. Three kinds of AI models, namely, machine learning, deep learning, and transfer learning, are used for TC. Further, the study presents recommendations for improving AI-based architectures for vascular studies. We conclude that the process of vascular damage due to COVID-19 has similarities across vessel types, even though it results in multi-organ dysfunction. Although the mortality rate is ~2% of those infected, the long-term effect of COVID-19 needs monitoring to avoid deaths. AI seems to be penetrating the health care industry at warp speed, and we expect to see an emerging role in patient care, reduce the mortality and morbidity rate.","Vascular Implications of COVID-19: Role of Radiological Imaging, Artificial Intelligence, and Tissue Characterization: A Special Report The SARS-CoV-2 virus has caused a pandemic, infecting nearly 80 million people worldwide, with mortality exceeding six million. The average survival span is just 14 days from the time the symptoms become aggressive. The present study delineates the deep-driven vascular damage in the pulmonary, renal, coronary, and carotid vessels due to SARS-CoV-2. This special report addresses an important gap in the literature in understanding (i) the pathophysiology of vascular damage and the role of medical imaging in the visualization of the damage caused by SARS-CoV-2, and (ii) further understanding the severity of COVID-19 using artificial intelligence (AI)-based tissue characterization (TC). PRISMA was used to select 296 studies for AI-based TC. Radiological imaging techniques such as magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound were selected for imaging of the vasculature infected by COVID-19. Four kinds of hypotheses are presented for showing the vascular damage in radiological images due to COVID-19. Three kinds of AI models, namely, machine learning, deep learning, and transfer learning, are used for TC. Further, the study presents recommendations for improving AI-based architectures for vascular studies. We conclude that the process of vascular damage due to COVID-19 has similarities across vessel types, even though it results in multi-organ dysfunction. Although the mortality rate is ~2% of those infected, the long-term effect of COVID-19 needs monitoring to avoid deaths. AI seems to be penetrating the health care industry at warp speed, and we expect to see an emerging role in patient care, reduce the mortality and morbidity rate.",0
29686471,Analysis of aggressiveness factors in hepatocellular carcinoma patients undergoing transarterial chemoembolization,"Ventura Y, Carr BI, Kori I, Guerra V, Shibolet O.",World J Gastroenterol. 2018 Apr 21;24(15):1641-1649. doi: 10.3748/wjg.v24.i15.1641.,Ventura Y,World J Gastroenterol,2018,25-04-2018,PMC5910547,,10.3748/wjg.v24.i15.1641,"AIM: To investigate novel predictors of survival in hepatocellular carcinoma (HCC) patients following transarterial chemoembolization (TACE).
METHODS: One hundred sixty seven patients with un-resectable HCC were retrospectively analyzed to identify factors that might contribute to their HCC biology and aggressiveness. We correlated routine laboratory results (total bilirubin, AST, ALKP, GGTP, albumin etc.) to maximum tumor diameter, number of tumor nodules, portal vein thrombosis and blood alpha-fetoprotein levels. These 4 parameters were previously combined to form an aggressiveness index (AgI). We used The Wilcoxon rank-sum (Mann-Whitney), to test the correlation between the AgI categories and liver function parameters. The Cox proportional hazards model was applied to evaluate the categories of AgI associated with overall survival.
RESULTS: The AgI was strongly correlated with survival in this novel patient population. Three year survival probability for AgI &gt; or &lt; 4 was 42.4% vs 61.8%; P &lt; 0.0863 respectively. Several factors independently correlated with AgI using univariate multiple logistic regression of AgI with 8 laboratory parameters. Lower albumin levels had an OR of 2.56 (95%CI: 1.120-5.863 P &lt; 0.026), elevated Alkaline phosphatase and gamma glutamyl transpeptidase (GGTP) had ORs of 1.01 (95%CI: 1.003-1.026, P &lt; 0.017) and 0.99 (95%CI: 0.99-1.00, P &lt; 0.053) respectively. In a Cox proportional hazard model combining mortality for AgI score and liver function parameters, only GGTP levels and the AgI were independently associated with survival. An AgI &gt; 4 had HR for mortality of 2.18 (95%CI: 1.108-4.310, P &lt; 0.024). GGTP's single unit change had a HR for mortality of 1.003 (95%CI: 1.001-1.006, P &lt; 0.016). These were considered in the final multivariate model with the total cohort. An AgI &gt; 4 had a HR for mortality of 2.26 (95%CI: 1.184-4.327, P &lt; 0.016). GGTP had a HR of 1.003 (95%CI: 1.001-1.004, P &lt; 0.001).
CONCLUSION: Our study validates the AgI in a new population with un-resectable HCC patients undergoing TACE. The analysis establishes a correlation between GGTP and the AgI.","Analysis of aggressiveness factors in hepatocellular carcinoma patients undergoing transarterial chemoembolization AIM: To investigate novel predictors of survival in hepatocellular carcinoma (HCC) patients following transarterial chemoembolization (TACE).
METHODS: One hundred sixty seven patients with un-resectable HCC were retrospectively analyzed to identify factors that might contribute to their HCC biology and aggressiveness. We correlated routine laboratory results (total bilirubin, AST, ALKP, GGTP, albumin etc.) to maximum tumor diameter, number of tumor nodules, portal vein thrombosis and blood alpha-fetoprotein levels. These 4 parameters were previously combined to form an aggressiveness index (AgI). We used The Wilcoxon rank-sum (Mann-Whitney), to test the correlation between the AgI categories and liver function parameters. The Cox proportional hazards model was applied to evaluate the categories of AgI associated with overall survival.
RESULTS: The AgI was strongly correlated with survival in this novel patient population. Three year survival probability for AgI &gt; or &lt; 4 was 42.4% vs 61.8%; P &lt; 0.0863 respectively. Several factors independently correlated with AgI using univariate multiple logistic regression of AgI with 8 laboratory parameters. Lower albumin levels had an OR of 2.56 (95%CI: 1.120-5.863 P &lt; 0.026), elevated Alkaline phosphatase and gamma glutamyl transpeptidase (GGTP) had ORs of 1.01 (95%CI: 1.003-1.026, P &lt; 0.017) and 0.99 (95%CI: 0.99-1.00, P &lt; 0.053) respectively. In a Cox proportional hazard model combining mortality for AgI score and liver function parameters, only GGTP levels and the AgI were independently associated with survival. An AgI &gt; 4 had HR for mortality of 2.18 (95%CI: 1.108-4.310, P &lt; 0.024). GGTP's single unit change had a HR for mortality of 1.003 (95%CI: 1.001-1.006, P &lt; 0.016). These were considered in the final multivariate model with the total cohort. An AgI &gt; 4 had a HR for mortality of 2.26 (95%CI: 1.184-4.327, P &lt; 0.016). GGTP had a HR of 1.003 (95%CI: 1.001-1.004, P &lt; 0.001).
CONCLUSION: Our study validates the AgI in a new population with un-resectable HCC patients undergoing TACE. The analysis establishes a correlation between GGTP and the AgI.",0
37986764,Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation,"Ge J, Sun S, Owens J, Galvez V, Gologorskaya O, Lai JC, Pletcher MJ, Lai K.",medRxiv [Preprint]. 2023 Nov 10:2023.11.10.23298364. doi: 10.1101/2023.11.10.23298364.,Ge J,medRxiv,2023,21-11-2023,PMC10659484,,10.1101/2023.11.10.23298364,"BACKGROUND: Large language models (LLMs) have significant capabilities in clinical information processing tasks. Commercially available LLMs, however, are not optimized for clinical uses and are prone to generating incorrect or hallucinatory information. Retrieval-augmented generation (RAG) is an enterprise architecture that allows embedding of customized data into LLMs. This approach ""specializes"" the LLMs and is thought to reduce hallucinations.
METHODS: We developed ""LiVersa,"" a liver disease-specific LLM, by using our institution's protected health information (PHI)-complaint text embedding and LLM platform, ""Versa."" We conducted RAG on 30 publicly available American Association for the Study of Liver Diseases (AASLD) guidelines and guidance documents to be incorporated into LiVersa. We evaluated LiVersa's performance by comparing its responses versus those of trainees from a previously published knowledge assessment study regarding hepatitis B (HBV) treatment and hepatocellular carcinoma (HCC) surveillance.
RESULTS: LiVersa answered all 10 questions correctly when forced to provide a ""yes"" or ""no"" answer. Full detailed responses with justifications and rationales, however, were not completely correct for three of the questions.
DISCUSSIONS: In this study, we demonstrated the ability to build disease-specific and PHI-compliant LLMs using RAG. While our LLM, LiVersa, demonstrated more specificity in answering questions related to clinical hepatology - there were some knowledge deficiencies due to limitations set by the number and types of documents used for RAG. The LiVersa prototype, however, is a proof of concept for utilizing RAG to customize LLMs for clinical uses and a potential strategy to realize personalized medicine in the future.","Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation BACKGROUND: Large language models (LLMs) have significant capabilities in clinical information processing tasks. Commercially available LLMs, however, are not optimized for clinical uses and are prone to generating incorrect or hallucinatory information. Retrieval-augmented generation (RAG) is an enterprise architecture that allows embedding of customized data into LLMs. This approach ""specializes"" the LLMs and is thought to reduce hallucinations.
METHODS: We developed ""LiVersa,"" a liver disease-specific LLM, by using our institution's protected health information (PHI)-complaint text embedding and LLM platform, ""Versa."" We conducted RAG on 30 publicly available American Association for the Study of Liver Diseases (AASLD) guidelines and guidance documents to be incorporated into LiVersa. We evaluated LiVersa's performance by comparing its responses versus those of trainees from a previously published knowledge assessment study regarding hepatitis B (HBV) treatment and hepatocellular carcinoma (HCC) surveillance.
RESULTS: LiVersa answered all 10 questions correctly when forced to provide a ""yes"" or ""no"" answer. Full detailed responses with justifications and rationales, however, were not completely correct for three of the questions.
DISCUSSIONS: In this study, we demonstrated the ability to build disease-specific and PHI-compliant LLMs using RAG. While our LLM, LiVersa, demonstrated more specificity in answering questions related to clinical hepatology - there were some knowledge deficiencies due to limitations set by the number and types of documents used for RAG. The LiVersa prototype, however, is a proof of concept for utilizing RAG to customize LLMs for clinical uses and a potential strategy to realize personalized medicine in the future.",0
33751621,The next-generation coronavirus diagnostic techniques with particular emphasis on the SARS-CoV-2,Hemida MG.,J Med Virol. 2021 Jul;93(7):4219-4241. doi: 10.1002/jmv.26926. Epub 2021 Mar 26.,Hemida MG,J Med Virol,2021,22-03-2021,PMC8207115,,10.1002/jmv.26926,"The potential zoonotic coronaviruses (SARS-CoV, MERS-CoV, and SARS-CoV-2) are of global health concerns. Early diagnosis is the milestone in their mitigation, control, and eradication. Many diagnostic techniques are showing great success and have many advantages, such as the rapid turnover of the results, high accuracy, and high specificity and sensitivity. However, some of these techniques have several pitfalls if samples were not collected, processed, and transported in the standard ways and if these techniques were not practiced with extreme caution and precision. This may lead to false-negative/positive results. This may affect the downstream management of the affected cases. These techniques require regular fine-tuning, upgrading, and optimization. The continuous evolution of new strains and viruses belong to the coronaviruses is hampering the success of many classical techniques. There are urgent needs for next generations of coronaviruses diagnostic assays that overcome these pitfalls. This new generation of diagnostic tests should be able to do simultaneous, multiplex, and high-throughput detection of various coronavirus in one reaction. Furthermore, the development of novel assays and techniques that enable the in situ detection of the virus on the environmental samples, especially air, water, and surfaces, should be given considerable attention in the future. These approaches will have a substantial positive impact on the mitigation and eradication of coronaviruses, including the current SARS-CoV-2 pandemic.","The next-generation coronavirus diagnostic techniques with particular emphasis on the SARS-CoV-2 The potential zoonotic coronaviruses (SARS-CoV, MERS-CoV, and SARS-CoV-2) are of global health concerns. Early diagnosis is the milestone in their mitigation, control, and eradication. Many diagnostic techniques are showing great success and have many advantages, such as the rapid turnover of the results, high accuracy, and high specificity and sensitivity. However, some of these techniques have several pitfalls if samples were not collected, processed, and transported in the standard ways and if these techniques were not practiced with extreme caution and precision. This may lead to false-negative/positive results. This may affect the downstream management of the affected cases. These techniques require regular fine-tuning, upgrading, and optimization. The continuous evolution of new strains and viruses belong to the coronaviruses is hampering the success of many classical techniques. There are urgent needs for next generations of coronaviruses diagnostic assays that overcome these pitfalls. This new generation of diagnostic tests should be able to do simultaneous, multiplex, and high-throughput detection of various coronavirus in one reaction. Furthermore, the development of novel assays and techniques that enable the in situ detection of the virus on the environmental samples, especially air, water, and surfaces, should be given considerable attention in the future. These approaches will have a substantial positive impact on the mitigation and eradication of coronaviruses, including the current SARS-CoV-2 pandemic.",0
33831536,A comparative analysis of system features used in the TREC-COVID information retrieval challenge,"Chen JS, Hersh WR.",J Biomed Inform. 2021 May;117:103745. doi: 10.1016/j.jbi.2021.103745. Epub 2021 Apr 6.,Chen JS,J Biomed Inform,2021,08-04-2021,PMC8021447,,10.1016/j.jbi.2021.103745,"The COVID-19 pandemic has resulted in a rapidly growing quantity of scientific publications from journal articles, preprints, and other sources. The TREC-COVID Challenge was created to evaluate information retrieval (IR) methods and systems for this quickly expanding corpus. Using the COVID-19 Open Research Dataset (CORD-19), several dozen research teams participated in over 5 rounds of the TREC-COVID Challenge. While previous work has compared IR techniques used on other test collections, there are no studies that have analyzed the methods used by participants in the TREC-COVID Challenge. We manually reviewed team run reports from Rounds 2 and 5, extracted features from the documented methodologies, and used a univariate and multivariate regression-based analysis to identify features associated with higher retrieval performance. We observed that fine-tuning datasets with relevance judgments, MS-MARCO, and CORD-19 document vectors was associated with improved performance in Round 2 but not in Round 5. Though the relatively decreased heterogeneity of runs in Round 5 may explain the lack of significance in that round, fine-tuning has been found to improve search performance in previous challenge evaluations by improving a system's ability to map relevant queries and phrases to documents. Furthermore, term expansion was associated with improvement in system performance, and the use of the narrative field in the TREC-COVID topics was associated with decreased system performance in both rounds. These findings emphasize the need for clear queries in search. While our study has some limitations in its generalizability and scope of techniques analyzed, we identified some IR techniques that may be useful in building search systems for COVID-19 using the TREC-COVID test collections.","A comparative analysis of system features used in the TREC-COVID information retrieval challenge The COVID-19 pandemic has resulted in a rapidly growing quantity of scientific publications from journal articles, preprints, and other sources. The TREC-COVID Challenge was created to evaluate information retrieval (IR) methods and systems for this quickly expanding corpus. Using the COVID-19 Open Research Dataset (CORD-19), several dozen research teams participated in over 5 rounds of the TREC-COVID Challenge. While previous work has compared IR techniques used on other test collections, there are no studies that have analyzed the methods used by participants in the TREC-COVID Challenge. We manually reviewed team run reports from Rounds 2 and 5, extracted features from the documented methodologies, and used a univariate and multivariate regression-based analysis to identify features associated with higher retrieval performance. We observed that fine-tuning datasets with relevance judgments, MS-MARCO, and CORD-19 document vectors was associated with improved performance in Round 2 but not in Round 5. Though the relatively decreased heterogeneity of runs in Round 5 may explain the lack of significance in that round, fine-tuning has been found to improve search performance in previous challenge evaluations by improving a system's ability to map relevant queries and phrases to documents. Furthermore, term expansion was associated with improvement in system performance, and the use of the narrative field in the TREC-COVID topics was associated with decreased system performance in both rounds. These findings emphasize the need for clear queries in search. While our study has some limitations in its generalizability and scope of techniques analyzed, we identified some IR techniques that may be useful in building search systems for COVID-19 using the TREC-COVID test collections.",0
33977022,Using data mining techniques to fight and control epidemics: A scoping review,"Safdari R, Rezayi S, Saeedi S, Tanhapour M, Gholamzadeh M.",Health Technol (Berl). 2021;11(4):759-771. doi: 10.1007/s12553-021-00553-7. Epub 2021 May 7.,Safdari R,Health Technol (Berl),2021,12-05-2021,PMC8102070,,10.1007/s12553-021-00553-7,"The main objective of this survey is to study the published articles to determine the most favorite data mining methods and gap of knowledge. Since the threat of pandemics has raised concerns for public health, data mining techniques were applied by researchers to reveal the hidden knowledge. Web of Science, Scopus, and PubMed databases were selected for systematic searches. Then, all of the retrieved articles were screened in the stepwise process according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist to select appropriate articles. All of the results were analyzed and summarized based on some classifications. Out of 335 citations were retrieved, 50 articles were determined as eligible articles through a scoping review. The review results showed that the most favorite DM belonged to Natural language processing (22%) and the most commonly proposed approach was revealing disease characteristics (22%). Regarding diseases, the most addressed disease was COVID-19. The studies show a predominance of applying supervised learning techniques (90%). Concerning healthcare scopes, we found that infectious disease (36%) to be the most frequent, closely followed by epidemiology discipline. The most common software used in the studies was SPSS (22%) and R (20%). The results revealed that some valuable researches conducted by employing the capabilities of knowledge discovery methods to understand the unknown dimensions of diseases in pandemics. But most researches will need in terms of treatment and disease control.","Using data mining techniques to fight and control epidemics: A scoping review The main objective of this survey is to study the published articles to determine the most favorite data mining methods and gap of knowledge. Since the threat of pandemics has raised concerns for public health, data mining techniques were applied by researchers to reveal the hidden knowledge. Web of Science, Scopus, and PubMed databases were selected for systematic searches. Then, all of the retrieved articles were screened in the stepwise process according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses checklist to select appropriate articles. All of the results were analyzed and summarized based on some classifications. Out of 335 citations were retrieved, 50 articles were determined as eligible articles through a scoping review. The review results showed that the most favorite DM belonged to Natural language processing (22%) and the most commonly proposed approach was revealing disease characteristics (22%). Regarding diseases, the most addressed disease was COVID-19. The studies show a predominance of applying supervised learning techniques (90%). Concerning healthcare scopes, we found that infectious disease (36%) to be the most frequent, closely followed by epidemiology discipline. The most common software used in the studies was SPSS (22%) and R (20%). The results revealed that some valuable researches conducted by employing the capabilities of knowledge discovery methods to understand the unknown dimensions of diseases in pandemics. But most researches will need in terms of treatment and disease control.",0
37683661,Amniotic Sludge and Prematurity: Systematic Review and Meta-analysis,"Pannain GD, Pereira AMG, Rocha MLTLFD, Lopes RGC.",Rev Bras Ginecol Obstet. 2023 Aug;45(8):e489-e498. doi: 10.1055/s-0043-1772189. Epub 2023 Sep 8.,Pannain GD,Rev Bras Ginecol Obstet,2023,08-09-2023,PMC10491474,,10.1055/s-0043-1772189,"OBJECTIVE:  To perform a systematic review and meta-analysis of studies on maternal, fetal, and neonatal outcomes of women with singleton pregnancies, after spontaneous conception, and with the diagnosis of amniotic sludge before 37 weeks of gestational age.
DATA SOURCES:  We conducted a search on the PubMed, Cochrane, Bireme, and Theses databases until June 2022.
SELECTION OF STUDIES: Using the keywords intra-amniotic sludge or fluid sludge or echogenic particles, we found 263 articles, 132 of which were duplicates, and 70 were discarded because they did not meet the inclusion criteria.
DATA COLLECTION:  The articles retrieved were analyzed by 2 reviewers; 61 were selected for full-text analysis, 18 were included for a qualitative analysis, and 14, for a quantitative analysis.
DATA SYNTHESIS:  Among the maternal outcomes analyzed, there was an increased risk of preterm labor (95% confidence interval [95%CI]: 1.45-2.03), premature rupture of ovular membranes (95%CI: 1.99-3.79), and clinical (95%CI: 1.41-6.19) and histological chorioamnionitis (95%CI: 1.75-3.12). Regarding the fetal outcomes, there was a significant increase in the risk of morbidity (95%CI: 1.80-3.17), mortality (95%CI: 1.14-18.57), admission to the Neonatal Intensive Care Unit (NICU; 95%CI: 1.17-1.95), and neonatal sepsis (95%CI: 2.29-7.55).
CONCLUSION:  The results of the present study indicate that the presence of amniotic sludge is a risk marker for preterm delivery. Despite the heterogeneity of the studies analyzed, even in patients with other risk factors for prematurity, such as short cervix and previous preterm delivery, the presence of amniotic sludge increases the risk of premature labor. Moreover, antibiotic therapy seems to be a treatment for amniotic sludge, and it may prolong pregnancy.","Amniotic Sludge and Prematurity: Systematic Review and Meta-analysis OBJECTIVE:  To perform a systematic review and meta-analysis of studies on maternal, fetal, and neonatal outcomes of women with singleton pregnancies, after spontaneous conception, and with the diagnosis of amniotic sludge before 37 weeks of gestational age.
DATA SOURCES:  We conducted a search on the PubMed, Cochrane, Bireme, and Theses databases until June 2022.
SELECTION OF STUDIES: Using the keywords intra-amniotic sludge or fluid sludge or echogenic particles, we found 263 articles, 132 of which were duplicates, and 70 were discarded because they did not meet the inclusion criteria.
DATA COLLECTION:  The articles retrieved were analyzed by 2 reviewers; 61 were selected for full-text analysis, 18 were included for a qualitative analysis, and 14, for a quantitative analysis.
DATA SYNTHESIS:  Among the maternal outcomes analyzed, there was an increased risk of preterm labor (95% confidence interval [95%CI]: 1.45-2.03), premature rupture of ovular membranes (95%CI: 1.99-3.79), and clinical (95%CI: 1.41-6.19) and histological chorioamnionitis (95%CI: 1.75-3.12). Regarding the fetal outcomes, there was a significant increase in the risk of morbidity (95%CI: 1.80-3.17), mortality (95%CI: 1.14-18.57), admission to the Neonatal Intensive Care Unit (NICU; 95%CI: 1.17-1.95), and neonatal sepsis (95%CI: 2.29-7.55).
CONCLUSION:  The results of the present study indicate that the presence of amniotic sludge is a risk marker for preterm delivery. Despite the heterogeneity of the studies analyzed, even in patients with other risk factors for prematurity, such as short cervix and previous preterm delivery, the presence of amniotic sludge increases the risk of premature labor. Moreover, antibiotic therapy seems to be a treatment for amniotic sludge, and it may prolong pregnancy.",0
33279995,Text mining approaches for dealing with the rapidly expanding literature on COVID-19,"Wang LL, Lo K.",Brief Bioinform. 2021 Mar 22;22(2):781-799. doi: 10.1093/bib/bbaa296.,Wang LL,Brief Bioinform,2021,06-12-2020,PMC7799291,,10.1093/bib/bbaa296,"More than 50 000 papers have been published about COVID-19 since the beginning of 2020 and several hundred new papers continue to be published every day. This incredible rate of scientific productivity leads to information overload, making it difficult for researchers, clinicians and public health officials to keep up with the latest findings. Automated text mining techniques for searching, reading and summarizing papers are helpful for addressing information overload. In this review, we describe the many resources that have been introduced to support text mining applications over the COVID-19 literature; specifically, we discuss the corpora, modeling resources, systems and shared tasks that have been introduced for COVID-19. We compile a list of 39 systems that provide functionality such as search, discovery, visualization and summarization over the COVID-19 literature. For each system, we provide a qualitative description and assessment of the system's performance, unique data or user interface features and modeling decisions. Many systems focus on search and discovery, though several systems provide novel features, such as the ability to summarize findings over multiple documents or linking between scientific articles and clinical trials. We also describe the public corpora, models and shared tasks that have been introduced to help reduce repeated effort among community members; some of these resources (especially shared tasks) can provide a basis for comparing the performance of different systems. Finally, we summarize promising results and open challenges for text mining the COVID-19 literature.","Text mining approaches for dealing with the rapidly expanding literature on COVID-19 More than 50 000 papers have been published about COVID-19 since the beginning of 2020 and several hundred new papers continue to be published every day. This incredible rate of scientific productivity leads to information overload, making it difficult for researchers, clinicians and public health officials to keep up with the latest findings. Automated text mining techniques for searching, reading and summarizing papers are helpful for addressing information overload. In this review, we describe the many resources that have been introduced to support text mining applications over the COVID-19 literature; specifically, we discuss the corpora, modeling resources, systems and shared tasks that have been introduced for COVID-19. We compile a list of 39 systems that provide functionality such as search, discovery, visualization and summarization over the COVID-19 literature. For each system, we provide a qualitative description and assessment of the system's performance, unique data or user interface features and modeling decisions. Many systems focus on search and discovery, though several systems provide novel features, such as the ability to summarize findings over multiple documents or linking between scientific articles and clinical trials. We also describe the public corpora, models and shared tasks that have been introduced to help reduce repeated effort among community members; some of these resources (especially shared tasks) can provide a basis for comparing the performance of different systems. Finally, we summarize promising results and open challenges for text mining the COVID-19 literature.",0
35430265,Text mining in mosquito-borne disease: A systematic review,"Ong SQ, Pauzi MBM, Gan KH.",Acta Trop. 2022 Jul;231:106447. doi: 10.1016/j.actatropica.2022.106447. Epub 2022 Apr 14.,Ong SQ,Acta Trop,2022,17-04-2022,PMC9663275,,10.1016/j.actatropica.2022.106447,"Mosquito-borne diseases are emerging and re-emerging across the globe, especially after the COVID19 pandemic. The recent advances in text mining in infectious diseases hold the potential of providing timely access to explicit and implicit associations among information in the text. In the past few years, the availability of online text data in the form of unstructured or semi-structured text with rich content of information from this domain enables many studies to provide solutions in this area, e.g., disease-related knowledge discovery, disease surveillance, early detection system, etc. However, a recent review of text mining in the domain of mosquito-borne disease was not available to the best of our knowledge. In this review, we survey the recent works in the text mining techniques used in combating mosquito-borne diseases. We highlight the corpus sources, technologies, applications, and the challenges faced by the studies, followed by the possible future directions that can be taken further in this domain. We present a bibliometric analysis of the 294 scientific articles that have been published in Scopus and PubMed in the domain of text mining in mosquito-borne diseases, from the year 2016 to 2021. The papers were further filtered and reviewed based on the techniques used to analyze the text related to mosquito-borne diseases. Based on the corpus of 158 selected articles, we found 27 of the articles were relevant and used text mining in mosquito-borne diseases. These articles covered the majority of Zika (38.70%), Dengue (32.26%), and Malaria (29.03%), with extremely low numbers or none of the other crucial mosquito-borne diseases like chikungunya, yellow fever, West Nile fever. Twitter was the dominant corpus resource to perform text mining in mosquito-borne diseases, followed by PubMed and LexisNexis databases. Sentiment analysis was the most popular technique of text mining to understand the discourse of the disease and followed by information extraction, which dependency relation and co-occurrence-based approach to extract relations and events. Surveillance was the main usage of most of the reviewed studies and followed by treatment, which focused on the drug-disease or symptom-disease association. The advance in text mining could improve the management of mosquito-borne diseases. However, the technique and application posed many limitations and challenges, including biases like user authentication and language, real-world implementation, etc. We discussed the future direction which can be useful to expand this area and domain. This review paper contributes mainly as a library for text mining in mosquito-borne diseases and could further explore the system for other neglected diseases.","Text mining in mosquito-borne disease: A systematic review Mosquito-borne diseases are emerging and re-emerging across the globe, especially after the COVID19 pandemic. The recent advances in text mining in infectious diseases hold the potential of providing timely access to explicit and implicit associations among information in the text. In the past few years, the availability of online text data in the form of unstructured or semi-structured text with rich content of information from this domain enables many studies to provide solutions in this area, e.g., disease-related knowledge discovery, disease surveillance, early detection system, etc. However, a recent review of text mining in the domain of mosquito-borne disease was not available to the best of our knowledge. In this review, we survey the recent works in the text mining techniques used in combating mosquito-borne diseases. We highlight the corpus sources, technologies, applications, and the challenges faced by the studies, followed by the possible future directions that can be taken further in this domain. We present a bibliometric analysis of the 294 scientific articles that have been published in Scopus and PubMed in the domain of text mining in mosquito-borne diseases, from the year 2016 to 2021. The papers were further filtered and reviewed based on the techniques used to analyze the text related to mosquito-borne diseases. Based on the corpus of 158 selected articles, we found 27 of the articles were relevant and used text mining in mosquito-borne diseases. These articles covered the majority of Zika (38.70%), Dengue (32.26%), and Malaria (29.03%), with extremely low numbers or none of the other crucial mosquito-borne diseases like chikungunya, yellow fever, West Nile fever. Twitter was the dominant corpus resource to perform text mining in mosquito-borne diseases, followed by PubMed and LexisNexis databases. Sentiment analysis was the most popular technique of text mining to understand the discourse of the disease and followed by information extraction, which dependency relation and co-occurrence-based approach to extract relations and events. Surveillance was the main usage of most of the reviewed studies and followed by treatment, which focused on the drug-disease or symptom-disease association. The advance in text mining could improve the management of mosquito-borne diseases. However, the technique and application posed many limitations and challenges, including biases like user authentication and language, real-world implementation, etc. We discussed the future direction which can be useful to expand this area and domain. This review paper contributes mainly as a library for text mining in mosquito-borne diseases and could further explore the system for other neglected diseases.",0
28052483,Natural language processing to ascertain two key variables from operative reports in ophthalmology,"Liu L, Shorstein NH, Amsden LB, Herrinton LJ.",Pharmacoepidemiol Drug Saf. 2017 Apr;26(4):378-385. doi: 10.1002/pds.4149. Epub 2017 Jan 3.,Liu L,Pharmacoepidemiol Drug Saf,2017,05-01-2017,PMC5380560,NIHMS832904,10.1002/pds.4149,"PURPOSE: Antibiotic prophylaxis is critical to ophthalmology and other surgical specialties. We performed natural language processing (NLP) of 743 838 operative notes recorded for 315 246 surgeries to ascertain two variables needed to study the comparative effectiveness of antibiotic prophylaxis in cataract surgery. The first key variable was an exposure variable, intracameral antibiotic injection. The second was an intraoperative complication, posterior capsular rupture (PCR), which functioned as a potential confounder. To help other researchers use NLP in their settings, we describe our NLP protocol and lessons learned.
METHODS: For each of the two variables, we used SAS Text Miner and other SAS text-processing modules with a training set of 10 000 (1.3%) operative notes to develop a lexicon. The lexica identified misspellings, abbreviations, and negations, and linked words into concepts (e.g. ""antibiotic"" linked with ""injection""). We confirmed the NLP tools by iteratively obtaining random samples of 2000 (0.3%) notes, with replacement.
RESULTS: The NLP tools identified approximately 60 000 intracameral antibiotic injections and 3500 cases of PCR. The positive and negative predictive values for intracameral antibiotic injection exceeded 99%. For the intraoperative complication, they exceeded 94%.
CONCLUSION: NLP was a valid and feasible method for obtaining critical variables needed for a research study of surgical safety. These NLP tools were intended for use in the study sample. Use with external datasets or future datasets in our own setting would require further testing. Copyright © 2017 John Wiley & Sons, Ltd.","Natural language processing to ascertain two key variables from operative reports in ophthalmology PURPOSE: Antibiotic prophylaxis is critical to ophthalmology and other surgical specialties. We performed natural language processing (NLP) of 743 838 operative notes recorded for 315 246 surgeries to ascertain two variables needed to study the comparative effectiveness of antibiotic prophylaxis in cataract surgery. The first key variable was an exposure variable, intracameral antibiotic injection. The second was an intraoperative complication, posterior capsular rupture (PCR), which functioned as a potential confounder. To help other researchers use NLP in their settings, we describe our NLP protocol and lessons learned.
METHODS: For each of the two variables, we used SAS Text Miner and other SAS text-processing modules with a training set of 10 000 (1.3%) operative notes to develop a lexicon. The lexica identified misspellings, abbreviations, and negations, and linked words into concepts (e.g. ""antibiotic"" linked with ""injection""). We confirmed the NLP tools by iteratively obtaining random samples of 2000 (0.3%) notes, with replacement.
RESULTS: The NLP tools identified approximately 60 000 intracameral antibiotic injections and 3500 cases of PCR. The positive and negative predictive values for intracameral antibiotic injection exceeded 99%. For the intraoperative complication, they exceeded 94%.
CONCLUSION: NLP was a valid and feasible method for obtaining critical variables needed for a research study of surgical safety. These NLP tools were intended for use in the study sample. Use with external datasets or future datasets in our own setting would require further testing. Copyright © 2017 John Wiley & Sons, Ltd.",0
32694268,Artificial intelligence in ophthalmology during COVID-19 and in the post COVID-19 era,"Hallak JA, Scanzera AC, Azar DT, Chan RVP.",Curr Opin Ophthalmol. 2020 Sep;31(5):447-453. doi: 10.1097/ICU.0000000000000685.,Hallak JA,Curr Opin Ophthalmol,2020,23-07-2020,PMC8516074,NIHMS1744118,10.1097/ICU.0000000000000685,"PURPOSE OF REVIEW: To highlight artificial intelligence applications in ophthalmology during the COVID-19 pandemic that can be used to: describe ocular findings and changes correlated with COVID-19; extract information from scholarly articles on SARS-CoV-2 and COVID-19 specific to ophthalmology; and implement efficient patient triage and telemedicine care.
RECENT FINDINGS: Ophthalmology has been leading in artificial intelligence and technology applications. With medical imaging analysis, pixel-annotated distinguishable features on COVID-19 patients may help with noninvasive diagnosis and severity outcome predictions. Using natural language processing (NLP) and data integration methods, topic modeling on more than 200 ophthalmology-related articles on COVID-19 can summarize ocular manifestations, viral transmission, treatment strategies, and patient care and practice management. Artificial intelligence for telemedicine applications can address the high demand, prioritize and triage patients, as well as improve at home-monitoring devices and secure data transfers.
SUMMARY: COVID-19 is significantly impacting the way we are delivering healthcare. Given the already successful implementation of artificial intelligence applications and telemedicine in ophthalmology, we expect that these systems will be embraced more as tools for research, education, and patient care.","Artificial intelligence in ophthalmology during COVID-19 and in the post COVID-19 era PURPOSE OF REVIEW: To highlight artificial intelligence applications in ophthalmology during the COVID-19 pandemic that can be used to: describe ocular findings and changes correlated with COVID-19; extract information from scholarly articles on SARS-CoV-2 and COVID-19 specific to ophthalmology; and implement efficient patient triage and telemedicine care.
RECENT FINDINGS: Ophthalmology has been leading in artificial intelligence and technology applications. With medical imaging analysis, pixel-annotated distinguishable features on COVID-19 patients may help with noninvasive diagnosis and severity outcome predictions. Using natural language processing (NLP) and data integration methods, topic modeling on more than 200 ophthalmology-related articles on COVID-19 can summarize ocular manifestations, viral transmission, treatment strategies, and patient care and practice management. Artificial intelligence for telemedicine applications can address the high demand, prioritize and triage patients, as well as improve at home-monitoring devices and secure data transfers.
SUMMARY: COVID-19 is significantly impacting the way we are delivering healthcare. Given the already successful implementation of artificial intelligence applications and telemedicine in ophthalmology, we expect that these systems will be embraced more as tools for research, education, and patient care.",0
38055548,Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection,"Silva RPD, Pollettini JT, Pazin Filho A.",Cad Saude Publica. 2023 Dec 4;39(11):e00243722. doi: 10.1590/0102-311XPT243722. eCollection 2023.,Silva RPD,Cad Saude Publica,2023,06-12-2023,PMC10695477,,10.1590/0102-311XPT243722,"Patients with post-COVID-19 syndrome benefit from health promotion programs. Their rapid identification is important for the cost-effective use of these programs. Traditional identification techniques perform poorly especially in pandemics. A descriptive observational study was carried out using 105,008 prior authorizations paid by a private health care provider with the application of an unsupervised natural language processing method by topic modeling to identify patients suspected of being infected by COVID-19. A total of 6 models were generated: 3 using the BERTopic algorithm and 3 Word2Vec models. The BERTopic model automatically creates disease groups. In the Word2Vec model, manual analysis of the first 100 cases of each topic was necessary to define the topics related to COVID-19. The BERTopic model with more than 1,000 authorizations per topic without word treatment selected more severe patients - average cost per prior authorizations paid of BRL 10,206 and total expenditure of BRL 20.3 million (5.4%) in 1,987 prior authorizations (1.9%). It had 70% accuracy compared to human analysis and 20% of cases with potential interest, all subject to analysis for inclusion in a health promotion program. It had an important loss of cases when compared to the traditional research model with structured language and identified other groups of diseases - orthopedic, mental and cancer. The BERTopic model served as an exploratory method to be used in case labeling and subsequent application in supervised models. The automatic identification of other diseases raises ethical questions about the treatment of health information by machine learning.","Unsupervised natural language processing in the identification of patients with suspected COVID-19 infection Patients with post-COVID-19 syndrome benefit from health promotion programs. Their rapid identification is important for the cost-effective use of these programs. Traditional identification techniques perform poorly especially in pandemics. A descriptive observational study was carried out using 105,008 prior authorizations paid by a private health care provider with the application of an unsupervised natural language processing method by topic modeling to identify patients suspected of being infected by COVID-19. A total of 6 models were generated: 3 using the BERTopic algorithm and 3 Word2Vec models. The BERTopic model automatically creates disease groups. In the Word2Vec model, manual analysis of the first 100 cases of each topic was necessary to define the topics related to COVID-19. The BERTopic model with more than 1,000 authorizations per topic without word treatment selected more severe patients - average cost per prior authorizations paid of BRL 10,206 and total expenditure of BRL 20.3 million (5.4%) in 1,987 prior authorizations (1.9%). It had 70% accuracy compared to human analysis and 20% of cases with potential interest, all subject to analysis for inclusion in a health promotion program. It had an important loss of cases when compared to the traditional research model with structured language and identified other groups of diseases - orthopedic, mental and cancer. The BERTopic model served as an exploratory method to be used in case labeling and subsequent application in supervised models. The automatic identification of other diseases raises ethical questions about the treatment of health information by machine learning.",0
32521776,Studies of Novel Coronavirus Disease 19 (COVID-19) Pandemic: A Global Analysis of Literature,"Tran BX, Ha GH, Nguyen LH, Vu GT, Hoang MT, Le HT, Latkin CA, Ho CSH, Ho RCM.",Int J Environ Res Public Health. 2020 Jun 8;17(11):4095. doi: 10.3390/ijerph17114095.,Tran BX,Int J Environ Res Public Health,2020,12-06-2020,PMC7312200,,10.3390/ijerph17114095,"Novel coronavirus disease 19 (COVID-19) is a global threat to millions of lives. Enormous efforts in knowledge production have been made in the last few months, requiring a comprehensive analysis to examine the research gaps and to help guide an agenda for further studies. This study aims to explore the current research foci and their country variations regarding levels of income and COVID-19 transmission features. This textual analysis of 5780 publications extracted from the Web of Science, Medline, and Scopus databases was performed to explore the current research foci and propose further research agenda. The Latent Dirichlet allocation was used for topic modeling. Regression analysis was conducted to examine country variations in the research foci. Results indicate that publications are mainly contributed by the United States, China, and European countries. Guidelines for emergency care and surgical, viral pathogenesis, and global responses in the COVID-19 pandemic are the most common topics. There is variation in the research approaches to mitigate COVID-19 problems in countries with different income and transmission levels. Findings highlighted the need for global research collaborations among high- and low/middle-income countries in the different stages of pandemic prevention and control.","Studies of Novel Coronavirus Disease 19 (COVID-19) Pandemic: A Global Analysis of Literature Novel coronavirus disease 19 (COVID-19) is a global threat to millions of lives. Enormous efforts in knowledge production have been made in the last few months, requiring a comprehensive analysis to examine the research gaps and to help guide an agenda for further studies. This study aims to explore the current research foci and their country variations regarding levels of income and COVID-19 transmission features. This textual analysis of 5780 publications extracted from the Web of Science, Medline, and Scopus databases was performed to explore the current research foci and propose further research agenda. The Latent Dirichlet allocation was used for topic modeling. Regression analysis was conducted to examine country variations in the research foci. Results indicate that publications are mainly contributed by the United States, China, and European countries. Guidelines for emergency care and surgical, viral pathogenesis, and global responses in the COVID-19 pandemic are the most common topics. There is variation in the research approaches to mitigate COVID-19 problems in countries with different income and transmission levels. Findings highlighted the need for global research collaborations among high- and low/middle-income countries in the different stages of pandemic prevention and control.",0
26379035,Environmental and Behavioural Determinants of Leptospirosis Transmission: A Systematic Review,"Mwachui MA, Crump L, Hartskeerl R, Zinsstag J, Hattendorf J.",PLoS Negl Trop Dis. 2015 Sep 17;9(9):e0003843. doi: 10.1371/journal.pntd.0003843. eCollection 2015.,Mwachui MA,PLoS Negl Trop Dis,2015,18-09-2015,PMC4574979,,10.1371/journal.pntd.0003843,"BACKGROUND: Leptospirosis is one of the most widespread zoonotic diseases, which is of global medical and veterinary importance, and also a re-emerging infectious disease. The main tracks of transmission are known; however, the relative importance of each of the components and the respective environmental risk factors are unclear. We aimed to assess and specify quantitative evidence of environmental risks of leptospirosis transmission.
METHODS/FINDINGS: A database of pre-selected studies, with publication dates from 1970 until 2008, was provided by an expert group. The database has been updated until 2015 using a text mining algorithm. Study selection was based on stringent quality criteria. A descriptive data analysis was performed to calculate the medians of the log transformed odds ratios. From a selection of 2723 unique publications containing information on leptospirosis, 428 papers dealing with risk factors were identified. Of these, 53 fulfilled the quality criteria, allowing us to identify trends in different geo-climatic regions. Water associated exposures were, with few exceptions, associated with an increased leptospirosis risk. In resource poor countries, floods and rainfall were of particular importance, whereas recreational water activities were more relevant in developed countries. Rodents were associated with increased leptospirosis risk, but the variation among studies was high, which might be partly explained by differences in exposure definition. Livestock contact was commonly associated with increased risk; however, several studies found no association. The median odds ratios associated with dog and cat contacts were close to unity. Sanitation and behavioural risk factors were almost always strongly associated with leptospirosis, although their impact was rarely investigated in Europe or North America.
CONCLUSION: This review confirms the complex environmental transmission pathways of leptospirosis, as previously established. Although, floods appeared to be among the most important drivers on islands and in Asia, the consistent pattern observed for exposure to rodents and behavioural and sanitation related risk factors indicate potential areas for intervention.","Environmental and Behavioural Determinants of Leptospirosis Transmission: A Systematic Review BACKGROUND: Leptospirosis is one of the most widespread zoonotic diseases, which is of global medical and veterinary importance, and also a re-emerging infectious disease. The main tracks of transmission are known; however, the relative importance of each of the components and the respective environmental risk factors are unclear. We aimed to assess and specify quantitative evidence of environmental risks of leptospirosis transmission.
METHODS/FINDINGS: A database of pre-selected studies, with publication dates from 1970 until 2008, was provided by an expert group. The database has been updated until 2015 using a text mining algorithm. Study selection was based on stringent quality criteria. A descriptive data analysis was performed to calculate the medians of the log transformed odds ratios. From a selection of 2723 unique publications containing information on leptospirosis, 428 papers dealing with risk factors were identified. Of these, 53 fulfilled the quality criteria, allowing us to identify trends in different geo-climatic regions. Water associated exposures were, with few exceptions, associated with an increased leptospirosis risk. In resource poor countries, floods and rainfall were of particular importance, whereas recreational water activities were more relevant in developed countries. Rodents were associated with increased leptospirosis risk, but the variation among studies was high, which might be partly explained by differences in exposure definition. Livestock contact was commonly associated with increased risk; however, several studies found no association. The median odds ratios associated with dog and cat contacts were close to unity. Sanitation and behavioural risk factors were almost always strongly associated with leptospirosis, although their impact was rarely investigated in Europe or North America.
CONCLUSION: This review confirms the complex environmental transmission pathways of leptospirosis, as previously established. Although, floods appeared to be among the most important drivers on islands and in Asia, the consistent pattern observed for exposure to rodents and behavioural and sanitation related risk factors indicate potential areas for intervention.",0
33489245,The prevalence of mental health problems in sub-Saharan adolescents living with HIV: a systematic review,"Dessauvagie AS, Jörns-Presentati A, Napp AK, Stein DJ, Jonker D, Breet E, Charles W, Swart RL, Lahti M, Suliman S, Jansen R, van den Heuvel LL, Seedat S, Groen G.",Glob Ment Health (Camb). 2020 Oct 26;7:e29. doi: 10.1017/gmh.2020.18. eCollection 2020.,Dessauvagie AS,Glob Ment Health (Camb),2020,25-01-2021,PMC7786273,,10.1017/gmh.2020.18,"Despite the progress made in HIV treatment and prevention, HIV remains a major cause of adolescent morbidity and mortality in sub-Saharan Africa. As perinatally infected children increasingly survive into adulthood, the quality of life and mental health of this population has increased in importance. This review provides a synthesis of the prevalence of mental health problems in this population and explores associated factors. A systematic database search (Medline, PsycINFO, Scopus) with an additional hand search was conducted. Peer-reviewed studies on adolescents (aged 10-19), published between 2008 and 2019, assessing mental health symptoms or psychiatric disorders, either by standardized questionnaires or by diagnostic interviews, were included. The search identified 1461 articles, of which 301 were eligible for full-text analysis. Fourteen of these, concerning HIV-positive adolescents, met the inclusion criteria and were critically appraised. Mental health problems were highly prevalent among this group, with around 25% scoring positive for any psychiatric disorder and 30-50% showing emotional or behavioral difficulties or significant psychological distress. Associated factors found by regression analysis were older age, not being in school, impaired family functioning, HIV-related stigma and bullying, and poverty. Social support and parental competence were protective factors. Mental health problems among HIV-positive adolescents are highly prevalent and should be addressed as part of regular HIV care.","The prevalence of mental health problems in sub-Saharan adolescents living with HIV: a systematic review Despite the progress made in HIV treatment and prevention, HIV remains a major cause of adolescent morbidity and mortality in sub-Saharan Africa. As perinatally infected children increasingly survive into adulthood, the quality of life and mental health of this population has increased in importance. This review provides a synthesis of the prevalence of mental health problems in this population and explores associated factors. A systematic database search (Medline, PsycINFO, Scopus) with an additional hand search was conducted. Peer-reviewed studies on adolescents (aged 10-19), published between 2008 and 2019, assessing mental health symptoms or psychiatric disorders, either by standardized questionnaires or by diagnostic interviews, were included. The search identified 1461 articles, of which 301 were eligible for full-text analysis. Fourteen of these, concerning HIV-positive adolescents, met the inclusion criteria and were critically appraised. Mental health problems were highly prevalent among this group, with around 25% scoring positive for any psychiatric disorder and 30-50% showing emotional or behavioral difficulties or significant psychological distress. Associated factors found by regression analysis were older age, not being in school, impaired family functioning, HIV-related stigma and bullying, and poverty. Social support and parental competence were protective factors. Mental health problems among HIV-positive adolescents are highly prevalent and should be addressed as part of regular HIV care.",0
32936777,Natural Language Processing Reveals Vulnerable Mental Health Support Groups and Heightened Health Anxiety on Reddit During COVID-19: Observational Study,"Low DM, Rumker L, Talkar T, Torous J, Cecchi G, Ghosh SS.",J Med Internet Res. 2020 Oct 12;22(10):e22635. doi: 10.2196/22635.,Low DM,J Med Internet Res,2020,16-09-2020,PMC7575341,,10.2196/22635,"BACKGROUND: The COVID-19 pandemic is impacting mental health, but it is not clear how people with different types of mental health problems were differentially impacted as the initial wave of cases hit.
OBJECTIVE: The aim of this study is to leverage natural language processing (NLP) with the goal of characterizing changes in 15 of the world's largest mental health support groups (eg, r/schizophrenia, r/SuicideWatch, r/Depression) found on the website Reddit, along with 11 non-mental health groups (eg, r/PersonalFinance, r/conspiracy) during the initial stage of the pandemic.
METHODS: We created and released the Reddit Mental Health Dataset including posts from 826,961 unique users from 2018 to 2020. Using regression, we analyzed trends from 90 text-derived features such as sentiment analysis, personal pronouns, and semantic categories. Using supervised machine learning, we classified posts into their respective support groups and interpreted important features to understand how different problems manifest in language. We applied unsupervised methods such as topic modeling and unsupervised clustering to uncover concerns throughout Reddit before and during the pandemic.
RESULTS: We found that the r/HealthAnxiety forum showed spikes in posts about COVID-19 early on in January, approximately 2 months before other support groups started posting about the pandemic. There were many features that significantly increased during COVID-19 for specific groups including the categories ""economic stress,"" ""isolation,"" and ""home,"" while others such as ""motion"" significantly decreased. We found that support groups related to attention-deficit/hyperactivity disorder, eating disorders, and anxiety showed the most negative semantic change during the pandemic out of all mental health groups. Health anxiety emerged as a general theme across Reddit through independent supervised and unsupervised machine learning analyses. For instance, we provide evidence that the concerns of a diverse set of individuals are converging in this unique moment of history; we discovered that the more users posted about COVID-19, the more linguistically similar (less distant) the mental health support groups became to r/HealthAnxiety (ρ=-0.96, P<.001). Using unsupervised clustering, we found the suicidality and loneliness clusters more than doubled in the number of posts during the pandemic. Specifically, the support groups for borderline personality disorder and posttraumatic stress disorder became significantly associated with the suicidality cluster. Furthermore, clusters surrounding self-harm and entertainment emerged.
CONCLUSIONS: By using a broad set of NLP techniques and analyzing a baseline of prepandemic posts, we uncovered patterns of how specific mental health problems manifest in language, identified at-risk users, and revealed the distribution of concerns across Reddit, which could help provide better resources to its millions of users. We then demonstrated that textual analysis is sensitive to uncover mental health complaints as they appear in real time, identifying vulnerable groups and alarming themes during COVID-19, and thus may have utility during the ongoing pandemic and other world-changing events such as elections and protests.","Natural Language Processing Reveals Vulnerable Mental Health Support Groups and Heightened Health Anxiety on Reddit During COVID-19: Observational Study BACKGROUND: The COVID-19 pandemic is impacting mental health, but it is not clear how people with different types of mental health problems were differentially impacted as the initial wave of cases hit.
OBJECTIVE: The aim of this study is to leverage natural language processing (NLP) with the goal of characterizing changes in 15 of the world's largest mental health support groups (eg, r/schizophrenia, r/SuicideWatch, r/Depression) found on the website Reddit, along with 11 non-mental health groups (eg, r/PersonalFinance, r/conspiracy) during the initial stage of the pandemic.
METHODS: We created and released the Reddit Mental Health Dataset including posts from 826,961 unique users from 2018 to 2020. Using regression, we analyzed trends from 90 text-derived features such as sentiment analysis, personal pronouns, and semantic categories. Using supervised machine learning, we classified posts into their respective support groups and interpreted important features to understand how different problems manifest in language. We applied unsupervised methods such as topic modeling and unsupervised clustering to uncover concerns throughout Reddit before and during the pandemic.
RESULTS: We found that the r/HealthAnxiety forum showed spikes in posts about COVID-19 early on in January, approximately 2 months before other support groups started posting about the pandemic. There were many features that significantly increased during COVID-19 for specific groups including the categories ""economic stress,"" ""isolation,"" and ""home,"" while others such as ""motion"" significantly decreased. We found that support groups related to attention-deficit/hyperactivity disorder, eating disorders, and anxiety showed the most negative semantic change during the pandemic out of all mental health groups. Health anxiety emerged as a general theme across Reddit through independent supervised and unsupervised machine learning analyses. For instance, we provide evidence that the concerns of a diverse set of individuals are converging in this unique moment of history; we discovered that the more users posted about COVID-19, the more linguistically similar (less distant) the mental health support groups became to r/HealthAnxiety (ρ=-0.96, P<.001). Using unsupervised clustering, we found the suicidality and loneliness clusters more than doubled in the number of posts during the pandemic. Specifically, the support groups for borderline personality disorder and posttraumatic stress disorder became significantly associated with the suicidality cluster. Furthermore, clusters surrounding self-harm and entertainment emerged.
CONCLUSIONS: By using a broad set of NLP techniques and analyzing a baseline of prepandemic posts, we uncovered patterns of how specific mental health problems manifest in language, identified at-risk users, and revealed the distribution of concerns across Reddit, which could help provide better resources to its millions of users. We then demonstrated that textual analysis is sensitive to uncover mental health complaints as they appear in real time, identifying vulnerable groups and alarming themes during COVID-19, and thus may have utility during the ongoing pandemic and other world-changing events such as elections and protests.",0
37533519,Sentiment analysis of epidemiological surveillance reports on COVID-19 in Greece using machine learning models,"Stefanis C, Giorgi E, Kalentzis K, Tselemponis A, Nena E, Tsigalou C, Kontogiorgis C, Kourkoutas Y, Chatzak E, Dokas I, Constantinidis T, Bezirtzoglou E.",Front Public Health. 2023 Jul 18;11:1191730. doi: 10.3389/fpubh.2023.1191730. eCollection 2023.,Stefanis C,Front Public Health,2023,03-08-2023,PMC10392838,,10.3389/fpubh.2023.1191730,"The present research deals with sentiment analysis performed with Microsoft Azure Machine Learning Studio to classify Facebook posts on the Greek National Public Health Organization (EODY) from November 2021 to January 2022 during the pandemic. Positive, negative and neutral sentiments were included after processing 300 reviews. This approach involved analyzing the words appearing in the comments and exploring the sentiments related to daily surveillance reports of COVID-19 published on the EODY Facebook page. Moreover, machine learning algorithms were implemented to predict the classification of sentiments. This research assesses the efficiency of a few popular machine learning models, which is one of the initial efforts in Greece in this domain. People have negative sentiments toward COVID surveillance reports. Words with the highest frequency of occurrence include government, vaccinated people, unvaccinated, telephone communication, health measures, virus, COVID-19 rapid/molecular tests, and of course, COVID-19. The experimental results disclose additionally that two classifiers, namely two class Neural Network and two class Bayes Point Machine, achieved high sentiment analysis accuracy and F1 score, particularly 87% and over 35%. A significant limitation of this study may be the need for more comparison with other research attempts that identified the sentiments of the EODY surveillance reports of COVID in Greece. Machine learning models can provide critical information combating public health hazards and enrich communication strategies and proactive actions in public health issues and opinion management during the COVID-19 pandemic.","Sentiment analysis of epidemiological surveillance reports on COVID-19 in Greece using machine learning models The present research deals with sentiment analysis performed with Microsoft Azure Machine Learning Studio to classify Facebook posts on the Greek National Public Health Organization (EODY) from November 2021 to January 2022 during the pandemic. Positive, negative and neutral sentiments were included after processing 300 reviews. This approach involved analyzing the words appearing in the comments and exploring the sentiments related to daily surveillance reports of COVID-19 published on the EODY Facebook page. Moreover, machine learning algorithms were implemented to predict the classification of sentiments. This research assesses the efficiency of a few popular machine learning models, which is one of the initial efforts in Greece in this domain. People have negative sentiments toward COVID surveillance reports. Words with the highest frequency of occurrence include government, vaccinated people, unvaccinated, telephone communication, health measures, virus, COVID-19 rapid/molecular tests, and of course, COVID-19. The experimental results disclose additionally that two classifiers, namely two class Neural Network and two class Bayes Point Machine, achieved high sentiment analysis accuracy and F1 score, particularly 87% and over 35%. A significant limitation of this study may be the need for more comparison with other research attempts that identified the sentiments of the EODY surveillance reports of COVID in Greece. Machine learning models can provide critical information combating public health hazards and enrich communication strategies and proactive actions in public health issues and opinion management during the COVID-19 pandemic.",0
38296310,Prevalence and clinical characteristics of patients with rheumatoid arthritis with interstitial lung disease using unstructured healthcare data and machine learning,"Román Ivorra JA, Trallero-Araguas E, Lopez Lasanta M, Cebrián L, Lojo L, López-Muñíz B, Fernández-Melon J, Núñez B, Silva-Fernández L, Veiga Cabello R, Ahijado P, De la Morena Barrio I, Costas Torrijo N, Safont B, Ornilla E, Restrepo J, Campo A, Andreu JL, Díez E, López Robles A, Bollo E, Benavent D, Vilanova D, Luján Valdés S, Castellanos-Moreira R.",RMD Open. 2024 Jan 30;10(1):e003353. doi: 10.1136/rmdopen-2023-003353.,Román Ivorra JA,RMD Open,2024,31-01-2024,PMC10836356,,10.1136/rmdopen-2023-003353,"OBJECTIVES: Real-world data regarding rheumatoid arthritis (RA) and its association with interstitial lung disease (ILD) is still scarce. This study aimed to estimate the prevalence of RA and ILD in patients with RA (RAILD) in Spain, and to compare clinical characteristics of patients with RA with and without ILD using natural language processing (NLP) on electronic health records (EHR).
METHODS: Observational case-control, retrospective and multicentre study based on the secondary use of unstructured clinical data from patients with adult RA and RAILD from nine hospitals between 2014 and 2019. NLP was used to extract unstructured clinical information from EHR and standardise it into a SNOMED-CT terminology. Prevalence of RA and RAILD were calculated, and a descriptive analysis was performed. Characteristics between patients with RAILD and RA patients without ILD (RAnonILD) were compared.
RESULTS: From a source population of 3 176 165 patients and 64 241 683 EHRs, 13 958 patients with RA were identified. Of those, 5.1% patients additionally had ILD (RAILD). The overall age-adjusted prevalence of RA and RAILD were 0.53% and 0.02%, respectively. The most common ILD subtype was usual interstitial pneumonia (29.3%). When comparing RAILD versus RAnonILD patients, RAILD patients were older and had more comorbidities, notably concerning infections (33.6% vs 16.5%, p<0.001), malignancies (15.9% vs 8.5%, p<0.001) and cardiovascular disease (25.8% vs 13.9%, p<0.001) than RAnonILD. RAILD patients also had higher inflammatory burden reflected in more pharmacological prescriptions and higher inflammatory parameters and presented a higher in-hospital mortality with a higher risk of death (HR 2.32; 95% CI 1.59 to 2.81, p<0.001).
CONCLUSIONS: We found an estimated age-adjusted prevalence of RA and RAILD by analysing real-world data through NLP. RAILD patients were more vulnerable at the time of inclusion with higher comorbidity and inflammatory burden than RAnonILD, which correlated with higher mortality.","Prevalence and clinical characteristics of patients with rheumatoid arthritis with interstitial lung disease using unstructured healthcare data and machine learning OBJECTIVES: Real-world data regarding rheumatoid arthritis (RA) and its association with interstitial lung disease (ILD) is still scarce. This study aimed to estimate the prevalence of RA and ILD in patients with RA (RAILD) in Spain, and to compare clinical characteristics of patients with RA with and without ILD using natural language processing (NLP) on electronic health records (EHR).
METHODS: Observational case-control, retrospective and multicentre study based on the secondary use of unstructured clinical data from patients with adult RA and RAILD from nine hospitals between 2014 and 2019. NLP was used to extract unstructured clinical information from EHR and standardise it into a SNOMED-CT terminology. Prevalence of RA and RAILD were calculated, and a descriptive analysis was performed. Characteristics between patients with RAILD and RA patients without ILD (RAnonILD) were compared.
RESULTS: From a source population of 3 176 165 patients and 64 241 683 EHRs, 13 958 patients with RA were identified. Of those, 5.1% patients additionally had ILD (RAILD). The overall age-adjusted prevalence of RA and RAILD were 0.53% and 0.02%, respectively. The most common ILD subtype was usual interstitial pneumonia (29.3%). When comparing RAILD versus RAnonILD patients, RAILD patients were older and had more comorbidities, notably concerning infections (33.6% vs 16.5%, p<0.001), malignancies (15.9% vs 8.5%, p<0.001) and cardiovascular disease (25.8% vs 13.9%, p<0.001) than RAnonILD. RAILD patients also had higher inflammatory burden reflected in more pharmacological prescriptions and higher inflammatory parameters and presented a higher in-hospital mortality with a higher risk of death (HR 2.32; 95% CI 1.59 to 2.81, p<0.001).
CONCLUSIONS: We found an estimated age-adjusted prevalence of RA and RAILD by analysing real-world data through NLP. RAILD patients were more vulnerable at the time of inclusion with higher comorbidity and inflammatory burden than RAnonILD, which correlated with higher mortality.",0
27515422,Human herpes viruses in burn patients: A systematic review,"Wurzer P, Guillory A, Parvizi D, Clayton RP, Branski LK, Kamolz LP, Finnerty CC, Herndon DN, Lee JO.",Burns. 2017 Feb;43(1):25-33. doi: 10.1016/j.burns.2016.02.003. Epub 2016 Aug 8.,Wurzer P,Burns,2017,13-08-2016,PMC5239736,NIHMS759013,10.1016/j.burns.2016.02.003,"OBJECTIVE: The contribution of human herpes viruses, including herpes simplex virus (HSV), cytomegalovirus (CMV), and varicella zoster virus (VZV) to morbidity and mortality after burns remains controversial. This systematic review was undertaken to assess evidence of herpes virus-related morbidity and mortality in burns.
MATERIALS AND METHODS: PubMed, Ovid, and Web of Science were searched to identify studies of HSV, CMV, or VZV infections in burn patients. Exclusion criteria included: A level of evidence (LoE) of IV or V; nonhuman in vivo studies; and non-English articles. There was no limitation by publication date.
RESULTS: Fifty articles were subjected to full-text analysis. Of these, 18 had LoE between I-III and were included in the final review (2 LoE I, 16 LoE II-III). Eight had a prospective study design, 9 had a retrospective study design, and 1 included both.
CONCLUSIONS: No direct evidence linked CMV and HSV infection with increased morbidity and mortality in burns. Following burn, CMV reactivation was more common than a primary CMV infection. Active HSV infection impaired wound healing but was not directly correlated to mortality. Infections with VZV are rare after burns but when they occur, VZV infections were associated with severe complications including mortality. The therapeutic effect of antiviral agents administered after burns warrants investigation via prospective randomized controlled trials.","Human herpes viruses in burn patients: A systematic review OBJECTIVE: The contribution of human herpes viruses, including herpes simplex virus (HSV), cytomegalovirus (CMV), and varicella zoster virus (VZV) to morbidity and mortality after burns remains controversial. This systematic review was undertaken to assess evidence of herpes virus-related morbidity and mortality in burns.
MATERIALS AND METHODS: PubMed, Ovid, and Web of Science were searched to identify studies of HSV, CMV, or VZV infections in burn patients. Exclusion criteria included: A level of evidence (LoE) of IV or V; nonhuman in vivo studies; and non-English articles. There was no limitation by publication date.
RESULTS: Fifty articles were subjected to full-text analysis. Of these, 18 had LoE between I-III and were included in the final review (2 LoE I, 16 LoE II-III). Eight had a prospective study design, 9 had a retrospective study design, and 1 included both.
CONCLUSIONS: No direct evidence linked CMV and HSV infection with increased morbidity and mortality in burns. Following burn, CMV reactivation was more common than a primary CMV infection. Active HSV infection impaired wound healing but was not directly correlated to mortality. Infections with VZV are rare after burns but when they occur, VZV infections were associated with severe complications including mortality. The therapeutic effect of antiviral agents administered after burns warrants investigation via prospective randomized controlled trials.",0
33737920,"Applications of Machine Learning in Human Microbiome Studies: A Review on Feature Selection, Biomarker Identification, Disease Prediction and Treatment","Marcos-Zambrano LJ, Karaduzovic-Hadziabdic K, Loncar Turukalo T, Przymus P, Trajkovik V, Aasmets O, Berland M, Gruca A, Hasic J, Hron K, Klammsteiner T, Kolev M, Lahti L, Lopes MB, Moreno V, Naskinova I, Org E, Paciência I, Papoutsoglou G, Shigdel R, Stres B, Vilne B, Yousef M, Zdravevski E, Tsamardinos I, Carrillo de Santa Pau E, Claesson MJ, Moreno-Indias I, Truu J.",Front Microbiol. 2021 Feb 19;12:634511. doi: 10.3389/fmicb.2021.634511. eCollection 2021.,Marcos-Zambrano LJ,Front Microbiol,2021,19-03-2021,PMC7962872,,10.3389/fmicb.2021.634511,"The number of microbiome-related studies has notably increased the availability of data on human microbiome composition and function. These studies provide the essential material to deeply explore host-microbiome associations and their relation to the development and progression of various complex diseases. Improved data-analytical tools are needed to exploit all information from these biological datasets, taking into account the peculiarities of microbiome data, i.e., compositional, heterogeneous and sparse nature of these datasets. The possibility of predicting host-phenotypes based on taxonomy-informed feature selection to establish an association between microbiome and predict disease states is beneficial for personalized medicine. In this regard, machine learning (ML) provides new insights into the development of models that can be used to predict outputs, such as classification and prediction in microbiology, infer host phenotypes to predict diseases and use microbial communities to stratify patients by their characterization of state-specific microbial signatures. Here we review the state-of-the-art ML methods and respective software applied in human microbiome studies, performed as part of the COST Action ML4Microbiome activities. This scoping review focuses on the application of ML in microbiome studies related to association and clinical use for diagnostics, prognostics, and therapeutics. Although the data presented here is more related to the bacterial community, many algorithms could be applied in general, regardless of the feature type. This literature and software review covering this broad topic is aligned with the scoping review methodology. The manual identification of data sources has been complemented with: (1) automated publication search through digital libraries of the three major publishers using natural language processing (NLP) Toolkit, and (2) an automated identification of relevant software repositories on GitHub and ranking of the related research papers relying on learning to rank approach.","Applications of Machine Learning in Human Microbiome Studies: A Review on Feature Selection, Biomarker Identification, Disease Prediction and Treatment The number of microbiome-related studies has notably increased the availability of data on human microbiome composition and function. These studies provide the essential material to deeply explore host-microbiome associations and their relation to the development and progression of various complex diseases. Improved data-analytical tools are needed to exploit all information from these biological datasets, taking into account the peculiarities of microbiome data, i.e., compositional, heterogeneous and sparse nature of these datasets. The possibility of predicting host-phenotypes based on taxonomy-informed feature selection to establish an association between microbiome and predict disease states is beneficial for personalized medicine. In this regard, machine learning (ML) provides new insights into the development of models that can be used to predict outputs, such as classification and prediction in microbiology, infer host phenotypes to predict diseases and use microbial communities to stratify patients by their characterization of state-specific microbial signatures. Here we review the state-of-the-art ML methods and respective software applied in human microbiome studies, performed as part of the COST Action ML4Microbiome activities. This scoping review focuses on the application of ML in microbiome studies related to association and clinical use for diagnostics, prognostics, and therapeutics. Although the data presented here is more related to the bacterial community, many algorithms could be applied in general, regardless of the feature type. This literature and software review covering this broad topic is aligned with the scoping review methodology. The manual identification of data sources has been complemented with: (1) automated publication search through digital libraries of the three major publishers using natural language processing (NLP) Toolkit, and (2) an automated identification of relevant software repositories on GitHub and ranking of the related research papers relying on learning to rank approach.",0
34127492,Ascertaining Framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre Atherosclerosis Risk in Communities (ARIC) validation study,"Moore CR, Jain S, Haas S, Yadav H, Whitsel E, Rosamand W, Heiss G, Kucharska-Newton AM.",BMJ Open. 2021 Jun 14;11(6):e047356. doi: 10.1136/bmjopen-2020-047356.,Moore CR,BMJ Open,2021,15-06-2021,PMC8204176,,10.1136/bmjopen-2020-047356,"OBJECTIVES: Using free-text clinical notes and reports from hospitalised patients, determine the performance of natural language processing (NLP) ascertainment of Framingham heart failure (HF) criteria and phenotype.
STUDY DESIGN: A retrospective observational study design of patients hospitalised in 2015 from four hospitals participating in the Atherosclerosis Risk in Communities (ARIC) study was used to determine NLP performance in the ascertainment of Framingham HF criteria and phenotype.
SETTING: Four ARIC study hospitals, each representing an ARIC study region in the USA.
PARTICIPANTS: A stratified random sample of hospitalisations identified using a broad range of International Classification of Disease, ninth revision, diagnostic codes indicative of an HF event and occurring during 2015 was drawn for this study. A randomly selected set of 394 hospitalisations was used as the derivation dataset and 406 hospitalisations was used as the validation dataset.
INTERVENTION: Use of NLP on free-text clinical notes and reports to ascertain Framingham HF criteria and phenotype.
PRIMARY AND SECONDARY OUTCOME MEASURES: NLP performance as measured by sensitivity, specificity, positive-predictive value (PPV) and agreement in ascertainment of Framingham HF criteria and phenotype. Manual medical record review by trained ARIC abstractors was used as the reference standard.
RESULTS: Overall, performance of NLP ascertainment of Framingham HF phenotype in the validation dataset was good, with 78.8%, 81.7%, 84.4% and 80.0% for sensitivity, specificity, PPV and agreement, respectively.
CONCLUSIONS: By decreasing the need for manual chart review, our results on the use of NLP to ascertain Framingham HF phenotype from free-text electronic health record data suggest that validated NLP technology holds the potential for significantly improving the feasibility and efficiency of conducting large-scale epidemiologic surveillance of HF prevalence and incidence.","Ascertaining Framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre Atherosclerosis Risk in Communities (ARIC) validation study OBJECTIVES: Using free-text clinical notes and reports from hospitalised patients, determine the performance of natural language processing (NLP) ascertainment of Framingham heart failure (HF) criteria and phenotype.
STUDY DESIGN: A retrospective observational study design of patients hospitalised in 2015 from four hospitals participating in the Atherosclerosis Risk in Communities (ARIC) study was used to determine NLP performance in the ascertainment of Framingham HF criteria and phenotype.
SETTING: Four ARIC study hospitals, each representing an ARIC study region in the USA.
PARTICIPANTS: A stratified random sample of hospitalisations identified using a broad range of International Classification of Disease, ninth revision, diagnostic codes indicative of an HF event and occurring during 2015 was drawn for this study. A randomly selected set of 394 hospitalisations was used as the derivation dataset and 406 hospitalisations was used as the validation dataset.
INTERVENTION: Use of NLP on free-text clinical notes and reports to ascertain Framingham HF criteria and phenotype.
PRIMARY AND SECONDARY OUTCOME MEASURES: NLP performance as measured by sensitivity, specificity, positive-predictive value (PPV) and agreement in ascertainment of Framingham HF criteria and phenotype. Manual medical record review by trained ARIC abstractors was used as the reference standard.
RESULTS: Overall, performance of NLP ascertainment of Framingham HF phenotype in the validation dataset was good, with 78.8%, 81.7%, 84.4% and 80.0% for sensitivity, specificity, PPV and agreement, respectively.
CONCLUSIONS: By decreasing the need for manual chart review, our results on the use of NLP to ascertain Framingham HF phenotype from free-text electronic health record data suggest that validated NLP technology holds the potential for significantly improving the feasibility and efficiency of conducting large-scale epidemiologic surveillance of HF prevalence and incidence.",0
35248103,Concerns among people who use opioids during the COVID-19 pandemic: a natural language processing analysis of social media posts,"Sarker A, Nataraj N, Siu W, Li S, Jones CM, Sumner SA.",Subst Abuse Treat Prev Policy. 2022 Mar 5;17(1):16. doi: 10.1186/s13011-022-00442-w.,Sarker A,Subst Abuse Treat Prev Policy,2022,06-03-2022,PMC8897722,,10.1186/s13011-022-00442-w,"BACKGROUND: Timely data from official sources regarding the impact of the COVID-19 pandemic on people who use prescription and illegal opioids is lacking. We conducted a large-scale, natural language processing (NLP) analysis of conversations on opioid-related drug forums to better understand concerns among people who use opioids.
METHODS: In this retrospective observational study, we analyzed posts from 14 opioid-related forums on the social network Reddit. We applied NLP to identify frequently mentioned substances and phrases, and grouped the phrases manually based on their contents into three broad key themes: (i) prescription and/or illegal opioid use; (ii) substance use disorder treatment access and care; and (iii) withdrawal. Phrases that were unmappable to any particular theme were discarded. We computed the frequencies of substance and theme mentions, and quantified their volumes over time. We compared changes in post volumes by key themes and substances between pre-COVID-19 (1/1/2019-2/29/2020) and COVID-19 (3/1/2020-11/30/2020) periods.
RESULTS: Seventy-seven thousand six hundred fifty-two and 119,168 posts were collected for the pre-COVID-19 and COVID-19 periods, respectively. By theme, posts about treatment and access to care increased by 300%, from 0.631 to 2.526 per 1000 posts between the pre-COVID-19 and COVID-19 periods. Conversations about withdrawal increased by 812% between the same periods (0.026 to 0.235 per 1,000 posts). Posts about drug use did not increase (0.219 to 0.218 per 1,000 posts). By substance, among medications for opioid use disorder, methadone had the largest increase in conversations (20.751 to 56.313 per 1,000 posts; 171.4% increase). Among other medications, posts about diphenhydramine exhibited the largest increase (0.341 to 0.927 per 1,000 posts; 171.8% increase).
CONCLUSIONS: Conversations on opioid-related forums among people who use opioids revealed increased concerns about treatment and access to care along with withdrawal following the emergence of COVID-19. Greater attention to social media data may help inform timely responses to the needs of people who use opioids during COVID-19.","Concerns among people who use opioids during the COVID-19 pandemic: a natural language processing analysis of social media posts BACKGROUND: Timely data from official sources regarding the impact of the COVID-19 pandemic on people who use prescription and illegal opioids is lacking. We conducted a large-scale, natural language processing (NLP) analysis of conversations on opioid-related drug forums to better understand concerns among people who use opioids.
METHODS: In this retrospective observational study, we analyzed posts from 14 opioid-related forums on the social network Reddit. We applied NLP to identify frequently mentioned substances and phrases, and grouped the phrases manually based on their contents into three broad key themes: (i) prescription and/or illegal opioid use; (ii) substance use disorder treatment access and care; and (iii) withdrawal. Phrases that were unmappable to any particular theme were discarded. We computed the frequencies of substance and theme mentions, and quantified their volumes over time. We compared changes in post volumes by key themes and substances between pre-COVID-19 (1/1/2019-2/29/2020) and COVID-19 (3/1/2020-11/30/2020) periods.
RESULTS: Seventy-seven thousand six hundred fifty-two and 119,168 posts were collected for the pre-COVID-19 and COVID-19 periods, respectively. By theme, posts about treatment and access to care increased by 300%, from 0.631 to 2.526 per 1000 posts between the pre-COVID-19 and COVID-19 periods. Conversations about withdrawal increased by 812% between the same periods (0.026 to 0.235 per 1,000 posts). Posts about drug use did not increase (0.219 to 0.218 per 1,000 posts). By substance, among medications for opioid use disorder, methadone had the largest increase in conversations (20.751 to 56.313 per 1,000 posts; 171.4% increase). Among other medications, posts about diphenhydramine exhibited the largest increase (0.341 to 0.927 per 1,000 posts; 171.8% increase).
CONCLUSIONS: Conversations on opioid-related forums among people who use opioids revealed increased concerns about treatment and access to care along with withdrawal following the emergence of COVID-19. Greater attention to social media data may help inform timely responses to the needs of people who use opioids during COVID-19.",0
33835932,"Using a Secure, Continually Updating, Web Source Processing Pipeline to Support the Real-Time Data Synthesis and Analysis of Scientific Literature: Development and Validation Study","Vaghela U, Rabinowicz S, Bratsos P, Martin G, Fritzilas E, Markar S, Purkayastha S, Stringer K, Singh H, Llewellyn C, Dutta D, Clarke JM, Howard M; PanSurg REDASA Curators; Serban O, Kinross J.",J Med Internet Res. 2021 May 6;23(5):e25714. doi: 10.2196/25714.,Vaghela U,J Med Internet Res,2021,09-04-2021,PMC8104004,,10.2196/25714,"BACKGROUND: The scale and quality of the global scientific response to the COVID-19 pandemic have unquestionably saved lives. However, the COVID-19 pandemic has also triggered an unprecedented ""infodemic""; the velocity and volume of data production have overwhelmed many key stakeholders such as clinicians and policy makers, as they have been unable to process structured and unstructured data for evidence-based decision making. Solutions that aim to alleviate this data synthesis-related challenge are unable to capture heterogeneous web data in real time for the production of concomitant answers and are not based on the high-quality information in responses to a free-text query.
OBJECTIVE: The main objective of this project is to build a generic, real-time, continuously updating curation platform that can support the data synthesis and analysis of a scientific literature framework. Our secondary objective is to validate this platform and the curation methodology for COVID-19-related medical literature by expanding the COVID-19 Open Research Dataset via the addition of new, unstructured data.
METHODS: To create an infrastructure that addresses our objectives, the PanSurg Collaborative at Imperial College London has developed a unique data pipeline based on a web crawler extraction methodology. This data pipeline uses a novel curation methodology that adopts a human-in-the-loop approach for the characterization of quality, relevance, and key evidence across a range of scientific literature sources.
RESULTS: REDASA (Realtime Data Synthesis and Analysis) is now one of the world's largest and most up-to-date sources of COVID-19-related evidence; it consists of 104,000 documents. By capturing curators' critical appraisal methodologies through the discrete labeling and rating of information, REDASA rapidly developed a foundational, pooled, data science data set of over 1400 articles in under 2 weeks. These articles provide COVID-19-related information and represent around 10% of all papers about COVID-19.
CONCLUSIONS: This data set can act as ground truth for the future implementation of a live, automated systematic review. The three benefits of REDASA's design are as follows: (1) it adopts a user-friendly, human-in-the-loop methodology by embedding an efficient, user-friendly curation platform into a natural language processing search engine; (2) it provides a curated data set in the JavaScript Object Notation format for experienced academic reviewers' critical appraisal choices and decision-making methodologies; and (3) due to the wide scope and depth of its web crawling method, REDASA has already captured one of the world's largest COVID-19-related data corpora for searches and curation.","Using a Secure, Continually Updating, Web Source Processing Pipeline to Support the Real-Time Data Synthesis and Analysis of Scientific Literature: Development and Validation Study BACKGROUND: The scale and quality of the global scientific response to the COVID-19 pandemic have unquestionably saved lives. However, the COVID-19 pandemic has also triggered an unprecedented ""infodemic""; the velocity and volume of data production have overwhelmed many key stakeholders such as clinicians and policy makers, as they have been unable to process structured and unstructured data for evidence-based decision making. Solutions that aim to alleviate this data synthesis-related challenge are unable to capture heterogeneous web data in real time for the production of concomitant answers and are not based on the high-quality information in responses to a free-text query.
OBJECTIVE: The main objective of this project is to build a generic, real-time, continuously updating curation platform that can support the data synthesis and analysis of a scientific literature framework. Our secondary objective is to validate this platform and the curation methodology for COVID-19-related medical literature by expanding the COVID-19 Open Research Dataset via the addition of new, unstructured data.
METHODS: To create an infrastructure that addresses our objectives, the PanSurg Collaborative at Imperial College London has developed a unique data pipeline based on a web crawler extraction methodology. This data pipeline uses a novel curation methodology that adopts a human-in-the-loop approach for the characterization of quality, relevance, and key evidence across a range of scientific literature sources.
RESULTS: REDASA (Realtime Data Synthesis and Analysis) is now one of the world's largest and most up-to-date sources of COVID-19-related evidence; it consists of 104,000 documents. By capturing curators' critical appraisal methodologies through the discrete labeling and rating of information, REDASA rapidly developed a foundational, pooled, data science data set of over 1400 articles in under 2 weeks. These articles provide COVID-19-related information and represent around 10% of all papers about COVID-19.
CONCLUSIONS: This data set can act as ground truth for the future implementation of a live, automated systematic review. The three benefits of REDASA's design are as follows: (1) it adopts a user-friendly, human-in-the-loop methodology by embedding an efficient, user-friendly curation platform into a natural language processing search engine; (2) it provides a curated data set in the JavaScript Object Notation format for experienced academic reviewers' critical appraisal choices and decision-making methodologies; and (3) due to the wide scope and depth of its web crawling method, REDASA has already captured one of the world's largest COVID-19-related data corpora for searches and curation.",0
37577535,Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study,"Weissenbacher D, O'Connor K, Klein A, Golder S, Flores I, Elyaderani A, Scotch M, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2023 Aug 4:2023.07.29.23293370. doi: 10.1101/2023.07.29.23293370.,Weissenbacher D,medRxiv,2023,14-08-2023,PMC10418574,,10.1101/2023.07.29.23293370,"There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GISAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.","Text mining biomedical literature to identify extremely unbalanced data for digital epidemiology and systematic reviews: dataset and methods for a SARS-CoV-2 genomic epidemiology study There are many studies that require researchers to extract specific information from the published literature, such as details about sequence records or about a randomized control trial. While manual extraction is cost efficient for small studies, larger studies such as systematic reviews are much more costly and time-consuming. To avoid exhaustive manual searches and extraction, and their related cost and effort, natural language processing (NLP) methods can be tailored for the more subtle extraction and decision tasks that typically only humans have performed. The need for such studies that use the published literature as a data source became even more evident as the COVID-19 pandemic raged through the world and millions of sequenced samples were deposited in public repositories such as GISAID and GenBank, promising large genomic epidemiology studies, but more often than not lacked many important details that prevented large-scale studies. Thus, granular geographic location or the most basic patient-relevant data such as demographic information, or clinical outcomes were not noted in the sequence record. However, some of these data was indeed published, but in the text, tables, or supplementary material of a corresponding published article. We present here methods to identify relevant journal articles that report having produced and made available in GenBank or GISAID, new SARS-CoV-2 sequences, as those that initially produced and made available the sequences are the most likely articles to include the high-level details about the patients from whom the sequences were obtained. Human annotators validated the approach, creating a gold standard set for training and validation of a machine learning classifier. Identifying these articles is a crucial step to enable future automated informatics pipelines that will apply Machine Learning and Natural Language Processing to identify patient characteristics such as co-morbidities, outcomes, age, gender, and race, enriching SARS-CoV-2 sequence databases with actionable information for defining large genomic epidemiology studies. Thus, enriched patient metadata can enable secondary data analysis, at scale, to uncover associations between the viral genome (including variants of concern and their sublineages), transmission risk, and health outcomes. However, for such enrichment to happen, the right papers need to be found and very detailed data needs to be extracted from them. Further, finding the very specific articles needed for inclusion is a task that also facilitates scoping and systematic reviews, greatly reducing the time needed for full-text analysis and extraction.",0
39117794,Global Research on Pandemics or Epidemics and Mental Health: A Natural Language Processing Study,"Ye X, Wang X, Lin H.",J Epidemiol Glob Health. 2024 Sep;14(3):1268-1280. doi: 10.1007/s44197-024-00284-8. Epub 2024 Aug 8.,Ye X,J Epidemiol Glob Health,2024,08-08-2024,PMC11442711,,10.1007/s44197-024-00284-8,"BACKGROUND: The global research on pandemics or epidemics and mental health has been growing exponentially recently, which cannot be integrated through traditional systematic review. Our study aims to systematically synthesize the evidence using natural language processing (NLP) techniques.
METHODS: Multiple databases were searched using titles, abstracts, and keywords. We systematically identified relevant literature published prior to Dec 31, 2023, using NLP techniques such as text classification, topic modelling and geoparsing methods. Relevant articles were categorized by content, date, and geographic location, outputting evidence heat maps, geographical maps, and narrative synthesis of trends in related publications.
RESULTS: Our NLP analysis identified 77,915 studies in the area of pandemics or epidemics and mental health published before Dec 31, 2023. The Covid pandemic was the most common, followed by SARS and HIV/AIDS; Anxiety and stress were the most frequently studied mental health outcomes; Social support and healthcare were the most common way of coping. Geographically, the evidence base was dominated by studies from high-income countries, with scant evidence from low-income counties. Co-occurrence of pandemics or epidemics and fear, depression, stress was common. Anxiety was one of the three most common topics in all continents except North America.
CONCLUSION: Our findings suggest the importance and feasibility of using NLP to comprehensively map pandemics or epidemics and mental health in the age of big literature. The review identifies clear themes for future clinical and public health research, and is critical for designing evidence-based approaches to reduce the negative mental health impacts of pandemics or epidemics.","Global Research on Pandemics or Epidemics and Mental Health: A Natural Language Processing Study BACKGROUND: The global research on pandemics or epidemics and mental health has been growing exponentially recently, which cannot be integrated through traditional systematic review. Our study aims to systematically synthesize the evidence using natural language processing (NLP) techniques.
METHODS: Multiple databases were searched using titles, abstracts, and keywords. We systematically identified relevant literature published prior to Dec 31, 2023, using NLP techniques such as text classification, topic modelling and geoparsing methods. Relevant articles were categorized by content, date, and geographic location, outputting evidence heat maps, geographical maps, and narrative synthesis of trends in related publications.
RESULTS: Our NLP analysis identified 77,915 studies in the area of pandemics or epidemics and mental health published before Dec 31, 2023. The Covid pandemic was the most common, followed by SARS and HIV/AIDS; Anxiety and stress were the most frequently studied mental health outcomes; Social support and healthcare were the most common way of coping. Geographically, the evidence base was dominated by studies from high-income countries, with scant evidence from low-income counties. Co-occurrence of pandemics or epidemics and fear, depression, stress was common. Anxiety was one of the three most common topics in all continents except North America.
CONCLUSION: Our findings suggest the importance and feasibility of using NLP to comprehensively map pandemics or epidemics and mental health in the age of big literature. The review identifies clear themes for future clinical and public health research, and is critical for designing evidence-based approaches to reduce the negative mental health impacts of pandemics or epidemics.",0
35608886,Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method,"Zheng C, Duffy J, Liu IA, Sy LS, Navarro RA, Kim SS, Ryan DS, Chen W, Qian L, Mercado C, Jacobsen SJ.",JMIR Public Health Surveill. 2022 May 24;8(5):e30426. doi: 10.2196/30426.,Zheng C,JMIR Public Health Surveill,2022,24-05-2022,PMC9175103,,10.2196/30426,"BACKGROUND: Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce.
OBJECTIVE: The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes.
METHODS: We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases.
RESULTS: In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively.
CONCLUSIONS: The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation.","Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method BACKGROUND: Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce.
OBJECTIVE: The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes.
METHODS: We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases.
RESULTS: In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively.
CONCLUSIONS: The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation.",0
37457889,Mapping Research Trends of Medications for Multidrug-Resistant Pulmonary Tuberculosis Based on the Co-Occurrence of Specific Semantic Types in the MeSH Tree: A Bibliometric and Visualization-Based Analysis of PubMed Literature (1966-2020),"Xu S, Fu Y, Xu D, Han S, Wu M, Ju X, Liu M, Huang DS, Guan P.",Drug Des Devel Ther. 2023 Jul 10;17:2035-2049. doi: 10.2147/DDDT.S409604. eCollection 2023.,Xu S,Drug Des Devel Ther,2023,17-07-2023,PMC10348322,,10.2147/DDDT.S409604,"BACKGROUND: Before the COVID-19 pandemic, tuberculosis is the leading cause of death from a single infectious agent worldwide for the past 30 years. Progress in the control of tuberculosis has been undermined by the emergence of multidrug-resistant tuberculosis. The aim of the study is to reveal the trends of research on medications for multidrug-resistant pulmonary tuberculosis (MDR-PTB) through a novel method of bibliometrics that co-occurs specific semantic Medical Subject Headings (MeSH).
METHODS: PubMed was used to identify the original publications related to medications for MDR-PTB. An R package for text mining of PubMed, pubMR, was adopted to extract data and construct the co-occurrence matrix-specific semantic types. Biclustering analysis of high-frequency MeSH term co-occurrence matrix was performed by gCLUTO. Scientific knowledge maps were constructed by VOSviewer to create overlay visualization and density visualization. Burst detection was performed by CiteSpace to identify the future research hotspots.
RESULTS: Two hundred and eight substances (chemical, drug, protein) and 147 diseases related to MDR-PTB were extracted to form a specific semantic co-occurrence matrix. MeSH terms with frequency greater than or equal to six were selected to construct high-frequency co-occurrence matrix (42 × 20) of specific semantic types contains 42 substances and 20 diseases. Biclustering analysis divided the medications for MDR-PTB into five clusters and reflected the characteristics of drug composition. The overlay map indicated the average age gradients of 42 high-frequency drugs. Fifteen top keywords and 37 top terms with the strongest citation bursts were detected.
CONCLUSION: This study evaluated the literatures related to MDR-PTB drug therapy, providing a co-occurrence matrix model based on the specific semantic types and a new attempt for text knowledge mining. Compared with the macro knowledge structure or hot spot analysis, this method may have a wider scope of application and a more in-depth degree of analysis.","Mapping Research Trends of Medications for Multidrug-Resistant Pulmonary Tuberculosis Based on the Co-Occurrence of Specific Semantic Types in the MeSH Tree: A Bibliometric and Visualization-Based Analysis of PubMed Literature (1966-2020) BACKGROUND: Before the COVID-19 pandemic, tuberculosis is the leading cause of death from a single infectious agent worldwide for the past 30 years. Progress in the control of tuberculosis has been undermined by the emergence of multidrug-resistant tuberculosis. The aim of the study is to reveal the trends of research on medications for multidrug-resistant pulmonary tuberculosis (MDR-PTB) through a novel method of bibliometrics that co-occurs specific semantic Medical Subject Headings (MeSH).
METHODS: PubMed was used to identify the original publications related to medications for MDR-PTB. An R package for text mining of PubMed, pubMR, was adopted to extract data and construct the co-occurrence matrix-specific semantic types. Biclustering analysis of high-frequency MeSH term co-occurrence matrix was performed by gCLUTO. Scientific knowledge maps were constructed by VOSviewer to create overlay visualization and density visualization. Burst detection was performed by CiteSpace to identify the future research hotspots.
RESULTS: Two hundred and eight substances (chemical, drug, protein) and 147 diseases related to MDR-PTB were extracted to form a specific semantic co-occurrence matrix. MeSH terms with frequency greater than or equal to six were selected to construct high-frequency co-occurrence matrix (42 × 20) of specific semantic types contains 42 substances and 20 diseases. Biclustering analysis divided the medications for MDR-PTB into five clusters and reflected the characteristics of drug composition. The overlay map indicated the average age gradients of 42 high-frequency drugs. Fifteen top keywords and 37 top terms with the strongest citation bursts were detected.
CONCLUSION: This study evaluated the literatures related to MDR-PTB drug therapy, providing a co-occurrence matrix model based on the specific semantic types and a new attempt for text knowledge mining. Compared with the macro knowledge structure or hot spot analysis, this method may have a wider scope of application and a more in-depth degree of analysis.",0
36827297,Surveillance of communicable diseases using social media: A systematic review,"Pilipiec P, Samsten I, Bota A.",PLoS One. 2023 Feb 24;18(2):e0282101. doi: 10.1371/journal.pone.0282101. eCollection 2023.,Pilipiec P,PLoS One,2023,24-02-2023,PMC9956027,,10.1371/journal.pone.0282101,"BACKGROUND: Communicable diseases pose a severe threat to public health and economic growth. The traditional methods that are used for public health surveillance, however, involve many drawbacks, such as being labor intensive to operate and resulting in a lag between data collection and reporting. To effectively address the limitations of these traditional methods and to mitigate the adverse effects of these diseases, a proactive and real-time public health surveillance system is needed. Previous studies have indicated the usefulness of performing text mining on social media.
OBJECTIVE: To conduct a systematic review of the literature that used textual content published to social media for the purpose of the surveillance and prediction of communicable diseases.
METHODOLOGY: Broad search queries were formulated and performed in four databases. Both journal articles and conference materials were included. The quality of the studies, operationalized as reliability and validity, was assessed. This qualitative systematic review was guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.
RESULTS: Twenty-three publications were included in this systematic review. All studies reported positive results for using textual social media content to surveille communicable diseases. Most studies used Twitter as a source for these data. Influenza was studied most frequently, while other communicable diseases received far less attention. Journal articles had a higher quality (reliability and validity) than conference papers. However, studies often failed to provide important information about procedures and implementation.
CONCLUSION: Text mining of health-related content published on social media can serve as a novel and powerful tool for the automated, real-time, and remote monitoring of public health and for the surveillance and prediction of communicable diseases in particular. This tool can address limitations related to traditional surveillance methods, and it has the potential to supplement traditional methods for public health surveillance.","Surveillance of communicable diseases using social media: A systematic review BACKGROUND: Communicable diseases pose a severe threat to public health and economic growth. The traditional methods that are used for public health surveillance, however, involve many drawbacks, such as being labor intensive to operate and resulting in a lag between data collection and reporting. To effectively address the limitations of these traditional methods and to mitigate the adverse effects of these diseases, a proactive and real-time public health surveillance system is needed. Previous studies have indicated the usefulness of performing text mining on social media.
OBJECTIVE: To conduct a systematic review of the literature that used textual content published to social media for the purpose of the surveillance and prediction of communicable diseases.
METHODOLOGY: Broad search queries were formulated and performed in four databases. Both journal articles and conference materials were included. The quality of the studies, operationalized as reliability and validity, was assessed. This qualitative systematic review was guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines.
RESULTS: Twenty-three publications were included in this systematic review. All studies reported positive results for using textual social media content to surveille communicable diseases. Most studies used Twitter as a source for these data. Influenza was studied most frequently, while other communicable diseases received far less attention. Journal articles had a higher quality (reliability and validity) than conference papers. However, studies often failed to provide important information about procedures and implementation.
CONCLUSION: Text mining of health-related content published on social media can serve as a novel and powerful tool for the automated, real-time, and remote monitoring of public health and for the surveillance and prediction of communicable diseases in particular. This tool can address limitations related to traditional surveillance methods, and it has the potential to supplement traditional methods for public health surveillance.",0
32955571,Novel Method to Flag Cardiac Implantable Device Infections by Integrating Text Mining With Structured Data in the Veterans Health Administration's Electronic Medical Record,"Mull HJ, Stolzmann KL, Shin MH, Kalver E, Schweizer ML, Branch-Elliman W.",JAMA Netw Open. 2020 Sep 1;3(9):e2012264. doi: 10.1001/jamanetworkopen.2020.12264.,Mull HJ,JAMA Netw Open,2020,21-09-2020,PMC7506515,,10.1001/jamanetworkopen.2020.12264,"IMPORTANCE: Health care-associated infections (HAIs) are preventable, harmful, and costly; however, few resources are dedicated to infection surveillance of nonsurgical procedures, particularly cardiovascular implantable electronic device (CIED) procedures.
OBJECTIVE: To develop a method that includes text mining of electronic clinical notes to reliably and efficiently measure HAIs for CIED procedures.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter, national cohort study using electronic medical record data for patients undergoing CIED procedures in Veterans Health Administration (VA) facilities for fiscal years (FYs) 2016 and 2017, an algorithm to flag cases with a true CIED-related infection based on structured (eg, microbiology orders, vital signs) and free text diagnostic and therapeutic data (eg, procedure notes, discharge summaries, microbiology results) was developed and validated. Procedure data were divided into development and validation data sets. Criterion validity (ie, positive predictive validity [PPV], sensitivity, and specificity) was assessed via criterion-standard manual medical record review.
EXPOSURES: CIED procedure.
MAIN OUTCOMES AND MEASURES: The concordance between medical record review and the study algorithm with respect to the presence or absence of a CIED infection. CIED infection in the algorithm included 90-day mortality, congestive heart failure and nonmetastatic tumor comorbidities, CIED or surgical site infection International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Clinical Modification (ICD-10-CM) diagnosis codes, antibiotic treatment of Staphylococci, a microbiology test of a cardiac specimen, and text documentation of infection in specific clinical notes (eg, cardiology, infectious diseases, inpatient discharge summaries).
RESULTS: The algorithm sample consisted of 19 212 CIED procedures; 15 077 patients (78.5%) were White individuals, 1487 (15.5%) were African American; 18 766 (97.7%) were men. The mean (SD) age in our sample was 71.8 (10.6) years. The infection detection threshold of predicted probability was set to greater than 0.10 and the algorithm flagged 276 of 9606 (2.9%) cases in the development data set (9606 procedures); PPV in this group was 41.4% (95% CI, 31.6%-51.8%). In the validation set (9606 procedures), at predicted probability 0.10 or more the algorithm PPV was 43.5% (95% CI, 37.1%-50.2%), and overall sensitivity and specificity were 94.4% (95% CI, 88.2%-97.9%) and 48.8% (95% CI, 42.6%-55.1%), respectively.
CONCLUSIONS AND RELEVANCE: The findings of this study suggest that the method of combining structured and text data in VA electronic medical records can be used to expand infection surveillance beyond traditional boundaries to include outpatient and procedural areas.","Novel Method to Flag Cardiac Implantable Device Infections by Integrating Text Mining With Structured Data in the Veterans Health Administration's Electronic Medical Record IMPORTANCE: Health care-associated infections (HAIs) are preventable, harmful, and costly; however, few resources are dedicated to infection surveillance of nonsurgical procedures, particularly cardiovascular implantable electronic device (CIED) procedures.
OBJECTIVE: To develop a method that includes text mining of electronic clinical notes to reliably and efficiently measure HAIs for CIED procedures.
DESIGN, SETTING, AND PARTICIPANTS: In this multicenter, national cohort study using electronic medical record data for patients undergoing CIED procedures in Veterans Health Administration (VA) facilities for fiscal years (FYs) 2016 and 2017, an algorithm to flag cases with a true CIED-related infection based on structured (eg, microbiology orders, vital signs) and free text diagnostic and therapeutic data (eg, procedure notes, discharge summaries, microbiology results) was developed and validated. Procedure data were divided into development and validation data sets. Criterion validity (ie, positive predictive validity [PPV], sensitivity, and specificity) was assessed via criterion-standard manual medical record review.
EXPOSURES: CIED procedure.
MAIN OUTCOMES AND MEASURES: The concordance between medical record review and the study algorithm with respect to the presence or absence of a CIED infection. CIED infection in the algorithm included 90-day mortality, congestive heart failure and nonmetastatic tumor comorbidities, CIED or surgical site infection International Statistical Classification of Diseases and Related Health Problems, Tenth Revision, Clinical Modification (ICD-10-CM) diagnosis codes, antibiotic treatment of Staphylococci, a microbiology test of a cardiac specimen, and text documentation of infection in specific clinical notes (eg, cardiology, infectious diseases, inpatient discharge summaries).
RESULTS: The algorithm sample consisted of 19 212 CIED procedures; 15 077 patients (78.5%) were White individuals, 1487 (15.5%) were African American; 18 766 (97.7%) were men. The mean (SD) age in our sample was 71.8 (10.6) years. The infection detection threshold of predicted probability was set to greater than 0.10 and the algorithm flagged 276 of 9606 (2.9%) cases in the development data set (9606 procedures); PPV in this group was 41.4% (95% CI, 31.6%-51.8%). In the validation set (9606 procedures), at predicted probability 0.10 or more the algorithm PPV was 43.5% (95% CI, 37.1%-50.2%), and overall sensitivity and specificity were 94.4% (95% CI, 88.2%-97.9%) and 48.8% (95% CI, 42.6%-55.1%), respectively.
CONCLUSIONS AND RELEVANCE: The findings of this study suggest that the method of combining structured and text data in VA electronic medical records can be used to expand infection surveillance beyond traditional boundaries to include outpatient and procedural areas.",0
33684054,COVID-19 Discourse on Twitter in Four Asian Countries: Case Study of Risk Communication,"Park S, Han S, Kim J, Molaie MM, Vu HD, Singh K, Han J, Lee W, Cha M.",J Med Internet Res. 2021 Mar 16;23(3):e23272. doi: 10.2196/23272.,Park S,J Med Internet Res,2021,08-03-2021,PMC8108572,,10.2196/23272,"BACKGROUND: COVID-19, caused by SARS-CoV-2, has led to a global pandemic. The World Health Organization has also declared an infodemic (ie, a plethora of information regarding COVID-19 containing both false and accurate information circulated on the internet). Hence, it has become critical to test the veracity of information shared online and analyze the evolution of discussed topics among citizens related to the pandemic.
OBJECTIVE: This research analyzes the public discourse on COVID-19. It characterizes risk communication patterns in four Asian countries with outbreaks at varying degrees of severity: South Korea, Iran, Vietnam, and India.
METHODS: We collected tweets on COVID-19 from four Asian countries in the early phase of the disease outbreak from January to March 2020. The data set was collected by relevant keywords in each language, as suggested by locals. We present a method to automatically extract a time-topic cohesive relationship in an unsupervised fashion based on natural language processing. The extracted topics were evaluated qualitatively based on their semantic meanings.
RESULTS: This research found that each government's official phases of the epidemic were not well aligned with the degree of public attention represented by the daily tweet counts. Inspired by the issue-attention cycle theory, the presented natural language processing model can identify meaningful transition phases in the discussed topics among citizens. The analysis revealed an inverse relationship between the tweet count and topic diversity.
CONCLUSIONS: This paper compares similarities and differences of pandemic-related social media discourse in Asian countries. We observed multiple prominent peaks in the daily tweet counts across all countries, indicating multiple issue-attention cycles. Our analysis identified which topics the public concentrated on; some of these topics were related to misinformation and hate speech. These findings and the ability to quickly identify key topics can empower global efforts to fight against an infodemic during a pandemic.","COVID-19 Discourse on Twitter in Four Asian Countries: Case Study of Risk Communication BACKGROUND: COVID-19, caused by SARS-CoV-2, has led to a global pandemic. The World Health Organization has also declared an infodemic (ie, a plethora of information regarding COVID-19 containing both false and accurate information circulated on the internet). Hence, it has become critical to test the veracity of information shared online and analyze the evolution of discussed topics among citizens related to the pandemic.
OBJECTIVE: This research analyzes the public discourse on COVID-19. It characterizes risk communication patterns in four Asian countries with outbreaks at varying degrees of severity: South Korea, Iran, Vietnam, and India.
METHODS: We collected tweets on COVID-19 from four Asian countries in the early phase of the disease outbreak from January to March 2020. The data set was collected by relevant keywords in each language, as suggested by locals. We present a method to automatically extract a time-topic cohesive relationship in an unsupervised fashion based on natural language processing. The extracted topics were evaluated qualitatively based on their semantic meanings.
RESULTS: This research found that each government's official phases of the epidemic were not well aligned with the degree of public attention represented by the daily tweet counts. Inspired by the issue-attention cycle theory, the presented natural language processing model can identify meaningful transition phases in the discussed topics among citizens. The analysis revealed an inverse relationship between the tweet count and topic diversity.
CONCLUSIONS: This paper compares similarities and differences of pandemic-related social media discourse in Asian countries. We observed multiple prominent peaks in the daily tweet counts across all countries, indicating multiple issue-attention cycles. Our analysis identified which topics the public concentrated on; some of these topics were related to misinformation and hate speech. These findings and the ability to quickly identify key topics can empower global efforts to fight against an infodemic during a pandemic.",0
26042846,What can we learn about the Ebola outbreak from tweets?,"Odlum M, Yoon S.",Am J Infect Control. 2015 Jun;43(6):563-71. doi: 10.1016/j.ajic.2015.02.023.,Odlum M,Am J Infect Control,2015,05-06-2015,PMC4591071,NIHMS723184,10.1016/j.ajic.2015.02.023,"BACKGROUND: Twitter can address the challenges of the current Ebola outbreak surveillance. The aims of this study are to demonstrate the use of Twitter as a real-time method of Ebola outbreak surveillance to monitor information spread, capture early epidemic detection, and examine content of public knowledge and attitudes.
METHODS: We collected tweets mentioning Ebola in English during the early stage of the current Ebola outbreak from July 24-August 1, 2014. Our analysis for this observational study includes time series analysis with geologic visualization to observe information dissemination and content analysis using natural language processing to examine public knowledge and attitudes.
RESULTS: A total of 42,236 tweets (16,499 unique and 25,737 retweets) mentioning Ebola were posted and disseminated to 9,362,267,048 people, 63 times higher than the initial number. Tweets started to rise in Nigeria 3-7 days prior to the official announcement of the first probable Ebola case. The topics discussed in tweets include risk factors, prevention education, disease trends, and compassion.
CONCLUSION: Because of the analysis of a unique Twitter dataset captured in the early stage of the current Ebola outbreak, our results provide insight into the intersection of social media and public health outbreak surveillance. Findings demonstrate the usefulness of Twitter mining to inform public health education.","What can we learn about the Ebola outbreak from tweets? BACKGROUND: Twitter can address the challenges of the current Ebola outbreak surveillance. The aims of this study are to demonstrate the use of Twitter as a real-time method of Ebola outbreak surveillance to monitor information spread, capture early epidemic detection, and examine content of public knowledge and attitudes.
METHODS: We collected tweets mentioning Ebola in English during the early stage of the current Ebola outbreak from July 24-August 1, 2014. Our analysis for this observational study includes time series analysis with geologic visualization to observe information dissemination and content analysis using natural language processing to examine public knowledge and attitudes.
RESULTS: A total of 42,236 tweets (16,499 unique and 25,737 retweets) mentioning Ebola were posted and disseminated to 9,362,267,048 people, 63 times higher than the initial number. Tweets started to rise in Nigeria 3-7 days prior to the official announcement of the first probable Ebola case. The topics discussed in tweets include risk factors, prevention education, disease trends, and compassion.
CONCLUSION: Because of the analysis of a unique Twitter dataset captured in the early stage of the current Ebola outbreak, our results provide insight into the intersection of social media and public health outbreak surveillance. Findings demonstrate the usefulness of Twitter mining to inform public health education.",0
31043825,U.S. prevalence of endocrine therapy-naïve locally advanced or metastatic breast cancer,"Nunes AP, Liang C, Gradishar WJ, Dalvi T, Lewis J, Jones N, Green E, Doherty M, Seeger JD.",Curr Oncol. 2019 Apr;26(2):e180-e187. doi: 10.3747/co.26.4163. Epub 2019 Apr 1.,Nunes AP,Curr Oncol,2019,03-05-2019,PMC6476436,,10.3747/co.26.4163,"BACKGROUND: Variations in treatment choice, or late stage at first diagnosis, mean that, despite guideline recommendations, not all patients with hormone receptor (hr)-positive locally advanced or metastatic breast cancer (la/mbca) will have received endocrine therapy before disease progression. In the present study, we aimed to estimate the proportion of women with postmenopausal hr-positive la/mbca in the United States who are endocrine therapy-naïve.
METHODS: Women in the Optum Electronic Health Record (ehr) database with a breast cancer (bca) diagnosis (January 2008-March 2015) were included. Patient and malignancy characteristics were identified using structured data fields and natural-language processing of free-text clinical notes. The proportion of women with postmenopausal hr-positive, human epidermal growth factor 2 (her2)-negative (or unknown) la/mbca who had not received prior endocrine therapy was determined. Results were extrapolated to the entire U.S. population using the U.S. National Cancer Institute's Surveillance, Epidemiology, and End Results database. Results are presented descriptively.
RESULTS: In the ehr database, 11,831 women with bca had discernible information on postmenopausal status, hr status, and disease stage. Of those women, 1923 (16.3%) had postmenopausal hr-positive, her2-negative (or unknown) la/mbca, and 70.7% of those 1923 patients (n = 1360) had not received prior endocrine therapy, accounting for 11.5% of the overall population. Extrapolating those estimates nationally suggests an annual incidence of 14,784 cases, and a 5-year limited duration prevalence of 50,638 cases.
CONCLUSIONS: A substantial proportion of women with postmenopausal hr-positive la/mbca in the United States could be endocrine therapy-naïve.","U.S. prevalence of endocrine therapy-naïve locally advanced or metastatic breast cancer BACKGROUND: Variations in treatment choice, or late stage at first diagnosis, mean that, despite guideline recommendations, not all patients with hormone receptor (hr)-positive locally advanced or metastatic breast cancer (la/mbca) will have received endocrine therapy before disease progression. In the present study, we aimed to estimate the proportion of women with postmenopausal hr-positive la/mbca in the United States who are endocrine therapy-naïve.
METHODS: Women in the Optum Electronic Health Record (ehr) database with a breast cancer (bca) diagnosis (January 2008-March 2015) were included. Patient and malignancy characteristics were identified using structured data fields and natural-language processing of free-text clinical notes. The proportion of women with postmenopausal hr-positive, human epidermal growth factor 2 (her2)-negative (or unknown) la/mbca who had not received prior endocrine therapy was determined. Results were extrapolated to the entire U.S. population using the U.S. National Cancer Institute's Surveillance, Epidemiology, and End Results database. Results are presented descriptively.
RESULTS: In the ehr database, 11,831 women with bca had discernible information on postmenopausal status, hr status, and disease stage. Of those women, 1923 (16.3%) had postmenopausal hr-positive, her2-negative (or unknown) la/mbca, and 70.7% of those 1923 patients (n = 1360) had not received prior endocrine therapy, accounting for 11.5% of the overall population. Extrapolating those estimates nationally suggests an annual incidence of 14,784 cases, and a 5-year limited duration prevalence of 50,638 cases.
CONCLUSIONS: A substantial proportion of women with postmenopausal hr-positive la/mbca in the United States could be endocrine therapy-naïve.",0
39318625,Variation in worldwide incidence of Guillain-Barré syndrome: a population-based study in urban China and existing global evidence,"Xu L, Zhao C, Bao Y, Liu Y, Liang Y, Wei J, Liu G, Wang J, Zhan S, Wang S, Fan D.",Front Immunol. 2024 Sep 10;15:1415986. doi: 10.3389/fimmu.2024.1415986. eCollection 2024.,Xu L,Front Immunol,2024,25-09-2024,PMC11420027,,10.3389/fimmu.2024.1415986,"BACKGROUND AND OBJECTIVES: Geographical variation existed in the incidences of Guillain-Barré syndrome (GBS), but no national population-based study has evaluated the incidences of GBS in China. This study aimed to estimate the incidence of GBS in urban China and evaluate the worldwide variation in the incidence of GBS.
METHODS: Firstly, we did a population-based study to calculate the incidence of GBS in urban China based on the National Urban Medical Insurance database from 2013 to 2017. To identify GBS cases, natural language processing was used first for handling the lengthy and unstructured diagnostic information and then checked by prestigious neurologists. Secondly, a systematic review and meta-analysis were performed to analyze the incidence of GBS worldwide. Up to July 4, 2022, Medline, Embase, and Web of Science were retrieved to identify the population-based studies regarding the incidence of GBS. The basic information and the statistics regarding incidence were extracted. Quality assessment considered sample representativeness, condition assessment, and statistical methods.
RESULTS: A total of 1.44 billion person-years in insurance data was covered, with 3,534 GBS cases identified. The annual incidences of GBS in urban China between 2013 and 2017 ranged from 0.41 (95% CI: 0.27 to 0.58) to 0.58 (95% CI: 0.38 to 0.82) per 100,000 person-years. The incidence was the highest in Northwest China and the lowest in Northeast China. The meta-analysis included 122 articles. The quality assessment showed that the quality scores of 43.3% of studies were ≥ 0.75 (the total score is 1). The global incidence of GBS was 1.12 (95% CI: 0.98 to 1.27) per 100,000 person-years. The incidences in West Europe, South Asia, and North Europe were higher, while the incidences in Australia and New Zealand, Southeast Asia, and North Africa were lower. The incidence of enteric infections was positively associated with the incidence of GBS (coefficient=0.0000185, P=0.007). The incidence in Europe, Australia, and America rose significantly from 1960 to 2020 (coefficient=0.01, t=2.52, P=0.015).
DISCUSSION: There is a clear regional variation of the GBS incidence at both national and global levels. Careful control of enteric infections should be conducted to reduce the disease burden.","Variation in worldwide incidence of Guillain-Barré syndrome: a population-based study in urban China and existing global evidence BACKGROUND AND OBJECTIVES: Geographical variation existed in the incidences of Guillain-Barré syndrome (GBS), but no national population-based study has evaluated the incidences of GBS in China. This study aimed to estimate the incidence of GBS in urban China and evaluate the worldwide variation in the incidence of GBS.
METHODS: Firstly, we did a population-based study to calculate the incidence of GBS in urban China based on the National Urban Medical Insurance database from 2013 to 2017. To identify GBS cases, natural language processing was used first for handling the lengthy and unstructured diagnostic information and then checked by prestigious neurologists. Secondly, a systematic review and meta-analysis were performed to analyze the incidence of GBS worldwide. Up to July 4, 2022, Medline, Embase, and Web of Science were retrieved to identify the population-based studies regarding the incidence of GBS. The basic information and the statistics regarding incidence were extracted. Quality assessment considered sample representativeness, condition assessment, and statistical methods.
RESULTS: A total of 1.44 billion person-years in insurance data was covered, with 3,534 GBS cases identified. The annual incidences of GBS in urban China between 2013 and 2017 ranged from 0.41 (95% CI: 0.27 to 0.58) to 0.58 (95% CI: 0.38 to 0.82) per 100,000 person-years. The incidence was the highest in Northwest China and the lowest in Northeast China. The meta-analysis included 122 articles. The quality assessment showed that the quality scores of 43.3% of studies were ≥ 0.75 (the total score is 1). The global incidence of GBS was 1.12 (95% CI: 0.98 to 1.27) per 100,000 person-years. The incidences in West Europe, South Asia, and North Europe were higher, while the incidences in Australia and New Zealand, Southeast Asia, and North Africa were lower. The incidence of enteric infections was positively associated with the incidence of GBS (coefficient=0.0000185, P=0.007). The incidence in Europe, Australia, and America rose significantly from 1960 to 2020 (coefficient=0.01, t=2.52, P=0.015).
DISCUSSION: There is a clear regional variation of the GBS incidence at both national and global levels. Careful control of enteric infections should be conducted to reduce the disease burden.",0
32795992,"Social, Behavioral, and Cultural factors of HIV in Malawi: Semi-Automated Systematic Review","Thiabaud A, Triulzi I, Orel E, Tal K, Keiser O.",J Med Internet Res. 2020 Aug 14;22(8):e18747. doi: 10.2196/18747.,Thiabaud A,J Med Internet Res,2020,16-08-2020,PMC7455873,,10.2196/18747,"BACKGROUND: Demographic and sociobehavioral factors are strong drivers of HIV infection rates in sub-Saharan Africa. These factors are often studied in qualitative research but ignored in quantitative analyses. However, they provide in-depth insight into the local behavior and may help to improve HIV prevention.
OBJECTIVE: To obtain a comprehensive overview of the sociobehavioral factors influencing HIV prevalence and incidence in Malawi, we systematically reviewed the literature using a newly programmed tool for automatizing part of the systematic review process.
METHODS: Due to the choice of broad search terms (""HIV AND Malawi""), our preliminary search revealed many thousands of articles. We, therefore, developed a Python tool to automatically extract, process, and categorize open-access articles published from January 1, 1987 to October 1, 2019 in the PubMed, PubMed Central, JSTOR, Paperity, and arXiV databases. We then used a topic modelling algorithm to classify and identify publications of interest.
RESULTS: Our tool extracted 22,709 unique articles; 16,942 could be further processed. After topic modelling, 519 of these were clustered into relevant topics, of which 20 were kept after manual screening. We retrieved 7 more publications after examining the references so that 27 publications were finally included in the review. Reducing the 16,942 articles to 519 potentially relevant articles using the software took 5 days. Several factors contributing to the risk of HIV infection were identified, including religion, gender and relationship dynamics, beliefs, and sociobehavioral attitudes.
CONCLUSIONS: Our software does not replace traditional systematic reviews, but it returns useful results to broad queries of open-access literature in under a week, without a priori knowledge. This produces a ""seed dataset"" of relevance that could be further developed. It identified known factors and factors that may be specific to Malawi. In the future, we aim to expand the tool by adding more social science databases and applying it to other sub-Saharan African countries.","Social, Behavioral, and Cultural factors of HIV in Malawi: Semi-Automated Systematic Review BACKGROUND: Demographic and sociobehavioral factors are strong drivers of HIV infection rates in sub-Saharan Africa. These factors are often studied in qualitative research but ignored in quantitative analyses. However, they provide in-depth insight into the local behavior and may help to improve HIV prevention.
OBJECTIVE: To obtain a comprehensive overview of the sociobehavioral factors influencing HIV prevalence and incidence in Malawi, we systematically reviewed the literature using a newly programmed tool for automatizing part of the systematic review process.
METHODS: Due to the choice of broad search terms (""HIV AND Malawi""), our preliminary search revealed many thousands of articles. We, therefore, developed a Python tool to automatically extract, process, and categorize open-access articles published from January 1, 1987 to October 1, 2019 in the PubMed, PubMed Central, JSTOR, Paperity, and arXiV databases. We then used a topic modelling algorithm to classify and identify publications of interest.
RESULTS: Our tool extracted 22,709 unique articles; 16,942 could be further processed. After topic modelling, 519 of these were clustered into relevant topics, of which 20 were kept after manual screening. We retrieved 7 more publications after examining the references so that 27 publications were finally included in the review. Reducing the 16,942 articles to 519 potentially relevant articles using the software took 5 days. Several factors contributing to the risk of HIV infection were identified, including religion, gender and relationship dynamics, beliefs, and sociobehavioral attitudes.
CONCLUSIONS: Our software does not replace traditional systematic reviews, but it returns useful results to broad queries of open-access literature in under a week, without a priori knowledge. This produces a ""seed dataset"" of relevance that could be further developed. It identified known factors and factors that may be specific to Malawi. In the future, we aim to expand the tool by adding more social science databases and applying it to other sub-Saharan African countries.",0
34298499,Determinants of Shielding Behavior During the COVID-19 Pandemic and Associations With Well-being Among National Health Service Patients: Longitudinal Observational Study,"Bachtiger P, Adamson A, Maclean WA, Kelshiker MA, Quint JK, Peters NS.",JMIR Public Health Surveill. 2021 Sep 20;7(9):e30460. doi: 10.2196/30460.,Bachtiger P,JMIR Public Health Surveill,2021,23-07-2021,PMC8454693,,10.2196/30460,"BACKGROUND: The UK National Health Service (NHS) classified 2.2 million people as clinically extremely vulnerable (CEV) during the first wave of the 2020 COVID-19 pandemic, advising them to ""shield"" (to not leave home for any reason).
OBJECTIVE: The aim of this study was to measure the determinants of shielding behavior and associations with well-being in a large NHS patient population for informing future health policy.
METHODS: Patients contributing to an ongoing longitudinal participatory epidemiology study (Longitudinal Effects on Wellbeing of the COVID-19 Pandemic [LoC-19], n=42,924) received weekly email invitations to complete questionnaires (17-week shielding period starting April 9, 2020) within their NHS personal electronic health record. Question items focused on well-being. Participants were stratified into four groups by self-reported CEV status (qualifying condition) and adoption of shielding behavior (baselined at week 1 or 2). The distribution of CEV criteria was reported alongside situational variables and univariable and multivariable logistic regression. Longitudinal trends in physical and mental well-being were displayed graphically. Free-text responses reporting variables impacting well-being were semiquantified using natural language processing. In the lead up to a second national lockdown (October 23, 2020), a follow-up questionnaire evaluated subjective concern if further shielding was advised.
RESULTS: The study included 7240 participants. In the CEV group (n=2391), 1133 (47.3%) assumed shielding behavior at baseline, compared with 633 (13.0%) in the non-CEV group (n=4849). CEV participants who shielded were more likely to be Asian (odds ratio [OR] 2.02, 95% CI 1.49-2.76), female (OR 1.24, 95% CI 1.05-1.45), older (OR per year increase 1.01, 95% CI 1.00-1.02), living in a home with an outdoor space (OR 1.34, 95% CI 1.06-1.70) or three to four other inhabitants (three: OR 1.49, 95% CI 1.15-1.94; four: OR 1.49, 95% CI 1.10-2.01), or solid organ transplant recipients (OR 2.85, 95% CI 2.18-3.77), or have severe chronic lung disease (OR 1.63, 95% CI 1.30-2.04). Receipt of a government letter advising shielding was reported in 1115 (46.6%) CEV participants and 180 (3.7%) non-CEV participants, and was associated with adopting shielding behavior (OR 3.34, 95% CI 2.82-3.95 and OR 2.88, 95% CI 2.04-3.99, respectively). In CEV participants, shielding at baseline was associated with a lower rating of mental well-being and physical well-being. Similar results were found for non-CEV participants. Concern for well-being if future shielding was required was most prevalent among CEV participants who had originally shielded.
CONCLUSIONS: Future health policy must balance the potential protection from COVID-19 against our findings that shielding negatively impacted well-being and was adopted in many in whom it was not indicated and variably in whom it was indicated. This therefore also requires clearer public health messaging and support for well-being if shielding is to be advised in future pandemic scenarios.","Determinants of Shielding Behavior During the COVID-19 Pandemic and Associations With Well-being Among National Health Service Patients: Longitudinal Observational Study BACKGROUND: The UK National Health Service (NHS) classified 2.2 million people as clinically extremely vulnerable (CEV) during the first wave of the 2020 COVID-19 pandemic, advising them to ""shield"" (to not leave home for any reason).
OBJECTIVE: The aim of this study was to measure the determinants of shielding behavior and associations with well-being in a large NHS patient population for informing future health policy.
METHODS: Patients contributing to an ongoing longitudinal participatory epidemiology study (Longitudinal Effects on Wellbeing of the COVID-19 Pandemic [LoC-19], n=42,924) received weekly email invitations to complete questionnaires (17-week shielding period starting April 9, 2020) within their NHS personal electronic health record. Question items focused on well-being. Participants were stratified into four groups by self-reported CEV status (qualifying condition) and adoption of shielding behavior (baselined at week 1 or 2). The distribution of CEV criteria was reported alongside situational variables and univariable and multivariable logistic regression. Longitudinal trends in physical and mental well-being were displayed graphically. Free-text responses reporting variables impacting well-being were semiquantified using natural language processing. In the lead up to a second national lockdown (October 23, 2020), a follow-up questionnaire evaluated subjective concern if further shielding was advised.
RESULTS: The study included 7240 participants. In the CEV group (n=2391), 1133 (47.3%) assumed shielding behavior at baseline, compared with 633 (13.0%) in the non-CEV group (n=4849). CEV participants who shielded were more likely to be Asian (odds ratio [OR] 2.02, 95% CI 1.49-2.76), female (OR 1.24, 95% CI 1.05-1.45), older (OR per year increase 1.01, 95% CI 1.00-1.02), living in a home with an outdoor space (OR 1.34, 95% CI 1.06-1.70) or three to four other inhabitants (three: OR 1.49, 95% CI 1.15-1.94; four: OR 1.49, 95% CI 1.10-2.01), or solid organ transplant recipients (OR 2.85, 95% CI 2.18-3.77), or have severe chronic lung disease (OR 1.63, 95% CI 1.30-2.04). Receipt of a government letter advising shielding was reported in 1115 (46.6%) CEV participants and 180 (3.7%) non-CEV participants, and was associated with adopting shielding behavior (OR 3.34, 95% CI 2.82-3.95 and OR 2.88, 95% CI 2.04-3.99, respectively). In CEV participants, shielding at baseline was associated with a lower rating of mental well-being and physical well-being. Similar results were found for non-CEV participants. Concern for well-being if future shielding was required was most prevalent among CEV participants who had originally shielded.
CONCLUSIONS: Future health policy must balance the potential protection from COVID-19 against our findings that shielding negatively impacted well-being and was adopted in many in whom it was not indicated and variably in whom it was indicated. This therefore also requires clearer public health messaging and support for well-being if shielding is to be advised in future pandemic scenarios.",0
39546783,AI for Analyzing Mental Health Disorders Among Social Media Users: Quarter-Century Narrative Review of Progress and Challenges,"Owen D, Lynham AJ, Smart SE, Pardiñas AF, Camacho Collados J.",J Med Internet Res. 2024 Nov 15;26:e59225. doi: 10.2196/59225.,Owen D,J Med Internet Res,2024,15-11-2024,PMC11607554,,10.2196/59225,"BACKGROUND: Mental health disorders are currently the main contributor to poor quality of life and years lived with disability. Symptoms common to many mental health disorders lead to impairments or changes in the use of language, which are observable in the routine use of social media. Detection of these linguistic cues has been explored throughout the last quarter century, but interest and methodological development have burgeoned following the COVID-19 pandemic. The next decade may see the development of reliable methods for predicting mental health status using social media data. This might have implications for clinical practice and public health policy, particularly in the context of early intervention in mental health care.
OBJECTIVE: This study aims to examine the state of the art in methods for predicting mental health statuses of social media users. Our focus is the development of artificial intelligence-driven methods, particularly natural language processing, for analyzing large volumes of written text. This study details constraints affecting research in this area. These include the dearth of high-quality public datasets for methodological benchmarking and the need to adopt ethical and privacy frameworks acknowledging the stigma experienced by those with a mental illness.
METHODS: A Google Scholar search yielded peer-reviewed articles dated between 1999 and 2024. We manually grouped the articles by 4 primary areas of interest: datasets on social media and mental health, methods for predicting mental health status, longitudinal analyses of mental health, and ethical aspects of the data and analysis of mental health. Selected articles from these groups formed our narrative review.
RESULTS: Larger datasets with precise dates of participants' diagnoses are needed to support the development of methods for predicting mental health status, particularly in severe disorders such as schizophrenia. Inviting users to donate their social media data for research purposes could help overcome widespread ethical and privacy concerns. In any event, multimodal methods for predicting mental health status appear likely to provide advancements that may not be achievable using natural language processing alone.
CONCLUSIONS: Multimodal methods for predicting mental health status from voice, image, and video-based social media data need to be further developed before they may be considered for adoption in health care, medical support, or as consumer-facing products. Such methods are likely to garner greater public confidence in their efficacy than those that rely on text alone. To achieve this, more high-quality social media datasets need to be made available and privacy concerns regarding the use of these data must be formally addressed. A social media platform feature that invites users to share their data upon publication is a possible solution. Finally, a review of literature studying the effects of social media use on a user's depression and anxiety is merited.","AI for Analyzing Mental Health Disorders Among Social Media Users: Quarter-Century Narrative Review of Progress and Challenges BACKGROUND: Mental health disorders are currently the main contributor to poor quality of life and years lived with disability. Symptoms common to many mental health disorders lead to impairments or changes in the use of language, which are observable in the routine use of social media. Detection of these linguistic cues has been explored throughout the last quarter century, but interest and methodological development have burgeoned following the COVID-19 pandemic. The next decade may see the development of reliable methods for predicting mental health status using social media data. This might have implications for clinical practice and public health policy, particularly in the context of early intervention in mental health care.
OBJECTIVE: This study aims to examine the state of the art in methods for predicting mental health statuses of social media users. Our focus is the development of artificial intelligence-driven methods, particularly natural language processing, for analyzing large volumes of written text. This study details constraints affecting research in this area. These include the dearth of high-quality public datasets for methodological benchmarking and the need to adopt ethical and privacy frameworks acknowledging the stigma experienced by those with a mental illness.
METHODS: A Google Scholar search yielded peer-reviewed articles dated between 1999 and 2024. We manually grouped the articles by 4 primary areas of interest: datasets on social media and mental health, methods for predicting mental health status, longitudinal analyses of mental health, and ethical aspects of the data and analysis of mental health. Selected articles from these groups formed our narrative review.
RESULTS: Larger datasets with precise dates of participants' diagnoses are needed to support the development of methods for predicting mental health status, particularly in severe disorders such as schizophrenia. Inviting users to donate their social media data for research purposes could help overcome widespread ethical and privacy concerns. In any event, multimodal methods for predicting mental health status appear likely to provide advancements that may not be achievable using natural language processing alone.
CONCLUSIONS: Multimodal methods for predicting mental health status from voice, image, and video-based social media data need to be further developed before they may be considered for adoption in health care, medical support, or as consumer-facing products. Such methods are likely to garner greater public confidence in their efficacy than those that rely on text alone. To achieve this, more high-quality social media datasets need to be made available and privacy concerns regarding the use of these data must be formally addressed. A social media platform feature that invites users to share their data upon publication is a possible solution. Finally, a review of literature studying the effects of social media use on a user's depression and anxiety is merited.",0
32511492,"Extending A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter to England, UK","Golder S, Klein AZ, Magge A, O'Connor K, Cai H, Weissenbacher D, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2020 May 8:2020.05.05.20083436. doi: 10.1101/2020.05.05.20083436.,Golder S,medRxiv,2020,09-06-2020,PMC7273260,,10.1101/2020.05.05.20083436,"The rapidly evolving COVID-19 pandemic presents challenges for actively monitoring its transmission. In this study, we extend a social media mining approach used in the US to automatically identify personal reports of COVID-19 on Twitter in England, UK. The findings indicate that natural language processing and machine learning framework could help provide an early indication of the chronological and geographical distribution of COVID-19 in England.","Extending A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter to England, UK The rapidly evolving COVID-19 pandemic presents challenges for actively monitoring its transmission. In this study, we extend a social media mining approach used in the US to automatically identify personal reports of COVID-19 on Twitter in England, UK. The findings indicate that natural language processing and machine learning framework could help provide an early indication of the chronological and geographical distribution of COVID-19 in England.",0
38516566,Social vulnerabilities among immigrants and refugees in emergencies and disasters: a systematic review,"Doust Mohammadi MM, Salmani I, Farahmandnia H.",Front Public Health. 2024 Mar 7;11:1235464. doi: 10.3389/fpubh.2023.1235464. eCollection 2023.,Doust Mohammadi MM,Front Public Health,2024,22-03-2024,PMC10956690,,10.3389/fpubh.2023.1235464,"BACKGROUND: Due to cultural, economic, and societal factors, immigrants and refugees are pivotal groups in dealing with social vulnerability in disasters. Ignoring or inadequate attention to those groups in preparing for and responding to disasters and health emergencies could decrease the effectiveness of efforts. This article aims to identify the most basic social vulnerabilities among immigrants and refugees and provide effective solutions to alleviate or eliminate these vulnerabilities.
METHODS: This systematic review was performed based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The main keywords include Social Vulnerabilities, Immigrants, Refugees, and Disasters. All articles published up to February 2023 were reviewed regardless of language and location. A total of 575 articles were extracted from SCOPUS, Web of Science, ScienceDirect, ProQuest, PubMed, EMBASE, and PsycINFO databases, and finally, 14 articles were selected for full-text analysis. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) was used to evaluate the quality of the selected articles.
RESULTS: Fourteen articles including 4 qualitative and 10 quantitative articles were selected and analyzed in this review. The findings showed: 1. According to the consensus of the studies, the most vulnerable people who need urgent care during an epidemic due to their special conditions are immigrants and refugees; 2. In most countries, no database provides reliable, up-to-date, and accurate statistics about these people; 3. Refugees usually hesitate to express their vulnerability and receive services due to the fear of deportation; and 4. The main challenges faced by refugees are socio-economic problems such as language problems, lack of emotional and social support, and living in crowded places.
CONCLUSION: Considering the prevalence of migration among countries, it is essential to identify the social problems and vulnerabilities of immigrants and provide effective solutions to cope with their challenges, especially during crises and emergencies.
SYSTEMATIC REVIEW REGISTRATION: https://clinicaltrials.gov/, identifier CRD42022371345.","Social vulnerabilities among immigrants and refugees in emergencies and disasters: a systematic review BACKGROUND: Due to cultural, economic, and societal factors, immigrants and refugees are pivotal groups in dealing with social vulnerability in disasters. Ignoring or inadequate attention to those groups in preparing for and responding to disasters and health emergencies could decrease the effectiveness of efforts. This article aims to identify the most basic social vulnerabilities among immigrants and refugees and provide effective solutions to alleviate or eliminate these vulnerabilities.
METHODS: This systematic review was performed based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The main keywords include Social Vulnerabilities, Immigrants, Refugees, and Disasters. All articles published up to February 2023 were reviewed regardless of language and location. A total of 575 articles were extracted from SCOPUS, Web of Science, ScienceDirect, ProQuest, PubMed, EMBASE, and PsycINFO databases, and finally, 14 articles were selected for full-text analysis. The Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) was used to evaluate the quality of the selected articles.
RESULTS: Fourteen articles including 4 qualitative and 10 quantitative articles were selected and analyzed in this review. The findings showed: 1. According to the consensus of the studies, the most vulnerable people who need urgent care during an epidemic due to their special conditions are immigrants and refugees; 2. In most countries, no database provides reliable, up-to-date, and accurate statistics about these people; 3. Refugees usually hesitate to express their vulnerability and receive services due to the fear of deportation; and 4. The main challenges faced by refugees are socio-economic problems such as language problems, lack of emotional and social support, and living in crowded places.
CONCLUSION: Considering the prevalence of migration among countries, it is essential to identify the social problems and vulnerabilities of immigrants and provide effective solutions to cope with their challenges, especially during crises and emergencies.
SYSTEMATIC REVIEW REGISTRATION: https://clinicaltrials.gov/, identifier CRD42022371345.",0
33620282,"Trends of pulmonary fungal infections from 2013 to 2019: an AI-based real-world observational study in Guangzhou, China","Li Z, Li Y, Chen Y, Li J, Li S, Li C, Lin Y, Jian W, Shi J, Zhan Y, Cheng J, Zheng J, Zhong N, Ye F.",Emerg Microbes Infect. 2021 Dec;10(1):450-460. doi: 10.1080/22221751.2021.1894902.,Li Z,Emerg Microbes Infect,2021,23-02-2021,PMC7971272,,10.1080/22221751.2021.1894902,"Recently, the prevalence trend of pulmonary fungal infection (PFI) has rapidly increased. Changes in the risk factors for, distributions of underlying diseases associated with and clinical characteristics of some individual PFIs have been reported in the past decade. However, data regarding PFIs remain uncertain. This study reports the epidemiological characteristics and trends of PFIs over time in recent years. We applied an automated natural language processing (NLP) system to extract clinically relevant information from the electronic health records (EHRs) of PFI patients at the First Affiliated Hospital of Guangzhou Medical University. Then, a trend analysis was performed. From January 1, 2013, to December 31, 2019, 40,504 inpatients and 219,414 outpatients with respiratory diseases were screened, in which 1368 inpatients and 1313 outpatients with PFI were identified. These patients were from throughout the country, but most patients were from southern China. Upward trends in PFIs were observed in both hospitalized patients and outpatients (P&lt;0.05). The stratification by age showed that the incidence of hospitalized patients aged 14-30 years exhibited the most obvious upward trend, increasing from 9.5 per 1000 patients in 2013 to 88.3 per 1000 patients in 2019. Aspergillosis (56.69%) was the most common PFI, but notably, the incidence rates of Talaromyces marneffei, which used to be considered uncommon, exhibited the most rapid increases. In younger PFI patients, the incidence and trend of PFIs have increased. Infection by previously uncommon pathogens has also gradually increased. Increased attention should be paid to young PFI patients and uncommon PFI pathogen infections.","Trends of pulmonary fungal infections from 2013 to 2019: an AI-based real-world observational study in Guangzhou, China Recently, the prevalence trend of pulmonary fungal infection (PFI) has rapidly increased. Changes in the risk factors for, distributions of underlying diseases associated with and clinical characteristics of some individual PFIs have been reported in the past decade. However, data regarding PFIs remain uncertain. This study reports the epidemiological characteristics and trends of PFIs over time in recent years. We applied an automated natural language processing (NLP) system to extract clinically relevant information from the electronic health records (EHRs) of PFI patients at the First Affiliated Hospital of Guangzhou Medical University. Then, a trend analysis was performed. From January 1, 2013, to December 31, 2019, 40,504 inpatients and 219,414 outpatients with respiratory diseases were screened, in which 1368 inpatients and 1313 outpatients with PFI were identified. These patients were from throughout the country, but most patients were from southern China. Upward trends in PFIs were observed in both hospitalized patients and outpatients (P&lt;0.05). The stratification by age showed that the incidence of hospitalized patients aged 14-30 years exhibited the most obvious upward trend, increasing from 9.5 per 1000 patients in 2013 to 88.3 per 1000 patients in 2019. Aspergillosis (56.69%) was the most common PFI, but notably, the incidence rates of Talaromyces marneffei, which used to be considered uncommon, exhibited the most rapid increases. In younger PFI patients, the incidence and trend of PFIs have increased. Infection by previously uncommon pathogens has also gradually increased. Increased attention should be paid to young PFI patients and uncommon PFI pathogen infections.",0
32511608,A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter,"Klein AZ, Magge A, O'Connor KMS, Cai H, Weissenbacher D, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2020 Apr 22:2020.04.19.20069948. doi: 10.1101/2020.04.19.20069948.,Klein AZ,medRxiv,2020,09-06-2020,PMC7276035,,10.1101/2020.04.19.20069948,"The rapidly evolving outbreak of COVID-19 presents challenges for actively monitoring its spread. In this study, we assessed a social media mining approach for automatically analyzing the chronological and geographical distribution of users in the United States reporting personal information related to COVID-19 on Twitter. The results suggest that our natural language processing and machine learning framework could help provide an early indication of the spread of COVID-19.","A Chronological and Geographical Analysis of Personal Reports of COVID-19 on Twitter The rapidly evolving outbreak of COVID-19 presents challenges for actively monitoring its spread. In this study, we assessed a social media mining approach for automatically analyzing the chronological and geographical distribution of users in the United States reporting personal information related to COVID-19 on Twitter. The results suggest that our natural language processing and machine learning framework could help provide an early indication of the spread of COVID-19.",0
37546903,Looking at the Full Picture: Utilizing Topic Modeling to Determine Disease-Associated Microbiome Communities,"Shrode RL, Ollberding NJ, Mangalam AK.",bioRxiv [Preprint]. 2023 Jul 25:2023.07.21.549984. doi: 10.1101/2023.07.21.549984.,Shrode RL,bioRxiv,2023,07-08-2023,PMC10401927,,10.1101/2023.07.21.549984,"The microbiome is a complex micro-ecosystem that provides the host with pathogen defense, food metabolism, and other vital processes. Alterations of the microbiome (dysbiosis) have been linked with a number of diseases such as cancers, multiple sclerosis (MS), Alzheimer's disease, etc. Generally, differential abundance testing between the healthy and patient groups is performed to identify important bacteria (enriched or depleted in one group). However, simply providing a singular species of bacteria to an individual lacking that species for health improvement has not been as successful as fecal matter transplant (FMT) therapy. Interestingly, FMT therapy transfers the entire gut microbiome of a healthy (or mixture of) individual to an individual with a disease. FMTs do, however, have limited success, possibly due to concerns that not all bacteria in the community may be responsible for the healthy phenotype. Therefore, it is important to identify the community of microorganisms linked to the health as well as the disease state of the host. Here we applied topic modeling, a natural language processing tool, to assess latent interactions occurring among microbes; thus, providing a representation of the community of bacteria relevant to healthy vs. disease state. Specifically, we utilized our previously published data that studied the gut microbiome of patients with relapsing-remitting MS (RRMS), a neurodegenerative autoimmune disease that has been linked to a variety of factors, including a dysbiotic gut microbiome. With topic modeling we identified communities of bacteria associated with RRMS, including genera previously discovered, but also other taxa that would have been overlooked simply with differential abundance testing. Our work shows that topic modeling can be a useful tool for analyzing the microbiome in dysbiosis and that it could be considered along with the commonly utilized differential abundance tests to better understand the role of the gut microbiome in health and disease.","Looking at the Full Picture: Utilizing Topic Modeling to Determine Disease-Associated Microbiome Communities The microbiome is a complex micro-ecosystem that provides the host with pathogen defense, food metabolism, and other vital processes. Alterations of the microbiome (dysbiosis) have been linked with a number of diseases such as cancers, multiple sclerosis (MS), Alzheimer's disease, etc. Generally, differential abundance testing between the healthy and patient groups is performed to identify important bacteria (enriched or depleted in one group). However, simply providing a singular species of bacteria to an individual lacking that species for health improvement has not been as successful as fecal matter transplant (FMT) therapy. Interestingly, FMT therapy transfers the entire gut microbiome of a healthy (or mixture of) individual to an individual with a disease. FMTs do, however, have limited success, possibly due to concerns that not all bacteria in the community may be responsible for the healthy phenotype. Therefore, it is important to identify the community of microorganisms linked to the health as well as the disease state of the host. Here we applied topic modeling, a natural language processing tool, to assess latent interactions occurring among microbes; thus, providing a representation of the community of bacteria relevant to healthy vs. disease state. Specifically, we utilized our previously published data that studied the gut microbiome of patients with relapsing-remitting MS (RRMS), a neurodegenerative autoimmune disease that has been linked to a variety of factors, including a dysbiotic gut microbiome. With topic modeling we identified communities of bacteria associated with RRMS, including genera previously discovered, but also other taxa that would have been overlooked simply with differential abundance testing. Our work shows that topic modeling can be a useful tool for analyzing the microbiome in dysbiosis and that it could be considered along with the commonly utilized differential abundance tests to better understand the role of the gut microbiome in health and disease.",0
31824670,Evidence-based Clinical Decision Support Systems for the prediction and detection of three disease states in critical care: A systematic literature review,"Medic G, Kosaner Kließ M, Atallah L, Weichert J, Panda S, Postma M, El-Kerdi A.",F1000Res. 2019 Oct 8;8:1728. doi: 10.12688/f1000research.20498.2. eCollection 2019.,Medic G,F1000Res,2019,14-12-2019,PMC6894361,,10.12688/f1000research.20498.2,"Background: Clinical decision support (CDS) systems have emerged as tools providing intelligent decision making to address challenges of critical care. CDS systems can be based on existing guidelines or best practices; and can also utilize machine learning to provide a diagnosis, recommendation, or therapy course. Methods: This research aimed to identify evidence-based study designs and outcome measures to determine the clinical effectiveness of clinical decision support systems in the detection and prediction of hemodynamic instability, respiratory distress, and infection within critical care settings. PubMed, ClinicalTrials.gov and Cochrane Database of Systematic Reviews were systematically searched to identify primary research published in English between 2013 and 2018. Studies conducted in the USA, Canada, UK, Germany and France with more than 10 participants per arm were included. Results: In studies on hemodynamic instability, the prediction and management of septic shock were the most researched topics followed by the early prediction of heart failure. For respiratory distress, the most popular topics were pneumonia detection and prediction followed by pulmonary embolisms. Given the importance of imaging and clinical notes, this area combined Machine Learning with image analysis and natural language processing. In studies on infection, the most researched areas were the detection, prediction, and management of sepsis, surgical site infections, as well as acute kidney injury. Overall, a variety of Machine Learning algorithms were utilized frequently, particularly support vector machines, boosting techniques, random forest classifiers and neural networks. Sensitivity, specificity, and ROC AUC were the most frequently reported performance measures. Conclusion: This review showed an increasing use of Machine Learning for CDS in all three areas. Large datasets are required for training these algorithms; making it imperative to appropriately address, challenges such as class imbalance, correct labelling of data and missing data. Recommendations are formulated for the development and successful adoption of CDS systems.","Evidence-based Clinical Decision Support Systems for the prediction and detection of three disease states in critical care: A systematic literature review Background: Clinical decision support (CDS) systems have emerged as tools providing intelligent decision making to address challenges of critical care. CDS systems can be based on existing guidelines or best practices; and can also utilize machine learning to provide a diagnosis, recommendation, or therapy course. Methods: This research aimed to identify evidence-based study designs and outcome measures to determine the clinical effectiveness of clinical decision support systems in the detection and prediction of hemodynamic instability, respiratory distress, and infection within critical care settings. PubMed, ClinicalTrials.gov and Cochrane Database of Systematic Reviews were systematically searched to identify primary research published in English between 2013 and 2018. Studies conducted in the USA, Canada, UK, Germany and France with more than 10 participants per arm were included. Results: In studies on hemodynamic instability, the prediction and management of septic shock were the most researched topics followed by the early prediction of heart failure. For respiratory distress, the most popular topics were pneumonia detection and prediction followed by pulmonary embolisms. Given the importance of imaging and clinical notes, this area combined Machine Learning with image analysis and natural language processing. In studies on infection, the most researched areas were the detection, prediction, and management of sepsis, surgical site infections, as well as acute kidney injury. Overall, a variety of Machine Learning algorithms were utilized frequently, particularly support vector machines, boosting techniques, random forest classifiers and neural networks. Sensitivity, specificity, and ROC AUC were the most frequently reported performance measures. Conclusion: This review showed an increasing use of Machine Learning for CDS in all three areas. Large datasets are required for training these algorithms; making it imperative to appropriately address, challenges such as class imbalance, correct labelling of data and missing data. Recommendations are formulated for the development and successful adoption of CDS systems.",0
38814687,Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development and Validation,"Invernici F, Bernasconi A, Ceri S.",J Med Internet Res. 2024 May 30;26:e52655. doi: 10.2196/52655.,Invernici F,J Med Internet Res,2024,30-05-2024,PMC11176882,,10.2196/52655,"BACKGROUND: Since the beginning of the COVID-19 pandemic, >1 million studies have been collected within the COVID-19 Open Research Dataset, a corpus of manuscripts created to accelerate research against the disease. Their related abstracts hold a wealth of information that remains largely unexplored and difficult to search due to its unstructured nature. Keyword-based search is the standard approach, which allows users to retrieve the documents of a corpus that contain (all or some of) the words in a target list. This type of search, however, does not provide visual support to the task and is not suited to expressing complex queries or compensating for missing specifications.
OBJECTIVE: This study aims to consider small graphs of concepts and exploit them for expressing graph searches over existing COVID-19-related literature, leveraging the increasing use of graphs to represent and query scientific knowledge and providing a user-friendly search and exploration experience.
METHODS: We considered the COVID-19 Open Research Dataset corpus and summarized its content by annotating the publications' abstracts using terms selected from the Unified Medical Language System and the Ontology of Coronavirus Infectious Disease. Then, we built a co-occurrence network that includes all relevant concepts mentioned in the corpus, establishing connections when their mutual information is relevant. A sophisticated graph query engine was built to allow the identification of the best matches of graph queries on the network. It also supports partial matches and suggests potential query completions using shortest paths.
RESULTS: We built a large co-occurrence network, consisting of 128,249 entities and 47,198,965 relationships; the GRAPH-SEARCH interface allows users to explore the network by formulating or adapting graph queries; it produces a bibliography of publications, which are globally ranked; and each publication is further associated with the specific parts of the query that it explains, thereby allowing the user to understand each aspect of the matching.
CONCLUSIONS: Our approach supports the process of query formulation and evidence search upon a large text corpus; it can be reapplied to any scientific domain where documents corpora and curated ontologies are made available.","Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development and Validation BACKGROUND: Since the beginning of the COVID-19 pandemic, >1 million studies have been collected within the COVID-19 Open Research Dataset, a corpus of manuscripts created to accelerate research against the disease. Their related abstracts hold a wealth of information that remains largely unexplored and difficult to search due to its unstructured nature. Keyword-based search is the standard approach, which allows users to retrieve the documents of a corpus that contain (all or some of) the words in a target list. This type of search, however, does not provide visual support to the task and is not suited to expressing complex queries or compensating for missing specifications.
OBJECTIVE: This study aims to consider small graphs of concepts and exploit them for expressing graph searches over existing COVID-19-related literature, leveraging the increasing use of graphs to represent and query scientific knowledge and providing a user-friendly search and exploration experience.
METHODS: We considered the COVID-19 Open Research Dataset corpus and summarized its content by annotating the publications' abstracts using terms selected from the Unified Medical Language System and the Ontology of Coronavirus Infectious Disease. Then, we built a co-occurrence network that includes all relevant concepts mentioned in the corpus, establishing connections when their mutual information is relevant. A sophisticated graph query engine was built to allow the identification of the best matches of graph queries on the network. It also supports partial matches and suggests potential query completions using shortest paths.
RESULTS: We built a large co-occurrence network, consisting of 128,249 entities and 47,198,965 relationships; the GRAPH-SEARCH interface allows users to explore the network by formulating or adapting graph queries; it produces a bibliography of publications, which are globally ranked; and each publication is further associated with the specific parts of the query that it explains, thereby allowing the user to understand each aspect of the matching.
CONCLUSIONS: Our approach supports the process of query formulation and evidence search upon a large text corpus; it can be reapplied to any scientific domain where documents corpora and curated ontologies are made available.",0
35789657,"The needs of cancer patients during the COVID-19 pandemic-psychosocial, ethical and spiritual aspects-systematic review","Zapała J, Matecka M, Zok A, Baum E.",PeerJ. 2022 Jun 29;10:e13480. doi: 10.7717/peerj.13480. eCollection 2022.,Zapała J,PeerJ,2022,05-07-2022,PMC9250307,,10.7717/peerj.13480,"The COVID-19 pandemic resulted in unprecedented changes in the functioning of the health care system, which were connected with the occurrence of new challenges for both the health care system's employees and for the patients. The purpose of the present article is to analyze the needs of persons with oncological diseases. Taking into account the multiple aspects of the term health, psychological, social, and existential needs of the patients were analyzed. This article is directed mainly at persons who remain in a direct therapeutic relation with a patient. It is to facilitate recognizing the needs of ill people and to increase sensitivity to the issue of maintaining or improving the well-being of patients which requires paying special attention to their psychological, social, and existential needs during the period of hindered access to the health care system. This systematic review takes advantage of quantitative and qualitative methods of text analysis with phenomenological analysis factored in. The COVID-19 pandemic resulted in the appearance of new problems in the population of oncological patients or it made the existing problems more severe. As a consequence, it made it significantly more difficult to meet their needs on various levels and sometimes it even made it impossible. It seems necessary to determine and introduce strategies to ensure that patients with oncological diseases have access to psychological and spiritual support in the period of the pandemic.","The needs of cancer patients during the COVID-19 pandemic-psychosocial, ethical and spiritual aspects-systematic review The COVID-19 pandemic resulted in unprecedented changes in the functioning of the health care system, which were connected with the occurrence of new challenges for both the health care system's employees and for the patients. The purpose of the present article is to analyze the needs of persons with oncological diseases. Taking into account the multiple aspects of the term health, psychological, social, and existential needs of the patients were analyzed. This article is directed mainly at persons who remain in a direct therapeutic relation with a patient. It is to facilitate recognizing the needs of ill people and to increase sensitivity to the issue of maintaining or improving the well-being of patients which requires paying special attention to their psychological, social, and existential needs during the period of hindered access to the health care system. This systematic review takes advantage of quantitative and qualitative methods of text analysis with phenomenological analysis factored in. The COVID-19 pandemic resulted in the appearance of new problems in the population of oncological patients or it made the existing problems more severe. As a consequence, it made it significantly more difficult to meet their needs on various levels and sometimes it even made it impossible. It seems necessary to determine and introduce strategies to ensure that patients with oncological diseases have access to psychological and spiritual support in the period of the pandemic.",0
38045356,Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data,"Klein AZ, Kunatharaju S, Golder S, Levine LD, Figueiredo JC, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2023 Nov 21:2023.11.17.23298696. doi: 10.1101/2023.11.17.23298696.,Klein AZ,medRxiv,2023,04-12-2023,PMC10690358,,10.1101/2023.11.17.23298696,"BACKGROUND: Preterm birth, defined as birth at <37 weeks of gestation, is the leading cause of neonatal death globally and, together with low birthweight, the second leading cause of infant mortality in the United States. There is mounting evidence that COVID-19 infection during pregnancy is associated with an increased risk of preterm birth; however, data remain limited by trimester of infection. The ability to study COVID-19 infection during the earlier stages of pregnancy has been limited by available sources of data. The objective of this study was to use self-reports in large-scale, longitudinal social media data to assess the association between trimester of COVID-19 infection and preterm birth.
METHODS: In this retrospective cohort study, we used natural language processing and machine learning, followed by manual validation, to identify pregnant Twitter users and to search their longitudinal collection of publicly available tweets for reports of COVID-19 infection during pregnancy and, subsequently, a preterm birth or term birth (i.e., a gestational age ≥37 weeks) outcome. Among the users who reported their pregnancy on Twitter, we also identified a 1:1 age-matched control group, consisting of users with a due date prior to January 1, 2020-that is, without COVID-19 infection during pregnancy. We calculated the odds ratios (ORs) with 95% confidence intervals (CIs) to compare the overall rates of preterm birth for pregnancies with and without COVID-19 infection and by timing of infection: first trimester (weeks 1-13), second trimester (weeks 1427), or third trimester (weeks 28-36).
RESULTS: Through August 2022, we identified 298 Twitter users who reported COVID-19 infection during pregnancy, a preterm birth or term birth outcome, and maternal age: 94 (31.5%) with first-trimester infection, 110 (36.9%) second-trimester infection, and 95 (31.9%) third-trimester infection. In total, 26 (8.8%) of these 298 users reported preterm birth: 8 (8.5%) were infected during the first trimester, 7 (6.4%) were infected during the second trimester, and 12 (12.6%) were infected during the third trimester. In the 1:1 age-matched control group, 13 (4.4%) of the 298 users reported preterm birth. Overall, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection compared to those without (OR 2.1, 95% CI 1.06-4.16). In particular, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection during the third trimester (OR 3.17, CI 1.39-7.21).
CONCLUSION: The results of our study suggest that COVID-19 infection particularly during the third trimester is associated with an increased risk of preterm birth.","Association Between COVID-19 During Pregnancy and Preterm Birth by Trimester of Infection: A Retrospective Cohort Study Using Longitudinal Social Media Data BACKGROUND: Preterm birth, defined as birth at <37 weeks of gestation, is the leading cause of neonatal death globally and, together with low birthweight, the second leading cause of infant mortality in the United States. There is mounting evidence that COVID-19 infection during pregnancy is associated with an increased risk of preterm birth; however, data remain limited by trimester of infection. The ability to study COVID-19 infection during the earlier stages of pregnancy has been limited by available sources of data. The objective of this study was to use self-reports in large-scale, longitudinal social media data to assess the association between trimester of COVID-19 infection and preterm birth.
METHODS: In this retrospective cohort study, we used natural language processing and machine learning, followed by manual validation, to identify pregnant Twitter users and to search their longitudinal collection of publicly available tweets for reports of COVID-19 infection during pregnancy and, subsequently, a preterm birth or term birth (i.e., a gestational age ≥37 weeks) outcome. Among the users who reported their pregnancy on Twitter, we also identified a 1:1 age-matched control group, consisting of users with a due date prior to January 1, 2020-that is, without COVID-19 infection during pregnancy. We calculated the odds ratios (ORs) with 95% confidence intervals (CIs) to compare the overall rates of preterm birth for pregnancies with and without COVID-19 infection and by timing of infection: first trimester (weeks 1-13), second trimester (weeks 1427), or third trimester (weeks 28-36).
RESULTS: Through August 2022, we identified 298 Twitter users who reported COVID-19 infection during pregnancy, a preterm birth or term birth outcome, and maternal age: 94 (31.5%) with first-trimester infection, 110 (36.9%) second-trimester infection, and 95 (31.9%) third-trimester infection. In total, 26 (8.8%) of these 298 users reported preterm birth: 8 (8.5%) were infected during the first trimester, 7 (6.4%) were infected during the second trimester, and 12 (12.6%) were infected during the third trimester. In the 1:1 age-matched control group, 13 (4.4%) of the 298 users reported preterm birth. Overall, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection compared to those without (OR 2.1, 95% CI 1.06-4.16). In particular, the risk of preterm birth was significantly higher for pregnancies with COVID-19 infection during the third trimester (OR 3.17, CI 1.39-7.21).
CONCLUSION: The results of our study suggest that COVID-19 infection particularly during the third trimester is associated with an increased risk of preterm birth.",0
38805611,A Bayesian System to Detect and Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases: Algorithm Development and Validation,"Aronis JM, Ye Y, Espino J, Hochheiser H, Michaels MG, Cooper GF.",JMIR Public Health Surveill. 2024 Aug 13;10:e57349. doi: 10.2196/57349.,Aronis JM,JMIR Public Health Surveill,2024,28-05-2024,PMC11350309,,10.2196/57349,"BACKGROUND:  The early identification of outbreaks of both known and novel influenza-like illnesses (ILIs) is an important public health problem.
OBJECTIVE:  This study aimed to describe the design and testing of a tool that detects and tracks outbreaks of both known and novel ILIs, such as the SARS-CoV-2 worldwide pandemic, accurately and early.
METHODS:  This paper describes the ILI Tracker algorithm that first models the daily occurrence of a set of known ILIs in hospital emergency departments in a monitored region using findings extracted from patient care reports using natural language processing. We then show how the algorithm can be extended to detect and track the presence of an unmodeled disease that may represent a novel disease outbreak.
RESULTS:  We include results based on modeling diseases like influenza, respiratory syncytial virus, human metapneumovirus, and parainfluenza for 5 emergency departments in Allegheny County, Pennsylvania, from June 1, 2014, to May 31, 2015. We also include the results of detecting the outbreak of an unmodeled disease, which in retrospect was very likely an outbreak of the enterovirus D68 (EV-D68).
CONCLUSIONS:  The results reported in this paper provide support that ILI Tracker was able to track well the incidence of 4 modeled influenza-like diseases over a 1-year period, relative to laboratory-confirmed cases, and it was computationally efficient in doing so. The system was also able to detect a likely novel outbreak of EV-D68 early in an outbreak that occurred in Allegheny County in 2014 as well as clinically characterize that outbreak disease accurately.","A Bayesian System to Detect and Track Outbreaks of Influenza-Like Illnesses Including Novel Diseases: Algorithm Development and Validation BACKGROUND:  The early identification of outbreaks of both known and novel influenza-like illnesses (ILIs) is an important public health problem.
OBJECTIVE:  This study aimed to describe the design and testing of a tool that detects and tracks outbreaks of both known and novel ILIs, such as the SARS-CoV-2 worldwide pandemic, accurately and early.
METHODS:  This paper describes the ILI Tracker algorithm that first models the daily occurrence of a set of known ILIs in hospital emergency departments in a monitored region using findings extracted from patient care reports using natural language processing. We then show how the algorithm can be extended to detect and track the presence of an unmodeled disease that may represent a novel disease outbreak.
RESULTS:  We include results based on modeling diseases like influenza, respiratory syncytial virus, human metapneumovirus, and parainfluenza for 5 emergency departments in Allegheny County, Pennsylvania, from June 1, 2014, to May 31, 2015. We also include the results of detecting the outbreak of an unmodeled disease, which in retrospect was very likely an outbreak of the enterovirus D68 (EV-D68).
CONCLUSIONS:  The results reported in this paper provide support that ILI Tracker was able to track well the incidence of 4 modeled influenza-like diseases over a 1-year period, relative to laboratory-confirmed cases, and it was computationally efficient in doing so. The system was also able to detect a likely novel outbreak of EV-D68 early in an outbreak that occurred in Allegheny County in 2014 as well as clinically characterize that outbreak disease accurately.",0
35593186,Signs and symptoms to determine if a patient presenting in primary care or hospital outpatient settings has COVID-19,"Struyf T, Deeks JJ, Dinnes J, Takwoingi Y, Davenport C, Leeflang MM, Spijker R, Hooft L, Emperador D, Domen J, Tans A, Janssens S, Wickramasinghe D, Lannoy V, Horn SRA, Van den Bruel A; Cochrane COVID-19 Diagnostic Test Accuracy Group.",Cochrane Database Syst Rev. 2022 May 20;5(5):CD013665. doi: 10.1002/14651858.CD013665.pub3.,Struyf T,Cochrane Database Syst Rev,2022,20-05-2022,PMC9121352,,10.1002/14651858.CD013665.pub3,"BACKGROUND: COVID-19 illness is highly variable, ranging from infection with no symptoms through to pneumonia and life-threatening consequences. Symptoms such as fever, cough, or loss of sense of smell (anosmia) or taste (ageusia), can help flag early on if the disease is present. Such information could be used either to rule out COVID-19 disease, or to identify people who need to go for COVID-19 diagnostic tests. This is the second update of this review, which was first published in 2020.
OBJECTIVES: To assess the diagnostic accuracy of signs and symptoms to determine if a person presenting in primary care or to hospital outpatient settings, such as the emergency department or dedicated COVID-19 clinics, has COVID-19.
SEARCH METHODS: We undertook electronic searches up to 10 June 2021 in the University of Bern living search database. In addition, we checked repositories of COVID-19 publications. We used artificial intelligence text analysis to conduct an initial classification of documents. We did not apply any language restrictions.
SELECTION CRITERIA: Studies were eligible if they included people with clinically suspected COVID-19, or recruited known cases with COVID-19 and also controls without COVID-19 from a single-gate cohort. Studies were eligible when they recruited people presenting to primary care or hospital outpatient settings. Studies that included people who contracted SARS-CoV-2 infection while admitted to hospital were not eligible. The minimum eligible sample size of studies was 10 participants. All signs and symptoms were eligible for this review, including individual signs and symptoms or combinations. We accepted a range of reference standards.
DATA COLLECTION AND ANALYSIS: Pairs of review authors independently selected all studies, at both title and abstract, and full-text stage. They resolved any disagreements by discussion with a third review author. Two review authors independently extracted data and assessed risk of bias using the QUADAS-2 checklist, and resolved disagreements by discussion with a third review author. Analyses were restricted to prospective studies only. We presented sensitivity and specificity in paired forest plots, in receiver operating characteristic (ROC) space and in dumbbell plots. We estimated summary parameters using a bivariate random-effects meta-analysis whenever five or more primary prospective studies were available, and whenever heterogeneity across studies was deemed acceptable.
MAIN RESULTS: We identified 90 studies; for this update we focused on the results of 42 prospective studies with 52,608 participants. Prevalence of COVID-19 disease varied from 3.7% to 60.6% with a median of 27.4%. Thirty-five studies were set in emergency departments or outpatient test centres (46,878 participants), three in primary care settings (1230 participants), two in a mixed population of in- and outpatients in a paediatric hospital setting (493 participants), and two overlapping studies in nursing homes (4007 participants). The studies did not clearly distinguish mild COVID-19 disease from COVID-19 pneumonia, so we present the results for both conditions together. Twelve studies had a high risk of bias for selection of participants because they used a high level of preselection to decide whether reverse transcription polymerase chain reaction (RT-PCR) testing was needed, or because they enrolled a non-consecutive sample, or because they excluded individuals while they were part of the study base. We rated 36 of the 42 studies as high risk of bias for the index tests because there was little or no detail on how, by whom and when, the symptoms were measured. For most studies, eligibility for testing was dependent on the local case definition and testing criteria that were in effect at the time of the study, meaning most people who were included in studies had already been referred to health services based on the symptoms that we are evaluating in this review. The applicability of the results of this review iteration improved in comparison with the previous reviews. This version has more studies of people presenting to ambulatory settings, which is where the majority of assessments for COVID-19 take place. Only three studies presented any data on children separately, and only one focused specifically on older adults. We found data on 96 symptoms or combinations of signs and symptoms. Evidence on individual signs as diagnostic tests was rarely reported, so this review reports mainly on the diagnostic value of symptoms. Results were highly variable across studies. Most had very low sensitivity and high specificity. RT-PCR was the most often used reference standard (40/42 studies). Only cough (11 studies) had a summary sensitivity above 50% (62.4%, 95% CI 50.6% to 72.9%)); its specificity was low (45.4%, 95% CI 33.5% to 57.9%)). Presence of fever had a sensitivity of 37.6% (95% CI 23.4% to 54.3%) and a specificity of 75.2% (95% CI 56.3% to 87.8%). The summary positive likelihood ratio of cough was 1.14 (95% CI 1.04 to 1.25) and that of fever 1.52 (95% CI 1.10 to 2.10). Sore throat had a summary positive likelihood ratio of 0.814 (95% CI 0.714 to 0.929), which means that its presence increases the probability of having an infectious disease other than COVID-19. Dyspnoea (12 studies) and fatigue (8 studies) had a sensitivity of 23.3% (95% CI 16.4% to 31.9%) and 40.2% (95% CI 19.4% to 65.1%) respectively. Their specificity was 75.7% (95% CI 65.2% to 83.9%) and 73.6% (95% CI 48.4% to 89.3%). The summary positive likelihood ratio of dyspnoea was 0.96 (95% CI 0.83 to 1.11) and that of fatigue 1.52 (95% CI 1.21 to 1.91), which means that the presence of fatigue slightly increases the probability of having COVID-19. Anosmia alone (7 studies), ageusia alone (5 studies), and anosmia or ageusia (6 studies) had summary sensitivities below 50% but summary specificities over 90%. Anosmia had a summary sensitivity of 26.4% (95% CI 13.8% to 44.6%) and a specificity of 94.2% (95% CI 90.6% to 96.5%). Ageusia had a summary sensitivity of 23.2% (95% CI 10.6% to 43.3%) and a specificity of 92.6% (95% CI 83.1% to 97.0%). Anosmia or ageusia had a summary sensitivity of 39.2% (95% CI 26.5% to 53.6%) and a specificity of 92.1% (95% CI 84.5% to 96.2%). The summary positive likelihood ratios of anosmia alone and anosmia or ageusia were 4.55 (95% CI 3.46 to 5.97) and 4.99 (95% CI 3.22 to 7.75) respectively, which is just below our arbitrary definition of a 'red flag', that is, a positive likelihood ratio of at least 5. The summary positive likelihood ratio of ageusia alone was 3.14 (95% CI 1.79 to 5.51). Twenty-four studies assessed combinations of different signs and symptoms, mostly combining olfactory symptoms. By combining symptoms with other information such as contact or travel history, age, gender, and a local recent case detection rate, some multivariable prediction scores reached a sensitivity as high as 90%.
AUTHORS' CONCLUSIONS: Most individual symptoms included in this review have poor diagnostic accuracy. Neither absence nor presence of symptoms are accurate enough to rule in or rule out the disease. The presence of anosmia or ageusia may be useful as a red flag for the presence of COVID-19. The presence of cough also supports further testing. There is currently no evidence to support further testing with PCR in any individuals presenting only with upper respiratory symptoms such as sore throat, coryza or rhinorrhoea. Combinations of symptoms with other readily available information such as contact or travel history, or the local recent case detection rate may prove more useful and should be further investigated in an unselected population presenting to primary care or hospital outpatient settings. The diagnostic accuracy of symptoms for COVID-19 is moderate to low and any testing strategy using symptoms as selection mechanism will result in both large numbers of missed cases and large numbers of people requiring testing. Which one of these is minimised, is determined by the goal of COVID-19 testing strategies, that is, controlling the epidemic by isolating every possible case versus identifying those with clinically important disease so that they can be monitored or treated to optimise their prognosis. The former will require a testing strategy that uses very few symptoms as entry criterion for testing, the latter could focus on more specific symptoms such as fever and anosmia.","Signs and symptoms to determine if a patient presenting in primary care or hospital outpatient settings has COVID-19 BACKGROUND: COVID-19 illness is highly variable, ranging from infection with no symptoms through to pneumonia and life-threatening consequences. Symptoms such as fever, cough, or loss of sense of smell (anosmia) or taste (ageusia), can help flag early on if the disease is present. Such information could be used either to rule out COVID-19 disease, or to identify people who need to go for COVID-19 diagnostic tests. This is the second update of this review, which was first published in 2020.
OBJECTIVES: To assess the diagnostic accuracy of signs and symptoms to determine if a person presenting in primary care or to hospital outpatient settings, such as the emergency department or dedicated COVID-19 clinics, has COVID-19.
SEARCH METHODS: We undertook electronic searches up to 10 June 2021 in the University of Bern living search database. In addition, we checked repositories of COVID-19 publications. We used artificial intelligence text analysis to conduct an initial classification of documents. We did not apply any language restrictions.
SELECTION CRITERIA: Studies were eligible if they included people with clinically suspected COVID-19, or recruited known cases with COVID-19 and also controls without COVID-19 from a single-gate cohort. Studies were eligible when they recruited people presenting to primary care or hospital outpatient settings. Studies that included people who contracted SARS-CoV-2 infection while admitted to hospital were not eligible. The minimum eligible sample size of studies was 10 participants. All signs and symptoms were eligible for this review, including individual signs and symptoms or combinations. We accepted a range of reference standards.
DATA COLLECTION AND ANALYSIS: Pairs of review authors independently selected all studies, at both title and abstract, and full-text stage. They resolved any disagreements by discussion with a third review author. Two review authors independently extracted data and assessed risk of bias using the QUADAS-2 checklist, and resolved disagreements by discussion with a third review author. Analyses were restricted to prospective studies only. We presented sensitivity and specificity in paired forest plots, in receiver operating characteristic (ROC) space and in dumbbell plots. We estimated summary parameters using a bivariate random-effects meta-analysis whenever five or more primary prospective studies were available, and whenever heterogeneity across studies was deemed acceptable.
MAIN RESULTS: We identified 90 studies; for this update we focused on the results of 42 prospective studies with 52,608 participants. Prevalence of COVID-19 disease varied from 3.7% to 60.6% with a median of 27.4%. Thirty-five studies were set in emergency departments or outpatient test centres (46,878 participants), three in primary care settings (1230 participants), two in a mixed population of in- and outpatients in a paediatric hospital setting (493 participants), and two overlapping studies in nursing homes (4007 participants). The studies did not clearly distinguish mild COVID-19 disease from COVID-19 pneumonia, so we present the results for both conditions together. Twelve studies had a high risk of bias for selection of participants because they used a high level of preselection to decide whether reverse transcription polymerase chain reaction (RT-PCR) testing was needed, or because they enrolled a non-consecutive sample, or because they excluded individuals while they were part of the study base. We rated 36 of the 42 studies as high risk of bias for the index tests because there was little or no detail on how, by whom and when, the symptoms were measured. For most studies, eligibility for testing was dependent on the local case definition and testing criteria that were in effect at the time of the study, meaning most people who were included in studies had already been referred to health services based on the symptoms that we are evaluating in this review. The applicability of the results of this review iteration improved in comparison with the previous reviews. This version has more studies of people presenting to ambulatory settings, which is where the majority of assessments for COVID-19 take place. Only three studies presented any data on children separately, and only one focused specifically on older adults. We found data on 96 symptoms or combinations of signs and symptoms. Evidence on individual signs as diagnostic tests was rarely reported, so this review reports mainly on the diagnostic value of symptoms. Results were highly variable across studies. Most had very low sensitivity and high specificity. RT-PCR was the most often used reference standard (40/42 studies). Only cough (11 studies) had a summary sensitivity above 50% (62.4%, 95% CI 50.6% to 72.9%)); its specificity was low (45.4%, 95% CI 33.5% to 57.9%)). Presence of fever had a sensitivity of 37.6% (95% CI 23.4% to 54.3%) and a specificity of 75.2% (95% CI 56.3% to 87.8%). The summary positive likelihood ratio of cough was 1.14 (95% CI 1.04 to 1.25) and that of fever 1.52 (95% CI 1.10 to 2.10). Sore throat had a summary positive likelihood ratio of 0.814 (95% CI 0.714 to 0.929), which means that its presence increases the probability of having an infectious disease other than COVID-19. Dyspnoea (12 studies) and fatigue (8 studies) had a sensitivity of 23.3% (95% CI 16.4% to 31.9%) and 40.2% (95% CI 19.4% to 65.1%) respectively. Their specificity was 75.7% (95% CI 65.2% to 83.9%) and 73.6% (95% CI 48.4% to 89.3%). The summary positive likelihood ratio of dyspnoea was 0.96 (95% CI 0.83 to 1.11) and that of fatigue 1.52 (95% CI 1.21 to 1.91), which means that the presence of fatigue slightly increases the probability of having COVID-19. Anosmia alone (7 studies), ageusia alone (5 studies), and anosmia or ageusia (6 studies) had summary sensitivities below 50% but summary specificities over 90%. Anosmia had a summary sensitivity of 26.4% (95% CI 13.8% to 44.6%) and a specificity of 94.2% (95% CI 90.6% to 96.5%). Ageusia had a summary sensitivity of 23.2% (95% CI 10.6% to 43.3%) and a specificity of 92.6% (95% CI 83.1% to 97.0%). Anosmia or ageusia had a summary sensitivity of 39.2% (95% CI 26.5% to 53.6%) and a specificity of 92.1% (95% CI 84.5% to 96.2%). The summary positive likelihood ratios of anosmia alone and anosmia or ageusia were 4.55 (95% CI 3.46 to 5.97) and 4.99 (95% CI 3.22 to 7.75) respectively, which is just below our arbitrary definition of a 'red flag', that is, a positive likelihood ratio of at least 5. The summary positive likelihood ratio of ageusia alone was 3.14 (95% CI 1.79 to 5.51). Twenty-four studies assessed combinations of different signs and symptoms, mostly combining olfactory symptoms. By combining symptoms with other information such as contact or travel history, age, gender, and a local recent case detection rate, some multivariable prediction scores reached a sensitivity as high as 90%.
AUTHORS' CONCLUSIONS: Most individual symptoms included in this review have poor diagnostic accuracy. Neither absence nor presence of symptoms are accurate enough to rule in or rule out the disease. The presence of anosmia or ageusia may be useful as a red flag for the presence of COVID-19. The presence of cough also supports further testing. There is currently no evidence to support further testing with PCR in any individuals presenting only with upper respiratory symptoms such as sore throat, coryza or rhinorrhoea. Combinations of symptoms with other readily available information such as contact or travel history, or the local recent case detection rate may prove more useful and should be further investigated in an unselected population presenting to primary care or hospital outpatient settings. The diagnostic accuracy of symptoms for COVID-19 is moderate to low and any testing strategy using symptoms as selection mechanism will result in both large numbers of missed cases and large numbers of people requiring testing. Which one of these is minimised, is determined by the goal of COVID-19 testing strategies, that is, controlling the epidemic by isolating every possible case versus identifying those with clinically important disease so that they can be monitored or treated to optimise their prognosis. The former will require a testing strategy that uses very few symptoms as entry criterion for testing, the latter could focus on more specific symptoms such as fever and anosmia.",0
37461046,"Global incidence, prevalence and disease burden of silicosis: 30 years' overview and forecasted trends","Liu X, Jiang Q, Wu P, Han L, Zhou P.",BMC Public Health. 2023 Jul 17;23(1):1366. doi: 10.1186/s12889-023-16295-2.,Liu X,BMC Public Health,2023,17-07-2023,PMC10353232,,10.1186/s12889-023-16295-2,"BACKGROUND: Globally, silicosis accounts for 90% of all pneumoconiosis cases and is a serious public health issue. It is characterized by progressive inflammation and irreversible pulmonary fibrosis. A comprehensive analysis at temporal, spatial and population levels with the most updated data from GBD 2019 is provided in this study to estimate the disease burden of silicosis from 1990 to 2019 and make predictions to 2029.
METHODS: We delineated silicosis data on incidence, prevalence, and disability-adjusted life years (DALYs) as well as age-standardized rates (ASRs) across 30 years from GBD 2019. Joinpoint regression analysis was employed to detect temporal changes and estimate annual percentage change (APC) of each trend segment. Measures were stratified by time, location, age, and sociodemographic index (SDI). Back propagation artificial neural network (BP-ANN) model was applied to elaborate ASR trends from 1990 to 2019 and projections to the next 10 years.
RESULTS: Globally, silicosis incident, prevalent cases, and DALYs increased by 64.6%, 91.4%, and 20.8%, respectively. However, all the corresponding ASRs showed overall downward trends with an estimated average APC (AAPC) of -0.5(-0.7 to -0.3), -0.2(-0.5 to 0.0), and - 2.0(-2.2 to -1.8), respectively. Middle and high-middle SDI regions carried the heaviest disease burden. The highest disease burden of silicosis was mainly transferred to the older from 1990 to 2019. The trend of ASRs demonstrated a rapid decline between 2005 and 2019, followed by a continuous decline until 2029.
CONCLUSION: Though disease burden of silicosis has been on a decline in general from 1990 to 2019, which shows a promising prospect but cannot be ignored. We should pay more attention to implementing preventive tactics and improving the life quality of present sufferers.","Global incidence, prevalence and disease burden of silicosis: 30 years' overview and forecasted trends BACKGROUND: Globally, silicosis accounts for 90% of all pneumoconiosis cases and is a serious public health issue. It is characterized by progressive inflammation and irreversible pulmonary fibrosis. A comprehensive analysis at temporal, spatial and population levels with the most updated data from GBD 2019 is provided in this study to estimate the disease burden of silicosis from 1990 to 2019 and make predictions to 2029.
METHODS: We delineated silicosis data on incidence, prevalence, and disability-adjusted life years (DALYs) as well as age-standardized rates (ASRs) across 30 years from GBD 2019. Joinpoint regression analysis was employed to detect temporal changes and estimate annual percentage change (APC) of each trend segment. Measures were stratified by time, location, age, and sociodemographic index (SDI). Back propagation artificial neural network (BP-ANN) model was applied to elaborate ASR trends from 1990 to 2019 and projections to the next 10 years.
RESULTS: Globally, silicosis incident, prevalent cases, and DALYs increased by 64.6%, 91.4%, and 20.8%, respectively. However, all the corresponding ASRs showed overall downward trends with an estimated average APC (AAPC) of -0.5(-0.7 to -0.3), -0.2(-0.5 to 0.0), and - 2.0(-2.2 to -1.8), respectively. Middle and high-middle SDI regions carried the heaviest disease burden. The highest disease burden of silicosis was mainly transferred to the older from 1990 to 2019. The trend of ASRs demonstrated a rapid decline between 2005 and 2019, followed by a continuous decline until 2029.
CONCLUSION: Though disease burden of silicosis has been on a decline in general from 1990 to 2019, which shows a promising prospect but cannot be ignored. We should pay more attention to implementing preventive tactics and improving the life quality of present sufferers.",0
32188419,Artificial neural network-based models used for predicting 28- and 90-day mortality of patients with hepatitis B-associated acute-on-chronic liver failure,"Hou Y, Zhang Q, Gao F, Mao D, Li J, Gong Z, Luo X, Chen G, Li Y, Yang Z, Sun K, Wang X.",BMC Gastroenterol. 2020 Mar 13;20(1):75. doi: 10.1186/s12876-020-01191-5.,Hou Y,BMC Gastroenterol,2020,20-03-2020,PMC7081680,,10.1186/s12876-020-01191-5,"BACKGROUND: This study aimed to develop prognostic models for predicting 28- and 90-day mortality rates of hepatitis B virus (HBV)-associated acute-on-chronic liver failure (HBV-ACLF) through artificial neural network (ANN) systems.
METHODS: Six hundred and eight-four cases of consecutive HBV-ACLF patients were retrospectively reviewed. Four hundred and twenty-three cases were used for training and constructing ANN models, and the remaining 261 cases were for validating the established models. Predictors associated with mortality were determined by univariate analysis and were then included in ANN models for predicting prognosis of mortality. The receiver operating characteristic curve analysis was used to evaluate the predictive performance of the ANN models in comparison with various current prognostic models.
RESULTS: Variables with statistically significant difference or important clinical characteristics were input in the ANN training process, and eight independent risk factors, including age, hepatic encephalopathy, serum sodium, prothrombin activity, γ-glutamyltransferase, hepatitis B e antigen, alkaline phosphatase and total bilirubin, were eventually used to establish ANN models. For 28-day mortality in the training cohort, the model's predictive accuracy (AUR 0.948, 95% CI 0.925-0.970) was significantly higher than that of the Model for End-stage Liver Disease (MELD), MELD-sodium (MELD-Na), Chronic Liver Failure-ACLF (CLIF-ACLF), and Child-Turcotte-Pugh (CTP) (all p < 0.001). In the validation cohorts the predictive accuracy of ANN model (AUR 0.748, 95% CI: 0.673-0.822) was significantly higher than that of MELD (p = 0.0099) and insignificantly higher than that of MELD-Na, CTP and CLIF-ACLF (p > 0.05). For 90-day mortality in the training cohort, the model's predictive accuracy (AUR 0.913, 95% CI 0.887-0.938) was significantly higher than that of MELD, MELD-Na, CTP and CLIF-ACLF (all p < 0.001). In the validation cohorts, the prediction accuracy of the ANN model (AUR 0.754, 95% CI: 0.697-0.812 was significantly higher than that of MELD (p = 0.019) and insignificantly higher than MELD-Na, CTP and CLIF-ACLF (p > 0.05).
CONCLUSIONS: The established ANN models can more accurately predict short-term mortality risk in patients with HBV- ACLF. The main content has been postered as an abstract at the AASLD Hepatology Conference (https://doi.org/10.1002/hep.30257).","Artificial neural network-based models used for predicting 28- and 90-day mortality of patients with hepatitis B-associated acute-on-chronic liver failure BACKGROUND: This study aimed to develop prognostic models for predicting 28- and 90-day mortality rates of hepatitis B virus (HBV)-associated acute-on-chronic liver failure (HBV-ACLF) through artificial neural network (ANN) systems.
METHODS: Six hundred and eight-four cases of consecutive HBV-ACLF patients were retrospectively reviewed. Four hundred and twenty-three cases were used for training and constructing ANN models, and the remaining 261 cases were for validating the established models. Predictors associated with mortality were determined by univariate analysis and were then included in ANN models for predicting prognosis of mortality. The receiver operating characteristic curve analysis was used to evaluate the predictive performance of the ANN models in comparison with various current prognostic models.
RESULTS: Variables with statistically significant difference or important clinical characteristics were input in the ANN training process, and eight independent risk factors, including age, hepatic encephalopathy, serum sodium, prothrombin activity, γ-glutamyltransferase, hepatitis B e antigen, alkaline phosphatase and total bilirubin, were eventually used to establish ANN models. For 28-day mortality in the training cohort, the model's predictive accuracy (AUR 0.948, 95% CI 0.925-0.970) was significantly higher than that of the Model for End-stage Liver Disease (MELD), MELD-sodium (MELD-Na), Chronic Liver Failure-ACLF (CLIF-ACLF), and Child-Turcotte-Pugh (CTP) (all p < 0.001). In the validation cohorts the predictive accuracy of ANN model (AUR 0.748, 95% CI: 0.673-0.822) was significantly higher than that of MELD (p = 0.0099) and insignificantly higher than that of MELD-Na, CTP and CLIF-ACLF (p > 0.05). For 90-day mortality in the training cohort, the model's predictive accuracy (AUR 0.913, 95% CI 0.887-0.938) was significantly higher than that of MELD, MELD-Na, CTP and CLIF-ACLF (all p < 0.001). In the validation cohorts, the prediction accuracy of the ANN model (AUR 0.754, 95% CI: 0.697-0.812 was significantly higher than that of MELD (p = 0.019) and insignificantly higher than MELD-Na, CTP and CLIF-ACLF (p > 0.05).
CONCLUSIONS: The established ANN models can more accurately predict short-term mortality risk in patients with HBV- ACLF. The main content has been postered as an abstract at the AASLD Hepatology Conference (https://doi.org/10.1002/hep.30257).",0
32853285,"Predicting and analyzing the COVID-19 epidemic in China: Based on SEIRD, LSTM and GWR models","Liu F, Wang J, Liu J, Li Y, Liu D, Tong J, Li Z, Yu D, Fan Y, Bi X, Zhang X, Mo S.",PLoS One. 2020 Aug 27;15(8):e0238280. doi: 10.1371/journal.pone.0238280. eCollection 2020.,Liu F,PLoS One,2020,28-08-2020,PMC7451659,,10.1371/journal.pone.0238280,"In December 2019, the novel coronavirus pneumonia (COVID-19) occurred in Wuhan, Hubei Province, China. The epidemic quickly broke out and spread throughout the country. Now it becomes a pandemic that affects the whole world. In this study, three models were used to fit and predict the epidemic situation in China: a modified SEIRD (Susceptible-Exposed-Infected-Recovered-Dead) dynamic model, a neural network method LSTM (Long Short-Term Memory), and a GWR (Geographically Weighted Regression) model reflecting spatial heterogeneity. Overall, all the three models performed well with great accuracy. The dynamic SEIRD prediction APE (absolute percent error) of China had been ≤ 1.0% since Mid-February. The LSTM model showed comparable accuracy. The GWR model took into account the influence of geographical differences, with R2 = 99.98% in fitting and 97.95% in prediction. Wilcoxon test showed that none of the three models outperformed the other two at the significance level of 0.05. The parametric analysis of the infectious rate and recovery rate demonstrated that China's national policies had effectively slowed down the spread of the epidemic. Furthermore, the models in this study provided a wide range of implications for other countries to predict the short-term and long-term trend of COVID-19, and to evaluate the intensity and effect of their interventions.","Predicting and analyzing the COVID-19 epidemic in China: Based on SEIRD, LSTM and GWR models In December 2019, the novel coronavirus pneumonia (COVID-19) occurred in Wuhan, Hubei Province, China. The epidemic quickly broke out and spread throughout the country. Now it becomes a pandemic that affects the whole world. In this study, three models were used to fit and predict the epidemic situation in China: a modified SEIRD (Susceptible-Exposed-Infected-Recovered-Dead) dynamic model, a neural network method LSTM (Long Short-Term Memory), and a GWR (Geographically Weighted Regression) model reflecting spatial heterogeneity. Overall, all the three models performed well with great accuracy. The dynamic SEIRD prediction APE (absolute percent error) of China had been ≤ 1.0% since Mid-February. The LSTM model showed comparable accuracy. The GWR model took into account the influence of geographical differences, with R2 = 99.98% in fitting and 97.95% in prediction. Wilcoxon test showed that none of the three models outperformed the other two at the significance level of 0.05. The parametric analysis of the infectious rate and recovery rate demonstrated that China's national policies had effectively slowed down the spread of the epidemic. Furthermore, the models in this study provided a wide range of implications for other countries to predict the short-term and long-term trend of COVID-19, and to evaluate the intensity and effect of their interventions.",0
35954895,The Prediction of Public Risk Perception by Internal Characteristics and External Environment: Machine Learning on Big Data,"Xie Q, Xue Y.",Int J Environ Res Public Health. 2022 Aug 3;19(15):9545. doi: 10.3390/ijerph19159545.,Xie Q,Int J Environ Res Public Health,2022,12-08-2022,PMC9368627,,10.3390/ijerph19159545,"Presently, the public's perception of risk in terms of topical social issues is mainly measured quantitively using a psychological scale, but this approach is not accurate enough for everyday data. In this paper, we explored the ways in which public risk perception can be more accurately predicted in the era of big data. We obtained internal characteristics and external environment predictor variables through a literature review, and then built our prediction model using the machine learning of a BP neural network via three steps: the calculation of the node number of the implication level, a performance test of the BP neural network, and the computation of the weight of every input node. Taking the public risk perception of the Sino-US trade friction and the COVID-19 pandemic in China as research cases, we found that, according to our tests, the node number of the implication level was 15 in terms of the Sino-US trade friction and 14 in terms of the COVID-19 pandemic. Following this, machine learning was conducted, through which we found that the R2 of the BP neural network prediction model was 0.88651 and 0.87125, respectively, for the two cases, which accurately predicted the public's risk perception of the data on a certain day, and simultaneously obtained the weight of every predictor variable in each case. In this paper, we provide comments and suggestions for building a model to predict the public's perception of topical issues.","The Prediction of Public Risk Perception by Internal Characteristics and External Environment: Machine Learning on Big Data Presently, the public's perception of risk in terms of topical social issues is mainly measured quantitively using a psychological scale, but this approach is not accurate enough for everyday data. In this paper, we explored the ways in which public risk perception can be more accurately predicted in the era of big data. We obtained internal characteristics and external environment predictor variables through a literature review, and then built our prediction model using the machine learning of a BP neural network via three steps: the calculation of the node number of the implication level, a performance test of the BP neural network, and the computation of the weight of every input node. Taking the public risk perception of the Sino-US trade friction and the COVID-19 pandemic in China as research cases, we found that, according to our tests, the node number of the implication level was 15 in terms of the Sino-US trade friction and 14 in terms of the COVID-19 pandemic. Following this, machine learning was conducted, through which we found that the R2 of the BP neural network prediction model was 0.88651 and 0.87125, respectively, for the two cases, which accurately predicted the public's risk perception of the data on a certain day, and simultaneously obtained the weight of every predictor variable in each case. In this paper, we provide comments and suggestions for building a model to predict the public's perception of topical issues.",0
30173661,"Scoping review on vector-borne diseases in urban areas: transmission dynamics, vectorial capacity and co-infection","Eder M, Cortes F, Teixeira de Siqueira Filha N, Araújo de França GV, Degroote S, Braga C, Ridde V, Turchi Martelli CM.",Infect Dis Poverty. 2018 Sep 3;7(1):90. doi: 10.1186/s40249-018-0475-7.,Eder M,Infect Dis Poverty,2018,04-09-2018,PMC6120094,,10.1186/s40249-018-0475-7,"BACKGROUND: Transmission dynamics, vectorial capacity, and co-infections have substantial impacts on vector-borne diseases (VBDs) affecting urban and suburban populations. Reviewing key factors can provide insight into priority research areas and offer suggestions for potential interventions.
MAIN BODY: Through a scoping review, we identify knowledge gaps on transmission dynamics, vectorial capacity, and co-infections regarding VBDs in urban areas. Peer-reviewed and grey literature published between 2000 and 2016 was searched. We screened abstracts and full texts to select studies. Using an extraction grid, we retrieved general data, results, lessons learned and recommendations, future research avenues, and practice implications. We classified studies by VBD and country/continent and identified relevant knowledge gaps. Of 773 articles selected for full-text screening, 50 were included in the review: 23 based on research in the Americas, 15 in Asia, 10 in Africa, and one each in Europe and Australia. The largest body of evidence concerning VBD epidemiology in urban areas concerned dengue and malaria. Other arboviruses covered included chikungunya and West Nile virus, other parasitic diseases such as leishmaniasis and trypanosomiasis, and bacterial rickettsiosis and plague. Most articles retrieved in our review combined transmission dynamics and vectorial capacity; only two combined transmission dynamics and co-infection. The review identified significant knowledge gaps on the role of asymptomatic individuals, the effects of co-infection and other host factors, and the impacts of climatic, environmental, and socioeconomic factors on VBD transmission in urban areas. Limitations included the trade-off from narrowing the search strategy (missing out on classical modelling studies), a lack of studies on co-infections, most studies being only descriptive, and few offering concrete public health recommendations. More research is needed on transmission risk in homes and workplaces, given increasingly dynamic and mobile populations. The lack of studies on co-infection hampers monitoring of infections transmitted by the same vector.
CONCLUSIONS: Strengthening VBD surveillance and control, particularly in asymptomatic cases and mobile populations, as well as using early warning tools to predict increasing transmission, were key strategies identified for public health policy and practice.","Scoping review on vector-borne diseases in urban areas: transmission dynamics, vectorial capacity and co-infection BACKGROUND: Transmission dynamics, vectorial capacity, and co-infections have substantial impacts on vector-borne diseases (VBDs) affecting urban and suburban populations. Reviewing key factors can provide insight into priority research areas and offer suggestions for potential interventions.
MAIN BODY: Through a scoping review, we identify knowledge gaps on transmission dynamics, vectorial capacity, and co-infections regarding VBDs in urban areas. Peer-reviewed and grey literature published between 2000 and 2016 was searched. We screened abstracts and full texts to select studies. Using an extraction grid, we retrieved general data, results, lessons learned and recommendations, future research avenues, and practice implications. We classified studies by VBD and country/continent and identified relevant knowledge gaps. Of 773 articles selected for full-text screening, 50 were included in the review: 23 based on research in the Americas, 15 in Asia, 10 in Africa, and one each in Europe and Australia. The largest body of evidence concerning VBD epidemiology in urban areas concerned dengue and malaria. Other arboviruses covered included chikungunya and West Nile virus, other parasitic diseases such as leishmaniasis and trypanosomiasis, and bacterial rickettsiosis and plague. Most articles retrieved in our review combined transmission dynamics and vectorial capacity; only two combined transmission dynamics and co-infection. The review identified significant knowledge gaps on the role of asymptomatic individuals, the effects of co-infection and other host factors, and the impacts of climatic, environmental, and socioeconomic factors on VBD transmission in urban areas. Limitations included the trade-off from narrowing the search strategy (missing out on classical modelling studies), a lack of studies on co-infections, most studies being only descriptive, and few offering concrete public health recommendations. More research is needed on transmission risk in homes and workplaces, given increasingly dynamic and mobile populations. The lack of studies on co-infection hampers monitoring of infections transmitted by the same vector.
CONCLUSIONS: Strengthening VBD surveillance and control, particularly in asymptomatic cases and mobile populations, as well as using early warning tools to predict increasing transmission, were key strategies identified for public health policy and practice.",0
31209084,Comparison of autoregressive integrated moving average model and generalised regression neural network model for prediction of haemorrhagic fever with renal syndrome in China: a time-series study,"Wang YW, Shen ZZ, Jiang Y.",BMJ Open. 2019 Jun 16;9(6):e025773. doi: 10.1136/bmjopen-2018-025773.,Wang YW,BMJ Open,2019,19-06-2019,PMC6589045,,10.1136/bmjopen-2018-025773,"OBJECTIVES: Haemorrhagic fever with renal syndrome (HFRS) is a serious threat to public health in China, accounting for almost 90% cases reported globally. Infectious disease prediction may help in disease prevention despite some uncontrollable influence factors. This study conducted a comparison between a hybrid model and two single models in forecasting the monthly incidence of HFRS in China.
DESIGN: Time-series study.
SETTING: The People's Republic of China.
METHODS: Autoregressive integrated moving average (ARIMA) model, generalised regression neural network (GRNN) model and hybrid ARIMA-GRNN model were constructed by R V.3.4.3 software. The monthly reported incidence of HFRS from January 2011 to May 2018 were adopted to evaluate models' performance. Root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) were adopted to evaluate these models' effectiveness. Spatial stratified heterogeneity of the time series was tested by month and another GRNN model was built with a new series.
RESULTS: The monthly incidence of HFRS in the past several years showed a slight downtrend and obvious seasonal variation. A total of four plausible ARIMA models were built and ARIMA(2,1,1) (2,1,1)<sub>12</sub> model was selected as the optimal model in HFRS fitting. The smooth factors of the basic GRNN model and the hybrid model were 0.027 and 0.043, respectively. The single ARIMA model was the best in fitting part (MAPE=9.1154, MAE=89.0302, RMSE=138.8356) while the hybrid model was the best in prediction (MAPE=17.8335, MAE=152.3013, RMSE=196.4682). GRNN model was revised by building model with new series and the forecasting performance of revised model (MAPE=17.6095, MAE=163.8000, RMSE=169.4751) was better than original GRNN model (MAPE=19.2029, MAE=177.0356, RMSE=202.1684).
CONCLUSIONS: The hybrid ARIMA-GRNN model was better than single ARIMA and basic GRNN model in forecasting monthly incidence of HFRS in China. It could be considered as a decision-making tool in HFRS prevention and control.","Comparison of autoregressive integrated moving average model and generalised regression neural network model for prediction of haemorrhagic fever with renal syndrome in China: a time-series study OBJECTIVES: Haemorrhagic fever with renal syndrome (HFRS) is a serious threat to public health in China, accounting for almost 90% cases reported globally. Infectious disease prediction may help in disease prevention despite some uncontrollable influence factors. This study conducted a comparison between a hybrid model and two single models in forecasting the monthly incidence of HFRS in China.
DESIGN: Time-series study.
SETTING: The People's Republic of China.
METHODS: Autoregressive integrated moving average (ARIMA) model, generalised regression neural network (GRNN) model and hybrid ARIMA-GRNN model were constructed by R V.3.4.3 software. The monthly reported incidence of HFRS from January 2011 to May 2018 were adopted to evaluate models' performance. Root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) were adopted to evaluate these models' effectiveness. Spatial stratified heterogeneity of the time series was tested by month and another GRNN model was built with a new series.
RESULTS: The monthly incidence of HFRS in the past several years showed a slight downtrend and obvious seasonal variation. A total of four plausible ARIMA models were built and ARIMA(2,1,1) (2,1,1)<sub>12</sub> model was selected as the optimal model in HFRS fitting. The smooth factors of the basic GRNN model and the hybrid model were 0.027 and 0.043, respectively. The single ARIMA model was the best in fitting part (MAPE=9.1154, MAE=89.0302, RMSE=138.8356) while the hybrid model was the best in prediction (MAPE=17.8335, MAE=152.3013, RMSE=196.4682). GRNN model was revised by building model with new series and the forecasting performance of revised model (MAPE=17.6095, MAE=163.8000, RMSE=169.4751) was better than original GRNN model (MAPE=19.2029, MAE=177.0356, RMSE=202.1684).
CONCLUSIONS: The hybrid ARIMA-GRNN model was better than single ARIMA and basic GRNN model in forecasting monthly incidence of HFRS in China. It could be considered as a decision-making tool in HFRS prevention and control.",0
32453658,Forecasting tuberculosis using diabetes-related google trends data,"Frauenfeld L, Nann D, Sulyok Z, Feng YS, Sulyok M.",Pathog Glob Health. 2020 Jul;114(5):236-241. doi: 10.1080/20477724.2020.1767854. Epub 2020 May 26.,Frauenfeld L,Pathog Glob Health,2020,27-05-2020,PMC7480530,,10.1080/20477724.2020.1767854,"Online activity-based data can be used to aid infectious disease forecasting. Our aim was to exploit the converging nature of the tuberculosis (TB) and diabetes epidemics to forecast TB case numbers. Thus, we extended TB prediction models based on traditional data with diabetes-related Google searches. We obtained data on the weekly case numbers of TB in Germany from June 8th, 2014, to May 5th, 2019. Internet search data were obtained from a Google Trends (GTD) search for 'diabetes' to the corresponding interval. A seasonal autoregressive moving average (SARIMA) model (0,1,1) (1,0,0) [52] was selected to describe the weekly TB case numbers with and without GTD as an external regressor. We cross-validated the SARIMA models to obtain the root mean squared errors (RMSE). We repeated this procedure with autoregressive feed-forward neural network (NNAR) models using 5-fold cross-validation. To simulate a data-poor surveillance setting, we also tested traditional and GTD-extended models against a hold-out dataset using a decreased 52-week-long period with missing values for training. Cross-validation resulted in an RMSE of 20.83 for the traditional model and 18.56 for the GTD-extended model. Cross-validation of the NNAR models showed a mean RMSE of 19.49 for the traditional model and 18.99 for the GTD-extended model. When we tested the models trained on a decreased dataset with missing values, the GTD-extended models achieved significantly better prediction than the traditional models (p &lt; 0.001). The GTD-extended models outperformed the traditional models in all assessed model evaluation parameters. Using online activity-based data regarding diabetes can improve TB forecasting, but further validation is warranted.","Forecasting tuberculosis using diabetes-related google trends data Online activity-based data can be used to aid infectious disease forecasting. Our aim was to exploit the converging nature of the tuberculosis (TB) and diabetes epidemics to forecast TB case numbers. Thus, we extended TB prediction models based on traditional data with diabetes-related Google searches. We obtained data on the weekly case numbers of TB in Germany from June 8th, 2014, to May 5th, 2019. Internet search data were obtained from a Google Trends (GTD) search for 'diabetes' to the corresponding interval. A seasonal autoregressive moving average (SARIMA) model (0,1,1) (1,0,0) [52] was selected to describe the weekly TB case numbers with and without GTD as an external regressor. We cross-validated the SARIMA models to obtain the root mean squared errors (RMSE). We repeated this procedure with autoregressive feed-forward neural network (NNAR) models using 5-fold cross-validation. To simulate a data-poor surveillance setting, we also tested traditional and GTD-extended models against a hold-out dataset using a decreased 52-week-long period with missing values for training. Cross-validation resulted in an RMSE of 20.83 for the traditional model and 18.56 for the GTD-extended model. Cross-validation of the NNAR models showed a mean RMSE of 19.49 for the traditional model and 18.99 for the GTD-extended model. When we tested the models trained on a decreased dataset with missing values, the GTD-extended models achieved significantly better prediction than the traditional models (p &lt; 0.001). The GTD-extended models outperformed the traditional models in all assessed model evaluation parameters. Using online activity-based data regarding diabetes can improve TB forecasting, but further validation is warranted.",0
35030203,Comparison of ARIMA and LSTM for prediction of hemorrhagic fever at different time scales in China,"Zhang R, Song H, Chen Q, Wang Y, Wang S, Li Y.",PLoS One. 2022 Jan 14;17(1):e0262009. doi: 10.1371/journal.pone.0262009. eCollection 2022.,Zhang R,PLoS One,2022,14-01-2022,PMC8759700,,10.1371/journal.pone.0262009,"OBJECTIVES: This study intends to build and compare two kinds of forecasting models at different time scales for hemorrhagic fever incidence in China.
METHODS: Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory Neural Network (LSTM) were adopted to fit monthly, weekly and daily incidence of hemorrhagic fever in China from 2013 to 2018. The two models, combined and uncombined with rolling forecasts, were used to predict the incidence in 2019 to examine their stability and applicability.
RESULTS: ARIMA (2, 1, 1) (0, 1, 1)12, ARIMA (1, 1, 3) (1, 1, 1)52 and ARIMA (5, 0, 1) were selected as the best fitting ARIMA model for monthly, weekly and daily incidence series, respectively. The LSTM model with 64 neurons and Stochastic Gradient Descent (SGDM) for monthly incidence, 8 neurons and Adaptive Moment Estimation (Adam) for weekly incidence, and 64 neurons and Root Mean Square Prop (RMSprop) for daily incidence were selected as the best fitting LSTM models. The values of root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of the models combined with rolling forecasts in 2019 were lower than those of the direct forecasting models for both ARIMA and LSTM. It was shown from the forecasting performance in 2019 that ARIMA was better than LSTM for monthly and weekly forecasting while the LSTM was better than ARIMA for daily forecasting in rolling forecasting models.
CONCLUSIONS: Both ARIMA and LSTM could be used to build a prediction model for the incidence of hemorrhagic fever. Different models might be more suitable for the incidence prediction at different time scales. The findings can provide a good reference for future selection of prediction models and establishments of early warning systems for hemorrhagic fever.","Comparison of ARIMA and LSTM for prediction of hemorrhagic fever at different time scales in China OBJECTIVES: This study intends to build and compare two kinds of forecasting models at different time scales for hemorrhagic fever incidence in China.
METHODS: Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory Neural Network (LSTM) were adopted to fit monthly, weekly and daily incidence of hemorrhagic fever in China from 2013 to 2018. The two models, combined and uncombined with rolling forecasts, were used to predict the incidence in 2019 to examine their stability and applicability.
RESULTS: ARIMA (2, 1, 1) (0, 1, 1)12, ARIMA (1, 1, 3) (1, 1, 1)52 and ARIMA (5, 0, 1) were selected as the best fitting ARIMA model for monthly, weekly and daily incidence series, respectively. The LSTM model with 64 neurons and Stochastic Gradient Descent (SGDM) for monthly incidence, 8 neurons and Adaptive Moment Estimation (Adam) for weekly incidence, and 64 neurons and Root Mean Square Prop (RMSprop) for daily incidence were selected as the best fitting LSTM models. The values of root mean square error (RMSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of the models combined with rolling forecasts in 2019 were lower than those of the direct forecasting models for both ARIMA and LSTM. It was shown from the forecasting performance in 2019 that ARIMA was better than LSTM for monthly and weekly forecasting while the LSTM was better than ARIMA for daily forecasting in rolling forecasting models.
CONCLUSIONS: Both ARIMA and LSTM could be used to build a prediction model for the incidence of hemorrhagic fever. Different models might be more suitable for the incidence prediction at different time scales. The findings can provide a good reference for future selection of prediction models and establishments of early warning systems for hemorrhagic fever.",0
31485259,Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay,"Mello-Román JD, Mello-Román JC, Gómez-Guerrero S, García-Torres M.",Comput Math Methods Med. 2019 Jul 29;2019:7307803. doi: 10.1155/2019/7307803. eCollection 2019.,Mello-Román JD,Comput Math Methods Med,2019,06-09-2019,PMC6702853,,10.1155/2019/7307803,"Early diagnosis of dengue continues to be a concern for public health in countries with a high incidence of this disease. In this work, we compared two machine learning techniques: artificial neural networks (ANN) and support vector machines (SVM) as assistance tools for medical diagnosis. The performance of classification models was evaluated in a real dataset of patients with a previous diagnosis of dengue extracted from the public health system of Paraguay during the period 2012-2016. The ANN multilayer perceptron achieved better results with an average of 96% accuracy, 96% sensitivity, and 97% specificity, with low variation in thirty different partitions of the dataset. In comparison, SVM polynomial obtained results above 90% for accuracy, sensitivity, and specificity.","Predictive Models for the Medical Diagnosis of Dengue: A Case Study in Paraguay Early diagnosis of dengue continues to be a concern for public health in countries with a high incidence of this disease. In this work, we compared two machine learning techniques: artificial neural networks (ANN) and support vector machines (SVM) as assistance tools for medical diagnosis. The performance of classification models was evaluated in a real dataset of patients with a previous diagnosis of dengue extracted from the public health system of Paraguay during the period 2012-2016. The ANN multilayer perceptron achieved better results with an average of 96% accuracy, 96% sensitivity, and 97% specificity, with low variation in thirty different partitions of the dataset. In comparison, SVM polynomial obtained results above 90% for accuracy, sensitivity, and specificity.",0
25621078,Predicting outcomes in patients with perforated gastroduodenal ulcers: artificial neural network modelling indicates a highly complex disease,"Søreide K, Thorsen K, Søreide JA.",Eur J Trauma Emerg Surg. 2015 Feb;41(1):91-8. doi: 10.1007/s00068-014-0417-4. Epub 2014 Jun 14.,Søreide K,Eur J Trauma Emerg Surg,2015,27-01-2015,PMC4298653,,10.1007/s00068-014-0417-4,"PURPOSE: Mortality prediction models for patients with perforated peptic ulcer (PPU) have not yielded consistent or highly accurate results. Given the complex nature of this disease, which has many non-linear associations with outcomes, we explored artificial neural networks (ANNs) to predict the complex interactions between the risk factors of PPU and death among patients with this condition.
METHODS: ANN modelling using a standard feed-forward, back-propagation neural network with three layers (i.e., an input layer, a hidden layer and an output layer) was used to predict the 30-day mortality of consecutive patients from a population-based cohort undergoing surgery for PPU. A receiver-operating characteristic (ROC) analysis was used to assess model accuracy.
RESULTS: Of the 172 patients, 168 had their data included in the model; the data of 117 (70%) were used for the training set, and the data of 51 (39%) were used for the test set. The accuracy, as evaluated by area under the ROC curve (AUC), was best for an inclusive, multifactorial ANN model (AUC 0.90, 95% CIs 0.85-0.95; p < 0.001). This model outperformed standard predictive scores, including Boey and PULP. The importance of each variable decreased as the number of factors included in the ANN model increased.
CONCLUSIONS: The prediction of death was most accurate when using an ANN model with several univariate influences on the outcome. This finding demonstrates that PPU is a highly complex disease for which clinical prognoses are likely difficult. The incorporation of computerised learning systems might enhance clinical judgments to improve decision making and outcome prediction.","Predicting outcomes in patients with perforated gastroduodenal ulcers: artificial neural network modelling indicates a highly complex disease PURPOSE: Mortality prediction models for patients with perforated peptic ulcer (PPU) have not yielded consistent or highly accurate results. Given the complex nature of this disease, which has many non-linear associations with outcomes, we explored artificial neural networks (ANNs) to predict the complex interactions between the risk factors of PPU and death among patients with this condition.
METHODS: ANN modelling using a standard feed-forward, back-propagation neural network with three layers (i.e., an input layer, a hidden layer and an output layer) was used to predict the 30-day mortality of consecutive patients from a population-based cohort undergoing surgery for PPU. A receiver-operating characteristic (ROC) analysis was used to assess model accuracy.
RESULTS: Of the 172 patients, 168 had their data included in the model; the data of 117 (70%) were used for the training set, and the data of 51 (39%) were used for the test set. The accuracy, as evaluated by area under the ROC curve (AUC), was best for an inclusive, multifactorial ANN model (AUC 0.90, 95% CIs 0.85-0.95; p < 0.001). This model outperformed standard predictive scores, including Boey and PULP. The importance of each variable decreased as the number of factors included in the ANN model increased.
CONCLUSIONS: The prediction of death was most accurate when using an ANN model with several univariate influences on the outcome. This finding demonstrates that PPU is a highly complex disease for which clinical prognoses are likely difficult. The incorporation of computerised learning systems might enhance clinical judgments to improve decision making and outcome prediction.",0
39198754,Study on the impact of meteorological factors on influenza in different periods and prediction based on artificial intelligence RF-Bi-LSTM algorithm: to compare the COVID-19 period with the non-COVID-19 period,"Zhu H, Chen S, Qin W, Aynur J, Chen Y, Wang X, Chen K, Xie Z, Li L, Liu Y, Chen G, Ou J, Zheng K.",BMC Infect Dis. 2024 Aug 28;24(1):878. doi: 10.1186/s12879-024-09750-x.,Zhu H,BMC Infect Dis,2024,28-08-2024,PMC11360838,,10.1186/s12879-024-09750-x,"OBJECTIVE: At different times, public health faces various challenges and the degree of intervention measures varies. The research on the impact and prediction of meteorology factors on influenza is increasing gradually, however, there is currently no evidence on whether its research results are affected by different periods. This study aims to provide limited evidence to reveal this issue.
METHODS: Daily data on influencing factors and influenza in Xiamen were divided into three parts: overall period (phase AB), non-COVID-19 epidemic period (phase A), and COVID-19 epidemic period (phase B). The association between influencing factors and influenza was analysed using generalized additive models (GAMs). The excess risk (ER) was used to represent the percentage change in influenza as the interquartile interval (IQR) of meteorology factors increases. The 7-day average daily influenza cases were predicted using the combination of bi-directional long short memory (Bi-LSTM) and random forest (RF) through multi-step rolling input of the daily multifactor values of the previous 7-day.
RESULTS: In periods A and AB, air temperature below 22 °C was a risk factor for influenza. However, in phase B, temperature showed a U-shaped effect on it. Relative humidity had a more significant cumulative effect on influenza in phase AB than in phase A (peak: accumulate 14d, AB: ER = 281.54, 95% CI = 245.47 ~ 321.37; A: ER = 120.48, 95% CI = 100.37 ~ 142.60). Compared to other age groups, children aged 4-12 were more affected by pressure, precipitation, sunshine, and day light, while those aged ≥ 13 were more affected by the accumulation of humidity over multiple days. The accuracy of predicting influenza was highest in phase A and lowest in phase B.
CONCLUSIONS: The varying degrees of intervention measures adopted during different phases led to significant differences in the impact of meteorology factors on influenza and in the influenza prediction. In association studies of respiratory infectious diseases, especially influenza, and environmental factors, it is advisable to exclude periods with more external interventions to reduce interference with environmental factors and influenza related research, or to refine the model to accommodate the alterations brought about by intervention measures. In addition, the RF-Bi-LSTM model has good predictive performance for influenza.","Study on the impact of meteorological factors on influenza in different periods and prediction based on artificial intelligence RF-Bi-LSTM algorithm: to compare the COVID-19 period with the non-COVID-19 period OBJECTIVE: At different times, public health faces various challenges and the degree of intervention measures varies. The research on the impact and prediction of meteorology factors on influenza is increasing gradually, however, there is currently no evidence on whether its research results are affected by different periods. This study aims to provide limited evidence to reveal this issue.
METHODS: Daily data on influencing factors and influenza in Xiamen were divided into three parts: overall period (phase AB), non-COVID-19 epidemic period (phase A), and COVID-19 epidemic period (phase B). The association between influencing factors and influenza was analysed using generalized additive models (GAMs). The excess risk (ER) was used to represent the percentage change in influenza as the interquartile interval (IQR) of meteorology factors increases. The 7-day average daily influenza cases were predicted using the combination of bi-directional long short memory (Bi-LSTM) and random forest (RF) through multi-step rolling input of the daily multifactor values of the previous 7-day.
RESULTS: In periods A and AB, air temperature below 22 °C was a risk factor for influenza. However, in phase B, temperature showed a U-shaped effect on it. Relative humidity had a more significant cumulative effect on influenza in phase AB than in phase A (peak: accumulate 14d, AB: ER = 281.54, 95% CI = 245.47 ~ 321.37; A: ER = 120.48, 95% CI = 100.37 ~ 142.60). Compared to other age groups, children aged 4-12 were more affected by pressure, precipitation, sunshine, and day light, while those aged ≥ 13 were more affected by the accumulation of humidity over multiple days. The accuracy of predicting influenza was highest in phase A and lowest in phase B.
CONCLUSIONS: The varying degrees of intervention measures adopted during different phases led to significant differences in the impact of meteorology factors on influenza and in the influenza prediction. In association studies of respiratory infectious diseases, especially influenza, and environmental factors, it is advisable to exclude periods with more external interventions to reduce interference with environmental factors and influenza related research, or to refine the model to accommodate the alterations brought about by intervention measures. In addition, the RF-Bi-LSTM model has good predictive performance for influenza.",0
39570994,Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models,"Madden WG, Jin W, Lopman B, Zufle A, Dalziel B, E Metcalf CJ, Grenfell BT, Lau MSY.",PLoS Comput Biol. 2024 Nov 21;20(11):e1012616. doi: 10.1371/journal.pcbi.1012616. eCollection 2024 Nov.,Madden WG,PLoS Comput Biol,2024,21-11-2024,PMC11620694,,10.1371/journal.pcbi.1012616,"Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that while the TSIR model yields similarly performant short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, our neural network model (SFNN) consistently achieves lower root mean squared error (RMSE) across other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental models and neural networks. Our results show that the TSIR can facilitate the reconstruction of latent susceptible dynamics, thereby enhancing both forecasts in terms of mean absolute error (MAE) and parameter inference of measles dynamics within the PINN. In summary, our results show that appropriately designed neural network-based models can outperform traditional mechanistic models for short to long-term forecasts, while simultaneously providing mechanistic interpretability. Our work also provides valuable insights into more effectively integrating machine learning models with mechanistic models to enhance public health responses to measles and similar infectious disease systems.","Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that while the TSIR model yields similarly performant short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, our neural network model (SFNN) consistently achieves lower root mean squared error (RMSE) across other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental models and neural networks. Our results show that the TSIR can facilitate the reconstruction of latent susceptible dynamics, thereby enhancing both forecasts in terms of mean absolute error (MAE) and parameter inference of measles dynamics within the PINN. In summary, our results show that appropriately designed neural network-based models can outperform traditional mechanistic models for short to long-term forecasts, while simultaneously providing mechanistic interpretability. Our work also provides valuable insights into more effectively integrating machine learning models with mechanistic models to enhance public health responses to measles and similar infectious disease systems.",0
35564940,Predictive Models for Forecasting Public Health Scenarios: Practical Experiences Applied during the First Wave of the COVID-19 Pandemic,"Martin-Moreno JM, Alegre-Martinez A, Martin-Gorgojo V, Alfonso-Sanchez JL, Torres F, Pallares-Carratala V.",Int J Environ Res Public Health. 2022 May 3;19(9):5546. doi: 10.3390/ijerph19095546.,Martin-Moreno JM,Int J Environ Res Public Health,2022,14-05-2022,PMC9101183,,10.3390/ijerph19095546,"Background: Forecasting the behavior of epidemic outbreaks is vital in public health. This makes it possible to anticipate the planning and organization of the health system, as well as possible restrictive or preventive measures. During the COVID-19 pandemic, this need for prediction has been crucial. This paper attempts to characterize the alternative models that were applied in the first wave of this pandemic context, trying to shed light that could help to understand them for future practical applications. Methods: A systematic literature search was performed in standardized bibliographic repertoires, using keywords and Boolean operators to refine the findings, and selecting articles according to the main PRISMA 2020 statement recommendations. Results: After identifying models used throughout the first wave of this pandemic (between March and June 2020), we begin by examining standard data-driven epidemiological models, including studies applying models such as SIR (Susceptible-Infected-Recovered), SQUIDER, SEIR, time-dependent SIR, and other alternatives. For data-driven methods, we identify experiences using autoregressive integrated moving average (ARIMA), evolutionary genetic programming machine learning, short-term memory (LSTM), and global epidemic and mobility models. Conclusions: The COVID-19 pandemic has led to intensive and evolving use of alternative infectious disease prediction models. At this point it is not easy to decide which prediction method is the best in a generic way. Moreover, although models such as the LSTM emerge as remarkably versatile and useful, the practical applicability of the alternatives depends on the specific context of the underlying variable and on the information of the target to be prioritized. In addition, the robustness of the assessment is conditioned by heterogeneity in the quality of information sources and differences in the characteristics of disease control interventions. Further comprehensive comparison of the performance of models in comparable situations, assessing their predictive validity, is needed. This will help determine the most reliable and practical methods for application in future outbreaks and eventual pandemics.","Predictive Models for Forecasting Public Health Scenarios: Practical Experiences Applied during the First Wave of the COVID-19 Pandemic Background: Forecasting the behavior of epidemic outbreaks is vital in public health. This makes it possible to anticipate the planning and organization of the health system, as well as possible restrictive or preventive measures. During the COVID-19 pandemic, this need for prediction has been crucial. This paper attempts to characterize the alternative models that were applied in the first wave of this pandemic context, trying to shed light that could help to understand them for future practical applications. Methods: A systematic literature search was performed in standardized bibliographic repertoires, using keywords and Boolean operators to refine the findings, and selecting articles according to the main PRISMA 2020 statement recommendations. Results: After identifying models used throughout the first wave of this pandemic (between March and June 2020), we begin by examining standard data-driven epidemiological models, including studies applying models such as SIR (Susceptible-Infected-Recovered), SQUIDER, SEIR, time-dependent SIR, and other alternatives. For data-driven methods, we identify experiences using autoregressive integrated moving average (ARIMA), evolutionary genetic programming machine learning, short-term memory (LSTM), and global epidemic and mobility models. Conclusions: The COVID-19 pandemic has led to intensive and evolving use of alternative infectious disease prediction models. At this point it is not easy to decide which prediction method is the best in a generic way. Moreover, although models such as the LSTM emerge as remarkably versatile and useful, the practical applicability of the alternatives depends on the specific context of the underlying variable and on the information of the target to be prioritized. In addition, the robustness of the assessment is conditioned by heterogeneity in the quality of information sources and differences in the characteristics of disease control interventions. Further comprehensive comparison of the performance of models in comparable situations, assessing their predictive validity, is needed. This will help determine the most reliable and practical methods for application in future outbreaks and eventual pandemics.",0
38698304,Prediction of hospital-acquired influenza using machine learning algorithms: a comparative study,"Cho Y, Lee HK, Kim J, Yoo KB, Choi J, Lee Y, Choi M.",BMC Infect Dis. 2024 May 2;24(1):466. doi: 10.1186/s12879-024-09358-1.,Cho Y,BMC Infect Dis,2024,02-05-2024,PMC11067145,,10.1186/s12879-024-09358-1,"BACKGROUND: Hospital-acquired influenza (HAI) is under-recognized despite its high morbidity and poor health outcomes. The early detection of HAI is crucial for curbing its transmission in hospital settings.
AIM: This study aimed to investigate factors related to HAI, develop predictive models, and subsequently compare them to identify the best performing machine learning algorithm for predicting the occurrence of HAI.
METHODS: This retrospective observational study was conducted in 2022 and included 111 HAI and 73,748 non-HAI patients from the 2011-2012 and 2019-2020 influenza seasons. General characteristics, comorbidities, vital signs, laboratory and chest X-ray results, and room information within the electronic medical record were analysed. Logistic Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Network (ANN) techniques were used to construct the predictive models. Employing randomized allocation, 80% of the dataset constituted the training set, and the remaining 20% comprised the test set. The performance of the developed models was assessed using metrics such as the area under the receiver operating characteristic curve (AUC), the count of false negatives (FN), and the determination of feature importance.
RESULTS: Patients with HAI demonstrated notable differences in general characteristics, comorbidities, vital signs, laboratory findings, chest X-ray result, and room status compared to non-HAI patients. Among the developed models, the RF model demonstrated the best performance taking into account both the AUC (83.3%) and the occurrence of FN (four). The most influential factors for prediction were staying in double rooms, followed by vital signs and laboratory results.
CONCLUSION: This study revealed the characteristics of patients with HAI and emphasized the role of ventilation in reducing influenza incidence. These findings can aid hospitals in devising infection prevention strategies, and the application of machine learning-based predictive models especially RF can enable early intervention to mitigate the spread of influenza in healthcare settings.","Prediction of hospital-acquired influenza using machine learning algorithms: a comparative study BACKGROUND: Hospital-acquired influenza (HAI) is under-recognized despite its high morbidity and poor health outcomes. The early detection of HAI is crucial for curbing its transmission in hospital settings.
AIM: This study aimed to investigate factors related to HAI, develop predictive models, and subsequently compare them to identify the best performing machine learning algorithm for predicting the occurrence of HAI.
METHODS: This retrospective observational study was conducted in 2022 and included 111 HAI and 73,748 non-HAI patients from the 2011-2012 and 2019-2020 influenza seasons. General characteristics, comorbidities, vital signs, laboratory and chest X-ray results, and room information within the electronic medical record were analysed. Logistic Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Network (ANN) techniques were used to construct the predictive models. Employing randomized allocation, 80% of the dataset constituted the training set, and the remaining 20% comprised the test set. The performance of the developed models was assessed using metrics such as the area under the receiver operating characteristic curve (AUC), the count of false negatives (FN), and the determination of feature importance.
RESULTS: Patients with HAI demonstrated notable differences in general characteristics, comorbidities, vital signs, laboratory findings, chest X-ray result, and room status compared to non-HAI patients. Among the developed models, the RF model demonstrated the best performance taking into account both the AUC (83.3%) and the occurrence of FN (four). The most influential factors for prediction were staying in double rooms, followed by vital signs and laboratory results.
CONCLUSION: This study revealed the characteristics of patients with HAI and emphasized the role of ventilation in reducing influenza incidence. These findings can aid hospitals in devising infection prevention strategies, and the application of machine learning-based predictive models especially RF can enable early intervention to mitigate the spread of influenza in healthcare settings.",0
38725544,Validation of a Thai artificial chatmate designed for cheering up the elderly during the COVID-19 pandemic,"Deepaisarn S, Imkome EU, Wongpatikaseree K, Yuenyong S, Lakanavisid P, Soonthornchaiva R, Yomaboot P, Angkoonsawaengsuk A, Munpansa N.",F1000Res. 2024 Feb 28;11:1411. doi: 10.12688/f1000research.127431.3. eCollection 2022.,Deepaisarn S,F1000Res,2024,10-05-2024,PMC11079584,,10.12688/f1000research.127431.3,"BACKGROUND: The COVID-19 pandemic severely affected populations of all age groups. The elderly are a high-risk group and are highly vulnerable to COVID-19. Assistive software chatbots can enhance the mental health status of the elderly by providing support and companionship. The objective of this study was to validate a Thai artificial chatmate for the elderly during the COVID-19 pandemic and floods.
METHODS: Chatbot design includes the establishment of a dataset and emotional word vectors in which data consisting of emotional sentences were converted into the word vector form using a pre-trained word2vec model. A word vector was then input into a convolutional neural network (CNN) and trained until the model converges using sentence embedding and similarity word segmentation. Sentence vectors were generated by averaging each word vector using an averaged vector method. For approximate similarity matching, the Annoy library was used to create the indices in tree sorting. Data were collected from 22 elderly and assessed by the Post-Study System Usability Questionnaire (PSSUQ).
RESULTS: The study revealed that 72.73% of the respondents found the chatbot easy to learn and use, 63.64% of the respondents found the chatbot can autonomously determine the next course of action, and 59.09% of the respondents believed that troubleshooting guidelines were provided for overcoming errors. The accuracy of the chatbot providing a reasonable response is 56.20±13.99%.
CONCLUSIONS: Most users were satisfied with the chatbot system. The proposed chatbot provided considerable essential insights into the development of assistance systems for the elderly during the coronavirus pandemic (COVID-19) and during the period of national disasters. The model can be expanded to other applications in the future.","Validation of a Thai artificial chatmate designed for cheering up the elderly during the COVID-19 pandemic BACKGROUND: The COVID-19 pandemic severely affected populations of all age groups. The elderly are a high-risk group and are highly vulnerable to COVID-19. Assistive software chatbots can enhance the mental health status of the elderly by providing support and companionship. The objective of this study was to validate a Thai artificial chatmate for the elderly during the COVID-19 pandemic and floods.
METHODS: Chatbot design includes the establishment of a dataset and emotional word vectors in which data consisting of emotional sentences were converted into the word vector form using a pre-trained word2vec model. A word vector was then input into a convolutional neural network (CNN) and trained until the model converges using sentence embedding and similarity word segmentation. Sentence vectors were generated by averaging each word vector using an averaged vector method. For approximate similarity matching, the Annoy library was used to create the indices in tree sorting. Data were collected from 22 elderly and assessed by the Post-Study System Usability Questionnaire (PSSUQ).
RESULTS: The study revealed that 72.73% of the respondents found the chatbot easy to learn and use, 63.64% of the respondents found the chatbot can autonomously determine the next course of action, and 59.09% of the respondents believed that troubleshooting guidelines were provided for overcoming errors. The accuracy of the chatbot providing a reasonable response is 56.20±13.99%.
CONCLUSIONS: Most users were satisfied with the chatbot system. The proposed chatbot provided considerable essential insights into the development of assistance systems for the elderly during the coronavirus pandemic (COVID-19) and during the period of national disasters. The model can be expanded to other applications in the future.",0
32579598,"A comparative study of two methods to predict the incidence of hepatitis B in Guangxi, China","Zheng Y, Zhang L, Zhu X, Guo G.",PLoS One. 2020 Jun 24;15(6):e0234660. doi: 10.1371/journal.pone.0234660. eCollection 2020.,Zheng Y,PLoS One,2020,25-06-2020,PMC7314421,,10.1371/journal.pone.0234660,"In recent years, the incidence of hepatitis B (HB) in Guangxi is higher than that of the national level; it has been increasing, so it is urgent to do a good predictive research of HB incidence, which can help analyze the early warning of hepatitis B in Guangxi, China. In the study, the feasibility of predicting HB incidence in Guangxi by autoregressive integrated moving average (ARIMA) model method and Elman neural network (ElmanNN) method was discussed respectively, and the prediction accuracy of the two models was compared. Finally, we established the ARIMA (0, 1, 1) model and ElmanNN with 8 neurons. Both ARIMA (0, 1, 1) model and ElmanNN model had good performance, and their prediction accuracy were high. The fitting and prediction root-mean-square error (RMSE) and mean absolute error (MAE) of ElmanNN were smaller than those of ARIMA (0, 1, 1) model, which indicated that ElmanNN was superior to ARIMA (0, 1, 1) model in predicting the incidence of hepatitis B in Guangxi. Based on the ElmanNN, the HB incidence from September 2019 to December 2020 in Guangxi was predicted, the predicted results showed that the incidence of HB in 2020 was slightly higher than that in 2019 and the change trend was similar to that in 2019, for 2021 and beyond, the ElmanNN model could be used to continue the predictive analysis.","A comparative study of two methods to predict the incidence of hepatitis B in Guangxi, China In recent years, the incidence of hepatitis B (HB) in Guangxi is higher than that of the national level; it has been increasing, so it is urgent to do a good predictive research of HB incidence, which can help analyze the early warning of hepatitis B in Guangxi, China. In the study, the feasibility of predicting HB incidence in Guangxi by autoregressive integrated moving average (ARIMA) model method and Elman neural network (ElmanNN) method was discussed respectively, and the prediction accuracy of the two models was compared. Finally, we established the ARIMA (0, 1, 1) model and ElmanNN with 8 neurons. Both ARIMA (0, 1, 1) model and ElmanNN model had good performance, and their prediction accuracy were high. The fitting and prediction root-mean-square error (RMSE) and mean absolute error (MAE) of ElmanNN were smaller than those of ARIMA (0, 1, 1) model, which indicated that ElmanNN was superior to ARIMA (0, 1, 1) model in predicting the incidence of hepatitis B in Guangxi. Based on the ElmanNN, the HB incidence from September 2019 to December 2020 in Guangxi was predicted, the predicted results showed that the incidence of HB in 2020 was slightly higher than that in 2019 and the change trend was similar to that in 2019, for 2021 and beyond, the ElmanNN model could be used to continue the predictive analysis.",0
39072020,Identifying Importation and Asymptomatic Spreaders of Multi-drug Resistant Organisms in Hospital Settings,"Cui J, Heavey J, Klein E, Madden GR, Vullikanti A, Prakash BA.",medRxiv [Preprint]. 2024 Jul 15:2024.07.14.24310393. doi: 10.1101/2024.07.14.24310393.,Cui J,medRxiv,2024,29-07-2024,PMC11275683,,10.1101/2024.07.14.24310393,"Healthcare-associated infections (HAIs) due to multi-drug resistant organisms (MDROs) are a significant burden to the healthcare system. Patients are sometimes already infected at the time of admission to the hospital (referred to as ""importation""), and additional patients might get infected in the hospital through transmission (""nosocomial infection""). Since many of these importation and nosocomial infection cases may present no symptoms (i.e., ""asymptomatic""), rapidly identifying them is difficult since testing is limited and incurs significant delays. Although there has been a lot of work on examining the utility of both mathematical models of transmission and machine learning for identifying patients at risk of MDRO infections in recent years, these methods have limited performance and suffer from different drawbacks: Transmission modeling-based methods do not make full use of rich data contained in electronic health records (EHR), while machine learning-based methods typically lack information about mechanistic processes. In this work, we propose NEURABM, a new framework which integrates both neural networks and agent-based models (ABM) to combine the advantages of both modeling-based and machine learning-based methods. NEURABM simultaneously learns a neural network model for patient-level prediction of importation, as well as the ABM model which is used for identifying infections. Our results demonstrate that NEURABM identifies importation and nosocomial infection cases more accurately than existing methods.","Identifying Importation and Asymptomatic Spreaders of Multi-drug Resistant Organisms in Hospital Settings Healthcare-associated infections (HAIs) due to multi-drug resistant organisms (MDROs) are a significant burden to the healthcare system. Patients are sometimes already infected at the time of admission to the hospital (referred to as ""importation""), and additional patients might get infected in the hospital through transmission (""nosocomial infection""). Since many of these importation and nosocomial infection cases may present no symptoms (i.e., ""asymptomatic""), rapidly identifying them is difficult since testing is limited and incurs significant delays. Although there has been a lot of work on examining the utility of both mathematical models of transmission and machine learning for identifying patients at risk of MDRO infections in recent years, these methods have limited performance and suffer from different drawbacks: Transmission modeling-based methods do not make full use of rich data contained in electronic health records (EHR), while machine learning-based methods typically lack information about mechanistic processes. In this work, we propose NEURABM, a new framework which integrates both neural networks and agent-based models (ABM) to combine the advantages of both modeling-based and machine learning-based methods. NEURABM simultaneously learns a neural network model for patient-level prediction of importation, as well as the ABM model which is used for identifying infections. Our results demonstrate that NEURABM identifies importation and nosocomial infection cases more accurately than existing methods.",0
29540225,Community approval required for periconceptional adolescent adherence to weekly iron and/or folic acid supplementation: a qualitative study in rural Burkina Faso,"Compaoré A, Gies S, Brabin B, Tinto H, Brabin L.",Reprod Health. 2018 Mar 14;15(1):48. doi: 10.1186/s12978-018-0490-y.,Compaoré A,Reprod Health,2018,16-03-2018,PMC5852966,,10.1186/s12978-018-0490-y,"BACKGROUND: Iron deficiency remains a prevalent adolescent health problem in low income countries. Iron supplementation is recommended but improvement of iron status requires good adherence.
OBJECTIVES: We explored factors affecting adolescent adherence to weekly iron and/or folic acid supplements in a setting of low secondary school attendance.
METHODS: Taped in-depth interviews were conducted with participants in a randomised, controlled, periconceptional iron supplementation trial for young nulliparous women living in a rural, malaria endemic region of Burkina Faso. Participants with good, medium or poor adherence were selected. Interviews were transcribed and analysed thematically.
RESULTS: Thirty-nine interviews were conducted. The community initially thought supplements were contraceptives. The potential benefits of giving iron supplementation to unmarried ""girls"" ahead of pregnancy were not recognised. Trial participation, which required parental consent, remained high but was not openly admitted because iron supplements were thought to be contraceptives. Unmarried non-school attenders, being mobile, were often sent to provide domestic labour in varied locations. This interrupted adherence - as did movement of school girls during vacations and at marriage. Field workers tracked participants and trial provision of free treatment encouraged adherence. Most interviewees did not identify health benefits from taking supplements.
CONCLUSIONS: For success, communities must be convinced of the value of an adolescent intervention. During this safety trial, benefits not routinely available in iron supplementation programmes were important to this low income community, ensuring adolescent participation. Nevertheless, adolescents were obliged to fulfil cultural duties and roles that interfered with regular adherence to the iron supplementation regime.
TRIAL REGISTRATION: Trial Registration at clinicaltrials.gov : NCT01210040.","Community approval required for periconceptional adolescent adherence to weekly iron and/or folic acid supplementation: a qualitative study in rural Burkina Faso BACKGROUND: Iron deficiency remains a prevalent adolescent health problem in low income countries. Iron supplementation is recommended but improvement of iron status requires good adherence.
OBJECTIVES: We explored factors affecting adolescent adherence to weekly iron and/or folic acid supplements in a setting of low secondary school attendance.
METHODS: Taped in-depth interviews were conducted with participants in a randomised, controlled, periconceptional iron supplementation trial for young nulliparous women living in a rural, malaria endemic region of Burkina Faso. Participants with good, medium or poor adherence were selected. Interviews were transcribed and analysed thematically.
RESULTS: Thirty-nine interviews were conducted. The community initially thought supplements were contraceptives. The potential benefits of giving iron supplementation to unmarried ""girls"" ahead of pregnancy were not recognised. Trial participation, which required parental consent, remained high but was not openly admitted because iron supplements were thought to be contraceptives. Unmarried non-school attenders, being mobile, were often sent to provide domestic labour in varied locations. This interrupted adherence - as did movement of school girls during vacations and at marriage. Field workers tracked participants and trial provision of free treatment encouraged adherence. Most interviewees did not identify health benefits from taking supplements.
CONCLUSIONS: For success, communities must be convinced of the value of an adolescent intervention. During this safety trial, benefits not routinely available in iron supplementation programmes were important to this low income community, ensuring adolescent participation. Nevertheless, adolescents were obliged to fulfil cultural duties and roles that interfered with regular adherence to the iron supplementation regime.
TRIAL REGISTRATION: Trial Registration at clinicaltrials.gov : NCT01210040.",0
33193364,Vasculitis as a Major Morbidity Factor in Patients With Partial RAG Deficiency,"Geier CB, Farmer JR, Foldvari Z, Ujhazi B, Steininger J, Sleasman JW, Parikh S, Dilley MA, Pai SY, Henderson L, Hazen M, Neven B, Moshous D, Sharapova SO, Mihailova S, Yankova P, Naumova E, Özen S, Byram K, Fernandez J, Wolf HM, Eibl MM, Notarangelo LD, Calabrese LH, Walter JE.",Front Immunol. 2020 Oct 21;11:574738. doi: 10.3389/fimmu.2020.574738. eCollection 2020.,Geier CB,Front Immunol,2020,16-11-2020,PMC7609967,,10.3389/fimmu.2020.574738,"Vasculitis can be a life-threatening complication associated with high mortality and morbidity among patients with primary immunodeficiencies (PIDs), including variants of severe and combined immunodeficiencies ((S)CID). Our understanding of vasculitis in partial defects in recombination activating gene (RAG) deficiency, a prototype of (S)CIDs, is limited with no published systematic evaluation of diagnostic and therapeutic modalities. In this report, we sought to establish the clinical, laboratory features, and treatment outcome of patients with vasculitis due to partial RAG deficiency. Vasculitis was a major complication in eight (13%) of 62 patients in our cohort with partial RAG deficiency with features of infections and immune dysregulation. Vasculitis occurred early in life, often as first sign of disease (50%) and was complicated by significant end organ damage. Viral infections often preceded the onset of predominately non-granulomatous-small vessel vasculitis. Autoantibodies against cytokines (IFN-α, -ω, and IL-12) were detected in a large fraction of the cases tested (80%), whereas the majority of patients were anti-neutrophil cytoplasmic antibodies (ANCA) negative (>80%). Genetic diagnosis of RAG deficiency was delayed up to 2 years from the onset of vasculitis. Clinical cases with sole skin manifestation responded well to first-line steroid treatment, whereas systemic vasculitis with severe end-organ complications required second-line immunosuppression and/or hematopoietic stem cell transplantation (HSCT) for definitive management. In conclusion, our data suggest that vasculitis in partial RAG deficiency is prevalent among patients with partial RAG deficiency and is associated with high morbidity. Therefore, partial RAG deficiency should be included in the differential diagnosis of patients with early-onset systemic vasculitis. Diagnostic serology may be misleading with ANCA negative findings, and search for conventional autoantibodies should be extended to include those targeting cytokines.","Vasculitis as a Major Morbidity Factor in Patients With Partial RAG Deficiency Vasculitis can be a life-threatening complication associated with high mortality and morbidity among patients with primary immunodeficiencies (PIDs), including variants of severe and combined immunodeficiencies ((S)CID). Our understanding of vasculitis in partial defects in recombination activating gene (RAG) deficiency, a prototype of (S)CIDs, is limited with no published systematic evaluation of diagnostic and therapeutic modalities. In this report, we sought to establish the clinical, laboratory features, and treatment outcome of patients with vasculitis due to partial RAG deficiency. Vasculitis was a major complication in eight (13%) of 62 patients in our cohort with partial RAG deficiency with features of infections and immune dysregulation. Vasculitis occurred early in life, often as first sign of disease (50%) and was complicated by significant end organ damage. Viral infections often preceded the onset of predominately non-granulomatous-small vessel vasculitis. Autoantibodies against cytokines (IFN-α, -ω, and IL-12) were detected in a large fraction of the cases tested (80%), whereas the majority of patients were anti-neutrophil cytoplasmic antibodies (ANCA) negative (>80%). Genetic diagnosis of RAG deficiency was delayed up to 2 years from the onset of vasculitis. Clinical cases with sole skin manifestation responded well to first-line steroid treatment, whereas systemic vasculitis with severe end-organ complications required second-line immunosuppression and/or hematopoietic stem cell transplantation (HSCT) for definitive management. In conclusion, our data suggest that vasculitis in partial RAG deficiency is prevalent among patients with partial RAG deficiency and is associated with high morbidity. Therefore, partial RAG deficiency should be included in the differential diagnosis of patients with early-onset systemic vasculitis. Diagnostic serology may be misleading with ANCA negative findings, and search for conventional autoantibodies should be extended to include those targeting cytokines.",0
28590319,SURGICAL OUTCOMES OF 27-GAUGE VITRECTOMY FOR A CONSECUTIVE SERIES OF 163 EYES WITH VARIOUS VITREOUS DISEASES,"Yoneda K, Morikawa K, Oshima Y, Kinoshita S, Sotozono C; Japan Microincision Vitrectomy Surgery Study Group.",Retina. 2017 Nov;37(11):2130-2137. doi: 10.1097/IAE.0000000000001442.,Yoneda K,Retina,2017,08-06-2017,PMC5690303,,10.1097/IAE.0000000000001442,"PURPOSE: To evaluate the safety and efficacy of 27-gauge vitrectomy for various vitreoretinal disorders.
METHODS: In this retrospective comparative study, 163 consecutive eyes with various diseases that underwent 27-gauge pars plana vitrectomy with or without ultraspeed transformer by a single surgeon from June 2012 through December 2014 were analyzed in regard to best-corrected visual acuity, intraocular pressure, intraoperative and postoperative complications, and surgery time.
RESULTS: In 2 eyes (1.2%), peripheral retina breaks were encountered intraoperatively, yet no other complications were found in those eyes. No cases required larger-gauge vitrectomy. Mean best-corrected visual acuity improved from 20/58 (logarithm of the minimum angle of resolution, 0.46 ± 0.64) preoperatively to 20/32 (logarithm of the minimum angle of resolution, 0.20 ± 0.40) postoperatively (P < 0.001). Mean follow-up was 16.7 months (range, 6-33 months). Intraocular pressure remained stable throughout the postoperative course. Hypotony was seen in 15 eyes (9.2%) at 1-day postoperative, yet that spontaneously improved within 1 week. No case of retinal detachment or endophthalmitis was recorded. In macular surgeries, such as idiopathic epiretinal membrane and macular hole combined with cataract surgery, the mean surgery time was 32.1 ± 6.9 minutes with ultraspeed transformer (n = 38) and 37.1 ± 7.7 minutes without ultraspeed transformer (n = 40) (P = 0.004).
CONCLUSION: The 27-gauge pars plana vitrectomy was found to be safe and effective for treating various vitreoretinal disorders.","SURGICAL OUTCOMES OF 27-GAUGE VITRECTOMY FOR A CONSECUTIVE SERIES OF 163 EYES WITH VARIOUS VITREOUS DISEASES PURPOSE: To evaluate the safety and efficacy of 27-gauge vitrectomy for various vitreoretinal disorders.
METHODS: In this retrospective comparative study, 163 consecutive eyes with various diseases that underwent 27-gauge pars plana vitrectomy with or without ultraspeed transformer by a single surgeon from June 2012 through December 2014 were analyzed in regard to best-corrected visual acuity, intraocular pressure, intraoperative and postoperative complications, and surgery time.
RESULTS: In 2 eyes (1.2%), peripheral retina breaks were encountered intraoperatively, yet no other complications were found in those eyes. No cases required larger-gauge vitrectomy. Mean best-corrected visual acuity improved from 20/58 (logarithm of the minimum angle of resolution, 0.46 ± 0.64) preoperatively to 20/32 (logarithm of the minimum angle of resolution, 0.20 ± 0.40) postoperatively (P < 0.001). Mean follow-up was 16.7 months (range, 6-33 months). Intraocular pressure remained stable throughout the postoperative course. Hypotony was seen in 15 eyes (9.2%) at 1-day postoperative, yet that spontaneously improved within 1 week. No case of retinal detachment or endophthalmitis was recorded. In macular surgeries, such as idiopathic epiretinal membrane and macular hole combined with cataract surgery, the mean surgery time was 32.1 ± 6.9 minutes with ultraspeed transformer (n = 38) and 37.1 ± 7.7 minutes without ultraspeed transformer (n = 40) (P = 0.004).
CONCLUSION: The 27-gauge pars plana vitrectomy was found to be safe and effective for treating various vitreoretinal disorders.",0
37187529,Prediction of the spread of African swine fever through pig and carcass movements in Thailand using a network analysis and diffusion model,"Poolkhet C, Kasemsuwan S, Thongratsakul S, Warrasuth N, Pamaranon N, Nuanualsuwan S.",PeerJ. 2023 May 9;11:e15359. doi: 10.7717/peerj.15359. eCollection 2023.,Poolkhet C,PeerJ,2023,15-05-2023,PMC10178211,,10.7717/peerj.15359,"BACKGROUND: African swine fever (ASF) is a serious contagious viral disease of pigs that affects the pig industry. This study aimed to evaluate the possible African swine fever (ASF) distribution using network analysis and a diffusion model through live pig, carcass, and pig product movement data.
MATERIAL AND METHODS: Empirical movement data from Thailand for the year 2019 were used, and expert opinions were sought to evaluate network properties and the diffusion model. The networks were presented as live pig movement and carcass movement data at the provincial and district levels. For network analysis, a descriptive network analysis was performed using outdegree, indegree, betweenness, fragmentation, and power law distribution, and cutpoints were used to describe movement patterns. For the diffusion model, we simulated each network using spatially different infected locations, patterns, and initial infection sites. Based on expert opinions, the initial infection site, the probability of ASF occurrence, and the probability of the initial infected adopter were selected for the appropriated network. In this study, we also simulated networks under varying network parameters to predict the infection speed.
RESULTS AND CONCLUSIONS: The total number of movements recorded was 2,594,364. These were divided into 403,408 (403,408/2,594,364; 15.55%) for live pigs and 2,190,956 (2,190,956/2,594,364; 84.45%) for carcasses. We found that carcass movement at the provincial level showed the highest outdegree (mean = 342.554, standard deviation (SD) = 900.528) and indegree values (mean = 342.554, SD = 665.509). In addition, the outdegree and indegree presented similar mean values and the degree distributions of both district networks followed a power-law function. The network of live pigs at provincial level showed the highest value for betweenness (mean = 0.011, SD = 0.017), and the network of live pigs at provincial level showed the highest value for fragmentation (mean = 0.027, SD = 0.005). Our simulation data indicated that the disease occurred randomly due to live pig and carcass movements along the central and western regions of Thailand, causing the rapid spread of ASF. Without control measures, it could spread to all provinces within 5- and 3-time units and in all districts within 21- and 30-time units for the network of live pigs and carcasses, respectively. This study assists the authorities to plan control and preventive measures and limit economic losses caused by ASF.","Prediction of the spread of African swine fever through pig and carcass movements in Thailand using a network analysis and diffusion model BACKGROUND: African swine fever (ASF) is a serious contagious viral disease of pigs that affects the pig industry. This study aimed to evaluate the possible African swine fever (ASF) distribution using network analysis and a diffusion model through live pig, carcass, and pig product movement data.
MATERIAL AND METHODS: Empirical movement data from Thailand for the year 2019 were used, and expert opinions were sought to evaluate network properties and the diffusion model. The networks were presented as live pig movement and carcass movement data at the provincial and district levels. For network analysis, a descriptive network analysis was performed using outdegree, indegree, betweenness, fragmentation, and power law distribution, and cutpoints were used to describe movement patterns. For the diffusion model, we simulated each network using spatially different infected locations, patterns, and initial infection sites. Based on expert opinions, the initial infection site, the probability of ASF occurrence, and the probability of the initial infected adopter were selected for the appropriated network. In this study, we also simulated networks under varying network parameters to predict the infection speed.
RESULTS AND CONCLUSIONS: The total number of movements recorded was 2,594,364. These were divided into 403,408 (403,408/2,594,364; 15.55%) for live pigs and 2,190,956 (2,190,956/2,594,364; 84.45%) for carcasses. We found that carcass movement at the provincial level showed the highest outdegree (mean = 342.554, standard deviation (SD) = 900.528) and indegree values (mean = 342.554, SD = 665.509). In addition, the outdegree and indegree presented similar mean values and the degree distributions of both district networks followed a power-law function. The network of live pigs at provincial level showed the highest value for betweenness (mean = 0.011, SD = 0.017), and the network of live pigs at provincial level showed the highest value for fragmentation (mean = 0.027, SD = 0.005). Our simulation data indicated that the disease occurred randomly due to live pig and carcass movements along the central and western regions of Thailand, causing the rapid spread of ASF. Without control measures, it could spread to all provinces within 5- and 3-time units and in all districts within 21- and 30-time units for the network of live pigs and carcasses, respectively. This study assists the authorities to plan control and preventive measures and limit economic losses caused by ASF.",0
34853342,Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays,"Gidde PS, Prasad SS, Singh AP, Bhatheja N, Prakash S, Singh P, Saboo A, Takhar R, Gupta S, Saurav S, M V R, Singh A, Sardana V, Mahajan H, Kalyanpur A, Mandal AS, Mahajan V, Agrawal A, Agrawal A, Venugopal VK, Singh S, Dash D.",Sci Rep. 2021 Dec 1;11(1):23210. doi: 10.1038/s41598-021-02003-w.,Gidde PS,Sci Rep,2021,02-12-2021,PMC8636645,,10.1038/s41598-021-02003-w,"SARS-CoV2 pandemic exposed the limitations of artificial intelligence based medical imaging systems. Earlier in the pandemic, the absence of sufficient training data prevented effective deep learning (DL) solutions for the diagnosis of COVID-19 based on X-Ray data. Here, addressing the lacunae in existing literature and algorithms with the paucity of initial training data; we describe CovBaseAI, an explainable tool using an ensemble of three DL models and an expert decision system (EDS) for COVID-Pneumonia diagnosis, trained entirely on pre-COVID-19 datasets. The performance and explainability of CovBaseAI was primarily validated on two independent datasets. Firstly, 1401 randomly selected CxR from an Indian quarantine center to assess effectiveness in excluding radiological COVID-Pneumonia requiring higher care. Second, curated dataset; 434 RT-PCR positive cases and 471 non-COVID/Normal historical scans, to assess performance in advanced medical settings. CovBaseAI had an accuracy of 87% with a negative predictive value of 98% in the quarantine-center data. However, sensitivity was 0.66-0.90 taking RT-PCR/radiologist opinion as ground truth. This work provides new insights on the usage of EDS with DL methods and the ability of algorithms to confidently predict COVID-Pneumonia while reinforcing the established learning; that benchmarking based on RT-PCR may not serve as reliable ground truth in radiological diagnosis. Such tools can pave the path for multi-modal high throughput detection of COVID-Pneumonia in screening and referral.","Validation of expert system enhanced deep learning algorithm for automated screening for COVID-Pneumonia on chest X-rays SARS-CoV2 pandemic exposed the limitations of artificial intelligence based medical imaging systems. Earlier in the pandemic, the absence of sufficient training data prevented effective deep learning (DL) solutions for the diagnosis of COVID-19 based on X-Ray data. Here, addressing the lacunae in existing literature and algorithms with the paucity of initial training data; we describe CovBaseAI, an explainable tool using an ensemble of three DL models and an expert decision system (EDS) for COVID-Pneumonia diagnosis, trained entirely on pre-COVID-19 datasets. The performance and explainability of CovBaseAI was primarily validated on two independent datasets. Firstly, 1401 randomly selected CxR from an Indian quarantine center to assess effectiveness in excluding radiological COVID-Pneumonia requiring higher care. Second, curated dataset; 434 RT-PCR positive cases and 471 non-COVID/Normal historical scans, to assess performance in advanced medical settings. CovBaseAI had an accuracy of 87% with a negative predictive value of 98% in the quarantine-center data. However, sensitivity was 0.66-0.90 taking RT-PCR/radiologist opinion as ground truth. This work provides new insights on the usage of EDS with DL methods and the ability of algorithms to confidently predict COVID-Pneumonia while reinforcing the established learning; that benchmarking based on RT-PCR may not serve as reliable ground truth in radiological diagnosis. Such tools can pave the path for multi-modal high throughput detection of COVID-Pneumonia in screening and referral.",1
34629796,Artificial intelligence for hepatitis evaluation,"Liu W, Liu X, Peng M, Chen GQ, Liu PH, Cui XW, Jiang F, Dietrich CF.",World J Gastroenterol. 2021 Sep 14;27(34):5715-5726. doi: 10.3748/wjg.v27.i34.5715.,Liu W,World J Gastroenterol,2021,11-10-2021,PMC8473592,,10.3748/wjg.v27.i34.5715,"Recently, increasing attention has been paid to the application of artificial intelligence (AI) to the diagnosis of diverse hepatic diseases, which comprises traditional machine learning and deep learning. Recent studies have shown the possible value of AI based data mining in predicting the incidence of hepatitis, classifying the different stages of hepatitis, diagnosing or screening for hepatitis, forecasting the progression of hepatitis, and predicting response to antiviral drugs in chronic hepatitis C patients. More importantly, AI based on radiology has been proven to be useful in predicting hepatitis and liver fibrosis as well as grading hepatocellular carcinoma (HCC) and differentiating it from benign liver tumors. It can predict the risk of vascular invasion of HCC, the risk of hepatic encephalopathy secondary to hepatitis B related cirrhosis, and the risk of liver failure after hepatectomy in HCC patients. In this review, we summarize the application of AI in hepatitis, and identify the challenges and future perspectives.","Artificial intelligence for hepatitis evaluation Recently, increasing attention has been paid to the application of artificial intelligence (AI) to the diagnosis of diverse hepatic diseases, which comprises traditional machine learning and deep learning. Recent studies have shown the possible value of AI based data mining in predicting the incidence of hepatitis, classifying the different stages of hepatitis, diagnosing or screening for hepatitis, forecasting the progression of hepatitis, and predicting response to antiviral drugs in chronic hepatitis C patients. More importantly, AI based on radiology has been proven to be useful in predicting hepatitis and liver fibrosis as well as grading hepatocellular carcinoma (HCC) and differentiating it from benign liver tumors. It can predict the risk of vascular invasion of HCC, the risk of hepatic encephalopathy secondary to hepatitis B related cirrhosis, and the risk of liver failure after hepatectomy in HCC patients. In this review, we summarize the application of AI in hepatitis, and identify the challenges and future perspectives.",1
37354819,"Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations","Rafique Q, Rehman A, Afghan MS, Ahmad HM, Zafar I, Fayyaz K, Ain Q, Rayan RA, Al-Aidarous KM, Rashid S, Mushtaq G, Sharma R.",Comput Biol Med. 2023 Sep;163:107191. doi: 10.1016/j.compbiomed.2023.107191. Epub 2023 Jun 20.,Rafique Q,Comput Biol Med,2023,24-06-2023,PMC10281043,,10.1016/j.compbiomed.2023.107191,"The COVID-19 pandemic has necessitated the development of reliable diagnostic methods for accurately detecting the novel coronavirus and its variants. Deep learning (DL) techniques have shown promising potential as screening tools for COVID-19 detection. In this study, we explore the realistic development of DL-driven COVID-19 detection methods and focus on the fully automatic framework using available resources, which can effectively investigate various coronavirus variants through modalities. We conducted an exploration and comparison of several diagnostic techniques that are widely used and globally validated for the detection of COVID-19. Furthermore, we explore review-based studies that provide detailed information on synergistic medicine combinations for the treatment of COVID-19. We recommend DL methods that effectively reduce time, cost, and complexity, providing valuable guidance for utilizing available synergistic combinations in clinical and research settings. This study also highlights the implication of innovative diagnostic technical and instrumental strategies, exploring public datasets, and investigating synergistic medicines using optimised DL rules. By summarizing these findings, we aim to assist future researchers in their endeavours by providing a comprehensive overview of the implication of DL techniques in COVID-19 detection and treatment. Integrating DL methods with various diagnostic approaches holds great promise in improving the accuracy and efficiency of COVID-19 diagnostics, thus contributing to effective control and management of the ongoing pandemic.","Reviewing methods of deep learning for diagnosing COVID-19, its variants and synergistic medicine combinations The COVID-19 pandemic has necessitated the development of reliable diagnostic methods for accurately detecting the novel coronavirus and its variants. Deep learning (DL) techniques have shown promising potential as screening tools for COVID-19 detection. In this study, we explore the realistic development of DL-driven COVID-19 detection methods and focus on the fully automatic framework using available resources, which can effectively investigate various coronavirus variants through modalities. We conducted an exploration and comparison of several diagnostic techniques that are widely used and globally validated for the detection of COVID-19. Furthermore, we explore review-based studies that provide detailed information on synergistic medicine combinations for the treatment of COVID-19. We recommend DL methods that effectively reduce time, cost, and complexity, providing valuable guidance for utilizing available synergistic combinations in clinical and research settings. This study also highlights the implication of innovative diagnostic technical and instrumental strategies, exploring public datasets, and investigating synergistic medicines using optimised DL rules. By summarizing these findings, we aim to assist future researchers in their endeavours by providing a comprehensive overview of the implication of DL techniques in COVID-19 detection and treatment. Integrating DL methods with various diagnostic approaches holds great promise in improving the accuracy and efficiency of COVID-19 diagnostics, thus contributing to effective control and management of the ongoing pandemic.",1
32946413,Artificial Intelligence for COVID-19: Rapid Review,"Chen J, See KC.",J Med Internet Res. 2020 Oct 27;22(10):e21476. doi: 10.2196/21476.,Chen J,J Med Internet Res,2020,18-09-2020,PMC7595751,,10.2196/21476,"BACKGROUND: COVID-19 was first discovered in December 2019 and has since evolved into a pandemic.
OBJECTIVE: To address this global health crisis, artificial intelligence (AI) has been deployed at various levels of the health care system. However, AI has both potential benefits and limitations. We therefore conducted a review of AI applications for COVID-19.
METHODS: We performed an extensive search of the PubMed and EMBASE databases for COVID-19-related English-language studies published between December 1, 2019, and March 31, 2020. We supplemented the database search with reference list checks. A thematic analysis and narrative review of AI applications for COVID-19 was conducted.
RESULTS: In total, 11 papers were included for review. AI was applied to COVID-19 in four areas: diagnosis, public health, clinical decision making, and therapeutics. We identified several limitations including insufficient data, omission of multimodal methods of AI-based assessment, delay in realization of benefits, poor internal/external validation, inability to be used by laypersons, inability to be used in resource-poor settings, presence of ethical pitfalls, and presence of legal barriers. AI could potentially be explored in four other areas: surveillance, combination with big data, operation of other core clinical services, and management of patients with COVID-19.
CONCLUSIONS: In view of the continuing increase in the number of cases, and given that multiple waves of infections may occur, there is a need for effective methods to help control the COVID-19 pandemic. Despite its shortcomings, AI holds the potential to greatly augment existing human efforts, which may otherwise be overwhelmed by high patient numbers.","Artificial Intelligence for COVID-19: Rapid Review BACKGROUND: COVID-19 was first discovered in December 2019 and has since evolved into a pandemic.
OBJECTIVE: To address this global health crisis, artificial intelligence (AI) has been deployed at various levels of the health care system. However, AI has both potential benefits and limitations. We therefore conducted a review of AI applications for COVID-19.
METHODS: We performed an extensive search of the PubMed and EMBASE databases for COVID-19-related English-language studies published between December 1, 2019, and March 31, 2020. We supplemented the database search with reference list checks. A thematic analysis and narrative review of AI applications for COVID-19 was conducted.
RESULTS: In total, 11 papers were included for review. AI was applied to COVID-19 in four areas: diagnosis, public health, clinical decision making, and therapeutics. We identified several limitations including insufficient data, omission of multimodal methods of AI-based assessment, delay in realization of benefits, poor internal/external validation, inability to be used by laypersons, inability to be used in resource-poor settings, presence of ethical pitfalls, and presence of legal barriers. AI could potentially be explored in four other areas: surveillance, combination with big data, operation of other core clinical services, and management of patients with COVID-19.
CONCLUSIONS: In view of the continuing increase in the number of cases, and given that multiple waves of infections may occur, there is a need for effective methods to help control the COVID-19 pandemic. Despite its shortcomings, AI holds the potential to greatly augment existing human efforts, which may otherwise be overwhelmed by high patient numbers.",1
37930788,Deep Learning Analysis of COVID-19 Vaccine Hesitancy and Confidence Expressed on Twitter in 6 High-Income Countries: Longitudinal Observational Study,"Zhou X, Song S, Zhang Y, Hou Z.",J Med Internet Res. 2023 Nov 6;25:e49753. doi: 10.2196/49753.,Zhou X,J Med Internet Res,2023,06-11-2023,PMC10629504,,10.2196/49753,"BACKGROUND: An ongoing monitoring of national and subnational trajectory of COVID-19 vaccine hesitancy could offer support in designing tailored policies on improving vaccine uptake.
OBJECTIVE: We aim to track the temporal and spatial distribution of COVID-19 vaccine hesitancy and confidence expressed on Twitter during the entire pandemic period in major English-speaking countries.
METHODS: We collected 5,257,385 English-language tweets regarding COVID-19 vaccination between January 1, 2020, and June 30, 2022, in 6 countries-the United States, the United Kingdom, Australia, New Zealand, Canada, and Ireland. Transformer-based deep learning models were developed to classify each tweet as intent to accept or reject COVID-19 vaccination and the belief that COVID-19 vaccine is effective or unsafe. Sociodemographic factors associated with COVID-19 vaccine hesitancy and confidence in the United States were analyzed using bivariate and multivariable linear regressions.
RESULTS: The 6 countries experienced similar evolving trends of COVID-19 vaccine hesitancy and confidence. On average, the prevalence of intent to accept COVID-19 vaccination decreased from 71.38% of 44,944 tweets in March 2020 to 34.85% of 48,167 tweets in June 2022 with fluctuations. The prevalence of believing COVID-19 vaccines to be unsafe continuously rose by 7.49 times from March 2020 (2.84% of 44,944 tweets) to June 2022 (21.27% of 48,167 tweets). COVID-19 vaccine hesitancy and confidence varied by country, vaccine manufacturer, and states within a country. The democrat party and higher vaccine confidence were significantly associated with lower vaccine hesitancy across US states.
CONCLUSIONS: COVID-19 vaccine hesitancy and confidence evolved and were influenced by the development of vaccines and viruses during the pandemic. Large-scale self-generated discourses on social media and deep learning models provide a cost-efficient approach to monitoring routine vaccine hesitancy.","Deep Learning Analysis of COVID-19 Vaccine Hesitancy and Confidence Expressed on Twitter in 6 High-Income Countries: Longitudinal Observational Study BACKGROUND: An ongoing monitoring of national and subnational trajectory of COVID-19 vaccine hesitancy could offer support in designing tailored policies on improving vaccine uptake.
OBJECTIVE: We aim to track the temporal and spatial distribution of COVID-19 vaccine hesitancy and confidence expressed on Twitter during the entire pandemic period in major English-speaking countries.
METHODS: We collected 5,257,385 English-language tweets regarding COVID-19 vaccination between January 1, 2020, and June 30, 2022, in 6 countries-the United States, the United Kingdom, Australia, New Zealand, Canada, and Ireland. Transformer-based deep learning models were developed to classify each tweet as intent to accept or reject COVID-19 vaccination and the belief that COVID-19 vaccine is effective or unsafe. Sociodemographic factors associated with COVID-19 vaccine hesitancy and confidence in the United States were analyzed using bivariate and multivariable linear regressions.
RESULTS: The 6 countries experienced similar evolving trends of COVID-19 vaccine hesitancy and confidence. On average, the prevalence of intent to accept COVID-19 vaccination decreased from 71.38% of 44,944 tweets in March 2020 to 34.85% of 48,167 tweets in June 2022 with fluctuations. The prevalence of believing COVID-19 vaccines to be unsafe continuously rose by 7.49 times from March 2020 (2.84% of 44,944 tweets) to June 2022 (21.27% of 48,167 tweets). COVID-19 vaccine hesitancy and confidence varied by country, vaccine manufacturer, and states within a country. The democrat party and higher vaccine confidence were significantly associated with lower vaccine hesitancy across US states.
CONCLUSIONS: COVID-19 vaccine hesitancy and confidence evolved and were influenced by the development of vaccines and viruses during the pandemic. Large-scale self-generated discourses on social media and deep learning models provide a cost-efficient approach to monitoring routine vaccine hesitancy.",1
35534142,Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review,"Comito C, Pizzuti C.",Artif Intell Med. 2022 Jun;128:102286. doi: 10.1016/j.artmed.2022.102286. Epub 2022 Mar 28.,Comito C,Artif Intell Med,2022,09-05-2022,PMC8958821,,10.1016/j.artmed.2022.102286,"The outbreak of novel corona virus 2019 (COVID-19) has been treated as a public health crisis of global concern by the World Health Organization (WHO). COVID-19 pandemic hugely affected countries worldwide raising the need to exploit novel, alternative and emerging technologies to respond to the emergency created by the weak health-care systems. In this context, Artificial Intelligence (AI) techniques can give a valid support to public health authorities, complementing traditional approaches with advanced tools. This study provides a comprehensive review of methods, algorithms, applications, and emerging AI technologies that can be utilized for forecasting and diagnosing COVID-19. The main objectives of this review are summarized as follows. (i) Understanding the importance of AI approaches such as machine learning and deep learning for COVID-19 pandemic; (ii) discussing the efficiency and impact of these methods for COVID-19 forecasting and diagnosing; (iii) providing an extensive background description of AI techniques to help non-expert to better catch the underlying concepts; (iv) for each work surveyed, give a detailed analysis of the rationale behind the approach, highlighting the method used, the type and size of data analyzed, the validation method, the target application and the results achieved; (v) focusing on some future challenges in COVID-19 forecasting and diagnosing.","Artificial intelligence for forecasting and diagnosing COVID-19 pandemic: A focused review The outbreak of novel corona virus 2019 (COVID-19) has been treated as a public health crisis of global concern by the World Health Organization (WHO). COVID-19 pandemic hugely affected countries worldwide raising the need to exploit novel, alternative and emerging technologies to respond to the emergency created by the weak health-care systems. In this context, Artificial Intelligence (AI) techniques can give a valid support to public health authorities, complementing traditional approaches with advanced tools. This study provides a comprehensive review of methods, algorithms, applications, and emerging AI technologies that can be utilized for forecasting and diagnosing COVID-19. The main objectives of this review are summarized as follows. (i) Understanding the importance of AI approaches such as machine learning and deep learning for COVID-19 pandemic; (ii) discussing the efficiency and impact of these methods for COVID-19 forecasting and diagnosing; (iii) providing an extensive background description of AI techniques to help non-expert to better catch the underlying concepts; (iv) for each work surveyed, give a detailed analysis of the rationale behind the approach, highlighting the method used, the type and size of data analyzed, the validation method, the target application and the results achieved; (v) focusing on some future challenges in COVID-19 forecasting and diagnosing.",1
33886097,COVID-19 in the Age of Artificial Intelligence: A Comprehensive Review,"Rasheed J, Jamil A, Hameed AA, Al-Turjman F, Rasheed A.",Interdiscip Sci. 2021 Jun;13(2):153-175. doi: 10.1007/s12539-021-00431-w. Epub 2021 Apr 22.,Rasheed J,Interdiscip Sci,2021,22-04-2021,PMC8060789,,10.1007/s12539-021-00431-w,"The recent COVID-19 pandemic, which broke at the end of the year 2019 in Wuhan, China, has infected more than 98.52 million people by today (January 23, 2021) with over 2.11 million deaths across the globe. To combat the growing pandemic on urgent basis, there is need to design effective solutions using new techniques that could exploit recent technology, such as machine learning, deep learning, big data, artificial intelligence, Internet of Things, for identification and tracking of COVID-19 cases in near real time. These technologies have offered inexpensive and rapid solution for proper screening, analyzing, prediction and tracking of COVID-19 positive cases. In this paper, a detailed review of the role of AI as a decisive tool for prognosis, analyze, and tracking the COVID-19 cases is performed. We searched various databases including Google Scholar, IEEE Library, Scopus and Web of Science using a combination of different keywords consisting of COVID-19 and AI. We have identified various applications, where AI can help healthcare practitioners in the process of identification and monitoring of COVID-19 cases. A compact summary of the corona virus cases are first highlighted, followed by the application of AI. Finally, we conclude the paper by highlighting new research directions and discuss the research challenges. Even though scientists and researchers have gathered and exchanged sufficient knowledge over last couple of months, but this structured review also examined technological perspectives while encompassing the medical aspect to help the healthcare practitioners, policymakers, decision makers, policymakers, AI scientists and virologists to quell this infectious COVID-19 pandemic outbreak.","COVID-19 in the Age of Artificial Intelligence: A Comprehensive Review The recent COVID-19 pandemic, which broke at the end of the year 2019 in Wuhan, China, has infected more than 98.52 million people by today (January 23, 2021) with over 2.11 million deaths across the globe. To combat the growing pandemic on urgent basis, there is need to design effective solutions using new techniques that could exploit recent technology, such as machine learning, deep learning, big data, artificial intelligence, Internet of Things, for identification and tracking of COVID-19 cases in near real time. These technologies have offered inexpensive and rapid solution for proper screening, analyzing, prediction and tracking of COVID-19 positive cases. In this paper, a detailed review of the role of AI as a decisive tool for prognosis, analyze, and tracking the COVID-19 cases is performed. We searched various databases including Google Scholar, IEEE Library, Scopus and Web of Science using a combination of different keywords consisting of COVID-19 and AI. We have identified various applications, where AI can help healthcare practitioners in the process of identification and monitoring of COVID-19 cases. A compact summary of the corona virus cases are first highlighted, followed by the application of AI. Finally, we conclude the paper by highlighting new research directions and discuss the research challenges. Even though scientists and researchers have gathered and exchanged sufficient knowledge over last couple of months, but this structured review also examined technological perspectives while encompassing the medical aspect to help the healthcare practitioners, policymakers, decision makers, policymakers, AI scientists and virologists to quell this infectious COVID-19 pandemic outbreak.",1
33905341,A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study,"Wang S, Dong D, Li L, Li H, Bai Y, Hu Y, Huang Y, Yu X, Liu S, Qiu X, Lu L, Wang M, Zha Y, Tian J.",IEEE J Biomed Health Inform. 2021 Jul;25(7):2353-2362. doi: 10.1109/JBHI.2021.3076086. Epub 2021 Jul 27.,Wang S,IEEE J Biomed Health Inform,2021,27-04-2021,PMC8545077,,10.1109/JBHI.2021.3076086,"OBJECTIVE: Coronavirus disease 2019 (COVID-19) has caused considerable morbidity and mortality, especially in patients with underlying health conditions. A precise prognostic tool to identify poor outcomes among such cases is desperately needed.
METHODS: Total 400 COVID-19 patients with underlying health conditions were retrospectively recruited from 4 centers, including 54 dead cases (labeled as poor outcomes) and 346 patients discharged or hospitalized for at least 7 days since initial CT scan. Patients were allocated to a training set (n = 271), a test set (n = 68), and an external test set (n = 61). We proposed an initial CT-derived hybrid model by combining a 3D-ResNet10 based deep learning model and a quantitative 3D radiomics model to predict the probability of COVID-19 patients reaching poor outcome. The model performance was assessed by area under the receiver operating characteristic curve (AUC), survival analysis, and subgroup analysis.
RESULTS: The hybrid model achieved AUCs of 0.876 (95% confidence interval: 0.752-0.999) and 0.864 (0.766-0.962) in test and external test sets, outperforming other models. The survival analysis verified the hybrid model as a significant risk factor for mortality (hazard ratio, 2.049 [1.462-2.871], P < 0.001) that could well stratify patients into high-risk and low-risk of reaching poor outcomes (P < 0.001).
CONCLUSION: The hybrid model that combined deep learning and radiomics could accurately identify poor outcomes in COVID-19 patients with underlying health conditions from initial CT scans. The great risk stratification ability could help alert risk of death and allow for timely surveillance plans.","A Deep Learning Radiomics Model to Identify Poor Outcome in COVID-19 Patients With Underlying Health Conditions: A Multicenter Study OBJECTIVE: Coronavirus disease 2019 (COVID-19) has caused considerable morbidity and mortality, especially in patients with underlying health conditions. A precise prognostic tool to identify poor outcomes among such cases is desperately needed.
METHODS: Total 400 COVID-19 patients with underlying health conditions were retrospectively recruited from 4 centers, including 54 dead cases (labeled as poor outcomes) and 346 patients discharged or hospitalized for at least 7 days since initial CT scan. Patients were allocated to a training set (n = 271), a test set (n = 68), and an external test set (n = 61). We proposed an initial CT-derived hybrid model by combining a 3D-ResNet10 based deep learning model and a quantitative 3D radiomics model to predict the probability of COVID-19 patients reaching poor outcome. The model performance was assessed by area under the receiver operating characteristic curve (AUC), survival analysis, and subgroup analysis.
RESULTS: The hybrid model achieved AUCs of 0.876 (95% confidence interval: 0.752-0.999) and 0.864 (0.766-0.962) in test and external test sets, outperforming other models. The survival analysis verified the hybrid model as a significant risk factor for mortality (hazard ratio, 2.049 [1.462-2.871], P < 0.001) that could well stratify patients into high-risk and low-risk of reaching poor outcomes (P < 0.001).
CONCLUSION: The hybrid model that combined deep learning and radiomics could accurately identify poor outcomes in COVID-19 patients with underlying health conditions from initial CT scans. The great risk stratification ability could help alert risk of death and allow for timely surveillance plans.",1
33236007,AI-Driven Multiscale Simulations Illuminate Mechanisms of SARS-CoV-2 Spike Dynamics,"Casalino L, Dommer A, Gaieb Z, Barros EP, Sztain T, Ahn SH, Trifan A, Brace A, Bogetti A, Ma H, Lee H, Turilli M, Khalid S, Chong L, Simmerling C, Hardy DJ, Maia JDC, Phillips JC, Kurth T, Stern A, Huang L, McCalpin J, Tatineni M, Gibbs T, Stone JE, Jha S, Ramanathan A, Amaro RE.",bioRxiv [Preprint]. 2020 Nov 20:2020.11.19.390187. doi: 10.1101/2020.11.19.390187.,Casalino L,bioRxiv,2020,25-11-2020,PMC7685317,,10.1101/2020.11.19.390187,"We develop a generalizable AI-driven workflow that leverages heterogeneous HPC resources to explore the time-dependent dynamics of molecular systems. We use this workflow to investigate the mechanisms of infectivity of the SARS-CoV-2 spike protein, the main viral infection machinery. Our workflow enables more efficient investigation of spike dynamics in a variety of complex environments, including within a complete SARS-CoV-2 viral envelope simulation, which contains 305 million atoms and shows strong scaling on ORNL Summit using NAMD. We present several novel scientific discoveries, including the elucidation of the spike's full glycan shield, the role of spike glycans in modulating the infectivity of the virus, and the characterization of the flexible interactions between the spike and the human ACE2 receptor. We also demonstrate how AI can accelerate conformational sampling across different systems and pave the way for the future application of such methods to additional studies in SARS-CoV-2 and other molecular systems.","AI-Driven Multiscale Simulations Illuminate Mechanisms of SARS-CoV-2 Spike Dynamics We develop a generalizable AI-driven workflow that leverages heterogeneous HPC resources to explore the time-dependent dynamics of molecular systems. We use this workflow to investigate the mechanisms of infectivity of the SARS-CoV-2 spike protein, the main viral infection machinery. Our workflow enables more efficient investigation of spike dynamics in a variety of complex environments, including within a complete SARS-CoV-2 viral envelope simulation, which contains 305 million atoms and shows strong scaling on ORNL Summit using NAMD. We present several novel scientific discoveries, including the elucidation of the spike's full glycan shield, the role of spike glycans in modulating the infectivity of the virus, and the characterization of the flexible interactions between the spike and the human ACE2 receptor. We also demonstrate how AI can accelerate conformational sampling across different systems and pave the way for the future application of such methods to additional studies in SARS-CoV-2 and other molecular systems.",1
33528225,Combining In Vivo Corneal Confocal Microscopy With Deep Learning-Based Analysis Reveals Sensory Nerve Fiber Loss in Acute Simian Immunodeficiency Virus Infection,"McCarron ME, Weinberg RL, Izzi JM, Queen SE, Tarwater PM, Misra SL, Russakoff DB, Oakley JD, Mankowski JL.",Cornea. 2021 May 1;40(5):635-642. doi: 10.1097/ICO.0000000000002661.,McCarron ME,Cornea,2021,02-02-2021,PMC8009813,NIHMS1653938,10.1097/ICO.0000000000002661,"PURPOSE: To characterize corneal subbasal nerve plexus features of normal and simian immunodeficiency virus (SIV)-infected macaques by combining in vivo corneal confocal microscopy (IVCM) with automated assessments using deep learning-based methods customized for macaques.
METHODS: IVCM images were collected from both male and female age-matched rhesus and pigtailed macaques housed at the Johns Hopkins University breeding colony using the Heidelberg HRTIII with Rostock Corneal Module. We also obtained repeat IVCM images of 12 SIV-infected animals including preinfection and 10-day post-SIV infection time points. All IVCM images were analyzed using a deep convolutional neural network architecture developed specifically for macaque studies.
RESULTS: Deep learning-based segmentation of subbasal nerves in IVCM images from macaques demonstrated that corneal nerve fiber length and fractal dimension measurements did not differ between species, but pigtailed macaques had significantly higher baseline corneal nerve fiber tortuosity than rhesus macaques (P = 0.005). Neither sex nor age of macaques was associated with differences in any of the assessed corneal subbasal nerve parameters. In the SIV/macaque model of human immunodeficiency virus, acute SIV infection induced significant decreases in both corneal nerve fiber length and fractal dimension (P = 0.01 and P = 0.008, respectively).
CONCLUSIONS: The combination of IVCM and robust objective deep learning analysis is a powerful tool to track sensory nerve damage, enabling early detection of neuropathy. Adapting deep learning analyses to clinical corneal nerve assessments will improve monitoring of small sensory nerve fiber damage in numerous clinical settings including human immunodeficiency virus.","Combining In Vivo Corneal Confocal Microscopy With Deep Learning-Based Analysis Reveals Sensory Nerve Fiber Loss in Acute Simian Immunodeficiency Virus Infection PURPOSE: To characterize corneal subbasal nerve plexus features of normal and simian immunodeficiency virus (SIV)-infected macaques by combining in vivo corneal confocal microscopy (IVCM) with automated assessments using deep learning-based methods customized for macaques.
METHODS: IVCM images were collected from both male and female age-matched rhesus and pigtailed macaques housed at the Johns Hopkins University breeding colony using the Heidelberg HRTIII with Rostock Corneal Module. We also obtained repeat IVCM images of 12 SIV-infected animals including preinfection and 10-day post-SIV infection time points. All IVCM images were analyzed using a deep convolutional neural network architecture developed specifically for macaque studies.
RESULTS: Deep learning-based segmentation of subbasal nerves in IVCM images from macaques demonstrated that corneal nerve fiber length and fractal dimension measurements did not differ between species, but pigtailed macaques had significantly higher baseline corneal nerve fiber tortuosity than rhesus macaques (P = 0.005). Neither sex nor age of macaques was associated with differences in any of the assessed corneal subbasal nerve parameters. In the SIV/macaque model of human immunodeficiency virus, acute SIV infection induced significant decreases in both corneal nerve fiber length and fractal dimension (P = 0.01 and P = 0.008, respectively).
CONCLUSIONS: The combination of IVCM and robust objective deep learning analysis is a powerful tool to track sensory nerve damage, enabling early detection of neuropathy. Adapting deep learning analyses to clinical corneal nerve assessments will improve monitoring of small sensory nerve fiber damage in numerous clinical settings including human immunodeficiency virus.",1
33301414,An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model,"Ko H, Chung H, Kang WS, Park C, Kim DW, Kim SE, Chung CR, Ko RE, Lee H, Seo JH, Choi TY, Jaimes R, Kim KW, Lee J.",J Med Internet Res. 2020 Dec 23;22(12):e25442. doi: 10.2196/25442.,Ko H,J Med Internet Res,2020,10-12-2020,PMC7759509,,10.2196/25442,"BACKGROUND: COVID-19, which is accompanied by acute respiratory distress, multiple organ failure, and death, has spread worldwide much faster than previously thought. However, at present, it has limited treatments.
OBJECTIVE: To overcome this issue, we developed an artificial intelligence (AI) model of COVID-19, named EDRnet (ensemble learning model based on deep neural network and random forest models), to predict in-hospital mortality using a routine blood sample at the time of hospital admission.
METHODS: We selected 28 blood biomarkers and used the age and gender information of patients as model inputs. To improve the mortality prediction, we adopted an ensemble approach combining deep neural network and random forest models. We trained our model with a database of blood samples from 361 COVID-19 patients in Wuhan, China, and applied it to 106 COVID-19 patients in three Korean medical institutions.
RESULTS: In the testing data sets, EDRnet provided high sensitivity (100%), specificity (91%), and accuracy (92%). To extend the number of patient data points, we developed a web application (BeatCOVID19) where anyone can access the model to predict mortality and can register his or her own blood laboratory results.
CONCLUSIONS: Our new AI model, EDRnet, accurately predicts the mortality rate for COVID-19. It is publicly available and aims to help health care providers fight COVID-19 and improve patients' outcomes.","An Artificial Intelligence Model to Predict the Mortality of COVID-19 Patients at Hospital Admission Time Using Routine Blood Samples: Development and Validation of an Ensemble Model BACKGROUND: COVID-19, which is accompanied by acute respiratory distress, multiple organ failure, and death, has spread worldwide much faster than previously thought. However, at present, it has limited treatments.
OBJECTIVE: To overcome this issue, we developed an artificial intelligence (AI) model of COVID-19, named EDRnet (ensemble learning model based on deep neural network and random forest models), to predict in-hospital mortality using a routine blood sample at the time of hospital admission.
METHODS: We selected 28 blood biomarkers and used the age and gender information of patients as model inputs. To improve the mortality prediction, we adopted an ensemble approach combining deep neural network and random forest models. We trained our model with a database of blood samples from 361 COVID-19 patients in Wuhan, China, and applied it to 106 COVID-19 patients in three Korean medical institutions.
RESULTS: In the testing data sets, EDRnet provided high sensitivity (100%), specificity (91%), and accuracy (92%). To extend the number of patient data points, we developed a web application (BeatCOVID19) where anyone can access the model to predict mortality and can register his or her own blood laboratory results.
CONCLUSIONS: Our new AI model, EDRnet, accurately predicts the mortality rate for COVID-19. It is publicly available and aims to help health care providers fight COVID-19 and improve patients' outcomes.",1
37961168,Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders,"Rancati S, Nicora G, Prosperi M, Bellazzi R, Salemi M, Marini S.",bioRxiv [Preprint]. 2024 Sep 26:2023.10.24.563721. doi: 10.1101/2023.10.24.563721.,Rancati S,bioRxiv,2024,14-11-2023,PMC10634784,,10.1101/2023.10.24.563721,"The coronavirus disease of 2019 (COVID-19) pandemic is characterized by sequential emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) variants, lineages, and sublineages, outcompeting previously circulating ones because of, among other factors, increased transmissibility and immune escape. We propose DeepAutoCoV, an unsupervised deep learning anomaly detection system to predict future dominant lineages (FDLs). We define FDLs as viral (sub)lineages that will constitute more than 10% of all the viral sequences added to the GISAID database on a given week. DeepAutoCoV is trained and validated by assembling global and country-specific data sets from over 16 million Spike protein sequences sampled over a period of about 4 years. DeepAutoCoV successfully flags FDLs at very low frequencies (0.01% - 3%), with median lead times of 4-17 weeks, and predicts FDLs ~5 and ~25 times better than a baseline approach For example, the B.1.617.2 vaccine reference strain was flagged as FDL when its frequency was only 0.01%, more than a year before it was considered for an updated COVID-19 vaccine. Furthermore, DeepAutoCoV outputs interpretable results by pinpointing specific mutations potentially linked to increased fitness, and may provide significant insights for the optimization of public health pre-emptive intervention strategies.","Forecasting dominance of SARS-CoV-2 lineages by anomaly detection using deep AutoEncoders The coronavirus disease of 2019 (COVID-19) pandemic is characterized by sequential emergence of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) variants, lineages, and sublineages, outcompeting previously circulating ones because of, among other factors, increased transmissibility and immune escape. We propose DeepAutoCoV, an unsupervised deep learning anomaly detection system to predict future dominant lineages (FDLs). We define FDLs as viral (sub)lineages that will constitute more than 10% of all the viral sequences added to the GISAID database on a given week. DeepAutoCoV is trained and validated by assembling global and country-specific data sets from over 16 million Spike protein sequences sampled over a period of about 4 years. DeepAutoCoV successfully flags FDLs at very low frequencies (0.01% - 3%), with median lead times of 4-17 weeks, and predicts FDLs ~5 and ~25 times better than a baseline approach For example, the B.1.617.2 vaccine reference strain was flagged as FDL when its frequency was only 0.01%, more than a year before it was considered for an updated COVID-19 vaccine. Furthermore, DeepAutoCoV outputs interpretable results by pinpointing specific mutations potentially linked to increased fitness, and may provide significant insights for the optimization of public health pre-emptive intervention strategies.",1
33221381,Epicardial adipose tissue is associated with extent of pneumonia and adverse outcomes in patients with COVID-19,"Grodecki K, Lin A, Razipour A, Cadet S, McElhinney PA, Chan C, Pressman BD, Julien P, Maurovich-Horvat P, Gaibazzi N, Thakur U, Mancini E, Agalbato C, Menè R, Parati G, Cernigliaro F, Nerlekar N, Torlasco C, Pontone G, Slomka PJ, Dey D.",Metabolism. 2021 Feb;115:154436. doi: 10.1016/j.metabol.2020.154436. Epub 2020 Nov 19.,Grodecki K,Metabolism,2021,22-11-2020,PMC7676319,,10.1016/j.metabol.2020.154436,"AIM: We sought to examine the association of epicardial adipose tissue (EAT) quantified on chest computed tomography (CT) with the extent of pneumonia and adverse outcomes in patients with coronavirus disease 2019 (COVID-19).
METHODS: We performed a post-hoc analysis of a prospective international registry comprising 109 consecutive patients (age 64 ± 16 years; 62% male) with laboratory-confirmed COVID-19 and noncontrast chest CT imaging. Using semi-automated software, we quantified the burden (%) of lung abnormalities associated with COVID-19 pneumonia. EAT volume (mL) and attenuation (Hounsfield units) were measured using deep learning software. The primary outcome was clinical deterioration (intensive care unit admission, invasive mechanical ventilation, or vasopressor therapy) or in-hospital death.
RESULTS: In multivariable linear regression analysis adjusted for patient comorbidities, the total burden of COVID-19 pneumonia was associated with EAT volume (β = 10.6, p = 0.005) and EAT attenuation (β = 5.2, p = 0.004). EAT volume correlated with serum levels of lactate dehydrogenase (r = 0.361, p = 0.001) and C-reactive protein (r = 0.450, p < 0.001). Clinical deterioration or death occurred in 23 (21.1%) patients at a median of 3 days (IQR 1-13 days) following the chest CT. In multivariable logistic regression analysis, EAT volume (OR 5.1 [95% CI 1.8-14.1] per doubling p = 0.011) and EAT attenuation (OR 3.4 [95% CI 1.5-7.5] per 5 Hounsfield unit increase, p = 0.003) were independent predictors of clinical deterioration or death, as was total pneumonia burden (OR 2.5, 95% CI 1.4-4.6, p = 0.002), chronic lung disease (OR 1.3 [95% CI 1.1-1.7], p = 0.011), and history of heart failure (OR 3.5 [95% 1.1-8.2], p = 0.037).
CONCLUSIONS: EAT measures quantified from chest CT are independently associated with extent of pneumonia and adverse outcomes in patients with COVID-19, lending support to their use in clinical risk stratification.","Epicardial adipose tissue is associated with extent of pneumonia and adverse outcomes in patients with COVID-19 AIM: We sought to examine the association of epicardial adipose tissue (EAT) quantified on chest computed tomography (CT) with the extent of pneumonia and adverse outcomes in patients with coronavirus disease 2019 (COVID-19).
METHODS: We performed a post-hoc analysis of a prospective international registry comprising 109 consecutive patients (age 64 ± 16 years; 62% male) with laboratory-confirmed COVID-19 and noncontrast chest CT imaging. Using semi-automated software, we quantified the burden (%) of lung abnormalities associated with COVID-19 pneumonia. EAT volume (mL) and attenuation (Hounsfield units) were measured using deep learning software. The primary outcome was clinical deterioration (intensive care unit admission, invasive mechanical ventilation, or vasopressor therapy) or in-hospital death.
RESULTS: In multivariable linear regression analysis adjusted for patient comorbidities, the total burden of COVID-19 pneumonia was associated with EAT volume (β = 10.6, p = 0.005) and EAT attenuation (β = 5.2, p = 0.004). EAT volume correlated with serum levels of lactate dehydrogenase (r = 0.361, p = 0.001) and C-reactive protein (r = 0.450, p < 0.001). Clinical deterioration or death occurred in 23 (21.1%) patients at a median of 3 days (IQR 1-13 days) following the chest CT. In multivariable logistic regression analysis, EAT volume (OR 5.1 [95% CI 1.8-14.1] per doubling p = 0.011) and EAT attenuation (OR 3.4 [95% CI 1.5-7.5] per 5 Hounsfield unit increase, p = 0.003) were independent predictors of clinical deterioration or death, as was total pneumonia burden (OR 2.5, 95% CI 1.4-4.6, p = 0.002), chronic lung disease (OR 1.3 [95% CI 1.1-1.7], p = 0.011), and history of heart failure (OR 3.5 [95% 1.1-8.2], p = 0.037).
CONCLUSIONS: EAT measures quantified from chest CT are independently associated with extent of pneumonia and adverse outcomes in patients with COVID-19, lending support to their use in clinical risk stratification.",1
36945456,Conserved cysteine residues in Kaposi's sarcoma herpesvirus ORF34 are necessary for viral production and viral pre-initiation complex formation,"Watanabe T, McGraw A, Narayan K, Tibebe H, Kuriyama K, Nishimura M, Izumi T, Fujimuro M, Ohno S.",bioRxiv [Preprint]. 2024 Jun 11:2023.03.08.531831. doi: 10.1101/2023.03.08.531831.,Watanabe T,bioRxiv,2024,22-03-2023,PMC10028899,,10.1101/2023.03.08.531831,"Kaposi's sarcoma herpesvirus (KSHV) ORF34 plays a significant role as a component of the viral pre-initiation complex (vPIC), which is indispensable for late gene expression across beta and gamma herpesviruses. Although the key role of ORF34 within the vPIC and its function as a hub protein have been recognized, further clarification regarding its specific contribution to vPIC functionality and interactions with other components is required. This study employed a deep-learning algorithm-assisted structural model of ORF34, revealing highly conserved amino acid residues across human beta- and gamma-herpesviruses localized in structured domains. Thus, we engineered ORF34 alanine-scanning mutants by substituting conserved residues with alanine. These mutants were evaluated for their ability to interact with other vPIC factors and restore viral production in cells harboring the ORF34-deficient KSHV-BAC. Our experimental results highlight the crucial role of the 4 cysteine residues conserved in ORF34: a tetrahedral arrangement consisting of a pair of C-X<sub>n</sub>-C consensus motifs. This suggests the potential incorporation of metal cations in interacting with ORF24 and ORF66 vPIC components, facilitating late gene transcription, and promoting overall virus production by capturing metal cations. In summary, our findings underline the essential role of conserved cysteines in KSHV ORF34 for effective vPIC assembly and viral replication, thereby enhancing our understanding of the complex interplay between the vPIC components.","Conserved cysteine residues in Kaposi's sarcoma herpesvirus ORF34 are necessary for viral production and viral pre-initiation complex formation Kaposi's sarcoma herpesvirus (KSHV) ORF34 plays a significant role as a component of the viral pre-initiation complex (vPIC), which is indispensable for late gene expression across beta and gamma herpesviruses. Although the key role of ORF34 within the vPIC and its function as a hub protein have been recognized, further clarification regarding its specific contribution to vPIC functionality and interactions with other components is required. This study employed a deep-learning algorithm-assisted structural model of ORF34, revealing highly conserved amino acid residues across human beta- and gamma-herpesviruses localized in structured domains. Thus, we engineered ORF34 alanine-scanning mutants by substituting conserved residues with alanine. These mutants were evaluated for their ability to interact with other vPIC factors and restore viral production in cells harboring the ORF34-deficient KSHV-BAC. Our experimental results highlight the crucial role of the 4 cysteine residues conserved in ORF34: a tetrahedral arrangement consisting of a pair of C-X<sub>n</sub>-C consensus motifs. This suggests the potential incorporation of metal cations in interacting with ORF24 and ORF66 vPIC components, facilitating late gene transcription, and promoting overall virus production by capturing metal cations. In summary, our findings underline the essential role of conserved cysteines in KSHV ORF34 for effective vPIC assembly and viral replication, thereby enhancing our understanding of the complex interplay between the vPIC components.",1
31479448,A systematic review of the diagnostic accuracy of artificial intelligence-based computer programs to analyze chest x-rays for pulmonary tuberculosis,"Harris M, Qi A, Jeagal L, Torabi N, Menzies D, Korobitsyn A, Pai M, Nathavitharana RR, Ahmad Khan F.",PLoS One. 2019 Sep 3;14(9):e0221339. doi: 10.1371/journal.pone.0221339. eCollection 2019.,Harris M,PLoS One,2019,04-09-2019,PMC6719854,,10.1371/journal.pone.0221339,"We undertook a systematic review of the diagnostic accuracy of artificial intelligence-based software for identification of radiologic abnormalities (computer-aided detection, or CAD) compatible with pulmonary tuberculosis on chest x-rays (CXRs). We searched four databases for articles published between January 2005-February 2019. We summarized data on CAD type, study design, and diagnostic accuracy. We assessed risk of bias with QUADAS-2. We included 53 of the 4712 articles reviewed: 40 focused on CAD design methods (""Development"" studies) and 13 focused on evaluation of CAD (""Clinical"" studies). Meta-analyses were not performed due to methodological differences. Development studies were more likely to use CXR databases with greater potential for bias as compared to Clinical studies. Areas under the receiver operating characteristic curve (median AUC [IQR]) were significantly higher: in Development studies AUC: 0.88 [0.82-0.90]) versus Clinical studies (0.75 [0.66-0.87]; p-value 0.004); and with deep-learning (0.91 [0.88-0.99]) versus machine-learning (0.82 [0.75-0.89]; p = 0.001). We conclude that CAD programs are promising, but the majority of work thus far has been on development rather than clinical evaluation. We provide concrete suggestions on what study design elements should be improved.","A systematic review of the diagnostic accuracy of artificial intelligence-based computer programs to analyze chest x-rays for pulmonary tuberculosis We undertook a systematic review of the diagnostic accuracy of artificial intelligence-based software for identification of radiologic abnormalities (computer-aided detection, or CAD) compatible with pulmonary tuberculosis on chest x-rays (CXRs). We searched four databases for articles published between January 2005-February 2019. We summarized data on CAD type, study design, and diagnostic accuracy. We assessed risk of bias with QUADAS-2. We included 53 of the 4712 articles reviewed: 40 focused on CAD design methods (""Development"" studies) and 13 focused on evaluation of CAD (""Clinical"" studies). Meta-analyses were not performed due to methodological differences. Development studies were more likely to use CXR databases with greater potential for bias as compared to Clinical studies. Areas under the receiver operating characteristic curve (median AUC [IQR]) were significantly higher: in Development studies AUC: 0.88 [0.82-0.90]) versus Clinical studies (0.75 [0.66-0.87]; p-value 0.004); and with deep-learning (0.91 [0.88-0.99]) versus machine-learning (0.82 [0.75-0.89]; p = 0.001). We conclude that CAD programs are promising, but the majority of work thus far has been on development rather than clinical evaluation. We provide concrete suggestions on what study design elements should be improved.",1
35671409,COVID-19 Vaccine Fact-Checking Posts on Facebook: Observational Study,"Xue H, Gong X, Stevens H.",J Med Internet Res. 2022 Jun 21;24(6):e38423. doi: 10.2196/38423.,Xue H,J Med Internet Res,2022,07-06-2022,PMC9217154,,10.2196/38423,"BACKGROUND: Effective interventions aimed at correcting COVID-19 vaccine misinformation, known as fact-checking messages, are needed to combat the mounting antivaccine infodemic and alleviate vaccine hesitancy.
OBJECTIVE: This work investigates (1) the changes in the public's attitude toward COVID-19 vaccines over time, (2) the effectiveness of COVID-19 vaccine fact-checking information on social media engagement and attitude change, and (3) the emotional and linguistic features of the COVID-19 vaccine fact-checking information ecosystem.
METHODS: We collected a data set of 12,553 COVID-19 vaccine fact-checking Facebook posts and their associated comments (N=122,362) from January 2020 to March 2022 and conducted a series of natural language processing and statistical analyses to investigate trends in public attitude toward the vaccine in COVID-19 vaccine fact-checking posts and comments, and emotional and linguistic features of the COVID-19 fact-checking information ecosystem.
RESULTS: The percentage of fact-checking posts relative to all COVID-19 vaccine posts peaked in May 2020 and then steadily decreased as the pandemic progressed (r=-0.92, df=21, t=-10.94, 95% CI -0.97 to -0.82, P<.001). The salience of COVID-19 vaccine entities was significantly lower in comments (mean 0.03, SD 0.03, t=39.28, P<.001) than in posts (mean 0.09, SD 0.11). Third-party fact checkers have been playing a more important role in more fact-checking over time (r=0.63, df=25, t=4.06, 95% CI 0.33-0.82, P<.001). COVID-19 vaccine fact-checking posts continued to be more analytical (r=0.81, df=25, t=6.88, 95% CI 0.62-0.91, P<.001) and more confident (r=0.59, df=25, t=3.68, 95% CI 0.27-0.79, P=.001) over time. Although comments did not exhibit a significant increase in confidence over time, tentativeness in comments significantly decreased (r=-0.62, df=25, t=-3.94, 95% CI -0.81 to -0.31, P=.001). In addition, although hospitals receive less engagement than other information sources, the comments expressed more positive attitudinal valence in comments compared to other information sources (b=0.06, 95% CI 0.00-0.12, t=2.03, P=.04).
CONCLUSIONS: The percentage of fact-checking posts relative to all posts about the vaccine steadily decreased after May 2020. As the pandemic progressed, third-party fact checkers played a larger role in posting fact-checking COVID-19 vaccine posts. COVID-19 vaccine fact-checking posts continued to be more analytical and more confident over time, reflecting increased confidence in posts. Similarly, tentativeness in comments decreased; this likewise suggests that public uncertainty diminished over time. COVID-19 fact-checking vaccine posts from hospitals yielded more positive attitudes toward vaccination than other information sources. At the same time, hospitals received less engagement than other information sources. This suggests that hospitals should invest more in generating engaging public health campaigns on social media.","COVID-19 Vaccine Fact-Checking Posts on Facebook: Observational Study BACKGROUND: Effective interventions aimed at correcting COVID-19 vaccine misinformation, known as fact-checking messages, are needed to combat the mounting antivaccine infodemic and alleviate vaccine hesitancy.
OBJECTIVE: This work investigates (1) the changes in the public's attitude toward COVID-19 vaccines over time, (2) the effectiveness of COVID-19 vaccine fact-checking information on social media engagement and attitude change, and (3) the emotional and linguistic features of the COVID-19 vaccine fact-checking information ecosystem.
METHODS: We collected a data set of 12,553 COVID-19 vaccine fact-checking Facebook posts and their associated comments (N=122,362) from January 2020 to March 2022 and conducted a series of natural language processing and statistical analyses to investigate trends in public attitude toward the vaccine in COVID-19 vaccine fact-checking posts and comments, and emotional and linguistic features of the COVID-19 fact-checking information ecosystem.
RESULTS: The percentage of fact-checking posts relative to all COVID-19 vaccine posts peaked in May 2020 and then steadily decreased as the pandemic progressed (r=-0.92, df=21, t=-10.94, 95% CI -0.97 to -0.82, P<.001). The salience of COVID-19 vaccine entities was significantly lower in comments (mean 0.03, SD 0.03, t=39.28, P<.001) than in posts (mean 0.09, SD 0.11). Third-party fact checkers have been playing a more important role in more fact-checking over time (r=0.63, df=25, t=4.06, 95% CI 0.33-0.82, P<.001). COVID-19 vaccine fact-checking posts continued to be more analytical (r=0.81, df=25, t=6.88, 95% CI 0.62-0.91, P<.001) and more confident (r=0.59, df=25, t=3.68, 95% CI 0.27-0.79, P=.001) over time. Although comments did not exhibit a significant increase in confidence over time, tentativeness in comments significantly decreased (r=-0.62, df=25, t=-3.94, 95% CI -0.81 to -0.31, P=.001). In addition, although hospitals receive less engagement than other information sources, the comments expressed more positive attitudinal valence in comments compared to other information sources (b=0.06, 95% CI 0.00-0.12, t=2.03, P=.04).
CONCLUSIONS: The percentage of fact-checking posts relative to all posts about the vaccine steadily decreased after May 2020. As the pandemic progressed, third-party fact checkers played a larger role in posting fact-checking COVID-19 vaccine posts. COVID-19 vaccine fact-checking posts continued to be more analytical and more confident over time, reflecting increased confidence in posts. Similarly, tentativeness in comments decreased; this likewise suggests that public uncertainty diminished over time. COVID-19 fact-checking vaccine posts from hospitals yielded more positive attitudes toward vaccination than other information sources. At the same time, hospitals received less engagement than other information sources. This suggests that hospitals should invest more in generating engaging public health campaigns on social media.",1
38562836,"Health activism, vaccine, and mpox discourse: BERTopic based mixed-method analyses of tweets from sexual minority men and gender diverse (SMMGD) individuals in the U.S","Wang Y, O'Connor K, Flores I, Berdahl CT, Urbanowicz RJ, Stevens R, Bauermeister JA, Gonzalez-Hernandez G.",medRxiv [Preprint]. 2024 Mar 19:2024.03.19.24304519. doi: 10.1101/2024.03.19.24304519.,Wang Y,medRxiv,2024,02-04-2024,PMC10984054,,10.1101/2024.03.19.24304519,"OBJECTIVES: To synthesize discussions among sexual minority men and gender diverse (SMMGD) individuals on mpox, given limited representation of SMMGD voices in existing mpox literature.
METHODS: BERTopic (a topic modeling technique) was employed with human validations to analyze mpox-related tweets (n = 8,688; October 2020-September 2022) from 2,326 self-identified SMMGD individuals in the U.S.; followed by content analysis and geographic analysis.
RESULTS: BERTopic identified 11 topics: health activism (29.81%); mpox vaccination (25.81%) and adverse events (0.98%); sarcasm, jokes, emotional expressions (14.04%); COVID-19 and mpox (7.32%); government/public health response (6.12%); mpox symptoms (2.74%); case reports (2.21%); puns on the virus' naming (i.e., monkeypox; 0.86%); media publicity (0.68%); mpox in children (0.67%). Mpox health activism negatively correlated with LGB social climate index at U.S. state level, ρ = -0.322, p = 0.031.
CONCLUSIONS: SMMGD discussions on mpox encompassed utilitarian (e.g., vaccine access, case reports, mpox symptoms) and emotionally-charged themes-advocating against homophobia, misinformation, and stigma. Mpox health activism was more prevalent in states with lower LGB social acceptance.
PUBLIC HEALTH IMPLICATIONS: Findings illuminate SMMGD engagement with mpox discourse, underscoring the need for more inclusive health communication strategies in infectious disease outbreaks to control associated stigma.","Health activism, vaccine, and mpox discourse: BERTopic based mixed-method analyses of tweets from sexual minority men and gender diverse (SMMGD) individuals in the U.S OBJECTIVES: To synthesize discussions among sexual minority men and gender diverse (SMMGD) individuals on mpox, given limited representation of SMMGD voices in existing mpox literature.
METHODS: BERTopic (a topic modeling technique) was employed with human validations to analyze mpox-related tweets (n = 8,688; October 2020-September 2022) from 2,326 self-identified SMMGD individuals in the U.S.; followed by content analysis and geographic analysis.
RESULTS: BERTopic identified 11 topics: health activism (29.81%); mpox vaccination (25.81%) and adverse events (0.98%); sarcasm, jokes, emotional expressions (14.04%); COVID-19 and mpox (7.32%); government/public health response (6.12%); mpox symptoms (2.74%); case reports (2.21%); puns on the virus' naming (i.e., monkeypox; 0.86%); media publicity (0.68%); mpox in children (0.67%). Mpox health activism negatively correlated with LGB social climate index at U.S. state level, ρ = -0.322, p = 0.031.
CONCLUSIONS: SMMGD discussions on mpox encompassed utilitarian (e.g., vaccine access, case reports, mpox symptoms) and emotionally-charged themes-advocating against homophobia, misinformation, and stigma. Mpox health activism was more prevalent in states with lower LGB social acceptance.
PUBLIC HEALTH IMPLICATIONS: Findings illuminate SMMGD engagement with mpox discourse, underscoring the need for more inclusive health communication strategies in infectious disease outbreaks to control associated stigma.",1
35421101,Dissecting recurrent waves of pertussis across the boroughs of London,"Saeidpour A, Bansal S, Rohani P.",PLoS Comput Biol. 2022 Apr 14;18(4):e1009898. doi: 10.1371/journal.pcbi.1009898. eCollection 2022 Apr.,Saeidpour A,PLoS Comput Biol,2022,14-04-2022,PMC9041754,,10.1371/journal.pcbi.1009898,"Pertussis has resurfaced in the UK, with incidence levels not seen since the 1980s. While the fundamental causes of this resurgence remain the subject of much conjecture, the study of historical patterns of pathogen diffusion can be illuminating. Here, we examined time series of pertussis incidence in the boroughs of Greater London from 1982 to 2013 to document the spatial epidemiology of this bacterial infection and to identify the potential drivers of its percolation. The incidence of pertussis over this period is characterized by 3 distinct stages: a period exhibiting declining trends with 4-year inter-epidemic cycles from 1982 to 1994, followed by a deep trough until 2006 and the subsequent resurgence. We observed systematic temporal trends in the age distribution of cases and the fade-out profile of pertussis coincident with increasing national vaccine coverage from 1982 to 1990. To quantify the hierarchy of epidemic phases across the boroughs of London, we used the Hilbert transform. We report a consistent pattern of spatial organization from 1982 to the early 1990s, with some boroughs consistently leading epidemic waves and others routinely lagging. To determine the potential drivers of these geographic patterns, a comprehensive parallel database of borough-specific features was compiled, comprising of demographic, movement and socio-economic factors that were used in statistical analyses to predict epidemic phase relationships among boroughs. Specifically, we used a combination of a feed-forward neural network (FFNN), and SHapley Additive exPlanations (SHAP) values to quantify the contribution of each covariate to model predictions. Our analyses identified a number of predictors of a borough's historical epidemic phase, specifically the age composition of households, the number of agricultural and skilled manual workers, latitude, the population of public transport commuters and high-occupancy households. Univariate regression analysis of the 2012 epidemic identified the ratio of cumulative unvaccinated children to the total population and population of Pakistan-born population to have moderate positive and negative association, respectively, with the timing of epidemic. In addition to providing a comprehensive overview of contemporary pertussis transmission in a large metropolitan population, this study has identified the characteristics that determine the spatial spread of this bacterium across the boroughs of London.","Dissecting recurrent waves of pertussis across the boroughs of London Pertussis has resurfaced in the UK, with incidence levels not seen since the 1980s. While the fundamental causes of this resurgence remain the subject of much conjecture, the study of historical patterns of pathogen diffusion can be illuminating. Here, we examined time series of pertussis incidence in the boroughs of Greater London from 1982 to 2013 to document the spatial epidemiology of this bacterial infection and to identify the potential drivers of its percolation. The incidence of pertussis over this period is characterized by 3 distinct stages: a period exhibiting declining trends with 4-year inter-epidemic cycles from 1982 to 1994, followed by a deep trough until 2006 and the subsequent resurgence. We observed systematic temporal trends in the age distribution of cases and the fade-out profile of pertussis coincident with increasing national vaccine coverage from 1982 to 1990. To quantify the hierarchy of epidemic phases across the boroughs of London, we used the Hilbert transform. We report a consistent pattern of spatial organization from 1982 to the early 1990s, with some boroughs consistently leading epidemic waves and others routinely lagging. To determine the potential drivers of these geographic patterns, a comprehensive parallel database of borough-specific features was compiled, comprising of demographic, movement and socio-economic factors that were used in statistical analyses to predict epidemic phase relationships among boroughs. Specifically, we used a combination of a feed-forward neural network (FFNN), and SHapley Additive exPlanations (SHAP) values to quantify the contribution of each covariate to model predictions. Our analyses identified a number of predictors of a borough's historical epidemic phase, specifically the age composition of households, the number of agricultural and skilled manual workers, latitude, the population of public transport commuters and high-occupancy households. Univariate regression analysis of the 2012 epidemic identified the ratio of cumulative unvaccinated children to the total population and population of Pakistan-born population to have moderate positive and negative association, respectively, with the timing of epidemic. In addition to providing a comprehensive overview of contemporary pertussis transmission in a large metropolitan population, this study has identified the characteristics that determine the spatial spread of this bacterium across the boroughs of London.",1
32132525,A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections,"Mayhew MB, Buturovic L, Luethy R, Midic U, Moore AR, Roque JA, Shaller BD, Asuni T, Rawling D, Remmel M, Choi K, Wacker J, Khatri P, Rogers AJ, Sweeney TE.",Nat Commun. 2020 Mar 4;11(1):1177. doi: 10.1038/s41467-020-14975-w.,Mayhew MB,Nat Commun,2020,06-03-2020,PMC7055276,,10.1038/s41467-020-14975-w,"Improved identification of bacterial and viral infections would reduce morbidity from sepsis, reduce antibiotic overuse, and lower healthcare costs. Here, we develop a generalizable host-gene-expression-based classifier for acute bacterial and viral infections. We use training data (N = 1069) from 18 retrospective transcriptomic studies. Using only 29 preselected host mRNAs, we train a neural-network classifier with a bacterial-vs-other area under the receiver-operating characteristic curve (AUROC) 0.92 (95% CI 0.90-0.93) and a viral-vs-other AUROC 0.92 (95% CI 0.90-0.93). We then apply this classifier, inflammatix-bacterial-viral-noninfected-version 1 (IMX-BVN-1), without retraining, to an independent cohort (N = 163). In this cohort, IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.86 (95% CI 0.77-0.93), and viral-vs.-other 0.85 (95% CI 0.76-0.93). In patients enrolled within 36 h of hospital admission (N = 70), IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.92 (95% CI 0.83-0.99), and viral-vs.-other 0.91 (95% CI 0.82-0.98). With further study, IMX-BVN-1 could provide a tool for assessing patients with suspected infection and sepsis at hospital admission.","A generalizable 29-mRNA neural-network classifier for acute bacterial and viral infections Improved identification of bacterial and viral infections would reduce morbidity from sepsis, reduce antibiotic overuse, and lower healthcare costs. Here, we develop a generalizable host-gene-expression-based classifier for acute bacterial and viral infections. We use training data (N = 1069) from 18 retrospective transcriptomic studies. Using only 29 preselected host mRNAs, we train a neural-network classifier with a bacterial-vs-other area under the receiver-operating characteristic curve (AUROC) 0.92 (95% CI 0.90-0.93) and a viral-vs-other AUROC 0.92 (95% CI 0.90-0.93). We then apply this classifier, inflammatix-bacterial-viral-noninfected-version 1 (IMX-BVN-1), without retraining, to an independent cohort (N = 163). In this cohort, IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.86 (95% CI 0.77-0.93), and viral-vs.-other 0.85 (95% CI 0.76-0.93). In patients enrolled within 36 h of hospital admission (N = 70), IMX-BVN-1 AUROCs are: bacterial-vs.-other 0.92 (95% CI 0.83-0.99), and viral-vs.-other 0.91 (95% CI 0.82-0.98). With further study, IMX-BVN-1 could provide a tool for assessing patients with suspected infection and sepsis at hospital admission.",1
34260529,An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission: Development and validation study,"Lin JK, Chien TW, Wang LY, Chou W.",Medicine (Baltimore). 2021 Jul 16;100(28):e26532. doi: 10.1097/MD.0000000000026532.,Lin JK,Medicine (Baltimore),2021,14-07-2021,PMC8284724,,10.1097/MD.0000000000026532,"BACKGROUND:: In a pandemic situation (e.g., COVID-19), the most important issue is to select patients at risk of high mortality at an early stage and to provide appropriate treatments. However, a few studies applied the model to predict in-hospital mortality using routine blood samples at the time of hospital admission. This study aimed to develop an app, name predict the mortality of COVID-19 patients (PMCP) app, to predict the mortality of COVID-19 patients at hospital-admission time.
METHODS:: We downloaded patient records from 2 studies, including 361 COVID-19 patients in Wuhan, China, and 106 COVID-19 patients in 3 Korean medical institutions. A total of 30 feature variables were retrieved, consisting of 28 blood biomarkers and 2 demographic variables (i.e., age and gender) of patients. Two models, namely, artificial neural network (ANN) and convolutional neural network (CNN), were compared with each other across 2 scenarios using: 1. raw laboratory versus normalized data and 2. training vs testing datasets (n = 361 and n = 106/361≅30%) to verify the model performance (e.g., sensitivity [SENS], specificity [SPEC], and area under the receiver operating characteristic curve [AUC]). An app for predicting the mortality of COVID-19 patients was developed using the model's estimated parameters for the prediction and classification of PMCP at an earlier stage. Feature variables and prediction results were visualized using the forest plot and category probability curves shown on Google Maps.
RESULTS:: We observed that: 1. the normalized dataset gains a relatively higher AUC(>0.9) when compared to that(<0.9) in the raw-laboratory dataset based on training data, 2. the normalized dataset in ANN yielded a high AUC of 0.96 that that(=0.91) in CNN based on testing data, and 3. a ready and available app, where anyone can access the model to predict mortality, for PMCP was developed in this study.
CONCLUSIONS:: Our new PMCP app with ANN model accurately predicts the mortality probability for COVID-19 patients. It is publicly available and aims to help health care providers fight COVID-19 and improve patients’ classifications against treatment risk.","An artificial neural network model to predict the mortality of COVID-19 patients using routine blood samples at the time of hospital admission: Development and validation study BACKGROUND:: In a pandemic situation (e.g., COVID-19), the most important issue is to select patients at risk of high mortality at an early stage and to provide appropriate treatments. However, a few studies applied the model to predict in-hospital mortality using routine blood samples at the time of hospital admission. This study aimed to develop an app, name predict the mortality of COVID-19 patients (PMCP) app, to predict the mortality of COVID-19 patients at hospital-admission time.
METHODS:: We downloaded patient records from 2 studies, including 361 COVID-19 patients in Wuhan, China, and 106 COVID-19 patients in 3 Korean medical institutions. A total of 30 feature variables were retrieved, consisting of 28 blood biomarkers and 2 demographic variables (i.e., age and gender) of patients. Two models, namely, artificial neural network (ANN) and convolutional neural network (CNN), were compared with each other across 2 scenarios using: 1. raw laboratory versus normalized data and 2. training vs testing datasets (n = 361 and n = 106/361≅30%) to verify the model performance (e.g., sensitivity [SENS], specificity [SPEC], and area under the receiver operating characteristic curve [AUC]). An app for predicting the mortality of COVID-19 patients was developed using the model's estimated parameters for the prediction and classification of PMCP at an earlier stage. Feature variables and prediction results were visualized using the forest plot and category probability curves shown on Google Maps.
RESULTS:: We observed that: 1. the normalized dataset gains a relatively higher AUC(>0.9) when compared to that(<0.9) in the raw-laboratory dataset based on training data, 2. the normalized dataset in ANN yielded a high AUC of 0.96 that that(=0.91) in CNN based on testing data, and 3. a ready and available app, where anyone can access the model to predict mortality, for PMCP was developed in this study.
CONCLUSIONS:: Our new PMCP app with ANN model accurately predicts the mortality probability for COVID-19 patients. It is publicly available and aims to help health care providers fight COVID-19 and improve patients’ classifications against treatment risk.",1
26940103,Salmonella infections modelling in Mississippi using neural network and geographical information system (GIS),"Akil L, Ahmad HA.",BMJ Open. 2016 Mar 3;6(3):e009255. doi: 10.1136/bmjopen-2015-009255.,Akil L,BMJ Open,2016,05-03-2016,PMC4785344,,10.1136/bmjopen-2015-009255,"OBJECTIVES: Mississippi (MS) is one of the southern states with high rates of foodborne infections. The objectives of this paper are to determine the extent of Salmonella and Escherichia coli infections in MS, and determine the Salmonella infections correlation with socioeconomic status using geographical information system (GIS) and neural network models.
METHODS: In this study, the relevant updated data of foodborne illness for southern states, from 2002 to 2011, were collected and used in the GIS and neural networks models. Data were collected from the Centers for Disease Control and Prevention (CDC), MS state Department of Health and the other states department of health. The correlation between low socioeconomic status and Salmonella infections were determined using models created by several software packages, including SAS, ArcGIS @RISK and NeuroShell.
RESULTS: Results of this study showed a significant increase in Salmonella outbreaks in MS during the study period, with highest rates in 2011 (47.84 ± 24.41 cases/100,000; p<0.001). MS had the highest rates of Salmonella outbreaks compared with other states (36 ± 6.29 cases/100,000; p<0.001). Regional and district variations in the rates were also observed. GIS maps of Salmonella outbreaks in MS in 2010 and 2011 showed the districts with higher rates of Salmonella. Regression analysis and neural network models showed a moderate correlation between cases of Salmonella infections and low socioeconomic factors. Poverty was shown to have a negative correlation with Salmonella outbreaks (R(2)=0.152, p<0.05).
CONCLUSIONS: Geographic location besides socioeconomic status may contribute to the high rates of Salmonella outbreaks in MS. Understanding the geographical and economic relationship with infectious diseases will help to determine effective methods to reduce outbreaks within low socioeconomic status communities.","Salmonella infections modelling in Mississippi using neural network and geographical information system (GIS) OBJECTIVES: Mississippi (MS) is one of the southern states with high rates of foodborne infections. The objectives of this paper are to determine the extent of Salmonella and Escherichia coli infections in MS, and determine the Salmonella infections correlation with socioeconomic status using geographical information system (GIS) and neural network models.
METHODS: In this study, the relevant updated data of foodborne illness for southern states, from 2002 to 2011, were collected and used in the GIS and neural networks models. Data were collected from the Centers for Disease Control and Prevention (CDC), MS state Department of Health and the other states department of health. The correlation between low socioeconomic status and Salmonella infections were determined using models created by several software packages, including SAS, ArcGIS @RISK and NeuroShell.
RESULTS: Results of this study showed a significant increase in Salmonella outbreaks in MS during the study period, with highest rates in 2011 (47.84 ± 24.41 cases/100,000; p<0.001). MS had the highest rates of Salmonella outbreaks compared with other states (36 ± 6.29 cases/100,000; p<0.001). Regional and district variations in the rates were also observed. GIS maps of Salmonella outbreaks in MS in 2010 and 2011 showed the districts with higher rates of Salmonella. Regression analysis and neural network models showed a moderate correlation between cases of Salmonella infections and low socioeconomic factors. Poverty was shown to have a negative correlation with Salmonella outbreaks (R(2)=0.152, p<0.05).
CONCLUSIONS: Geographic location besides socioeconomic status may contribute to the high rates of Salmonella outbreaks in MS. Understanding the geographical and economic relationship with infectious diseases will help to determine effective methods to reduce outbreaks within low socioeconomic status communities.",1
36231693,Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review,"Saegner T, Austys D.",Int J Environ Res Public Health. 2022 Sep 29;19(19):12394. doi: 10.3390/ijerph191912394.,Saegner T,Int J Environ Res Public Health,2022,14-10-2022,PMC9566212,,10.3390/ijerph191912394,"The probability of future Coronavirus Disease (COVID)-19 waves remains high, thus COVID-19 surveillance and forecasting remains important. Online search engines harvest vast amounts of data from the general population in real time and make these data publicly accessible via such tools as Google Trends (GT). Therefore, the aim of this study was to review the literature about possible use of GT for COVID-19 surveillance and prediction of its outbreaks. We collected and reviewed articles about the possible use of GT for COVID-19 surveillance published in the first 2 years of the pandemic. We resulted in 54 publications that were used in this review. The majority of the studies (83.3%) included in this review showed positive results of the possible use of GT for forecasting COVID-19 outbreaks. Most of the studies were performed in English-speaking countries (61.1%). The most frequently used keyword was ""coronavirus"" (53.7%), followed by ""COVID-19"" (31.5%) and ""COVID"" (20.4%). Many authors have made analyses in multiple countries (46.3%) and obtained the same results for the majority of them, thus showing the robustness of the chosen methods. Various methods including long short-term memory (3.7%), random forest regression (3.7%), Adaboost algorithm (1.9%), autoregressive integrated moving average, neural network autoregression (1.9%), and vector error correction modeling (1.9%) were used for the analysis. It was seen that most of the publications with positive results (72.2%) were using data from the first wave of the COVID-19 pandemic. Later, the search volumes reduced even though the incidence peaked. In most countries, the use of GT data showed to be beneficial for forecasting and surveillance of COVID-19 spread.","Forecasting and Surveillance of COVID-19 Spread Using Google Trends: Literature Review The probability of future Coronavirus Disease (COVID)-19 waves remains high, thus COVID-19 surveillance and forecasting remains important. Online search engines harvest vast amounts of data from the general population in real time and make these data publicly accessible via such tools as Google Trends (GT). Therefore, the aim of this study was to review the literature about possible use of GT for COVID-19 surveillance and prediction of its outbreaks. We collected and reviewed articles about the possible use of GT for COVID-19 surveillance published in the first 2 years of the pandemic. We resulted in 54 publications that were used in this review. The majority of the studies (83.3%) included in this review showed positive results of the possible use of GT for forecasting COVID-19 outbreaks. Most of the studies were performed in English-speaking countries (61.1%). The most frequently used keyword was ""coronavirus"" (53.7%), followed by ""COVID-19"" (31.5%) and ""COVID"" (20.4%). Many authors have made analyses in multiple countries (46.3%) and obtained the same results for the majority of them, thus showing the robustness of the chosen methods. Various methods including long short-term memory (3.7%), random forest regression (3.7%), Adaboost algorithm (1.9%), autoregressive integrated moving average, neural network autoregression (1.9%), and vector error correction modeling (1.9%) were used for the analysis. It was seen that most of the publications with positive results (72.2%) were using data from the first wave of the COVID-19 pandemic. Later, the search volumes reduced even though the incidence peaked. In most countries, the use of GT data showed to be beneficial for forecasting and surveillance of COVID-19 spread.",1
31234938,Comparative evaluation of time series models for predicting influenza outbreaks: application of influenza-like illness data from sentinel sites of healthcare centers in Iran,"Tapak L, Hamidi O, Fathian M, Karami M.",BMC Res Notes. 2019 Jun 24;12(1):353. doi: 10.1186/s13104-019-4393-y.,Tapak L,BMC Res Notes,2019,26-06-2019,PMC6591835,,10.1186/s13104-019-4393-y,"OBJECTIVE: Forecasting the time of future outbreaks would minimize the impact of diseases by taking preventive steps including public health messaging and raising awareness of clinicians for timely treatment and diagnosis. The present study investigated the accuracy of support vector machine, artificial neural-network, and random-forest time series models in influenza like illness (ILI) modeling and outbreaks detection. The models were applied to a data set of weekly ILI frequencies in Iran. The root mean square errors (RMSE), mean absolute errors (MAE), and intra-class correlation coefficient (ICC) statistics were employed as evaluation criteria.
RESULTS: It was indicated that the random-forest time series model outperformed other three methods in modeling weekly ILI frequencies (RMSE = 22.78, MAE = 14.99 and ICC = 0.88 for the test set). In addition neural-network was better in outbreaks detection with total accuracy of 0.889 for the test set. The results showed that the used time series models had promising performances suggesting they could be effectively applied for predicting weekly ILI frequencies and outbreaks.","Comparative evaluation of time series models for predicting influenza outbreaks: application of influenza-like illness data from sentinel sites of healthcare centers in Iran OBJECTIVE: Forecasting the time of future outbreaks would minimize the impact of diseases by taking preventive steps including public health messaging and raising awareness of clinicians for timely treatment and diagnosis. The present study investigated the accuracy of support vector machine, artificial neural-network, and random-forest time series models in influenza like illness (ILI) modeling and outbreaks detection. The models were applied to a data set of weekly ILI frequencies in Iran. The root mean square errors (RMSE), mean absolute errors (MAE), and intra-class correlation coefficient (ICC) statistics were employed as evaluation criteria.
RESULTS: It was indicated that the random-forest time series model outperformed other three methods in modeling weekly ILI frequencies (RMSE = 22.78, MAE = 14.99 and ICC = 0.88 for the test set). In addition neural-network was better in outbreaks detection with total accuracy of 0.889 for the test set. The results showed that the used time series models had promising performances suggesting they could be effectively applied for predicting weekly ILI frequencies and outbreaks.",1
36007846,"Evaluating the ability of the NLHA2 and artificial neural network models to predict COVID-19 severity, and comparing them with the four existing scoring systems","Dong Y, Wang K, Zou X, Tan X, Zang Y, Li X, Ren X, Xie D, Jie Z, Chen X, Zeng Y, Shi J.",Microb Pathog. 2022 Oct;171:105735. doi: 10.1016/j.micpath.2022.105735. Epub 2022 Aug 23.,Dong Y,Microb Pathog,2022,25-08-2022,PMC9395227,,10.1016/j.micpath.2022.105735,"To improve the identification and subsequent intervention of COVID-19 patients at risk for ICU admission, we constructed COVID-19 severity prediction models using logistic regression and artificial neural network (ANN) analysis and compared them with the four existing scoring systems (PSI, CURB-65, SMARTCOP, and MuLBSTA). In this prospective multi-center study, 296 patients with COVID-19 pneumonia were enrolled and split into the General-Ward-Care group (N = 238) and the ICU-Admission group (N = 58). The PSI model (AUC = 0.861) had the best results among the existing four scoring systems, followed by SMARTCOP (AUC = 0.770), motified-MuLBSTA (AUC = 0.761), and CURB-65 (AUC = 0.712). Data from 197 patients (training set) were analyzed for modeling. The beta coefficients from logistic regression were used to develop a severity prediction model and risk score calculator. The final model (NLHA2) included five covariates (consumes alcohol, neutrophil count, lymphocyte count, hemoglobin, and AKP). The NLHA2 model (training: AUC = 0.959; testing: AUC = 0.857) had similar results to the PSI model, but with fewer variable items. ANN analysis was used to build another complex model, which had higher accuracy (training: AUC = 1.000; testing: AUC = 0.907). Discrimination and calibration were further verified through bootstrapping (2000 replicates), Hosmer-Lemeshow goodness of fit testing, and Brier score calculation. In conclusion, the PSI model is the best existing system for predicting ICU admission among COVID-19 patients, while two newly-designed models (NLHA2 and ANN) performed better than PSI, and will provide a new approach for the development of prognostic evaluation system in a novel respiratory viral epidemic.","Evaluating the ability of the NLHA2 and artificial neural network models to predict COVID-19 severity, and comparing them with the four existing scoring systems To improve the identification and subsequent intervention of COVID-19 patients at risk for ICU admission, we constructed COVID-19 severity prediction models using logistic regression and artificial neural network (ANN) analysis and compared them with the four existing scoring systems (PSI, CURB-65, SMARTCOP, and MuLBSTA). In this prospective multi-center study, 296 patients with COVID-19 pneumonia were enrolled and split into the General-Ward-Care group (N = 238) and the ICU-Admission group (N = 58). The PSI model (AUC = 0.861) had the best results among the existing four scoring systems, followed by SMARTCOP (AUC = 0.770), motified-MuLBSTA (AUC = 0.761), and CURB-65 (AUC = 0.712). Data from 197 patients (training set) were analyzed for modeling. The beta coefficients from logistic regression were used to develop a severity prediction model and risk score calculator. The final model (NLHA2) included five covariates (consumes alcohol, neutrophil count, lymphocyte count, hemoglobin, and AKP). The NLHA2 model (training: AUC = 0.959; testing: AUC = 0.857) had similar results to the PSI model, but with fewer variable items. ANN analysis was used to build another complex model, which had higher accuracy (training: AUC = 1.000; testing: AUC = 0.907). Discrimination and calibration were further verified through bootstrapping (2000 replicates), Hosmer-Lemeshow goodness of fit testing, and Brier score calculation. In conclusion, the PSI model is the best existing system for predicting ICU admission among COVID-19 patients, while two newly-designed models (NLHA2 and ANN) performed better than PSI, and will provide a new approach for the development of prognostic evaluation system in a novel respiratory viral epidemic.",1
26270814,"Comparison of Two Hybrid Models for Forecasting the Incidence of Hemorrhagic Fever with Renal Syndrome in Jiangsu Province, China","Wu W, Guo J, An S, Guan P, Ren Y, Xia L, Zhou B.",PLoS One. 2015 Aug 13;10(8):e0135492. doi: 10.1371/journal.pone.0135492. eCollection 2015.,Wu W,PLoS One,2015,14-08-2015,PMC4536138,,10.1371/journal.pone.0135492,"BACKGROUND: Cases of hemorrhagic fever with renal syndrome (HFRS) are widely distributed in eastern Asia, especially in China, Russia, and Korea. It is proved to be a difficult task to eliminate HFRS completely because of the diverse animal reservoirs and effects of global warming. Reliable forecasting is useful for the prevention and control of HFRS.
METHODS: Two hybrid models, one composed of nonlinear autoregressive neural network (NARNN) and autoregressive integrated moving average (ARIMA) the other composed of generalized regression neural network (GRNN) and ARIMA were constructed to predict the incidence of HFRS in the future one year. Performances of the two hybrid models were compared with ARIMA model.
RESULTS: The ARIMA, ARIMA-NARNN ARIMA-GRNN model fitted and predicted the seasonal fluctuation well. Among the three models, the mean square error (MSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of ARIMA-NARNN hybrid model was the lowest both in modeling stage and forecasting stage. As for the ARIMA-GRNN hybrid model, the MSE, MAE and MAPE of modeling performance and the MSE and MAE of forecasting performance were less than the ARIMA model, but the MAPE of forecasting performance did not improve.
CONCLUSION: Developing and applying the ARIMA-NARNN hybrid model is an effective method to make us better understand the epidemic characteristics of HFRS and could be helpful to the prevention and control of HFRS.","Comparison of Two Hybrid Models for Forecasting the Incidence of Hemorrhagic Fever with Renal Syndrome in Jiangsu Province, China BACKGROUND: Cases of hemorrhagic fever with renal syndrome (HFRS) are widely distributed in eastern Asia, especially in China, Russia, and Korea. It is proved to be a difficult task to eliminate HFRS completely because of the diverse animal reservoirs and effects of global warming. Reliable forecasting is useful for the prevention and control of HFRS.
METHODS: Two hybrid models, one composed of nonlinear autoregressive neural network (NARNN) and autoregressive integrated moving average (ARIMA) the other composed of generalized regression neural network (GRNN) and ARIMA were constructed to predict the incidence of HFRS in the future one year. Performances of the two hybrid models were compared with ARIMA model.
RESULTS: The ARIMA, ARIMA-NARNN ARIMA-GRNN model fitted and predicted the seasonal fluctuation well. Among the three models, the mean square error (MSE), mean absolute error (MAE) and mean absolute percentage error (MAPE) of ARIMA-NARNN hybrid model was the lowest both in modeling stage and forecasting stage. As for the ARIMA-GRNN hybrid model, the MSE, MAE and MAPE of modeling performance and the MSE and MAE of forecasting performance were less than the ARIMA model, but the MAPE of forecasting performance did not improve.
CONCLUSION: Developing and applying the ARIMA-NARNN hybrid model is an effective method to make us better understand the epidemic characteristics of HFRS and could be helpful to the prevention and control of HFRS.",1
